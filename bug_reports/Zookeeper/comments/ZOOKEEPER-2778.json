[Github user hanm closed the pull request at:

    https://github.com/apache/zookeeper/pull/247
, GitHub user hanm reopened a pull request:

    https://github.com/apache/zookeeper/pull/247

    ZOOKEEPER-2778: Potential server deadlock between follower sync with leader and follower receiving external connection requests.

    Remove synchronization requirements on certain methods to prevent dead lock. Current analysis indicates these methods don't require synchronization for them to work properly. Patch is stress tested with 1k runs of entire unit test suites.


You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/hanm/zookeeper ZOOKEEPER-2778

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/zookeeper/pull/247.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #247
    
----
commit 4453ab2a32f8b1a6d195a65c5466c1749bbb3464
Author: Michael Han <hanm@apache.org>
Date:   2017-05-06T05:13:26Z

    Potential server deadlock between follower sync with leader and follower receiving external connection requests.
    Remove synchronization requirements on certain methods to prevent dead lock. Current analysis indicates these methods don't require synchronization for them to work properly.

----
, +1 overall.  GitHub Pull Request  Build
      

    +1 @author.  The patch does not contain any @author tags.

    +0 tests included.  The patch appears to be a documentation patch that doesn't require tests.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs (version 3.0.1) warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    +1 core tests.  The patch passed core unit tests.

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-ZOOKEEPER-github-pr-build/667//testReport/
Findbugs warnings: https://builds.apache.org/job/PreCommit-ZOOKEEPER-github-pr-build/667//artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Console output: https://builds.apache.org/job/PreCommit-ZOOKEEPER-github-pr-build/667//console

This message is automatically generated., Github user afine commented on a diff in the pull request:

    https://github.com/apache/zookeeper/pull/247#discussion_r117582004
  
    --- Diff: src/java/main/org/apache/zookeeper/server/quorum/QuorumPeer.java ---
    @@ -682,27 +682,19 @@ public void setQuorumAddress(InetSocketAddress addr){
         }
     
         public InetSocketAddress getElectionAddress(){
    -        synchronized (QV_LOCK) {
    -            return myElectionAddr;
    -        }
    +        return myElectionAddr;
    --- End diff --
    
    > All set code path was protected by QV_LOCK already, which implies that whoever calls set* should already acquire the QV_LOCK.
    
    Not sure about this one. `setElectionAddress` is called by `recreateSocketAddresses` which is called by `QuorumCnxManager#Listener.run` without acquiring QV_LOCK. Not sure what the implication of this is. Although I believe you are correct about `setClientAddress`.
    
    > if we get out dated addr (in case the current quorum peer is being reconfigured) and sent this to another peer, another peer will not able to connect but that's fine, it will retry until at certain point later it will get correct information.
    
    What is the behavior if we are able to connect to the "incorrect peer". Will we eventually disconnect or do we stay connected until reconfiguration occurs again?
, Hello,

We are computer science PhD students building a Distributed model checking tool. We have been able to reproduce this issue too, when the QuorumPeer thread is racing with the Listener thread and gets into deadlock by requesting QCNXManager lock while holding QV_LOCK (on the other side, Listener thread holds QCNXManager lock and requests QV_LOCK). We also see this potential issue with the WorkerSender thread while performing toSend -> connectOne (one argument, requesting QCNXManager_LOCK) -> connectOne (two arguments, requesting QCNXManager_LOCK) -> initiateConnection -> getElectionAddress (requesting QV_LOCK) which can also race with the QuorumPeer thread for the same locks.

, Thanks for your efforts on reproducing this bug (and many others), [~castuardo]! I'll resume working on this soon., Hey,

Happy to help [~hanm]! Are we correct about the issue (regarding the path)?, bq. Are we correct about the issue (regarding the path)?

Yes it sounds right - what you said:
{noformat}
We also see this potential issue with the WorkerSender thread while performing toSend -> connectOne (one argument, requesting QCNXManager_LOCK) -> connectOne (two arguments, requesting QCNXManager_LOCK) -> initiateConnection -> getElectionAddress (requesting QV_LOCK) which can also race with the QuorumPeer thread for the same locks.
{noformat}

Feel free to create a separate JIRA for this issue.]