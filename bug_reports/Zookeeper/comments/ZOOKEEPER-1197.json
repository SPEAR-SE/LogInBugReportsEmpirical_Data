[I'm not sure how to write a test for this. On a local connection, especially within the same VM, I really doubt that I can reproduce the issue (no luck so far). I have tested this manually., -1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12495373/ZOOKEEPER-1197.patch
  against trunk revision 1172406.

    +1 @author.  The patch does not contain any @author tags.

    -1 tests included.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    +1 core tests.  The patch passed core unit tests.

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-ZOOKEEPER-Build/574//testReport/
Findbugs warnings: https://builds.apache.org/job/PreCommit-ZOOKEEPER-Build/574//artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Console output: https://builds.apache.org/job/PreCommit-ZOOKEEPER-Build/574//console

This message is automatically generated., Could you please be so kind to add the Code for review to https://reviews.apache.org/r/new/ ? Thank you!, After some manual testing I've verified that this greatly improves the problem, but does not completely solve it, so I'm still stuck on this. Any help would be appreciated, this is a major annoyance when monitoring over any sort of WAN, One more update for this. After talking to some folks here that are more networking experts than I am, it appears that the only way to truly fix this bug is to allow the client to initiate the close of the socket, not the server. Because a socket close event (especially in recent Linux kernels) may cause the kernel to give up on sending data even when the server has not finished/received acks, the only way to guarantee that a client has actually received all the data is to wait for the client to close the connection. We can add a timeout in the server to clean up 4lw clients that have not closed their connection, but we cannot rely on all of the data getting to the client without an explicit client close., Camille, is setting the socket to linger an option here?, socket linger has no effect on this bug., Could you elaborate please? My understanding is that the linger option is there exactly to allow unsent data to be transmitted, so I'm not sure why you say that it has no effect., I'm saying, in my testing, setting this value has never had any effect. It seem that the OS is ignoring this setting., Camille,
 What do we want to do then? Closing the connection from client is probably not feasible. Should we just checkin what we have? I am not a big fan of letting the connections linger on the server and then close them later. , I'm not entirely sure why closing the connection from the client isn't feasible. Right now, if we were to leave the client connection as it is, it would still close itself in nc non-interactive (and possibly truncate the data), and for other clients it would close when the client closed, or we could put a timeout around connections created with a 4lw since we can identify them. I think the trickier thing is that anything else that comes in off a 4lw connection causes an IO length exception which is nasty. 

I'll play with SO_LINGER again. It doesn't fix this problem in my testing, but my testing was under windows. If it makes it better in linux, it's still worth doing for that bit., Can you take a look at ZOOKEEPER-1237 ? I believe we're seeing the same issue for regular sessions. This shows up much more frequently once linger is turned off (at least in my testing of ZOOKEEPER-1049 that seems to be the case).

Seems we need to do a better job coordinating session/4lw teardown across the board?, Interesting web page I found: http://ia600609.us.archive.org/22/items/TheUltimateSo_lingerPageOrWhyIsMyTcpNotReliable/the-ultimate-so_linger-page-or-why-is-my-tcp-not-reliable.html, Based on the second code snippet in the link Patrick found, I've written an alternate patch (ZOOKEEPER-1197_shutdown.patch) that waits for the client to shutdown the input connection before closing the socket.

I've managed to reproduce the problem locally for testing:
0. My base setup: trunk zk checkout, Ubuntu 12.04, Oracle Java 6, no fancy zoo.cfg 
1. I wrote a new 4lw, "long", that prints 100k '.'s followed by a '!' (so you can see if it's truncated). See long_4lw.patch.
2. Slow down your localhost connection: sudo tc qdisc add dev lo root netem delay 1000ms 
(To undo this command: sudo tc qdisc del dev lo root) 
3. Start a zk server with ./bin/zkServer.sh start 
4. Send a long command: echo long | nc localhost 2181 (I've also been using FourLetterWordMain) 
This should fill your terminal with dots, but shouldn't end with a !. If you see the !, the output wasn't truncated (i.e., you haven't hit the bug).

The new patch fixes the bug with this setup. Camille's patch also fixes it, although I do not fully understand how :) Since Camille reports having problems even after applying her patch (which I could not reproduce), this patch probably needs further testing as well. It would also be useful to test with a variety of clients (it sounds like this is the standard way to close a TCP connection, but I'm not positive every client will shut down the connection correctly)., afaik this is not a solvable problem short of implementing the client/server side properly - ala ZOOKEEPER-1346

Should we close this? (as unfixable)]