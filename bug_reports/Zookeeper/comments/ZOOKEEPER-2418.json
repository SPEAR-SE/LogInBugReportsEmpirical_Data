[Thanks for reporting this, [~nwolchko]. In your example, what happens to txns 451-499 at the leader? They don't seem to be in the memory commit log or the disk log. , Zookeeper applied them normally, but they were flushed from the commit log because it only stores the most recent transactions., When you say that ZK has applied them normally, I think you mean that 2, 3, and 4 have applied them. The leader can't have applied them because in your example they haven't gone through SyncRequestProcessor yet, otherwise they would be on disk. I feel that I'm missing something here..., Transactions are applied based on receiving a quorum of acks. The SyncRequestProcessor being stalled prevents the leader from acking proposals,  but committing is based only on receiving enough acks. If there are a quorum of followers who have acked the proposal, the leader will continue to commit the transaction even though it didn't ack it itself.

In my example the leader has applied all transactions from 1-1000 to its data tree even though the SyncRequestProcessor is stalled., Got it, I think you're referring to this logic in {{LearnerHandler}}:

{noformat}
                    LOG.info("Use txnlog and committedLog for peer sid: " +  getSid());
                    currentZxid = queueCommittedProposals(txnLogItr, peerLastZxid,
                                                         minCommittedLog, maxCommittedLog);

                    LOG.debug("Queueing committedLog 0x" + Long.toHexString(currentZxid));
                    Iterator<Proposal> committedLogItr = db.getCommittedLog().iterator();
                    currentZxid = queueCommittedProposals(committedLogItr, currentZxid,
                                                         null, maxCommittedLog);
{noformat}

We are currently assuming that the two sequences (txn log and committed log) overlap, but as your example rightfully shows, it may not be the case. There are three options I see here:

# Error the attempt to join the follower
# Block new commits until the leader catches up
# Leader drops leadership

The first option is better than having a gap, but I'm concerned that the leader might end up with a gap for a long time and may keep dropping followers. The second forces the leader to catch up, but it may be desirable to use the third in the case the leader is lagging behind. Having the leader slowing down the ensemble is not ideal. 
]