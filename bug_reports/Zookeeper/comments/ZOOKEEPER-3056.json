[cc [~nixon], [~breed] who introduced the check in ZOOKEEPER-2325.

What do you guys think about this? Do you always have valid snapshot files in your deployment?, [~hanm] [~nixon] [~breed]

 

 

Do you think it is worth reverting that change first? Or maybe put the validation in a if-else branch and controlled by a configuration setting. So people who is using 3.4.6 can turn the flag off for upgrading and turn the flag on after upgrade., I think we just need to differentiate the state of missing snapshot vs not taking a snapshot file. To do that, we can create a signal file under the dataLogDir whenever we are taking our first snapshot. The presence of that signal file indicates there is a dependency between transaction logs and snapshot and we can't just ignore the missing snapshot file. The conditional check now checks both the presence of that signal file and the snapshot file, and it only complains if it found the signal file but not found the snapshot file. This should cover all cases include upgrade. Note this is a best effort as it's still possible to subvert the effort but I think it's fine as we don't deal with Byzantine faults. , We have not run an ensemble without some form of ZOOKEEPER-2325 in years, as such we always have snapshots available and ZooKeeper being unable to load a valid snapshot is a sign that something is very wrong.

From my read on the mail thread there are two questions that we're trying to answer:
- how to update ensembles without snapshots from a pre-2325 to a post-2325 state
- what constitutes a stable db (and what role a snapshot plays in that)

The second ought to take more thought so I'll follow up on that after considering it.

Two possible interventions on the first:
- the base snapshot is very small and simple, one could copy/create a snapshot.0 file to the appropriate directory before upgrade
- property gate the entire "-1L == deserializeResult" conditional block in 3.4, 3.5, and master to allow a snapshot-less db. To the extent that we agree that snapshot-less is a degenerate mode, we also add a 4 letter or admin command to create a snapshot on demand (allowing the admin to quickly move out of this state post-upgrade), [~nixon] My concern is that in most cases there might not be an experienced ZK admin available, confortable in doing that operation. I would hope for a way to get a seamless migration path from 3.4 to 3.5 that doesn't require manual intervention. A flag to turn off that validation would be helpful. The risk is understood, but it would be the same behavior as in ZK-3.4.x., I agree we should try providing a seamless upgrade path. 

[~nixon] What do you think about my previous proposal on the signal file? I think it's pretty similar with the initialization marker file you introduced in ZK-261 whose presence indicate trust empty DB or not. The signal file's presence indicate trust of the transaction log alone or not (or, ignore the -1L == deserializeResult check or not).

This is like an automatic flag to turn on / off the deserializeResult check by ZK itself., [~mmerli] That's a very reasonable concern and I'd ideally have all upgrades be seamless in exactly the way you describe. Property gating the validation is only undesirable from a proliferation of config point of view.

[~hanm] I think the signal file is a very workable approach and pretty straightforward to implement. The first intervention that I scoped out (create a snapshot.0) was inspired by yours as it simplifies the path of "signal file" to "database load with trust in the transaction log" to "create snapshot, delete signal file". -- It's a trade-off between admin time and server side code complexity for sure.

In order of decreasing seamlessness/admin time:
 * property flag snapshot validation (default off)
 * property flag snapshot validation (default on)
 * signal file
 * admin script to create a snapshot.0 file in the snapshot directory
 * upgrade notes to create a snapshot.0 file in the snapshot directory

For the use cases that we maintain, it's far more likely that being unable to load a snapshot indicates corruption or machine malfeasance than a legitimate database so I'd like to expand that impression with more information from the community. Is a snapshot-less db expected/unremarkable under some reasonable workloads or is it something worth (politely) discouraging? I do believe ZOOKEEPER-2325 is a good feature and it would be a shame to set it off by default., how are you getting in a state where you have log file but no snapshot? is it that a machine starts up with no data and then diff syncs with the leader? or is there another case that i'm missing.

trying to use a txn log with no base snapshot seems frought with danger.

 , The main case is with ZK 3.4.x, for example with a single ZK quorum (though I think that would happen in the same way in a multi-node cluster).

 

 * Start ZK with 3.4.X

 * Create few z-nodes (not enough to trigger snapshot)

 * Stop ZK

 * Start with ZK 3.5.x --> Fail because snapshot is missing

 

 , {quote}It's a trade-off between admin time and server side code complexity for sure.
{quote}
I agree. If a snapshot-less use case is rare, it's better to provide an admin ool to force generate a snapshot before upgrade (or migrate data), to keep a simple server side code. 
{quote}I do believe ZOOKEEPER-2325is a good feature and it would be a shame to set it off by default.
{quote}
I agree, data consistency is important and even if we decide to provide such a flag, the check should be enabled by default.

 , As a work-around for anyone currently blocked on this issue, I've uploaded a empty snapshot file here.

To perform an upgrade (3.4 -> 3.5):
 * download the "snapshot.0" file attached
 * copy it to the versioned directory (e.g. "version-2") within your data directory (parameter "dataDir" in your config - this is the directory containing the "myid" file for a peer)
 * restart the peer
 * upgrade the peer (this can be combined with the above step if you like)

 ]