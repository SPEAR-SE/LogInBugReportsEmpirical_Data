[If anyone can assign this to me, I'll upload the patch I have., I added you to the list, you should be able to assign JIRAs to yourself now. Thanks!, -1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12816961/ZOOKEEPER-2471.patch
  against trunk revision 1750739.

    +1 @author.  The patch does not contain any @author tags.

    -1 tests included.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    +1 core tests.  The patch passed core unit tests.

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-ZOOKEEPER-Build/3268//testReport/
Findbugs warnings: https://builds.apache.org/job/PreCommit-ZOOKEEPER-Build/3268//artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Console output: https://builds.apache.org/job/PreCommit-ZOOKEEPER-Build/3268//console

This message is automatically generated., GitHub user DanBenediktson opened a pull request:

    https://github.com/apache/zookeeper/pull/330

    ZOOKEEPER-2471: ZK Java client should not count sleep time as connect time

    ClientCnxnSocket uses a member variable "now" to track the current time, but does not update it at all potentially-blocking times: in particular, it does not update it after the random sleep introduced if an initial connect attempt fails. This results in the random sleep time being counted towards connect time, resulting in incorrect application of connection timeout currently, and if ZOOKEEPER-2869 is taken, a very real possibility (we have seen it in production) of wedging the Zookeeper client so that it can never successfully reconnect, because its sleep time may grow beyond its connection timeout, especially in scenarios where there is a big gap between negotiated session timeout and client-requested session timeout.
    
    Rather than fixing the bug by adding another "updateNow()" call, keeping the brittle "updateNow()" implementation which led to the bug in the first place, I have deleted updateNow() and replaced usage of that member variable with actually getting the current system timestamp whenever the implementation needs to know the current time.
    
    Regarding unit testing, this is, IMO, too difficult to test without introducing a lot of invasive changes to ClientCnxn.java, seeing as the only effective change is that, on connection retry, the random sleep time is no longer counted towards a time budget. I can throw a lot of mocks at this, like ClientReconnectTest, but I'm still going to be stuck depending on the behavior of that randomly-generated sleep time, which is going to be inherently unreliable. If a fix is taken for ZOOKEEPER-2869, this should become much easier to test, since I will then be able to inject a different backoff sleep behavior, and since I'm planning to submit a pull request for that ticket as well, so maybe as a compromise I can submit a test for this bug fix at that time?

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/DanBenediktson/zookeeper ZOOKEEPER-2471

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/zookeeper/pull/330.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #330
    
----
commit 60f38726e7f07b4bb970cc8fb089363ff48eb3df
Author: Dan Benediktson <dbenediktson@twitter.com>
Date:   2017-08-09T16:41:42Z

    ZOOKEEPER-2471: Zookeeper Java client should not count time spent sleeping as time spent connecting
    
    Rather than keep the brittle "updateNow()" implementation which led to the bug and fixing the bug by
    adding another "updateNow()" call, I have deleted updateNow() and replaced usage of that member variable
    with actually getting the current system timestamp.
    
    This is, IMO, too difficult to test without introducing a lot of invasive changes to ClientCnxn.java,
    seeing as the only effective change is that, on connection retry, a random sleep time is no longer
    counted towards a time budget. If a fix is taken for ZOOKEEPER-2869, this should become much easier to
    test, and since I'm planning to submit a pull request for that ticket as well, maybe as a compromise
    I can submit a test for this patch at that time?

----
, -1 overall.  GitHub Pull Request  Build
      

    +1 @author.  The patch does not contain any @author tags.

    +0 tests included.  The patch appears to be a documentation patch that doesn't require tests.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs (version 3.0.1) warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    -1 core tests.  The patch failed core unit tests.

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-ZOOKEEPER-github-pr-build/929//testReport/
Findbugs warnings: https://builds.apache.org/job/PreCommit-ZOOKEEPER-github-pr-build/929//artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Console output: https://builds.apache.org/job/PreCommit-ZOOKEEPER-github-pr-build/929//console

This message is automatically generated., Core tests that I see failed in the log both had already passed on my local run:
ChrootClientTest.testNonExistingOpCode
WatchEventWhenAutoResetTest.testNodeDataChanged

The first one is clearly suspicious because my patch allegedly "fixed" the corresponding ClientTest.testNonExistingOpCode, which it shouldn't have done anything about, so I'm pretty certain that's just a flaky test.

I've tried running both of those test cases about 10 times on my MBP to no avail; they pass every time. I also already ran the full "ant test" suite before submitting the patch in the first place, and it all succeeded.

Any suggestions here?, These are known flaky tests. See ZOOKEEPER-2786, ZOOKEEPER-2807. They usually pass when run in isolation, because the flaky behavior is only triggered under specific conditions - e.g. when server uses Netty instead of NIO, or when multiple tests implicitly share resources but they shouldn't. If you also use Jenkins, you can set up a Jenkins job to stress test entire unit tests - that is what I usually do before declaring a flaky test is fixed, aside from doing code reviews and local verifications., +1 overall.  GitHub Pull Request  Build
      

    +1 @author.  The patch does not contain any @author tags.

    +0 tests included.  The patch appears to be a documentation patch that doesn't require tests.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs (version 3.0.1) warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    +1 core tests.  The patch passed core unit tests.

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-ZOOKEEPER-github-pr-build/932//testReport/
Findbugs warnings: https://builds.apache.org/job/PreCommit-ZOOKEEPER-github-pr-build/932//artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Console output: https://builds.apache.org/job/PreCommit-ZOOKEEPER-github-pr-build/932//console

This message is automatically generated., Github user nicktrav commented on the issue:

    https://github.com/apache/zookeeper/pull/330
  
    Feels a little awkward to have a non-trivial change without any tests :/
    
    > I'm still going to be stuck depending on the behavior of that randomly-generated sleep time, which is going to be inherently unreliable
    
    Thinking aloud here ... given your second commit updates to use the `Time` utility, could you now inject that class, (or perhaps a faked implementation given the methods are static), into `ClientCnxnSocket` and its subclasses? This would make it more amenable to testing. You'd have more control over the times that are returned.
    
    You'd still need to plumb that through into `ClientCnxn`, but it looks like the constructor takes a `ClientCnxnSocket`, which could work here?
    
    Maybe we can get that scaffolding wired up in another PR, get that merged in, and this change could leverage that?
, Github user hanm commented on the issue:

    https://github.com/apache/zookeeper/pull/330
  
    The `now` variable was there when this project starts, and `updateNow` was introduced in ZOOKEEPER-909 which was just a refactoring so it's irrelevant to the core logic. I had a chat with @phunt who wrote the original code and the `now` was not introduced by accident - according to Pat it's used to solve two problems:
    * A performance optimization by caching as on some platforms getting current time is not cheap.
    * On some platforms get current time will go backwards so to prevent that a cached time was used at the very start.
    Now after 10 years and many changes (like using monotonic clock) the original design might become irrelevant, and it might make sense to instead calculate the now time when needed. Though, I'd like to have another look into this issue before making a conclusion.
    
    One idea is to have a test case that shows the bug (client infinity connect loop etc), and then verify that the bug gets fixed with the patch. This will be more convincing. I understand writing such test takes more effort than the patch itself, but eventually it's something must to have for such a change.
    
    On a side note - this patch is doing fine with my stress test and does not cause any regressions.
    

, Github user nicktrav commented on the issue:

    https://github.com/apache/zookeeper/pull/330
  
    @DanBenediktson - I've been looking into writing a test for this patch, but I can't seem to replicate the case you speak about on the original ticket.
    
    Specifically:
    
    > The exact code path it goes through in this case is complicated, because there has to be a previously-closed socket still waiting in the selector (otherwise, the first timeout evaluation will not fail because "now" still hasn't been updated, and then the actual connect timeout will be applied in ClientCnxnSocket.doTransport()) so that select() will harvest the IO from the previous socket and updateNow(), resulting in the next loop through ClientCnxnSocket.SendThread.run() observing the spurious timeout and failing.
    
    Are you able to provide some more details on how this client can get into this state? Walking through the code, I'm having difficulty understanding how the client can end up a reconnect loop.
    
    We are keen to see this patch land as it would make a fix for ZOOKEEPER-2869 inherently safer.
, Thanks for the reviews, [~nickt] and [~hanm]. Sorry, I should have been more clear about the scenario: although I didn't realize it at the time I initially filed this bug (I wasn't aware of the extent of the divergence of my own fork from mainline), I don't think you can reasonably run into an infinite connect loop on *current* Apache Zookeeper. On the current code base, hitting an infinite connect loop basically requires falling victim to the random number generator repeatedly; not likely at all.

However, if you pick up exponential backup from ZOOKEEPER-2869, it becomes a certainty if you hit the right conditions: basically, you just need to get enough initial failures to rack up a large exponential sleep backoff, which in practice happened to us during leader election on a large ensemble, and then your sleep time can potentially outgrow your connect timeout. That's somewhat dependent on the backoff algorithm used, but the one we have is pretty reasonable in how it caps the backoff, and it was certainly still possible there: we had applications which went down completely since they were unable to connect to ZK until we recycled the application every time we leader elected the ensemble they talked to, until we fixed this.

So, that's why I suggested in the pull request that maybe a compromise would be to submit tests along with ZOOKEEPER-2869: a lot of the machinery that's needed to make this testable is actually stuff that can be introduced as part of the product feature in ZOOKEEPER-2869., Thanks for the response [~dbenediktson]. Re-reading your comments, I just can't seem to replicate the case you talk about where a client gets stuck in a reconnect loop.

Here's how I'm testing this:
- introduce an artificially high sleep time (say 5 seconds), replacing the random timeout in the client [here|https://github.com/apache/zookeeper/blob/release-3.5.3/src/java/main/org/apache/zookeeper/ClientCnxn.java#L1059], via what is essentially a crude patch for ZOOKEEPER-2869 
- Set up an ensemble of 5 ZK servers
- Set up a client with an artificially low connect timeout of 1 second, as you describe. Wait for an initial client connection to be established
- Trigger a leader re-election by restarting the current leader
- At this point, the client sleeps for the artificially long timeout for a few cycles through the loop, until the leader has been re-elected
- Ultimately, the client is able to reconnect

I'm not observing the infinite reconnect loop you describe.

In my mind it makes more sense to be able to observe this bug first before trying to patch it, and that seems to come up only _after_ introducing a fix for ZOOKEEPER-2869.

What do you think about opening an additional PR for ZOOKEEPER-2869 so we can try to more easily reproduce the bug for ZOOKEEPER-2471? At that point the test scaffolding will be in place to make this task much easier., Github user nicktrav commented on the issue:

    https://github.com/apache/zookeeper/pull/330
  
    @DanBenediktson - bumping this. Any thoughts?
, Hey, sorry, I've been meaning to get back to this, but I wasn't expecting to sign up for porting the exponential backoff retry until this was in. Polishing that patch up so that it can be accepted in mainline will take me a fair bit more time, since our version of the code straight-up replaced the existing logic with jittered exponential backoff (we haven't run a JVM ZK client without jittered exponential backoff in > 1.5 years), and I doubt Apache ZK would be willing to accept that. I simply don't have time right now to do that work, and won't for at least a month. It also makes me a bit nervous to offer a pull request for the exponential backoff feature without this fix already checked in, since this was an extremely expensive bug for us, but I'm sympathetic to the desire to unit test it; we simply didn't have time to concoct a unit test back when we needed the fix urgently, since the nature of Zookeeper code makes it generally pretty difficult to add unit tests for most areas, including this one., We (Square) are less concerned with this bug, more so with the exponential backoff fix for ZOOKEEPER-2869. Given we've not been able to reproduce the infinite reconnect issue (on both mainline as well as 3.4.x with our patch applied), I more inclined to say that a merging a fix for ZOOKEEPER-2869 makes more sense right now. I think that would, at least, make reproducing the infinite reconnect issue easier in the future, as it provides a means to set up a client with an artificially high reconnect time.

We have a patch for ZOOKEEPER-2869 that we are running internally, with tests (\!), that we'd be happy to offer up for review.

[~hanm] - any thoughts on the best path forward here?]