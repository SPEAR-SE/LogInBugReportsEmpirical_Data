[We're also wondering if this could be related to ZOOKEEPER-1732 and ZOOKEEPER-2172, We are experiencing this as well, but the node that continually drops the connection does not have the smallest {{myid}} – here it is 6 but 5 is the smallest (5, 6, 7 are the IDs).  ZooKeeper 3.4.6.  Killing the leader resulted in the full ensemble returning.

{code:java}
2018-02-12 16:29:48,428 [myid:6] - INFO  [Thread-1:QuorumCnxManager$Listener@504] - My election bind port: /10.122.11.104:6666
2018-02-12 16:29:48,440 [myid:6] - INFO  [QuorumPeer[myid=6]/0.0.0.0:4444:QuorumPeer@714] - LOOKING
2018-02-12 16:29:48,443 [myid:6] - INFO  [QuorumPeer[myid=6]/0.0.0.0:4444:FastLeaderElection@815] - New election. My id =  6, proposed zxid=0x1b00653e67
2018-02-12 16:29:48,453 [myid:6] - INFO  [WorkerSender[myid=6]:QuorumCnxManager@193] - Have smaller server identifier, so dropping the connection: (7, 6)
2018-02-12 16:29:48,453 [myid:6] - INFO  [WorkerReceiver[myid=6]:FastLeaderElection@597] - Notification: 1 (message format version), 6 (n.leader), 0x1b00653e67 (n.zxid), 0x1 (n.round), LOOKING (n.state), 6 (
n.sid), 0x1b (n.peerEpoch) LOOKING (my state)
2018-02-12 16:29:48,657 [myid:6] - INFO  [QuorumPeer[myid=6]/0.0.0.0:4444:FastLeaderElection@849] - Notification time out: 400
2018-02-12 16:29:48,657 [myid:6] - INFO  [WorkerReceiver[myid=6]:FastLeaderElection@597] - Notification: 1 (message format version), 6 (n.leader), 0x1b00653e67 (n.zxid), 0x1 (n.round), LOOKING (n.state), 6 (
n.sid), 0x1b (n.peerEpoch) LOOKING (my state)
2018-02-12 16:29:48,658 [myid:6] - INFO  [WorkerSender[myid=6]:QuorumCnxManager@193] - Have smaller server identifier, so dropping the connection: (7, 6)
2018-02-12 16:29:49,058 [myid:6] - INFO  [QuorumPeer[myid=6]/0.0.0.0:4444:FastLeaderElection@849] - Notification time out: 800
2018-02-12 16:29:49,058 [myid:6] - INFO  [WorkerReceiver[myid=6]:FastLeaderElection@597] - Notification: 1 (message format version), 6 (n.leader), 0x1b00653e67 (n.zxid), 0x1 (n.round), LOOKING (n.state), 6 (
n.sid), 0x1b (n.peerEpoch) LOOKING (my state)
2018-02-12 16:29:49,859 [myid:6] - INFO  [QuorumPeer[myid=6]/0.0.0.0:4444:FastLeaderElection@849] - Notification time out: 1600
2018-02-12 16:29:50,058 [myid:6] - INFO  [WorkerSender[myid=6]:QuorumCnxManager@193] - Have smaller server identifier, so dropping the connection: (7, 6)
2018-02-12 16:29:50,059 [myid:6] - INFO  [WorkerReceiver[myid=6]:FastLeaderElection@597] - Notification: 1 (message format version), 6 (n.leader), 0x1b00653e67 (n.zxid), 0x1 (n.round), LOOKING (n.state), 6 (
n.sid), 0x1b (n.peerEpoch) LOOKING (my state)
2018-02-12 16:29:50,059 [myid:6] - INFO  [WorkerSender[myid=6]:QuorumCnxManager@193] - Have smaller server identifier, so dropping the connection: (7, 6)
2018-02-12 16:29:51,660 [myid:6] - INFO  [QuorumPeer[myid=6]/0.0.0.0:4444:FastLeaderElection@849] - Notification time out: 3200
2018-02-12 16:29:51,660 [myid:6] - INFO  [WorkerReceiver[myid=6]:FastLeaderElection@597] - Notification: 1 (message format version), 6 (n.leader), 0x1b00653e67 (n.zxid), 0x1 (n.round), LOOKING (n.state), 6 (
n.sid), 0x1b (n.peerEpoch) LOOKING (my state)
2018-02-12 16:29:51,660 [myid:6] - INFO  [WorkerSender[myid=6]:QuorumCnxManager@193] - Have smaller server identifier, so dropping the connection: (7, 6)
2018-02-12 16:29:54,861 [myid:6] - INFO  [QuorumPeer[myid=6]/0.0.0.0:4444:FastLeaderElection@849] - Notification time out: 6400
2018-02-12 16:29:54,861 [myid:6] - INFO  [WorkerReceiver[myid=6]:FastLeaderElection@597] - Notification: 1 (message format version), 6 (n.leader), 0x1b00653e67 (n.zxid), 0x1 (n.round), LOOKING (n.state), 6 (
n.sid), 0x1b (n.peerEpoch) LOOKING (my state)
2018-02-12 16:29:54,862 [myid:6] - INFO  [WorkerSender[myid=6]:QuorumCnxManager@193] - Have smaller server identifier, so dropping the connection: (7, 6)
2018-02-12 16:30:01,262 [myid:6] - INFO  [QuorumPeer[myid=6]/0.0.0.0:4444:FastLeaderElection@849] - Notification time out: 12800
2018-02-12 16:30:01,263 [myid:6] - INFO  [WorkerReceiver[myid=6]:FastLeaderElection@597] - Notification: 1 (message format version), 6 (n.leader), 0x1b00653e67 (n.zxid), 0x1 (n.round), LOOKING (n.state), 6 (
n.sid), 0x1b (n.peerEpoch) LOOKING (my state)
2018-02-12 16:30:01,263 [myid:6] - INFO  [WorkerSender[myid=6]:QuorumCnxManager@193] - Have smaller server identifier, so dropping the connection: (7, 6)
2018-02-12 16:30:02,050 [myid:6] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:4444:NIOServerCnxnFactory@197] - Accepted socket connection from /127.0.0.1:54541
2018-02-12 16:30:02,057 [myid:6] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:4444:NIOServerCnxn@827] - Processing ruok command from /127.0.0.1:54541
2018-02-12 16:30:02,060 [myid:6] - INFO  [Thread-2:NIOServerCnxn@1007] - Closed socket connection for client /127.0.0.1:54541 (no session established for client)
2018-02-12 16:30:02,449 [myid:6] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:4444:NIOServerCnxnFactory@197] - Accepted socket connection from /127.0.0.1:54611
2018-02-12 16:30:02,450 [myid:6] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:4444:NIOServerCnxn@827] - Processing ruok command from /127.0.0.1:54611
2018-02-12 16:30:02,451 [myid:6] - INFO  [Thread-3:NIOServerCnxn@1007] - Closed socket connection for client /127.0.0.1:54611 (no session established for client)
2018-02-12 16:30:02,789 [myid:6] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:4444:NIOServerCnxnFactory@197] - Accepted socket connection from /127.0.0.1:54671
2018-02-12 16:30:02,790 [myid:6] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:4444:NIOServerCnxn@827] - Processing ruok command from /127.0.0.1:54671
2018-02-12 16:30:02,791 [myid:6] - INFO  [Thread-4:NIOServerCnxn@1007] - Closed socket connection for client /127.0.0.1:54671 (no session established for client)
... these messages continue
{code}, On our other quorum peers, we see a lot of connections in CLOSE_WAIT state to port 4181. Could these somehow prevent the quorum peer from processing leader election messages from the affected peer?, We have received similar issue in quorum of 5 nodes, id: 1, 2, 3, 4, 5. Here 2 & 4 have connection error from node 3. Node 5 is leader.

Node 3 while connecting to 2 & 4 failed due to connection error. But its giving similar error:
Have smaller server identifier, so dropping the connection: (5, 3)
And node 3 not able to join the quorum. But it should join (but 3 nodes are running as required for quorum)., [~bothra90]

Thanks for reporting this issue, I'm taking a look at it. You mentioned that's it might be related to ZOOKEEPER-1732, are you sure about that? That would mean that it had never been fixed.

Because the log snippet you provided and the one I can see from [~adamjshook] doesn't seem to me related. In the original issue there wasn't any connection problem between the participants. The node was unable to join the ensemble even though it had all the necessary information of the running ensembe. (e.g. all notifications from other servers)

[~sumitagrawal] This applies to your report as well, it looks like you all had similar issues, but I doubt it's anyhow related to 1732.

[~fpj] Would you please take a very quick look at this ticket?

You worked on the original issues and might be able to confirm that this is not related. Thanks., [~bothra90] [~adamjshook] [~sumitagrawal]

Are you saying that restarting only the failing node didn't solve the problem?

So, basically you had to restart the leader itself to get the full ensemble working again?, [~andorm]: Yes, restarting the failing node does not help, but restarting the leader does.]