{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12552443","self":"https://issues.apache.org/jira/rest/api/2/issue/12552443","key":"ZOOKEEPER-1453","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310801","id":"12310801","key":"ZOOKEEPER","name":"ZooKeeper","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310801&avatarId=10011","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310801&avatarId=10011","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310801&avatarId=10011","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310801&avatarId=10011"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10484","id":"10484","description":"Apache ZooKeeper related","name":"ZooKeeper"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":"2012-06-21T20:03:19.622+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Fri Mar 18 20:05:28 UTC 2016","customfield_12310420":"236868","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/ZOOKEEPER-1453/watchers","watchCount":7,"isWatching":false},"created":"2012-04-24T22:05:10.308+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/2","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/critical.svg","name":"Critical","id":"2"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"6.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12315482","id":"12315482","description":"Fix release against 3.3 branch","name":"3.3.3","archived":false,"released":true,"releaseDate":"2011-02-27"}],"issuelinks":[],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2016-03-18T20:05:28.220+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12312382","id":"12312382","name":"server","description":"General issues with the ZooKeeper server."}],"timeoriginalestimate":null,"description":"See ZOOKEEPER-1449 for background on this issue. The main problem is that during server recovery org.apache.zookeeper.server.persistence.FileTxnLog.FileTxnIterator.next() does not indicate if the available logs are valid or not. In some cases (say a truncated record and a single txnlog in the datadir) we will not detect that the file is corrupt, vs reaching the end of the file.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12535449","id":"12535449","filename":"10.10.5.123.tar.gz","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=marshall","name":"marshall","key":"marshall","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Marshall McMullen","active":true,"timeZone":"America/Denver"},"created":"2012-07-06T22:48:18.132+0000","size":4367232,"mimeType":"application/x-gzip","content":"https://issues.apache.org/jira/secure/attachment/12535449/10.10.5.123.tar.gz"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12535475","id":"12535475","filename":"10.10.5.123-withPath1489.tar.gz","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=marshall","name":"marshall","key":"marshall","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Marshall McMullen","active":true,"timeZone":"America/Denver"},"created":"2012-07-06T23:40:40.448+0000","size":4726089,"mimeType":"application/x-gzip","content":"https://issues.apache.org/jira/secure/attachment/12535475/10.10.5.123-withPath1489.tar.gz"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12535447","id":"12535447","filename":"10.10.5.42.tar.gz","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=marshall","name":"marshall","key":"marshall","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Marshall McMullen","active":true,"timeZone":"America/Denver"},"created":"2012-07-06T22:48:18.110+0000","size":1146520,"mimeType":"application/x-gzip","content":"https://issues.apache.org/jira/secure/attachment/12535447/10.10.5.42.tar.gz"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12535473","id":"12535473","filename":"10.10.5.42-withPath1489.tar.gz","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=marshall","name":"marshall","key":"marshall","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Marshall McMullen","active":true,"timeZone":"America/Denver"},"created":"2012-07-06T23:40:40.427+0000","size":892091,"mimeType":"application/x-gzip","content":"https://issues.apache.org/jira/secure/attachment/12535473/10.10.5.42-withPath1489.tar.gz"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12535448","id":"12535448","filename":"10.10.5.44.tar.gz","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=marshall","name":"marshall","key":"marshall","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Marshall McMullen","active":true,"timeZone":"America/Denver"},"created":"2012-07-06T22:48:18.124+0000","size":1798040,"mimeType":"application/x-gzip","content":"https://issues.apache.org/jira/secure/attachment/12535448/10.10.5.44.tar.gz"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12535474","id":"12535474","filename":"10.10.5.44-withPath1489.tar.gz","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=marshall","name":"marshall","key":"marshall","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Marshall McMullen","active":true,"timeZone":"America/Denver"},"created":"2012-07-06T23:40:40.439+0000","size":1569363,"mimeType":"application/x-gzip","content":"https://issues.apache.org/jira/secure/attachment/12535474/10.10.5.44-withPath1489.tar.gz"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"32550","customfield_12312823":null,"summary":"corrupted logs may not be correctly identified by FileTxnIterator","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=phunt","name":"phunt","key":"phunt","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Patrick Hunt","active":true,"timeZone":"America/Los_Angeles"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=phunt","name":"phunt","key":"phunt","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Patrick Hunt","active":true,"timeZone":"America/Los_Angeles"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12552443/comment/13398809","id":"13398809","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=marshall","name":"marshall","key":"marshall","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Marshall McMullen","active":true,"timeZone":"America/Denver"},"body":"We've hit this bug a few times now and are wondering if there are any thoughts around this or what the fix for this would entail. Perhaps adding an md5 file for each snapshot/log file.  Then on startup it can discard any that are corrupted... Thoughts?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=marshall","name":"marshall","key":"marshall","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Marshall McMullen","active":true,"timeZone":"America/Denver"},"created":"2012-06-21T20:03:19.622+0000","updated":"2012-06-21T20:03:19.622+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12552443/comment/13398997","id":"13398997","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=phunt","name":"phunt","key":"phunt","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Patrick Hunt","active":true,"timeZone":"America/Los_Angeles"},"body":"I don't think we need to do that, we just need to handle these cases better. We already have a checksum on the record but we're not handling all the cases.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=phunt","name":"phunt","key":"phunt","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Patrick Hunt","active":true,"timeZone":"America/Los_Angeles"},"created":"2012-06-21T23:31:24.375+0000","updated":"2012-06-21T23:31:24.375+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12552443/comment/13399664","id":"13399664","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=marshall","name":"marshall","key":"marshall","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Marshall McMullen","active":true,"timeZone":"America/Denver"},"body":"Oh, I didn't realize we already had a checksum on the record, that's helpful. Can you elaborate a little more on what cases we're not handling properly? I'd definitely like to help work on this but don't have any idea where to start looking.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=marshall","name":"marshall","key":"marshall","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Marshall McMullen","active":true,"timeZone":"America/Denver"},"created":"2012-06-22T22:16:18.028+0000","updated":"2012-06-22T22:16:18.028+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12552443/comment/13399671","id":"13399671","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=phunt","name":"phunt","key":"phunt","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Patrick Hunt","active":true,"timeZone":"America/Los_Angeles"},"body":"See this comment, it's a very clear (and easy to reproduce) use case:\nhttps://issues.apache.org/jira/browse/ZOOKEEPER-1449?focusedCommentId=13261071&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13261071\n\nBasically the crc is after the record, we don't have protection against issues prior to verifying the xsum (it's more complicated than that though - see the linked comment).","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=phunt","name":"phunt","key":"phunt","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Patrick Hunt","active":true,"timeZone":"America/Los_Angeles"},"created":"2012-06-22T22:19:55.471+0000","updated":"2012-06-22T22:19:55.471+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12552443/comment/13399853","id":"13399853","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=marshall","name":"marshall","key":"marshall","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Marshall McMullen","active":true,"timeZone":"America/Denver"},"body":"Patrick, thanks for taking the time to explain.. I read throw the other bug and your explanation is very clear. I'd like to work on a fix for this as it's hitting us very frequently with a stress test we do where we continually reboot one of our machines that is hosting one of our zk servers. Anyhow, I'm looking at the FileTxnIterator code, and I definitely see the bug in next() method in that it always assumes EOF is success. Have you given thought to the right solution here? Maybe giving precedence to validating CRC before checking for EOF? \n\nWhat do you think about this:\n\n{noformat}\npublic boolean next() throws IOException {\n    if (ia == null) {\n        return false;\n    }\n    try {\n        long crcValue = ia.readLong(\"crcvalue\");\n        byte[] bytes = Util.readTxnBytes(ia);\n        // validate CRC\n        Checksum crc = makeChecksumAlgorithm();\n        if (bytes) {\n            crc.update(bytes, 0, bytes.length);\n        }\n        if (crcValue != crc.getValue())\n            throw new IOException(CRC_ERROR);\n        if (bytes == null || bytes.length == 0)\n            throw new EOFException(\"Failed to read \" + logFile);\n        hdr = new TxnHeader();\n        record = SerializeUtils.deserializeTxn(bytes, hdr);\n    } catch (EOFException e) {\n    ...\n{noformat}\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=phunt","name":"phunt","key":"phunt","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Patrick Hunt","active":true,"timeZone":"America/Los_Angeles"},"created":"2012-06-23T06:47:30.652+0000","updated":"2012-06-24T04:37:40.879+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12552443/comment/13400098","id":"13400098","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=phunt","name":"phunt","key":"phunt","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Patrick Hunt","active":true,"timeZone":"America/Los_Angeles"},"body":"Marshall are you sure you have this fix? https://issues.apache.org/jira/browse/ZOOKEEPER-1156\n\nI think it would be good to fix this issue, however I'm more concerned about the fact that you're seeing corruption in your stress test environment. I think we need to track down the cause of that, my initial reaction is that you are seeing some bug that we need to fix. The ability to handle a corrupted log file is secondary to actually fixing the issue causing the corruption in the first place. Any insights on what might be causing the issue you are seeing? Perhaps you could file a bug report with log4j logs and a copy of your datadir?\n\nTo answer your question, I think we need to capture any failure to verify the crc as a failure, rather than EOF (as you suggest).","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=phunt","name":"phunt","key":"phunt","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Patrick Hunt","active":true,"timeZone":"America/Los_Angeles"},"created":"2012-06-24T04:41:36.247+0000","updated":"2012-06-24T04:41:36.247+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12552443/comment/13400160","id":"13400160","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=marshall","name":"marshall","key":"marshall","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Marshall McMullen","active":true,"timeZone":"America/Denver"},"body":"I'm running trunk revision 1339307, and it looks like ZOOKEEPER-1156 is included therein. So I think that I'm OK with regard to that particular bug.\n\nYou bring up a very valid point. I hadn't thought about pinpointing why we are seeing this corruption, only that we are and trying to prevent it from causing that node to not re-join the ensemble when it comes back up. \n\nThe next time this happens I'll grab log files and a copy of the datadir.\n\nThanks!","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=marshall","name":"marshall","key":"marshall","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Marshall McMullen","active":true,"timeZone":"America/Denver"},"created":"2012-06-24T14:49:21.057+0000","updated":"2012-06-24T14:49:21.057+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12552443/comment/13400162","id":"13400162","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=fpj","name":"fpj","key":"fpj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=fpj&avatarId=16030","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=fpj&avatarId=16030","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=fpj&avatarId=16030","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=fpj&avatarId=16030"},"displayName":"Flavio Junqueira","active":true,"timeZone":"Europe/Berlin"},"body":"Hi Marshall, One quick question here. When you say you're rebooting servers in your setting, I was wondering how you're doing that exactly.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=fpj","name":"fpj","key":"fpj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=fpj&avatarId=16030","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=fpj&avatarId=16030","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=fpj&avatarId=16030","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=fpj&avatarId=16030"},"displayName":"Flavio Junqueira","active":true,"timeZone":"Europe/Berlin"},"created":"2012-06-24T14:56:20.230+0000","updated":"2012-06-24T14:56:20.230+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12552443/comment/13400163","id":"13400163","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=marshall","name":"marshall","key":"marshall","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Marshall McMullen","active":true,"timeZone":"America/Denver"},"body":"Flavio, \n\nThis is on Linux servers, and we're trying to simulate non-graceful node failures, so we're calling \"reboot -f\". Since this doesn't call shutdown, it doesn't allow zookeeper a chance to gracefully shutdown. What I suspect is happening is if zookeeper happened to be in the middle of writing its logs or snapshots out to disk, this would get truncated or suffer some other file system corruption. When it comes back up we restart zookeeper and it never rejoins the ensemble. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=marshall","name":"marshall","key":"marshall","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Marshall McMullen","active":true,"timeZone":"America/Denver"},"created":"2012-06-24T15:05:27.085+0000","updated":"2012-06-24T15:05:27.085+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12552443/comment/13400257","id":"13400257","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=marshall","name":"marshall","key":"marshall","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Marshall McMullen","active":true,"timeZone":"America/Denver"},"body":"I was able to reproduce this problem again. After I power cycled the server a few times, the node in question refuses to join the ensemble and no clients can connect to it. When I try to telnet to the host in question and issue 'stat' it fails with:\n\nThis ZooKeeper instance is not currently serving requests\n\nI enabled tracing and in the log file as it's starting up it fails with:\n\n2012-06-24 20:34:31,734 [myid:1] - INFO  [main:FileSnap@83][] - Reading snapshot /sf/data/zookeeper/10.10.5.123/version-2/snapshot.0\n2012-06-24 20:34:31,738 [myid:1] - DEBUG [main:FileTxnLog$FileTxnIterator@575][] - Created new input stream /sf/data/zookeeper/10.10.5.123/version-2/log.100000001\n2012-06-24 20:34:31,738 [myid:1] - DEBUG [main:FileTxnLog$FileTxnIterator@578][] - Created new input archive /sf/data/zookeeper/10.10.5.123/version-2/log.100000001\n2012-06-24 20:34:31,763 [myid:1] - DEBUG [main:DataTree@951][] - Ignoring processTxn failure hdr: -1 : error: -110\n2012-06-24 20:34:31,763 [myid:1] - DEBUG [main:FileTxnSnapLog@241][] - Ignoring processTxn failure hdr: -1 : error: -110\n2012-06-24 20:34:31,763 [myid:1] - DEBUG [main:DataTree@951][] - Ignoring processTxn failure hdr: -1 : error: -110\n\n...[ repeats many many times ]...\n\n2012-06-24 20:34:32,065 [myid:1] - DEBUG [main:FileTxnLog$FileTxnIterator@618][] - EOF excepton java.io.EOFException: Failed to read /sf/data/zookeeper/10.10.5.123/version-2/log.100000001\n2012-06-24 20:34:32,067 [myid:1] - INFO  [NIOServerCxn.Factory:/10.10.5.123:2181:NIOServerCnxnFactory@227][] - Accepted socket connection from /10.10.5.123:39623\n2012-06-24 20:34:32,069 [myid:1] - INFO  [QuorumPeerListener:QuorumCnxManager$Listener@530][] - My election bind port: /10.10.5.123:2183\n2012-06-24 20:34:32,071 [myid:1] - WARN  [NIOServerCxn.Factory:/10.10.5.123:2181:NIOServerCnxn@354][] - Exception causing close of session 0x0 due to java.io.IOException: ZooKeeperServer not running\n2012-06-24 20:34:32,071 [myid:1] - DEBUG [NIOServerCxn.Factory:/10.10.5.123:2181:NIOServerCnxn@358][] - IOException stack trace\n\nI also have a copy of the data directory if it would help.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=marshall","name":"marshall","key":"marshall","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Marshall McMullen","active":true,"timeZone":"America/Denver"},"created":"2012-06-25T02:43:48.428+0000","updated":"2012-06-25T02:43:48.428+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12552443/comment/13400259","id":"13400259","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=marshall","name":"marshall","key":"marshall","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Marshall McMullen","active":true,"timeZone":"America/Denver"},"body":"Data directory of the node that won't rejoin zookeeper ensemble.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=marshall","name":"marshall","key":"marshall","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Marshall McMullen","active":true,"timeZone":"America/Denver"},"created":"2012-06-25T02:46:47.545+0000","updated":"2012-06-25T02:46:47.545+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12552443/comment/13400260","id":"13400260","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=marshall","name":"marshall","key":"marshall","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Marshall McMullen","active":true,"timeZone":"America/Denver"},"body":"By the way, when you untar the attached zookeeper.tar.gz file, inside is the full zookeeper_trace.log file.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=marshall","name":"marshall","key":"marshall","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Marshall McMullen","active":true,"timeZone":"America/Denver"},"created":"2012-06-25T02:49:07.372+0000","updated":"2012-06-25T02:49:07.372+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12552443/comment/13408100","id":"13408100","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=marshall","name":"marshall","key":"marshall","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Marshall McMullen","active":true,"timeZone":"America/Denver"},"body":"I'm seeing this again, same scenario as described before. Anyone have a chance to look at my log files to see what might be wrong here? \n\nAlso, I'm wondering if the new code for https://issues.apache.org/jira/browse/ZOOKEEPER-1427 could be helpful here. I noticed the code in 1427 makes the writes to acceptedEpoch and currentEpoch files atomic, but what about the log and snapshot files? Are those similarly written atomically? Maybe that is causing my corruption issues....? \n\nCould really use some help here.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=marshall","name":"marshall","key":"marshall","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Marshall McMullen","active":true,"timeZone":"America/Denver"},"created":"2012-07-06T15:59:46.492+0000","updated":"2012-07-06T15:59:46.492+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12552443/comment/13408124","id":"13408124","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=marshall","name":"marshall","key":"marshall","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Marshall McMullen","active":true,"timeZone":"America/Denver"},"body":"Patrick Hunt commented on 1427 that atomic writes of the snapshot and log files is not necessary. \n\nAnyhow, could still use some advice on what might be wrong here.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=marshall","name":"marshall","key":"marshall","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Marshall McMullen","active":true,"timeZone":"America/Denver"},"created":"2012-07-06T16:21:37.548+0000","updated":"2012-07-06T16:21:37.548+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12552443/comment/13408363","id":"13408363","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=fpj","name":"fpj","key":"fpj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=fpj&avatarId=16030","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=fpj&avatarId=16030","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=fpj&avatarId=16030","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=fpj&avatarId=16030"},"displayName":"Flavio Junqueira","active":true,"timeZone":"Europe/Berlin"},"body":"I don't think the trace file is here, this is the output of ls after untaring it:\n\n{noformat}\ndrwxr-xr-x  0 root   root        0 Jun 25 00:54 zookeeper/\n-rw-r-----  0 root   root      247 Jun 25 01:12 zookeeper/10.10.5.123_2181.cfg\n-rw-r-----  0 root   root      176 Jun 25 01:12 zookeeper/10.10.5.123_2181.cfg.dynamic\n-rw-r-----  0 root   root        1 Jun 25 01:12 zookeeper/myid\ndrwxr-xr-x  0 root   root        0 Jun 25 00:54 zookeeper/version-2/\n-rw-r--r--  0 root   root        1 Jun 25 00:54 zookeeper/version-2/currentEpoch\n-rw-r--r--  0 root   root        1 Jun 25 00:54 zookeeper/version-2/acceptedEpoch\n-rw-r--r--  0 root   root      669 Jun 25 00:54 zookeeper/version-2/snapshot.0\n-rw-r--r--  0 root   root 67108880 Jun 25 01:09 zookeeper/version-2/log.100000001\n{noformat}\n\nI was able to read the transaction log ok, though.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=fpj","name":"fpj","key":"fpj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=fpj&avatarId=16030","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=fpj&avatarId=16030","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=fpj&avatarId=16030","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=fpj&avatarId=16030"},"displayName":"Flavio Junqueira","active":true,"timeZone":"Europe/Berlin"},"created":"2012-07-06T21:29:42.010+0000","updated":"2012-07-06T21:29:42.010+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12552443/comment/13408418","id":"13408418","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=marshall","name":"marshall","key":"marshall","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Marshall McMullen","active":true,"timeZone":"America/Denver"},"body":"OK, reproduced this again.... This time I made sure to capture a tar file of the data directory on each node and there is now a zookeeper_trace.log file in each tar file. In this scenario, I had a 3-node ensemble {10.10.5.42, 10.10.5.44, 10.10.5.123} and I rebooted 10.10.5.42 via issuing \"reboot -f\" on that node. When the node comes back up, it spews the following log message as before. Around 16:35 it is rebooted, and comes back around 16:38.\n\n2012-07-06 16:35:51,512 [myid:3] - DEBUG [CommitProcessor:3:FinalRequestProcessor@158][] - sessionid:0x3385e6145f2000b type:setData cxid:0x4ff77654 zxid:0x100000d4f txntype:5 reqpath:n/a\n\n...[REBOOTED]...\n\n2012-07-06 16:38:38,026 [myid:] - INFO  [main:QuorumPeerConfig@99][] - Reading configuration from: /sf/data/zookeeper/10.10.5.42/10.10.5.42_2181.cfg\n2012-07-06 16:38:38,038 [myid:2] - INFO  [main:DatadirCleanupManager@78][] - autopurge.snapRetainCount set to 5\n2012-07-06 16:38:38,038 [myid:2] - INFO  [main:DatadirCleanupManager@79][] - autopurge.purgeInterval set to 1\n2012-07-06 16:38:38,039 [myid:2] - INFO  [PurgeTask:DatadirCleanupManager$PurgeTask@138][] - Purge task started.\n2012-07-06 16:38:38,045 [myid:2] - DEBUG [main:AbstractDynamicMBean@148][] - preRegister called. Server=com.sun.jmx.mbeanserver.JmxMBeanServer@49b979c0, name=log4j:hiearchy=default\n2012-07-06 16:38:38,045 [myid:2] - DEBUG [main:HierarchyDynamicMBean@260][] - postRegister is called.\n2012-07-06 16:38:38,046 [myid:2] - DEBUG [main:AbstractDynamicMBean@148][] - preRegister called. Server=com.sun.jmx.mbeanserver.JmxMBeanServer@49b979c0, name=log4j:logger=root\n2012-07-06 16:38:38,047 [myid:2] - DEBUG [main:LoggerDynamicMBean@258][] - Adding AppenderMBean for appender named CONSOLE\n2012-07-06 16:38:38,048 [myid:2] - DEBUG [main:AppenderDynamicMBean@158][] - getMBeanInfo called.\n2012-07-06 16:38:38,048 [myid:2] - DEBUG [main:AppenderDynamicMBean@337][] - preRegister called. Server=com.sun.jmx.mbeanserver.JmxMBeanServer@49b979c0, name=log4j:appender=CONSOLE\n2012-07-06 16:38:38,048 [myid:2] - DEBUG [main:AppenderDynamicMBean@197][] - Adding LayoutMBean:CONSOLE,layout=org.apache.log4j.PatternLayout\n2012-07-06 16:38:38,049 [myid:2] - DEBUG [main:LayoutDynamicMBean@140][] - getMBeanInfo called.\n2012-07-06 16:38:38,049 [myid:2] - DEBUG [main:AbstractDynamicMBean@148][] - preRegister called. Server=com.sun.jmx.mbeanserver.JmxMBeanServer@49b979c0, name=log4j:appender=CONSOLE,layout=org.apache.log4j.PatternLayout\n2012-07-06 16:38:38,049 [myid:2] - DEBUG [main:LoggerDynamicMBean@258][] - Adding AppenderMBean for appender named TRACEFILE\n2012-07-06 16:38:38,050 [myid:2] - DEBUG [main:AppenderDynamicMBean@158][] - getMBeanInfo called.\n2012-07-06 16:38:38,050 [myid:2] - DEBUG [main:AppenderDynamicMBean@337][] - preRegister called. Server=com.sun.jmx.mbeanserver.JmxMBeanServer@49b979c0, name=log4j:appender=TRACEFILE\n2012-07-06 16:38:38,051 [myid:2] - DEBUG [main:AppenderDynamicMBean@197][] - Adding LayoutMBean:TRACEFILE,layout=org.apache.log4j.PatternLayout\n2012-07-06 16:38:38,052 [myid:2] - DEBUG [main:LayoutDynamicMBean@140][] - getMBeanInfo called.\n2012-07-06 16:38:38,052 [myid:2] - DEBUG [main:AbstractDynamicMBean@148][] - preRegister called. Server=com.sun.jmx.mbeanserver.JmxMBeanServer@49b979c0, name=log4j:appender=TRACEFILE,layout=org.apache.log4j.PatternLayout\n2012-07-06 16:38:38,052 [myid:2] - INFO  [PurgeTask:DatadirCleanupManager$PurgeTask@144][] - Purge task completed.\n2012-07-06 16:38:38,052 [myid:2] - DEBUG [main:HierarchyDynamicMBean@128][] - ---Adding logger [root] as listener.\n2012-07-06 16:38:38,052 [myid:2] - DEBUG [main:AbstractDynamicMBean@148][] - preRegister called. Server=com.sun.jmx.mbeanserver.JmxMBeanServer@49b979c0, name=log4j:logger=org.apache.zookeeper.server.persistence.FileSnap\n2012-07-06 16:38:38,053 [myid:2] - DEBUG [main:HierarchyDynamicMBean@128][] - ---Adding logger [org.apache.zookeeper.server.persistence.FileSnap] as listener.\n2012-07-06 16:38:38,053 [myid:2] - DEBUG [main:AbstractDynamicMBean@148][] - preRegister called. Server=com.sun.jmx.mbeanserver.JmxMBeanServer@49b979c0, name=log4j:logger=org.apache.log4j.jmx.LoggerDynamicMBean\n2012-07-06 16:38:38,053 [myid:2] - DEBUG [main:HierarchyDynamicMBean@128][] - ---Adding logger [org.apache.log4j.jmx.LoggerDynamicMBean] as listener.\n2012-07-06 16:38:38,053 [myid:2] - DEBUG [main:AbstractDynamicMBean@148][] - preRegister called. Server=com.sun.jmx.mbeanserver.JmxMBeanServer@49b979c0, name=log4j:logger=org.apache.zookeeper.jmx.MBeanRegistry\n2012-07-06 16:38:38,053 [myid:2] - DEBUG [main:HierarchyDynamicMBean@128][] - ---Adding logger [org.apache.zookeeper.jmx.MBeanRegistry] as listener.\n2012-07-06 16:38:38,054 [myid:2] - DEBUG [main:AbstractDynamicMBean@148][] - preRegister called. Server=com.sun.jmx.mbeanserver.JmxMBeanServer@49b979c0, name=log4j:logger=org.apache.zookeeper.server.persistence.FileTxnSnapLog\n2012-07-06 16:38:38,054 [myid:2] - DEBUG [main:HierarchyDynamicMBean@128][] - ---Adding logger [org.apache.zookeeper.server.persistence.FileTxnSnapLog] as listener.\n2012-07-06 16:38:38,054 [myid:2] - DEBUG [main:AbstractDynamicMBean@148][] - preRegister called. Server=com.sun.jmx.mbeanserver.JmxMBeanServer@49b979c0, name=log4j:logger=org.apache.zookeeper.server.quorum.QuorumPeerConfig\n2012-07-06 16:38:38,054 [myid:2] - DEBUG [main:HierarchyDynamicMBean@128][] - ---Adding logger [org.apache.zookeeper.server.quorum.QuorumPeerConfig] as listener.\n2012-07-06 16:38:38,054 [myid:2] - DEBUG [main:AbstractDynamicMBean@148][] - preRegister called. Server=com.sun.jmx.mbeanserver.JmxMBeanServer@49b979c0, name=log4j:logger=org.apache.log4j.jmx.AppenderDynamicMBean\n2012-07-06 16:38:38,054 [myid:2] - DEBUG [main:HierarchyDynamicMBean@128][] - ---Adding logger [org.apache.log4j.jmx.AppenderDynamicMBean] as listener.\n2012-07-06 16:38:38,054 [myid:2] - DEBUG [main:AbstractDynamicMBean@148][] - preRegister called. Server=com.sun.jmx.mbeanserver.JmxMBeanServer@49b979c0, name=log4j:logger=org.apache.zookeeper.server.persistence.Util\n2012-07-06 16:38:38,055 [myid:2] - DEBUG [main:HierarchyDynamicMBean@128][] - ---Adding logger [org.apache.zookeeper.server.persistence.Util] as listener.\n2012-07-06 16:38:38,055 [myid:2] - DEBUG [main:AbstractDynamicMBean@148][] - preRegister called. Server=com.sun.jmx.mbeanserver.JmxMBeanServer@49b979c0, name=log4j:logger=org.apache.zookeeper.server.quorum.QuorumPeerMain\n2012-07-06 16:38:38,055 [myid:2] - DEBUG [main:HierarchyDynamicMBean@128][] - ---Adding logger [org.apache.zookeeper.server.quorum.QuorumPeerMain] as listener.\n2012-07-06 16:38:38,055 [myid:2] - DEBUG [main:AbstractDynamicMBean@148][] - preRegister called. Server=com.sun.jmx.mbeanserver.JmxMBeanServer@49b979c0, name=log4j:logger=org.apache.log4j.jmx.HierarchyDynamicMBean\n2012-07-06 16:38:38,055 [myid:2] - DEBUG [main:HierarchyDynamicMBean@128][] - ---Adding logger [org.apache.log4j.jmx.HierarchyDynamicMBean] as listener.\n2012-07-06 16:38:38,055 [myid:2] - DEBUG [main:AbstractDynamicMBean@148][] - preRegister called. Server=com.sun.jmx.mbeanserver.JmxMBeanServer@49b979c0, name=log4j:logger=org.apache.zookeeper.server.DatadirCleanupManager\n2012-07-06 16:38:38,055 [myid:2] - DEBUG [main:HierarchyDynamicMBean@128][] - ---Adding logger [org.apache.zookeeper.server.DatadirCleanupManager] as listener.\n2012-07-06 16:38:38,056 [myid:2] - DEBUG [main:AbstractDynamicMBean@148][] - preRegister called. Server=com.sun.jmx.mbeanserver.JmxMBeanServer@49b979c0, name=log4j:logger=org.apache.log4j.jmx.LayoutDynamicMBean\n2012-07-06 16:38:38,056 [myid:2] - DEBUG [main:HierarchyDynamicMBean@128][] - ---Adding logger [org.apache.log4j.jmx.LayoutDynamicMBean] as listener.\n2012-07-06 16:38:38,056 [myid:2] - DEBUG [main:AbstractDynamicMBean@148][] - preRegister called. Server=com.sun.jmx.mbeanserver.JmxMBeanServer@49b979c0, name=log4j:logger=org.apache.zookeeper.server.persistence.FileTxnLog\n2012-07-06 16:38:38,056 [myid:2] - DEBUG [main:HierarchyDynamicMBean@128][] - ---Adding logger [org.apache.zookeeper.server.persistence.FileTxnLog] as listener.\n2012-07-06 16:38:38,056 [myid:2] - INFO  [main:QuorumPeerMain@131][] - Starting quorum peer\n2012-07-06 16:38:38,072 [myid:2] - INFO  [main:NIOServerCnxnFactory@108][] - binding to port /10.10.5.42:2181\n2012-07-06 16:38:38,080 [myid:2] - INFO  [main:QuorumPeer@1107][] - tickTime set to 2000\n2012-07-06 16:38:38,080 [myid:2] - INFO  [main:QuorumPeer@1127][] - minSessionTimeout set to -1\n2012-07-06 16:38:38,080 [myid:2] - INFO  [main:QuorumPeer@1138][] - maxSessionTimeout set to -1\n2012-07-06 16:38:38,081 [myid:2] - INFO  [main:QuorumPeer@1153][] - initLimit set to 10\n2012-07-06 16:38:38,093 [myid:2] - INFO  [main:FileSnap@83][] - Reading snapshot /sf/data/zookeeper/10.10.5.42/version-2/snapshot.0\n2012-07-06 16:38:38,097 [myid:2] - DEBUG [main:FileTxnLog$FileTxnIterator@575][] - Created new input stream /sf/data/zookeeper/10.10.5.42/version-2/log.100000001\n2012-07-06 16:38:38,097 [myid:2] - DEBUG [main:FileTxnLog$FileTxnIterator@578][] - Created new input archive /sf/data/zookeeper/10.10.5.42/version-2/log.100000001\n2012-07-06 16:38:38,124 [myid:2] - DEBUG [main:DataTree@951][] - Ignoring processTxn failure hdr: -1 : error: -110\n2012-07-06 16:38:38,124 [myid:2] - DEBUG [main:FileTxnSnapLog@241][] - Ignoring processTxn failure hdr: -1 : error: -110\n2012-07-06 16:38:38,124 [myid:2] - DEBUG [main:DataTree@951][] - Ignoring processTxn failure hdr: -1 : error: -110\n2012-07-06 16:38:38,124 [myid:2] - DEBUG [main:FileTxnSnapLog@241][] - Ignoring processTxn failure hdr: -1 : error: -110\n2012-07-06 16:38:38,126 [myid:2] - DEBUG [main:DataTree@951][] - Ignoring processTxn failure hdr: -1 : error: -110\n2012-07-06 16:38:38,126 [myid:2] - DEBUG [main:FileTxnSnapLog@241][] - Ignoring processTxn failure hdr: -1 : error: -110\n\n... [ REPEATS FOR A LONG TIME ] ...\n\n2012-07-06 16:38:38,432 [myid:2] - DEBUG [main:FileTxnLog$FileTxnIterator@618][] - EOF excepton java.io.EOFException: Failed to read /sf/data/zookeeper/10.10.5.42/version-2/log.100000001\n2012-07-06 16:38:38,437 [myid:2] - INFO  [QuorumPeerListener:QuorumCnxManager$Listener@530][] - My election bind port: /10.10.5.42:2183\n2012-07-06 16:38:38,443 [myid:2] - DEBUG [QuorumPeer[myid=2]/10.10.5.42:2181:QuorumPeer@825][] - Starting quorum peer\n2012-07-06 16:38:38,447 [myid:2] - INFO  [QuorumPeer[myid=2]/10.10.5.42:2181:QuorumPeer@860][] - LOOKING\n2012-07-06 16:38:38,447 [myid:2] - DEBUG [QuorumPeer[myid=2]/10.10.5.42:2181:QuorumPeer@789][] - Initializing leader election protocol...\n2012-07-06 16:38:38,448 [myid:2] - DEBUG [QuorumPeer[myid=2]/10.10.5.42:2181:FastLeaderElection@732][] - Updating proposal: 2 (newleader), 0x100000d54 (newzxid), -1 (oldleader), 0xffffffffffffffff (oldzxid)\n2012-07-06 16:38:38,449 [myid:2] - INFO  [QuorumPeer[myid=2]/10.10.5.42:2181:FastLeaderElection@831][] - New election. My id =  2, proposed zxid=0x100000d54\n2012-07-06 16:38:38,449 [myid:2] - DEBUG [QuorumPeer[myid=2]/10.10.5.42:2181:FastLeaderElection@583][] - Sending Notification: 2 (n.leader), 0x100000d54 (n.zxid), 0x1 (n.round), 1 (recipient), 2 (myid), 0x1 (n.peerEpoch)\n2012-07-06 16:38:38,450 [myid:2] - DEBUG [QuorumPeer[myid=2]/10.10.5.42:2181:FastLeaderElection@583][] - Sending Notification: 2 (n.leader), 0x100000d54 (n.zxid), 0x1 (n.round), 2 (recipient), 2 (myid), 0x1 (n.peerEpoch)\n2012-07-06 16:38:38,450 [myid:2] - DEBUG [QuorumPeer[myid=2]/10.10.5.42:2181:FastLeaderElection@583][] - Sending Notification: 2 (n.leader), 0x100000d54 (n.zxid), 0x1 (n.round), 3 (recipient), 2 (myid), 0x1 (n.peerEpoch)\n2012-07-06 16:38:38,450 [myid:2] - DEBUG [WorkerSender[myid=2]:QuorumCnxManager@375][] - Opening channel to server 1\n2012-07-06 16:38:38,453 [myid:2] - DEBUG [WorkerSender[myid=2]:QuorumCnxManager@381][] - Connected to server 1\n2012-07-06 16:38:38,454 [myid:2] - DEBUG [WorkerSender[myid=2]:QuorumCnxManager$SendWorker@616][] - Address of remote peer: 1\n2012-07-06 16:38:38,456 [myid:2] - DEBUG [WorkerSender[myid=2]:QuorumCnxManager@375][] - Opening channel to server 3\n2012-07-06 16:38:38,456 [myid:2] - DEBUG [WorkerSender[myid=2]:QuorumCnxManager@381][] - Connected to server 3\n2012-07-06 16:38:38,456 [myid:2] - INFO  [WorkerSender[myid=2]:QuorumCnxManager@191][] - Have smaller server identifier, so dropping the connection: (3, 2)\n2012-07-06 16:38:38,457 [myid:2] - DEBUG [WorkerReceiver[myid=2]:FastLeaderElection$Messenger$WorkerReceiver@295][] - Receive new notification message. My id = 2\n2012-07-06 16:38:38,457 [myid:2] - INFO  [WorkerReceiver[myid=2]:FastLeaderElection@635][] - Notification: 2 (n.leader), 0x100000d54 (n.zxid), 0x1 (n.round), LOOKING (n.state), 2 (n.sid), 0x1 (n.peerEPoch), LOOKING (my state)0 (n.config version)\n2012-07-06 16:38:38,458 [myid:2] - DEBUG [QuorumPeer[myid=2]/10.10.5.42:2181:FastLeaderElection@652][] - id: 2, proposed id: 2, zxid: 0x100000d54, proposed zxid: 0x100000d54\n2012-07-06 16:38:38,458 [myid:2] - DEBUG [QuorumPeer[myid=2]/10.10.5.42:2181:FastLeaderElection@901][] - Adding vote: from=2, proposed leader=2, proposed zxid=0x100000d54, proposed election epoch=0x1\n2012-07-06 16:38:38,659 [myid:2] - DEBUG [QuorumPeer[myid=2]/10.10.5.42:2181:QuorumCnxManager@444][] - Queue size: 0\n2012-07-06 16:38:38,659 [myid:2] - DEBUG [QuorumPeer[myid=2]/10.10.5.42:2181:FastLeaderElection@583][] - Sending Notification: 2 (n.leader), 0x100000d54 (n.zxid), 0x1 (n.round), 1 (recipient), 2 (myid), 0x1 (n.peerEpoch)\n2012-07-06 16:38:38,659 [myid:2] - DEBUG [QuorumPeer[myid=2]/10.10.5.42:2181:FastLeaderElection@583][] - Sending Notification: 2 (n.leader), 0x100000d54 (n.zxid), 0x1 (n.round), 2 (recipient), 2 (myid), 0x1 (n.peerEpoch)\n2012-07-06 16:38:38,659 [myid:2] - DEBUG [WorkerSender[myid=2]:QuorumCnxManager@408][] - There is a connection already for server 1\n2012-07-06 16:38:38,659 [myid:2] - DEBUG [QuorumPeer[myid=2]/10.10.5.42:2181:FastLeaderElection@583][] - Sending Notification: 2 (n.leader), 0x100000d54 (n.zxid), 0x1 (n.round), 3 (recipient), 2 (myid), 0x1 (n.peerEpoch)\n2012-07-06 16:38:38,659 [myid:2] - INFO  [QuorumPeer[myid=2]/10.10.5.42:2181:FastLeaderElection@865][] - Notification time out: 400\n2012-07-06 16:38:38,660 [myid:2] - DEBUG [WorkerReceiver[myid=2]:FastLeaderElection$Messenger$WorkerReceiver@295][] - Receive new notification message. My id = 2\n2012-07-06 16:38:38,660 [myid:2] - DEBUG [WorkerSender[myid=2]:QuorumCnxManager@375][] - Opening channel to server 3\n2012-07-06 16:38:38,660 [myid:2] - DEBUG [WorkerSender[myid=2]:QuorumCnxManager@381][] - Connected to server 3\n2012-07-06 16:38:38,661 [myid:2] - INFO  [WorkerSender[myid=2]:QuorumCnxManager@191][] - Have smaller server identifier, so dropping the connection: (3, 2)\n2012-07-06 16:38:38,661 [myid:2] - INFO  [WorkerReceiver[myid=2]:FastLeaderElection@635][] - Notification: 2 (n.leader), 0x100000d54 (n.zxid), 0x1 (n.round), LOOKING (n.state), 2 (n.sid), 0x1 (n.peerEPoch), LOOKING (my state)0 (n.config version)\n2012-07-06 16:38:38,661 [myid:2] - DEBUG [QuorumPeer[myid=2]/10.10.5.42:2181:FastLeaderElection@652][] - id: 2, proposed id: 2, zxid: 0x100000d54, proposed zxid: 0x100000d54\n2012-07-06 16:38:38,661 [myid:2] - DEBUG [QuorumPeer[myid=2]/10.10.5.42:2181:FastLeaderElection@901][] - Adding vote: from=2, proposed leader=2, proposed zxid=0x100000d54, proposed election epoch=0x1\n2012-07-06 16:38:39,061 [myid:2] - DEBUG [QuorumPeer[myid=2]/10.10.5.42:2181:QuorumCnxManager@444][] - Queue size: 0\n2012-07-06 16:38:39,062 [myid:2] - DEBUG [QuorumPeer[myid=2]/10.10.5.42:2181:FastLeaderElection@583][] - Sending Notification: 2 (n.leader), 0x100000d54 (n.zxid), 0x1 (n.round), 1 (recipient), 2 (myid), 0x1 (n.peerEpoch)\n2012-07-06 16:38:39,062 [myid:2] - DEBUG [WorkerSender[myid=2]:QuorumCnxManager@408][] - There is a connection already for server 1\n2012-07-06 16:38:39,062 [myid:2] - DEBUG [QuorumPeer[myid=2]/10.10.5.42:2181:FastLeaderElection@583][] - Sending Notification: 2 (n.leader), 0x100000d54 (n.zxid), 0x1 (n.round), 2 (recipient), 2 (myid), 0x1 (n.peerEpoch)\n2012-07-06 16:38:39,062 [myid:2] - DEBUG [QuorumPeer[myid=2]/10.10.5.42:2181:FastLeaderElection@583][] - Sending Notification: 2 (n.leader), 0x100000d54 (n.zxid), 0x1 (n.round), 3 (recipient), 2 (myid), 0x1 (n.peerEpoch)\n2012-07-06 16:38:39,062 [myid:2] - INFO  [QuorumPeer[myid=2]/10.10.5.42:2181:FastLeaderElection@865][] - Notification time out: 800\n2012-07-06 16:38:39,062 [myid:2] - DEBUG [WorkerReceiver[myid=2]:FastLeaderElection$Messenger$WorkerReceiver@295][] - Receive new notification message. My id = 2\n2012-07-06 16:38:39,062 [myid:2] - DEBUG [WorkerSender[myid=2]:QuorumCnxManager@375][] - Opening channel to server 3\n2012-07-06 16:38:39,063 [myid:2] - DEBUG [WorkerSender[myid=2]:QuorumCnxManager@381][] - Connected to server 3\n2012-07-06 16:38:39,063 [myid:2] - INFO  [WorkerSender[myid=2]:QuorumCnxManager@191][] - Have smaller server identifier, so dropping the connection: (3, 2)\n2012-07-06 16:38:39,063 [myid:2] - INFO  [WorkerReceiver[myid=2]:FastLeaderElection@635][] - Notification: 2 (n.leader), 0x100000d54 (n.zxid), 0x1 (n.round), LOOKING (n.state), 2 (n.sid), 0x1 (n.peerEPoch), LOOKING (my state)0 (n.config version)\n2012-07-06 16:38:39,064 [myid:2] - DEBUG [QuorumPeer[myid=2]/10.10.5.42:2181:FastLeaderElection@652][] - id: 2, proposed id: 2, zxid: 0x100000d54, proposed zxid: 0x100000d54\n2012-07-06 16:38:39,064 [myid:2] - DEBUG [QuorumPeer[myid=2]/10.10.5.42:2181:FastLeaderElection@901][] - Adding vote: from=2, proposed leader=2, proposed zxid=0x100000d54, proposed election epoch=0x1\n2012-07-06 16:38:39,864 [myid:2] - DEBUG [QuorumPeer[myid=2]/10.10.5.42:2181:QuorumCnxManager@444][] - Queue size: 0\n2012-07-06 16:38:39,864 [myid:2] - DEBUG [QuorumPeer[myid=2]/10.10.5.42:2181:FastLeaderElection@583][] - Sending Notification: 2 (n.leader), 0x100000d54 (n.zxid), 0x1 (n.round), 1 (recipient), 2 (myid), 0x1 (n.peerEpoch)\n2012-07-06 16:38:39,864 [myid:2] - DEBUG [WorkerSender[myid=2]:QuorumCnxManager@408][] - There is a connection already for server 1\n2012-07-06 16:38:39,864 [myid:2] - DEBUG [QuorumPeer[myid=2]/10.10.5.42:2181:FastLeaderElection@583][] - Sending Notification: 2 (n.leader), 0x100000d54 (n.zxid), 0x1 (n.round), 2 (recipient), 2 (myid), 0x1 (n.peerEpoch)\n2012-07-06 16:38:39,864 [myid:2] - DEBUG [QuorumPeer[myid=2]/10.10.5.42:2181:FastLeaderElection@583][] - Sending Notification: 2 (n.leader), 0x100000d54 (n.zxid), 0x1 (n.round), 3 (recipient), 2 (myid), 0x1 (n.peerEpoch)\n2012-07-06 16:38:39,864 [myid:2] - INFO  [QuorumPeer[myid=2]/10.10.5.42:2181:FastLeaderElection@865][] - Notification time out: 1600\n2012-07-06 16:38:39,865 [myid:2] - DEBUG [WorkerReceiver[myid=2]:FastLeaderElection$Messenger$WorkerReceiver@295][] - Receive new notification message. My id = 2\n2012-07-06 16:38:39,865 [myid:2] - DEBUG [WorkerSender[myid=2]:QuorumCnxManager@375][] - Opening channel to server 3\n2012-07-06 16:38:39,865 [myid:2] - DEBUG [WorkerSender[myid=2]:QuorumCnxManager@381][] - Connected to server 3\n2012-07-06 16:38:39,865 [myid:2] - INFO  [WorkerSender[myid=2]:QuorumCnxManager@191][] - Have smaller server identifier, so dropping the connection: (3, 2)\n2012-07-06 16:38:39,866 [myid:2] - INFO  [WorkerReceiver[myid=2]:FastLeaderElection@635][] - Notification: 2 (n.leader), 0x100000d54 (n.zxid), 0x1 (n.round), LOOKING (n.state), 2 (n.sid), 0x1 (n.peerEPoch), LOOKING (my state)0 (n.config version)\n2012-07-06 16:38:39,866 [myid:2] - DEBUG [QuorumPeer[myid=2]/10.10.5.42:2181:FastLeaderElection@652][] - id: 2, proposed id: 2, zxid: 0x100000d54, proposed zxid: 0x100000d54\n2012-07-06 16:38:39,866 [myid:2] - DEBUG [QuorumPeer[myid=2]/10.10.5.42:2181:FastLeaderElection@901][] - Adding vote: from=2, proposed leader=2, proposed zxid=0x100000d54, proposed election epoch=0x1\n2012-07-06 16:38:41,259 [myid:2] - INFO  [NIOServerCxn.Factory:/10.10.5.42:2181:NIOServerCnxnFactory@227][] - Accepted socket connection from /10.10.5.44:50944\n2012-07-06 16:38:41,263 [myid:2] - WARN  [NIOServerCxn.Factory:/10.10.5.42:2181:NIOServerCnxn@354][] - Exception causing close of session 0x0 due to java.io.IOException: ZooKeeperServer not running\n2012-07-06 16:38:41,264 [myid:2] - DEBUG [NIOServerCxn.Factory:/10.10.5.42:2181:NIOServerCnxn@358][] - IOException stack trace\njava.io.IOException: ZooKeeperServer not running\n    at org.apache.zookeeper.server.NIOServerCnxn.readLength(NIOServerCnxn.java:926)\n    at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:229)\n    at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:238)\n    at java.lang.Thread.run(Thread.java:722)\n\n\nThereafter I see \" Exception causing close of session 0x0 due to java.io.IOException: ZooKeeperServer not running\" over and over. See full trace files on all three nodes in the attachments.\n\nI really need help on this, so anything anyone can offer will be immensely appreciated.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=marshall","name":"marshall","key":"marshall","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Marshall McMullen","active":true,"timeZone":"America/Denver"},"created":"2012-07-06T22:54:16.433+0000","updated":"2012-07-06T22:54:16.433+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12552443/comment/13408421","id":"13408421","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=phunt","name":"phunt","key":"phunt","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Patrick Hunt","active":true,"timeZone":"America/Los_Angeles"},"body":"Any chance you could apply the fix for ZOOKEEPER-1489 and try reproducing?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=phunt","name":"phunt","key":"phunt","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Patrick Hunt","active":true,"timeZone":"America/Los_Angeles"},"created":"2012-07-06T23:02:01.137+0000","updated":"2012-07-06T23:02:01.137+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12552443/comment/13408430","id":"13408430","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=marshall","name":"marshall","key":"marshall","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Marshall McMullen","active":true,"timeZone":"America/Denver"},"body":"Patrick, yes, I will try that right now and get back to you.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=marshall","name":"marshall","key":"marshall","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Marshall McMullen","active":true,"timeZone":"America/Denver"},"created":"2012-07-06T23:05:44.910+0000","updated":"2012-07-06T23:05:44.910+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12552443/comment/13408433","id":"13408433","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=phunt","name":"phunt","key":"phunt","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Patrick Hunt","active":true,"timeZone":"America/Los_Angeles"},"body":"Sweet, thx.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=phunt","name":"phunt","key":"phunt","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Patrick Hunt","active":true,"timeZone":"America/Los_Angeles"},"created":"2012-07-06T23:10:42.328+0000","updated":"2012-07-06T23:10:42.328+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12552443/comment/13408440","id":"13408440","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=marshall","name":"marshall","key":"marshall","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Marshall McMullen","active":true,"timeZone":"America/Denver"},"body":"Testing this with the fix from ZOOKEEPER-1489 right now. Usually takes about 30 minutes for our test to fail. Will report back with results when that finishes.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=marshall","name":"marshall","key":"marshall","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Marshall McMullen","active":true,"timeZone":"America/Denver"},"created":"2012-07-06T23:15:54.874+0000","updated":"2012-07-06T23:15:54.874+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12552443/comment/13408457","id":"13408457","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bbridge","name":"bbridge","key":"bbridge","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Bill Bridge","active":true,"timeZone":"America/Los_Angeles"},"body":"The ZooKeeper log records are not sector aligned on disk. When you crash a server there can be disk I/O in flight that is an integral number of sectors. Some will complete and some will not. The completion order is not guaranteed to be the same as the order in the file.  There is a reasonable chance that the last log record will be partial. There may be some unwritten sectors in the file and then some blocks with records.\n\nThe code needs to recognize that partial records at the end of a log are a possibility and pretend they were not written. One hazard with doing that is a corruption in the middle of a log might be considered an EOF. One sanity check would be to include in every log record the highest known to be persistent record id. After finding the end of the log the code could scan farther for a valid record and declare the log corrupt if the valid record implies the log was previously committed beyond the apparent EOF.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bbridge","name":"bbridge","key":"bbridge","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Bill Bridge","active":true,"timeZone":"America/Los_Angeles"},"created":"2012-07-06T23:42:55.947+0000","updated":"2012-07-06T23:42:55.947+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12552443/comment/13408458","id":"13408458","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=marshall","name":"marshall","key":"marshall","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Marshall McMullen","active":true,"timeZone":"America/Denver"},"body":"Unfortunately it failed again. I've uploaded new tar files with \"-withPath1489\" in the name (that was meant to be Patch not Path but anyhow...). Looks to be the same exact symptom. The rebooted node is never able to rejoin the ensemble. Any ideas or thoughts are greatly appreciated. \n\nIf this is a different bug than what's here in ZOOKEEPER-1453, then I can open a separate jira... just let me know.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=marshall","name":"marshall","key":"marshall","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Marshall McMullen","active":true,"timeZone":"America/Denver"},"created":"2012-07-06T23:43:53.671+0000","updated":"2012-07-06T23:43:53.671+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12552443/comment/13408600","id":"13408600","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=fpj","name":"fpj","key":"fpj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=fpj&avatarId=16030","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=fpj&avatarId=16030","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=fpj&avatarId=16030","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=fpj&avatarId=16030"},"displayName":"Flavio Junqueira","active":true,"timeZone":"Europe/Berlin"},"body":"I was wondering the same thing as Bill when I asked how you're doing this experiment. One way to verify is to disable the disk write cache and see if the problem goes away.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=fpj","name":"fpj","key":"fpj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=fpj&avatarId=16030","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=fpj&avatarId=16030","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=fpj&avatarId=16030","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=fpj&avatarId=16030"},"displayName":"Flavio Junqueira","active":true,"timeZone":"Europe/Berlin"},"created":"2012-07-07T08:05:10.825+0000","updated":"2012-07-07T08:05:10.825+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12552443/comment/13408705","id":"13408705","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=marshall","name":"marshall","key":"marshall","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Marshall McMullen","active":true,"timeZone":"America/Denver"},"body":"I disabled write cache on the drive that holds my zookeeper database, and it still fails in exactly the same way :-<. \n\nHere's the part that really baffles me, I tried removing the on-disk database entirely (the version-2 directory) and starting up zookeeper again on the thought that it would just pull down a fresh copy of the database from one of its peers. Unfortunately it still fails to connect. See the output below:\n\nroot@SF-42:/sf/data# java -cp /opt/zookeeper-3.5.0-p7/zookeeper-3.5.0-p7.jar:/opt/zookeeper-3.5.0-p7/lib/log4j-1.2.16.jar:/opt/zookeeper-3.5.0-p7/lib/commons-cli-1.2.jar:/opt/zookeeper-3.5.0-p7/lib/slf4j-log4j12-1.6.2.jar:/opt/zookeeper-3.5.0-p7/lib/netty-3.2.5.Final.jar:/opt/zookeeper-3.5.0-p7/lib/jline-0.9.94.jar:/opt/zookeeper-3.5.0-p7/lib/javacc.jar:/opt/zookeeper-3.5.0-p7/lib/slf4j-api-1.6.2.jar:/opt/zookeeper-3.5.0-p7/conf -Dzookeeper.root.logger=DEBUG,CONSOLE -Dzookeeper.log.dir=. -Dzookeeper.tracelog.dir=/sf/data/zookeeper/10.10.5.42/ -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.local.only=false -Djute.maxbuffer=4194304 org.apache.zookeeper.server.quorum.QuorumPeerMain /sf/data/zookeeper/10.10.5.42/10.10.5.42_2181.cfg\n2012-07-07 10:20:23,270 [myid:] - INFO  [main:QuorumPeerConfig@99] - Reading configuration from: /sf/data/zookeeper/10.10.5.42/10.10.5.42_2181.cfg\n2012-07-07 10:20:23,279 [myid:2] - INFO  [main:DatadirCleanupManager@78] - autopurge.snapRetainCount set to 5\n2012-07-07 10:20:23,279 [myid:2] - INFO  [main:DatadirCleanupManager@79] - autopurge.purgeInterval set to 1\n2012-07-07 10:20:23,280 [myid:2] - INFO  [PurgeTask:DatadirCleanupManager$PurgeTask@138] - Purge task started.\n2012-07-07 10:20:23,289 [myid:2] - INFO  [PurgeTask:DatadirCleanupManager$PurgeTask@144] - Purge task completed.\n2012-07-07 10:20:23,290 [myid:2] - INFO  [main:QuorumPeerMain@131] - Starting quorum peer\n2012-07-07 10:20:23,300 [myid:2] - INFO  [main:NIOServerCnxnFactory@108] - binding to port /10.10.5.42:2181\n2012-07-07 10:20:23,308 [myid:2] - INFO  [main:QuorumPeer@1107] - tickTime set to 2000\n2012-07-07 10:20:23,308 [myid:2] - INFO  [main:QuorumPeer@1127] - minSessionTimeout set to -1\n2012-07-07 10:20:23,308 [myid:2] - INFO  [main:QuorumPeer@1138] - maxSessionTimeout set to -1\n2012-07-07 10:20:23,308 [myid:2] - INFO  [main:QuorumPeer@1153] - initLimit set to 10\n2012-07-07 10:20:23,321 [myid:2] - INFO  [main:QuorumPeer@620] - currentEpoch not found! Creating with a reasonable default of 0. This should only happen when you are upgrading your installation\n2012-07-07 10:20:23,322 [myid:2] - INFO  [main:QuorumPeer@635] - acceptedEpoch not found! Creating with a reasonable default of 0. This should only happen when you are upgrading your installation\n2012-07-07 10:20:23,325 [myid:2] - INFO  [QuorumPeerListener:QuorumCnxManager$Listener@530] - My election bind port: /10.10.5.42:2183\n2012-07-07 10:20:23,333 [myid:2] - INFO  [QuorumPeer[myid=2]/10.10.5.42:2181:QuorumPeer@860] - LOOKING\n2012-07-07 10:20:23,334 [myid:2] - INFO  [QuorumPeer[myid=2]/10.10.5.42:2181:FastLeaderElection@831] - New election. My id =  2, proposed zxid=0x0\n2012-07-07 10:20:23,341 [myid:2] - INFO  [NIOServerCxn.Factory:/10.10.5.42:2181:NIOServerCnxnFactory@227] - Accepted socket connection from /10.10.5.44:48534\n2012-07-07 10:20:23,342 [myid:2] - INFO  [WorkerSender[myid=2]:QuorumCnxManager@191] - Have smaller server identifier, so dropping the connection: (3, 2)\n2012-07-07 10:20:23,342 [myid:2] - INFO  [WorkerReceiver[myid=2]:FastLeaderElection@635] - Notification: 2 (n.leader), 0x0 (n.zxid), 0x1 (n.round), LOOKING (n.state), 2 (n.sid), 0x0 (n.peerEPoch), LOOKING (my state)0 (n.config version)\n2012-07-07 10:20:23,345 [myid:2] - WARN  [NIOServerCxn.Factory:/10.10.5.42:2181:NIOServerCnxn@354] - Exception causing close of session 0x0 due to java.io.IOException: ZooKeeperServer not running\n2012-07-07 10:20:23,346 [myid:2] - INFO  [NIOServerCxn.Factory:/10.10.5.42:2181:NIOServerCnxn@1002] - Closed socket connection for client /10.10.5.44:48534 (no session established for client)\n2012-07-07 10:20:23,544 [myid:2] - INFO  [QuorumPeer[myid=2]/10.10.5.42:2181:FastLeaderElection@865] - Notification time out: 400\n2012-07-07 10:20:23,545 [myid:2] - INFO  [WorkerSender[myid=2]:QuorumCnxManager@191] - Have smaller server identifier, so dropping the connection: (3, 2)\n2012-07-07 10:20:23,545 [myid:2] - INFO  [WorkerReceiver[myid=2]:FastLeaderElection@635] - Notification: 2 (n.leader), 0x0 (n.zxid), 0x1 (n.round), LOOKING (n.state), 2 (n.sid), 0x0 (n.peerEPoch), LOOKING (my state)0 (n.config version)\n2012-07-07 10:20:23,680 [myid:2] - INFO  [NIOServerCxn.Factory:/10.10.5.42:2181:NIOServerCnxnFactory@227] - Accepted socket connection from /10.10.5.44:48535\n2012-07-07 10:20:23,680 [myid:2] - WARN  [NIOServerCxn.Factory:/10.10.5.42:2181:NIOServerCnxn@354] - Exception causing close of session 0x0 due to java.io.IOException: ZooKeeperServer not running\n2012-07-07 10:20:23,680 [myid:2] - INFO  [NIOServerCxn.Factory:/10.10.5.42:2181:NIOServerCnxn@1002] - Closed socket connection for client /10.10.5.44:48535 (no session established for client)\n2012-07-07 10:20:23,946 [myid:2] - INFO  [QuorumPeer[myid=2]/10.10.5.42:2181:FastLeaderElection@865] - Notification time out: 800\n2012-07-07 10:20:23,946 [myid:2] - INFO  [WorkerSender[myid=2]:QuorumCnxManager@191] - Have smaller server identifier, so dropping the connection: (3, 2)\n2012-07-07 10:20:23,947 [myid:2] - INFO  [WorkerReceiver[myid=2]:FastLeaderElection@635] - Notification: 2 (n.leader), 0x0 (n.zxid), 0x1 (n.round), LOOKING (n.state), 2 (n.sid), 0x0 (n.peerEPoch), LOOKING (my state)0 (n.config version)\n2012-07-07 10:20:24,014 [myid:2] - INFO  [NIOServerCxn.Factory:/10.10.5.42:2181:NIOServerCnxnFactory@227] - Accepted socket connection from /10.10.5.44:48536\n2012-07-07 10:20:24,014 [myid:2] - WARN  [NIOServerCxn.Factory:/10.10.5.42:2181:NIOServerCnxn@354] - Exception causing close of session 0x0 due to java.io.IOException: ZooKeeperServer not running\n2012-07-07 10:20:24,015 [myid:2] - INFO  [NIOServerCxn.Factory:/10.10.5.42:2181:NIOServerCnxn@1002] - Closed socket connection for client /10.10.5.44:48536 (no session established for client)\n2012-07-07 10:20:24,349 [myid:2] - INFO  [NIOServerCxn.Factory:/10.10.5.42:2181:NIOServerCnxnFactory@227] - Accepted socket connection from /10.10.5.44:48650\n2012-07-07 10:20:24,349 [myid:2] - WARN  [NIOServerCxn.Factory:/10.10.5.42:2181:NIOServerCnxn@354] - Exception causing close of session 0x0 due to java.io.IOException: ZooKeeperServer not running\n2012-07-07 10:20:24,349 [myid:2] - INFO  [NIOServerCxn.Factory:/10.10.5.42:2181:NIOServerCnxn@1002] - Closed socket connection for client /10.10.5.44:48650 (no session established for client)\n2012-07-07 10:20:24,683 [myid:2] - INFO  [NIOServerCxn.Factory:/10.10.5.42:2181:NIOServerCnxnFactory@227] - Accepted socket connection from /10.10.5.44:48678\n2012-07-07 10:20:24,683 [myid:2] - WARN  [NIOServerCxn.Factory:/10.10.5.42:2181:NIOServerCnxn@354] - Exception causing close of session 0x0 due to java.io.IOException: ZooKeeperServer not running\n2012-07-07 10:20:24,683 [myid:2] - INFO  [NIOServerCxn.Factory:/10.10.5.42:2181:NIOServerCnxn@1002] - Closed socket connection for client /10.10.5.44:48678 (no session established for client)\n2012-07-07 10:20:24,747 [myid:2] - INFO  [QuorumPeer[myid=2]/10.10.5.42:2181:FastLeaderElection@865] - Notification time out: 1600","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=marshall","name":"marshall","key":"marshall","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Marshall McMullen","active":true,"timeZone":"America/Denver"},"created":"2012-07-07T16:21:39.323+0000","updated":"2012-07-07T16:21:39.323+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12552443/comment/13408707","id":"13408707","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=marshall","name":"marshall","key":"marshall","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Marshall McMullen","active":true,"timeZone":"America/Denver"},"body":"Can anyone explain two things in the above that are really puzzling to me:\n\n(1) Why does it continually show \"ZooKeeperServer not running\" ? I am certain the *process* is running. So this must not refer to the process itself but something else. Can someone explain?\n\n(2) What does this message signify:\n\n2012-07-07 10:20:23,342 [myid:2] - INFO [WorkerSender[myid=2]:QuorumCnxManager@191] - Have smaller server identifier, so dropping the connection: (3, 2)\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=marshall","name":"marshall","key":"marshall","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Marshall McMullen","active":true,"timeZone":"America/Denver"},"created":"2012-07-07T16:23:51.299+0000","updated":"2012-07-07T16:23:51.299+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12552443/comment/13408714","id":"13408714","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=marshall","name":"marshall","key":"marshall","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Marshall McMullen","active":true,"timeZone":"America/Denver"},"body":"The only way I am able to get this node to rejoin the ensemble is to stop zookeeper, removing it's data directory entirely, then copy the entire version-2 directory from another peer by hand. Then when I start zk on that node everything works as expected.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=marshall","name":"marshall","key":"marshall","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Marshall McMullen","active":true,"timeZone":"America/Denver"},"created":"2012-07-07T16:44:52.730+0000","updated":"2012-07-07T16:44:52.730+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12552443/comment/13408948","id":"13408948","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bbridge","name":"bbridge","key":"bbridge","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Bill Bridge","active":true,"timeZone":"America/Los_Angeles"},"body":"This is not just about the disk write cache. It is necessary to disable the disk write cache to ensure a commit is truly persistent, but that is not the only source of this problem. \n\nThe problem is that the OS maintains a queue of disk writes. Some number of them have been submitted to the disk and some are still in the queue. These writes are not necessarily in file block order. When there is a reboot the write for the last data block may still be in the queue while the write to the block before it has gone to the disk. \n\nIf the reboot does a hardware reset or is caused by power failure, a similar thing can happen for the writes that have been given to the disk. Disks like to have about 4 - 8 requests queued to them so that they can order them to reduce seek/rotational latency. If there is a reset from the disk controller or loss of power, the disk cannot complete the requests it was given. This can result in some completing and some not. Since the disk reorders based on location of the sectors and the current location of the disk arm and current location of spindle rotation, it is not possible to predict what order writes will complete in.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bbridge","name":"bbridge","key":"bbridge","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Bill Bridge","active":true,"timeZone":"America/Los_Angeles"},"created":"2012-07-08T16:13:43.654+0000","updated":"2012-07-08T16:13:43.654+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12552443/comment/13408952","id":"13408952","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=marshall","name":"marshall","key":"marshall","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Marshall McMullen","active":true,"timeZone":"America/Denver"},"body":"Well this seems like a pretty huge limitation if an ensemble node can't reliably survive a power failure on one of the nodes without data corruption. \n\nSurely someone has seen this before or has an idea how this can be fixed? Why can't we simply write to a *.tmp file and then move it over to the real file only after we know all the writes to the *.tmp file completed? POSIX guarantees rename operation must be atomic (http://pubs.opengroup.org/onlinepubs/009695399/functions/rename.html). ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=marshall","name":"marshall","key":"marshall","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Marshall McMullen","active":true,"timeZone":"America/Denver"},"created":"2012-07-08T16:22:29.882+0000","updated":"2012-07-08T16:22:29.882+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12552443/comment/13408956","id":"13408956","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=marshall","name":"marshall","key":"marshall","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Marshall McMullen","active":true,"timeZone":"America/Denver"},"body":"Two other observations about this massive roadblock that I've seen:\n\n(1) Far, far more likely to be a problem if it's the leader node that is rebooted\n\n(2) Once rebooted, even if I clear out the version-2 directory and restart zookeeper on that node it cannot rejoin the ensemble. If I restart one of the other zookeeper processes that is already in the ensemble, then those *two nodes* can now properly see one another and form quorum. The third node that was already in the ensemble is suddenly not connectable. If I restart zookeeper on that node, then it joins the new ensemble and everything is fine.\n\nThis seems pretty catastrophic to me. \n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=marshall","name":"marshall","key":"marshall","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Marshall McMullen","active":true,"timeZone":"America/Denver"},"created":"2012-07-08T16:26:54.673+0000","updated":"2012-07-08T16:26:54.673+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12552443/comment/13408986","id":"13408986","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=marshall","name":"marshall","key":"marshall","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Marshall McMullen","active":true,"timeZone":"America/Denver"},"body":"Is it possible that the issue I'm seeing isn't necessarily caused by corrupted logs, but some sort of failed leader election? It seems very suspect that if I \"reboot -f\" the leader node, that it can't joint he ensemble on reboot. But once I restart the other two zk processes, then everyone syncs up and we're OK again. Must be a failure in leader election...?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=marshall","name":"marshall","key":"marshall","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Marshall McMullen","active":true,"timeZone":"America/Denver"},"created":"2012-07-08T17:28:35.361+0000","updated":"2012-07-08T17:28:35.361+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12552443/comment/13408996","id":"13408996","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=fpj","name":"fpj","key":"fpj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=fpj&avatarId=16030","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=fpj&avatarId=16030","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=fpj&avatarId=16030","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=fpj&avatarId=16030"},"displayName":"Flavio Junqueira","active":true,"timeZone":"Europe/Berlin"},"body":"We force it to disk, so if the disk write cache is disabled, then force returning successfully is an indication that it has been written to media. The observation about the OS buffers only holds if we don't sync to disk.\n\nI checked the files in the previous tar.gz without the traces, but I couldn't spot anything suspicious. I'll look into the last batch uploaded. Please don't delete old files. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=fpj","name":"fpj","key":"fpj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=fpj&avatarId=16030","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=fpj&avatarId=16030","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=fpj&avatarId=16030","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=fpj&avatarId=16030"},"displayName":"Flavio Junqueira","active":true,"timeZone":"Europe/Berlin"},"created":"2012-07-08T17:47:45.918+0000","updated":"2012-07-08T17:47:45.918+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12552443/comment/13409226","id":"13409226","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=fpj","name":"fpj","key":"fpj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=fpj&avatarId=16030","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=fpj&avatarId=16030","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=fpj&avatarId=16030","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=fpj&avatarId=16030"},"displayName":"Flavio Junqueira","active":true,"timeZone":"Europe/Berlin"},"body":"I have just checked the ids of the servers, both traces and myid file, and the id of the server 10.10.5.42 is wrong. From the traces, you can actually tell that it was 3 and later switched to 2 after the reboot. Having two servers with the same id seems to be causing the confusion you're observing here.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=fpj","name":"fpj","key":"fpj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=fpj&avatarId=16030","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=fpj&avatarId=16030","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=fpj&avatarId=16030","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=fpj&avatarId=16030"},"displayName":"Flavio Junqueira","active":true,"timeZone":"Europe/Berlin"},"created":"2012-07-09T06:57:32.321+0000","updated":"2012-07-09T06:57:32.321+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12552443/comment/13409401","id":"13409401","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=marshall","name":"marshall","key":"marshall","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Marshall McMullen","active":true,"timeZone":"America/Denver"},"body":"Oh my gosh, I can't believe it was a simple configuration issue!! Thank you so much for spotting the problem Flavio, you have seriously saved me!\n\nSorry to have spammed this jira with noise that wasn't related. It sure looked like it at first. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=marshall","name":"marshall","key":"marshall","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Marshall McMullen","active":true,"timeZone":"America/Denver"},"created":"2012-07-09T12:50:03.971+0000","updated":"2012-07-09T12:50:03.971+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12552443/comment/13409435","id":"13409435","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bbridge","name":"bbridge","key":"bbridge","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Bill Bridge","active":true,"timeZone":"America/Los_Angeles"},"body":"Glad to hear it was just a configuration issue. I hope fixing the configuration eliminates the corruption. If it does then the partial write problem is much less likely than your experiment implies. However it is a real world issue. If the OS crashes during a file sync, it is possible to have some blocks written and others not. The fix is to recognize partially written records and throw them away at recovery time. Oracle recovery has done this for many years.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bbridge","name":"bbridge","key":"bbridge","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Bill Bridge","active":true,"timeZone":"America/Los_Angeles"},"created":"2012-07-09T13:15:13.510+0000","updated":"2012-07-09T13:15:13.510+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12552443/comment/13409500","id":"13409500","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=marshall","name":"marshall","key":"marshall","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Marshall McMullen","active":true,"timeZone":"America/Denver"},"body":"Just wanted to confirm that this was indeed the problem. We use zookeeper in an embedded manner so our application code creates the myid file programatically when we start zookeeper. We now know there is a bug in how it's doing that. I can't believe how much time was wasted on such a simple configuration problem. So thankful to Flavio and everyone else here for helping me sort that out. Given how fatal this was, it might have been useful if ZK could have detected multiple servers with the same ID and given a more helpful error message.\n\nIn any event I agree with Bill that there is still a potential issue with corruption from a reboot that should be addressed under this jira.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=marshall","name":"marshall","key":"marshall","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Marshall McMullen","active":true,"timeZone":"America/Denver"},"created":"2012-07-09T14:11:27.531+0000","updated":"2012-07-09T14:11:27.531+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12552443/comment/13411382","id":"13411382","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=fpj","name":"fpj","key":"fpj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=fpj&avatarId=16030","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=fpj&avatarId=16030","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=fpj&avatarId=16030","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=fpj&avatarId=16030"},"displayName":"Flavio Junqueira","active":true,"timeZone":"Europe/Berlin"},"body":"I'm glad it worked, Marshall.\n\nbq. there is still a potential issue with corruption from a reboot that should be addressed under this jira.\n\nIn my understanding, the partial writes during syncs that Bill is referring to would be captured by the crc checks. Is this not enough?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=fpj","name":"fpj","key":"fpj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=fpj&avatarId=16030","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=fpj&avatarId=16030","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=fpj&avatarId=16030","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=fpj&avatarId=16030"},"displayName":"Flavio Junqueira","active":true,"timeZone":"Europe/Berlin"},"created":"2012-07-11T10:25:20.933+0000","updated":"2012-07-11T10:25:20.933+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12552443/comment/13411591","id":"13411591","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bbridge","name":"bbridge","key":"bbridge","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Bill Bridge","active":true,"timeZone":"America/Los_Angeles"},"body":"The CRC checks certainly should catch a partially written record at the end of the log. However since this is an expected event we do not want to discard the log as corrupt. We want to ignore the partial record at the end of the log, and any records that might follow. If a CRC failure is always treated as EOF, then corruption that is not from a partial write during a crash will not be treated like corruption. Thus the CRC will no longer fulfill its current role as an assurance of no corruption.\n\nYou can solve this problem by putting a block header on every sector of a log file. The block header includes a check value. Every log write is an integral number of blocks. The log is preformatted to contain valid blocks with an earlier log sequence number. Encountering valid blocks with a lower sequence number is EOF. Encountering a block with an invalid check value is a corruption. This is based on the assumption that a disk write always completes an integral number of sector writes. This is true, but in very rare circumstances writing a block can result in an I/O error on reading the block. This is infrequent enough that the multiple logs ZooKeeper uses should be sufficient protection.\n\nThis is not a quick fix. I think there should be another jira to propose this. In the mean time it may be sufficient to decide a CRC failure is EOF if it is caused by the CRC value being zero. This is based on the fact that you clear ahead with zero to reduce the number of allocations. I am hoping the CRC is the very last value in a record and on disk it is aligned to its size so that a partial record ends in zero. A partial record that ends at the file EOF should also be ignored and not considered corruption.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bbridge","name":"bbridge","key":"bbridge","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Bill Bridge","active":true,"timeZone":"America/Los_Angeles"},"created":"2012-07-11T14:46:16.745+0000","updated":"2012-07-11T14:46:16.745+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12552443/comment/13412037","id":"13412037","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=fpj","name":"fpj","key":"fpj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=fpj&avatarId=16030","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=fpj&avatarId=16030","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=fpj&avatarId=16030","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=fpj&avatarId=16030"},"displayName":"Flavio Junqueira","active":true,"timeZone":"Europe/Berlin"},"body":"Hi Bill, Thanks a lot for your input. I really appreciate that you're taking your time to revisit this part of the code. Check some comments I have below, please:\n\nbq. If a CRC failure is always treated as EOF, then corruption that is not from a partial write during a crash will not be treated like corruption\n\nI think that if we are to assume corruptions like bit flips and such, we need to do much more than adding CRCs and block-aligned writes. I'm a bit concerned about a full redesign of the transaction log scheme to consider cases that the current fault model of zookeeper does not cover.\n\nbq. The log is preformatted to contain valid blocks with an earlier log sequence number.\n\nI'm not sure I understand this step. How do we know the log sequence numbers beforehand?\n\nbq. It may be sufficient to decide a CRC failure is EOF if it is caused by the CRC value being zero.\n\nIt sounds right to me.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=fpj","name":"fpj","key":"fpj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=fpj&avatarId=16030","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=fpj&avatarId=16030","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=fpj&avatarId=16030","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=fpj&avatarId=16030"},"displayName":"Flavio Junqueira","active":true,"timeZone":"Europe/Berlin"},"created":"2012-07-11T21:48:13.703+0000","updated":"2012-07-11T21:48:13.703+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12552443/comment/13412241","id":"13412241","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=phunt","name":"phunt","key":"phunt","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Patrick Hunt","active":true,"timeZone":"America/Los_Angeles"},"body":"We already handle partial writes via the sentinel iirc. \n\nMy understanding is that we should treat any corruption as EOF as these records were written but not sync'd, therefore we would not have ACK'd the proposal. This sound right? The server will rejoin the quorum, if it does have a \"gap\" (say due to corruption) it will download the necessary transactions from the leader to catch up with the quorum.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=phunt","name":"phunt","key":"phunt","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Patrick Hunt","active":true,"timeZone":"America/Los_Angeles"},"created":"2012-07-11T22:33:47.949+0000","updated":"2012-07-11T22:33:47.949+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12552443/comment/13412379","id":"13412379","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bbridge","name":"bbridge","key":"bbridge","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Bill Bridge","active":true,"timeZone":"America/Los_Angeles"},"body":"Yes a full redesign of the logging system would be too much for this problem. Corruptions usually come from software bugs that misdirect data when writing or when the storage accidentally fails to write (note that writing to the wrong place can look like sa lost write at the correct place). Another common source is administrator mistakes like copying data to the wrong file or simultaneously assigning the same file to two different uses. Bit flips within a sector do not happen with disks. I think the CRC is a reasonable check value for the kinds of corruption we are likely to encounter.\n\nSorry, I omitted a critical point about preformattting logs. The same log file is used over and over again so that there is no allocation when writing. Before the first use, the log is initialized to contain valid empty blocks for log sequence zero. Since every reuse is at a higher sequence number the EOF is the first block with a lower sequence number than the sequence number recorded in the log header. This is how Oracle writes online logs. [Oracle Online Redo Log|http://docs.oracle.com/cd/E11882_01/server.112/e25789/physical.htm#i1006163]\n\nZooKeeper is different, it uses a new file for every log. It incrementally preallocates with zero to batch the allocations, and the zeroes are not forced to disk. The real data writes usually overwrite the zeroes in the filesystem buffer cache. Thus the zeroes are not likely to be on disk if there is a partial write due to a crash. I suppose there are times when the fsync unnecessarily forces the zeros to disk. I guess the consequences of a crash during fsync are file system dependent. Maybe checking for the 0x42 being 0 at the end of a record indicates a partial record when the zeros were flushed earlier, and EOF in the middle of a record means a partial write as well.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bbridge","name":"bbridge","key":"bbridge","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Bill Bridge","active":true,"timeZone":"America/Los_Angeles"},"created":"2012-07-11T23:56:53.461+0000","updated":"2012-07-11T23:56:53.461+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12552443/comment/13412448","id":"13412448","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bbridge","name":"bbridge","key":"bbridge","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Bill Bridge","active":true,"timeZone":"America/Los_Angeles"},"body":"I am not up to speed on ZooKeeper terminology so I am guessing that the \"sentinel iirc\" is the 0x42 (one of my favorite constants) at the end of each record. I see that in Util.readTxnBytes it is validated to be 'B' (aka 0x42) and the record is considered partial if it is wrong. This will certainly catch a partial record. \n\nIs there any way it could legitimately be anything other than 0x00 or 0x42? If not, then it would be marginally more robust to consider it partial only if it is 0x00, and corrupt if not 0x42. This could only happen if something outside of Zookeeper damaged the log after it was written. Once the head DBA (DataBase Administrator) from Amazon said to me \"Sometimes blocks just go bad\". Amazon has a lot of blocks.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bbridge","name":"bbridge","key":"bbridge","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Bill Bridge","active":true,"timeZone":"America/Los_Angeles"},"created":"2012-07-12T01:42:29.648+0000","updated":"2012-07-12T01:42:29.648+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12552443/comment/13412560","id":"13412560","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=phunt","name":"phunt","key":"phunt","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Patrick Hunt","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi Bill. \n\nbq. I am guessing that the \"sentinel iirc\" is the 0x42\n\nthat's correct.\n\nbq. ZooKeeper is different, it uses a new file for every log.\n\nBen was talking about changing this at one point. He wanted to reuse log files. Seemed like a good idea but he never completed the patch.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=phunt","name":"phunt","key":"phunt","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Patrick Hunt","active":true,"timeZone":"America/Los_Angeles"},"created":"2012-07-12T06:42:17.561+0000","updated":"2012-07-12T06:42:17.561+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12552443/comment/15045108","id":"15045108","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cristinagroapa","name":"cristinagroapa","key":"cristinagroapa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Cristina Groapa","active":true,"timeZone":"Etc/UTC"},"body":"Hi Bill, is there any progress being done on this issue? I saw some talk of a new Jira to handle corruption - is that still intended?\nMy team has recently started to use zookeeper. We had an incident where we couldn't restart a node without deleting its logs.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cristinagroapa","name":"cristinagroapa","key":"cristinagroapa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Cristina Groapa","active":true,"timeZone":"Etc/UTC"},"created":"2015-12-07T15:50:14.763+0000","updated":"2015-12-07T15:50:14.763+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12552443/comment/15202057","id":"15202057","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gsbiju","name":"gsbiju","key":"gsbiju","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Biju Nair","active":true,"timeZone":"Etc/UTC"},"body":"From the discussion looks like the issue is resolved. Can this be closed?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gsbiju","name":"gsbiju","key":"gsbiju","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Biju Nair","active":true,"timeZone":"Etc/UTC"},"created":"2016-03-18T20:05:28.220+0000","updated":"2016-03-18T20:05:28.220+0000"}],"maxResults":44,"total":44,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/ZOOKEEPER-1453/votes","votes":1,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i05xnb:"}}