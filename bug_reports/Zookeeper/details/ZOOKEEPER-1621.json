{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12627839","self":"https://issues.apache.org/jira/rest/api/2/issue/12627839","key":"ZOOKEEPER-1621","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":600,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310801","id":"12310801","key":"ZOOKEEPER","name":"ZooKeeper","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310801&avatarId=10011","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310801&avatarId=10011","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310801&avatarId=10011","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310801&avatarId=10011"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10484","id":"10484","description":"Apache ZooKeeper related","name":"ZooKeeper"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12326518","id":"12326518","name":"3.6.0","archived":false,"released":false},{"self":"https://issues.apache.org/jira/rest/api/2/version/12343268","id":"12343268","description":"Beta release against 3.5 branch","name":"3.5.5","archived":false,"released":false}],"aggregatetimespent":600,"resolution":null,"customfield_12312322":null,"customfield_12310220":"2013-01-16T16:03:54.431+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Mon Jul 30 20:21:12 UTC 2018","customfield_12310420":"304627","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/ZOOKEEPER-1621/watchers","watchCount":25,"isWatching":false},"created":"2013-01-16T15:24:08.856+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":["pull-request-available"],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"3.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":0,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12319288","id":"12319288","description":"Fix release against 3.4 branch","name":"3.4.3","archived":false,"released":true,"releaseDate":"2012-02-13"}],"issuelinks":[],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=michim","name":"michim","key":"michim","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Michi Mutsuzaki","active":true,"timeZone":"America/Los_Angeles"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2018-07-30T20:21:12.153+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/10002","description":"A patch for this issue has been uploaded to JIRA by a contributor.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/document.png","name":"Patch Available","id":"10002","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/4","id":4,"key":"indeterminate","colorName":"yellow","name":"In Progress"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12312382","id":"12312382","name":"server","description":"General issues with the ZooKeeper server."}],"timeoriginalestimate":null,"description":"The disk that ZooKeeper was using filled up. During a snapshot write, I got the following exception\n\n2013-01-16 03:11:14,098 - ERROR [SyncThread:0:SyncRequestProcessor@151] - Severe unrecoverable error, exiting\njava.io.IOException: No space left on device\n        at java.io.FileOutputStream.writeBytes(Native Method)\n        at java.io.FileOutputStream.write(FileOutputStream.java:282)\n        at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)\n        at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)\n        at org.apache.zookeeper.server.persistence.FileTxnLog.commit(FileTxnLog.java:309)\n        at org.apache.zookeeper.server.persistence.FileTxnSnapLog.commit(FileTxnSnapLog.java:306)\n        at org.apache.zookeeper.server.ZKDatabase.commit(ZKDatabase.java:484)\n        at org.apache.zookeeper.server.SyncRequestProcessor.flush(SyncRequestProcessor.java:162)\n        at org.apache.zookeeper.server.SyncRequestProcessor.run(SyncRequestProcessor.java:101)\n\nThen many subsequent exceptions like:\n\n2013-01-16 15:02:23,984 - ERROR [main:Util@239] - Last transaction was partial.\n2013-01-16 15:02:23,985 - ERROR [main:ZooKeeperServerMain@63] - Unexpected exception, exiting abnormally\njava.io.EOFException\n        at java.io.DataInputStream.readInt(DataInputStream.java:375)\n        at org.apache.jute.BinaryInputArchive.readInt(BinaryInputArchive.java:63)\n        at org.apache.zookeeper.server.persistence.FileHeader.deserialize(FileHeader.java:64)\n        at org.apache.zookeeper.server.persistence.FileTxnLog$FileTxnIterator.inStreamCreated(FileTxnLog.java:558)\n        at org.apache.zookeeper.server.persistence.FileTxnLog$FileTxnIterator.createInputArchive(FileTxnLog.java:577)\n        at org.apache.zookeeper.server.persistence.FileTxnLog$FileTxnIterator.goToNextLog(FileTxnLog.java:543)\n        at org.apache.zookeeper.server.persistence.FileTxnLog$FileTxnIterator.next(FileTxnLog.java:625)\n        at org.apache.zookeeper.server.persistence.FileTxnLog$FileTxnIterator.init(FileTxnLog.java:529)\n        at org.apache.zookeeper.server.persistence.FileTxnLog$FileTxnIterator.<init>(FileTxnLog.java:504)\n        at org.apache.zookeeper.server.persistence.FileTxnLog.read(FileTxnLog.java:341)\n        at org.apache.zookeeper.server.persistence.FileTxnSnapLog.restore(FileTxnSnapLog.java:130)\n        at org.apache.zookeeper.server.ZKDatabase.loadDataBase(ZKDatabase.java:223)\n        at org.apache.zookeeper.server.ZooKeeperServer.loadData(ZooKeeperServer.java:259)\n        at org.apache.zookeeper.server.ZooKeeperServer.startdata(ZooKeeperServer.java:386)\n        at org.apache.zookeeper.server.NIOServerCnxnFactory.startup(NIOServerCnxnFactory.java:138)\n        at org.apache.zookeeper.server.ZooKeeperServerMain.runFromConfig(ZooKeeperServerMain.java:112)\n        at org.apache.zookeeper.server.ZooKeeperServerMain.initializeAndRun(ZooKeeperServerMain.java:86)\n        at org.apache.zookeeper.server.ZooKeeperServerMain.main(ZooKeeperServerMain.java:52)\n        at org.apache.zookeeper.server.quorum.QuorumPeerMain.initializeAndRun(QuorumPeerMain.java:116)\n        at org.apache.zookeeper.server.quorum.QuorumPeerMain.main(QuorumPeerMain.java:78)\n\n\nIt seems to me that writing the transaction log should be fully atomic to avoid such situations. Is this not the case?\n\n","customfield_10010":null,"timetracking":{"remainingEstimate":"0h","timeSpent":"10m","remainingEstimateSeconds":0,"timeSpentSeconds":600},"customfield_12312026":null,"customfield_12312023":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12565144","id":"12565144","filename":"zookeeper.log.gz","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mumrah","name":"mumrah","key":"mumrah","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"David Arthur","active":true,"timeZone":"America/New_York"},"created":"2013-01-16T17:07:29.028+0000","size":131641,"mimeType":"application/x-gzip","content":"https://issues.apache.org/jira/secure/attachment/12565144/zookeeper.log.gz"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12837140","id":"12837140","filename":"ZOOKEEPER-1621.2.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=abhishekrai","name":"abhishekrai","key":"abhishekrai","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Abhishek Rai","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-11-04T14:32:11.679+0000","size":9533,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12837140/ZOOKEEPER-1621.2.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12645856","id":"12645856","filename":"ZOOKEEPER-1621.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=michim","name":"michim","key":"michim","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Michi Mutsuzaki","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-05-20T20:42:14.399+0000","size":7978,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12645856/ZOOKEEPER-1621.patch"}],"aggregatetimeestimate":0,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"252823","customfield_12312823":null,"summary":"ZooKeeper does not recover from crash when disk was full","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mumrah","name":"mumrah","key":"mumrah","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"David Arthur","active":true,"timeZone":"America/New_York"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mumrah","name":"mumrah","key":"mumrah","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"David Arthur","active":true,"timeZone":"America/New_York"},"customfield_12310290":null,"aggregateprogress":{"progress":600,"total":600,"percent":100},"customfield_12311024":null,"environment":"Ubuntu 12.04, Amazon EC2 instance","customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":600,"total":600,"percent":100},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12627839/comment/13555110","id":"13555110","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mumrah","name":"mumrah","key":"mumrah","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"David Arthur","active":true,"timeZone":"America/New_York"},"body":"I was able to workaround the issue by deleting the partially written snapshot file","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mumrah","name":"mumrah","key":"mumrah","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"David Arthur","active":true,"timeZone":"America/New_York"},"created":"2013-01-16T15:24:51.001+0000","updated":"2013-01-16T15:24:51.001+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12627839/comment/13555158","id":"13555158","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=fpj","name":"fpj","key":"fpj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=fpj&avatarId=16030","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=fpj&avatarId=16030","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=fpj&avatarId=16030","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=fpj&avatarId=16030"},"displayName":"Flavio Junqueira","active":true,"timeZone":"Europe/Berlin"},"body":"I believe the exception is being thrown while reading the snapshot and the partial transaction message is not an indication of what is causing it to crash. It sounds right that we should try a different snapshot, but according to the log messages you posted, it sounds like the problem is that we are not catching EOFException. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=fpj","name":"fpj","key":"fpj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=fpj&avatarId=16030","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=fpj&avatarId=16030","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=fpj&avatarId=16030","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=fpj&avatarId=16030"},"displayName":"Flavio Junqueira","active":true,"timeZone":"Europe/Berlin"},"created":"2013-01-16T16:03:54.431+0000","updated":"2013-01-16T16:03:54.431+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12627839/comment/13555169","id":"13555169","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mahadev","name":"mahadev","key":"mahadev","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Mahadev konar","active":true,"timeZone":"Etc/UTC"},"body":"David,\n So there exceptions are thrown when ZooKeeper is running? Am not sure why its exiting so many times. Do you guys restart the ZK server if it dies?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mahadev","name":"mahadev","key":"mahadev","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Mahadev konar","active":true,"timeZone":"Etc/UTC"},"created":"2013-01-16T16:21:34.633+0000","updated":"2013-01-16T16:21:34.633+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12627839/comment/13555189","id":"13555189","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mumrah","name":"mumrah","key":"mumrah","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"David Arthur","active":true,"timeZone":"America/New_York"},"body":"We run ZooKeeper with runit, so yes it is restarted when it dies. It ends up in a loop of:\n\n* No space left on device\n* Starting server\n* Last transaction was partial\n* Snapshotting: 0x19a3d to /opt/zookeeper-3.4.3/data/version-2/snapshot.19a3d\n* No space left on device","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mumrah","name":"mumrah","key":"mumrah","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"David Arthur","active":true,"timeZone":"America/New_York"},"created":"2013-01-16T16:42:10.047+0000","updated":"2013-01-16T16:42:10.047+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12627839/comment/13555192","id":"13555192","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mahadev","name":"mahadev","key":"mahadev","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Mahadev konar","active":true,"timeZone":"Etc/UTC"},"body":"David,\n I thought you said it does not recover when disk was full, but looks like the disk is still full? No?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mahadev","name":"mahadev","key":"mahadev","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Mahadev konar","active":true,"timeZone":"Etc/UTC"},"created":"2013-01-16T16:45:45.056+0000","updated":"2013-01-16T16:45:45.056+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12627839/comment/13555215","id":"13555215","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mumrah","name":"mumrah","key":"mumrah","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"David Arthur","active":true,"timeZone":"America/New_York"},"body":"Here is the full sequence of events (sorry for the confusion):\n\n* Noticed disk was full\n* Cleaned up disk space\n* Tried zkCli.sh, got errors\n* Checked ZK log, loop of:\n\n2013-01-16 15:01:35,194 - ERROR [main:Util@239] - Last transaction was partial.\n2013-01-16 15:01:35,196 - ERROR [main:ZooKeeperServerMain@63] - Unexpected exception, exiting abnormally\njava.io.EOFException\n\tat java.io.DataInputStream.readInt(DataInputStream.java:375)\n\tat org.apache.jute.BinaryInputArchive.readInt(BinaryInputArchive.java:63)\n\tat org.apache.zookeeper.server.persistence.FileHeader.deserialize(FileHeader.java:64)\n\tat org.apache.zookeeper.server.persistence.FileTxnLog$FileTxnIterator.inStreamCreated(FileTxnLog.java:558)\n\tat org.apache.zookeeper.server.persistence.FileTxnLog$FileTxnIterator.createInputArchive(FileTxnLog.java:577)\n\tat org.apache.zookeeper.server.persistence.FileTxnLog$FileTxnIterator.goToNextLog(FileTxnLog.java:543)\n\tat org.apache.zookeeper.server.persistence.FileTxnLog$FileTxnIterator.next(FileTxnLog.java:625)\n\tat org.apache.zookeeper.server.persistence.FileTxnLog$FileTxnIterator.init(FileTxnLog.java:529)\n\tat org.apache.zookeeper.server.persistence.FileTxnLog$FileTxnIterator.<init>(FileTxnLog.java:504)\n\tat org.apache.zookeeper.server.persistence.FileTxnLog.read(FileTxnLog.java:341)\n\tat org.apache.zookeeper.server.persistence.FileTxnSnapLog.restore(FileTxnSnapLog.java:130)\n\tat org.apache.zookeeper.server.ZKDatabase.loadDataBase(ZKDatabase.java:223)\n\tat org.apache.zookeeper.server.ZooKeeperServer.loadData(ZooKeeperServer.java:259)\n\tat org.apache.zookeeper.server.ZooKeeperServer.startdata(ZooKeeperServer.java:386)\n\tat org.apache.zookeeper.server.NIOServerCnxnFactory.startup(NIOServerCnxnFactory.java:138)\n\tat org.apache.zookeeper.server.ZooKeeperServerMain.runFromConfig(ZooKeeperServerMain.java:112)\n\tat org.apache.zookeeper.server.ZooKeeperServerMain.initializeAndRun(ZooKeeperServerMain.java:86)\n\tat org.apache.zookeeper.server.ZooKeeperServerMain.main(ZooKeeperServerMain.java:52)\n\tat org.apache.zookeeper.server.quorum.QuorumPeerMain.initializeAndRun(QuorumPeerMain.java:116)\n\tat org.apache.zookeeper.server.quorum.QuorumPeerMain.main(QuorumPeerMain.java:78)\n\n* Stopped ZK\n* Listed ZK data directory\n\nubuntu@ip-10-78-19-254:/opt/zookeeper-3.4.3/data/version-2$ ls -lat\ntotal 18096\ndrwxr-xr-x 2 zookeeper zookeeper     4096 Jan 16 06:41 .\n-rw-r--r-- 1 zookeeper zookeeper        0 Jan 16 06:41 log.19a3e\n-rw-r--r-- 1 zookeeper zookeeper   585377 Jan 16 06:41 snapshot.19a3d\n-rw-r--r-- 1 zookeeper zookeeper 67108880 Jan 16 03:11 log.19a2a\n-rw-r--r-- 1 zookeeper zookeeper   585911 Jan 16 03:11 snapshot.19a29\n-rw-r--r-- 1 zookeeper zookeeper 67108880 Jan 16 03:11 log.11549\n-rw-r--r-- 1 zookeeper zookeeper   585190 Jan 15 17:28 snapshot.11547\n-rw-r--r-- 1 zookeeper zookeeper 67108880 Jan 15 17:28 log.1\n-rw-r--r-- 1 zookeeper zookeeper      296 Jan 14 16:44 snapshot.0\ndrwxr-xr-x 3 zookeeper zookeeper     4096 Jan 14 16:44 ..\n\n* Removed log.19a3e and snapshot.19a3d\n\nubuntu@ip-10-78-19-254:/opt/zookeeper-3.4.3/data/version-2$ sudo rm log.19a3e\nubuntu@ip-10-78-19-254:/opt/zookeeper-3.4.3/data/version-2$ sudo rm snapshot.19a3d\n\n* Started ZK\n* Back to normal","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mumrah","name":"mumrah","key":"mumrah","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"David Arthur","active":true,"timeZone":"America/New_York"},"created":"2013-01-16T17:07:00.749+0000","updated":"2013-01-16T17:07:00.749+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12627839/comment/13555217","id":"13555217","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mumrah","name":"mumrah","key":"mumrah","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"David Arthur","active":true,"timeZone":"America/New_York"},"body":"Attaching zookeeper.log","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mumrah","name":"mumrah","key":"mumrah","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"David Arthur","active":true,"timeZone":"America/New_York"},"created":"2013-01-16T17:07:29.032+0000","updated":"2013-01-16T17:07:29.032+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12627839/comment/13555243","id":"13555243","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=eribeiro","name":"eribeiro","key":"eribeiro","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=eribeiro&avatarId=16169","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=eribeiro&avatarId=16169","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=eribeiro&avatarId=16169","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=eribeiro&avatarId=16169"},"displayName":"Edward Ribeiro","active":true,"timeZone":"America/Sao_Paulo"},"body":"Hi folks,\n\nFYI, this issue is a duplication of ZOOKEEPER-1612 (curiously, a permutation of the last two digits, heh). I'd suggest to close 1612 as dup instead, if possible.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=eribeiro","name":"eribeiro","key":"eribeiro","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=eribeiro&avatarId=16169","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=eribeiro&avatarId=16169","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=eribeiro&avatarId=16169","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=eribeiro&avatarId=16169"},"displayName":"Edward Ribeiro","active":true,"timeZone":"America/Sao_Paulo"},"created":"2013-01-16T17:34:21.677+0000","updated":"2013-01-16T17:34:21.677+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12627839/comment/13555318","id":"13555318","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mahadev","name":"mahadev","key":"mahadev","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Mahadev konar","active":true,"timeZone":"Etc/UTC"},"body":"Ill makr 1612 as dup. Thanks for pointing that out Edward.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mahadev","name":"mahadev","key":"mahadev","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Mahadev konar","active":true,"timeZone":"Etc/UTC"},"created":"2013-01-16T18:37:11.092+0000","updated":"2013-01-16T18:37:11.092+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12627839/comment/13557022","id":"13557022","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mahadev","name":"mahadev","key":"mahadev","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Mahadev konar","active":true,"timeZone":"Etc/UTC"},"body":"Looks like the header was incomplete. Unfortunately we do not handle corrupt header but do handle corrupt txn's later. Am suprised that this happened twice in a row for 2 users. Ill upload a patch and test case.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mahadev","name":"mahadev","key":"mahadev","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Mahadev konar","active":true,"timeZone":"Etc/UTC"},"created":"2013-01-18T07:37:48.153+0000","updated":"2013-01-18T07:37:48.153+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12627839/comment/14002556","id":"14002556","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=michim","name":"michim","key":"michim","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Michi Mutsuzaki","active":true,"timeZone":"America/Los_Angeles"},"body":"Should FileTxnIterator.goToNextLog() return false if the header is corrupted/incomplete, or should it skip the log file and go to the next log file if it exists?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=michim","name":"michim","key":"michim","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Michi Mutsuzaki","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-05-19T23:10:07.266+0000","updated":"2014-05-19T23:10:07.266+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12627839/comment/14003956","id":"14003956","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=michim","name":"michim","key":"michim","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Michi Mutsuzaki","active":true,"timeZone":"America/Los_Angeles"},"body":"https://reviews.apache.org/r/21732/","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=michim","name":"michim","key":"michim","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Michi Mutsuzaki","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-05-20T20:49:34.076+0000","updated":"2014-05-20T20:49:34.076+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12627839/comment/14003996","id":"14003996","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"-1 overall.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12645856/ZOOKEEPER-1621.patch\n  against trunk revision 1596284.\n\n    +1 @author.  The patch does not contain any @author tags.\n\n    +1 tests included.  The patch appears to include 3 new or modified tests.\n\n    +1 javadoc.  The javadoc tool did not generate any warning messages.\n\n    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.\n\n    +1 findbugs.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.\n\n    +1 release audit.  The applied patch does not increase the total number of release audit warnings.\n\n    -1 core tests.  The patch failed core unit tests.\n\n    +1 contrib tests.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-ZOOKEEPER-Build/2105//testReport/\nFindbugs warnings: https://builds.apache.org/job/PreCommit-ZOOKEEPER-Build/2105//artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html\nConsole output: https://builds.apache.org/job/PreCommit-ZOOKEEPER-Build/2105//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2014-05-20T21:26:58.138+0000","updated":"2014-05-20T21:26:58.138+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12627839/comment/14004109","id":"14004109","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shralex","name":"shralex","key":"shralex","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Alexander Shraer","active":true,"timeZone":"America/Los_Angeles"},"body":"Here's a different option - intuitively once zookeeper fails to write to disk, by continuing to operate normally it violates its promises to users (which is that if a majority acked the data is always there even if reboots happen). Once we realize the promise can't be kept it may be better to crash the server at that point and violate liveness (no availability) rather than to continue and risk coming up with a partial log at a later point violating safety (inconsistent state, lost transactions, etc).\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shralex","name":"shralex","key":"shralex","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Alexander Shraer","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-05-20T23:17:44.082+0000","updated":"2014-05-20T23:17:44.082+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12627839/comment/14004117","id":"14004117","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=michim","name":"michim","key":"michim","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Michi Mutsuzaki","active":true,"timeZone":"America/Los_Angeles"},"body":"I'm fine with Alex's suggestion. We should document how to manually recover when the server doesn't start because the log file doesn't contain the complete header.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=michim","name":"michim","key":"michim","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Michi Mutsuzaki","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-05-20T23:24:47.132+0000","updated":"2014-05-20T23:24:47.132+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12627839/comment/14340429","id":"14340429","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mumrah","name":"mumrah","key":"mumrah","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"David Arthur","active":true,"timeZone":"America/New_York"},"body":"I actually like [~shralex]'s suggestion. However, if this is going to be the way you recommended recovering a corrupt log file, there should be a script that does it for users: zk-recover.sh or some such. In this world of deployment automation, it's not a nice thing to say \"go delete the most recent log segment from ZK's data dir\". Much better for the application to handle it through a script or command.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mumrah","name":"mumrah","key":"mumrah","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"David Arthur","active":true,"timeZone":"America/New_York"},"created":"2015-02-27T17:34:15.976+0000","updated":"2015-02-27T17:34:15.976+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12627839/comment/14340511","id":"14340511","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"-1 overall.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12645856/ZOOKEEPER-1621.patch\n  against trunk revision 1662055.\n\n    +1 @author.  The patch does not contain any @author tags.\n\n    +1 tests included.  The patch appears to include 3 new or modified tests.\n\n    +1 javadoc.  The javadoc tool did not generate any warning messages.\n\n    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.\n\n    +1 findbugs.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.\n\n    +1 release audit.  The applied patch does not increase the total number of release audit warnings.\n\n    -1 core tests.  The patch failed core unit tests.\n\n    +1 contrib tests.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-ZOOKEEPER-Build/2538//testReport/\nFindbugs warnings: https://builds.apache.org/job/PreCommit-ZOOKEEPER-Build/2538//artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html\nConsole output: https://builds.apache.org/job/PreCommit-ZOOKEEPER-Build/2538//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2015-02-27T18:26:55.384+0000","updated":"2015-02-27T18:26:55.384+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12627839/comment/14707846","id":"14707846","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=arshad.mohammad","name":"arshad.mohammad","key":"arshad.mohammad","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10443","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10443","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10443","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10443"},"displayName":"Mohammad Arshad","active":true,"timeZone":"Asia/Singapore"},"body":"Apart from these corrective measures there should be some preventive measures as well. \nCan we have disk space availability checker which check periodically whether disk space is available  or not and if not available then close the Zookeeper gracefully.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=arshad.mohammad","name":"arshad.mohammad","key":"arshad.mohammad","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10443","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10443","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10443","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10443"},"displayName":"Mohammad Arshad","active":true,"timeZone":"Asia/Singapore"},"created":"2015-08-22T05:10:40.410+0000","updated":"2015-08-22T05:10:40.410+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12627839/comment/14708423","id":"14708423","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rgs","name":"rgs","key":"rgs","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=rgs&avatarId=18469","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=rgs&avatarId=18469","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=rgs&avatarId=18469","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=rgs&avatarId=18469"},"displayName":"Raul Gutierrez Segales","active":true,"timeZone":"America/Los_Angeles"},"body":"You mean, like a ZK thread dedicated to this? What would the behavior be, only shutdown if it's the leader?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rgs","name":"rgs","key":"rgs","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=rgs&avatarId=18469","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=rgs&avatarId=18469","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=rgs&avatarId=18469","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=rgs&avatarId=18469"},"displayName":"Raul Gutierrez Segales","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-08-23T16:18:23.393+0000","updated":"2015-08-23T16:18:23.393+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12627839/comment/14708873","id":"14708873","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=arshad.mohammad","name":"arshad.mohammad","key":"arshad.mohammad","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10443","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10443","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10443","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10443"},"displayName":"Mohammad Arshad","active":true,"timeZone":"Asia/Singapore"},"body":"* Yes, dedicated thread for this like {{org.apache.zookeeper.server.DatadirCleanupManager}}\n* shut-down in every case, because without disk space zookeeper can not serve any purpose\n* The idea is as follows\n** add two new zookeeper properties\n diskspace.min.threshold=5% (values can be % of data directory available space or in GB)\n diskspace.check.interval=5 second (default:5,min:1,max:Long.MAX_VALUE)\n** add dedicated disk check thread \n*** which runs on every {{diskspace.check.interval)) second\n*** if disk space is less than {{diskspace.min.threshold}} then shutdown zookeeper instance\n* Some clarifications:\n** Query: Suppose {{diskspace.check.interval=5}} and disk space can be full within 5 second  by zookeeper or by other process. What is handling for this?\n    Ans: User should know what is their usage scenario, and what other processes are using the same disk space and based on that they should optimize the {{diskspace.check.interval}} values\n** Query: let say {{diskspace.check.interval=1}} but disk space can be filled even within 1 second by zookeeper and other process\nAns: yes it can be filled if {{diskspace.min.threshold}} is less, again based on disk space usage user need to optimize {{diskspace.min.threshold}}   ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=arshad.mohammad","name":"arshad.mohammad","key":"arshad.mohammad","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10443","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10443","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10443","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10443"},"displayName":"Mohammad Arshad","active":true,"timeZone":"Asia/Singapore"},"created":"2015-08-24T06:55:07.406+0000","updated":"2015-08-24T06:55:07.406+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12627839/comment/14709593","id":"14709593","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"-1 overall.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12645856/ZOOKEEPER-1621.patch\n  against trunk revision 1697227.\n\n    +1 @author.  The patch does not contain any @author tags.\n\n    +1 tests included.  The patch appears to include 3 new or modified tests.\n\n    +1 javadoc.  The javadoc tool did not generate any warning messages.\n\n    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.\n\n    +1 findbugs.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.\n\n    +1 release audit.  The applied patch does not increase the total number of release audit warnings.\n\n    -1 core tests.  The patch failed core unit tests.\n\n    +1 contrib tests.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-ZOOKEEPER-Build/2834//testReport/\nFindbugs warnings: https://builds.apache.org/job/PreCommit-ZOOKEEPER-Build/2834//artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html\nConsole output: https://builds.apache.org/job/PreCommit-ZOOKEEPER-Build/2834//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2015-08-24T16:46:06.542+0000","updated":"2015-08-24T16:46:06.542+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12627839/comment/14717014","id":"14717014","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=arshad.mohammad","name":"arshad.mohammad","key":"arshad.mohammad","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10443","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10443","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10443","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10443"},"displayName":"Mohammad Arshad","active":true,"timeZone":"Asia/Singapore"},"body":"Hi [~rgs], does it make sense, can we create new jira for this","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=arshad.mohammad","name":"arshad.mohammad","key":"arshad.mohammad","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10443","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10443","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10443","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10443"},"displayName":"Mohammad Arshad","active":true,"timeZone":"Asia/Singapore"},"created":"2015-08-27T16:39:08.535+0000","updated":"2015-08-27T16:39:08.535+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12627839/comment/15342934","id":"15342934","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"-1 overall.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12645856/ZOOKEEPER-1621.patch\n  against trunk revision 1748630.\n\n    +1 @author.  The patch does not contain any @author tags.\n\n    +1 tests included.  The patch appears to include 3 new or modified tests.\n\n    +1 javadoc.  The javadoc tool did not generate any warning messages.\n\n    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.\n\n    -1 findbugs.  The patch appears to cause Findbugs (version 2.0.3) to fail.\n\n    +1 release audit.  The applied patch does not increase the total number of release audit warnings.\n\n    -1 core tests.  The patch failed core unit tests.\n\n    +1 contrib tests.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-ZOOKEEPER-Build/3215//testReport/\nConsole output: https://builds.apache.org/job/PreCommit-ZOOKEEPER-Build/3215//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2016-06-21T22:39:05.445+0000","updated":"2016-06-21T22:39:05.445+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12627839/comment/15560526","id":"15560526","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=abhishekrai","name":"abhishekrai","key":"abhishekrai","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Abhishek Rai","active":true,"timeZone":"America/Los_Angeles"},"body":"Reviving this old thread.  [~shralex] has a valid concern about trading off consistency for availability.  However, for the specific issue being addressed here, we can have both.\n\nThe patch skips transaction logs with an incomplete header (the first 16 bytes).  Skipping such files should not cause any loss of data as the header is an internal bookkeeping write from Zookeeper and does not contain any user data.  This avoids the current behavior of Zookeeper crashing on encountering an incomplete header, which compromises availability.\n\nThis has been a recurring problem for us in production because our app's operating environment occasionally causes a Zookeeper server's disk to become full.  After that, the server invariably runs into this problem - perhaps because there's something else that deterministically triggers a log rotation when the previous txn log throws an IOException due to disk full?\n\nThat said, we can tighten the exception being caught in [~michim]'s patch to EOFException instead of IOException to make sure that the log we are skipping indeed only has a partially written header and nothing else (in FileTxnLog.goToNextLog).\n\nAdditionally, I have written a test to verify that EOFException is thrown if and only if the header is truncated.  Zookeeper already ignores any other partially written transactions in the txn log.  If that's useful, I can upload the test, thanks.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=abhishekrai","name":"abhishekrai","key":"abhishekrai","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Abhishek Rai","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-10-09T19:56:02.192+0000","updated":"2016-10-09T19:56:02.192+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12627839/comment/15560533","id":"15560533","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"-1 overall.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12645856/ZOOKEEPER-1621.patch\n  against trunk revision df5519ab9dac9940f35cc4b308b560f2603aec7f.\n\n    +1 @author.  The patch does not contain any @author tags.\n\n    +1 tests included.  The patch appears to include 3 new or modified tests.\n\n    +1 javadoc.  The javadoc tool did not generate any warning messages.\n\n    -1 javac.  The patch appears to cause tar ant target to fail.\n\n    +1 findbugs.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.\n\n    +1 release audit.  The applied patch does not increase the total number of release audit warnings.\n\n    -1 core tests.  The patch failed core unit tests.\n\n    +1 contrib tests.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-ZOOKEEPER-Build/3476//testReport/\nFindbugs warnings: https://builds.apache.org/job/PreCommit-ZOOKEEPER-Build/3476//artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html\nConsole output: https://builds.apache.org/job/PreCommit-ZOOKEEPER-Build/3476//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2016-10-09T20:00:54.703+0000","updated":"2016-10-09T20:00:54.703+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12627839/comment/15616169","id":"15616169","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mkizner","name":"mkizner","key":"mkizner","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Meyer Kizner","active":true,"timeZone":"America/New_York"},"body":"Agreed. Forcing users to manually clean up the partial/empty header in this scenario seems undesirable, and if we only catch EOFException instead of IOException, we shouldn't run into any problems with correctness. Additionally, since this issue should only occur \"legitimately\" in the most recent txn log file, we can be even more conservative and only continue in that case.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mkizner","name":"mkizner","key":"mkizner","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Meyer Kizner","active":true,"timeZone":"America/New_York"},"created":"2016-10-28T18:31:10.502+0000","updated":"2016-10-28T18:31:10.502+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12627839/comment/15616237","id":"15616237","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=abhishekrai","name":"abhishekrai","key":"abhishekrai","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Abhishek Rai","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks [~mkizner].  Your suggestion of doing this only for the most recent txn log file is sound.  Are you also suggesting that we delete this truncated txn log file?\n\nCause, if we skip it and don't delete, then in the future, newer txn log files will get created.  So, the truncated txn log file will no longer be the latest txn log when we do a purge afterwards.\n\nDeletion seems consistent with this approach as well as consistent with PurgeTxnLog's behavior.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=abhishekrai","name":"abhishekrai","key":"abhishekrai","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Abhishek Rai","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-10-28T19:02:12.610+0000","updated":"2016-10-28T19:02:12.610+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12627839/comment/15616298","id":"15616298","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mkizner","name":"mkizner","key":"mkizner","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Meyer Kizner","active":true,"timeZone":"America/New_York"},"body":"Yes, we would have to delete such a log file upon encountering it. I don't believe this would cause any problems, and it seems desirable to have the extra check this enables.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mkizner","name":"mkizner","key":"mkizner","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Meyer Kizner","active":true,"timeZone":"America/New_York"},"created":"2016-10-28T19:25:26.071+0000","updated":"2016-10-28T19:25:26.071+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12627839/comment/15616950","id":"15616950","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hanm","name":"hanm","key":"hanm","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hanm&avatarId=26946","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hanm&avatarId=26946","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hanm&avatarId=26946","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hanm&avatarId=26946"},"displayName":"Michael Han","active":true,"timeZone":"America/Vancouver"},"body":"The proposal of the fix makes sense to me.\n\nIs it feasible to make a stronger guarantee for the ZooKeeper serialization semantics - that is, under no cases (disk full, power failure, hardware failure) would ZooKeeper generates invalid persistent files (for both snapshot and tx logs)? This might be possible by serializing things to a swap file first and then at one point do an atomic rename of the file. With the guarantee of the sanity of the on disk formats the deserializing logic would be simplified, as there will not be many corner cases to consider, besides the existing basic checksum check logic. \n\nI can think two potential drawback of this approach:\n* Performance: if we write to swap file and then rename for every writes, we will be making more sys calls per write. Might impact performance / latency of write?\n* Potential data loss during recover: to improve performance, we could batch writes and only do rename at certain points - (i.e. every 1000 writes). In case of a failure, part of the data might loss as those data (possibly corrupted / partially serialized) living in swap file will not be parsed by ZK during start up (we will only load and parse renamed files.).\n\nMy feeling is the best approach might be a mix of efforts on both serialization and deserialization side:\n* When serializing, we do our best efforts to avoid generate corrupted files (i.e. through atomic writes to files.).\n* When deserializing, we do best efforts to detect corrupt files and recover conservatively - the success of recovery might be case by case - for example for this disk full case the proposed fix sounds pretty safe to perform while in other cases it might not be straightforward to tell which data is good and which is bad.\n* As a result - the expectation is when things crash and files corrupted, ZK should be able to recover later without manual intervention. This would be good for users.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hanm","name":"hanm","key":"hanm","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hanm&avatarId=26946","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hanm&avatarId=26946","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hanm&avatarId=26946","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hanm&avatarId=26946"},"displayName":"Michael Han","active":true,"timeZone":"America/Vancouver"},"created":"2016-10-28T23:42:39.675+0000","updated":"2016-10-28T23:42:39.675+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12627839/comment/15623589","id":"15623589","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=abrahamfine","name":"abrahamfine","key":"abrahamfine","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Abraham Fine","active":true,"timeZone":"America/Los_Angeles"},"body":"[~hanm] I do not see an issue with the generation of invalid log files as long as no data is lost and the system knows how to handle them without user intervention especially if preventing this would have an impact on performance.\n\nbq. while in other cases it might not be straightforward to tell which data is good and which is bad\nWould you mind explaining what cases you are referring to?\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=abrahamfine","name":"abrahamfine","key":"abrahamfine","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Abraham Fine","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-10-31T22:16:40.015+0000","updated":"2016-10-31T22:16:40.015+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12627839/comment/15636514","id":"15636514","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=abhishekrai","name":"abhishekrai","key":"abhishekrai","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Abhishek Rai","active":true,"timeZone":"America/Los_Angeles"},"body":"Based on the discussion with [~mkizner] above, skipping of the truncated txn log file is insufficient, and its deletion is necessary.  Otherwise we can run into problems in two places:\n\n- FileTxnLog is required to include the latest txn log before the snapshot that it's loading.  If that latest txn log is truncated (and previously skipped), then it can incorrectly satisfy this requirement.  Instead, if we delete the truncated file, then we are forced to reach back into the older valid txn log.\n\n- PurgeTxnLog has similar logic about retaining the latest txn log before the last retained snapshot.  Therefore, without the deletion, its requirements would similarly be met by a truncated and useless txn log.\n\nI've now updated [~michim]'s patch with two changes and corresponding testing changes:\n- Deletion as described here.\n- Use a tighter exception (EOFException) instead of IOException.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=abhishekrai","name":"abhishekrai","key":"abhishekrai","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Abhishek Rai","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-11-04T14:32:11.898+0000","updated":"2016-11-04T14:32:11.898+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12627839/comment/15636622","id":"15636622","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"-1 overall.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12837140/ZOOKEEPER-1621.2.patch\n  against trunk revision bcb07a09b06c91243ed244f04a71b8daf629e286.\n\n    +1 @author.  The patch does not contain any @author tags.\n\n    +1 tests included.  The patch appears to include 3 new or modified tests.\n\n    +1 javadoc.  The javadoc tool did not generate any warning messages.\n\n    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.\n\n    -1 findbugs.  The patch appears to introduce 19 new Findbugs (version 3.0.1) warnings.\n\n    +1 release audit.  The applied patch does not increase the total number of release audit warnings.\n\n    +1 core tests.  The patch passed core unit tests.\n\n    +1 contrib tests.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-ZOOKEEPER-Build/3513//testReport/\nFindbugs warnings: https://builds.apache.org/job/PreCommit-ZOOKEEPER-Build/3513//artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html\nConsole output: https://builds.apache.org/job/PreCommit-ZOOKEEPER-Build/3513//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2016-11-04T15:10:49.722+0000","updated":"2016-11-04T15:10:49.722+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12627839/comment/16028195","id":"16028195","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jgrassler","name":"jgrassler","key":"jgrassler","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Johannes Grassler","active":true,"timeZone":"Europe/Berlin"},"body":"This has been open and unchanged for quite a while now, and the existing patch targets 3.5...has there been any progress on fixing this in the 3.4 branch (I am maintaining a Zookeeper 3.4.x package for OpenSUSE and if there is a fix that targets 3.4.x I'd like to include it).","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jgrassler","name":"jgrassler","key":"jgrassler","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Johannes Grassler","active":true,"timeZone":"Europe/Berlin"},"created":"2017-05-29T10:06:25.253+0000","updated":"2017-05-29T10:06:25.253+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12627839/comment/16165322","id":"16165322","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jeffwidman","name":"jeffwidman","key":"jeffwidman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jeff Widman","active":true,"timeZone":"America/Los_Angeles"},"body":"Any update on this? \n\nIt says 3.5.4, but looks like it hasn't been merged yet... despite (as best I can tell from the comments) consensus that the patch is an improvement over the current behavior.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jeffwidman","name":"jeffwidman","key":"jeffwidman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jeff Widman","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-09-13T21:34:35.477+0000","updated":"2017-09-13T21:34:35.477+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12627839/comment/16304970","id":"16304970","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jeffwidman","name":"jeffwidman","key":"jeffwidman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jeff Widman","active":true,"timeZone":"America/Los_Angeles"},"body":"Any update here?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jeffwidman","name":"jeffwidman","key":"jeffwidman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jeff Widman","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-12-28T01:14:05.293+0000","updated":"2017-12-28T01:14:05.293+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12627839/comment/16306470","id":"16306470","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"body":"GitHub user abhishekrai opened a pull request:\n\n    https://github.com/apache/zookeeper/pull/439\n\n    ZOOKEEPER-1621: Delete and skip txn log with incomplete header\n\n    Based on the patch by Michi Mutsuzaki.\r\n    \r\n    When Zookeeper server encounters a txn log with incomplete header,\r\n    the old behavior was to crash due to the resulting EOFException.\r\n    The new behavior is catch the exception and skip the txn log.\r\n    \r\n    Additionally, the txn log is deleted to ensure that it does not\r\n    influence future loads/PurgeTxnLog in believing that this is\r\n    the only txn log before the following snapshot that they need to\r\n    load/retain.\n\nYou can merge this pull request into a Git repository by running:\n\n    $ git pull https://github.com/abhishekrai/zookeeper ZOOKEEPER-1621\n\nAlternatively you can review and apply these changes as the patch at:\n\n    https://github.com/apache/zookeeper/pull/439.patch\n\nTo close this pull request, make a commit to your master/trunk branch\nwith (at least) the following in the commit message:\n\n    This closes #439\n    \n----\ncommit 6b457a069ccdb01e1ee77537b02db80f3005f5b1\nAuthor: Abhishek Rai <abhishekrai@...>\nDate:   2017-12-29T17:38:52Z\n\n    ZOOKEEPER-1621: Delete and skip txn log with incomplete header\n    \n    Based on the patch by Michi Mutsuzaki.\n    \n    When Zookeeper server encounters a txn log with incomplete header,\n    the old behavior was to crash due to the resulting EOFException.\n    The new behavior is catch the exception and skip the txn log.\n    \n    Additionally, the txn log is deleted to ensure that it does not\n    influence future loads/PurgeTxnLog in believing that this is\n    the only txn log before the following snapshot that they need to\n    load/retain.\n\n----\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"created":"2017-12-29T19:11:53.977+0000","updated":"2017-12-29T19:11:53.977+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12627839/comment/16306483","id":"16306483","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"-1 overall.  GitHub Pull Request  Build\n      \n\n    +1 @author.  The patch does not contain any @author tags.\n\n    +1 tests included.  The patch appears to include 3 new or modified tests.\n\n    +1 javadoc.  The javadoc tool did not generate any warning messages.\n\n    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.\n\n    +1 findbugs.  The patch does not introduce any new Findbugs (version 3.0.1) warnings.\n\n    +1 release audit.  The applied patch does not increase the total number of release audit warnings.\n\n    -1 core tests.  The patch failed core unit tests.\n\n    +1 contrib tests.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-ZOOKEEPER-github-pr-build/1392//testReport/\nFindbugs warnings: https://builds.apache.org/job/PreCommit-ZOOKEEPER-github-pr-build/1392//artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html\nConsole output: https://builds.apache.org/job/PreCommit-ZOOKEEPER-github-pr-build/1392//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2017-12-29T19:31:42.791+0000","updated":"2017-12-29T19:31:42.791+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12627839/comment/16316969","id":"16316969","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"body":"Github user anmolnar commented on a diff in the pull request:\n\n    https://github.com/apache/zookeeper/pull/439#discussion_r160243418\n  \n    --- Diff: src/java/test/org/apache/zookeeper/test/LoadFromLogTest.java ---\n    @@ -307,4 +315,104 @@ public void testReloadSnapshotWithMissingParent() throws Exception {\n     \n             startServer();\n         }\n    +\n    +    /**\n    +     * Verify that FileTxnIterator doesn't throw an EOFException when the\n    +     * transaction log header is incomplete.\n    +     */\n    +    @Test\n    +    public void testIncompleteHeader() throws Exception {\n    +        ClientBase.setupTestEnv();\n    +        File dataDir = ClientBase.createTmpDir();\n    +        loadDatabase(dataDir, NUM_MESSAGES);\n    +\n    +        File logDir = new File(dataDir, FileTxnSnapLog.version +\n    +                                        FileTxnSnapLog.VERSION);\n    +        FileTxnLog.FileTxnIterator fileItr = new FileTxnLog.FileTxnIterator(logDir, 0);\n    +        List<File> logFiles = fileItr.getStoredFiles();\n    +        int numTransactions = 0;\n    +        while (fileItr.next()) {\n    +            numTransactions++;\n    +        }\n    +        Assert.assertTrue(\"Verify the number of log files\",\n    +                          logFiles.size() > 0);\n    +        Assert.assertTrue(\"Verify the number of transactions\",\n    +                          numTransactions >= NUM_MESSAGES);\n    +\n    +        // Truncate the last log file.\n    +        File lastLogFile = logFiles.get(logFiles.size() - 1);\n    +        FileChannel channel = new FileOutputStream(lastLogFile).getChannel();\n    +        channel.truncate(0);\n    +        channel.close();\n    +\n    +        // This shouldn't thow Exception.\n    +        fileItr = new FileTxnLog.FileTxnIterator(logDir, 0);\n    +        logFiles = fileItr.getStoredFiles();\n    +        numTransactions = 0;\n    +        while (fileItr.next()) {\n    +        }\n    +\n    +        // Verify that the truncated log file does not exist anymore.\n    +        Assert.assertFalse(\"Verify truncated log file has been deleted\",\n    +                           lastLogFile.exists());\n    +    }\n    +\n    +    /**\n    +     * Verifies that FileTxnIterator throws CorruptedStreamException if the\n    +     * magic number is corrupted.\n    +     */\n    +    @Test(expected = StreamCorruptedException.class)\n    +    public void testCorruptMagicNumber() throws Exception {\n    +        ClientBase.setupTestEnv();\n    +        File dataDir = ClientBase.createTmpDir();\n    +        loadDatabase(dataDir, NUM_MESSAGES);\n    +\n    +        File logDir = new File(dataDir, FileTxnSnapLog.version +\n    +                                        FileTxnSnapLog.VERSION);\n    +        FileTxnLog.FileTxnIterator fileItr = new FileTxnLog.FileTxnIterator(logDir, 0);\n    +        List<File> logFiles = fileItr.getStoredFiles();\n    +        Assert.assertTrue(\"Verify the number of log files\",\n    +                          logFiles.size() > 0);\n    +\n    +        // Corrupt the magic number.\n    +        File lastLogFile = logFiles.get(logFiles.size() - 1);\n    +        RandomAccessFile file = new RandomAccessFile(lastLogFile, \"rw\");\n    +        file.seek(0);\n    +        file.writeByte(123);\n    +        file.close();\n    +\n    +        // This should throw CorruptedStreamException.\n    +        while (fileItr.next()) {\n    +        }\n    +    }\n    +\n    +    /**\n    +     * Starts a standalone server and create znodes.\n    +     */\n    +    public void loadDatabase(File dataDir, int numEntries) throws Exception {\n    --- End diff --\n    \n    This method could be private.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"created":"2018-01-08T20:15:27.325+0000","updated":"2018-01-08T20:15:27.325+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12627839/comment/16316970","id":"16316970","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"body":"Github user anmolnar commented on a diff in the pull request:\n\n    https://github.com/apache/zookeeper/pull/439#discussion_r160244035\n  \n    --- Diff: src/java/test/org/apache/zookeeper/test/LoadFromLogTest.java ---\n    @@ -307,4 +315,104 @@ public void testReloadSnapshotWithMissingParent() throws Exception {\n     \n             startServer();\n         }\n    +\n    +    /**\n    +     * Verify that FileTxnIterator doesn't throw an EOFException when the\n    +     * transaction log header is incomplete.\n    +     */\n    +    @Test\n    +    public void testIncompleteHeader() throws Exception {\n    +        ClientBase.setupTestEnv();\n    +        File dataDir = ClientBase.createTmpDir();\n    +        loadDatabase(dataDir, NUM_MESSAGES);\n    +\n    +        File logDir = new File(dataDir, FileTxnSnapLog.version +\n    +                                        FileTxnSnapLog.VERSION);\n    +        FileTxnLog.FileTxnIterator fileItr = new FileTxnLog.FileTxnIterator(logDir, 0);\n    +        List<File> logFiles = fileItr.getStoredFiles();\n    +        int numTransactions = 0;\n    +        while (fileItr.next()) {\n    +            numTransactions++;\n    +        }\n    +        Assert.assertTrue(\"Verify the number of log files\",\n    +                          logFiles.size() > 0);\n    +        Assert.assertTrue(\"Verify the number of transactions\",\n    +                          numTransactions >= NUM_MESSAGES);\n    +\n    +        // Truncate the last log file.\n    +        File lastLogFile = logFiles.get(logFiles.size() - 1);\n    +        FileChannel channel = new FileOutputStream(lastLogFile).getChannel();\n    +        channel.truncate(0);\n    +        channel.close();\n    +\n    +        // This shouldn't thow Exception.\n    +        fileItr = new FileTxnLog.FileTxnIterator(logDir, 0);\n    +        logFiles = fileItr.getStoredFiles();\n    +        numTransactions = 0;\n    +        while (fileItr.next()) {\n    +        }\n    +\n    +        // Verify that the truncated log file does not exist anymore.\n    +        Assert.assertFalse(\"Verify truncated log file has been deleted\",\n    +                           lastLogFile.exists());\n    +    }\n    +\n    +    /**\n    +     * Verifies that FileTxnIterator throws CorruptedStreamException if the\n    +     * magic number is corrupted.\n    +     */\n    +    @Test(expected = StreamCorruptedException.class)\n    +    public void testCorruptMagicNumber() throws Exception {\n    +        ClientBase.setupTestEnv();\n    +        File dataDir = ClientBase.createTmpDir();\n    +        loadDatabase(dataDir, NUM_MESSAGES);\n    +\n    +        File logDir = new File(dataDir, FileTxnSnapLog.version +\n    +                                        FileTxnSnapLog.VERSION);\n    +        FileTxnLog.FileTxnIterator fileItr = new FileTxnLog.FileTxnIterator(logDir, 0);\n    +        List<File> logFiles = fileItr.getStoredFiles();\n    +        Assert.assertTrue(\"Verify the number of log files\",\n    +                          logFiles.size() > 0);\n    +\n    +        // Corrupt the magic number.\n    +        File lastLogFile = logFiles.get(logFiles.size() - 1);\n    +        RandomAccessFile file = new RandomAccessFile(lastLogFile, \"rw\");\n    +        file.seek(0);\n    +        file.writeByte(123);\n    +        file.close();\n    +\n    +        // This should throw CorruptedStreamException.\n    +        while (fileItr.next()) {\n    +        }\n    +    }\n    +\n    +    /**\n    +     * Starts a standalone server and create znodes.\n    +     */\n    +    public void loadDatabase(File dataDir, int numEntries) throws Exception {\n    +        final String hostPort = HOST + PortAssignment.unique();\n    +        // setup a single server cluster\n    +        ZooKeeperServer zks = new ZooKeeperServer(dataDir, dataDir, 3000);\n    +        SyncRequestProcessor.setSnapCount(100);\n    +        final int PORT = Integer.parseInt(hostPort.split(\":\")[1]);\n    +        ServerCnxnFactory f = ServerCnxnFactory.createFactory(PORT, -1);\n    +        f.startup(zks);\n    +        Assert.assertTrue(\"waiting for server being up \",\n    +                ClientBase.waitForServerUp(hostPort,CONNECTION_TIMEOUT));\n    +        ZooKeeper zk = ClientBase.createZKClient(hostPort);\n    +\n    +        // Generate some transactions that will get logged.\n    +        try {\n    +            for (int i = 0; i < numEntries; i++) {\n    +                zk.create(\"/load-database-\" + i, new byte[0],\n    +                          Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n    +            }\n    +        } finally {\n    +            zk.close();\n    +        }\n    +        f.shutdown();\n    --- End diff --\n    \n    Starting the server is already implemented in base class' setUp() method and shutdown is already in tearDown(). It's safer to let junit's infrastructure to deal with startup / shutdown methods which makes sure the server(s) gets shutdown even if some error occurs.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"created":"2018-01-08T20:15:27.329+0000","updated":"2018-01-08T20:15:27.329+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12627839/comment/16316971","id":"16316971","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"body":"Github user anmolnar commented on a diff in the pull request:\n\n    https://github.com/apache/zookeeper/pull/439#discussion_r160244385\n  \n    --- Diff: src/java/test/org/apache/zookeeper/test/LoadFromLogTest.java ---\n    @@ -307,4 +315,104 @@ public void testReloadSnapshotWithMissingParent() throws Exception {\n     \n             startServer();\n         }\n    +\n    +    /**\n    +     * Verify that FileTxnIterator doesn't throw an EOFException when the\n    +     * transaction log header is incomplete.\n    +     */\n    +    @Test\n    +    public void testIncompleteHeader() throws Exception {\n    +        ClientBase.setupTestEnv();\n    +        File dataDir = ClientBase.createTmpDir();\n    +        loadDatabase(dataDir, NUM_MESSAGES);\n    --- End diff --\n    \n    Startup / shutdown logic should be in setUp() / tearDown() methods.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"created":"2018-01-08T20:15:27.369+0000","updated":"2018-01-08T20:15:27.369+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12627839/comment/16316972","id":"16316972","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"body":"Github user anmolnar commented on a diff in the pull request:\n\n    https://github.com/apache/zookeeper/pull/439#discussion_r160243609\n  \n    --- Diff: src/java/test/org/apache/zookeeper/test/LoadFromLogTest.java ---\n    @@ -307,4 +315,104 @@ public void testReloadSnapshotWithMissingParent() throws Exception {\n     \n             startServer();\n         }\n    +\n    +    /**\n    +     * Verify that FileTxnIterator doesn't throw an EOFException when the\n    +     * transaction log header is incomplete.\n    +     */\n    +    @Test\n    +    public void testIncompleteHeader() throws Exception {\n    +        ClientBase.setupTestEnv();\n    +        File dataDir = ClientBase.createTmpDir();\n    +        loadDatabase(dataDir, NUM_MESSAGES);\n    +\n    +        File logDir = new File(dataDir, FileTxnSnapLog.version +\n    +                                        FileTxnSnapLog.VERSION);\n    +        FileTxnLog.FileTxnIterator fileItr = new FileTxnLog.FileTxnIterator(logDir, 0);\n    +        List<File> logFiles = fileItr.getStoredFiles();\n    +        int numTransactions = 0;\n    +        while (fileItr.next()) {\n    +            numTransactions++;\n    +        }\n    +        Assert.assertTrue(\"Verify the number of log files\",\n    +                          logFiles.size() > 0);\n    +        Assert.assertTrue(\"Verify the number of transactions\",\n    +                          numTransactions >= NUM_MESSAGES);\n    +\n    +        // Truncate the last log file.\n    +        File lastLogFile = logFiles.get(logFiles.size() - 1);\n    +        FileChannel channel = new FileOutputStream(lastLogFile).getChannel();\n    +        channel.truncate(0);\n    +        channel.close();\n    +\n    +        // This shouldn't thow Exception.\n    +        fileItr = new FileTxnLog.FileTxnIterator(logDir, 0);\n    +        logFiles = fileItr.getStoredFiles();\n    +        numTransactions = 0;\n    +        while (fileItr.next()) {\n    +        }\n    +\n    +        // Verify that the truncated log file does not exist anymore.\n    +        Assert.assertFalse(\"Verify truncated log file has been deleted\",\n    +                           lastLogFile.exists());\n    +    }\n    +\n    +    /**\n    +     * Verifies that FileTxnIterator throws CorruptedStreamException if the\n    +     * magic number is corrupted.\n    +     */\n    +    @Test(expected = StreamCorruptedException.class)\n    +    public void testCorruptMagicNumber() throws Exception {\n    +        ClientBase.setupTestEnv();\n    +        File dataDir = ClientBase.createTmpDir();\n    +        loadDatabase(dataDir, NUM_MESSAGES);\n    +\n    +        File logDir = new File(dataDir, FileTxnSnapLog.version +\n    +                                        FileTxnSnapLog.VERSION);\n    +        FileTxnLog.FileTxnIterator fileItr = new FileTxnLog.FileTxnIterator(logDir, 0);\n    +        List<File> logFiles = fileItr.getStoredFiles();\n    +        Assert.assertTrue(\"Verify the number of log files\",\n    +                          logFiles.size() > 0);\n    +\n    +        // Corrupt the magic number.\n    +        File lastLogFile = logFiles.get(logFiles.size() - 1);\n    +        RandomAccessFile file = new RandomAccessFile(lastLogFile, \"rw\");\n    +        file.seek(0);\n    +        file.writeByte(123);\n    +        file.close();\n    +\n    +        // This should throw CorruptedStreamException.\n    +        while (fileItr.next()) {\n    +        }\n    +    }\n    +\n    +    /**\n    +     * Starts a standalone server and create znodes.\n    +     */\n    +    public void loadDatabase(File dataDir, int numEntries) throws Exception {\n    +        final String hostPort = HOST + PortAssignment.unique();\n    +        // setup a single server cluster\n    +        ZooKeeperServer zks = new ZooKeeperServer(dataDir, dataDir, 3000);\n    +        SyncRequestProcessor.setSnapCount(100);\n    +        final int PORT = Integer.parseInt(hostPort.split(\":\")[1]);\n    +        ServerCnxnFactory f = ServerCnxnFactory.createFactory(PORT, -1);\n    +        f.startup(zks);\n    +        Assert.assertTrue(\"waiting for server being up \",\n    +                ClientBase.waitForServerUp(hostPort,CONNECTION_TIMEOUT));\n    +        ZooKeeper zk = ClientBase.createZKClient(hostPort);\n    --- End diff --\n    \n    Down to this line the logic is already implemented in the base class. Please consider re-using it in your tests.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"created":"2018-01-08T20:15:27.403+0000","updated":"2018-01-08T20:15:27.403+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12627839/comment/16316973","id":"16316973","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"body":"Github user anmolnar commented on a diff in the pull request:\n\n    https://github.com/apache/zookeeper/pull/439#discussion_r160244289\n  \n    --- Diff: src/java/test/org/apache/zookeeper/test/LoadFromLogTest.java ---\n    @@ -38,10 +40,16 @@\n     import org.slf4j.LoggerFactory;\n     \n     import java.io.File;\n    +import java.io.FileOutputStream;\n     import java.io.IOException;\n    +import java.io.RandomAccessFile;\n    +import java.io.StreamCorruptedException;\n    +import java.nio.channels.FileChannel;\n    +import java.util.List;\n     \n     public class LoadFromLogTest extends ClientBase {\n         private static final int NUM_MESSAGES = 300;\n    +    private static final String HOST = \"127.0.0.1:\";\n    --- End diff --\n    \n    It's already in the base class.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"created":"2018-01-08T20:15:27.416+0000","updated":"2018-01-08T20:15:27.416+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12627839/comment/16316984","id":"16316984","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"body":"Github user anmolnar commented on a diff in the pull request:\n\n    https://github.com/apache/zookeeper/pull/439#discussion_r160245528\n  \n    --- Diff: src/java/test/org/apache/zookeeper/test/LoadFromLogTest.java ---\n    @@ -307,4 +315,104 @@ public void testReloadSnapshotWithMissingParent() throws Exception {\n     \n             startServer();\n         }\n    +\n    +    /**\n    +     * Verify that FileTxnIterator doesn't throw an EOFException when the\n    +     * transaction log header is incomplete.\n    +     */\n    +    @Test\n    +    public void testIncompleteHeader() throws Exception {\n    +        ClientBase.setupTestEnv();\n    +        File dataDir = ClientBase.createTmpDir();\n    +        loadDatabase(dataDir, NUM_MESSAGES);\n    +\n    +        File logDir = new File(dataDir, FileTxnSnapLog.version +\n    +                                        FileTxnSnapLog.VERSION);\n    +        FileTxnLog.FileTxnIterator fileItr = new FileTxnLog.FileTxnIterator(logDir, 0);\n    +        List<File> logFiles = fileItr.getStoredFiles();\n    +        int numTransactions = 0;\n    +        while (fileItr.next()) {\n    +            numTransactions++;\n    +        }\n    +        Assert.assertTrue(\"Verify the number of log files\",\n    +                          logFiles.size() > 0);\n    +        Assert.assertTrue(\"Verify the number of transactions\",\n    +                          numTransactions >= NUM_MESSAGES);\n    +\n    +        // Truncate the last log file.\n    +        File lastLogFile = logFiles.get(logFiles.size() - 1);\n    +        FileChannel channel = new FileOutputStream(lastLogFile).getChannel();\n    +        channel.truncate(0);\n    +        channel.close();\n    +\n    +        // This shouldn't thow Exception.\n    +        fileItr = new FileTxnLog.FileTxnIterator(logDir, 0);\n    +        logFiles = fileItr.getStoredFiles();\n    +        numTransactions = 0;\n    --- End diff --\n    \n    logFiles & numTransactions variables are not being used in the rest of this test.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"created":"2018-01-08T20:19:42.655+0000","updated":"2018-01-08T20:19:42.655+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12627839/comment/16317193","id":"16317193","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"body":"Github user afine commented on the issue:\n\n    https://github.com/apache/zookeeper/pull/439\n  \n    @abhishekrai Looking through the JIRA I found:\r\n    \r\n    > This has been a recurring problem for us in production because our app's operating environment occasionally causes a Zookeeper server's disk to become full. After that, the server invariably runs into this problem - perhaps because there's something else that deterministically triggers a log rotation when the previous txn log throws an IOException due to disk full?\r\n    \r\n    Do we have evidence that the log roll is being triggered \"deterministically\"? It would be great to know for sure that we are handling the disk filling up appropriately all the time rather than just a work around for special cases.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"created":"2018-01-08T22:13:33.751+0000","updated":"2018-01-08T22:13:33.751+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12627839/comment/16562446","id":"16562446","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"-1 overall.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12837140/ZOOKEEPER-1621.2.patch\n  against trunk revision 78e4a1047c701006dd4ec8d09065eda0e7adedb5.\n\n    +1 @author.  The patch does not contain any @author tags.\n\n    +1 tests included.  The patch appears to include 3 new or modified tests.\n\n    -1 patch.  The patch command could not apply the patch.\n\nConsole output: https://builds.apache.org/job/PreCommit-ZOOKEEPER-Build/3700//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2018-07-30T20:21:12.153+0000","updated":"2018-07-30T20:21:12.153+0000"}],"maxResults":45,"total":45,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/ZOOKEEPER-1621/votes","votes":6,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":1,"worklogs":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12627839/worklog/128922","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=githubbot","name":"githubbot","key":"githubbot","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ASF GitHub Bot","active":true,"timeZone":"Etc/UTC"},"comment":"Github user anmolnar commented on the issue:\n\n    https://github.com/apache/zookeeper/pull/439\n  \n    @abhishekrai @hanm \r\n    Given that we closed #560 , is this pull request still relevant?\r\n    Maybe I'm missing something here and these are just similar issues and not the same.\n","created":"2018-07-30T20:11:20.547+0000","updated":"2018-07-30T20:11:20.547+0000","started":"2018-07-30T20:11:20.546+0000","timeSpent":"10m","timeSpentSeconds":600,"id":"128922","issueId":"12627839"}]},"customfield_12311820":"0|i17nsf:"}}