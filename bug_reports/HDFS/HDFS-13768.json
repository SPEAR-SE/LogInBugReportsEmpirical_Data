{
    "expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields",
    "fields": {
        "aggregateprogress": {
            "progress": 0,
            "total": 0
        },
        "aggregatetimeestimate": null,
        "aggregatetimeoriginalestimate": null,
        "aggregatetimespent": null,
        "assignee": {
            "active": true,
            "avatarUrls": {
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10432",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10432",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10432",
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10432"
            },
            "displayName": "Ranith Sardar",
            "key": "ranith",
            "name": "RANith",
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=RANith",
            "timeZone": "Asia/Kolkata"
        },
        "components": [],
        "created": "2018-07-26T05:38:24.000+0000",
        "creator": {
            "active": true,
            "avatarUrls": {
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=linyiqun&avatarId=25258",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=linyiqun&avatarId=25258",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=linyiqun&avatarId=25258",
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=linyiqun&avatarId=25258"
            },
            "displayName": "Yiqun Lin",
            "key": "linyiqun",
            "name": "linyiqun",
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=linyiqun",
            "timeZone": "Asia/Shanghai"
        },
        "customfield_10010": null,
        "customfield_12310191": null,
        "customfield_12310192": null,
        "customfield_12310220": "2018-09-01T08:34:21.747+0000",
        "customfield_12310222": null,
        "customfield_12310230": null,
        "customfield_12310250": null,
        "customfield_12310290": null,
        "customfield_12310291": null,
        "customfield_12310300": null,
        "customfield_12310310": "1.0",
        "customfield_12310320": [
            {
                "archived": false,
                "description": "2.10.0 release",
                "id": "12341705",
                "name": "2.10.0",
                "released": false,
                "self": "https://issues.apache.org/jira/rest/api/2/version/12341705"
            },
            {
                "archived": false,
                "description": "",
                "id": "12342772",
                "name": "3.2.0",
                "released": false,
                "self": "https://issues.apache.org/jira/rest/api/2/version/12342772"
            },
            {
                "archived": false,
                "description": "3.1.2 release",
                "id": "12343763",
                "name": "3.1.2",
                "released": false,
                "self": "https://issues.apache.org/jira/rest/api/2/version/12343763"
            }
        ],
        "customfield_12310420": "9223372036854775807",
        "customfield_12310920": "9223372036854775807",
        "customfield_12310921": null,
        "customfield_12311020": null,
        "customfield_12311024": null,
        "customfield_12311120": null,
        "customfield_12311820": "0|i3wbzr:",
        "customfield_12312022": null,
        "customfield_12312023": null,
        "customfield_12312024": null,
        "customfield_12312026": null,
        "customfield_12312220": null,
        "customfield_12312320": null,
        "customfield_12312321": null,
        "customfield_12312322": null,
        "customfield_12312323": null,
        "customfield_12312324": null,
        "customfield_12312325": null,
        "customfield_12312326": null,
        "customfield_12312327": null,
        "customfield_12312328": null,
        "customfield_12312329": null,
        "customfield_12312330": null,
        "customfield_12312331": null,
        "customfield_12312332": null,
        "customfield_12312333": null,
        "customfield_12312334": null,
        "customfield_12312335": null,
        "customfield_12312336": null,
        "customfield_12312337": null,
        "customfield_12312338": null,
        "customfield_12312339": null,
        "customfield_12312340": null,
        "customfield_12312341": null,
        "customfield_12312520": null,
        "customfield_12312521": "Tue Sep 04 08:17:34 UTC 2018",
        "customfield_12312720": null,
        "customfield_12312823": null,
        "customfield_12312920": null,
        "customfield_12312921": null,
        "customfield_12312923": null,
        "customfield_12313422": "false",
        "customfield_12313520": null,
        "description": "We find DN starting so slowly when rolling upgrade our cluster. When we restart DNs, the DNs start so slowly and not register to NN immediately. And this cause a lots of following error:\r\n{noformat}\r\nDataXceiver error processing WRITE_BLOCK operation  src: /xx.xx.xx.xx:64360 dst: /xx.xx.xx.xx:50010\r\njava.io.IOException: Not ready to serve the block pool, BP-1508644862-xx.xx.xx.xx-1493781183457.\r\n        at org.apache.hadoop.hdfs.server.datanode.DataXceiver.checkAndWaitForBP(DataXceiver.java:1290)\r\n        at org.apache.hadoop.hdfs.server.datanode.DataXceiver.checkAccess(DataXceiver.java:1298)\r\n        at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:630)\r\n        at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:169)\r\n        at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:106)\r\n        at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:246)\r\n        at java.lang.Thread.run(Thread.java:745)\r\n{noformat}\r\n\r\nLooking into the logic of DN startup, it will do the initial block pool operation before the registration. And during initializing block pool operation, we found the adding replicas to volume map is the most expensive operation.  Related log:\r\n{noformat}\r\n2018-07-26 10:46:23,771 INFO [Thread-105] org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1508644862-xx.xx.xx.xx-1493781183457 on volume /home/hard_disk/1/dfs/dn/current: 242722ms\r\n2018-07-26 10:46:26,231 INFO [Thread-109] org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1508644862-xx.xx.xx.xx-1493781183457 on volume /home/hard_disk/5/dfs/dn/current: 245182ms\r\n2018-07-26 10:46:32,146 INFO [Thread-112] org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1508644862-xx.xx.xx.xx-1493781183457 on volume /home/hard_disk/8/dfs/dn/current: 251097ms\r\n2018-07-26 10:47:08,283 INFO [Thread-106] org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1508644862-xx.xx.xx.xx-1493781183457 on volume /home/hard_disk/2/dfs/dn/current: 287235ms\r\n{noformat}\r\n\r\nCurrently DN uses independent thread to scan and add replica for each volume, but we still need to wait the slowest thread to finish its work. So the main problem here is that we could make the thread to run faster.\r\n\r\nThe jstack we get when DN blocking in the adding replica:\r\n{noformat}\r\n\"Thread-113\" #419 daemon prio=5 os_prio=0 tid=0x00007f40879ff000 nid=0x145da runnable [0x00007f4043a38000]\r\n   java.lang.Thread.State: RUNNABLE\r\n\tat java.io.UnixFileSystem.list(Native Method)\r\n\tat java.io.File.list(File.java:1122)\r\n\tat java.io.File.listFiles(File.java:1207)\r\n\tat org.apache.hadoop.fs.FileUtil.listFiles(FileUtil.java:1165)\r\n\tat org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice.addToReplicasMap(BlockPoolSlice.java:445)\r\n\tat org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice.addToReplicasMap(BlockPoolSlice.java:448)\r\n\tat org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice.addToReplicasMap(BlockPoolSlice.java:448)\r\n\tat org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice.getVolumeMap(BlockPoolSlice.java:342)\r\n\tat org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImpl.getVolumeMap(FsVolumeImpl.java:864)\r\n\tat org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeList$1.run(FsVolumeList.java:191)\r\n{noformat}\r\n\r\nOne improvement maybe we can use ForkJoinPool to do this recursive task, rather than a sync way. This will be a great improvement because it can greatly speed up recovery process.",
        "duedate": null,
        "environment": null,
        "fixVersions": [],
        "issuelinks": [],
        "issuetype": {
            "avatarId": 21133,
            "description": "A problem which impairs or prevents the functions of the product.",
            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
            "id": "1",
            "name": "Bug",
            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
            "subtask": false
        },
        "labels": [],
        "lastViewed": null,
        "priority": {
            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
            "id": "3",
            "name": "Major",
            "self": "https://issues.apache.org/jira/rest/api/2/priority/3"
        },
        "progress": {
            "progress": 0,
            "total": 0
        },
        "project": {
            "avatarUrls": {
                "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094",
                "24x24": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094",
                "32x32": "https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094",
                "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094"
            },
            "id": "12310942",
            "key": "HDFS",
            "name": "Hadoop HDFS",
            "projectCategory": {
                "description": "Scalable Distributed Computing",
                "id": "10292",
                "name": "Hadoop",
                "self": "https://issues.apache.org/jira/rest/api/2/projectCategory/10292"
            },
            "self": "https://issues.apache.org/jira/rest/api/2/project/12310942"
        },
        "reporter": {
            "active": true,
            "avatarUrls": {
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=linyiqun&avatarId=25258",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=linyiqun&avatarId=25258",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=linyiqun&avatarId=25258",
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=linyiqun&avatarId=25258"
            },
            "displayName": "Yiqun Lin",
            "key": "linyiqun",
            "name": "linyiqun",
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=linyiqun",
            "timeZone": "Asia/Shanghai"
        },
        "resolution": null,
        "resolutiondate": null,
        "status": {
            "description": "A patch for this issue has been uploaded to JIRA by a contributor.",
            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/document.png",
            "id": "10002",
            "name": "Patch Available",
            "self": "https://issues.apache.org/jira/rest/api/2/status/10002",
            "statusCategory": {
                "colorName": "yellow",
                "id": 4,
                "key": "indeterminate",
                "name": "In Progress",
                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/4"
            }
        },
        "subtasks": [],
        "summary": " Adding replicas to volume map makes DataNode start slowly ",
        "timeestimate": null,
        "timeoriginalestimate": null,
        "timespent": null,
        "updated": "2018-09-04T08:18:01.000+0000",
        "versions": [{
            "archived": false,
            "description": "3.1.0 release",
            "id": "12341434",
            "name": "3.1.0",
            "releaseDate": "2018-04-06",
            "released": true,
            "self": "https://issues.apache.org/jira/rest/api/2/version/12341434"
        }],
        "votes": {
            "hasVoted": false,
            "self": "https://issues.apache.org/jira/rest/api/2/issue/HDFS-13768/votes",
            "votes": 0
        },
        "watches": {
            "isWatching": false,
            "self": "https://issues.apache.org/jira/rest/api/2/issue/HDFS-13768/watchers",
            "watchCount": 8
        },
        "workratio": -1
    },
    "id": "13174733",
    "key": "HDFS-13768",
    "self": "https://issues.apache.org/jira/rest/api/2/issue/13174733"
}