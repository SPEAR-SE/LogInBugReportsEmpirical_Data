{
    "expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields",
    "fields": {
        "aggregateprogress": {
            "progress": 0,
            "total": 0
        },
        "aggregatetimeestimate": null,
        "aggregatetimeoriginalestimate": null,
        "aggregatetimespent": null,
        "assignee": null,
        "components": [{
            "id": "12312928",
            "name": "hdfs-client",
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312928"
        }],
        "created": "2015-09-18T14:37:36.000+0000",
        "creator": {
            "active": true,
            "avatarUrls": {
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452",
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
            },
            "displayName": "Aaron McCurry",
            "key": "amccurry",
            "name": "amccurry",
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=amccurry",
            "timeZone": "America/New_York"
        },
        "customfield_10010": null,
        "customfield_12310191": null,
        "customfield_12310192": null,
        "customfield_12310220": null,
        "customfield_12310222": null,
        "customfield_12310230": null,
        "customfield_12310250": null,
        "customfield_12310290": null,
        "customfield_12310291": null,
        "customfield_12310300": null,
        "customfield_12310310": "0.0",
        "customfield_12310320": null,
        "customfield_12310420": "9223372036854775807",
        "customfield_12310920": "9223372036854775807",
        "customfield_12310921": null,
        "customfield_12311020": null,
        "customfield_12311024": null,
        "customfield_12311120": null,
        "customfield_12311820": "0|i2l4ev:",
        "customfield_12312022": null,
        "customfield_12312023": null,
        "customfield_12312024": null,
        "customfield_12312026": null,
        "customfield_12312220": null,
        "customfield_12312320": null,
        "customfield_12312321": null,
        "customfield_12312322": null,
        "customfield_12312323": null,
        "customfield_12312324": null,
        "customfield_12312325": null,
        "customfield_12312326": null,
        "customfield_12312327": null,
        "customfield_12312328": null,
        "customfield_12312329": null,
        "customfield_12312330": null,
        "customfield_12312331": null,
        "customfield_12312332": null,
        "customfield_12312333": null,
        "customfield_12312334": null,
        "customfield_12312335": null,
        "customfield_12312336": null,
        "customfield_12312337": null,
        "customfield_12312338": null,
        "customfield_12312339": null,
        "customfield_12312340": null,
        "customfield_12312341": null,
        "customfield_12312520": null,
        "customfield_12312521": "2015-09-18 14:37:36.0",
        "customfield_12312720": null,
        "customfield_12312823": null,
        "customfield_12312920": null,
        "customfield_12312921": null,
        "customfield_12312923": null,
        "customfield_12313422": "false",
        "customfield_12313520": null,
        "description": "I recently have come across a bug that causes an infinite loop in the DFSClient.  I have experienced this issue in hadoop 2.5.0 and the issue seems to be present in 2.6.0.\n\nThe bug is hard to reproduce, it seems to only occurs when the NameNode is under great pressure because I think it's a timing issue.\n\nOn the client side, a small file (100s of bytes or so) is written and then sync() is called.  The depreciated sync because the code is setup to cross compile against hadoop 1 and hadoop 2.  After the sync is called the close happens on the outputstream in another thread async to the writing thread.  This happens because the close call can be very time consuming.\n\nOnce the sync happens and the outputstream is handed off to the closing thread.  The writing thread turns around and reads the output it has written and synced.  When this happens I believe the client reads the length from the Namenode which appears to still be 0 (more on that in a moment).\n\nOnce the inputstream is open and the first byte is trying to be read the DFSInputStream goes into an infinite loop.  It appears to be error handling logical that is not handling all IOExceptions.\n\nfetchBlockByteRange  => https://github.com/apache/hadoop/blob/release-2.6.0/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java#L991\n\nThe loop occurs in the fetchBlockByteRange method, which catches all IOExceptions and just recalls the actualGetFromOneDataNode method, assuming that method handles everything correctly.\n\nactualGetFromOneDataNode  => https://github.com/apache/hadoop/blob/release-2.6.0/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java#L1025\n\nIn the actualGetFromOneDataNode inside the while loop it calls getBlockAt which throws a IOException that is not handled by the actualGetFromOneDataNode method (the real issue).\n\nactualGetFromOneDataNode calls getBlockAt =>\nhttps://github.com/apache/hadoop/blob/release-2.6.0/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java#L1040\n\ngetBlockAt => https://github.com/apache/hadoop/blob/release-2.6.0/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java#L406\n\nIn the getBlockAt method it checks that position to read are within the file length, which I believe to still be zero at this point.  This is where I believe the IOException is thrown.\n\nIOException => https://github.com/apache/hadoop/blob/release-2.6.0/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java#L413\n\nAnd because the IOException is not handled in the actualGetFromOneDataNode method and the fetchBlockByteRange blindly recalls the actualGetFromOneDataNode method over and over again the infinite loop is created.\n\nMy current work around is to wait until the file length is properly reported by the namenode before opening the file.  Likely this is the correct choice regardless, but I think that client should never go into an infinite loop during an error condition.\n",
        "duedate": null,
        "environment": null,
        "fixVersions": [],
        "issuelinks": [],
        "issuetype": {
            "avatarId": 21133,
            "description": "A problem which impairs or prevents the functions of the product.",
            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
            "id": "1",
            "name": "Bug",
            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
            "subtask": false
        },
        "labels": [],
        "lastViewed": null,
        "priority": {
            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
            "id": "3",
            "name": "Major",
            "self": "https://issues.apache.org/jira/rest/api/2/priority/3"
        },
        "progress": {
            "progress": 0,
            "total": 0
        },
        "project": {
            "avatarUrls": {
                "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094",
                "24x24": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094",
                "32x32": "https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094",
                "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094"
            },
            "id": "12310942",
            "key": "HDFS",
            "name": "Hadoop HDFS",
            "projectCategory": {
                "description": "Scalable Distributed Computing",
                "id": "10292",
                "name": "Hadoop",
                "self": "https://issues.apache.org/jira/rest/api/2/projectCategory/10292"
            },
            "self": "https://issues.apache.org/jira/rest/api/2/project/12310942"
        },
        "reporter": {
            "active": true,
            "avatarUrls": {
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452",
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
            },
            "displayName": "Aaron McCurry",
            "key": "amccurry",
            "name": "amccurry",
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=amccurry",
            "timeZone": "America/New_York"
        },
        "resolution": null,
        "resolutiondate": null,
        "status": {
            "description": "The issue is open and ready for the assignee to start work on it.",
            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/open.png",
            "id": "1",
            "name": "Open",
            "self": "https://issues.apache.org/jira/rest/api/2/status/1",
            "statusCategory": {
                "colorName": "blue-gray",
                "id": 2,
                "key": "new",
                "name": "To Do",
                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/2"
            }
        },
        "subtasks": [],
        "summary": "DFSInputStream goes into infinite loop",
        "timeestimate": null,
        "timeoriginalestimate": null,
        "timespent": null,
        "updated": "2015-09-18T16:46:32.000+0000",
        "versions": [
            {
                "archived": false,
                "description": "2.5.0 release",
                "id": "12326264",
                "name": "2.5.0",
                "releaseDate": "2014-08-11",
                "released": true,
                "self": "https://issues.apache.org/jira/rest/api/2/version/12326264"
            },
            {
                "archived": false,
                "description": "2.6.0 release",
                "id": "12327181",
                "name": "2.6.0",
                "releaseDate": "2014-11-18",
                "released": true,
                "self": "https://issues.apache.org/jira/rest/api/2/version/12327181"
            }
        ],
        "votes": {
            "hasVoted": false,
            "self": "https://issues.apache.org/jira/rest/api/2/issue/HDFS-9104/votes",
            "votes": 0
        },
        "watches": {
            "isWatching": false,
            "self": "https://issues.apache.org/jira/rest/api/2/issue/HDFS-9104/watchers",
            "watchCount": 12
        },
        "workratio": -1
    },
    "id": "12888570",
    "key": "HDFS-9104",
    "self": "https://issues.apache.org/jira/rest/api/2/issue/12888570"
}