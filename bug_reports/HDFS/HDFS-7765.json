{
    "expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields",
    "fields": {
        "aggregateprogress": {
            "progress": 0,
            "total": 0
        },
        "aggregatetimeestimate": null,
        "aggregatetimeoriginalestimate": null,
        "aggregatetimespent": null,
        "assignee": {
            "active": true,
            "avatarUrls": {
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452",
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
            },
            "displayName": "Janmejay Singh",
            "key": "janmejay",
            "name": "janmejay",
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=janmejay",
            "timeZone": "Etc/UTC"
        },
        "components": [{
            "id": "12312928",
            "name": "hdfs-client",
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312928"
        }],
        "created": "2015-02-10T17:54:54.000+0000",
        "creator": {
            "active": true,
            "avatarUrls": {
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452",
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
            },
            "displayName": "Keith Turner",
            "key": "kturner",
            "name": "kturner",
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=kturner",
            "timeZone": "America/New_York"
        },
        "customfield_10010": null,
        "customfield_12310191": null,
        "customfield_12310192": null,
        "customfield_12310220": "2015-02-18T14:12:06.922+0000",
        "customfield_12310222": null,
        "customfield_12310230": null,
        "customfield_12310250": null,
        "customfield_12310290": null,
        "customfield_12310291": null,
        "customfield_12310300": null,
        "customfield_12310310": "2.0",
        "customfield_12310320": null,
        "customfield_12310420": "9223372036854775807",
        "customfield_12310920": "9223372036854775807",
        "customfield_12310921": null,
        "customfield_12311020": null,
        "customfield_12311024": null,
        "customfield_12311120": null,
        "customfield_12311820": "0|i25fk7:",
        "customfield_12312022": null,
        "customfield_12312023": null,
        "customfield_12312024": null,
        "customfield_12312026": null,
        "customfield_12312220": null,
        "customfield_12312320": null,
        "customfield_12312321": null,
        "customfield_12312322": null,
        "customfield_12312323": null,
        "customfield_12312324": null,
        "customfield_12312325": null,
        "customfield_12312326": null,
        "customfield_12312327": null,
        "customfield_12312328": null,
        "customfield_12312329": null,
        "customfield_12312330": null,
        "customfield_12312331": null,
        "customfield_12312332": null,
        "customfield_12312333": null,
        "customfield_12312334": null,
        "customfield_12312335": null,
        "customfield_12312336": null,
        "customfield_12312337": null,
        "customfield_12312338": null,
        "customfield_12312339": null,
        "customfield_12312340": null,
        "customfield_12312341": null,
        "customfield_12312520": null,
        "customfield_12312521": "Wed Jun 27 08:57:09 UTC 2018",
        "customfield_12312720": null,
        "customfield_12312823": null,
        "customfield_12312920": null,
        "customfield_12312921": null,
        "customfield_12312923": null,
        "customfield_12313422": "false",
        "customfield_12313520": null,
        "description": "While running an Accumulo test, saw exceptions like the following while trying to write to write ahead log in HDFS. \n\nThe exception occurrs at [FSOutputSummer.java:76|https://github.com/apache/hadoop/blob/release-2.6.0/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FSOutputSummer.java#L76] which is attempting to update a byte array.\n\n{noformat}\n2015-02-06 19:46:49,769 [log.DfsLogger] WARN : Exception syncing java.lang.reflect.InvocationTargetException\njava.lang.ArrayIndexOutOfBoundsException: 4608\n        at org.apache.hadoop.fs.FSOutputSummer.write(FSOutputSummer.java:76)\n        at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.write(FSDataOutputStream.java:50)\n        at java.io.DataOutputStream.write(DataOutputStream.java:88)\n        at java.io.DataOutputStream.writeByte(DataOutputStream.java:153)\n        at org.apache.accumulo.tserver.logger.LogFileKey.write(LogFileKey.java:87)\n        at org.apache.accumulo.tserver.log.DfsLogger.write(DfsLogger.java:526)\n        at org.apache.accumulo.tserver.log.DfsLogger.logFileData(DfsLogger.java:540)\n        at org.apache.accumulo.tserver.log.DfsLogger.logManyTablets(DfsLogger.java:573)\n        at org.apache.accumulo.tserver.log.TabletServerLogger$6.write(TabletServerLogger.java:373)\n        at org.apache.accumulo.tserver.log.TabletServerLogger.write(TabletServerLogger.java:274)\n        at org.apache.accumulo.tserver.log.TabletServerLogger.logManyTablets(TabletServerLogger.java:365)\n        at org.apache.accumulo.tserver.TabletServer$ThriftClientHandler.flush(TabletServer.java:1667)\n        at org.apache.accumulo.tserver.TabletServer$ThriftClientHandler.closeUpdate(TabletServer.java:1754)\n        at sun.reflect.GeneratedMethodAccessor8.invoke(Unknown Source)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:606)\n        at org.apache.accumulo.trace.instrument.thrift.RpcServerInvocationHandler.invoke(RpcServerInvocationHandler.java:46)\n        at org.apache.accumulo.server.util.RpcWrapper$1.invoke(RpcWrapper.java:47)\n        at com.sun.proxy.$Proxy22.closeUpdate(Unknown Source)\n        at org.apache.accumulo.core.tabletserver.thrift.TabletClientService$Processor$closeUpdate.getResult(TabletClientService.java:2370)\n        at org.apache.accumulo.core.tabletserver.thrift.TabletClientService$Processor$closeUpdate.getResult(TabletClientService.java:2354)\n        at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)\n        at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)\n        at org.apache.accumulo.server.util.TServerUtils$TimedProcessor.process(TServerUtils.java:168)\n        at org.apache.thrift.server.AbstractNonblockingServer$FrameBuffer.invoke(AbstractNonblockingServer.java:516)\n        at org.apache.accumulo.server.util.CustomNonBlockingServer$1.run(CustomNonBlockingServer.java:77)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n        at org.apache.accumulo.trace.instrument.TraceRunnable.run(TraceRunnable.java:47)\n        at org.apache.accumulo.core.util.LoggingRunnable.run(LoggingRunnable.java:34)\n        at java.lang.Thread.run(Thread.java:744)\n2015-02-06 19:46:49,769 [log.DfsLogger] WARN : Exception syncing java.lang.reflect.InvocationTargetException\n2015-02-06 19:46:49,772 [log.DfsLogger] ERROR: java.lang.ArrayIndexOutOfBoundsException: 4609\njava.lang.ArrayIndexOutOfBoundsException: 4609\n        at org.apache.hadoop.fs.FSOutputSummer.write(FSOutputSummer.java:76)\n        at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.write(FSDataOutputStream.java:50)\n        at java.io.DataOutputStream.write(DataOutputStream.java:88)\n        at java.io.DataOutputStream.writeByte(DataOutputStream.java:153)\n        at org.apache.accumulo.tserver.logger.LogFileKey.write(LogFileKey.java:87)\n        at org.apache.accumulo.tserver.log.DfsLogger.write(DfsLogger.java:526)\n        at org.apache.accumulo.tserver.log.DfsLogger.logFileData(DfsLogger.java:540)\n        at org.apache.accumulo.tserver.log.DfsLogger.logManyTablets(DfsLogger.java:573)\n        at org.apache.accumulo.tserver.log.TabletServerLogger$6.write(TabletServerLogger.java:373)\n        at org.apache.accumulo.tserver.log.TabletServerLogger.write(TabletServerLogger.java:274)\n        at org.apache.accumulo.tserver.log.TabletServerLogger.logManyTablets(TabletServerLogger.java:365)\n        at org.apache.accumulo.tserver.TabletServer$ThriftClientHandler.flush(TabletServer.java:1667)\n        at org.apache.accumulo.tserver.TabletServer$ThriftClientHandler.applyUpdates(TabletServer.java:1574)\n        at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:606)\n        at org.apache.accumulo.trace.instrument.thrift.RpcServerInvocationHandler.invoke(RpcServerInvocationHandler.java:46)\n        at org.apache.accumulo.server.util.RpcWrapper$1.invoke(RpcWrapper.java:47)\n        at com.sun.proxy.$Proxy22.applyUpdates(Unknown Source)\n        at org.apache.accumulo.core.tabletserver.thrift.TabletClientService$Processor$applyUpdates.getResult(TabletClientService.java:2349)\n        at org.apache.accumulo.core.tabletserver.thrift.TabletClientService$Processor$applyUpdates.getResult(TabletClientService.java:2335)\n        at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)\n        at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)\n        at org.apache.accumulo.server.util.TServerUtils$TimedProcessor.process(TServerUtils.java:168)\n        at org.apache.thrift.server.AbstractNonblockingServer$FrameBuffer.invoke(AbstractNonblockingServer.java:516)\n        at org.apache.accumulo.server.util.CustomNonBlockingServer$1.run(CustomNonBlockingServer.java:77)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n        at org.apache.accumulo.trace.instrument.TraceRunnable.run(TraceRunnable.java:47)\n        at org.apache.accumulo.core.util.LoggingRunnable.run(LoggingRunnable.java:34)\n        at java.lang.Thread.run(Thread.java:744)\n\n  .\n  .\n  .\n\njava.lang.ArrayIndexOutOfBoundsException: 4632\n        at org.apache.hadoop.fs.FSOutputSummer.write(FSOutputSummer.java:76)\n        at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.write(FSDataOutputStream.java:50)\n        at java.io.DataOutputStream.write(DataOutputStream.java:88)\n        at java.io.DataOutputStream.writeByte(DataOutputStream.java:153)\n        at org.apache.accumulo.tserver.logger.LogFileKey.write(LogFileKey.java:87)\n        at org.apache.accumulo.tserver.log.DfsLogger.write(DfsLogger.java:526)\n        at org.apache.accumulo.tserver.log.DfsLogger.logFileData(DfsLogger.java:540)\n        at org.apache.accumulo.tserver.log.DfsLogger.logManyTablets(DfsLogger.java:573)\n        at org.apache.accumulo.tserver.log.TabletServerLogger$6.write(TabletServerLogger.java:373)\n        at org.apache.accumulo.tserver.log.TabletServerLogger.write(TabletServerLogger.java:274)\n        at org.apache.accumulo.tserver.log.TabletServerLogger.logManyTablets(TabletServerLogger.java:365)\n        at org.apache.accumulo.tserver.TabletServer$ThriftClientHandler.flush(TabletServer.java:1667)\n        at org.apache.accumulo.tserver.TabletServer$ThriftClientHandler.applyUpdates(TabletServer.java:1574)\n        at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:606)\n        at org.apache.accumulo.trace.instrument.thrift.RpcServerInvocationHandler.invoke(RpcServerInvocationHandler.java:46)\n        at org.apache.accumulo.server.util.RpcWrapper$1.invoke(RpcWrapper.java:47)\n        at com.sun.proxy.$Proxy22.applyUpdates(Unknown Source)\n        at org.apache.accumulo.core.tabletserver.thrift.TabletClientService$Processor$applyUpdates.getResult(TabletClientService.java:2349)\n        at org.apache.accumulo.core.tabletserver.thrift.TabletClientService$Processor$applyUpdates.getResult(TabletClientService.java:2335)\n        at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)\n        at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)\n        at org.apache.accumulo.server.util.TServerUtils$TimedProcessor.process(TServerUtils.java:168)\n        at org.apache.thrift.server.AbstractNonblockingServer$FrameBuffer.invoke(AbstractNonblockingServer.java:516)\n        at org.apache.accumulo.server.util.CustomNonBlockingServer$1.run(CustomNonBlockingServer.java:77)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n        at org.apache.accumulo.trace.instrument.TraceRunnable.run(TraceRunnable.java:47)\n        at org.apache.accumulo.core.util.LoggingRunnable.run(LoggingRunnable.java:34)\n        at java.lang.Thread.run(Thread.java:744)\n{noformat}\n\nImmediately before the above exception occurred, the following exception was logged by a hdfs client background thread.\n\n{noformat}\n2015-02-06 19:46:49,767 [hdfs.DFSClient] WARN : DataStreamer Exception\njava.net.SocketTimeoutException: 70000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.1.2.17:59411 remote=/10.1.2.24:50010]\n        at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)\n        at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)\n        at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)\n        at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:118)\n        at java.io.FilterInputStream.read(FilterInputStream.java:83)\n        at java.io.FilterInputStream.read(FilterInputStream.java:83)\n        at org.apache.hadoop.hdfs.protocolPB.PBHelper.vintPrefixed(PBHelper.java:2201)\n        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.transfer(DFSOutputStream.java:1142)\n        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.addDatanode2ExistingPipeline(DFSOutputStream.java:1112)\n        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1253)\n        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:1004)\n        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:548)\n{noformat}\n\nInformation on how accumulo opened the file.\n\n{noformat}\n2015-02-06 19:43:10,051 [fs.VolumeManagerImpl] DEBUG: Found CREATE enum CREATE\n2015-02-06 19:43:10,051 [fs.VolumeManagerImpl] DEBUG: Found synch enum SYNC_BLOCK\n2015-02-06 19:43:10,051 [fs.VolumeManagerImpl] DEBUG: CreateFlag set: [CREATE, SYNC_BLOCK]\n2015-02-06 19:43:10,051 [fs.VolumeManagerImpl] DEBUG: creating hdfs://ip-10-1-2-11:9000/accumulo/wal/ip-10-1-2-17+9997/2e548d95-d075-484d-abac-bdd877ea205b with SYNCH_BLOCK flag\n{noformat}",
        "duedate": null,
        "environment": "Centos 6, Open JDK 7, Amazon EC2, Accumulo 1.6.2RC4",
        "fixVersions": [],
        "issuelinks": [],
        "issuetype": {
            "avatarId": 21133,
            "description": "A problem which impairs or prevents the functions of the product.",
            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
            "id": "1",
            "name": "Bug",
            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
            "subtask": false
        },
        "labels": [],
        "lastViewed": null,
        "priority": {
            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
            "id": "3",
            "name": "Major",
            "self": "https://issues.apache.org/jira/rest/api/2/priority/3"
        },
        "progress": {
            "progress": 0,
            "total": 0
        },
        "project": {
            "avatarUrls": {
                "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094",
                "24x24": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094",
                "32x32": "https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094",
                "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094"
            },
            "id": "12310942",
            "key": "HDFS",
            "name": "Hadoop HDFS",
            "projectCategory": {
                "description": "Scalable Distributed Computing",
                "id": "10292",
                "name": "Hadoop",
                "self": "https://issues.apache.org/jira/rest/api/2/projectCategory/10292"
            },
            "self": "https://issues.apache.org/jira/rest/api/2/project/12310942"
        },
        "reporter": {
            "active": true,
            "avatarUrls": {
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452",
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
            },
            "displayName": "Keith Turner",
            "key": "kturner",
            "name": "kturner",
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=kturner",
            "timeZone": "America/New_York"
        },
        "resolution": null,
        "resolutiondate": null,
        "status": {
            "description": "The issue is open and ready for the assignee to start work on it.",
            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/open.png",
            "id": "1",
            "name": "Open",
            "self": "https://issues.apache.org/jira/rest/api/2/status/1",
            "statusCategory": {
                "colorName": "blue-gray",
                "id": 2,
                "key": "new",
                "name": "To Do",
                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/2"
            }
        },
        "subtasks": [],
        "summary": "FSOutputSummer throwing ArrayIndexOutOfBoundsException",
        "timeestimate": null,
        "timeoriginalestimate": null,
        "timespent": null,
        "updated": "2018-06-27T08:57:09.000+0000",
        "versions": [{
            "archived": false,
            "description": "2.6.0 release",
            "id": "12327181",
            "name": "2.6.0",
            "releaseDate": "2014-11-18",
            "released": true,
            "self": "https://issues.apache.org/jira/rest/api/2/version/12327181"
        }],
        "votes": {
            "hasVoted": false,
            "self": "https://issues.apache.org/jira/rest/api/2/issue/HDFS-7765/votes",
            "votes": 2
        },
        "watches": {
            "isWatching": false,
            "self": "https://issues.apache.org/jira/rest/api/2/issue/HDFS-7765/watchers",
            "watchCount": 17
        },
        "workratio": -1
    },
    "id": "12773906",
    "key": "HDFS-7765",
    "self": "https://issues.apache.org/jira/rest/api/2/issue/12773906"
}