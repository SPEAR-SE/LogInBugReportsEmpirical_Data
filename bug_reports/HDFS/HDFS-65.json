{
    "expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields",
    "fields": {
        "aggregateprogress": {
            "progress": 0,
            "total": 0
        },
        "aggregatetimeestimate": null,
        "aggregatetimeoriginalestimate": null,
        "aggregatetimespent": null,
        "assignee": null,
        "components": [],
        "created": "2008-07-17T16:19:51.000+0000",
        "creator": {
            "active": true,
            "avatarUrls": {
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452",
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
            },
            "displayName": "Thibaut",
            "key": "bluelu",
            "name": "bluelu",
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=bluelu",
            "timeZone": "Europe/Berlin"
        },
        "customfield_10010": null,
        "customfield_12310191": null,
        "customfield_12310192": null,
        "customfield_12310220": "2008-08-22T18:39:57.014+0000",
        "customfield_12310222": "1_*:*_1_*:*_254701742_*|*_5_*:*_2_*:*_1379304717_*|*_4_*:*_1_*:*_187760996552",
        "customfield_12310230": null,
        "customfield_12310250": null,
        "customfield_12310290": null,
        "customfield_12310291": null,
        "customfield_12310300": null,
        "customfield_12310310": "0.0",
        "customfield_12310320": null,
        "customfield_12310420": "16859",
        "customfield_12310920": "107961",
        "customfield_12310921": null,
        "customfield_12311020": null,
        "customfield_12311024": null,
        "customfield_12311120": null,
        "customfield_12311820": "0|i0iu1j:",
        "customfield_12312022": null,
        "customfield_12312023": null,
        "customfield_12312024": null,
        "customfield_12312026": null,
        "customfield_12312220": null,
        "customfield_12312320": null,
        "customfield_12312321": null,
        "customfield_12312322": null,
        "customfield_12312323": null,
        "customfield_12312324": null,
        "customfield_12312325": null,
        "customfield_12312326": null,
        "customfield_12312327": null,
        "customfield_12312328": null,
        "customfield_12312329": null,
        "customfield_12312330": null,
        "customfield_12312331": null,
        "customfield_12312332": null,
        "customfield_12312333": null,
        "customfield_12312334": null,
        "customfield_12312335": null,
        "customfield_12312336": null,
        "customfield_12312337": null,
        "customfield_12312338": null,
        "customfield_12312339": null,
        "customfield_12312340": null,
        "customfield_12312341": null,
        "customfield_12312520": null,
        "customfield_12312521": "Fri Aug 22 18:53:24 UTC 2008",
        "customfield_12312720": null,
        "customfield_12312823": null,
        "customfield_12312920": null,
        "customfield_12312921": null,
        "customfield_12312923": null,
        "customfield_12313422": "false",
        "customfield_12313520": null,
        "description": "Hi, I'm trying to access the hdfs of my hadoop cluster in a non hadoop application. Hadoop 0.17.1 is running on standart ports (The same error also occured on earlier verisons). The code however will fail, as there is a version conflict.\n\n\nThis is the code I use:\n\nFileSystem fileSystem = null;\n                String hdfsurl = \"hdfs://localhost:50010\";\nfileSystem = new DistributedFileSystem();\n\n                try {\n                        fileSystem.initialize(new URI(hdfsurl), new Configuration());\n                } catch (Exception e) {\n                        e.printStackTrace();\n                        System.out.println(\"init error:\");\n                        System.exit(1);\n\n                }\n\n\nwhich fails with the exception:\n\n\njava.net.SocketTimeoutException: timed out waiting for rpc response\n        at org.apache.hadoop.ipc.Client.call(Client.java:559)\n        at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:212)\n        at org.apache.hadoop.dfs.$Proxy0.getProtocolVersion(Unknown Source)\n        at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:313)\n        at org.apache.hadoop.dfs.DFSClient.createRPCNamenode(DFSClient.java:102)\n        at org.apache.hadoop.dfs.DFSClient.<init>(DFSClient.java:178)\n        at org.apache.hadoop.dfs.DistributedFileSystem.initialize(DistributedFileSystem.java:68)\n        at com.iterend.spider.conf.Config.getRemoteFileSystem(Config.java:72)\n        at tests.RemoteFileSystemTest.main(RemoteFileSystemTest.java:22)\ninit error:\n\n\nThe haddop logfile contains the following error:\nSTARTUP_MSG: Starting DataNode\nSTARTUP_MSG:   host = bluelu-PC/192.168.1.130\nSTARTUP_MSG:   args = []\nSTARTUP_MSG:   version = 0.17.1\nSTARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.17 -r 669344; compiled by 'hadoopqa' on Thu Jun 19 01:18:25 UTC 2008 \n2008-07-10 23:05:47,840 INFO org.apache.hadoop.dfs.Storage: Storage directory \\hadoop\\tmp\\hadoop-sshd_server\\dfs\\data is not formatted.\n2008-07-10 23:05:47,840 INFO org.apache.hadoop.dfs.Storage: Formatting ...\n2008-07-10 23:05:47,928 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean\n2008-07-10 23:05:47,929 INFO org.apache.hadoop.dfs.DataNode: Opened server at 50010\n2008-07-10 23:05:47,933 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s\n2008-07-10 23:05:48,128 INFO org.mortbay.util.Credential: Checking Resource aliases\n2008-07-10 23:05:48,344 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4\n2008-07-10 23:05:48,346 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]\n2008-07-10 23:05:48,346 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]\n2008-07-10 23:05:49,047 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@15bc6c8\n2008-07-10 23:05:49,244 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]\n2008-07-10 23:05:49,247 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075\n2008-07-10 23:05:49,247 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@47a0d4\n2008-07-10 23:05:49,257 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null\n2008-07-10 23:05:49,535 INFO org.apache.hadoop.dfs.DataNode: New storage id DS-2117780943-192.168.1.130-50010-1215723949510 is assigned to data-node 127.0.0.1:50010\n2008-07-10 23:05:49,586 INFO org.apache.hadoop.dfs.DataNode: 127.0.0.1:50010In DataNode.run, data = FSDataset{dirpath='c:\\hadoop\\tmp\\hadoop-sshd_server\\dfs\\data\\current'}\n2008-07-10 23:05:49,586 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 60000msec\n2008-07-10 23:06:04,636 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 0 blocks got processed in 11 msecs\n2008-07-10 23:19:54,512 ERROR org.apache.hadoop.dfs.DataNode: 127.0.0.1:50010:DataXceiver: java.io.IOException: Version Mismatch\n        at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:961)\n        at java.lang.Thread.run(Thread.java:619)\n\n\nWhen compiling my own jar from the 0.17-1, I see that the distributed version has the revision number compiled into version number, instead of using the one from the source code (26738 vs 9). Skipping this check triggers another exception:\n\n2008-07-17 17:28:51,268 ERROR org.apache.hadoop.dfs.DataNode: 127.0.0.1:50010:DataXceiver: java.io.IOException: Unknown opcode 112 in data stream\n\tat org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1002)\n\tat java.lang.Thread.run(Thread.java:619)\n\n\nWhat do I do different from a hadoop application accessing hdfs?\n",
        "duedate": null,
        "environment": "Client Eclipse, server windows/cygwin",
        "fixVersions": [],
        "issuelinks": [],
        "issuetype": {
            "avatarId": 21133,
            "description": "A problem which impairs or prevents the functions of the product.",
            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
            "id": "1",
            "name": "Bug",
            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
            "subtask": false
        },
        "labels": [],
        "lastViewed": null,
        "priority": {
            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
            "id": "3",
            "name": "Major",
            "self": "https://issues.apache.org/jira/rest/api/2/priority/3"
        },
        "progress": {
            "progress": 0,
            "total": 0
        },
        "project": {
            "avatarUrls": {
                "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094",
                "24x24": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094",
                "32x32": "https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094",
                "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094"
            },
            "id": "12310942",
            "key": "HDFS",
            "name": "Hadoop HDFS",
            "projectCategory": {
                "description": "Scalable Distributed Computing",
                "id": "10292",
                "name": "Hadoop",
                "self": "https://issues.apache.org/jira/rest/api/2/projectCategory/10292"
            },
            "self": "https://issues.apache.org/jira/rest/api/2/project/12310942"
        },
        "reporter": {
            "active": true,
            "avatarUrls": {
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452",
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
            },
            "displayName": "Thibaut",
            "key": "bluelu",
            "name": "bluelu",
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=bluelu",
            "timeZone": "Europe/Berlin"
        },
        "resolution": {
            "description": "All attempts at reproducing this issue failed, or not enough information was available to reproduce the issue. Reading the code produces no clues as to why this behavior would occur. If more information appears later, please reopen the issue.",
            "id": "5",
            "name": "Cannot Reproduce",
            "self": "https://issues.apache.org/jira/rest/api/2/resolution/5"
        },
        "resolutiondate": "2014-07-18T18:03:14.000+0000",
        "status": {
            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
            "id": "5",
            "name": "Resolved",
            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
            "statusCategory": {
                "colorName": "green",
                "id": 3,
                "key": "done",
                "name": "Done",
                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3"
            }
        },
        "subtasks": [],
        "summary": "Unable to access data from non hadoop application (Version mismatch in DataNode)",
        "timeestimate": null,
        "timeoriginalestimate": null,
        "timespent": null,
        "updated": "2014-07-18T18:03:14.000+0000",
        "versions": [],
        "votes": {
            "hasVoted": false,
            "self": "https://issues.apache.org/jira/rest/api/2/issue/HDFS-65/votes",
            "votes": 0
        },
        "watches": {
            "isWatching": false,
            "self": "https://issues.apache.org/jira/rest/api/2/issue/HDFS-65/watchers",
            "watchCount": 1
        },
        "workratio": -1
    },
    "id": "12400493",
    "key": "HDFS-65",
    "self": "https://issues.apache.org/jira/rest/api/2/issue/12400493"
}