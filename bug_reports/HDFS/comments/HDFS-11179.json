[When a blockId is a large number, this method doesn't remove the block correctly.
{code:title=LightWeightHashSet.java}
protected LinkedElement<T> removeElem(final T key) {
  LinkedElement<T> found = null;
  final int hashCode = key.hashCode();
  final int index = getIndex(hashCode);
  if (entries[index] == null) {
    return null;
{code}, [~tasanuma0829] thanks for filing the bug report.
While I think this fix is important, I don't see why it's a blocker.

For reference, we've seen block id overflow in the past in logs, but we've not noticed it caused real issues., Agree with [~jojochuang]. Especially, this EC staff doesn't show up in 2.8 release, remove 2.8 in target version., Thanks for the comments, [~jojochuang], [~djp].

That's right, I have just observed {{postponedMisreplicatedBlocksCount}} has been going below zero at the moment. I'd like to set lower priority., I'm sorry but my assumption that LightWeightHashSet has bug may not be valid. I will look into this more., We have been running with HDFS-8674 internally for quite some time and don't remember seeing the count going negative.  It removes the separate counter and simply uses the size of the data structure, so it is very likely that it fixes what you saw., Thanks for the information and working on that, [~kihwal]! We'd like to apply it to our environment., I apologize that my thoughts were wrong. Actually postponed blocks haven't used {{LightWeightHashSet}} in our test cluster yet.

Now I rather think HDFS-8792 (and HDFS-8674) may solve this problem. I will upgrade our cluster and do tests again. If this problem appears again, I will create another jira.

Sorry for my mistakes and thanks for paying attention to this jira.]