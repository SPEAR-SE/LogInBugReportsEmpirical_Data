[The issue is that it's starting replay at the beginning of the next full segment, instead of starting with the previous half-replayed segment and skipping forward to the correct txid. We could either fix this, or change the 2NN so that if edit log replay fails, it aborts itself entirely (given such errors are generally going to just happen again on the next attempt, it's probably better to fail hard so an admin notices, instead of retrying forever), Aborting definitely seems like the safest thing to do-- do we know that all transactions are applied atomically (i.e. if they fail and throw an exception in the middle, is there rollback of whatever they did to the FSImage?)  I'm not clear on that point., Good point, Colin. I definitely don't think that's a safe assumption to make, so I agree we should abort if there is an exception on the application of an edit, I've seen similar issues due to a quota bug, which I have yet to reproduce. NN allows users to go a bit over quota due to this bug. On 2NN, since updateCountForINodeWithQuota() is called every time it checkpoints, any such error is corrected, but quota violations allowed by NN will still be there. (WARN is printed on 2NN)  If replaying of edits on top of this namespace state meets a quota exception, it gets into the unrecoverable loop of retry. 

It seems that 2NN state needs to be reset when an exception occurs during replaying edits. Then 2NN will load everything from scratch and create an accurate state without losing any edits. We will still see WARN messages revealing bugs that cause NN state to be inaccurate.

Since 2NN retries every minute, it can cause generation of a huge number of edit files. 2NN should give up after  rolling and creating new edit, say, 100 times. This is related to HDFS-280, but in this case we do not download everything all over again.

, The patch keeps count of merge errors. If it's > 0, reload is done. If successful, the counter is reset. If counter reaches the threshold (i.e. N consecutive checkpointing failures due to merge errors), 2NN exits in order to prevent generation of a large number of edits by rolling frequently., {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12571518/hdfs-4128.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 tests included appear to have a timeout.{color}

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/4019//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/4019//console

This message is automatically generated., Patch looks straightforward.  A few comments:
* Default of 60 retries seems a bit high, esp. for a cluster with a large image and edits.  I'd think something like the standard 3 would be sufficient because if the 2NN aborts it will get the attention faster of the admin.
* I think ">= maxRetries" should be ">" because ">=" means attempts instead of retries.  Ie. Currently if I specify 1 max retry, it doesn't retry at all.
* Given the former issue, there should be a test that maxRetries is actually honored.
* Spelling police told me "occured" should be "occurred" :)
, I agree that exceptions during merge will rarely be caused by transient errors, if any. So 3 or even 2 may be sufficient. Spelling is something that constantly evolving. But I will refrain from boldly going where speller checkers have never gone before., The revised patch includes the improved test case that checks number of retries done before exit in addition to detecting exit. , {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12571616/hdfs-4128.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 tests included appear to have a timeout.{color}

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/4023//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/4023//console

This message is automatically generated., +1 Looks good, will commit shortly., Committed to trunk/2/23.  Thanks Kihwal!, Integrated in Hadoop-trunk-Commit #3409 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/3409/])
    HDFS-4128. 2NN gets stuck in inconsistent state if edit log replay fails in the middle (kihwal via daryn) (Revision 1452384)

     Result = SUCCESS
daryn : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1452384
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSConfigKeys.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CheckpointConf.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CheckpointFaultInjector.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/resources/hdfs-default.xml
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestCheckpoint.java
, Integrated in Hadoop-Yarn-trunk #146 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/146/])
    HDFS-4128. 2NN gets stuck in inconsistent state if edit log replay fails in the middle (kihwal via daryn) (Revision 1452384)

     Result = SUCCESS
daryn : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1452384
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSConfigKeys.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CheckpointConf.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CheckpointFaultInjector.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/resources/hdfs-default.xml
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestCheckpoint.java
, Integrated in Hadoop-Hdfs-0.23-Build #544 (See [https://builds.apache.org/job/Hadoop-Hdfs-0.23-Build/544/])
    HDFS-4128. 2NN gets stuck in inconsistent state if edit log replay fails in the middle (kihwal via daryn) (Revision 1452391)

     Result = FAILURE
daryn : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1452391
Files : 
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSConfigKeys.java
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/main/resources/hdfs-default.xml
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestCheckpoint.java
, Integrated in Hadoop-Hdfs-trunk #1335 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1335/])
    HDFS-4128. 2NN gets stuck in inconsistent state if edit log replay fails in the middle (kihwal via daryn) (Revision 1452384)

     Result = SUCCESS
daryn : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1452384
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSConfigKeys.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CheckpointConf.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CheckpointFaultInjector.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/resources/hdfs-default.xml
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestCheckpoint.java
]