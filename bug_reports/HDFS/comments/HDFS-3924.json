[Patch changing the {{byte}} to an {{int}}, which should be sufficient for any realistic number of disks per machine. Also fixed a typo.

I didn't manually test with >127 storage locations, but I ran the existing BlockStorage tests (which passed), and the ids printed in the output looked sane., -1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12544765/hdfs-3924-1.patch
  against trunk revision .

    +1 @author.  The patch does not contain any @author tags.

    -1 tests included.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 eclipse:eclipse.  The patch built with eclipse:eclipse.

    +1 findbugs.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    -1 core tests.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.TestDatanodeBlockScanner

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/3178//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/3178//console

This message is automatically generated., {code}
@@ -234,8 +235,8 @@ class BlockStorageLocationUtil {
         }
         // Get the VolumeId by indexing into the list of VolumeIds
         // provided by the datanode
-        HdfsVolumeId id = new HdfsVolumeId(metaVolumeIds.get(volumeIndex)[0],
-            true);
+        int volumeId = ByteBuffer.wrap(metaVolumeIds.get(volumeIndex)).getInt();
+        HdfsVolumeId id = new HdfsVolumeId(volumeId, true);
         // Find out which index we are in the LocatedBlock's replicas
         LocatedBlock locBlock = extBlockToLocBlock.get(extBlock);
         DatanodeInfo[] dnInfos = locBlock.getLocations();
{code}
This change is a wire compatibility change; the old code puts 1 byte in the protobuf and the new code requires 4 bytes to decode (else {{.getInt}} throws BufferUnderflowException), unless I'm missing something.

Maybe we don't care about wire compatibility, but if so we should explicitly state that we don't care., bq. Maybe we don't care about wire compatibility, but if so we should explicitly state that we don't care.

We don't care in this case because this code has never been released., Hey Andrew, this does indeed increase the size of the valid range of unique volume identifiers by interpreting the bytes on the wire as ints instead of bytes, but to make this identifier truly opaque, I think we should not interpret the byte[] sent at all. Instead, HdfsVolumeId should store and compare the values in the byte array directly., Thanks for the review ATM. I changed it from an int to a byte[] on the client side.

I also nailed a camelCase mistake (VolumeId -> volumeId)., The latest patch looks pretty good to me. My only suggestion is to either get rid of HdfsVolumeId#toString entirely, or have it print out the Base64 encoding of the identifier. Returning the toString() of a byte[] isn't very helpful - it just uses the Object#toString() method., toString is now Base64'd., The latest patch looks good to me. +1 pending Jenkins., -1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12545051/hdfs-3924-2.patch
  against trunk revision .

    +1 @author.  The patch does not contain any @author tags.

    -1 tests included.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 eclipse:eclipse.  The patch built with eclipse:eclipse.

    -1 findbugs.  The patch appears to introduce 1 new Findbugs (version 1.3.9) warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    +1 core tests.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/3186//testReport/
Findbugs warnings: https://builds.apache.org/job/PreCommit-HDFS-Build/3186//artifact/trunk/patchprocess/newPatchFindbugsWarningshadoop-hdfs.html
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/3186//console

This message is automatically generated., -1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12545061/hdfs-3924-3.patch
  against trunk revision .

    +1 @author.  The patch does not contain any @author tags.

    -1 tests included.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 eclipse:eclipse.  The patch built with eclipse:eclipse.

    +1 findbugs.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    +1 core tests.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/3187//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/3187//console

This message is automatically generated., I've just committed this to trunk and branch-2. Thanks a lot for the contribution, Andrew., Integrated in Hadoop-Hdfs-trunk-Commit #2793 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk-Commit/2793/])
    HDFS-3924. Multi-byte id in HdfsVolumeId. Contributed by Andrew Wang. (Revision 1384602)

     Result = SUCCESS
atm : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1384602
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/fs/HdfsVolumeId.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/BlockStorageLocationUtil.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java
, Integrated in Hadoop-Common-trunk-Commit #2730 (See [https://builds.apache.org/job/Hadoop-Common-trunk-Commit/2730/])
    HDFS-3924. Multi-byte id in HdfsVolumeId. Contributed by Andrew Wang. (Revision 1384602)

     Result = SUCCESS
atm : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1384602
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/fs/HdfsVolumeId.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/BlockStorageLocationUtil.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java
, Integrated in Hadoop-Mapreduce-trunk-Commit #2754 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk-Commit/2754/])
    HDFS-3924. Multi-byte id in HdfsVolumeId. Contributed by Andrew Wang. (Revision 1384602)

     Result = FAILURE
atm : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1384602
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/fs/HdfsVolumeId.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/BlockStorageLocationUtil.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java
, Integrated in Hadoop-Hdfs-trunk #1165 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1165/])
    HDFS-3924. Multi-byte id in HdfsVolumeId. Contributed by Andrew Wang. (Revision 1384602)

     Result = FAILURE
atm : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1384602
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/fs/HdfsVolumeId.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/BlockStorageLocationUtil.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java
, Integrated in Hadoop-Mapreduce-trunk #1196 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1196/])
    HDFS-3924. Multi-byte id in HdfsVolumeId. Contributed by Andrew Wang. (Revision 1384602)

     Result = SUCCESS
atm : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1384602
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/fs/HdfsVolumeId.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/BlockStorageLocationUtil.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java
]