[For block placement differences, {{DFSNetworkTopology}} is new in Hadoop 3. It might be related. See HDFS-11419. [~vagarychen] might be able to tell whether it is related.

Missing Client ID is very strange as it has a call ID. Both come from the handler's thread local variable set by the RPC server. The client ID field  isn't the last field in the edit either. It is created when a RPC client is created and this is set in the connection context header. It is all internal and automatic. I don't know what happens when the connection is dropped before edit logging, while the call is still being processed. [~daryn], does server reset the client ID in this case?
, Hi all,

We are having the same issue after upgrading from 2.8.2 to 3.1.0, we have a cluster with one name node 3 datanodes and no journal node, that worked without issues during an entire year. The upgrade went fine but problem started after a system maintenance that restarted all nodes. Here are the main information on the log

2018-07-03 10:57:35,543 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream '/space/hadoop/hadoop_run/head_node/current/edits_0000000000023174228-0000000000023184599' 
to transaction ID 23174224 
2018-07-03 10:57:35,575 ERROR org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader: Encountered exception on operation AddOp [length=0, inodeId=6383051, path=/spark/.sparkStaging/application_1530536780991_0001/commons-compress-1.14.jar, replication=3, mtime=1530538999482, atime=1530538999482, blockSize=134217728, blocks=[], permissions=spark:hadoop:rw-r--r--, aclEntries=null, clientName=DFSClient_NONMAPREDUCE_291933719_1, clientMachine=10.1.19.65, overwrite=true, RpcClientId=, RpcCallId=269330502, storagePolicyId=0, erasureCodingPolicyId=0, opCode=OP_ADD, txid=23174233]
java.lang.IllegalArgumentException: Invalid clientId - length is 0 expected length 16
 at com.google.common.base.Preconditions.checkArgument(Preconditions.java:88)
 at org.apache.hadoop.ipc.RetryCache$CacheEntry.<init>(RetryCache.java:74)
 at org.apache.hadoop.ipc.RetryCache$CacheEntry.<init>(RetryCache.java:86)
 at org.apache.hadoop.ipc.RetryCache$CacheEntryWithPayload.<init>(RetryCache.java:163)
 at org.apache.hadoop.ipc.RetryCache.addCacheEntryWithPayload(RetryCache.java:322)
 at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.addCacheEntryWithPayload(FSNamesystem.java:960)
 at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.applyEditLogOp(FSEditLogLoader.java:397)
 at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadEditRecords(FSEditLogLoader.java:249)
 at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadFSEdits(FSEditLogLoader.java:158)
 at org.apache.hadoop.hdfs.server.namenode.FSImage.loadEdits(FSImage.java:888)
 at org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:745)
 at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:323)
 at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:1086)
 at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:714)
 at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:669)
 at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:731)
 at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:968)
 at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:947)
 at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1674)
 at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1741)
2018-07-03 10:57:35,577 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Encountered exception loading fsimage
java.io.IOException: java.lang.IllegalStateException: Cannot skip to less than the current value (=6383051), where newValue=6383050
 at org.apache.hadoop.hdfs.server.namenode.FSDirectory.resetLastInodeId(FSDirectory.java:1945)
 at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadEditRecords(FSEditLogLoader.java:298)
 at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadFSEdits(FSEditLogLoader.java:158)
 at org.apache.hadoop.hdfs.server.namenode.FSImage.loadEdits(FSImage.java:888)
 at org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:745)
 at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:323)
 at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:1086)
 at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:714)
 at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:669)
 at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:731)
 at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:968)
 at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:947)
 at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1674)
 at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1741)
Caused by: java.lang.IllegalStateException: Cannot skip to less than the current value (=6383051), where newValue=6383050
 at org.apache.hadoop.util.SequentialNumber.skipTo(SequentialNumber.java:58)
 at org.apache.hadoop.hdfs.server.namenode.FSDirectory.resetLastInodeId(FSDirectory.java:1943)
 ... 13 more, Hi [~_ph], as I see you reported two problems when upgrading the cluster. Looks like they are unrelated. Could you file a new JIRA for tracking Rack Awareness problem you found? And let this JIRA focus on SBN tailing edits error., The "restart fails after upgrade" issue is being addressed in HDFS-13596. Workaround is to do "saveNamespace" against the active NN after an upgrade from 2.x to 3.x. The Standby NN will need to be re-bootstrapped., Hi [~linyiqun], I create additional issue about _NotEnoughReplicasException_ - HDFS-13718.]