[This patch fixes the memory leaks mentioned in the description and some additional ones in 

hdfsGetCapacity
hdfsGetUsed
hdfsConnectAsUser
hdfsConnectAsUserNewInstance, patch.HADOOP-6034 is for trunk
patch.HADOOP-6034.0.18 is for hadoop-0.18 (just has the memory leaks mentioned in description), Cool catch! +1., -1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12410612/patch.HADOOP-6034.0.18
  against trunk revision 785065.

    +1 @author.  The patch does not contain any @author tags.

    -1 tests included.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no tests are needed for this patch.

    -1 patch.  The patch command could not apply the patch.

Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-vesta.apache.org/512/console

This message is automatically generated., Reattaching patch for trunk, hopefully allowing hudson to pick up the correct patch, Resubmitting patch., libhdfs was accidentally moved to the mapreduce project..  See MAPREDUCE-665., Updated patch for trunk, Now, with libhdfs back in HDFS (finally!) there is no reason not to apply this patch.

Most of the memory leaks are on the failure path, but there are a couple which happen on the success path as well (hdfsExists, connecting with user id).

Therefore, I will mark it as blocker.

BTW, not being a JNI expert, I am not confident that all memory leaks are fixed. There might be more., Patch looks good. Did you run the libhdfs test?   

fyi filed HDFS-773 for testing for additional memory leaks (eg run the code under valgrind)., Thanks for looking at the patch.

Sorry, I do not have the setup to run libhdfs test.

We are running the equivalent patch on hadoop-0.20.1 for months now in our applications, and we use libhdfs extensively but, of course, this does not guarantee a comprehensive test., If you've got a build you should be able to run the libhdfs test with:

{code}
ant compile -Dcompile.c++=true -Dlibhdfs=true test-c++-libhdfs
{code}, Thanks, that was simple!
Yes, libhdfs test passed in trunk with patch HADOOP-6034.patch., Excellent. +1, Comments:
# hdfs.c - In hdfsConnectAsUserNewInstance90 method jAttrString is not released before subsequent returns. Is this fine?
# hdfs.c - In hdfsOpenFile(), {{jpath, jStrBufferSize, jStrReplication, jStrBlockSize}} is not release before subsequent return (if (!file) check)
# hdfs.c - In hdfsGetHosts() does {{blockHosts}} leak in subsequent return NULL?

On a side note, the code seems to be prone to introducing leaks. Seems to me we should have some kind of stack variable that tracks the objects to be deleted and cleans them up when it goes out of scope.
, -1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12426579/HADOOP-6034.patch
  against trunk revision 899747.

    +1 @author.  The patch does not contain any @author tags.

    -1 tests included.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    -1 core tests.  The patch failed core unit tests.

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h5.grid.sp2.yahoo.net/191/testReport/
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h5.grid.sp2.yahoo.net/191/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h5.grid.sp2.yahoo.net/191/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h5.grid.sp2.yahoo.net/191/console

This message is automatically generated., &gt;   1.  hdfs.c - In hdfsConnectAsUserNewInstance90 method jAttrString is not released before subsequent returns. Is this fine?
You are entirely correct that it should be released, similar to jAttrString in hdfsConnectAsUser

&gt;   2. hdfs.c - In hdfsOpenFile(), jpath, jStrBufferSize, jStrReplication, jStrBlockSize is not release before subsequent return (if (!file) check)
The original author must have thought that if you cannot malloc a few bytes you are hosed anyhow.

&gt;   3. hdfs.c - In hdfsGetHosts() does blockHosts leak in subsequent return NULL?
It is the responsibility of the client to call hdfsFreeHosts, similar to calling hdfsFreeFileInfo after a call to hdfsGetPathInfo.


&gt;   On a side note, the code seems to be prone to introducing leaks. Seems to me we should have some kind of stack variable that tracks the objects to be deleted and cleans them up when it goes out of scope.
One giant step forward would be to replace the libhfds library (which uses JNI) with a socket interface allowing C++ to directly access hdfs servers (would increase performance and reduce memory footprint) :), Looks like the patch just needs to be updated to address points 1 and 2 right? By the way it looks like all but four of these cases has been covered by patches Brian Bockelman has posted to various hdfs jiras. , If the new patch is uploaded, I will commit this change to trunk, branch 0.21 and 0.20 as well., Don't see the new patch. Christian's response was on Jan 10 and the latest patch is from Dec 1. , I will upload a new patch shortly (btw, my last comment was on Jan. 16), New patch fixing some additional memory leaks., The new patch passed libhdfs test., +1 for the patch., Integrated in Hadoop-Hdfs-trunk-Commit #174 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-Hdfs-trunk-Commit/174/])
    . Fix memory leaks in libhdfs. Contributed by Christian Kunz.
, Committed this patch to trunk. Thank you Christian.

, Since this is a 0.21 blocker, reopen for committing this to 0.21., I have committed this to MAPREDUCE-0.21, which contains libhdfs., Integrated in Hadoop-Hdfs-trunk #207 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-Hdfs-trunk/207/])
    . Fix memory leaks in libhdfs. Contributed by Christian Kunz.
, Integrated in Hdfs-Patch-h2.grid.sp2.yahoo.net #101 (See [http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h2.grid.sp2.yahoo.net/101/])
    . Fix memory leaks in libhdfs. Contributed by Christian Kunz.
, Integrated in Hdfs-Patch-h5.grid.sp2.yahoo.net #205 (See [http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h5.grid.sp2.yahoo.net/205/])
    , Attaching release 20 version of the patch., +1 for hdfs-464.rel20.patch except the following section should be deleted (this is when USE_UUGI is not defined, which does not happen)

{code}
@@ -276,12 +281,14 @@ hdfsFS hdfsConnectAsUser(const char* host, tPort port, const char *user , const
           destroyLocalReference(env, jGroups);
         }
         destroyLocalReference(env, jUgi);
+        destroyLocalReference(env, jAttrString);
         return NULL;
       }
       
       destroyLocalReference(env, jUserString);
       destroyLocalReference(env, jGroups);
       destroyLocalReference(env, jUgi);
+      destroyLocalReference(env, jAttrString);
     }
 #endif      
     //Check what type of FileSystem the caller wants...
{code}, Attached new patch file incorporating comments from Christian..., +1 for hdfs-464.1.rel20.patch
Thanks for the 0.20 patch, Suresh!]