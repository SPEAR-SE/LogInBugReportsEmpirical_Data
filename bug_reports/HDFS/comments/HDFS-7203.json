[The patch includes a unit test case that reproduces the issue. The fix is to use a fresh file status AFTER calling namenode append() method.

When the meta file does not contain all required checksum data, DN gets an exception like this:

{panel}
java.io.EOFException
        at java.io.DataInputStream.readFully(DataInputStream.java:197)
        at org.apache.hadoop.hdfs.server.datanode.BlockSender.readChecksum(BlockSender.java:609)
...
{panel}, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12673416/HDFS-7203.patch
  against trunk revision 9196db9.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The test build failed in hadoop-hdfs-project/hadoop-hdfs 

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/8344//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/8344//console

This message is automatically generated., Good finding [~kihwal].
Your test reproduces the issue sometime as its a race between concurrent writes.

+1, Patch looks good to me.

I feel we can avoid two RPCs to namenode for append if we can combine LastBlock and HdfsFileStatus
I will file a separate Jira for this improvement., Filed HDFS-7210 for the improvement, Thanks for the review, Vinay., I've committed this to branch-2, branch-2.6 and trunk., FAILURE: Integrated in Hadoop-trunk-Commit #6214 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/6214/])
HDFS-7203. Concurrent appending to the same file can cause data (kihwal: rev 853cb704edf54207313c0e70c9c375212d288b60)
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSClient.java
* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileAppend3.java
* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
, SUCCESS: Integrated in Hadoop-Yarn-trunk #706 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/706/])
HDFS-7203. Concurrent appending to the same file can cause data (kihwal: rev 853cb704edf54207313c0e70c9c375212d288b60)
* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSClient.java
* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileAppend3.java
, FAILURE: Integrated in Hadoop-Hdfs-trunk #1896 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1896/])
HDFS-7203. Concurrent appending to the same file can cause data (kihwal: rev 853cb704edf54207313c0e70c9c375212d288b60)
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSClient.java
* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileAppend3.java
, FAILURE: Integrated in Hadoop-Mapreduce-trunk #1921 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1921/])
HDFS-7203. Concurrent appending to the same file can cause data (kihwal: rev 853cb704edf54207313c0e70c9c375212d288b60)
* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileAppend3.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSClient.java
* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
]