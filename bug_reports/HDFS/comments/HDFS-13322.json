[As I have checked, the tests for fuse are not running, and they are not configured for neither in CMake, nor to run the tests in TestFuseDFS class. I have attached a script that shows the behaviour.

The testHDFS-13322.sh requires a Hadoop cluster to mount, the fuse package installed, two kerberos principals, and the keytab file for those principals to run.

The patch fixes the behaviour. I am attaching an example output of the test from before and from after the patch., Added patch v2 with the forgotten API doc changes added., | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 37s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 26m 36s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 15m 19s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  7m 44s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 59m 59s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  8m 14s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 16m  8s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} cc {color} | {color:green} 16m  8s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 16m  8s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  8m  8s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 11m 36s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 24m 38s{color} | {color:green} hadoop-hdfs-native-client in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 24s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}130m 50s{color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:abb62dd |
| JIRA Issue | HDFS-13322 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12922350/HDFS-13322.002.patch |
| Optional Tests |  asflicense  compile  cc  mvnsite  javac  unit  |
| uname | Linux 3019cd8416f0 3.13.0-143-generic #192-Ubuntu SMP Tue Feb 27 10:45:36 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 696a4be |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_162 |
|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/24146/testReport/ |
| Max. process+thread count | 301 (vs. ulimit of 10000) |
| modules | C: hadoop-hdfs-project/hadoop-hdfs-native-client U: hadoop-hdfs-project/hadoop-hdfs-native-client |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/24146/console |
| Powered by | Apache Yetus 0.8.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

, Adding patch v3, after review myself I have realized that we do need to check for the Environment only if the authentication method is Kerberos authentication, otherwise the connect should not need to deal with any ticket cache path. Also it is not worth to check the kpath in a non kerberized environment., | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 27s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 28m 16s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 18m  5s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  9m 24s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 67m 12s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 10m 12s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 18m 28s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} cc {color} | {color:green} 18m 28s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 18m 28s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  9m 36s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 13m 21s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 28m 50s{color} | {color:green} hadoop-hdfs-native-client in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 25s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}150m 13s{color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:abb62dd |
| JIRA Issue | HDFS-13322 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12922563/HDFS-13322.003.patch |
| Optional Tests |  asflicense  compile  cc  mvnsite  javac  unit  |
| uname | Linux 26089ba405a5 3.13.0-143-generic #192-Ubuntu SMP Tue Feb 27 10:45:36 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 69aac69 |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_162 |
|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/24157/testReport/ |
| Max. process+thread count | 338 (vs. ulimit of 10000) |
| modules | C: hadoop-hdfs-project/hadoop-hdfs-native-client U: hadoop-hdfs-project/hadoop-hdfs-native-client |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/24157/console |
| Powered by | Apache Yetus 0.8.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

, Thank you for the patch [~pifta]. This code is new to me, so shout if I misread somthing.  Left some inline comments here:

{noformat}
 static int hdfsConnCompare(const struct hdfsConn *a, const struct hdfsConn *b)
 {
-  return strcmp(a->usrname, b->usrname);
+  int rc = strcmp(a->usrname, b->usrname);
+  if (rc) return rc;
// AF: here we know the usernames are equal since rc == 0 
+  return gHdfsAuthConf == AUTH_CONF_KERBEROS && strcmp(a->kpath, b->kpath);
// AF: If auth is not kerb, we return 0 (equal), ok
// AF: if auth is kerb, we return 0 if kpath's are equal (ok), or 1 if they are not.
 }
 {noformat}

This is the comparator for a RB tree of hdfsConn objects by username, so ordering needs to be consistent. Looks like kpath is immutable once the conn is created, and we only have a few cache files in use, so this should be ok.

{noformat}
@@ -542,8 +546,13 @@ static int fuseConnect(const char *usrname, struct fuse_context *ctx,
   int ret;
   struct hdfsConn* conn;
 
+  char kpath[PATH_MAX] = { 0 };
+  if (gHdfsAuthConf == AUTH_CONF_KERBEROS) {
+    findKerbTicketCachePath(ctx, kpath, sizeof(kpath));
+  }
{noformat}

It looks like this is fast-path code (called on most fuse ops), and this change would add a good amount of overhead. I'd expect a performance regression.

I'm wondering if we need to cache the path in the KRB5CCNAME by pid or something.  Any other ideas?  Parsing /proc entries on every FS operation seems bad.

, Hello [~fabbri],

thank you for the review, and the really constructive questions, please find my answers below.

I agree with the first part, maybe one thing, the second string comparison can yield to zero if the two strings are equal, otherwise to any number not just 1, so the order between users will be decided based on the username first, then based on the kerberos ticket cache file if the authentication method is kerberos that was the aim of this change.

 

On the second part, performance is a concern of mine as well, but I did not find a better way, as we are caching connections in the RB tree, and for this to work we need to differentiate between connections with different ticket cache path. The method is called on every file system access, and we may gain performance if we cache the ticket cache path for a pid in cases where there is an application that is using the fuse mount often and remains running. In case where the user runs file system commands from a shell for example or from a shell script, every command will have its own pid I believe (though I have not tested) so this use case on the other hand can add on memory usage, and in edge cases can also cause slowness. And also in this case we would need to take care of the cleanup that introduce complexity. I haven't done any benchmarks on this, but I think I can run some over the weekend, or early next week, let's see how performance changes in different scenarios.

I am planning to run the following tests, let me know if you see it sufficient to test around the perf difference:
- test 10k access of a file via cat command on a random file with and without the patch
- test 10k access for the same file using a small java program that runs with the same pid during the test with and without the patch

Though I do not see anything besides the increased complexity with the pid<->krb_ticket_cache mapping being cached, so that might be as well a good approach here. I can think of the following scenarios:
- there is a scheduler, that schedules different processes to run in different environments (different KRB5CCNAME) but with the same user id, then pid can be a good differentiation and we can spare the lookup for the path
- there is a scheduler that schedules different tasks in threads, in this case threads are inheriting the environment, and a change in the ticket cache path will not be detected if we cache it by pid, but this scenario will not fulfill the need of different principals used for different tasks only if we introduce a different inheritance of the security context of the caller which I think we don't want to do.

Do you see any other scenarios? As if you don't, we can try to measure and see the perf difference in fuse-dfs with KRB5CCNAME value cached for a pid, and evicted the same way as connections are getting expired from the cache. What do you think about this approach? I do not really have further ideas at the moment, though while I am working on the testing, I will try to figure out other feasible ways., Hello [~fabbri],

sorry for the delay here, I was not able to get to the end of the measurement so far, I had some other things, and some problems with the environment setup over the weekend. I am mostly offline during this week, if you have any time, and have the mood to run the test, that would be great, but otherwise I am also glad to have just your patience on this one until about mid next week., Hello [~fabbri],

finally I was able to find some time to setup the environment for testing, and prepare and run the tests.

I am attaching the test codes that I have used, and also I am attaching the measurements from 10 run from both tests on the old and the new fuse code.

The test was run on a single linux vm against a CDH5.14 cluster with 3 DataNodes. The randomfile I used was a 1MB and a 1KB file created with /dev/urandom as the source, and a 1 byte file that contained the letter "a"
||test version||1MB file read * 10k avg.||1KB file read * 10k avg.||1B file read * 10k avg.||10k different 1KB file||
|Original version with catter.sh|174.064 sec|78.725 sec|79.195 sec|90.683 sec|
|Patched version with catter.sh|180.675 sec|81.028 sec|81.187 sec|92.859 sec|
|*Performance degradation*|*3.8%*|*2.9%*|*2.5%* |*2.4%* |
|Original version with TestFuse.java|137.159 sec|65.982 sec|65.713 sec|67.411 sec|
|Patched version with TestFuse.java|139.095 sec |68.457 sec |68.919 sec|69.101 sec|
|*Performance degradation*|*1.4%*| *3.8%*|*4.9%*|*2.5%* |

After running these test, I thought I check if the page cache has any effect, and tried with 10k 10KB file generated from /dev/urandom as well, it seems that under a certain size network traffic of getting the data is not really a factor, so I got suspicious hence I ran a test with different files as well as the last step.

As it seems from the result the performance degradation due to the change in the proposed patch is under 5% in all of the scenarios I have tested, and mostly in the 2-4% range.

Let me know if you have any observation on the provided code and perf test, also let me know if these values seem to be acceptable., Thanks for the thorough performance testing, and for walking me through how to test this.  I'm +1 and will commit this in an hour or so.  Thanks for including your test scripts as well.

Some possible followup work (we can create new Jira if anyone wants):
 * There doesn't seem to be any unit tests that exercise this kerberos/fuse stuff.  Not sure where to start but would be an improvement over manual testing.
 * We could add a config flag that disables the new kerb ticket cache lookup (parsing /proc).  For now I'm not sure this is used in high-performance scenarios that would justify yet another config flag., Committed to trunk. Thanks again for the excellent work on this issue [~pifta], SUCCESS: Integrated in Jenkins build Hadoop-trunk-Commit #14681 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/14681/])
HDFS-13322 fuse dfs - uid persists when switching between ticket caches. (fabbri: rev 40f9b0c5c13f40921b6976589543a04efa489f93)
* (edit) hadoop-hdfs-project/hadoop-hdfs-native-client/src/main/native/fuse-dfs/fuse_connect.c
, Thanks for working on this [~pifta], [~fabbri]!]