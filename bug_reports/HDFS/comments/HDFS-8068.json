[The patch adds a check in {{NameNodeProxies#createNonHAProxy()}}. If the address is unresolved (i.e. cannot be resolved), it throws. This makes the rpc proxy creation fail for both HA and non-HA case. In HA, failover proxy providers get this exception and thow a {{RunTimeException}} in {{getProxy()}}, which is called by {{RetryInvocationHandler}} in its ctor or {{invoke()}} during failover.  If {{ConfiguredFailoverProxyProvider}} is used and the initial proxy object was okay, the second {{getProxy()}} call from {{invoke()}} will throw. In this case, the particular call will fail instead of the proxy creation. The (ha)proxy in the {{DFSClient}} instance is still intact, so creation of underlying non-HA proxy will be retried in the next call., {{FailoverOnNetworkExceptionRetry#shouldRetry()}} thinks {{UnknownHostException}} is retriable, but it's not in the current form. If we are to support transparent retry and recovery, there has to be a way to tell the failover proxy provider to abandon underlying broken proxy and recreate on reception of  {{UnknownHostException}}. This can be a bit ugly.  An alternative way is to have the failover proxy provider check the address of the existing proxy object in {{getProxy()}} and recreate if it is bad. The newly created one may still be broken causing calls to throw {{UnklnowHostException}}, but if DNS recovers, it will eventually succeed after some number of retries(recreations). But it has a drawback of having to be fixed in the pluggable failover proxy provider level.  Is namenode HA also supposed to cover infrastructure outages? If not, the v1 patch should be sufficient., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12723430/HDFS-8068.v1.patch
  against trunk revision 28bebc8.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.web.TestWebHdfsFileSystemContract

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/10183//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/10183//console

This message is automatically generated., HADOOP-9657 covers better reporting of the unbound address problem; this would be a good place to combine them. Unbound/0.0.0.0 addresses are usually a sign of config problems, either on client or DNS, for that reason, -1 to the current patch; all it throws is an IOE. 

# It must be an {{UnknownHostException}}
# the text should include a link to http://wiki.apache.org/hadoop/UnknownHost
# Text should also say more than "trying to create proxy", which means things to developers, it must be something for ops & individuals. Something like "Address of namenode is not defined, check value of <property>;  see http://wiki.apache.org/hadoop/UnknownHost"
# Test can be updated to look for the new exception
, Thanks for the review, [~stevel@apache.org]

The updated patch throws an {{UnknownHostException}} and shows the following log message:
{panel}
2015-04-07 10:59:45,068 ERROR hdfs.NameNodeProxies (NameNodeProxies.java:createNonHAProxy(314)) - The specified namenode name could not be resolved: this.doesnt.exist. See http://wiki.apache.org/hadoop/UnknownHost for possible causes.
{panel}
, getting better
# could you include the entire error text in the exception that is thrown, as well as the logs. It's most likely to get seen then.
# the test can be changed to catch a {{UnknownHostException}}, removing the need to look inside its string value. this makes for a more robust test, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12723657/HDFS-8068.v2.patch
  against trunk revision 0b5d7d2.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.web.TestWebHdfsFileSystemContract

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/10193//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/10193//console

This message is automatically generated., bq.    could you include the entire error text in the exception that is thrown, as well as the logs. It's most likely to get seen then.
It is possible to pass any string to {{UnknownHostException}}, but it is meant for the host name. If you insist, I will make it pass the entire error string.

bq.    the test can be changed to catch a UnknownHostException, removing the need to look inside its string value. this makes for a more robust test
The failover proxy provider catches it and throws a RunTimeException. I think this is to bypass the checks {{shouldRetry()}} in retry policies and make the exception bubble up., \\
\\
| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:red}-1{color} | patch |   0m  0s | The patch command could not apply the patch during dryrun. |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12723657/HDFS-8068.v2.patch |
| Optional Tests | javadoc javac unit findbugs checkstyle |
| git revision | trunk / aa07dea |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/11508/console |


This message was automatically generated., Recently I ran across a similar situation except it involved YarnClient trying to setup the RM proxy rather than DFSClient trying to setup the NN proxy.  If possible, I'd much rather try to fix this in the RPC layer so we don't require every subsystem that wants to setup proxies to handle this separately.  Filed HADOOP-12125 to track that effort., | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m  0s{color} | {color:blue} Docker mode activated. {color} |
| {color:red}-1{color} | {color:red} patch {color} | {color:red}  0m  4s{color} | {color:red} HDFS-8068 does not apply to trunk. Rebase required? Wrong Branch? See https://wiki.apache.org/hadoop/HowToContribute for help. {color} |
\\
\\
|| Subsystem || Report/Notes ||
| JIRA Issue | HDFS-8068 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12723657/HDFS-8068.v2.patch |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/18077/console |
| Powered by | Apache Yetus 0.5.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

, | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m  0s{color} | {color:blue} Docker mode activated. {color} |
| {color:red}-1{color} | {color:red} patch {color} | {color:red}  0m  5s{color} | {color:red} HDFS-8068 does not apply to trunk. Rebase required? Wrong Branch? See https://wiki.apache.org/hadoop/HowToContribute for help. {color} |
\\
\\
|| Subsystem || Report/Notes ||
| JIRA Issue | HDFS-8068 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12723657/HDFS-8068.v2.patch |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/22450/console |
| Powered by | Apache Yetus 0.7.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

]