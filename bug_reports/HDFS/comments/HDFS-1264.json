[The first OOME happened with this trace, which apparently borked the checksum buffer in some interesting way:

Caused by: java.lang.OutOfMemoryError: Java heap space
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$Packet.<init>(DFSClient.java:2204)
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.writeChunk(DFSClient.java:3085)
        at org.apache.hadoop.fs.FSOutputSummer.writeChecksumChunk(FSOutputSummer.java:150)
        at org.apache.hadoop.fs.FSOutputSummer.flushBuffer(FSOutputSummer.java:132)
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.sync(DFSClient.java:3168)
        at org.apache.hadoop.fs.FSDataOutputStream.sync(FSDataOutputStream.java:97)

Will upload the logs for this block as well., here are the DN and NN logs for the block. Timestamps are NTP-synced, One of the issues here is that it's the *last* node in the pipeline that verifies the checksum. So let's say I am writing to pipeline A,B,C. I first write a good packet (512) bytes, then I write a packet with bad checksum. This gets written to disk on A and B without verifying checksum. C verifies the checksum, gets the error, and forwards it back up the chain. The client then drops C from the pipeline and initiates recovery. The recovery process gets the replica info on A and B, both of which have length 1024 at this point. So it recovers the block to a length that includes the bad checksum chunk, when we reopen the file, we have issues., It turns out this is very similar to HDFS-679. I backported the test case from 679 and sure enough it fails.]