[GitHub user eric-maynard opened a pull request:

    https://github.com/apache/hadoop/pull/375

    HDFS-13513. Avoid edge case where BUFFER_SIZE is 0

    As reported in HDFS-13513, there is a potential bug in the following code block:
    
    byte[] data = new byte[BUFFER_SIZE];
    long val= 0;
    while (val >= 0) {
      val = in.read(data);
    }
    where BUFFER_SIZE is 0
    I believe switching to a simple do/while can fix this.

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/eric-maynard/hadoop HDFS-13513

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/hadoop/pull/375.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #375
    
----
commit 762db5bde1c69b54458bea8eb69aa544636c709a
Author: Eric Maynard <emaynard@...>
Date:   2018-04-30T20:40:31Z

    HDFS-13513. Avoid edge case where BUFFER_SIZE is 0
    
    As reported in HDFS-13513, there is a potential bug in the following code block:
    
    byte[] data = new byte[BUFFER_SIZE];
    long val= 0;
    while (val >= 0) {
      val = in.read(data);
    }
    where BUFFER_SIZE is 0
    I believe switching to a simple do/while can fix this.

----
, Github user functicons commented on a diff in the pull request:

    https://github.com/apache/hadoop/pull/375#discussion_r185160425
  
    --- Diff: hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/BenchmarkThroughput.java ---
    @@ -134,9 +134,9 @@ private void readFile(FileSystem fs,
         InputStream in = fs.open(f);
         byte[] data = new byte[BUFFER_SIZE];
         long val = 0;
    -    while (val >= 0) {
    +    do {
           val = in.read(data);
    -    }
    +    } while (val > 0);
    --- End diff --
    
    I don't think this is fix is correct. According to the [InputStream.read](762db5bde1c69b54458bea8eb69aa544636c709a) doc, "the total number of bytes read into the buffer, or -1 if there is no more data because the end of the stream has been reached". It is possible that BUFFER_SIZE > 0 and val == 0, in this case, it should continue to read, otherwise it will miss the data. Instead, I think we should check BUFFER_SIZE explicitly.
]