[{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12608253/HDFS-5355.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/5180//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/5180//console

This message is automatically generated., Could anybody review this change and give me any advices? Thanks. :-), Thanks for filing JIRA and working on it
Make sense to me for making this same as flush metrics. I think, we need not expose sync metrics for 2 i.e checksum file and blockfile. We can add them into one as you proposed. I am not sure if there is a real reason to do so. 
I think, BlockReceiver#close also has similar issue?

{code}
  datanode.metrics.incrFsyncCount();
+        datanode.metrics.addFsyncNanos(fsyncTotalNanos);
{code}
Please follow hadoop formater. Indentation should be 2 spaces.

.


, Hey folks, I think this is a case where the comment is wrong but the code is basically right. Although poorly named and documented, right now we're using these metrics to track two different things: the # of "logical" syncs e.g. via hsync, and the # of actual fsyncs via {{#force}}. Changing this would be a little incompatible., In fact, I think we should change
{code:java}
((FileOutputStream)cout).getChannel().force(true);
{code}
to
{code:java}
((FileOutputStream)cout).getChannel().force(false);
{code}

Form the JavaDoc, it mentions that:
{quote}
The metaData parameter can be used to limit the number of I/O operations that this method is required to perform. Passing false for this parameter indicates that only updates to the file's content need be written to storage; passing true indicates that updates to both the file's content and metadata must be written, which generally requires at least one more I/O operation.
{quote}

I am if all the write operations are override. If it is so, set force(false) could reduce unnecessary IO. But if all the write operations are append, set force(true) couldn't bring any performance improvements., [~andrewwakeling] The metrics of hflush and hsync looks inconsistent.... I think if we don't fix the metrics of hsync, we should update the metrics of hflush. When the datanode receive a packet, the hsync metrics add twice while the hflush metrics add one seems unreasonable., Moving bugs out of previously closed releases into the next minor release 2.8.0.]