[Hi [~jojochuang],

Thanks for reporting the issue and finding the cause. It sounds to me a simple supportability fix would to make the message clear about why the NPE (exceeding the max num of file within a directory),  and state that the corresponding config param can be increased to make it pass.

Thanks.


, Do you know how it got into this state?  If the serving namenode had the same config, this op should have failed and wouldn't have logged in the first place. Do you suspect a bug in enforcement similar to HDFS-6099?, Hi Kihwal, thanks for the comment.
The SbNN crashed when it started and loaded edits. There was a point in time when {{dfs.namenode.fs-limits.max-directory-items}} was increased, which explains why the number of items exceeds 1048576 by a lot, but maybe it was only changed in ANN but not SbNN. Or maybe it was increased and then decreased.

I saw tremendous amount of rename operations before the {{MaxDirectoryItemsExceededException}}, but the version the cluster is running has the HDFS-6099 fix.

At this point it looks more like an operational error, although I think the NPE should be improved. I don't know if NameNodes should terminate when it sees max directory items is violated, but at least it should terminate more gracefully., Attach v01 patch. Changed the log level from debug to warn. Whenever this exception is thrown in FSDirWriteFileOp#addFileForEditLog, something really bad is happening, and NameNode will eventually abort, so it makes sense to me to log it at WARN. Additionally, add a hint to the log the property that can be used to workaround the error., I just hit the submit patch button., | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 19s{color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  7m 16s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 47s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 25s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 54s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 13s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 56s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m  1s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m  3s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m  0s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  1m  0s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 27s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  5s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 10s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 59s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 57s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 89m  0s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 21s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}110m 21s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.hdfs.server.namenode.ha.TestBootstrapStandby |
|   | hadoop.hdfs.security.TestDelegationTokenForProxyUser |
|   | hadoop.hdfs.TestFileCorruption |
| Timed out junit tests | org.apache.hadoop.hdfs.TestLeaseRecovery2 |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:9560f25 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12823767/HDFS-10729.001.patch |
| JIRA Issue | HDFS-10729 |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux b09705f97c13 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / ffe1fff |
| Default Java | 1.8.0_101 |
| findbugs | v3.0.0 |
| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/16439/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/16439/testReport/ |
| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/16439/console |
| Powered by | Apache Yetus 0.4.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

, All failed tests passed locally. [~kihwal] would you like to take a look again? Thanks, They pass for me too.
{noformat}
-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running org.apache.hadoop.hdfs.server.namenode.ha.TestBootstrapStandby
Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 31.175 sec - in org.apache.hadoop.hdfs.server.namenode.ha.TestBootstrapStandby
Running org.apache.hadoop.hdfs.TestLeaseRecovery2
Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 84.721 sec - in org.apache.hadoop.hdfs.TestLeaseRecovery2
Running org.apache.hadoop.hdfs.TestFileCorruption
Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 13.311 sec - in org.apache.hadoop.hdfs.TestFileCorruption
Running org.apache.hadoop.hdfs.security.TestDelegationTokenForProxyUser
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.407 sec - in org.apache.hadoop.hdfs.security.TestDelegationTokenForProxyUser

Results :

Tests run: 19, Failures: 0, Errors: 0, Skipped: 0
{noformat}, +1 the patch looks good., [~jojochuang], thanks for the patch. I've committed this to trunk, branch-2 and branch-2.8., SUCCESS: Integrated in Jenkins build Hadoop-trunk-Commit #10379 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/10379/])
HDFS-10729. Improve log message for edit loading failures caused by FS (kihwal: rev 01721dd88ee532d20eda841254437da4dfd69db5)
* (edit) hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirWriteFileOp.java
, Thanks [~yzhangal] for the suggestion of improving log message and thanks [~kihwal] for reviewing and committing the patch!]