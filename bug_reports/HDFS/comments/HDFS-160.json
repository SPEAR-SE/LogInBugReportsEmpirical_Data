[what stack trace does a kill -QUIT on the namenode show up?, just replaced  hadoop-env.sh with correct one. i wasn't using openjdk but gcj.
when using openjdk hadoop dies after a couple of seconds, quietly., I get nothing.
This is what I did:
{noformat}
[fabiand@power search]$ rm logs/*
[fabiand@power search]$ bin/hadoop namenode & sleep 180 ; kill -QUIT $!
[1] 1861
[fabiand@power search]$ cat logs/*
2008-08-04 19:28:52,319 INFO  util.Credential - Checking Resource aliases
2008-08-04 19:28:52,499 INFO  http.HttpServer - Version Jetty/5.1.4
2008-08-04 19:28:52,509 INFO  util.Container - Started HttpContext[/logs,/logs]
2008-08-04 19:28:55,903 INFO  util.Container - Started org.mortbay.jetty.servlet.WebApplicationHandler@491f4f80
2008-08-04 19:28:56,222 INFO  util.Container - Started WebApplicationContext[/,/]
2008-08-04 19:28:56,223 INFO  util.Container - Started HttpContext[/static,/static]
2008-08-04 19:28:56,226 INFO  http.SocketListener - Started SocketListener on 0.0.0.0:50070
2008-08-04 19:28:56,226 INFO  util.Container - Started org.mortbay.jetty.Server@49623b00
[1]+  Verlassen               bin/hadoop namenode
[fabiand@power search]$ 
{noformat}, I don't know about a different way on debuging this, so I tried strace.
It hangs at "getdents64(3, ..." all the 180seconds.

{noformat}
[fabiand@power search]$ rm logs/* ; strace bin/hadoop namenode & sleep 180 ; kill -QUIT $!
[1] 1907
...
open("/home/fabiand/work/nutch/search/bin/../", O_RDONLY|O_NONBLOCK|O_LARGEFILE|O_DIRECTORY|0x80000) = 3
fstat64(3, {st_mode=S_IFDIR|0755, st_size=4096, ...}) = 3
fcntl64(3, F_GETFD)                     = 0x3 (flags FD_CLOEXEC|0x2)
getdents64(3, 
[fabiand@power search]$
{noformat}, jdb session of a running namenode, which receives a kill -QUIT, HPROF data.
hadoop dies automagically after a while.
It seems as if the problem is related to some socket/ipc/rpc things., The last stack trace shows that main() is waiting for a response from the server about filesystem versions; if it quits after this then it may be that the versions of the different processes are inconsistent. Nothing else looks busy

        at java.lang.Object.wait(Native Method)
        - waiting on <0x56d716d8> (a org.apache.hadoop.ipc.Client$Call)
        at org.apache.hadoop.ipc.Client.call(Client.java:465)
        - locked <0x56d716d8> (a org.apache.hadoop.ipc.Client$Call)
        at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:163)
        at org.apache.hadoop.dfs.$Proxy0.getProtocolVersion(Unknown Source)
        at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:247)
        at org.apache.hadoop.dfs.DFSClient.<init>(DFSClient.java:105)
        at org.apache.hadoop.dfs.DistributedFileSystem$RawDistributedFileSystem.initialize(DistributedFileSystem.java:67)
        at org.apache.hadoop.fs.FilterFileSystem.initialize(FilterFileSystem.java:57)
        at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:160)
        - locked <0x88f65668> (a java.lang.Class for org.apache.hadoop.fs.FileSystem)
        at org.apache.hadoop.fs.FileSystem.getNamed(FileSystem.java:119)
        at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:91)
        at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:144)
        - locked <0x88f65668> (a java.lang.Class for org.apache.hadoop.fs.FileSystem)
        at org.apache.hadoop.fs.Path.getFileSystem(Path.java:159)
        at org.apache.hadoop.fs.Trash.<init>(Trash.java:58)
        at org.apache.hadoop.dfs.NameNode.init(NameNode.java:184)
        at org.apache.hadoop.dfs.NameNode.<init>(NameNode.java:195)
        at org.apache.hadoop.dfs.NameNode.main(NameNode.java:728), This mostly not because of mismatch since this is running inside the NameNode it wants to contact. Output of '-QUIT' seems to show that RPC server in NameNode is stuck in side Seletctor, which is unusual. We could take thread stacks multiple times with 'jstack'. Do unit tests under core/io and core/net pass?

{noformat}
"IPC Server listener on 9000" daemon prio=10 tid=0x1006d570 nid=0x8d5 runnable [0x8e3c2000..0x8e3c2ae0]
   java.lang.Thread.State: RUNNABLE
        at java.util.HashMap.keySet(HashMap.java:886)
        at java.util.HashSet.iterator(HashSet.java:170)
        at sun.nio.ch.SelectorImpl.processDeregisterQueue(SelectorImpl.java:145)
        - locked <0x56d679d8> (a java.util.HashSet)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:87)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:87)
        - locked <0x56d61c20> (a sun.nio.ch.Util$1)
        - locked <0x56d61c30> (a java.util.Collections$UnmodifiableSet)
        - locked <0x56d61be0> (a sun.nio.ch.EPollSelectorImpl)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:98)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:102)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:253)
{noformat}
, During the following lines, java is hogging on the CPU:
{noformat}
[junit] 2008-08-06 15:12:41,355 INFO  ipc.Client (Client.java:setupIOstreams(190)) - Retrying connect to server: power.local/127.0.0.1:44005. Already tried 1 time(s).
    [junit] 2008-08-06 15:13:44,390 INFO  ipc.Client (Client.java:setupIOstreams(190)) - Retrying connect to server: power.local/127.0.0.1:44005. Already tried 2 time(s).
    [junit] 2008-08-06 15:14:47,439 INFO  ipc.Client (Client.java:setupIOstreams(190)) - Retrying connect to server: power.local/127.0.0.1:44005. Already tried 3 time(s).
    [junit] 2008-08-06 15:15:50,225 INFO  ipc.Client (Client.java:setupIOstreams(190)) - Retrying connect to server: power.local/127.0.0.1:44005. Already tried 4 time(s).
    [junit] 2008-08-06 15:16:53,196 INFO  ipc.Client (Client.java:setupIOstreams(190)) - Retrying connect to server: power.local/127.0.0.1:44005. Already tried 5 time(s).
{noformat}

I also attached a log of netstat. Interesting might be, that there is only a process bound to port 44005 on an ipv6 address., # ant -l build.log -Dtest.output=yes test

Killed after a couple of minutes., netstat during test, This has likely gone stale now, and no similar reports have been received (PPC may be the reason?) - closing this one out as Cannot Reproduce.]