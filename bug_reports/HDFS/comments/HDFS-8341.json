[I've done a manually scripted move of blocks under the hood in this scenario... but this functionality is effectively a blocker for hdfs storage tiering., Are you sure that there are other blocks needed to move?  Mover uses a thread pool and ExecutorService to dispatch block moves.  So it should not stuck with failures.  In other words, if there are failures, it should continue with the rest of the block moves., currenlty {{scheduleMoves4Block()}} API will schedule only one replica at a time. If replica scheduled successfully it will return, but here it should continue for next replica.

{code}
        for (final MLocation ml : locations) {
          final Source source = storages.getSource(ml);
          if (ml.storageType == t && source != null) {
            // try to schedule one replica move.
            if (scheduleMoveReplica(db, source, diff.expected)) {
              return true;
            }
          }
        }
{code}
Now the problem is, if file have more than one block for example 10 and some problem in moving first replica then {{scheduleMoves4Block()}} API will always schedule first replica in each iteration and it will return. It will keep on doing in all the iteration and other replica's never schedule for move.
, I had to move several thousand blocks by hand via scripting which was a significant proportion of the total blocks given that I had only put some limited amount of expendible data on the archive tier for testing. Given the dimensions of the data I'm certain it wasn't only successive blocks for one given file.

The command was looping on the same block, which also implies it never proceeded to try to move the blocks of the other files, hence the large number of blocks left behind and not moved back to the regular disk tier., > ... If replica scheduled successfully it will return, but here it should continue for next replica.

The reason of returning is that we don't want to move multiple replicas of the same block at once.

> Now the problem is, if file have more than one block for example 10 ... 

Do you mean "a block has more than one replicas for example 10"?

> ... and some problem in moving first replica then scheduleMoves4Block() API will always schedule first replica in each iteration and it will return.
The locations are shuffled so that the first replica is not necessarily the same in each iteration.  Am I missing anything?
{code}
//scheduleMoves4Block
      Collections.shuffle(locations);
{code}
, bq. Do you mean "a block has more than one replicas for example 10"?
yes

bq. The locations are shuffled so that the first replica is not necessarily the same in each iteration. Am I missing anything?

Ooh sorry I missed it.

But still problem is there. We don't now how many iteration it will take for moving correct replicas. Whenever corrupt replica comes at first position in shuffled list that iteration will fail., > But still problem is there. ...

This is only a minor problem which may not be needed to fix.

Let go back to the bug describing this JIRA. Would the Mover stuck or not?  The summary says "HDFS mover stuck in loop after failing to move block, doesn't move rest of blocks, can't get data back off decommissioning external storage tier as a result".  Is it still true?, Added (Summary & Description may be invalid) to the Summary and changed the priority to minor., Resolving as invalid.  Please feel free to reopen if you disagree., [~szetszwo] I believe this ticket is still valid:

There were holes in the data since that storage tier had replication factor 1 as the replication was supposed to be handled within the proprietary hyperscale storage solution underpinning that tier so there was no point in storing multiple HDFS replicas there. So if a given block's checksum failed, HDFS Mover looped on that block (probably hoping to find other valid block replicas to use but there were no other replicas so it was stuck looping on the one corrupt replica) and never got past that block so it didn't transfer the rest of the data's other blocks.

This would be the same problem if all replicas were corrupt or if a block was under replicated (which happens often) and the existing replica was corrupt.

So this jira is still valid - if HDFS Mover can't find a valid/non-corrupt replica then it doesn't proceed to move the rest of the other blocks, which prevented decommissioning of this storage tier. This is the reason I scripted a custom recovery job under the hood of Hadoop since the other blocks were fine and it was leaving a lot of data behind on the external storage tier., > ... So if a given block's checksum failed, HDFS Mover looped on that block ... and never got past that block so it didn't transfer the rest of the data's other blocks.

This statement seems wrong.  Mover won't loop on the same block according to the code.  Do you have a way to reproduce the bug?, All I can say is what I observed, as per the original code paste showing it looped on the same block number on each run and never got past it.

I've moved on since then and that storage tier was decommissioned anyway so I don't have any way to reproduce it right now. Perhaps a new cluster with a storage tiering with rep factor 1 where the block is intentionally corrupted might be able to reproduce this., > ... original code paste showing it looped on the same block number on each run and never got past it.

Do you mean the code posted on [this comment|https://issues.apache.org/jira/browse/HDFS-8341?focusedCommentId=14536366&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14536366]?  It loops on the locations but it will exit after looped all locations.  So "never got past it" seems a wrong statement.

[~surendrasingh], could comment on this?

> ... so I don't have any way to reproduce it right now. Perhaps a new cluster with a storage tiering with rep factor 1 where the block is intentionally corrupted might be able to reproduce this.

Could you try to reproduce the problem?  If we cannot reproduce it, we should resolve this JIRA for the moment.  We may reopen this or file a new JIRA in case we see the problem later.

IMO, this bug does not exist.  You may indeed have encountered a similar problem but it might be caused by something else but not the Mover. , [~szetszwo] No I meant the original log description at the top which shows
{code}balancer.Dispatcher: Failed to move blk_1075156654_1438349{code} repeats over and over in the output which is what made me think it was looping on the same block.

There's only 1 replica for each block... so it's not iterating on locations as the code snippet you are pointing to suggests since there are no other locations to try, but exiting and then restarting at the same block which still has no uncorrupted replicas available, exiting again, restarting at the same block again etc., Hi [~harisekhon], that is my mistake. The locations are shuffled, so it will not move same replica in each iteration.
Please check the [comment|https://issues.apache.org/jira/browse/HDFS-8341?focusedCommentId=14538625&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14538625] given by [~szetszwo].
, [~surendrasingh] it doesn't matter if the block replica locations are shuffled or not when there is only one replica.

The crux of the problem is not the locations, it's that it exits and tries from the same block again which doesn't have any uncorrupted replicas, so the mover never progresses to the next block., > ... it's that it exits and tries from the same block again  ...

No, it does not exit.

BTW, which version of Hadoop were you using?  I wonder that you might be using a development version so that you hit this problem.]