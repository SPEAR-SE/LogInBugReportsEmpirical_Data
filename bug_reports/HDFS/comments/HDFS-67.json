[The problem occur when an exception is thrown in the endBlock() method.
We never reach the deleteBackupFile() at the end of the method.

I added a try{} finally{} block to make sure we reach that code.

you can remove the LOG.info if you want., Good catch.
It looks like the problem here is more general than what your solution does.
The client writes to the backup file for as long as it reaches the block size. So if the client fails anywhere between 2 individual writes the backupFile will not be deleted. Simple try-catch will not solve it. And there is not much you can do about it.
This issue should probably be resolved as a part of HADOOP-1707, which intends to eliminate the local backup file completely.
Benjamin, could you please take a look at 1707 to make sure the solution works for you., Linking to HADOOP-1707. Dhruba, could you please check that clients do not leave unattended temporary files after your patch is in., Not a problem after Dhruba's HDFS-1707., Er, make that HADOOP-1707 sorry.]