[[~mingma]   Is it  the same as https://issues.apache.org/jira/browse/HDFS-7609 , Would  you like  give a look ? , [~piaoyu zhang], In latest versions of hadoop. {{dfshealth.jsp}} has been replaced by new HTML5 webUI {{dfshealth.html}}

Where page will load without any hiccups. Its completely lockless and works entirely on basis of JMX metrics., [~vinayrpet]   I konw the  latest versions of hadoop  replaced by new HTML5 webUI dfshealth.html .  
But We still use Hadoop-2.2.0.  We open the jmx metrics and find it very slow too. 
 And sometimes the Active NameNode lost the node and recorvery in a few times . 
 I update the stacks for Standby NameNode , [~piaoyu zhang] based on the thread dump you provided, it is HDFS-7609 which caused {{addCacheEntry}} to hold the {{FSNamesystem}}'s lock for too long. To add to [~vinayrpet]'s point, with HDFS-7182 jmx access doesn't need to acquire {{FSNamesystem}}'s lock., [~mingma],thanks you , [~mingma],is it OK for set the disable retry cache for standby ?, Or I can reduce  dfs.namenode.retrycache.expirytime.millis time  value 
and increase dfs.namenode.retrycache.heap.percent  value 
to ease this problem ?, You want to the disable the feature on the active, as well as the standby so that it is consistent when the standby becomes the active. Alternatively you can upgrade to later versions of hadoop or backport the fix., [~mingma],thank you.  I disable retry cache and set the dfs.namenode.checkpoint.txns to 10000000,The standby become normal.
But I find the performance spikes still exits  in every three min .  
And we have dfs.ha.tail-edits.period value 60s and
 the dfs.ha.log-roll.period value 120s.   Should we reduce the value ?

I Update the Rpc CallQueueLength image with standby 
, HDFS-7097 and HDFS-6763 also mitigate spikes on standby name nodes. , [~kihwal]   thanks. it really helpful  for us. ]