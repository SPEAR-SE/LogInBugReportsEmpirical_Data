[An easy way to reproduce this is to create a file on a cluster, then restart NN without DNs, manually leave SafeMode, and try to append data to the file. On a real cluster one can kill 3 DNs (on different racks), then some blocks will be missing, and it is likely that one of them will be the last of some file., Attaching patch to reproduce issue. This can reproduced on a MiniDFSCluster of 1 NameNode and 1 DataNode.

Once the environment is in the state of NameNode having zero block locations of some file X and out of SafeMode the following events will happen:
The first append to X will fail with 'unable to retrieve last block of file X'.
Subsequent appends will fail with AlreadyBeingCreatedException until lease recovery occurs., The test seems to be doing all the right checks, but succeeding if the conditions are met instead of failing. It should be the other way around., Attached a patch to fail on the current state of closed. It does an append with no locations as [~zero45] did, then ensures that the file is closed. As of now, this test fails. , Here is a patch with a proposed fix to introduce BlockManager#isSufficientlyReplicated and a unit test. 
-This will check that the block is replicated to at least the min of number of live DNs and the replication factor of the file. 

The unit test will
1. start 6 DNs
2. create a file with a rep factor of 3
3. Kill the DNs with the block locations of that file. 
4. run append and ensure failure
5. ensure the file is not opened afterwards. 
 , Here are some thoughts after experimenting and discussions.

# We should still allow executing append if the number of live DNs on the cluster is less than file replication factor. This is to support cases with small clusters or replication being set intentionally high.
# We should probably go for option (1) with min-replication. This has an advantage that there will be no change in semantics with current implementation. The disadvantage is that once file is opened for append the ongoing replications of the last block will fail, because of the genStamp change.
# In the end our main goal is to make append fail earlier to prevent the file from being under construction while nobody can use it, which happens when the last  block has 0 replicas., Patch review comments:
# Need to change full-replication to min-replication.
# You should not check sufficient replication if the last block is already under construction.
# JavaDoc comment for isSufficientlyReplicated() is not clear and the comment in the body is redundant.
# The test looks good. I see a few long lines though., 1. Fixed isSufficientlyReplicated and comments for minimum replication check. 
2. Added a isComplete check so we dont check underconstruction files in FSNamesystem. 
3. Fixed lines in test. , {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12644461/HDFS-6325.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.server.balancer.TestBalancerWithNodeGroup
                  org.apache.hadoop.hdfs.TestFileAppend4

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/6879//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/6879//console

This message is automatically generated., testFileAppend4 failure: 
There may be an overlap of shutdown of testAppendInsufficientLocations and startup of testCompleteOtherLeaseHoldersFile. 
I changed testAppendInsufficientLocations to use the field variable "cluster" instead of creating my own as a local variable and also reduced the number of DNs from 6 to 4. Otherwise, I see that testCompleteOtherLeaseHoldersFile is progressing so I think a bigger timeout may be required as stated in this JIRA: https://issues.apache.org/jira/browse/HADOOP-8596. 

TestBalancerWithNodeGroup: 
This also seems to be an intermittent issue from https://issues.apache.org/jira/browse/HDFS-6250. 





, {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12644527/HDFS-6325.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/6885//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/6885//console

This message is automatically generated., This looks good. Just two final touches:
- In appendFileInternal() you can actually combine nested if statements into one with three conditions.
- In testAppendInsufficientLocations() you should use {{LOG.info("message", e);}} instead of {{+ e.getMessage()}}

The patch cleanly applies to branch-2 and branch-2.4. 
It would be nice to have it in 2.4.1. If there are no there objections?, Attached patch.

Addressed the above comments and passed the TestFileAppend* tests locally. , {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12645053/HDFS-6325.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/6913//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/6913//console

This message is automatically generated., +1 looks good., SUCCESS: Integrated in Hadoop-trunk-Commit #5606 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/5606/])
HDFS-6325. Append should fail if the last block has insufficient number of replicas (Keith Pak via cos) (cos: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1595744)
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileAppend4.java
, FAILURE: Integrated in Hadoop-Yarn-trunk #562 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/562/])
HDFS-6325. Append should fail if the last block has insufficient number of replicas (Keith Pak via cos) (cos: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1595744)
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileAppend4.java
, FAILURE: Integrated in Hadoop-Hdfs-trunk #1754 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1754/])
HDFS-6325. Append should fail if the last block has insufficient number of replicas (Keith Pak via cos) (cos: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1595744)
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileAppend4.java
, FAILURE: Integrated in Hadoop-Mapreduce-trunk #1780 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1780/])
HDFS-6325. Append should fail if the last block has insufficient number of replicas (Keith Pak via cos) (cos: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1595744)
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileAppend4.java
]