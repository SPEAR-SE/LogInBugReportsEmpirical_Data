[I agree with Hairong. Recently, I've been playing around with this, and found the same problem as shown in the attachment (underReplicatedQueue.pdf).

At a high-level, if the round-robin iterator is in queue-2 (queue with priority=2), then the UR blocks in queue-0 must wait until the iterator wraps to queue-0 again.  So, I assume, in worst case, if queue-2 is long (as depicted in the graph), the UR blocks in queue-0 will take a very long time to be served!

The setup of the figure:
I have 20 nodes.  Each node holds 3000 blocks. I fail 4 nodes.
q-0: UR blocks with 1 replica
q-2: UR blocks with 2 replicas
pq: pending queue
(I stopped the experiment in the middle, because the pattern is obvious)

More details why the round-robin iterator does not work:

It is true that round-robin iterates through queue-0 first,
but the replication monitor runs this logic:
- choose a block B to be replicated
- pick a source node S that still has B 
- BUT if S were already chosen to replicate other blocks 
  (i.e. S' rep stream is already larger than the maxrepstream(2)),
  then increment the iterator (and thus this block B in queue-0
  will not be served until the round-robin iterator wraps).
  And if other queues (e.g. q1 and q2) are super long, then queue-0
  might be starved for a long time.

, One scenario here:
 Accidentally user configured single rack so, all the block goes to under replicated.
after some time, high priority blocks got added to queues. 
While processing it is trying to process only previos underreplicated blocks, even though there are high priority blocks added.

Looking at this part, single replecatioIndex maintained for all the priority queues. For suppose if it needs to process 100blocks in this iteration, it may not be able to find the targets because there is only single rack available. 
so, the replecationIndex will not be decremented. In Next iteration it will try to skip the number of replecationIndex blocks. Lets say 50 blocks added to high priority queue now. ReplIndex was already 100. So, it will skip first 100 blcoks and start picking the remaining. Due to this, high peiority blocks are not getting chance to replicate quickly.

,   Attached the Doc : HDFS-1765.pdf
  Which covers some cases for replication to explain the problems and proposed solution., Hi Uma, the proposed solution sounds good.  Having an index for each priority will solve the problem.

BTW, chooseUnderReplicatedBlocks(..) and replIndex in BlockManager should be moved to UnderReplicatedBlocks., HDFS-1765.patch :1st Patch.
Updated with the propose solution.

@Nicholas, Addressed your comment for moving the chooseUnderReplicatedBlocks to UnderReplicatedBlocks class. 
Thanks a lot for the document Reviews., -1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12506283/HDFS-1765.patch
  against trunk revision .

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 5 new or modified tests.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    -1 core tests.  The patch failed these unit tests:
                  org.apache.hadoop.hdfs.server.namenode.metrics.TestNameNodeMetrics

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/1648//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/1648//console

This message is automatically generated., {quote}-1 core tests. The patch failed these unit tests:
org.apache.hadoop.hdfs.server.namenode.metrics.TestNameNodeMetrics
{quote}
Failure should not be due to this patch. Without this patch also it is failing locally for me.
After deleting the file it is checking for Underreplicated blocks count to be 0. That will be updated once DN updates about delete. This is handled in testFileAdd. Same added for this test also. , +1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12506376/HDFS-1765.patch
  against trunk revision .

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 8 new or modified tests.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    +1 core tests.  The patch passed unit tests in .

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/1653//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/1653//console

This message is automatically generated., I should have put the namesystem unlock in finally even though chooseUnderReplicatedBlocks doesn't throw exception for more safe.
{code}
neededReplications.chooseUnderReplicatedBlocks(blocksToProcess);
+    namesystem.writeUnlock();
{code}


I will include this point in next patch along with the review comments if any.


Thanks
Uma, Thanks for taking this on Uma. Feedback on your latest patch follows: 

BlockManager:
* Why do we have to hold the write lock across chooseUnderReplicatedBlocks and computeReplicationWorkForBlocks now? Seems like the current granularity is sufficient.
* computeReplicationWork writeUnlock needs to be in a finaly clause

UnderreplicatedBlocks:
* I'd make chooseUnderReplicatedBlocks synchronized instead of synchronizing on this
* Why reset all repl indices at the same time? Shouldn't we reset the repl index for a priority only when that given priority runs out?
* I'd populate priorityVsReplIndex in the 1st loop so you don't need to check gets for null when setting repleIndex
* I'd make the loop over blocks a while loop, eg
{code}
  while (blockCount < blocksToProcess && neededRepls.hasNext()) {
      blockCount++
      replIndex++;
      ...
   }
{code}
* "All priority Queues last block index used for replication work." -> "Stores the replication index for each priority"
* Rename "priorityVsReplIdx" to "priorityToReplIdx" and "repleIndex" to "replIndex"
* param javadocs for decrementReplicationIndex and chooseUnderReplicatedBlocks should be on their own line
* I'd remove the comment about "# of blocks to process equals either twice the number of live data-nodes" as its a function of the argument blocksToProcess and so this comment is stale as soon as eg REPLICATION_WORK_MULTIPLIER_PER_ITERATION (which is multiple callers up) changes.
* I'd rename "replicationPriority" just "priority"
* !neededRep.hasNext() instead of "false == neededRep.hasNext()"
* We don't need to qualify the code in chooseUnderReplicatedBlocks with UnderReplicatedBlocks anymore (eg LEVEL and BlockIterator) now that it lives in this class
* The warn of unexpected replication priority should be an assert right? The block should never have an invalid priority.


TestReplPolicy:
* Seems like the test needs to check that there are no blocks in the high priority queue but there are still blocks in the low priority queue. It currently just tests that the high priority queue is empty, but that could be because it's has sufficient time to empty all queues right?
* Maybe write a unit test directly against chooseUnderReplicatedBlocks?
* Nit: replace 3000 with a constant and set DFS_NAMENODE_REPLICATION_INTERVAL_KEY in the conf in the test (you could lower it to 1000 so the test runs more quickly).
* Can import static org.junit.Assert.* 
* "replicationinterval" is two words
* "high priority blocks to process very quickly than the low priority blocks" -> "high priority blocks are processed before the low priority blocks"

TestNNMetrics:
* Where you've replaced updateMetrics with the new code/comment to sleep how about putting this in a method (eg waitForDeletion) and calling that., Thanks a lot Eli for the nice review.

I have updated the patch with the comments addressed.

BlockManager:

•Why do we have to hold the write lock across chooseUnderReplicatedBlocks and computeReplicationWorkForBlocks now? Seems like the current granularity is sufficient.
   I got this suspect when i am working on this. But that synchronization if not introduced as part of this JIRA.
   I will file separate JIRA for it?
•computeReplicationWork writeUnlock needs to be in a finaly clause
  Addressed as part of my above comment. Thanks for noticing.

UnderreplicatedBlocks:

•I'd make chooseUnderReplicatedBlocks synchronized instead of synchronizing on this
  There are some code which is not required of synchronization. But anyway there is no big benifit because of that small loop before. Just made it to method level Synchronization.

•Why reset all repl indices at the same time? Shouldn't we reset the repl index for a priority only when that given priority runs out?
   This is because, if any of the queue blocks are not able to clear, then that queues replication index will be at end. If we reset immeditely here. On next ReplicationInterval, again the same blocks will be iterated , even though are blocks in next priority blocks not visited yet. 

    take a case here:
       priority 3 has 20 blocks(which can not be processed for replication work) and 4 has 10 blocks. blocksToProcess is 10.
       1st replicationInterval : it will take 10 blocks from priority 3. (assume the block can not find targets to replicate, so the replIndex will not be decremented)
       2nd replicationInterval : it will take 10 blocks from priority 3 again. Assume same case like #1. 
          If we reset replIndex here immediately, on 3rd replicationInterval, again it will steart visiting the blocks in 3rd priority. It will not go to 4th priority.

•I'd populate priorityVsReplIndex in the 1st loop so you don't need to check gets for null when setting repleIndex
  done in UnderReplicatedBlocks constructor.

•I'd make the loop over blocks a while loop, eg 
while (blockCount < blocksToProcess && neededRepls.hasNext()) {
      blockCount++
      replIndex++;
      ...
   }
  Done.

•"All priority Queues last block index used for replication work." -> "Stores the replication index for each priority"
•Rename "priorityVsReplIdx" to "priorityToReplIdx" and "repleIndex" to "replIndex"
  Done

•param javadocs for decrementReplicationIndex and chooseUnderReplicatedBlocks should be on their own line
  Done. This is due to eclipse shortcut.

•I'd remove the comment about "# of blocks to process equals either twice the number of live data-nodes" as its a function of the argument blocksToProcess and so this comment is stale as soon as eg REPLICATION_WORK_MULTIPLIER_PER_ITERATION (which is multiple callers up) changes.
  sorry, removed the comment.

•I'd rename "replicationPriority" just "priority"
   Done

•!neededRep.hasNext() instead of "false == neededRep.hasNext()"
  Done
•We don't need to qualify the code in chooseUnderReplicatedBlocks with UnderReplicatedBlocks anymore (eg LEVEL and BlockIterator) now that it lives in this class
  Done.

•The warn of unexpected replication priority should be an assert right? The block should never have an invalid priority.
     Since there is no intermediate priority changes, need not have this check now. Loop  and iterater is specific to priority. They will never mismatch.

TestReplPolicy: 

•Seems like the test needs to check that there are no blocks in the high priority queue but there are still blocks in the low priority queue. It currently just tests that the high priority queue is empty, but that could be because it's has sufficient time to empty all queues right?
 Now aound after ~7 blocks, high priority block got processed. to complete 100 blocks it will take 25secs.  
•Maybe write a unit test directly against chooseUnderReplicatedBlocks?
  Added the testcases directly with chooseUnderReplicatedBlocks.

•Nit: replace 3000 with a constant and set DFS_NAMENODE_REPLICATION_INTERVAL_KEY in the conf in the test (you could lower it to 1000 so the test runs more quickly).
Done

•Can import static org.junit.Assert.*
  Done. This is becuase of eclipse shortcut.
•"replicationinterval" is two words 
  Done
•"high priority blocks to process very quickly than the low priority blocks" -> "high priority blocks are processed before the low priority blocks"
 Done

TestNNMetrics:

•Where you've replaced updateMetrics with the new code/comment to sleep how about putting this in a method (eg waitForDeletion) and calling that.
  Sure. Can do it.... Done., -1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12506643/HDFS-1765.patch
  against trunk revision .

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 6 new or modified tests.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    -1 findbugs.  The patch appears to introduce 1 new Findbugs (version 1.3.9) warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    -1 core tests.  The patch failed these unit tests:
                  org.apache.hadoop.hdfs.TestParallelRead
                  org.apache.hadoop.hdfs.TestCrcCorruption
                  org.apache.hadoop.hdfs.TestQuota
                  org.apache.hadoop.hdfs.security.token.block.TestBlockToken
                  org.apache.hadoop.hdfs.TestFileAppend3
                  org.apache.hadoop.hdfs.TestDatanodeConfig
                  org.apache.hadoop.hdfs.security.TestDelegationToken
                  org.apache.hadoop.hdfs.tools.TestGetGroups
                  org.apache.hadoop.hdfs.tools.offlineEditsViewer.TestOfflineEditsViewer
                  org.apache.hadoop.hdfs.TestClientReportBadBlock

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/1663//testReport/
Findbugs warnings: https://builds.apache.org/job/PreCommit-HDFS-Build/1663//artifact/trunk/hadoop-hdfs-project/patchprocess/newPatchFindbugsWarningshadoop-hdfs.html
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/1663//console

This message is automatically generated., I ran this tests locally, they are passing for me, seems to be unrelated. Lets trigger QA again., -1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12506691/HDFS-1765.patch
  against trunk revision .

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 6 new or modified tests.

    -1 javadoc.  The javadoc tool appears to have generated 90 warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    -1 findbugs.  The patch appears to introduce 5 new Findbugs (version 1.3.9) warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    -1 core tests.  The patch failed these unit tests:
                  org.apache.hadoop.hdfs.security.TestDelegationToken
                  org.apache.hadoop.hdfs.tools.offlineEditsViewer.TestOfflineEditsViewer

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/1665//testReport/
Findbugs warnings: https://builds.apache.org/job/PreCommit-HDFS-Build/1665//artifact/trunk/hadoop-hdfs-project/patchprocess/newPatchFindbugsWarningshadoop-hdfs-httpfs.html
Findbugs warnings: https://builds.apache.org/job/PreCommit-HDFS-Build/1665//artifact/trunk/hadoop-hdfs-project/patchprocess/newPatchFindbugsWarningshadoop-hdfs.html
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/1665//console

This message is automatically generated., Again test failures and javadoc comments are unrelated. Findbugs also not related to this patch. Looks they are coming from HttpFs. filed a JIRA for it. HDFS-2646
, Test failures are due to HADOOP-7902, not related to this patch!, Thanks Uma - looking good! Just some minor stuff remaining..

TestReplicationPolicy:
* rename chooseUnderReplicatedBlocks to chosenBlocks
* The new testChooseUnderReplicatedBlocks looks great

UnderReplicatedBlocks:
* Can remove the " // replicate blocks" comment since we're not actually replicating blocks here.
* The comment in chooseUnderReplicatedBlocks references priorityVsReplIndex instead of priorityToReplIdx
* "is no blocks" -> "are no blocks"
" "full fill" -> "fulfill"

, Thanks a lot Eli, for the reviews!

Updated the patch. Functionally same as last patch with addressing the comments from Eli.

TestReplicationPolicy:

    * rename chooseUnderReplicatedBlocks to chosenBlocks
    Done
    * The new testChooseUnderReplicatedBlocks looks great
    Thanks Eli. :-)

UnderReplicatedBlocks:

    * Can remove the " // replicate blocks" comment since we're not actually replicating blocks here.
    
     Actually this is in BlockManager and was a old comment. Just removed it.

    * The comment in chooseUnderReplicatedBlocks references priorityVsReplIndex instead of priorityToReplIdx
      couldn't figure out in last patch. Done. Thanks for catching it.
    * "is no blocks" -> "are no blocks"
      " "full fill" -> "fulfill" - done.
      

Thanks
Uma
, +1 looks great, I've committed this. Thanks Uma!

I think this would be a good fix for 23, however w/o 1st merging HDFS-2362 this is a non-trivial merge so leaving as 0.24 for now., Integrated in Hadoop-Mapreduce-trunk-Commit #1428 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk-Commit/1428/])
    HDFS-1765. Block Replication should respect under-replication block priority. Contributed by Uma Maheswara Rao G

eli : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1213537
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/UnderReplicatedBlocks.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestReplicationPolicy.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/metrics/TestNameNodeMetrics.java
, Integrated in Hadoop-Mapreduce-trunk-Commit #1429 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk-Commit/1429/])
    Put HDFS-1765 in the right place in the changelog.

eli : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1213541
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
, Integrated in Hadoop-Common-trunk-Commit #1405 (See [https://builds.apache.org/job/Hadoop-Common-trunk-Commit/1405/])
    Put HDFS-1765 in the right place in the changelog.
HDFS-1765. Block Replication should respect under-replication block priority. Contributed by Uma Maheswara Rao G

eli : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1213541
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt

eli : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1213537
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/UnderReplicatedBlocks.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestReplicationPolicy.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/metrics/TestNameNodeMetrics.java
, Integrated in Hadoop-Hdfs-trunk-Commit #1479 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk-Commit/1479/])
    Put HDFS-1765 in the right place in the changelog.
HDFS-1765. Block Replication should respect under-replication block priority. Contributed by Uma Maheswara Rao G

eli : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1213541
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt

eli : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1213537
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/UnderReplicatedBlocks.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestReplicationPolicy.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/metrics/TestNameNodeMetrics.java
, -1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12507109/HDFS-1765.patch
  against trunk revision .

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 6 new or modified tests.

    -1 patch.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/1699//console

This message is automatically generated., Integrated in Hadoop-Hdfs-trunk #893 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/893/])
    Put HDFS-1765 in the right place in the changelog.
HDFS-1765. Block Replication should respect under-replication block priority. Contributed by Uma Maheswara Rao G

eli : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1213541
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt

eli : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1213537
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/UnderReplicatedBlocks.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestReplicationPolicy.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/metrics/TestNameNodeMetrics.java
, Integrated in Hadoop-Mapreduce-trunk #926 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/926/])
    Put HDFS-1765 in the right place in the changelog.
HDFS-1765. Block Replication should respect under-replication block priority. Contributed by Uma Maheswara Rao G

eli : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1213541
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt

eli : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1213537
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/UnderReplicatedBlocks.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestReplicationPolicy.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/metrics/TestNameNodeMetrics.java
, Thanks a lot Eli,

Do we have plans to push HDFS-2362 to 0.23 version? If yes, we can request Thomas to put the patch for 0.23 as well. Otherwise i can create patch for 0.23 version directly?

Thanks
Uma, bq. Do we have plans to push HDFS-2362 to 0.23 version?

Not that I know of, hopefully we can merge the couple changes that introduced a big delta to 23 so merges like this will be easier., Thanks a lot Suresh, for merging it to 23 branch. I will mark this issue as resolved now, as it was left for 0.23 version merge., Integrated in Hadoop-Hdfs-0.23-Commit #646 (See [https://builds.apache.org/job/Hadoop-Hdfs-0.23-Commit/646/])
    HDFS-1765. Merging change r1213537 from trunk to 0.23 (Revision 1297865)

     Result = SUCCESS
suresh : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1297865
Files : 
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/UnderReplicatedBlocks.java
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestReplicationPolicy.java
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/metrics/TestNameNodeMetrics.java
, Integrated in Hadoop-Common-0.23-Commit #655 (See [https://builds.apache.org/job/Hadoop-Common-0.23-Commit/655/])
    HDFS-1765. Merging change r1213537 from trunk to 0.23 (Revision 1297865)

     Result = SUCCESS
suresh : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1297865
Files : 
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/UnderReplicatedBlocks.java
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestReplicationPolicy.java
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/metrics/TestNameNodeMetrics.java
, Integrated in Hadoop-Mapreduce-0.23-Commit #655 (See [https://builds.apache.org/job/Hadoop-Mapreduce-0.23-Commit/655/])
    HDFS-1765. Merging change r1213537 from trunk to 0.23 (Revision 1297865)

     Result = SUCCESS
suresh : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1297865
Files : 
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/UnderReplicatedBlocks.java
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestReplicationPolicy.java
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/metrics/TestNameNodeMetrics.java
, Integrated in Hadoop-Hdfs-trunk-Commit #1921 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk-Commit/1921/])
    Moving HDFS-2158, HDFS-2188, HDFS-2334, HDFS-2477, HDFS-2495, HDFS-2476, HDFS-1580, HDFS-1765 to 0.23.3 section in CHANGES.txt (Revision 1297903)

     Result = SUCCESS
suresh : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1297903
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
, Integrated in Hadoop-Common-trunk-Commit #1847 (See [https://builds.apache.org/job/Hadoop-Common-trunk-Commit/1847/])
    Moving HDFS-2158, HDFS-2188, HDFS-2334, HDFS-2477, HDFS-2495, HDFS-2476, HDFS-1580, HDFS-1765 to 0.23.3 section in CHANGES.txt (Revision 1297903)

     Result = SUCCESS
suresh : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1297903
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
, Integrated in Hadoop-Mapreduce-trunk-Commit #1855 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk-Commit/1855/])
    Moving HDFS-2158, HDFS-2188, HDFS-2334, HDFS-2477, HDFS-2495, HDFS-2476, HDFS-1580, HDFS-1765 to 0.23.3 section in CHANGES.txt (Revision 1297903)

     Result = SUCCESS
suresh : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1297903
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
, Integrated in Hadoop-Hdfs-0.23-Build #190 (See [https://builds.apache.org/job/Hadoop-Hdfs-0.23-Build/190/])
    HDFS-1765. Merging change r1213537 from trunk to 0.23 (Revision 1297865)

     Result = SUCCESS
suresh : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1297865
Files : 
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/UnderReplicatedBlocks.java
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestReplicationPolicy.java
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/metrics/TestNameNodeMetrics.java
, Integrated in Hadoop-Hdfs-trunk #977 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/977/])
    Moving HDFS-2158, HDFS-2188, HDFS-2334, HDFS-2477, HDFS-2495, HDFS-2476, HDFS-1580, HDFS-1765 to 0.23.3 section in CHANGES.txt (Revision 1297903)

     Result = FAILURE
suresh : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1297903
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
, Integrated in Hadoop-Mapreduce-0.23-Build #218 (See [https://builds.apache.org/job/Hadoop-Mapreduce-0.23-Build/218/])
    HDFS-1765. Merging change r1213537 from trunk to 0.23 (Revision 1297865)

     Result = FAILURE
suresh : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1297865
Files : 
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/UnderReplicatedBlocks.java
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestReplicationPolicy.java
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/metrics/TestNameNodeMetrics.java
, Integrated in Hadoop-Mapreduce-trunk #1012 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1012/])
    Moving HDFS-2158, HDFS-2188, HDFS-2334, HDFS-2477, HDFS-2495, HDFS-2476, HDFS-1580, HDFS-1765 to 0.23.3 section in CHANGES.txt (Revision 1297903)

     Result = FAILURE
suresh : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1297903
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
, Committed to branch-0.23., Integrated in Hadoop-Hdfs-0.23-Build #513 (See [https://builds.apache.org/job/Hadoop-Hdfs-0.23-Build/513/])
    merge -r 1213536:1213537 Merging from trunk to branch-0.23 to fix HDFS-1765 (Revision 1441577)

     Result = SUCCESS
kihwal : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1441577
Files : 
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/UnderReplicatedBlocks.java
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestReplicationPolicy.java
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/metrics/TestNameNodeMetrics.java
]