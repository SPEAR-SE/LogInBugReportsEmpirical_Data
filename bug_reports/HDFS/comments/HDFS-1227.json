[Believe this is addressed by HDFS-1186 in the 20-append branch, Going to resolve this as invalid. If you can reproduce after HDFS-1186 is committed, or provide a unit test, we can reopen., In the append-branch, I saw the "unmatched file length exception happens", but then the client retries RecoverBlock, hence, tolerates this, when startBlockRecovery is called, the writer thread is interrupted. But the effect/changes that this write made to disk (if any) is still there, right?
Hence this exception still happens (after HDFS-1186 is committed)., Hi Thanh. Since the writer is interrupted before getting the recovery info, it will return the new length, with the effect of the write, like you said. But when the synchronized length is calculated, it's taken as the minimum of the lengths (ie the length at DN1), which is what we want.

Did you test this against the append branch with HDFS-1186 applied on top? (Note that 1186 has not yet been committed to the branch), >Dn1 is primary. The pipeline is dn3-dn2-dn1. recoverBlock succeeds.
>Client starts sending data to the dn3 - the first datanode in pipeline.

I am slightly confused by the above. The first datanode in the write pipeline is typically the primary datanode. If the client is writing to d1, d1 is forwarding it to d2 and d2 is forwarding it to d3, then the primary is d1, isn't it?

Also, this bug should already be solved in the append-0.20 branch.]