[Can you please add more detailed description about the problem?, I see that addBlock() has a new parameter fileId while complete() doesn't have it.
In current implementation neither of the two need the parameter, because both use the path to find the file INode. But addBlock() verifies that the fileId passed as the parameter is the same as in the inode. While complete() uses GRANDFATHER_INODE_ID, which essentially means don't check fileId.
I don't know what the plan is, but if it is to eventually use fileId as an identifier of the file INode for open file, then it will make sense to use it in both addBlock() and complete(). And if we will want to change the implementation without changing wire APIs, we should probably add fileId parameter to complete() now.
This will also enable verification that we are closing the correct file by checking the real fileId in complete(), same as in addBlock().
Does it make sense?, Hi Konstantin, it makes sense to use fileId in complete(). 

Adding fileId can do things right in two cases: 1. after renaming an opened file, the client should still be able to close the file.
2. after renaming an opened file, the client should not close the wrong file (it could if using only path in complete()).

Here is an example of case2. 
1. Client opens file A and B.
2. Delete B, rename A to B.
3. Close B. Without fileId in complete(), original file A is closed.
, BTW, adding fileId to complete() is not an incompatible change., Added the fileId param, passing it to checkId() to ensure that Inode id is the one expected. , {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12588668/HDFS-4883.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 3 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/4541//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/4541//console

This message is automatically generated., Thanks for the patch!
A few comments:
1. in ClientNamenodeProtocolServerSideTranslatorPB.java, req.getFileId() should be "req.hasFileId() ? req.getFileId() : INodeId.GRANDFATHER_INODE_ID" for backward compatibility. 

2. in ClientNamenodeProtocol.proto, instead of:
  required uint64 fileId = 3;
  optional ExtendedBlockProto last = 4;

it should be:
  optional ExtendedBlockProto last = 3;
  optional uint64 fileId = 4;

3. checkLease() throws exception when src and fileId don't match. It seems a better approach if fileId presents, the namenode API should use fileId instead of src to serve the request. I am OK if you think this is beyond this JIRA and doesn't have to be fixed here.

4. It would be nice to add simple unit test to validate the change.
, Looking good. Few comments.
# The proto definition for fileId should be optional, looking like
{code}optional uint64 fileId = 4 [default = 0];{code}
it should be the last to match the parameters with the fields ordering.
# In NameNodeRpcServer.complete() one line is longer than 80.
# Please remove unrelated typo fix in FSNamesystem() constructor.
# It would be good to add a test case in one of the existing tests, which confirms the fileId is actually checked and an exception is thrown., Oops, Brandon beat me.
Yes let's make the use of fileId for getting INodes instead of src in a separate jira. This should be implemented both for complete() and addBlock()., Thanks Brandon and Konstantin. I have uploaded the revised patch. , {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12588729/HDFS-4883.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 4 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/4546//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/4546//console

This message is automatically generated., This assert failed in the @After shutdown() for TestQuorumJournalManager.testPurgeLogs():
{code}
    // Should not leak clients between tests -- this can cause flaky tests.
    // (See HDFS-4643)
    GenericTestUtils.assertNoThreadsMatching(".*IPC Client.*");
{code}

However, it does not seem to be related to this patch, and I cannot reproduce this issue by running the test locally after applying this patch. , {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12588957/HDFS-4883.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 4 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/4553//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/4553//console

This message is automatically generated., +1. Looks good.
Tao, I suggest you file a jira for the failure of TestQuorumJournalManager.testPurgeLogs() listing the exception in a comment (rather than the description)., Integrated in Hadoop-trunk-Commit #3994 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/3994/])
    HDFS-4883. complete() should verify fileId. Contributed by Tao Luo. (Revision 1495302)

     Result = SUCCESS
shv : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1495302
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/ClientProtocol.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolTranslatorPB.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNodeRpcServer.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/proto/ClientNamenodeProtocol.proto
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSClientRetries.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileAppend4.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileCreation.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/NNThroughputBenchmark.java
, I just committed this. Thank you Tao., Integrated in Hadoop-trunk-Commit #3995 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/3995/])
    Move changes for HDFS-4883 to 2.1.0 section. (Revision 1495314)

     Result = SUCCESS
shv : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1495314
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
, Integrated in Hadoop-Yarn-trunk #247 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/247/])
    Move changes for HDFS-4883 to 2.1.0 section. (Revision 1495314)
HDFS-4883. complete() should verify fileId. Contributed by Tao Luo. (Revision 1495302)

     Result = FAILURE
shv : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1495314
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt

shv : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1495302
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/ClientProtocol.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolTranslatorPB.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNodeRpcServer.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/proto/ClientNamenodeProtocol.proto
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSClientRetries.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileAppend4.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileCreation.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/NNThroughputBenchmark.java
, Integrated in Hadoop-Hdfs-trunk #1437 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1437/])
    Move changes for HDFS-4883 to 2.1.0 section. (Revision 1495314)
HDFS-4883. complete() should verify fileId. Contributed by Tao Luo. (Revision 1495302)

     Result = FAILURE
shv : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1495314
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt

shv : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1495302
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/ClientProtocol.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolTranslatorPB.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNodeRpcServer.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/proto/ClientNamenodeProtocol.proto
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSClientRetries.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileAppend4.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileCreation.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/NNThroughputBenchmark.java
, Integrated in Hadoop-Mapreduce-trunk #1464 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1464/])
    Move changes for HDFS-4883 to 2.1.0 section. (Revision 1495314)
HDFS-4883. complete() should verify fileId. Contributed by Tao Luo. (Revision 1495302)

     Result = SUCCESS
shv : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1495314
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt

shv : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1495302
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/ClientProtocol.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolTranslatorPB.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNodeRpcServer.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/proto/ClientNamenodeProtocol.proto
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSClientRetries.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileAppend4.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileCreation.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/NNThroughputBenchmark.java
, {quote}Yes let's make the use of fileId for getting INodes instead of src in a separate jira. This should be implemented both for complete() and addBlock().{quote}
I've filed HDFS-4928 to track this.
]