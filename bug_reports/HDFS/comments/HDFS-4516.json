[Recovery also will not happen because, if there are no locations, we can not recover.
{code}
if (replicas.size() == 0) {
      NameNode.stateChangeLog.warn("BLOCK*"
        + " BlockInfoUnderConstruction.initLeaseRecovery:"
        + " No blocks found, lease removed.");
    }
{code}

In this situation clients also will see last block locations as 0. But we are assuming here that DNs might not have reported and we will retry for 3 times and read will fail. Here currently there is no way to detect whether blocks are created in DN or not.

One idea, What I am having is. When we create block immediate we should not have length as 0, because this block might not yet created in DN. Initial block length can be set as -1 when allocating in NN. Once DN reports block receving then we can set the length to 0. 
By this time if client synced with some data, anyway that size will be persisted. When block receiving request comes from DN to NN, NN will update length to 0 if and only if length is -1. Otherwise it can leave as is, because it might have synced with some data and updated that length.

And client can check, if last block length is -1, then direct it can return 0, because DNs not yet created and reported (or) not synced by client. We have to be care where and used block.getNumButes method take actions accordingly. 


, One more option what I can see is, How about not persisting block along with allocate block. and persist the block with separate call to NN after createBlockOutPutStream success.

If createBlockOutputStream success, block must have create in DNs, So now that is correct time to persist in NN also before start writing any content i.e, just after createBlockOutputStream success.
But I know, this will introduce one extra NN call for block and will have performnace impact. Somewhat may compensated by not persisting the blocks along with allocate block but still have NW call. Any other thoughts/suggestions?, Hi Uma.
For the first method. There is also problem that the datanode has written the data, but yet not reported to the NN. This will mislead the client that no data for the file even synced, whick broke the defination of sync. 
Second method seems ok althgh a performace loss, however, the frequence is low and then affect is ok., For second method, we could revise like that:
1. for server in addBlock(), we don't call 
   dir.persistBlocks(src, pendingFile); and
   getEditLog().logSync();
2. for client, after call createBlockOutputStream(nodes, 0L, false);
   if (!success) {
     //
   } else {
     dfsClient.namenode.fsync(src, dfsClient.clientName);
   }
only after createBlockOutputStream succeed, we consider that the block is ok to log, Yes, you are right. That is the code change I am proposing.
I would like to hear some thoughts from others as well on this.
, I think directly depending on fsync call after creatBlockOutStream also will have one issue.
Suppose, if createBlockOutPutStream sucess and trying to call fsync, at the same time active NN failed and standyb becomes active. In this case, fsync call will end up persisting empty blocks details and there won't be any block collection in new Namenode related to file. When DNs reporting that created blocks, they will be invalidated saying there are no stored block available with it., Yes, i also find this problem.
We need another rpc method such as confirmAddBlock
or set the fsync as not Idempotent., i perfer to add confirmAddBlock since that make fsync not idempotent will let the actully idemponent operation as not, raw patch, {code}
   } else {
+          // confirm would failed, it is possible that a failover happened, see
+          // HDFS-4516 for more
+          success = confirmAddBlock();
+        } 
+        
{code}
Problem with this code is, when persistBlock failed you will not abaondon the block and continue retry and createBlock again.

Another potential issue with this approach is, generation stamps can jump to higher than this block genstamp before we actually persist this block. Since other blocks higher genstamp number already reached to standby, it may try invlidate this block if DN reports to standby in HA mode.

I think we need to think better approach to fix this issue. 
I will attach a testcase to reproduce this issue., Attached a testcase which will reproduce the case., The current issue is more concerned about reading the data which is already written to complete blocks and the synced data (if any) in the current block.

So what needs to be taken care is :
1. Client should be able to read all the previous blocks 
2. Client should be able to read the data in current block if any sync call from client is success.
3. Recovery of such files should be successful


So, Here is one simple solution,
1. One first sync call of new block, persist the length of the block.
2. While reading if there are no locations available for last under construction block and the length is 0, this will be considered as crashed block and will skip it. If length is non-zero, then exception will be thrown.
3. Same as #2, while recovery also, last under construction block can be removed and file can be closed.
, Here is the patch for above solution. Please review., Attached updated patch.., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12597457/HDFS-4516.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 3 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:red}-1 javadoc{color}.  The javadoc tool appears to have generated 2 warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/4810//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/4810//console

This message is automatically generated., Attaching the latest rebased patch for this issue.

Please somebody take a look at the patch. 
This is very important issue as this would fail the reading of entire file if the last block have zero locations due to client crash., {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12614572/HDFS-4516.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 3 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/5484//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/5484//console

This message is automatically generated., +1 patch looks good., Thanks Nicholas for the review! I will commit it shortly., Thanks Uma and Nicholas, SUCCESS: Integrated in Hadoop-trunk-Commit #4767 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/4767/])
HDFS-4516. Client crash after block allocation and NN switch before lease recovery for the same file can cause readers to fail forever. Contributed by Vinay. (umamahesh: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1543829)
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSClient.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/DFSClientAdapter.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestPersistBlocks.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestHASafeMode.java
, I have just committed this to trunk, branch-2 and 2.2.
Thanks a lot for your work on this JIRA.  Vinay and [~yians] 
Thanks Nicholas for the review!, FAILURE: Integrated in Hadoop-Yarn-trunk #398 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/398/])
HDFS-4516. Client crash after block allocation and NN switch before lease recovery for the same file can cause readers to fail forever. Contributed by Vinay. (umamahesh: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1543829)
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSClient.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/DFSClientAdapter.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestPersistBlocks.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestHASafeMode.java
, FAILURE: Integrated in Hadoop-Hdfs-trunk #1589 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1589/])
HDFS-4516. Client crash after block allocation and NN switch before lease recovery for the same file can cause readers to fail forever. Contributed by Vinay. (umamahesh: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1543829)
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSClient.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/DFSClientAdapter.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestPersistBlocks.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestHASafeMode.java
, FAILURE: Integrated in Hadoop-Mapreduce-trunk #1615 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1615/])
HDFS-4516. Client crash after block allocation and NN switch before lease recovery for the same file can cause readers to fail forever. Contributed by Vinay. (umamahesh: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1543829)
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSClient.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/DFSClientAdapter.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestPersistBlocks.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestHASafeMode.java
, The revision is elegant. We are benefit from the modified fsync to which the blocklength para is added.
Nice work.]