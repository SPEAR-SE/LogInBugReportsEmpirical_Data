[I'd suggest to raise the priority on this, because it makes full build {{ant test}} to fail all the time., Agreed, I'll have a patch out soon., Patch attached. The project split means the libhdfs test needs to access both the hdfs and common respos. The test lives in and is run out of the hdfs repo, however it runs an instance of hdfs, and therefore needs access to the common repo's bin directory. test-libhdfs.sh runs the hdfs instance out of the common repo (build/test/libhdfs and sub-directories get created there) since hadoop-daemon.sh makes doing otherwise a pain. 

*This means the test now requires setting HADOOP_CORE_HOME.* Once HDFS-621 is checked in it would be nice to convert this test to run a MiniDFS cluster and no longer depend on a common repo. It doesn't seem like running one-daemon per process using the traditional startup scripts adds much additional coverage. Reasonable?

To run the test:
{{export HADOOP_CORE_HOME=<common repo dir>}}
{{ant -Dcompile.c\+\+=true -Dlibhdfs=true test-c\+\+-libhdfs}}

You may need to ant clean your common directory to remove old hdfs jar files in the root directory, build/ivy or the lib dirs., I don't think a dependency on a Common workspace is the very plausible idea. For once, it will affect Hudson's configurations and will introduce an inter-build dependencies there.

I believe a better way is to rely on the content of hadoop-core SNAPSHOT file which includes all bin/ scripts in it packed into bin.tgz file. What has to be done is to create a temp directory to unpack said bin.tgz file and then use it for the purpose of the test.

This approach will allow to make the test self-sufficient and avoid having potentially harmful dependencies., -1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12425177/hdfs-756.patch
  against trunk revision 881017.

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 13 new or modified tests.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    -1 core tests.  The patch failed core unit tests.

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h5.grid.sp2.yahoo.net/116/testReport/
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h5.grid.sp2.yahoo.net/116/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h5.grid.sp2.yahoo.net/116/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h5.grid.sp2.yahoo.net/116/console

This message is automatically generated., Slightly different modification of the proposal above is to have all needed scripts checked in along with the test.

Also, I feel kind of uncomfortable with such a 'end-to-end' test to be executed as a part of what is essentially unit/functional validation. Shall we move it to a integration test suite or something?, Hey Konstantin -- Thanks for the feedback. Using the snapshot jar should work and removes the dependency on a common repo. Since the snapshot jar is updated from maven this approach will still work if you've also got changes in a common repo that should be used when running the test. If people are OK with that I'll update the patch.  Per the above though I think this patch should be temporary, what do you think about converting this test to run a MiniDFS cluster (once HDFS-621 is in) and have a separate end-to-end test?
, I'd prefer using the snapshot jar instead of duplicating the scripts, we're going to require the snapshot jar anyway to execute. , Let's use the snapshot jar for now., bq. I think this patch should be temporary, what do you think about converting this test to run a MiniDFS cluster (once HDFS-621 is in) and have a separate end-to-end test?

I think this is a very good idea!, Here's an updated patch that creates the bin directory from the core jar. The config scripts in the bin directory assume the bin directory is named "bin" and that it lives in the hadoop home directory, so that's where the test scripts extracts it. The test script does not clobber a bin directory if it already exists, which I tested by creating an empty bin directory and checking that the tests fail because they can find the scripts to start the daemons. The tests pass after applying the patch from HDFS-727., That last part should have read "the tests fails because it can not find the scripts to start the daemons". Sorry for the noise., +1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12425498/hdfs-756-2.patch
  against trunk revision 881695.

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 3 new or modified tests.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    +1 core tests.  The patch passed core unit tests.

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h5.grid.sp2.yahoo.net/119/testReport/
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h5.grid.sp2.yahoo.net/119/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h5.grid.sp2.yahoo.net/119/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h5.grid.sp2.yahoo.net/119/console

This message is automatically generated., The patch seems Ok. However, test is failing on my linux box (see the log file), You need to apply the patch from HDFS-727 first. That's patch is ready to go just need a comitter to commit it., bq. You need to apply the patch from HDFS-727 first

yup, my bad. everything seems to be working.

+1 patch looks good, I've just committed this. Thanks Eli., Integrated in Hadoop-Hdfs-trunk-Commit #118 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-Hdfs-trunk-Commit/118/])
    . libhdfs unit tests do not run. (Eli Collins via cos).
, Integrated in Hdfs-Patch-h5.grid.sp2.yahoo.net #121 (See [http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h5.grid.sp2.yahoo.net/121/])
    . libhdfs unit tests do not run. (Eli Collins via cos).
, Integrated in Hadoop-Hdfs-trunk #150 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-Hdfs-trunk/150/])
    , Integrated in Hdfs-Patch-h2.grid.sp2.yahoo.net #81 (See [http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h2.grid.sp2.yahoo.net/81/])
    ]