[Hey there,

I was also able to reproduce this issue on a fedora 21 distribution (with linux kernel 3.16.1). Both hadoop versions 2.6.0 and 2.6.5 produced this same error. However, version 2.7.3 did not. It is worth mentioning that I tested on a pseudo-distributed cluster.
Does that mean the issue is resolved or should the same solution for [branch 2.7|https://github.com/apache/hadoop/tree/branch-2.7] be applied to [branch 2.6|https://github.com/apache/hadoop/tree/branch-2.6]?
Bellow is the output I got with and without the error:

{code:title=HADOOP 2.7.3|borderStyle=solid}
Python 2.7.8 (default, Apr 15 2015, 09:26:43)
[GCC 4.9.2 20150212 (Red Hat 4.9.2-6)] on linux2
Type "help", "copyright", "credits" or "license" for more information.
>>> import requests
>>> resp = requests.get('http://localhost:50070/webhdfs/v1/tmp/\x00/not_found.txt?op=GETFILESTATUS')
>>> resp.content
'{"RemoteException":{"exception":"FileNotFoundException","javaClassName":"java.io.FileNotFoundException","message":"File does not exist: /tmp/\\u0000/not_found.txt"}}'
>> resp.json()
{u'RemoteException': {u'exception': u'FileNotFoundException', u'javaClassName': u'java.io.FileNotFoundException', u'message': u'File does not exist: /tmp/\x00/not_found.txt'}}
{code}

{code:title=HADOOP 2.6.0 and 2.6.5|borderStyle=solid}
Python 2.7.8 (default, Apr 15 2015, 09:26:43)
[GCC 4.9.2 20150212 (Red Hat 4.9.2-6)] on linux2
Type "help", "copyright", "credits" or "license" for more information.
>>> import requests
>>> resp = requests.get('http://localhost:50070/webhdfs/v1/tmp/test/\x00/not_found.txt?op=GETFILESTATUS')
>>> resp.content
'{"RemoteException":{"exception":"FileNotFoundException","javaClassName":"java.io.FileNotFoundException","message":"File does not exist: /tmp/test/\x00/not_found.txt"}}'
>>> resp.json()
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "/usr/lib/python2.7/site-packages/requests/models.py", line 833, in json
    self.content.decode(encoding), **kwargs
  File "/usr/lib64/python2.7/json/__init__.py", line 338, in loads
    return _default_decoder.decode(s)
  File "/usr/lib64/python2.7/json/decoder.py", line 366, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/lib64/python2.7/json/decoder.py", line 382, in raw_decode
    obj, end = self.scan_once(s, idx)
ValueError: Invalid control character at: line 1 column 147 (char 146)

{code}, [~lucaslm]
Hey! Nice report! Seems like issue is indeed solved in new Hadoop versions. Thanks a lot for information! Closing this issue then.]