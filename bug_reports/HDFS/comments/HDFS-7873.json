[This patch contains a test case which reproduce the issue with the following steps:
# Launch a MiniDFSCluster
# Create a folder
# Create 10000 files inside
# Turn on safe mode, save metaspace
# Retrieve the latest FSImage and launch into OIV::webhdfs
# try a hdfs dfs -ls webhdfs://... on that folder
# Assert everything goes well and the output is as expected.

This patch also fix properly the issue, ensuring the channel is closed *after* all the content has been streamed out of the webhdfs instance., With the ASF headers., Can you please format the code with the compliance of the Hadoop coding style:

http://wiki.apache.org/hadoop/CodeReviewChecklist

I also don't understand why the unit test can effectively cover this issue. Can you explain?, When a folder contains a lot of files, the output sent back to the client is split in several packets. As {{channel.write}} call is async, it returns directly and is thus not waiting for all the data being sent, which might take some time.
Now the problem is that {{MessageEvent.getFuture()}} will return a future which is already completed because the header has been sent properly before the data (there're two calls to {{channel.write}}, one for the header, one for the content), so {{ChannelFutureListener.CLOSE}} will be called immediately, potentially before all the packets are sent across the channel. This premature close of the channel leaves the client in a incomplete response.

The test launches a MiniDFSCluster and create 10000 files in a folder because with this number, I was able to repeatably reproduce the issue. The FSImage is then generated and loaded in OIV. Finally the content of the "big" folder is listed, and output asserted. Without the patch, the exception initially reported appears here

I hope this will help.]