[Attached patch for branch-2 and trunk..

*v1 patch :*

1. As discussed with [~arpitagarwal] offline, using common log4j properties for NameNode and DataNode metrics logger.
2. Changed metrics log file name.. 

Please review.., \\
\\
| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:red}-1{color} | patch |   0m  0s | The patch command could not apply the patch during dryrun. |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12764055/HDFS-9114-trunk.01.patch |
| Optional Tests | shellcheck javadoc javac unit findbugs checkstyle |
| git revision | trunk / 151fca5 |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/12729/console |


This message was automatically generated., Re-based patch..., \\
\\
| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:red}-1{color} | pre-patch |  19m 39s | Pre-patch trunk has 2 extant Findbugs (version 3.0.0) warnings. |
| {color:green}+1{color} | @author |   0m  0s | The patch does not contain any @author tags. |
| {color:green}+1{color} | tests included |   0m  0s | The patch appears to include 1 new or modified test files. |
| {color:green}+1{color} | javac |   8m  0s | There were no new javac warning messages. |
| {color:green}+1{color} | javadoc |  10m 11s | There were no new javadoc warning messages. |
| {color:green}+1{color} | release audit |   0m 23s | The applied patch does not increase the total number of release audit warnings. |
| {color:green}+1{color} | checkstyle |   2m 31s | There were no new checkstyle issues. |
| {color:red}-1{color} | shellcheck |   0m  6s | The applied patch generated  2 new shellcheck (v0.3.3) issues (total was 20, now 22). |
| {color:green}+1{color} | whitespace |   0m  0s | The patch has no lines that end in whitespace. |
| {color:green}+1{color} | install |   1m 29s | mvn install still works. |
| {color:green}+1{color} | eclipse:eclipse |   0m 33s | The patch built with eclipse:eclipse. |
| {color:green}+1{color} | findbugs |   4m 22s | The patch does not introduce any new Findbugs (version 3.0.0) warnings. |
| {color:green}+1{color} | common tests |   7m 52s | Tests passed in hadoop-common. |
| {color:red}-1{color} | hdfs tests | 109m 31s | Tests failed in hadoop-hdfs. |
| | | 164m 40s | |
\\
\\
|| Reason || Tests ||
| Failed unit tests | hadoop.hdfs.server.datanode.TestDirectoryScanner |
|   | hadoop.hdfs.server.namenode.ha.TestQuotasWithHA |
| Timed out tests | org.apache.hadoop.hdfs.server.blockmanagement.TestDatanodeManager |
|   | org.apache.hadoop.hdfs.server.balancer.TestBalancer |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12764187/HDFS-9114-trunk.02.patch |
| Optional Tests | shellcheck javadoc javac unit findbugs checkstyle |
| git revision | trunk / 151fca5 |
| Pre-patch Findbugs warnings | https://builds.apache.org/job/PreCommit-HDFS-Build/12734/artifact/patchprocess/trunkFindbugsWarningshadoop-common.html |
| Pre-patch Findbugs warnings | https://builds.apache.org/job/PreCommit-HDFS-Build/12734/artifact/patchprocess/trunkFindbugsWarningshadoop-hdfs.html |
| shellcheck | https://builds.apache.org/job/PreCommit-HDFS-Build/12734/artifact/patchprocess/diffpatchshellcheck.txt |
| hadoop-common test log | https://builds.apache.org/job/PreCommit-HDFS-Build/12734/artifact/patchprocess/testrun_hadoop-common.txt |
| hadoop-hdfs test log | https://builds.apache.org/job/PreCommit-HDFS-Build/12734/artifact/patchprocess/testrun_hadoop-hdfs.txt |
| Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/12734/testReport/ |
| Java | 1.7.0_55 |
| uname | Linux asf901.gq1.ygridcore.net 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/12734/console |


This message was automatically generated., 1. I feel, you can also add one more env variable to define the metrics logger , similar to HDFS_AUDIT_LOGGER
2. Also these env variables needs to be updated (commented) in hadoop-env.sh and hadoop-env.cmd
3. You might need to update hdfs.cmd as well to support this in windows
4. You can set default logger to NullAppender for tests as well as these metrics outputs are not verified from the file in tests. There will be one more appender added in tests. Currently there is no NullAppender in test's log4j, you can add the following entry.
{code}
# Null Appender
log4j.appender.NullAppender=org.apache.log4j.varia.NullAppender
{code}
, The more and more I look at this, the more and more I'm inclined to revert HDFS-8880 .  A property of hadoop.metrics.log.file *greatly* implies that we're configuring the metrics2 file sink and not some HDFS-specific hook.  This is going to be *extremely* confusing for the end user.

The fact that that patch wasn't committed with documentation just makes it that much worse., I've brought up a discussion on hdfs-dev@ since this covers a bunch of diverse JIRAs.

Depending upon what sort of consensus is reached, I have different feedback for different scenarios., At this point, I'm -1 this change.

This log file is effectively a metrics sink.  Like all other metric sinks, it should be configured via the metrics2 API using those constructs.  This particular sink bypasses all of that configuration and has it's own custom configuration. There's zero reason to impact effectively the entire rest of the Hadoop platform with that poorly thought out decision (for what is essentially a debug mode) which is what this patch currently does.

Essentially, you've got two choices:

a)  if you want this patch to go forward, you're going to have to do it without hitting the shell code and without making any configuration bits appear to be from the metrics2 subsystem (which is what hadoop.metrics implies)

b) Revert HDFS-8880 and rewrite this logging mechanism to actually be a metrics2 sink, which would allow you to keep names such as hadoop.metrics

, Thanks [~aw] for initiating  discussion in Dev group

HDFS-8880 and HDFS-8953 added separate log4j configuration for metrics logger
{code}
# NameNode metrics logging.
# The default is to retain two namenode-metrics.log files up to 64MB each.
#
namenode.metrics.logger=INFO,NullAppender
log4j.logger.NameNodeMetricsLog=${namenode.metrics.logger}
log4j.additivity.NameNodeMetricsLog=false
log4j.appender.NNMETRICSRFA=org.apache.log4j.RollingFileAppender
log4j.appender.NNMETRICSRFA.File=${hadoop.log.dir}/namenode-metrics.log
log4j.appender.NNMETRICSRFA.layout=org.apache.log4j.PatternLayout
log4j.appender.NNMETRICSRFA.layout.ConversionPattern=%d{ISO8601}%m%n
log4j.appender.NNMETRICSRFA.MaxBackupIndex=1
log4j.appender.NNMETRICSRFA.MaxFileSize=64MB
#
# DataNode metrics logging.
# The default is to retain two datanode-metrics.log files up to 64MB each.
#
datanode.metrics.logger=INFO,NullAppender
log4j.logger.DataNodeMetricsLog=${datanode.metrics.logger}
log4j.additivity.DataNodeMetricsLog=false
log4j.appender.DNMETRICSRFA=org.apache.log4j.RollingFileAppender
log4j.appender.DNMETRICSRFA.File=${hadoop.log.dir}/datanode-metrics.log
log4j.appender.DNMETRICSRFA.layout=org.apache.log4j.PatternLayout
log4j.appender.DNMETRICSRFA.layout.ConversionPattern=%d{ISO8601}%m%n
log4j.appender.DNMETRICSRFA.MaxBackupIndex=1
log4j.appender.DNMETRICSRFA.MaxFileSize=64MB
{code}

In yarn also one jira is there for yarn metrics YARN-4192.

Through this jira I just want to make common configuration for all this logger.
For example:
{code}
# Metrics logging.
#
metrics.logger=INFO,NullAppender
hadoop.metrics.log.file=metrics.log
log4j.logger.MetricsLog=${metrics.logger}
log4j.additivity.MetricsLog=false
log4j.appender.METRICSRFA=org.apache.log4j.RollingFileAppender
log4j.appender.METRICSRFA.File=${hadoop.log.dir}/${hadoop.metrics.log.file}
log4j.appender.METRICSRFA.layout=org.apache.log4j.PatternLayout
log4j.appender.METRICSRFA.layout.ConversionPattern=%d{ISO8601} %m%n
log4j.appender.METRICSRFA.MaxBackupIndex=1
log4j.appender.METRICSRFA.MaxFileSize=64MB
{code}

[~arpitagarwal], [~aw], [~vinayrpet]
I you feel itâ€™s not required then we can close this jira..]