[This is current DFS behavior. We can mv, rename, delete the opened files.
If the older client still continue on that files, then they will suffer with this exception.

Even in linux, you can move the file, while other thread writing it, file content will not be reflected in moved file., Hi Uma,

Then, this issue should also come in hadoop 0.23 .

Regards,
Mitesh, On linux, if file is moved while being created, the contents are still added to the new moved location (same happened in hadoop 0.23).

{noformat}
$ ls -l temp xyz
temp:
total 0K

xyz:
total 4K
-rw-r--r-- 1 mitesh mitesh 64 Jun 13 20:10 big_file.txt
$ ls -l temp xyz
temp:
total 0K

xyz:
total 4K
-rw-r--r-- 1 mitesh mitesh 72 Jun 13 20:10 big_file.txt
{noformat}

But in hadoop 0.20.2xx the file is moved to new location with 0 bytes and creation program failed with LeaseExpiredException.
, 0.23/2.0 is no different from 0.20.205/1.0.x on this. If you don't see it in your test case, that's because the timings are different.  I have seen the same thing happening on 0.23.

This is commonly seen when users forget to close the output streams of their task output. The temporary name of the parent directory will be renamed to the final one before the last block is completed in the shutdown hook in this case. Depending on the timing, there can be data loss as well.  Namenode will eventually notice the state of the final block and take care of it.

, As explained in above comments, this is expected behaviour. Resolving.]