[By seeing the ThreadDump attached, recoverBlock(..) call is waiting to join the writer thread in ReplicaInPipeline#stopWriter().

{code}  public void stopWriter() throws IOException {
    if (writer != null && writer != Thread.currentThread() && writer.isAlive()) {
      writer.interrupt();
      try {
        writer.join();
      } catch (InterruptedException e) {
        throw new IOException("Waiting for writer thread is interrupted.");
      }
    }
  }{code}

FSDataSetImpl#initReplicaRecovery will call the above Method, but it have already locked the FSDataSet.

In the current thread dump, writer thread is one of the DataXceiver threads, which are waiting on their respective PacketResponder threads. 

# Here *writer.interrupt()* will succeed in interrupting the thread only in case if the it is in waiting/sleeping state. otherwise it will not actually intterrupt it. So it will wait till the thread completes its execution.
# writer thread is DataXceiver thread, which is waiting to join PacketResponder Thread.
# Packet Responders are waiting on *fsdataset* lock to finalize the block.

So its a deadlock.

Here ReplicaInPipeline#stopWriter() should ensure that thread is interrupted successfully.

following changes should work in this case
{code}  public void stopWriter() throws IOException {
    if (writer != null && writer != Thread.currentThread()) {
      while (writer.isAlive()) {
        writer.interrupt();
        try {
          writer.wait(100);
        } catch (InterruptedException e) {
          throw new IOException("Waiting for writer thread is interrupted.");
        }
      }
    }
  }{code}, I really would like to see this fixed in 0.23 as well., With the proposed fix, the DataXceiver thread would break out of responder.join(), but wouldn't PacketResponder keep running and do finalizeBlock() and closeBlock()? It would even try to send an ack back, which would probably fail anyway. 

Rather than letting PacketResponder asynchronously modify the state, can we make it stop?, Hi Lee,
I agree your suggestion.
But as of now there is no suggestion to stop the PacketResponder.

Following things can happen with the proposed solution,
# initReplicaRecovery(..) call will interrupt the receiver thread, but it will make the replica state to RUR and release the fsdataset lock.
# now PacketResponder may finalize the block, i.e. replica state will be changed to FINALIZED,
# then updateReplicaUnderRecovery(..) call will fail because replica is not in RUR state

I think we can restrict PacketResponder to finalize the block which is in RUR by throwing exception. In this case updateReplicaUnderRecovery(..) will not fail, and recovery will be success.
, {quote}But as of now there is no way to stop the PacketResponder.{quote}, I found out the Actual Problem.

Problem resides in PacketResponder#close()
{code}public synchronized void close() {
      while (running && ackQueue.size() != 0 && datanode.shouldRun) {
        try {
          wait();
        } catch (InterruptedException e) {
          running = false;
        }
      }
      if(LOG.isDebugEnabled()) {
        LOG.debug(myString + ": closing");
      }
      running = false;
      notifyAll();
    }{code}

Here InterruptedException is handled but, intterrupted flag is not reset. and BlockReceiver is waiting for PacketResponder to join. But PacketResponder is BLOCKED., bq. But as of now there is no way to stop the PacketResponder

When (DataXciever) writer gets interrupted, it can fire an interrupt to (PacketResponder) responder. If we put a Thread.interrupted() check in finalizeBlock() and let it bail out or throw an InterruptedException, we can stop responder. Of course, PacketResponder will also need some changes to propely handle the exception. What do you think?, Attaching the patch. Fixed as per suggestions by Lee. Please review.., -1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12533031/HDFS-3541.patch
  against trunk revision .

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 1 new or modified test files.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    -1 javadoc.  The javadoc tool appears to have generated 13 warning messages.

    +1 eclipse:eclipse.  The patch built with eclipse:eclipse.

    +1 findbugs.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    -1 core tests.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.TestDatanodeBlockScanner

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/2683//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/2683//console

This message is automatically generated., Below failures are not replated to current patch
{noformat}-1 javadoc. The javadoc tool appears to have generated 13 warning messages.

-1 core tests. The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:

org.apache.hadoop.hdfs.TestDatanodeBlockScanner

{noformat}, Patch looks pretty good to me. Just two small comments:

# Misspelled "interrupted": "Finalizing block from Inturrupted thread should fail"
# This chunk of code confuses me, since you don't use {{written}} again after the loop, and there doesn't seem to be any need to call {{write(...)}} many times:
{code}
+      int written = 0;
+      for (; written < 512;) {
+        out.writeBytes(data);
+        written += 4;
+      }
{code}

Kihwal, how does this patch look to you?, The patch looks okay but I was wondering whether the test can be improved. 

The test in the current patch does not directly recreate the original race condition. Probably an artificial deadlock can be created by creating a thread which does sleep and then kills the writer inside a {{synchronized(datanode.data)}} block. While it's sleeping, another thread could try closing the {{DFSOutputStream}}. This should fail when the writer (i.e. the {{DataXceiver}} thread) is killed and streams get closed.  After this we could verify the block is not finalized. Then we know the {{PacketResponder}} thread didn't finalize the block. 

Does it make sense?
, for the comment:
{quote}
2.This chunk of code confuses me, since you don't use written again after the loop, and there doesn't seem to be any need to call write(...) many times:
{quote}
try using util APIs already available for writing data.

@Kihwal, good point, worth asserting block finalization. , Attaching the patch which address above comments.
Thanks Lee for the hint to write test to reproduce same case., +1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12535219/HDFS-3541-2.patch
  against trunk revision .

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 1 new or modified test files.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 eclipse:eclipse.  The patch built with eclipse:eclipse.

    +1 findbugs.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    +1 core tests.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/2742//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/2742//console

This message is automatically generated., The new patch looks good. I ran the new test case without the fix. It successfully deadlocked and failed. It passed with the actual fix., +1 Patch looks good to me as well. I will commit this patch in some time., Integrated in Hadoop-Common-trunk-Commit #2433 (See [https://builds.apache.org/job/Hadoop-Common-trunk-Commit/2433/])
    HDFS-3541. Deadlock between recovery, xceiver and packet responder. Contributed by Vinay.

Submitted by:	Vinay
Reviewed by:	Uma Maheswara Rao G (Revision 1358794)

     Result = SUCCESS
umamahesh : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1358794
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestBlockRecovery.java
, Integrated in Hadoop-Hdfs-trunk-Commit #2501 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk-Commit/2501/])
    HDFS-3541. Deadlock between recovery, xceiver and packet responder. Contributed by Vinay.

Submitted by:	Vinay
Reviewed by:	Uma Maheswara Rao G (Revision 1358794)

     Result = SUCCESS
umamahesh : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1358794
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestBlockRecovery.java
, I have just committed this to trunk and branch-2.
Thanks a lot Vinay for the patch.
Also Thanks to Kihwal, Aaron for your reviews.

Submitted by:Vivay
Reviewed by:    Uma Maheswara Rao G, Kihwal Lee, Aaron

, Hi Bobby,

{quote}
I really would like to see this fixed in 0.23 as well.
{quote}
Do you mind merging it to 23 branch as you showed interest to be fixed in 0.23 as well?
, Integrated in Hadoop-Mapreduce-trunk-Commit #2451 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk-Commit/2451/])
    HDFS-3541. Deadlock between recovery, xceiver and packet responder. Contributed by Vinay.

Submitted by:	Vinay
Reviewed by:	Uma Maheswara Rao G (Revision 1358794)

     Result = FAILURE
umamahesh : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1358794
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestBlockRecovery.java
, Integrated in Hadoop-Hdfs-trunk #1098 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1098/])
    HDFS-3541. Deadlock between recovery, xceiver and packet responder. Contributed by Vinay.

Submitted by:	Vinay
Reviewed by:	Uma Maheswara Rao G (Revision 1358794)

     Result = FAILURE
umamahesh : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1358794
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestBlockRecovery.java
, Integrated in Hadoop-Mapreduce-trunk #1131 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1131/])
    HDFS-3541. Deadlock between recovery, xceiver and packet responder. Contributed by Vinay.

Submitted by:	Vinay
Reviewed by:	Uma Maheswara Rao G (Revision 1358794)

     Result = SUCCESS
umamahesh : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1358794
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestBlockRecovery.java
, @Uma,

Sorry it took me so long to respond.  Yes, I would be happy to look into do the porting, as the patch does not just apply. I filed HDFS-3622 to do this work on., Integrated in Hadoop-Hdfs-trunk-Commit #2508 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk-Commit/2508/])
    HDFS-3541. Deadlock between recovery, xceiver and packet responder. Contributed by Vinay.

Submitted by:	Vinay
Reviewed by:	Uma Maheswara Rao G (Revision 1358794)

     Result = SUCCESS
umamahesh : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1358794
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestBlockRecovery.java
, Integrated in Hadoop-Common-trunk-Commit #2441 (See [https://builds.apache.org/job/Hadoop-Common-trunk-Commit/2441/])
    HDFS-3541. Deadlock between recovery, xceiver and packet responder. Contributed by Vinay.

Submitted by:	Vinay
Reviewed by:	Uma Maheswara Rao G (Revision 1358794)

     Result = SUCCESS
umamahesh : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1358794
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestBlockRecovery.java
, Integrated in Hadoop-Hdfs-0.23-Build #316 (See [https://builds.apache.org/job/Hadoop-Hdfs-0.23-Build/316/])
    HDFS-3622. Backport HDFS-3541 to branch-0.23 (bobby via daryn) (Revision 1362150)

     Result = SUCCESS
daryn : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1362150
Files : 
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BPOfferService.java
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/FSDataset.java
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestBlockRecovery.java
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/test/unit/org/apache/hadoop/hdfs/server/datanode/TestBlockRecovery.java
]