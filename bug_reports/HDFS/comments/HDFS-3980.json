[Log Trace:

{noformat}
2012-09-26 12:18:53,761 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://*****.168:50070/getimage?getimage=1&txid=2841&storageInfo=-40:1613522265:0:CID-41727827-e93b-4764-a344-36ea765187ea
2012-09-26 12:18:55,737 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Throwable Exception in doCheckpoint
java.lang.RuntimeException: java.lang.NullPointerException
	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1137)
	at sun.net.www.protocol.http.HttpURLConnection.getHeaderField(HttpURLConnection.java:2338)
	at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:388)
	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.isNegotiate(KerberosAuthenticator.java:187)
	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:142)
	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:168)
	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:248)
	at org.apache.hadoop.security.SecurityUtil.openSecureHttpConnection(SecurityUtil.java:477)
	at org.apache.hadoop.hdfs.server.namenode.TransferFsImage.getFileClient(TransferFsImage.java:219)
	at org.apache.hadoop.hdfs.server.namenode.TransferFsImage.downloadImageToStorage(TransferFsImage.java:82)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$3.run(SecondaryNameNode.java:374)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$3.run(SecondaryNameNode.java:361)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1232)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:454)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:319)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$2.run(SecondaryNameNode.java:286)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:337)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1212)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:282)
	at java.lang.Thread.run(Thread.java:662)
Caused by: java.lang.NullPointerException
	at sun.net.www.protocol.http.NegotiateAuthentication.setHeaders(NegotiateAuthentication.java:161)
	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1294)
	at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:379)
	... 22 more
2012-09-26 12:18:57,456 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at host-***-168/*****.168
************************************************************/

{noformat}, Attached configurations.., Same tried for HA...Standby Namenode is also throwing NPE.Please check following trace from Standby Namenode

{noformat}
2012-09-26 03:17:13,009 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/SEPT26/Security/install/hadoop/namenode/hadoop-root/dfs/name/current/fsimage_0000000000000000015, cpktTxId=0000000000000000015)
2012-09-26 03:17:13,045 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://1****.168:50070/getimage?putimage=1&txid=19&port=50070&storageInfo=-40:1224627981:0:CID-228c6cac-4a99-4359-aadf-e9904f01e1d7
2012-09-26 03:17:13,111 ERROR org.apache.hadoop.hdfs.server.namenode.ha.StandbyCheckpointer: Exception in doCheckpoint
java.lang.RuntimeException: java.lang.NullPointerException
	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1137)
	at sun.net.www.protocol.http.HttpURLConnection.getHeaderField(HttpURLConnection.java:2338)
	at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:388)
	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.isNegotiate(KerberosAuthenticator.java:187)
	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:142)
	at 

{noformat}, I've seen this error occur before with out-of-date keytab files, i.e. keytab files which contain info for principals (or KVNOs) which are no longer current. Brahma, could you please check on this possibility?, Hi ATM,

Thanks for look..I had created keytab files again and checked..But I got same problem.


{code}
try {
            GSSManager gssManager = GSSManager.getInstance();
            String servicePrincipal = KerberosUtil.getWebDfsPrincipalAndReset();
            if (servicePrincipal == null) {
              servicePrincipal = "HTTP/"
                  + KerberosAuthenticator.this.url.getHost();
            }
            Oid oid = KerberosUtil.getOidInstance("NT_GSS_KRB5_PRINCIPAL");
            GSSName serviceName = gssManager.createName(servicePrincipal,
                                                        oid);

{code}
Here I have one more doubt..getWebDfsPrincipalAndReset() is returning null..Hence principal is HTTP/hostname which is not added in the KDC and then ticket is failing like following..

Oct 04 03:07:43 host-*******-168 krb5kdc[24598](info): TGS_REQ (6 etypes {3 1 23 16 17 18}) *******.168: ISSUE: authtime 1349300202, etypes {rep=23 tkt=18 ses=23}, hdfs/hadoop@HADOOP.COM for hdfs/hadoop@HADOOP.COM
Oct 04 03:07:43 host-*******-168 krb5kdc[24598](info): TGS_REQ (6 etypes {3 1 23 16 17 18}) *******.168: ISSUE: authtime 1349300202, etypes {rep=23 tkt=18 ses=23}, hdfs/hadoop@HADOOP.COM for hdfs/hadoop@HADOOP.COM
Oct 04 03:07:43 host-*******-168 krb5kdc[24598](info): TGS_REQ (6 etypes {3 1 23 16 17 18}) *******.168: ISSUE: authtime 1349300202, etypes {rep=23 tkt=18 ses=23}, hdfs/hadoop@HADOOP.COM for HTTP/*******.168@HADOOP.COM
Oct 04 03:07:43 host-*******-168 krb5kdc[24598](info): TGS_REQ (6 etypes {3 1 23 16 17 18}) *******.168: ISSUE: authtime 1349300202, etypes {rep=23 tkt=18 ses=23}, hdfs/hadoop@HADOOP.COM for HTTP/*******.168@HADOOP.COM

Please help me this anything I am missing,Why Ticket and Principal both are coming as null..?

(principal and token are coming null while authenticating so getWebDfsPrincipalAndReset() are coming as null..)
, Hi Brahma, can you tell me exactly what you did to generate the keytab in question? It's unfortunately quite easy to accidentally invalidate a keytab for a given principal if you later export another keytab including entries for the same principal.

The fact that servicePrincipal is null is interesting, and I would guess that it's due to having not properly configured the relevant principal setting in your configs. One things confuses me, however: I can't find the method KerberosUtil#getWebDfsPrincipalAndReset in any version of Hadoop that I'm aware of. What exact version are you experiencing this with?, [~atm] 
Thanks a lot for reply..

{quote}
can you tell me exactly what you did to generate the keytab in question? It's unfortunately quite easy to accidentally invalidate a keytab for a given principal if you later export another keytab including entries for the same principal
{quote}
I have generated keytab using following

xst -norandkey -k /etc/hadoop/hdfs.keytab hdfs/(hostname of machine)@HADOOP.COM
xst -norandkey -k /etc/hadoop/hdfs.keytab HTTP/(hostname of machine)@HADOOP.COM
and these two only I had configured..Please check following link for same..

https://issues.apache.org/jira/browse/HDFS-4043?focusedCommentId=13478670&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13478670
{quote}
 I can't find the method KerberosUtil#getWebDfsPrincipalAndReset in any version of Hadoop that I'm aware of. What exact version are you experiencing this with?
{quote}

Internally we had added this one.I removed that(getWebDfsPrincipalAndReset) one executed even then checkpoint is failing by throwing followig exception..


{noformat}
2012-10-18 10:04:55,907 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://10.***.177:50070/getimage?getimage=1&txid=280&storageInfo=-40:85372811:0:CID-86a868d5-df3a-4a3c-b068-cc9a3bafec9b
2012-10-18 10:05:21,943 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:hdfs/linux-177@HADOOP.COM (auth:KERBEROS) cause:java.io.IOException: Exception trying to open authenticated connection to http://10.***.177:50070/getimage?getimage=1&txid=280&storageInfo=-40:85372811:0:CID-86a868d5-df3a-4a3c-b068-cc9a3bafec9b
2012-10-18 10:05:21,944 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Exception trying to open authenticated connection to http://10.***.177:50070/getimage?getimage=1&txid=280&storageInfo=-40:85372811:0:CID-86a868d5-df3a-4a3c-b068-cc9a3bafec9b
	at org.apache.hadoop.security.SecurityUtil.openSecureHttpConnection(SecurityUtil.java:510)
	at org.apache.hadoop.hdfs.server.namenode.TransferFsImage.doGetUrl(TransferFsImage.java:229)
	at org.apache.hadoop.hdfs.server.namenode.TransferFsImage.getFileClient(TransferFsImage.java:222)
	at org.apache.hadoop.hdfs.server.namenode.TransferFsImage.downloadImageToStorage(TransferFsImage.java:86)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$3.run(SecondaryNameNode.java:399)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$3.run(SecondaryNameNode.java:385)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1367)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:384)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:477)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:343)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$2.run(SecondaryNameNode.java:310)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:337)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1347)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:450)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:306)
	at java.lang.Thread.run(Thread.java:662)
Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - UNKNOWN_SERVER)
	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:273)
	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:169)
	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:232)
	at org.apache.hadoop.security.SecurityUtil.openSecureHttpConnection(SecurityUtil.java:508)
	... 18 more
Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - UNKNOWN_SERVER)
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:663)
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:230)
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:162)
	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:252)
	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:228)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:228)
	... 21 more
Caused by: KrbException: Server not found in Kerberos database (7) - UNKNOWN_SERVER
	at sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:64)
	at sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:185)
	at sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:294)
	at sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:106)
	at sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:557)
	at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:594)
	... 28 more
Caused by: KrbException: Identifier doesn't match expected value (906)
	at sun.security.krb5.internal.KDCRep.init(KDCRep.java:133)
	at sun.security.krb5.internal.TGSRep.init(TGSRep.java:58)
	at sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:53)
	at sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:46)
	... 33 more
{noformat}

Please correct me If I am wrong..

, Hi Brahma, that keytab config looks fine. Regarding the new stack trace you included above, my guess would be that you've misconfigured the expected principal name of the NN.

At this point I think we should perhaps close this JIRA as invalid, and move this conversation to user@hadoop.apache.org. I don't think this is an actual bug, but rather a misconfiguration of some sort. What do you think, Brahma? We could certainly reopen this JIRA if it proves to be an actual bug., HI ATM,

I got cause,
fs.default.name I configured as IP and then principal coming as HTTP/IP(Usually it should be HTTP/hostname) which is not present in KDC.
After changing that to hostname it's working fine..
{code}
 String servicePrincipal = KerberosUtil.getServicePrincipal("HTTP",
                KerberosAuthenticator.this.url.getHost());
{code}
here URL will take from fs.default.name..Since I configured as IP,principal is coming as HTTP/IP which is not present.
I think following need to look as part of this defect...Once you finalize I'll duplicate HDFS-4043
[~ahadr] comment from HDFS-4043
{quote}
KerberosAuthenticator.this.url.getHost() call does not always return the fully qualified host name, and thus causes the namenode to login to fail due to kerberos's inability to find a matching hdfs principal in the hdfs.keytab file. Instead it should use InetAddress.getCanonicalHostName. This is consistent with what is used internally by SecurityUtil.java to login in other services, such as the DataNode.
{quote}

Thanks
Brahma.
, Yep, sounds like this was just a little misconfiguration. Let's go ahead and close this JIRA., [~atm]
I have two doubts.. 
i) Even If we configure IP, It should be resolved rite.(as I mentioned in defect, host-name resolution should be done rite.).
ii) NPE,can we address NPE ?

Please let me know your comments..?
, bq. i) Even If we configure IP, It should be resolved rite.(as I mentioned in defect, host-name resolution should be done rite.).

I suppose we could perform reverse DNS on the configured fs.defaultFS, but I must admit that I don't understand the use case for configuring an explicit IP address when the node in question does indeed have an externally resolvable hostname that could be used.

bq. NPE,can we address NPE ?

I'm pretty sure that the NPE itself is actually a bug in the JDK. We might be able to check for a specific Hadoop misconfiguration at a higher level so that we never reach the code that will cause the NPE, but doing so in such a way that would cover all possible cases of this NPE might prove difficult., This is HADOOP-9363 surfacing]