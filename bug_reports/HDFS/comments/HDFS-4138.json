[When FSNamesystem#startCommonServices() is called from initialize(), the following happens during invoking DefaultMetricsSystem.instance().register(). Before starting the backup node, a MiniDFSCluster was up and ready.

{panel}
2012-11-01 12:59:43,397 ERROR lib.MethodMetric (MethodMetric.java:snapshot(118)) - Error invoking method getTransactionsSinceLastLogRoll
	java.lang.reflect.InvocationTargetException
...
Caused by: java.lang.IllegalStateException: Bad state: UNINITIALIZED
	at com.google.common.base.Preconditions.checkState(Preconditions.java:172)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.getCurSegmentTxId(FSEditLog.java:452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getTransactionsSinceLastLogRoll(FSNamesystem.java:3488)
{panel}	

It then tries to enter the active state, which fails.

{panel}
2012-11-01 12:59:43,445 FATAL namenode.NameNode (NameNode.java:doImmediateShutdown(1291)) - Error encountered requiring NN shutdown. Shutting down immediately.
java.lang.NullPointerException
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startActiveServices(FSNamesystem.java:645)
	at org.apache.hadoop.hdfs.server.namenode.NameNode$NameNodeHAContext.startActiveServices(NameNode.java:1315)
	at org.apache.hadoop.hdfs.server.namenode.ha.ActiveState.enterState(ActiveState.java:61)
{panel}

This is caught by ExitUtil and the test fails. , When BackupNode is coming up, the following happens.

1. BackupNode#initialize() calls NameNode#initialize().
2.   NameNode#initialize() calls loadNamesystem(), which instantiates an FsImage (or BackupImage) object.
3.   It also calls startCommonServices(), which calls DefaultMetricsSystem.instance().register().
4. BackupNode#initialize() then calls runCheckpointDaemon(conf)


Before HDFS-3573, FSImage's ctor would initialize the edit log in step 2, so next steps worked. After HDFS-3573, the edit log is not initialized when step 3 and 4 run, thus causing the two exceptions reported above and failing backup node startup.

, It is normally okay and actually desired as explained in HDFS-3573. In FSNamesystem.loadFromDisk(), loadFSImage() is called right after loading the NamespaceInfo, so the edit log is initialized by the time loadNamesystem() is done.  Only BackupNode overrides loadNamesystem(), the solution will be adding a call to FSImage#initEditLog() before returning., TestBackupNode passes in trunk because HDFS-3625 added initEditLog() to BackupNode#registerWith(). But the metrics system initialization still fails showing the first exception. I think it should be done earlier in BackupNode#loadNamesystem()., Hey Kihwal. Just curious: are you planning to use the BN or just trying to fix the failing test? Would appreciate your commentary on HDFS-4114., I have a patch to fix both exceptions, but if this is going to be deprecated, we can just ignore the test cases.  I will wait at least several days for the resolution of HDFS-4114.

Depending on the outcome:

1. BackupNode becomes deprecated: Ignore the test case. Leave it unmaintained.

2. No conclusion with -1 still in effect, draging on: pull in HDFS-3625 to branch-2.  This is not complete fix for BackupNode, but will make the test to pass.

3. BackupNode gets committed developers for making it up to date (e.g. HA-compatible): I will post the complete fix., According to HDFS-4114, it looks like BackupNode is not going away any time soon.  I am attaching a minimal patch to get rid of the exception from metrics initialization.  For branch-2, we also need HDFS-3625.  , {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12552112/hdfs-4138.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/3443//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/3443//console

This message is automatically generated., Kihwal, this is not deterministic, right? I managed to reproduce it once so I have the logs. Looking. Is there a Jenkins build with the failure?, Kihwal, your analysis of the problem is absolutely correct. There is a race between startCommonServices(), which initializes metrics, and runCheckpointDaemon(), which initializes EditLog.
I also agree we should be able to move initialization of BackupImage along with its EditLog out of registerWith() into BN.loadNamesystem(), but this will require some rework of current code.
The simplest way is to modify the condition in getTransactionsSinceLastLogRoll() as you did in your patch, only we should avoid adding additional member in FSNamesystem. I did that in the patch attached.
It becomes a one-line change, only I couldn't help it and removed two redundant fields in BackupNode, which are not used and anyways replicated in Storage, and also fixed one warning.
I was able to start BN successfully with this patch., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12552235/hdfs-4138.patch
  against trunk revision .

    {color:red}-1 patch{color}.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/3449//console

This message is automatically generated., Konstantin, the new patch contains what I originally intended to do + incorporates your change to FSNamesystem., I added HDFS-3625 as a dependency. For branch-2, please apply HDFS-3625 first., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12552278/hdfs-4138.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/3453//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/3453//console

This message is automatically generated., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12552300/hdfs-4138.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/3454//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/3454//console

This message is automatically generated., Test not included: the patch removes an exception occurring in TestBackupNode., I am on trunk, so don't need to apply extra patches.
Your patch is in the right direction. 
# If you could pass nsInfo without making it a member it would be really good. This is what I meant it needs some rework. Not sure how to do it yet. If you have ideas please share.
# If you have edits initialized then you don't need the extra condition in getTransactionsSinceLastLogRoll()., After examining more the current state of BN I think we should stick with the extra condition in getTransactionsSinceLastLogRoll() and not change the order of initialization at this point. In the end it is right to return 0, because there were no rolls in the beginning.
I further found that we do not set blockPoolId in BN.namesystem, which we should. Let's add {code}namesystem.setBlockPoolId(nsInfo.getBlockPoolID());{code} and get that committed., Here is a new patch that sets the block pool id, less initialization changes., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12552476/hdfs-4138.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/3460//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/3460//console

This message is automatically generated., +1. Looks good.
Targeting this together with the dependent issue for 2.0 and 0.23, if there are no other opinions., Integrated in Hadoop-trunk-Commit #2973 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/2973/])
    HDFS-4138. BackupNode startup fails due to uninitialized edit log. Contributed by Kihwal Lee. (Revision 1406734)

     Result = SUCCESS
shv : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1406734
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/BackupNode.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java
, I committed this to trunk and branch-2.
The same problem exists in branch0.23 but the patch is not applying directly, neither two.
Kihwal would like to make a patch for 0.23?, Branch-0.23 is okay since it does not have HDFS-3573. The edit log is initialized in FSImage's constructor, which means the edit log is initialized by the time loadNamespace() returns., Integrated in Hadoop-Yarn-trunk #30 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/30/])
    HDFS-4138. BackupNode startup fails due to uninitialized edit log. Contributed by Kihwal Lee. (Revision 1406734)

     Result = SUCCESS
shv : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1406734
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/BackupNode.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java
, Integrated in Hadoop-Hdfs-trunk #1220 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1220/])
    HDFS-4138. BackupNode startup fails due to uninitialized edit log. Contributed by Kihwal Lee. (Revision 1406734)

     Result = SUCCESS
shv : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1406734
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/BackupNode.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java
, Integrated in Hadoop-Mapreduce-trunk #1250 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1250/])
    HDFS-4138. BackupNode startup fails due to uninitialized edit log. Contributed by Kihwal Lee. (Revision 1406734)

     Result = FAILURE
shv : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1406734
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/BackupNode.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java
, Integrated in Hadoop-trunk-Commit #2982 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/2982/])
    Move HDFS-3625 and HDFS-4138 under 2.0.3 (Revision 1407189)

     Result = SUCCESS
shv : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1407189
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
, Integrated in Hadoop-Yarn-trunk #31 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/31/])
    Move HDFS-3625 and HDFS-4138 under 2.0.3 (Revision 1407189)

     Result = SUCCESS
shv : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1407189
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
, Integrated in Hadoop-Hdfs-trunk #1221 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1221/])
    Move HDFS-3625 and HDFS-4138 under 2.0.3 (Revision 1407189)

     Result = SUCCESS
shv : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1407189
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
, Integrated in Hadoop-Mapreduce-trunk #1251 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1251/])
    Move HDFS-3625 and HDFS-4138 under 2.0.3 (Revision 1407189)

     Result = FAILURE
shv : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1407189
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
]