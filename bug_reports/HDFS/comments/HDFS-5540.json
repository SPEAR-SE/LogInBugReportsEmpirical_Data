[Read the [log|https://builds.apache.org/job/PreCommit-HDFS-Build/5504//testReport/org.apache.hadoop.hdfs.server.blockmanagement/TestBlocksWithNotEnoughRacks/testCorruptBlockRereplicatedAcrossRacks/]

{code}
2013-11-20 17:29:58,638 INFO  DataNode.clienttrace (BlockSender.java:sendBlock(734)) - src: /127.0.0.1:45980, dest: /127.0.0.1:47450, bytes: 516, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_1758168951_1, offset: 0, srvID: DS-655102145-67.195.138.24-45980-1384968592304, blockid: BP-62019746-67.195.138.24-1384968591859:blk_1073741825_1001, duration: 244566
Waiting for 1 corrupt replicas

2013-11-20 17:29:58,660 INFO  BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(88)) - BLOCK NameSystem.addToCorruptReplicasMap: blk_1073741825 added as corrupt on 127.0.0.1:41043 by localhost/127.0.0.1 because client machine reported it

2013-11-20 17:29:59,346 INFO  datanode.DataNode (DataXceiver.java:writeBlock(594)) - Received BP-62019746-67.195.138.24-1384968591859:blk_1073741825_1001 src: /127.0.0.1:39752 dest: /127.0.0.1:49340 of size 512
2013-11-20 17:29:59,347 INFO  BlockStateChange (BlockManager.java:logAddStoredBlock(2275)) - BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:49340 is added to blk_1073741825_1001 size 512
2013-11-20 17:29:59,347 INFO  BlockStateChange (BlockManager.java:invalidateBlock(1092)) - BLOCK* invalidateBlock: blk_1073741825_1001(same as stored) on 127.0.0.1:41043

2013-11-20 17:29:59,640 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7373)) - allowed=true ugi=jenkins (auth:SIMPLE) ip=/127.0.0.1 cmd=open  src=/testFile dst=null  perm=null
Waiting for 1 corrupt replicas
{code}

From the log we can see that, DFSTestUtil.waitCorruptReplicas check corrupt repls every 1 second, but hdfs found and recover the block just within just a second, so DFSTestUtil.waitCorruptReplicas have never detected the corrupt block, causing timeout.

, attach initial patch, make the check more often, for 1000ms to 100ms, {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12615263/HDFS-5540.v1.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/5536//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/5536//console

This message is automatically generated., I am reviewing this patch which seems a little out of sync. Binglin, would you sync the patch to latest trunk? Thanks., Strangeï¼ŒI try the patch and it applied fine. What error are you encounter?, It can be applied, but not very clean. It is typically OK for small patch like this. However, given Jenkins test already has been about 1 month, it is safer to submit a new one can applied cleanly and we can double check the Jenkins' result. 
In addition, I would suggest to follow Hadoop wiki (http://wiki.apache.org/hadoop/HowToContribute) to generate a patch that can be applied with "patch -p0"., Update the patch, now the patch can apply with p0 clean, thanks for the comments Junping!, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12619480/HDFS-5540.v2.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/5765//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/5765//console

This message is automatically generated., +1. The test failure is unrelated and will file a separated JIRA to fix it. Will commit it shortly., I have commit this to trunk and branch-2. Thanks Binglin for the patch!, SUCCESS: Integrated in Hadoop-trunk-Commit #4919 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/4919/])
HDFS-5540. Fix intermittent failure in TestBlocksWithNotEnoughRacks. (Binglin Chang via junping_du) (junping_du: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1552256)
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/DFSTestUtil.java
, FAILURE: Integrated in Hadoop-Yarn-trunk #426 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/426/])
HDFS-5540. Fix intermittent failure in TestBlocksWithNotEnoughRacks. (Binglin Chang via junping_du) (junping_du: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1552256)
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/DFSTestUtil.java
, FAILURE: Integrated in Hadoop-Mapreduce-trunk #1643 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1643/])
HDFS-5540. Fix intermittent failure in TestBlocksWithNotEnoughRacks. (Binglin Chang via junping_du) (junping_du: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1552256)
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/DFSTestUtil.java
, FAILURE: Integrated in Hadoop-Hdfs-trunk #1617 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1617/])
HDFS-5540. Fix intermittent failure in TestBlocksWithNotEnoughRacks. (Binglin Chang via junping_du) (junping_du: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1552256)
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/DFSTestUtil.java
]