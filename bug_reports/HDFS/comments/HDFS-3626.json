[Todd, is this related to the new editlog changes from HDFS-1073 or applicable 1.x also?, Not sure whether this affects the 1.0 branch as well, but I wouldn't be surprised if it does.

IMO we need two fixes:
1) we should fix at the "write" side to properly canonicalize the path before logging the operation
2) we should fix at the "read" side to canonicalize as well, so if someone ends up with edit logs from a prior version that have this issue, they could upgrade to repair the cluster., 99% sure it wasn't a regression due to HDFS-1073, but may be a regression in branch-2 due to various mkdir-related or path-handling changes. I'm going to work on a patch for trunk first, but I'll definitely check on prior versions before closing out., This patch fixes the issue in several places:

- Modifies {{FSDirectory.addFile(...)}} so that, if someone tries to create the file "/", it fails gracefully instead of throwing an NPE.
- Modifies DFSUtil.isValidName() to check for "//" in the middle of a path, since other parts of the NN barf if they hit this.
- Modifies the {{Path(URI)}} constructor that the shell was using to properly normalize the URI.

The tests check non-canonical paths via three paths: creating a Path with a URI, creating a Path from a string, and directly RPCing to the NameNode (since we don't want to rely on the client side here). When directly RPCing to the NN, rather than normalizing the path, the expected behavior is currently to reject the create.

I verified this from the commandline as described above: without the patch, I reproduced the failure to restart, and with the patch, it correctly creates the file as one would expect., (I elected not to fix the "read" side in this patch. If people think it's important, I can do so. But it seems a rare enough problem.)

I'll also look into whether this exists in prior versions., In branch-1, the problem isn't as obvious, because the shell implementation doesn't use the {{Path(URI)}} constructor. To test the server side, I modified the {{touchz}} command to use {{new Path(new URI(src))}}, and then I was able to reproduce the issue in branch-1 as well.

Since user code may do that, I think we should apply a similar fix to branch-1 before closing this out. But, I'll wait for the trunk patch to be +1ed before preparing the branch-1 patch., -1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12536333/hdfs-3626.txt
  against trunk revision .

    -1 patch.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/2812//console

This message is automatically generated., Oops, trunk moved under me. New patch rebased on trunk., -1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12536335/hdfs-3626.txt
  against trunk revision .

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 5 new or modified test files.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 eclipse:eclipse.  The patch built with eclipse:eclipse.

    +1 findbugs.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    -1 core tests.  The patch failed these unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.server.namenode.TestBackupNode
                  org.apache.hadoop.hdfs.server.common.TestJspHelper

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/2813//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/2813//console

This message is automatically generated., I was really hoping to remove {{PathData}}'s internal {{URI}} and just use {{Path}}'s {{URI}}.  This patch would prevent that from being possible...  Shouldn't the normalization just occur on the server side?

{{FsShell}} is using the {{Path(URI)}} ctor to avoid the uri being altered.  Otherwise, it caused some messages (exceptions or output) to not include the exact path supplied by the user which precludes matching output against the input paths.  This led some to invoke {{FsShell}} per path, which is very inefficient compared to invoking with multiple paths.  For that reason, {{PathData}} records the {{URI}} internally and uses that in as many places as possible, but again, I hoped to eventually remove it and use {{Path}}'s {{URI}}.

On a side note, I'm a bit concerned that ".." isn't a valid path element?  Won't this cause paths that cross through symlinks before a ".." to not resolve correctly?

, While some discussions are still happening. Since 1.1window is about to close, should we commit this patch and continue the discussion in another Jira?, I believe this patch is for 2.x, is that what you meant?, bq. Shouldn't the normalization just occur on the server side?

Well, we already normalize the Path(String) constructor, which is the much more commonly used one throughout all the code I've seen. So I think we should be consistent between the URI and String constructors.

bq. Shouldn't the normalization just occur on the server side?

I don't think so, because on the client side you at least need to resolve things like relative paths from the home directory. Or, eg, if you have a viewfs, you need to be able to handle normalization of "/mount1/../mount2/foo" on the client side in order to know that you need to go to mount2 and not mount1's NN.

My other concern with doing normalization on the server side has to do with things like lease renewal. We have to be very careful that the leases are tracked with the correct (canonical) strings and then renewed with the same strings. Of course, if we normalize consistently everywhere, this will work, but I wanted to just fix this bug here rather than try to overhaul where we do normalization.

Given the above, and given that DFSUtil _already_ checks for non-canonical elements like "../" in the path, I think this current approach is the most self-consistent, and if we want to move the normalization to server-side, we should do it separately from the bugfix. If there's a bug with "../" in symlinks, then I think that bug already exists and wouldn't be introduced by this patch, right?, Daryn/Suresh: are you guys OK with this current patch given the justification above?, I'm reluctant to approve, but I won't block it.

Regarding the normalization of symlinks, "/mount2/foo" is not supposed to normalize to "/mount1/../mount2/foo".  It's supposed to traverse the link, and then apply the ".." from that location.  Ex:
{noformat}
$ find a b -ls
62514417        0 drwxr-xr-x    4 daryn    daryn         136 Jul 18 08:18 a
62514557        0 drwxr-xr-x    3 daryn    daryn         102 Jul 18 08:17 a/a2
62514730        0 -rw-r--r--    1 daryn    daryn           0 Jul 18 08:16 a/a2/faa2
62514457        0 -rw-r--r--    1 daryn    daryn           0 Jul 18 08:15 a/fa
62514728        8 lrwxr-xr-x    1 daryn    daryn           4 Jul 18 08:16 b -> a/a2
$ ls b/..
a2/	fa
{noformat}, Correction:  "/mount1/../mount2/foo" is not supposed to normalize to "/mount2/foo".  Where's my coffee..., {code}
cmccabe@keter:~/tmp> mkdir a a/b
cmccabe@keter:~/tmp> ln -s a/b c
cmccabe@keter:~/tmp> ls -l c
lrwxrwxrwx 1 cmccabe users 3 Jul 18 10:17 c -> a/b
cmccabe@keter:~/tmp> cd c
cmccabe@keter:~/tmp/c> pwd
/home/cmccabe/tmp/c
cmccabe@keter:~/tmp/c> ls ..
b
{code}

I don't think path normalization can be done client-side, if it's going to be done in a UNIX-like way., Although it can't (entirely) be done server-side else symlinks can't cross mount points., This is especially true with ViewFs.  A symbolic link for one client could point to a totally different file/directory for another client., Daryn, 

Not sure I follow, path normalization and symlink resolution are different. Resolution needs to be partly done client-side to span file systems but this still works even if path normalization is done client side (eg given path /foo/../bar and /bar -> hdfs://someotherhost/X the path will resolve to to hdfs://someotherhost/X even if we normalize /foo/../bar to /bar client side).

Btw linking to ".." for symlinks is covered in FileContextSymlinkBaseTest#testCreateLinkToDotDot and testCreateLinkToDotDotPrefix. Sounds like we need similar tests that access paths using ".." and confirm they work as expected. I'd expect the path normalization to be done client side ie the user writing the path isn't expected to be aware of how the particular symlink target changes the resolution. , bq. /foo/../bar and /bar -> hdfs://someotherhost/X the path will resolve to to hdfs://someotherhost/X even if we normalize /foo/../bar to /bar client side

That's not necessarily true, which is what Colin and I are demonstrating.  If /foo is a link to somewhere else, the ".." is relative to the resolved location.

I'm +0 on the change.  It just means that some exceptions from the shell aren't going to necessarily contain the original path given on the cmdline.  For now it's much more important to prevent corruption in the NN., bq. That's not necessarily true, which is what Colin and I are demonstrating. If /foo is a link to somewhere else, the ".." is relative to the resolved location.

That's true for Unix paths (ie the path part of a URI) but it's true for Hadoop Paths (which are URIs). Eg see the following from TestPath:

{code}
assertEquals(new Path("/foo/bar/../baz").toString(), "/foo/baz");
{code}

We normalize the path immediately on creation, ie it doesn't matter if bar is a link here because HDFS will never see it. , Sorry, that should read *not* true for Hadoop Paths., The change here is that {{Path(URI)}} did not normalize prior to this patch, whereas {{Path(String)}} does normalize as you've demonstrated., ok, it sounds like this is working as designed then.  It's an interesting divergence from POSIX, but it sounds like there was a good reason for it.  Thanks for the explanation., bq. The change here is that Path(URI) did not normalize prior to this patch, whereas Path(String) does normalize as you've demonstrated.

Right, that's the bug here. The other Path constructors, not just Path(String) but Path(Path, Path) and friends too, normalize the path on creation.  Ie I don't think the intent was for eg this usage in the code
{code}  
new Path(new Path(uri), new Path("/"));
{code}
to normalize the path but new Path(uri) not to., New patch rebased to trunk (had some conflicts after the JUnit4-ification of the test cases), We've veered off the road, but I think Path should have been little more than a simple wrapper over a URI that allowed us to parse a URI w/o percent encoding in the path component.  The normalization in Path does annoying things like strip off a trailing slash so you can't distinguish if the URI was intended to be a directory or not.  Or the post-normalization basename of "dir1/dir2/" or "dir1/dir2/." is "dir2" and the parent is "dir1"??

I think {{uri.equals(Path(uri).toUri())}} should be true unless you explicitly asked for normalization.  I'm not objecting to the patch, just grumping about Path., +1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12537092/hdfs-3626.txt
  against trunk revision .

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 5 new or modified test files.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 eclipse:eclipse.  The patch built with eclipse:eclipse.

    +1 findbugs.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    +1 core tests.  The patch passed unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs.

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/2856//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/2856//console

This message is automatically generated., Daryn, I feel you. URIs have some goofiness too btw when you're used to Unix paths.  Btw checkout HADOOP-6427, HADOOP-8087, HADOOP-7418, HADOOP-1891 and friends., So.. any +1s? :), In DFSTestUtil#createFile why catch the root case in the test function instead of letting it go down to the fs, which is presumably a path we want to test right (eg your change to FSDirectory)?  +1 otherwise, I added that change to DFSTestUtil because, without it, we end up calling fs.mkdirs(null). That (correctly) throws NullPointerException. I hit this in one of the test cases accidentally, but I found it hard to immediately see that my test code was in fact at fault (i.e not a true HDFS bug). Does that seem reasonable?, But why do we want DFSTestUtil#createFile to throw an IOE in this case instead?  I'm +1 to this if we resolve this in a follow on jira that removes the check and fixes up the test that's creating / and is expecting an IOE instead of an NPE., No test was actually doing that. Just in the course of developing the unit tests in this patch, I accidentally did that, and was confused by the NPE. I can remove this hunk and the tests should still pass. Sound good?, Sounds good, thanks for the explanation., Attached removes the change from DFSTestUtil as discussed above., -1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12537628/hdfs-3626.txt
  against trunk revision .

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 4 new or modified test files.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 eclipse:eclipse.  The patch built with eclipse:eclipse.

    +1 findbugs.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    -1 core tests.  The patch failed these unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.TestDatanodeBlockScanner

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/2891//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/2891//console

This message is automatically generated., +1  TestDatanodeBlockScanner failure is unrelated, Just to be sure I'm not holding this up, I'm a +0.5 because I'm not happy about normalization but it's important to fix the NN corruption.  Eli's +1 is sufficient to commit., Thanks Daryn, want to file a follow-up jira so we can address your concern?, Committed to branch-2 and trunk. Does anyone have time to work on a branch-1 backport of the NameNode-side changes that reject invalid RPCs? It's less critical since the shell in branch-1 only sends pre-normalized paths and thus you have to write custom code to trigger this., Integrated in Hadoop-Common-trunk-Commit #2521 (See [https://builds.apache.org/job/Hadoop-Common-trunk-Commit/2521/])
    HDFS-3626. Creating file with invalid path can corrupt edit log. Contributed by Todd Lipcon. (Revision 1365801)

     Result = SUCCESS
todd : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1365801
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FileUtil.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/Path.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestPath.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSUtil.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSMkdirs.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSUtil.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileCreation.java
, Integrated in Hadoop-Hdfs-trunk-Commit #2586 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk-Commit/2586/])
    Amend previous commit of HDFS-3626: accidentally included a hunk from HADOOP-8621 in svn commit. Reverting that hunk (Revision 1365817)
HDFS-3626. Creating file with invalid path can corrupt edit log. Contributed by Todd Lipcon. (Revision 1365801)

     Result = SUCCESS
todd : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1365817
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FileUtil.java

todd : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1365801
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FileUtil.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/Path.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestPath.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSUtil.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSMkdirs.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSUtil.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileCreation.java
, Integrated in Hadoop-Common-trunk-Commit #2522 (See [https://builds.apache.org/job/Hadoop-Common-trunk-Commit/2522/])
    Amend previous commit of HDFS-3626: accidentally included a hunk from HADOOP-8621 in svn commit. Reverting that hunk (Revision 1365817)

     Result = SUCCESS
todd : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1365817
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FileUtil.java
, Integrated in Hadoop-Mapreduce-trunk-Commit #2542 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk-Commit/2542/])
    Amend previous commit of HDFS-3626: accidentally included a hunk from HADOOP-8621 in svn commit. Reverting that hunk (Revision 1365817)
HDFS-3626. Creating file with invalid path can corrupt edit log. Contributed by Todd Lipcon. (Revision 1365801)

     Result = FAILURE
todd : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1365817
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FileUtil.java

todd : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1365801
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FileUtil.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/Path.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestPath.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSUtil.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSMkdirs.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSUtil.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileCreation.java
, Integrated in Hadoop-Hdfs-trunk #1116 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1116/])
    Amend previous commit of HDFS-3626: accidentally included a hunk from HADOOP-8621 in svn commit. Reverting that hunk (Revision 1365817)
HDFS-3626. Creating file with invalid path can corrupt edit log. Contributed by Todd Lipcon. (Revision 1365801)

     Result = FAILURE
todd : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1365817
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FileUtil.java

todd : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1365801
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FileUtil.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/Path.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestPath.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSUtil.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSMkdirs.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSUtil.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileCreation.java
, Integrated in Hadoop-Mapreduce-trunk #1148 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1148/])
    Amend previous commit of HDFS-3626: accidentally included a hunk from HADOOP-8621 in svn commit. Reverting that hunk (Revision 1365817)
HDFS-3626. Creating file with invalid path can corrupt edit log. Contributed by Todd Lipcon. (Revision 1365801)

     Result = FAILURE
todd : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1365817
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FileUtil.java

todd : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1365801
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FileUtil.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/Path.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestPath.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSUtil.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSMkdirs.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSUtil.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileCreation.java
, I've merged this into branch-23., Integrated in Hadoop-Hdfs-0.23-Build #326 (See [https://builds.apache.org/job/Hadoop-Hdfs-0.23-Build/326/])
    svn merge -r 1365800:1365817 FIXES: HDFS-3626. Creating file with invalid path can corrupt edit log. Contributed by Todd Lipcon. (Revision 1366074)

     Result = SUCCESS
daryn : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1366074
Files : 
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/Path.java
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestPath.java
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSUtil.java
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSMkdirs.java
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSUtil.java
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileCreation.java
, Filed HDFS-3821 for a v1 backport., Can we close this since HDFS-3821 tracks HDFS1 backport?, Yep, resolving since there's a separate backport JIRA]