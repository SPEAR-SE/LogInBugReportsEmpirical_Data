[I took a quick look at ORCFile and Impala, and both of them get the length of the file beforehand and don't read past it, to work around our EOF issues.  So I don't think this will affect existing clients at all., Why return empty buffer vs raise EOF?, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12633078/HDFS-6065.001.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.TestPread

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/6323//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/6323//console

This message is automatically generated., bq. Why return empty buffer vs raise EOF?

A few reasons:
* I wanted the libhdfs interface to look the same as the java interface to avoid confusion.  We map java exceptions to errno values there, but it's unclear what errno value EOFException would be.  Of course, we could choose an arbitrary value (or even 0), but it would be difficult to stop other pieces of code from returning this value.

* We've had issues in the past with people assuming that a zero-length read will do something different than return 0 when the stream is at EOF.  (See HDFS-5672).  This interface neatly sidesteps this issue by returning the same thing for a zero-length read as an EOF.

* Making the client wait for an {{EOFException}} leads to using exceptions as flow control, which tends to get ugly.  It's a lot easier if the client can assume that any exception is a bad thing, rather than having to catch them inside a loop or something.  In my opinion, this is why the Java designers made functions like {{InputStream#read}} return a special value for EOF rather than raising {{EOFException}}., bq. Why return empty buffer vs raise EOF?

I agree with Colin.  Raw byte reading methods tend to return a sentinel value to indicate EOF.  The {{EOFException}} tends to be used only for things like {{DataInputStream#readLong}}, where you might exhaust the stream before reading a full 8 bytes, and there is no reasonable sentinel value to use in the range of possible return values.  The zero-copy API is a raw byte reading interface.

The patch mostly looks good, but it turns out that it breaks a snippet of code that I've been using as a simple example of using zero-copy:

{code}
  @Override
  public int run(String[] args) {
    FileSystem fs = null;
    FSDataInputStream is = null;

    try {
      fs = FileSystem.get(this.getConf());
      is = fs.open(new Path(args[0]));
      ByteBufferPool bbp = args.length > 1 && Boolean.valueOf(args[1]) ?
        new ElasticByteBufferPool() : null;
      EnumSet<ReadOption> readOpts = EnumSet.of(ReadOption.SKIP_CHECKSUMS);
      for (;;) {
        System.out.println("reading");
        ByteBuffer bb = is.read(bbp, BUFFER_MAX_LENGTH, readOpts);
        //if (bb == null) break; // EOF
        if (!bb.hasRemaining()) break; // EOF
        System.out.println("handling");
        byte[] bytes = new byte[bb.remaining()];
        bb.get(bytes);
        System.out.println(new String(bytes, "UTF-8"));
        is.releaseBuffer(bb);
      }
    } catch (IOException e) {
      e.printStackTrace();
    } finally {
      IOUtils.cleanup(null, is, fs);
    }

    return 0;
  }
{code}

Note the commented out EOF line.  Previously, I used null to check for EOF, and that worked.  With this patch, we stop getting nulls returned, so the code goes into an infinite loop.  I needed to switch to checking {{hasRemaining}}.  This is only a problem when using fallback buffers.  The existing code in {{ByteBufferUtil#fallbackRead}} returned null to indicate EOF:

{code}
    } finally {
      if (!success) {
        // If we got an error while reading, or if we are at EOF, we 
        // don't need the buffer any more.  We can give it back to the
        // bufferPool.
        bufferPool.putBuffer(buffer);
        buffer = null;
      }
    }
{code}

Considering zero-copy already shipped in 2.3.0, I think we need to consider backwards-compatibility.  The solutions I can think of are:
# We play a bit of revisionist history and declare that my code sample was always buggy in the first place.  :-)
# Change the code to keep returning null for EOF only if the caller is using fallback buffers.  I don't like this very much, because the caller could be forced to check both null and hasRemaining if their buffer handling code is decoupled from their reading code (i.e. background buffer handling threads).
# Change this patch to use null instead of empty buffer for its sentinel value.

Overall, I favor #3 for consistency, even though I normally prefer to avoid null returns.  Colin, what do you think?, bq. Overall, I favor #3 for consistency, even though I normally prefer to avoid null returns. Colin, what do you think?

In the interest of compatibility, I guess we can have a null return here.  In libhdfs, we can check the output of {{hadoopRzBufferGet}}.  I uploaded a new version., By the way, the "see also" jira I posted should be HDFS-5762., +1 for the patch, pending Jenkins run on v2.  I retested with my code sample unchanged, and it works now.  Thanks for making the change, Colin., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12633231/HDFS-6065.002.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 2 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.cli.TestAclCLI

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/6328//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/6328//console

This message is automatically generated., The {{TestAclCLI}} failure is unrelated.  I've posted a patch on HDFS-6063 to fix that., committed, thanks, SUCCESS: Integrated in Hadoop-trunk-Commit #5279 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/5279/])
HDFS-6065. HDFS zero-copy reads should return null on EOF when doing ZCR (cmccabe) (cmccabe: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1575109)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/HasEnhancedByteBufferAccess.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/client/ShortCircuitReplica.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/native/libhdfs/expect.h
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/native/libhdfs/hdfs.h
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/native/libhdfs/test/test_libhdfs_zerocopy.c
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestEnhancedByteBufferAccess.java
]