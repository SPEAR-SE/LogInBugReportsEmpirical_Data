[Here is the output of the dfs -cat

11/09/27 18:06:05 WARN hdfs.DFSClient: Failed to connect to /IP:1019, add to deadNodes and continuejava.io.IOException: Got error for OP_READ_BLOCK, self=/IP:55657, remote=/IP:1019, for file /some_file.txt, for block -607102961416835735_7654

11/09/27 18:06:05 INFO hdfs.DFSClient: Could not obtain block blk_-607102961416835735_7654 from any node: java.io.IOException: No live nodes contain current block. Will get new block locations from namenode and retry



at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.chooseDataNode(DFSClient.java:2093)
        at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.blockSeekTo(DFSClient.java:1897)
        at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.read(DFSClient.java:2048)
        at java.io.DataInputStream.read(DataInputStream.java:83)
        at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:68)
        at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:47)
        at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:100)
        at org.apache.hadoop.fs.FsShell.printToStdout(FsShell.java:114)
        at org.apache.hadoop.fs.FsShell.access$100(FsShell.java:49)
        at org.apache.hadoop.fs.FsShell$1.process(FsShell.java:349)
        at org.apache.hadoop.fs.FsShell$DelayedExceptionThrowing.globAndProcess(FsShell.java:1913)
        at org.apache.hadoop.fs.FsShell.cat(FsShell.java:346)
        at org.apache.hadoop.fs.FsShell.doall(FsShell.java:1557)
        at org.apache.hadoop.fs.FsShell.run(FsShell.java:1776)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:79)
        at org.apache.hadoop.fs.FsShell.main(FsShell.java:1895)



And then after this if the fsck call is made it reports the fs as healthy. It should mark the fs as corrupt., Hey Arpit, this sounds like it might be a duplicate of HDFS-2263. Do you agree?, Resolving it as duplicate of HDFS-2263, Thanks Aaron]