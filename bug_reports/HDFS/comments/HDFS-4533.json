[Added patch to take other options in start-dfs.sh., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12571164/HDFS-4533.patch
  against trunk revision .

    {color:red}-1 patch{color}.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/4008//console

This message is automatically generated., Instead of the while loop the following code will add the remaining options, right?
{code}
nameStartOpt="$nameStartOpts $@"
{code}

Did you manually test this?, Hi suresh,

I did manually test on our cluster. It does work well. I changed the patch to using $@ instead of while loop.

I generate patch under svn: "hadoop/common/branches/branch-2.0.3-alpha/hadoop-hdfs-project/hadoop-hdfs/src/main/bin", I don't think this a wrong svn directory for my patch.

, should I generate patch under svn: "hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/bin" ?, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12573006/HDFS-4533.patch
  against trunk revision .

    {color:red}-1 patch{color}.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/4067//console

This message is automatically generated., Generate patch against trunk revision., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12573007/HDFS-4533.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.server.datanode.TestDataDirs

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/4069//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/4069//console

This message is automatically generated., I think I would rather have something like this:

{code}
usage="Usage: start-dfs.sh [-upgrade|-rollback] [-nnOpt <additional NameNode options>]
{code}

that way you could do something like this:
{code}
./start-dfs.sh -nnOpt '-clusterId 123'
{code}

That way, it would be easy for us to add a way to pass options to the {{JournalNode}}, {{DataNode}}, etc. in the future.  Just dumping everything we can't parse into the NameNode arguments seems suboptimal... and will prevent us giving helpful error messages when the user messes up., +1 for the patch.

Colin, please file another jira to do what you suggested. Personally I do not think it adds value beyond what is being don now and is necessary. The current patch looks good to me., Hi Suresh,

My concern is that this change will regress error handling.

Before the patch:
{code}
cmccabe@keter:/h> ./sbin/start-dfs.sh -crazygonuts
Usage: start-dfs.sh [-upgrade|-rollback]
{code}

After the patch:
{code}
cmccabe@keter:/h> ./sbin/start-dfs.sh -crazygonuts
[... silently does the wrong thing ...]
{code}

Does that make sense?, [~cmccabe] Can you explain how after the patch the invalid option is ignored? Did you run this command with the patch? , I ran the command with the patch, and {{./sbin/start-dfs.sh -crazygonuts}} was rejected.  However, {{./sbin/start-dfs.sh -upgrade -crazygonuts}} was accepted without a visible error message.

Given that the obvious error handling cases are covered, I withdraw my earlier objection.  I still think we should add a way to pass arguments to the other daemons, but I suppose that can be added in a separate JIRA when we actually need it., Integrated in Hadoop-trunk-Commit #3739 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/3739/])
    HDFS-4533. start-dfs.sh ignores additional parameters besides -upgrade. Contributed by Fengdong Yu. (Revision 1481178)

     Result = SUCCESS
suresh : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1481178
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/bin/start-dfs.sh
, I committed the patch to trunk and branch-2. Thank you Fengdong!, Integrated in Hadoop-Yarn-trunk #206 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/206/])
    HDFS-4533. start-dfs.sh ignores additional parameters besides -upgrade. Contributed by Fengdong Yu. (Revision 1481178)

     Result = SUCCESS
suresh : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1481178
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/bin/start-dfs.sh
, Integrated in Hadoop-Hdfs-trunk #1395 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1395/])
    HDFS-4533. start-dfs.sh ignores additional parameters besides -upgrade. Contributed by Fengdong Yu. (Revision 1481178)

     Result = FAILURE
suresh : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1481178
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/bin/start-dfs.sh
, Integrated in Hadoop-Mapreduce-trunk #1422 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1422/])
    HDFS-4533. start-dfs.sh ignores additional parameters besides -upgrade. Contributed by Fengdong Yu. (Revision 1481178)

     Result = SUCCESS
suresh : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1481178
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/bin/start-dfs.sh
, [~azuryy] Can you please file icla - http://www.apache.org/licenses/icla.txt. Once you do that, I will add you as a contributor and assign this jira to you., Hi Suresh,
I Just noticed this issue was fixed, sorry for response later. I will file icla soon. Thanks., Hi Suresh,
I've send email to submit icla, Thanks., Hi Suresh,
My ICLA was confirmed, the following is from the Secretary e-mail. 

{quote}
Dear Azuryy Yu,

This message acknowledges receipt of your ICLA, which has been filed in the Apache Software Foundation records.

If you have been invited as a committer, please advise the project PMC that your ICLA has been filed.

Warm Regards,

-- Craig L Russell
Secretary, Apache Software Foundation
{quote}, [~azuryy] I added you as HDFS contributor and assigned this jira to you. Congrats and look forward to more contributions!, Thanks, Suresh., There was a bug for add addtional name node's options., I reopened this issue, because there is a minor bug, which I found during my upgrade test., Can you describe what the bug is? Also please open another Jira, add a link to that Jira in this Jira, instead of reopening this Jira. 


, there is a typo, I've uploaded the patch here.
{code}
 nameStartOpt="$nameStartOpts $@ 
{code}

it should be:
{code}
 nameStartOpt="$nameStartOpt $@
{code}

I will open a new JIRA. Thanks.
, I should have done a better job code reviewing this. In fact I might have been the reason for this - see https://issues.apache.org/jira/browse/HDFS-4533?focusedCommentId=13597719&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13597719

Thanks for the follow up [~azuryy], {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12588502/HDFS-4533_2.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/4534//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/4534//console

This message is automatically generated.]