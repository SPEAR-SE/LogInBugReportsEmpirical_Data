[Uploaded a patch to HDFS-9406 that also solves the problem here.
, I followed the same steps and written one test and got exception during deletion of s2 itself. It didnt even save fsimage. But the patch posted in HDFS-9406, issue didnt occur.
Something else we are missing here? because, since RPC itself failing here, so no chance of image corruption.

{noformat}org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at java.util.Objects.requireNonNull(Unknown Source)
	at java.util.Arrays$ArrayList.<init>(Unknown Source)
	at java.util.Arrays.asList(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.storagespaceConsumedContiguous(INodeFile.java:843)
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.storagespaceConsumed(INodeFile.java:813)
	at org.apache.hadoop.hdfs.server.namenode.snapshot.FileWithSnapshotFeature.updateQuotaAndCollectBlocks(FileWithSnapshotFeature.java:195)
	at org.apache.hadoop.hdfs.server.namenode.snapshot.FileDiff.destroyDiffAndCollectBlocks(FileDiff.java:112)
	at org.apache.hadoop.hdfs.server.namenode.snapshot.FileDiff.destroyDiffAndCollectBlocks(FileDiff.java:1)
	at org.apache.hadoop.hdfs.server.namenode.snapshot.AbstractINodeDiffList.deleteSnapshotDiff(AbstractINodeDiffList.java:78)
	at org.apache.hadoop.hdfs.server.namenode.snapshot.FileWithSnapshotFeature.cleanFile(FileWithSnapshotFeature.java:136)
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.cleanSubtree(INodeFile.java:588)
	at org.apache.hadoop.hdfs.server.namenode.INodeReference$WithName.destroyAndCollectBlocks(INodeReference.java:596)
	at org.apache.hadoop.hdfs.server.namenode.snapshot.DirectoryWithSnapshotFeature$DirectoryDiff$1.process(DirectoryWithSnapshotFeature.java:210)
	at org.apache.hadoop.hdfs.server.namenode.snapshot.DirectoryWithSnapshotFeature$DirectoryDiff$1.process(DirectoryWithSnapshotFeature.java:1)
	at org.apache.hadoop.hdfs.util.Diff.combinePosterior(Diff.java:464)
	at org.apache.hadoop.hdfs.server.namenode.snapshot.DirectoryWithSnapshotFeature$DirectoryDiff.combinePosteriorAndCollectBlocks(DirectoryWithSnapshotFeature.java:205)
	at org.apache.hadoop.hdfs.server.namenode.snapshot.DirectoryWithSnapshotFeature$DirectoryDiff.combinePosteriorAndCollectBlocks(DirectoryWithSnapshotFeature.java:1)
	at org.apache.hadoop.hdfs.server.namenode.snapshot.AbstractINodeDiffList.deleteSnapshotDiff(AbstractINodeDiffList.java:91)
	at org.apache.hadoop.hdfs.server.namenode.snapshot.DirectoryWithSnapshotFeature.cleanDirectory(DirectoryWithSnapshotFeature.java:731)
	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.cleanSubtree(INodeDirectory.java:801)
	at org.apache.hadoop.hdfs.server.namenode.snapshot.DirectorySnapshottableFeature.removeSnapshot(DirectorySnapshottableFeature.java:215)
	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.removeSnapshot(INodeDirectory.java:267)
	at org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager.deleteSnapshot(SnapshotManager.java:235)
	at org.apache.hadoop.hdfs.server.namenode.FSDirSnapshotOp.deleteSnapshot(FSDirSnapshotOp.java:221)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteSnapshot(FSNamesystem.java:5896)
{noformat}, Hi [~vinayrpet],

Thanks for trying it out. I think your test exposed a different bug in the trunk: with the same sequence I posted here, a different NPE is thrown.

The investigation work I have done so far is based on an earlier version of CDH, likely some latest change in trunk changed some old behavior. I will take a look and update later.



, Hi [~vinayrpet],

Interesting thing here, I tried latest trunk with the steps I listed and could not reproduce the same stack trace as I reported in this jira. Need to understand what happened.
, On the other hand, I did not reproduce the stack trace you listed, actually my run is successful and did not report error. The commit tip I used is 662e17b46a0f41ade6a304e12925b70b5d09fc2f.


, I could reproduce the exception reported by [~vinayrpet] in trunk. The exception was thrown when deleting snapshot s2., Looks like the NPE was caused by some recent changes on quota updating code. I.e., we've already cleared the file's block list but still try to calculate its new quota so as to get the quota usage change. It can be fixed by the following change:
{code}
--- a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java
+++ b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java
@@ -501,7 +501,7 @@ public long getHeaderLong() {
   /** @return the blocks of the file. */
   @Override // BlockCollection
   public BlockInfo[] getBlocks() {
-    return this.blocks;
+    return this.blocks == null ? BlockInfo.EMPTY_ARRAY : this.blocks;
   }
{code}

Looks like the fsimage corruption was caused by the same bug from HDFS-9406. With the fix the test case can pass., [~yzhangal], if you can confirm the test case here can be fixed by the same change in HDFS-9406, maybe we can combine the two jiras and resolve this one as duplicate?, Hi [~jingzhao],

Agree with you.

Weird thing, I tried 7f46636495e23693d588b0915f464fa7afd9102e which is the latest trunk tip and still can't not reproduce the exception stack you and [~vinayrpet] were able to see.

May I know the tip commit of your build? 

Thanks.
, Still I am able to reproduce on latest trunk. 09d831c95ba18e2892cddd749f6e06f112dda7f5

Attaching the test which i used.

, Attaching one more test, with fix to previous stack trace.

With this I am able to get below trace
{noformat}
java.lang.NullPointerException
	at org.apache.hadoop.hdfs.server.namenode.snapshot.FSImageFormatPBSnapshot$Loader.loadINodeReference(FSImageFormatPBSnapshot.java:126)
	at org.apache.hadoop.hdfs.server.namenode.snapshot.FSImageFormatPBSnapshot$Loader.loadINodeReferenceSection(FSImageFormatPBSnapshot.java:117)
	at org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf$Loader.loadInternal(FSImageFormatProtobuf.java:258)
	at org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf$Loader.load(FSImageFormatProtobuf.java:180)
	at org.apache.hadoop.hdfs.server.namenode.FSImageFormat$LoaderDelegator.load(FSImageFormat.java:228)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:883)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:867)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImageFile(FSImage.java:740)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:673)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:290)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:943)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:650)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:621)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:683)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:884)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:863)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1581){noformat}, Thanks a lot [~vinayrpet]! I really feel the power of our community!

I tried the test code you put together, it can reproduce the symptom I reported in this jira. Though the test you put together is exactly what I planned to do, what I have been trying so far is to run the sequence on a pseudo-distributed cluster. I get help from [~xiaochen] to try the same, somehow non of us could reproduce the same stack trace you reported, or the stack trace I reported in this jira with trunk. However, we are constantly able to reproduce on a CDH code base.

I'm incorporating the changes you posted here to the HDFS-9406 patch that I will post soon.

, Resolved as duplicate of HDFS-9406. Thanks.
]