[Thanks for opening new JIRA, Hajo. One thing: in the future, please try to limit 'Description' field to a self-explanatory short diagnosis of a problem and post any error messages, code snippets, etc. as 'Comment' messages., I found this in my datanode logs:

2010-10-20 15:31:17,154 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(10.17.5.3:50010, storageID=DS-266784496-78.46.65.54-50010-1287004808819, infoPort=50075, ipcPort=50020):DataXceiver
java.io.IOException: xceiverCount 257 exceeds the limit of concurrent xcievers 256
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:88)
	at java.lang.Thread.run(Thread.java:619)

2010-10-20 15:31:19,115 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(10.17.5.3:50010, storageID=DS-266784496-78.46.65.54-50010-1287004808819, infoPort=50075, ipcPort=50020):Got exception while serving blk_-8099607957427967059_1974 to /10.17.5.4:
java.net.SocketTimeoutException: 480000 millis timeout while waiting for channel to be ready for write. ch : java.nio.channels.SocketChannel[connected local=/10.17.5.3:50010 remote=/10.17.5.4:51336]
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:246)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:159)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:198)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendChunks(BlockSender.java:313)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:401)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:180)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:95)
	at java.lang.Thread.run(Thread.java:619)

and so far using this configuration snippet seems to fix the problem:

<property>
  <name>dfs.datanode.handler.count</name>
  <value>40</value>
  <description>The number of server threads for the datanode.</description>
</property>

<property>
  <name>dfs.namenode.handler.count</name>
  <value>40</value>
  <description>The number of server threads for the namenode.</description>
</property>

<property>      
  <name>dfs.datanode.max.xcievers</name>        
  <value>2048</value>   
  <description>The maximum # of threads that can be connected to a data
ndoe simultaneously. Default value is 256.      
  </description>        
</property>


So the underlying problem seems to be that when max xcievers is reached that the client does not get notified and thus reports unusable error messages., The NPE on client side is caused by this on datanode side:


2010-10-20 15:31:17,177 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(10.17.5.3:50010, storageID=DS-266784496-78.46.65.54-50010-1287004808819, infoPort=50075, ipcPort=50020):DataXceiver
java.io.IOException: xceiverCount 257 exceeds the limit of concurrent xcievers 256
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:88)
	at java.lang.Thread.run(Thread.java:619)
]