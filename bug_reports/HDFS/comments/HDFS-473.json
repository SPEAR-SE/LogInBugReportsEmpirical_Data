[This problem also exists in cygwin.  To reproduce it, you may run "ant test-contrib" (or "ant test" but it will take a longer time)., --->This problem also exists in cygwin. 

in cygwin, the error is different.  I used the old svn trunk before split reproduced the error and solved the error. 

The error is due to the environment difference between cygwin and linux.  In cygwin, ugi from "id -Gn" returns none for the user. add the following lines before "new MiniDFSCluster" in testHdfsProxyInterface()  would solve the error.

    String osName = System.getProperty("os.name");
      if (osName.indexOf("Windows") >= 0) {
    	  dfsConf.setStrings("hadoop.job.ugi", "Administrators", "Administrators");
      } else {
    	  dfsConf.setStrings("hadoop.job.ugi", "nobody", "users");
      }

In the new hdfs trunk after trunk split, the test would give different error in cygwin, probably something to do with namenode as TestDFSShell would give similar error. Here is what I got from both TestHdfsProxy and TestDFSShell.

2009-06-28 22:15:05,381 ERROR namenode.FSNamesystem (FSNamesystem.java:<init>(238)) - FSNamesystem initialization failed.
java.io.IOException: All specified directories are not accessible or do not exist.
	at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:370)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.loadFSImage(FSDirectory.java:99)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initialize(FSNamesystem.java:255)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:236)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:254)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:299)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:405)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:399)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1159)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:278)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:120), Zhiyong, thanks for checking this.

BTW, TestHdfsProxy keeps failing from [the first build|http://hudson.zones.apache.org/hudson/view/Hadoop/job/Hdfs-Patch-vesta.apache.org/0/testReport/] to [the latest build|http://hudson.zones.apache.org/hudson/view/Hadoop/job/Hdfs-Patch-vesta.apache.org/4/testReport/] in [Hudson|http://hudson.zones.apache.org/hudson/view/Hadoop/job/Hdfs-Patch-vesta.apache.org/] after the project split.  Could you take a look?  Thanks again., I think it is the same as what HDFS-439 was trying to solve, although none of us was able to reproduce the error on the dev machine. , HDFS-439 is committed. I think this jira can be closed.
, Closing this as a duplication of HDFS-439.  Thanks, Zhiyong and Raghu.]