[Patch attached. I verified on a secure cluster that hftp now works w/o setting dfs.https.port to the http port., +1 pending Jenkins, seems right to me given we're using SPNEGO auth instead of KSSL. Did you test hsftp as well?, Updated patch attached. Makes the same updates to TestHftpDelegationToken that TestHftpFileSystem required to reflect the new expected behavior. We use the configured http port (not the https port) and we no longer need to worry about using the secure port even if the user accesses hftp using an authority with port specified. The new behavior matches WebHDFS, we respect the port specified in the URI and use the http port by default., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12546800/hdfs-3983.txt
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.TestHftpDelegationToken

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/3240//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/3240//console

This message is automatically generated., {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12546815/hdfs-3983.txt
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 2 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/3241//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/3241//console

This message is automatically generated., Btw per your comment wrt Hsftp, I haven't tested it. I don't think it works or has for a while, confirmed offline a couple other people thought the same am going to start a thread about removing it., If we remove hsftp, how do we do a cross-datacenter copy where the link between them is untrusted?, By having Hftp and WebHdfs support https (via HADOOP-8581). Ie have one FileSystem implementation support both schemes., Actually Tucu pointed out offline that you need two classes because clients like curl (for webhdfs) can't check the hadoop.ssl.enabled flag. So basically there are two things here:
# Add a "webhdfss" that supports SSL
# Make sure Hsftp works with the SSL server provided by HADOOP-8581 and remove the duplicate SSL listener code in the NN (HttpServer and NameNodeHttpServer) , Btw I'm going to hold off on committing this patch for now because like HDFS-3461 it needs to support KSSL for getting the delegation token. We need this to support distcp from v1 using hftp and security., Is it not already broken in trunk? In HDFS-2617, we removed all of the Krb5CipherSuites stuff, which would indicate that it won't work regardless., Yes, it's already broken in trunk. HDFS-3699 tracks fixing this, and once that's in we'll still need to use the https port right? I'm removing the use of the https port entirely here, which we won't want to do. How about a smaller fix in the meantime that just defaults to the http port and we can make it use the https port per HDFS-3461 once HDFS-3699 is in?, IMO we should use a different scheme (via a new FileSystem client), i.e. *webhdfss* for the following reasons:

* The URLs themselves will indicate if the resource is served over a secure transport or not.
* A client may need to communicate with both webhdfs:// and webhdfss:// endpoints, thus a client config will not cut it.
, I filed HDFS-3989 to remove the duplicate Http server SSL code and update Hsftp. Tucu filed HDFS-3987 for WebHdfss.

For this jira I think we should just change the default Hftp to use the http port so secure distcp using SPNEGO works by default and in HDFS-3699 we can fall back on KSSL if SPNEGO is not enabled.
, I have marked this as blocker for 2.1.1-beta., Any update on this? Is this ready to go? Thanks., I will not be able to fix this in 2.1.1-beta timeframe. Will mark this as blocker for the GA release., Is this a dup of HDFS-3699? If so we can resolve one of the two., KSSL is deprecated and should never be used for secure deployments.]