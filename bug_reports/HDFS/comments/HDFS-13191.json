[[^HDFS-13191.001.patch] illustrates a basic fix without adding new tests, which is fairly straightforward. Unittests would be tricky without duplicating all the layers of chunk -> block -> file checksum computation in the test case, though doing so could be worthwhile as a regression test to detect when checksum implementations change even if they're internally consistent within a fresh set of tests. If I apply the DataOutputBuffer randomization change without these fixes, then TestFileChecksum fails; the test succeeds with the patch., | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 16s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  1m 13s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 17m  0s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 13m 35s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m 11s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  3m 19s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 16m 12s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  5m 17s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m 37s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 17s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  2m 32s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 12m 42s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 12m 42s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m  7s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  3m  2s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 10m 26s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  5m 51s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m 32s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  8m 38s{color} | {color:green} hadoop-common in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  1m 32s{color} | {color:green} hadoop-hdfs-client in the patch passed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 98m  7s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 38s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}207m 52s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting |
|   | hadoop.hdfs.server.namenode.ha.TestPendingCorruptDnMessages |
|   | hadoop.hdfs.server.blockmanagement.TestRBWBlockInvalidation |
|   | hadoop.hdfs.server.blockmanagement.TestBlockStatsMXBean |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:5b98639 |
| JIRA Issue | HDFS-13191 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12911860/HDFS-13191.001.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |
| uname | Linux c40c49a3aaf7 3.13.0-139-generic #188-Ubuntu SMP Tue Jan 9 14:43:09 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 329a4fd |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_151 |
| findbugs | v3.1.0-RC1 |
| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/23185/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/23185/testReport/ |
| Max. process+thread count | 4194 (vs. ulimit of 10000) |
| modules | C: hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs-client hadoop-hdfs-project/hadoop-hdfs U: . |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/23185/console |
| Powered by | Apache Yetus 0.8.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

, [~dennishuo], thanks for finding this subtle bug. How about fixing original bug by overriding {{DataOutputBuffer#getData}} to something like:
{code}public byte[] getData() { return Arrays.copyOfRange(buf, 0, count); }{code}
This will not break syntactic compatibility.
, Thanks for the input! I personally don't feel too strongly about any particular approach and the uploaded patch is intended more to illustrate the issue than necessarily be the right fix, but I do foresee the downside of modifying getData() to return only the trimmed copy of the data would include:
 # The original intent of DataOutputBuffer appears to be for the sole purpose of being able to reuse a single byte array to avoid re-allocating an array. If getData() always allocates a new array, it likely eliminates any (perceived) advantage of using DataOutputBuffer in the first place, and in fact would become the same as just using a raw ByteArrayOutputStream instead.
 # Even though its interface doesn't promise anything about the size of the returned byte[], the fact that the checksums are sensitive to it means at least some places are apparently (unintentionally) relying on the exact buffer-sizing behavior already, so changing it inside DataOutputBuffer directly has a higher risk of breaking unexpected system components.

Honestly I can't think of a good solution for any of this though. One approach that's safer but much slower is to very gradually deprecate the DataOutputBuffer entirely in favor of just using a ByteArrayOutputStream; the majority of places I've seen using it don't even benefit from "reuse" at all. Then each call site could be assessed case-by-case for impact and carefully mitigated/documented. For example, in the ones I listed in this JIRA, it would mean checksums become inconsistent during an in-place upgrade, or when comparing across HDFS versions, so an admin would have to somehow coordinate around any distcp jobs in-progress.,  Ya, it seems there is no good solution to this.
{quote} If getData() always allocates a new array, it likely eliminates any (perceived) advantage of using DataOutputBuffer in the first place{quote}
Modifying getData() to return only the trimmed copy of the array will result in overhead of new byte array allocation. Although we can minimize this by wrapping it with an if condition. (Create new copy only when count< length). 
{quote}Even though its interface doesn't promise anything about the size of the returned byte[], the fact that the checksums are sensitive to it means at least some places are apparently (unintentionally) relying on the exact buffer-sizing behavior already, so changing it inside DataOutputBuffer directly has a higher risk of breaking unexpected system components.{quote} Ya, but leaving it as it is may also involve risk of breaking some future functionality.
I don't feel strongly about any specific approach but leaving bug as it is may result in more innocuous  critical bugs somewhere else. At the minimum we should add more documentation to it to warn users about this bug.]