[I see that there is a semantic problem with ClientProtocol.exists() and ClientProtocol.isDir(). The locking is such that they can race with another thread that is creating the directory at the same time. It can so happen that Thread A is is executing mkdir(foodir), but before this transaction is logged into the FsEdits log, another thread B executes exists(foodir) and returns success. Right after this, the namenode shuts down and the transaction is never logged. However, the namenode had already returned "true" to the exists(foodir) call.

This appears to be a semantic bug to me., HADOOP-1513 talks about a race when dir.exists() and dir.mkdirs() is invoked by multiple threads at the same time., The code that shows this problem is in Configuration.getFile()

{noformat}

 public File getFile(String dirsProp, String path) {
    ...
    if (dir.exists() || dir.mkdirs()) {  .......... (A)
        return file;                            ...........(B)
      }
}
{noformat}

The Statement A is intended to create a directory if it does not exists. However, when executed by multiple threads/processes at the same time, Statement (A) returns false and Statement (B) does not gets executed., A comment here is that the File class's mkdirs( ) is vulnerable to the problem (as I commented https://issues.apache.org/jira/browse/HADOOP-1513#action_12507128), but File.mkdir( ) is not. File class doesn't cache updates (as is true with HDFS). 
File.mkdir( ), File.exists( ) calls are passed on to the OS. So for example, if a thread calls File.mkdir(), and, if another thread makes a call to File.exists() while the mkdir( ) is in progress, that exists( ) call will return false. So if a call to File.exists() returns true, we can be sure that the native filesystem contains that path., I tried to bring up a new 2-node 0.13.0 cluster with the namenode formatted.  I get this error every time I try to write a file (directories are okay).  I can't find a work-around., So, in my case, the problem was that the user of the fs client didn't have write permission to dfs.client.buffer.dir.  In this case, we should probably make the error message more clear., This appears to have been long resolved after we changed the way we did writes.]