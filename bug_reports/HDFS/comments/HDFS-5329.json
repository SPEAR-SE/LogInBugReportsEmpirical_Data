[{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12607532/HDFS-5329.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.TestShortCircuitLocalRead
                  org.apache.hadoop.hdfs.server.balancer.TestBalancerWithMultipleNameNodes
                  org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting
                  org.apache.hadoop.hdfs.server.blockmanagement.TestBlockTokenWithDFS
                  org.apache.hadoop.hdfs.TestDFSShell
                  org.apache.hadoop.hdfs.TestFileConcurrentReader
                  org.apache.hadoop.hdfs.server.namenode.TestListCorruptFileBlocks
                  org.apache.hadoop.hdfs.TestCrcCorruption
                  org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration
                  org.apache.hadoop.fs.viewfs.TestViewFileSystemHdfs
                  org.apache.hadoop.hdfs.server.balancer.TestBalancerWithHANameNodes
                  org.apache.hadoop.hdfs.server.namenode.TestProcessCorruptBlocks
                  org.apache.hadoop.hdfs.TestHDFSTrash
                  org.apache.hadoop.hdfs.server.blockmanagement.TestOverReplicatedBlocks
                  org.apache.hadoop.hdfs.TestClientReportBadBlock
                  org.apache.hadoop.hdfs.TestSmallBlock
                  org.apache.hadoop.fs.TestEnhancedByteBufferAccess
                  org.apache.hadoop.hdfs.server.datanode.TestBlockReplacement
                  org.apache.hadoop.hdfs.TestListPathServlet
                  org.apache.hadoop.hdfs.TestBlockReaderLocalLegacy
                  org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestDatanodeRestart
                  org.apache.hadoop.hdfs.server.namenode.TestFavoredNodesEndToEnd
                  org.apache.hadoop.hdfs.server.namenode.TestFSEditLogLoader
                  org.apache.hadoop.hdfs.server.namenode.TestAuditLogs
                  org.apache.hadoop.hdfs.TestFileAppend
                  org.apache.hadoop.hdfs.server.datanode.TestDiskError
                  org.apache.hadoop.hdfs.TestBlockReaderLocal
                  org.apache.hadoop.fs.shell.TestTextCommand
                  org.apache.hadoop.cli.TestHDFSCLI
                  org.apache.hadoop.hdfs.server.blockmanagement.TestUnderReplicatedBlocks
                  org.apache.hadoop.fs.viewfs.TestViewFsHdfs
                  org.apache.hadoop.hdfs.server.balancer.TestBalancer
                  org.apache.hadoop.hdfs.TestQuota
                  org.apache.hadoop.hdfs.TestSetrepDecreasing
                  org.apache.hadoop.hdfs.server.datanode.TestBlockReport
                  org.apache.hadoop.hdfs.TestDatanodeDeath
                  org.apache.hadoop.hdfs.TestFileStatus
                  org.apache.hadoop.hdfs.TestFileAppend3
                  org.apache.hadoop.hdfs.TestListFilesInDFS
                  org.apache.hadoop.security.TestPermissionSymlinks
                  org.apache.hadoop.fs.TestGlobPaths
                  org.apache.hadoop.hdfs.server.blockmanagement.TestBlocksWithNotEnoughRacks
                  org.apache.hadoop.hdfs.TestLeaseRecovery
                  org.apache.hadoop.hdfs.server.namenode.TestCorruptFilesJsp
                  org.apache.hadoop.hdfs.TestHftpFileSystem
                  org.apache.hadoop.hdfs.TestSetrepIncreasing
                  org.apache.hadoop.hdfs.server.balancer.TestBalancerWithNodeGroup
                  org.apache.hadoop.hdfs.server.blockmanagement.TestNodeCount
                  org.apache.hadoop.hdfs.TestReplication
                  org.apache.hadoop.hdfs.server.namenode.TestHostsFiles
                  org.apache.hadoop.hdfs.TestSafeMode
                  org.apache.hadoop.hdfs.TestDFSClientRetries
                  org.apache.hadoop.fs.TestSymlinkHdfsFileSystem
                  org.apache.hadoop.fs.TestSymlinkHdfsFileContext
                  org.apache.hadoop.hdfs.TestFileAppend4
                  org.apache.hadoop.fs.viewfs.TestViewFsAtHdfsRoot
                  org.apache.hadoop.hdfs.server.balancer.TestBalancerWithEncryptedTransfer
                  org.apache.hadoop.fs.viewfs.TestViewFileSystemAtHdfsRoot
                  org.apache.hadoop.hdfs.TestDatanodeBlockScanner
                  org.apache.hadoop.hdfs.server.namenode.TestINodeFile
                  org.apache.hadoop.hdfs.server.namenode.TestFsck
                  org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure
                  org.apache.hadoop.hdfs.TestDistributedFileSystem
                  org.apache.hadoop.hdfs.server.datanode.TestDeleteBlockPool

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/5147//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/5147//console

This message is automatically generated., Looks good at first glance if it didn't break a bunch of tests., Thanks for looking the patch.
Uploaded a new patch. Hope this one breaks fewer tests  :-), {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12607746/HDFS-5329.1.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/5162//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/5162//console

This message is automatically generated., The second patch doesn't include the first patch's change to return the path component in the returned status?  The new patch seems to expect {{startAfter}} to now be a full path instead of just the path component?  That's not right.

Could you elaborate on the actual bug you are seeing?  The linked jira mentions an issue with using inode paths, but passing back an inode path for the directory and a start after path component appears like it should work fine., The problem we have is that, NFS gateway doesn't know the name of startAfter and has to use inode id instead.
NFS protocol uses readdir and readdirplus to list directory content. In the response, each dirent has an 8-byte number verifier.

To list the content of large directories, NFS client sends multiple readdir or readdirplus requests to NFS gateway with one verifier(resume point) in the request. The verifier is basically of the same usage as "startAfter" in getListing. Since NFSv3 uses file handle to communicate and doesn't know the file name. NFS gateway has to use the inode id path as "startAfter" when sending getList request to NN, however NN currently expects "startAfter" to be just a file name. As a result, NFS gateway can't list the content of large directories. 

We have two ways to fix this issue. We can change getListing to be able to get file name from startAfter's inodeId path as in the second patch. We can also change getFileInfo to return file name as in the first patch, which seems to upset lots of unit tests. , Uploaded a new patch, which throws exception if the startAfter inode can't be found. Also update the title to reflect the real change., Instead of throwing an exception, restart the listing seems to be a better option when the startAfter inode can't be found. Uploaded a new patch., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12607919/HDFS-5329.2.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:red}-1 eclipse:eclipse{color}.  The patch failed to build with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

        {color:red}-1 release audit{color}.  The applied patch generated 1 release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.server.datanode.fsdataset.TestAvailableSpaceVolumeChoosingPolicy

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/5167//testReport/
Release audit warnings: https://builds.apache.org/job/PreCommit-HDFS-Build/5167//artifact/trunk/patchprocess/patchReleaseAuditProblems.txt
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/5167//console

This message is automatically generated., {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12607926/HDFS-5329.3.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/5169//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/5169//console

This message is automatically generated., How does NFS handle the case that the verifier file is deleted?  Why don't we do the same in HDFS?, NFS server returns the directory modification time to NFS clients.
If the client noticed the directory is changed(e,g., the startAfter file is deleted, or other files are added),  NFS client implements would redo the directory listing from the beginning, or accept whatever returned by the server. Given NFS gateway always returns directory mtime along with the listing result, it's acceptable that HDFS lists the directory form the beginning if the startAfter file can't be found. , I think we should throw exception instead of setting startAfter to empty when the inode is not found.

For the new patch, it may be better rename StartAfterNotFoundException to DirectoryListingStartAfterNotFoundException, or simply use the existing PathNotFoundException.  Patch looks good other than that., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12608111/HDFS-5329.4.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:red}-1 eclipse:eclipse{color}.  The patch failed to build with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

        {color:red}-1 release audit{color}.  The applied patch generated 1 release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/5174//testReport/
Release audit warnings: https://builds.apache.org/job/PreCommit-HDFS-Build/5174//artifact/trunk/patchprocess/patchReleaseAuditProblems.txt
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/5174//console

This message is automatically generated., Thank you, Nicholas, for reviewing the patch. I've rename StartAfterNotFoundException to DirectoryListingStartAfterNotFoundException in the new uploaded patch., {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12608133/HDFS-5329.5.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/5176//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/5176//console

This message is automatically generated., +1 patch looks good.  Thanks, Brandon., Thank you, Nicholas.  I've committed the patch., SUCCESS: Integrated in Hadoop-trunk-Commit #4592 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/4592/])
HDFS-5329. Update FSNamesystem#getListing() to handle inode path in startAfter token. Contributed by Brandon Li (brandonli: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1531617)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/DirectoryListingStartAfterNotFoundException.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestINodeFile.java
, SUCCESS: Integrated in Hadoop-Yarn-trunk #361 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/361/])
HDFS-5329. Update FSNamesystem#getListing() to handle inode path in startAfter token. Contributed by Brandon Li (brandonli: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1531617)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/DirectoryListingStartAfterNotFoundException.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestINodeFile.java
, FAILURE: Integrated in Hadoop-Hdfs-trunk #1551 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1551/])
HDFS-5329. Update FSNamesystem#getListing() to handle inode path in startAfter token. Contributed by Brandon Li (brandonli: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1531617)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/DirectoryListingStartAfterNotFoundException.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestINodeFile.java
, FAILURE: Integrated in Hadoop-Mapreduce-trunk #1577 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1577/])
HDFS-5329. Update FSNamesystem#getListing() to handle inode path in startAfter token. Contributed by Brandon Li (brandonli: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1531617)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/DirectoryListingStartAfterNotFoundException.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestINodeFile.java
, Hi Brandon,

I'm adding "nfs" as a component of this bug in addition to namenode. Would you please correct me if I'm wrong? 

Thanks.

--Yongjun]