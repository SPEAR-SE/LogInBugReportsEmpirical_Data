[I hit this as well a couple of weeks ago. Would be nice to have it fixed.

What could be considered as a "safe replica #s available" level? A min. of 3? A formula based on rounded-off average replication factor? Your ideas please! :), This has become a FEI (Frequently Encountered Issue) for new dev/QAs :)

Maybe we should introduce a dfsadmin -decommission command that handles all these logic with a --force option to automatically setrep #remaining-nodes on the files with replications > #remaining-nodes and a --force-data-loss option to immediately remove nodes (mostly for testing purpose.), If the NN is able to complete the replication of all the blocks of the decommissioning DN to other participating DNs, then that should satisfy the decommission operation.  NameNode itself already keeps track of the underplicated blocks, so it should not hold back this node from finishing decommissioning and putting it to dead node list.  If I follow this logic, the most extrem case will be when there are only 1 DN remaining and you want to decommission that.  That doesn't make sense to me, because it will render HDFS unusable, might as well, put the cluster into safemode and shut it down.  

This scenario is mostly encountered in development and QA environments where the cluster footprint is really small and tiny.  So the proposed patch should not be so drastic that it undermines the stability of the existing HDFS code base.  
]