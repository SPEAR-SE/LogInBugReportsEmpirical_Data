[This issue is different from HDFS-415 and couldn't be solved with its patch., After some debugging and analysis it has been noted that occasionally we might see an expected behavior, e.g. an exception reported back to the test. In order to see the exception I have added catch Throwable to the test. The clause does nothing but just prints the stack trace of the received exception.

This is an example when the test is able to receive exception from the client. The main difference between this case and the original one (i.e. when test was hanging) is that in the latter case DataStreamer is able to write received block and the IOException is getting back to the test and it is shutting down HDFS Cluster.
, It seems that the issue isn't in the test, but rather is caused by some thread synchronization issues withint DFSClient class. Thus the bug report is reassigned to hdfs-client component.

In order to reproduce the issue one can utilize new FI framework (HADOOP-6003). The following set of command would almost guarantee illustrate the problem:
  % ant injectfaults
  % ant run-test-hdfs -Dtestcase=TestFileCreation -Dfi.BlockReceiver=.50 -Dtest.output=yes 2>&1

It is advised to set test.output=yes because when the test is time outed JUnit will discard all its output. , In the new design of fault injection framework the above two command won't work. Instead 
{noformat}
  % ant run-test-hdfs-fault-inject -Dtestcase=TestFileCreation -Dfi.BlockReceiver=.50 -Dtest.output=yes 2>&1
{noformat}
will do everything. 

Also, the execution of non fault injection tests will be possible only after HDFS-549 commit.]