[I don't think {{(capacity == multimap.keySet().size())}} would be correct.  If multiple threads are calling the same DataNode concurrently, then there could be multiple sockets ({{Peer}} instances) mapped to the same {{DatanodeID}} (basically the DN address) in the multi-map.  {{dfs.client.socketcache.capacity}} limits the number of sockets in the cache (the values), not the number of distinct DN addresses (the keys)., Right.  {{dfs.client.socketcache.capacity}} is the capacity of the socket cache, not the number of distinct datanodes it holds.

The right size for {{dfs.client.socketcache.capacity}} depends on a few things.  The more HDFS input streams you have open at once, the more sockets you will use at once.  The more datanodes you have in your cluster, the larger you may want the cache to be, so that you get a better hit rate.

We could certainly raise the default value for this.  Probably it should be at least 32 or 64., [~rajesh.balamohan], as per the prior comments from me and Colin, we cannot make the suggested code change.  Shall we resolve this as Won't Fix?  Alternatively, do you want to keep it open as a request to increase the default cache capacity like Colin described?, I'm resolving this as Won't Fix as per prior discussion.  (Please feel free to reopen if there are further thoughts on configuration tuning.)]