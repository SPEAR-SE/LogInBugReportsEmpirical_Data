[Theoretically, this seems plausible. are you experiencing it? do u have a unit test that I can use to reliably reproduce this problem?, {noformat}
package org.apache.hadoop.hdfs.server.namenode;

import static org.junit.Assert.assertTrue;

import java.io.IOException;
import java.io.OutputStream;
import java.util.ArrayList;
import java.util.List;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FSDataOutputStream;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.hdfs.MiniDFSCluster;
import org.apache.hadoop.hdfs.protocol.Block;
import org.apache.hadoop.hdfs.protocol.LocatedBlock;
import org.apache.hadoop.hdfs.protocol.LocatedBlocks;
import org.junit.Test;

public class TestAddStoredBlockForNPE {
  
  @Test
  public void testaddStoredBlockShouldInvalidateStaleBlock() throws Exception {
    MiniDFSCluster cluster = null;
    List<String> list = new ArrayList<String>();
    list.add("test");
    try {
      Configuration conf = new Configuration();
      conf.setInt ( "dfs.block.size", 1024 );
      cluster = new MiniDFSCluster(conf, 2, true, null);
      FileSystem dfs = cluster.getFileSystem();
      String fname = "/test";
      FSDataOutputStream fsdataout = dfs.create(new Path(fname));
      int fileLen = 10 * 1024+94;
      write(fsdataout, 0, fileLen);
      FSNamesystem namesystem = cluster.getNameNode().namesystem;

      LocatedBlocks blockLocations = cluster.getNameNode().getBlockLocations(
	  fname, 0, fileLen);
      List<LocatedBlock> blockList = blockLocations.getLocatedBlocks();
      Block block = blockList.get(blockList.size() - 1).getBlock();
 
      Block block1 = new Block();
      block1.setBlockId(block.getBlockId());
      block1.setGenerationStamp(block.getGenerationStamp() - 10);
      block1.setNumBytes(block.getNumBytes() + 10);

      namesystem.blockReceived(cluster.getDataNodes().get(1).dnRegistration,
	  block1, null);
      dfs.close();
      list.remove(0);
    }

    finally {
      if (null != cluster) {
	cluster.shutdown();
	
      }
      assertTrue("The flow should have executed without nullpointer exception",
	  list.size() == 0);
    }
  }

  private static void write(OutputStream out, int offset, int length)
      throws IOException {
    final byte[] bytes = new byte[length];
    for (int i = 0; i < length; i++) {
      bytes[i] = (byte) (offset + i);
    }
    out.write(bytes);
  }
}
{noformat}, In this 
if (storedBlock != null
	  && storedBlock.getINode() != null
	  && (storedBlock.getGenerationStamp() <= block.getGenerationStamp() || storedBlock
	      .getINode().isUnderConstruction()))
What is the significance to check if INode is under construction?
Only the generationtimestamp check may be enough?

Kindly provide your comments.]