[New patch uses an existing method for filling in the name field., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12611694/HDFS-5449.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.server.blockmanagement.TestBlocksWithNotEnoughRacks
                  org.apache.hadoop.hdfs.server.balancer.TestBalancerWithNodeGroup

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/5323//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/5323//console

This message is automatically generated., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12611697/HDFS-5449.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/5324//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/5324//console

This message is automatically generated., Patch looks pretty good to me.  One question about the toDatanodeInfo change: should we do anything different if ipAddr == null but colonIdx <= 0?  Looks like we'll just NPE in that case.  Granted we _shouldn't_ see that in practice, but I noticed that the old 0.23 DatanodeInfo code that parsed the name string would assume a default port of 50010 if it was missing.  Wasn't sure if we should either default the port if missing in a similar manner or provide a more descriptive error than the resulting NPE if this does somehow happen., bq. should we do anything different if ipAddr == null but colonIdx <= 0?
This is for client consumption and defaulting to a default port may not be ideal. The current patch will put -1 in this case, so it won't NPE. But this isn't ideal either, since clients will discover the issue later. It should either NPE to be consistent with others (but less useful), or error out with a more descriptive message.  I will update the patch., The new patch throws an IOException if ipAddr or xferPort cannot be set properly.  A new test case is also added.  A slightly different patch will be needed for branch-2 since HDFS-4949 is not in branch-2. I will post the branch-2 patch once the trunk version is approved., Can:
{code}xferPort = (int)(long)(Long)m.get("xferPort"){code}
be simplied to:
{code}xferPort = m.get("xferPort").intValue(){code}?, Do we also want to add some javadoc/comment for the changes
{code}
+    m.put("name", datanodeinfo.getXferAddr());
{code}
and 
{code}
+    if (ipAddr == null) {
+      String name = getString(m, "name", null);
{code}
just explaining why we write/read the name field?, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12619408/HDFS-5449.trunk.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode
                  org.apache.hadoop.hdfs.TestDatanodeConfig

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/5761//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/5761//console

This message is automatically generated., bq. Can: xferPort = (int)(long)(Long)m.get("xferPort") be simplied to: xferPort = m.get("xferPort").intValue() ?
[~daryn]; I believe I deleted the specific line you are refering to. There are many other similar cases throughout the source file. Since the changes are not directly related to this jira or confined to the area of code this jira is modiying, please file a separate one, if you think they need to be fixed.

I will add more comments., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12619868/HDFS-5449.trunk.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.tools.offlineEditsViewer.TestOfflineEditsViewer

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/5788//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/5788//console

This message is automatically generated., +1 Looks good.  The odd casting isn't a big deal., The branch-2 version of patch is attached. It is a straight port of the trunk version. The difference is due to the use of the new get methods in trunk.  Locally tested.  PreCommit won't succeed as the patch won't apply to trunk., I've committed this to trunk and branch-2., SUCCESS: Integrated in Hadoop-trunk-Commit #4979 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/4979/])
HDFS-5449. WebHdfs compatibility broken between 2.2 and 1.x / 23.x. Contributed by Kihwal Lee. (kihwal: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1556927)
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/JsonUtil.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestJsonUtil.java
, FAILURE: Integrated in Hadoop-Yarn-trunk #448 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/448/])
HDFS-5449. WebHdfs compatibility broken between 2.2 and 1.x / 23.x. Contributed by Kihwal Lee. (kihwal: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1556927)
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/JsonUtil.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestJsonUtil.java
, FAILURE: Integrated in Hadoop-Hdfs-trunk #1640 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1640/])
HDFS-5449. WebHdfs compatibility broken between 2.2 and 1.x / 23.x. Contributed by Kihwal Lee. (kihwal: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1556927)
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/JsonUtil.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestJsonUtil.java
, SUCCESS: Integrated in Hadoop-Mapreduce-trunk #1665 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1665/])
HDFS-5449. WebHdfs compatibility broken between 2.2 and 1.x / 23.x. Contributed by Kihwal Lee. (kihwal: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1556927)
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/JsonUtil.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestJsonUtil.java
]