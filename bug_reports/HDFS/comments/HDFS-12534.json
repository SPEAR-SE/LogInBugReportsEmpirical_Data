[cc [~HuafengWang] and [~drankye] from HDFS-12222. This is basically taking Huafeng's 004 patch and extending it a little further. I'll try and post something today for discussion., This ends up being kind of complicated, since we don't have the preferredBlockSize in the LocatedBlock. We do have it in the FileStatus, but some of the client APIs only return a BlockLocation and don't query a FileStatus.

The most efficient solution is to add preferredBlockSize to the LocatedBlock proto. We already have some EC-specific fields for the LocatedStripedBlock subclass. It's hard to plumb this though, since LocatedBlock is created pretty far down in BlockManager, and the preferredBlockSize comes from the file in FSNamesystem.

We could also make the client make another RPC to get the FileStatus for EC files. This would be for the APIs that take a path and return a BlockLocation, since the LocatedFileStatus APIs already have a FileStatus. This comes at a performance cost.

I lean toward the efficient option. I didn't have time to plumb preferredBlockSize into the LocatedBlock today. I'm going to unassign myself for now in case [~HuafengWang] or someone else would like to pick this up.

Sidenote for [~vanzin], I checked S3AFileSystem and it looks like we just return a single location per file (the dummy FileSystem implementation), which [~fabbri] confirmed. Are you sure we can split within a single S3 file?, bq. Are you sure we can split within a single S3 file?

Location != split. You can have x splits all with the same location. I'm pretty sure reading from a single s3 file using FileInputFormat generates multiple tasks (one per "split"). You may want to look at how it does that, it might be all client-side based on some client-side configuration., Hi [~andrew.wang], I have a question here. 
{quote}
Applications depend on HDFS BlockLocation to understand where the split points are.
{quote}
I think currently the returned logical BlockLocation per block group has all the data block and parity block's locations. Isn't these information enough? What's the difference between splitting a single block group and multiple logical block locations here? 
, Hi [~HuafengWang], thanks for taking a look, let me try to explain in more detail based on my understanding from talking with Marcelo:

* When writing, applications write with awareness of the blocksize. They will try to pad to block boundaries, and expect the file to be splittable at the block boundaries.
* When reading, applications use the BlockLocations returned by HDFS to understand where the split points are.
* With the current EC scheme, since an entire block group is represented by a single BlockLocation, we won't get as much parallelism as we'd like. For instance, with RS(6,3) with a blocksize of 100MB, a 600MB file would be written to have six split points, but only have a single BlockLocation for the entire block group.

I haven't looked at FileInputFormat yet to figure out how this works for S3.]