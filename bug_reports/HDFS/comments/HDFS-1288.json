[If I explicitly set $HADOOP_HDFS_HOME=$HADOOP_HOME/hdfs then it works fine. But what is curious is that I do not need to explicitly set $HADOOP_MAPRED_HOME.

So there's some asymmetry in how these scripts work with HDFS and mapred. At the very least, they should print a warning that they couldn't do the dfs-side work if they can't find the scripts?
, This is a regression and should be a blocker., I haven't been able to reproduce this. I successfully ran the following with RC0 (HADOOP_HDFS_HOME was not set):

{code}
export HADOOP_HOME=...

$HADOOP_HOME/bin/hadoop namenode -format
$HADOOP_HOME/bin/start-all.sh
$HADOOP_HOME/bin/hdfs dfsadmin -safemode wait
sleep 60
$HADOOP_HOME/bin/hadoop fs -mkdir input
$HADOOP_HOME/bin/hadoop fs -put $HADOOP_HOME/LICENSE.txt input
$HADOOP_HOME/bin/hadoop jar $HADOOP_HOME/hadoop-*-examples-*.jar grep \
  input output Apache
$HADOOP_HOME/bin/hadoop fs -cat 'output/part-r-00000' | grep Apache
$HADOOP_HOME/bin/stop-all.sh
{code}

Aaron, what did you run to see this problem?, Strange, now I can't reproduce it. I might have had some other configuration state in my environment which was conflicting with this. Feel free to resolve as invalid if nobody else can reproduce this.]