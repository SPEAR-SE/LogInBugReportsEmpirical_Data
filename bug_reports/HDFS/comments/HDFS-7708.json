[Good find.  It seems like the balancer should delete its pid file on exit.  You could try atExit, or perhaps a signal handler..., Thanks [~cmccabe] for the hint. Attached simple fix. Kindly review it.

While removing pid file, its not doing special checks for 'balancer' command, considering that the same problem is applicable to all commands. Please feel free to correct me if am missing anything., Hi Rakesh,

Thanks for looking at this.  However, this approach isn't going to work here.  The bash script execs java.  That means that any bash commands after the exec are not relevant, since the bash process is replaced by the Java process.  If you want a signal handler or an atexit handler, you need to do it from java., Thanks [~cmccabe] for correcting me, let me try out an approach using {{Runtime.getRuntime().addShutdownHook}} in Balancer. I hope you are also suggesting the same., Hi [~rakeshr], how is this issue going on? I'd like to take it over if you don't have time., Thanks [~ajisakaa] for the reminder and makes this alive. I'll try out the {{ShutdownHook}} based approach and will update it tomorrow (IST)., Hi [~ajisakaa], Attached patch, here I've tried {{HADOOP_PID_DIR}} env variable to find the {{balancer.pid}} file and then delete it through shutdown hook. Please review the proposal. Thanks!, | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 0s {color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:red}-1{color} | {color:red} test4tests {color} | {color:red} 0m 0s {color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue} 0m 9s {color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 9m 31s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 1m 21s {color} | {color:green} trunk passed with JDK v1.8.0_66 {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 1m 2s {color} | {color:green} trunk passed with JDK v1.7.0_91 {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 25s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 16s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 16s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 2m 39s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 46s {color} | {color:green} trunk passed with JDK v1.8.0_66 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 2m 12s {color} | {color:green} trunk passed with JDK v1.7.0_91 {color} |
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue} 0m 10s {color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 1m 7s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 1m 12s {color} | {color:green} the patch passed with JDK v1.8.0_66 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 1m 12s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 0m 56s {color} | {color:green} the patch passed with JDK v1.7.0_91 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 0m 56s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 25s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 8s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 15s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green} 0m 0s {color} | {color:green} Patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 2m 57s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 52s {color} | {color:green} the patch passed with JDK v1.8.0_66 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 2m 21s {color} | {color:green} the patch passed with JDK v1.7.0_91 {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 76m 30s {color} | {color:red} hadoop-hdfs in the patch failed with JDK v1.8.0_66. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 81m 56s {color} | {color:red} hadoop-hdfs in the patch failed with JDK v1.7.0_91. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green} 0m 24s {color} | {color:green} Patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 195m 30s {color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| JDK v1.8.0_66 Failed junit tests | hadoop.hdfs.shortcircuit.TestShortCircuitCache |
|   | hadoop.hdfs.server.namenode.ha.TestHAAppend |
|   | hadoop.hdfs.qjournal.TestSecureNNWithQJM |
|   | hadoop.hdfs.server.namenode.TestFileTruncate |
|   | hadoop.hdfs.server.datanode.TestBlockReplacement |
|   | hadoop.hdfs.security.TestDelegationTokenForProxyUser |
|   | hadoop.hdfs.TestFileAppend |
|   | hadoop.hdfs.server.namenode.TestNamenodeCapacityReport |
|   | hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider |
|   | hadoop.hdfs.TestDataTransferKeepalive |
|   | hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl |
| JDK v1.8.0_66 Timed out junit tests | org.apache.hadoop.hdfs.TestDFSStartupVersions |
|   | org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure190 |
|   | org.apache.hadoop.hdfs.TestFileAppend3 |
|   | org.apache.hadoop.hdfs.server.balancer.TestBalancer |
| JDK v1.7.0_91 Failed junit tests | hadoop.hdfs.TestEncryptionZones |
|   | hadoop.hdfs.server.namenode.TestNameNodeMetadataConsistency |
|   | hadoop.hdfs.TestMissingBlocksAlert |
|   | hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:0ca8df7 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12785787/HDFS-7708-002.patch |
| JIRA Issue | HDFS-7708 |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux 2cea9e947fee 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 700a176 |
| Default Java | 1.7.0_91 |
| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_66 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_91 |
| findbugs | v3.0.0 |
| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/14343/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.8.0_66.txt |
| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/14343/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.7.0_91.txt |
| unit test logs |  https://builds.apache.org/job/PreCommit-HDFS-Build/14343/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.8.0_66.txt https://builds.apache.org/job/PreCommit-HDFS-Build/14343/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.7.0_91.txt |
| JDK v1.7.0_91  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/14343/testReport/ |
| modules | C:  hadoop-hdfs-project/hadoop-hdfs  U: hadoop-hdfs-project/hadoop-hdfs |
| Max memory used | 77MB |
| Powered by | Apache Yetus 0.2.0-SNAPSHOT   http://yetus.apache.org |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/14343/console |


This message was automatically generated.

, bq. However, this approach isn't going to work here. The bash script execs java. That means that any bash commands after the exec are not relevant, since the bash process is replaced by the Java process. If you want a signal handler or an atexit handler, you need to do it from java.

IMO, its no need to handle in start-$daemon.sh script or from java. Each daemon have its own stop script provided along with them. Better to handle removal of pid file corresponding to a daemon there.
For ex: For balancer, even if the balancer is running or exited after re-balancing, let the pid file there. On error, stop script can be called, which internally check for the pid file and corresponding command is running or not. If some other process is running with same pid as in pid file, instead of killing the other process, just can remove the pid file. 
Check of whether the process is same as command we are trying to stop, can be checked, by checking the existence of {{-Dproc_balancer}} in command line.

Since this general problem for all daemons. Have seen some other Jiras also facing same problem.

I see, samething is discussed in HADOOP-12105, but according to [~aw], its not worth changing it., Thanks a lot [~vinayrpet] for pointing out the case and suggestions. Yes, I got it, this is a common problem for all daemons. IMHO, HADOOP-12105 can be used to discuss more and fix the general issue. But I'd like to get the opinion of balancer daemon case. Mostly balancer will be exited automatically after re-balancing operation and may not always execute the stop script. In that case what is your opinion in providing an additional shutdown hooks especially for the balancer daemon to cleanup/remove the balancer pid file ?, bq. Mostly balancer will be exited automatically after re-balancing operation and may not always execute the stop script. In that case what is your opinion in providing an additional shutdown hooks especially for the balancer daemon to cleanup/remove the balancer pid file ?
Since the balancer comes with stop-script, why not use it.
There balancer could be started as foreground process too {{hdfs balancer}}, if shutdownhook added, that time also it tries to delete it, no harm though.
Still, since the pid file is created by script, I tend towards handling that in script itself., Thanks [~vinayrpet]. IMHO, will listen from others opinion as well and based on their responses will wrap up this jira.

cc: [~ajisakaa], [~cmccabe], it would be great if you can pitch in and give your opinion about the necessity of {{shutdown hook}} in balancer. Thanks!, Have we actually seen this happen in trunk or is this just more bad stuff in branch-2?

At least in trunk (and maybe branch-2?), this code won't work.  It needs to know the name of the pid file which, at least today, is controlled by the shell code.

bq. There balancer could be started as foreground process too hdfs balancer, if shutdownhook added, that time also it tries to delete it, no harm though.

... except this looks like this is going to throw a pretty useless exception.  (and yes, people run balancer in the foreground all the time), bq. At least in trunk (and maybe branch-2?), this code won't work. It needs to know the name of the pid file which, at least today, is controlled by the shell code
Thanks [~aw] for the comments.  AFAIK pid file pattern contains {{COMMAND}} part, in case of balancer the pid file name will be ending with  => {{balancer.pid}} string. In my patch, I've used {{FilenameFilter}} which will be filtering out the balancer file by searching {{filename.endsWith("balancer.pid");}} file pattern under the {{HADOOP_PID_DIR}} directory., The bash code in trunk allows for major parts of it to be replaced by the user.  There is no guarantee at the Java level that the pid files being touched here are actually the pid files it wants.  There's also the problem that if someone launches multiple balancers to different clusters on the same machine with the same PID dir (easily accomplished out of the box by using the HADOOP_IDENT_STRING component), this will actually remove all of them that it has permission to remove.

So not only will this not work for various edge cases, it's actually pretty disastrous.

, Thanks again [~aw] for the explanation. [~ajisakaa] IMHO this case also can be considered in the way HADOOP-12105 jira is trying to fix, that is proposing/discussing a more generic approach. Does this makes sense to you?, Thanks Rakesh and Allen! I'll close this jira.]