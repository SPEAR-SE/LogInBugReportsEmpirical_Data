[I can think of a few ways to fix this:

1) Consider it a test error, and have the test set the pending replication timeout to a much lower value (like 5 secs). This is under the assumption that this is a rare phenomenon, and in practice we are OK waiting 10 minutes to make a new replica when this happens.

2) Add a field to the DN heartbeat which reports back a failed replication for a given block. The NN would use this to decrement the pendingReplication count, which would cause a new replication attempt to be made if it was still under-replicated.


Option 1 is clearly less risky, since it's a test-only change, but option 2 is probably "righter" and has the advantage of reducing the under-replication window in some rare cases., Implement todd's #1 suggestion, reduce dfs.replication.pending.timeout.sec to 5.  This makes the testBlockCorruptionPolicy2 pass about 9/10 times, in my looping tests., -1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12545244/hdfs3931.txt
  against trunk revision .

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 1 new or modified test files.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 eclipse:eclipse.  The patch built with eclipse:eclipse.

    +1 findbugs.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    -1 core tests.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.TestDatanodeBlockScanner

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/3195//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/3195//console

This message is automatically generated., Looks like 5s isn't enough? Failed on jenkins above and for me on my first run wit the patch., Proposed, hackish, fix in three parts:
* set DFS_NAMENODE_REPLICATION_PENDING_TIMEOUT_SEC to 5 seconds
* increase delay in waitReplication so pending replication timeouts have more than one chance to kick in
* when attempting to corrupt blocks, if the blockscanner beats us in the race, retry.

In my testing with these changes, I had just one failure in 100 iterations., +1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12545650/hdfs3931-1.txt
  against trunk revision .

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 2 new or modified test files.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 eclipse:eclipse.  The patch built with eclipse:eclipse.

    +1 findbugs.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    +1 core tests.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/3206//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/3206//console

This message is automatically generated., This ran 1030 iterations overnight without a failure (on my SSD devbox), so let me post a slightly cleaned up version and I think we're good to go., -1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12545762/hdfs3931-2.txt
  against trunk revision .

    -1 patch.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/3212//console

This message is automatically generated., waitReplicas
, Oops, auto-submitted.  Looks like the patch needs to be rebased on trunk. hdfs3931-1.txt looks cleaner so maybe -2.txt is the wrong patch? 

- I don't think we double waitReplication for everyone. Is that necessary? If so perhaps add a method that allows you to pass an attempts value.
- Ditto for waitCorruptReplicas, adding a version that lets you pass an attempts value would be cleaner
, bq. Looks like the patch needs to be rebased on trunk. hdfs3931-1.txt looks cleaner so maybe -2.txt is the wrong patch? 

I uploaded a {{git diff -b}} by accident, sorry.  I've uploaded -3.txt which should be right.

bq. I don't think we double waitReplication for everyone.

What's the downside to increasing waitReplication's iteration count?  We don't have failures frequently hitting this path, and there aren't any users that catch the TimeoutException.  I certainly could add a parameter, but it seems like just increasing the timeout from 20 seconds to 40 seconds is fine, since it only affects tests that were going to fail.

bq. Ditto for waitCorruptReplicas, adding a version that lets you pass an attempts value would be cleaner

The patch doesn't change the behavior of waitCorruptReplicas, and it's not obvious to me how I could hoist the loop in testBlockCorruptionPolicy2 down into waitCorruptReplicas., +1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12545825/hdfs3931-3.txt
  against trunk revision .

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 2 new or modified test files.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 eclipse:eclipse.  The patch built with eclipse:eclipse.

    +1 findbugs.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    +1 core tests.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/3217//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/3217//console

This message is automatically generated., bq. What's the downside to increasing waitReplication's iteration count? We don't have failures frequently hitting this path, and there aren't any users that catch the TimeoutException. I certainly could add a parameter, but it seems like just increasing the timeout from 20 seconds to 40 seconds is fine, since it only affects tests that were going to fail.

I think the answer I'm looking for is "the test is timing out in waitReplication because sometimes it takes more than 20 iterations". It's not clear to me the timeout is because 20 iterations is insufficient or the failure is due to us timing out because there's a race where we'll *never* reach all the iterations (because the block will never be sufficiently replicated). If it's the latter then bumping the count doesn't help, so I presume it's the former then? I'm surprised that there's a scenario where 20 is insufficient but it still eventually does get replicated correctly.

bq. The patch doesn't change the behavior of waitCorruptReplicas,

I was suggesting that waitCorruptReplicas could just wait longer rather than loop in the test. Why is restarting the datanodes ITERATIONS times necessary?  Is the DN restart necessary to kick the block scanner? In which case would it make the test more reliable to just trigger the DN block scan directly rather than indirectly via restart?, bq. I'm surprised that there's a scenario where 20 is insufficient but it still eventually does get replicated correctly.
The scenario is
- NN requests replication, puts block on pending replication queue.
- requested replication source is corrupt, replication fails.
- eventually NN times out pending replication queue and tries again. Block scanner has run and marked replica as corrupt so eventually we are guaranteed the replication source is not corrupt.

Without cranking DFS_NAMENODE_REPLICATION_PENDING_TIMEOUT_SEC_KEY down, we fail 1/2 tries. After speeding up pending replication timeouts, we fail 1/2*1/2*1/2... until the waitReplication loop bails. If the blockScanner has a chance to run and mark replicas corrupt, and after blockScanner finishes the replication queue has time to run, then we succeed reliably.

Without increasing the timeout from 20 seconds to 40 seconds, the test fails 1/3 times.

bq. Why is restarting the datanodes ITERATIONS times necessary?

As the test is currently structured, we're polling to notice that the corrupt replica count has increased. With the fixed blockscanner from HDFS-3828, the test fails to hit the timing window to notice corrupt replicas because the blockscanner sometimes (1/20 in my tests IIRC) wins a race and the NN deletes the corrupt replica before the test can poll it.  If this happens, we have to go back and re-try the whole "corrupt two replicas, restart their DNs, poll" loop.

So it's not "restarting the datanodes" that we are retrying here.  The thing we're retrying is "corrupt the replicas, restart the DNs, watch the corrupt count to verify it changed".
, With hdfs3931-3, my testbox ran 1000 iterations with one test failure. Without the 20->40 increase, I fail about 1/3 runs.  Without the "retry checking the corrupt count" loop, I fail 1/10 runs., Thanks for the explanation Andy. +1 to the latest patch. How about filing a jira to implement #2 so we can actually fix the issue so we don't have to work around it in the test?, I've committed this and merged to branch-2. Thanks Andy!, Integrated in Hadoop-Common-trunk-Commit #2750 (See [https://builds.apache.org/job/Hadoop-Common-trunk-Commit/2750/])
    HDFS-3931. TestDatanodeBlockScanner#testBlockCorruptionPolicy2 is broken. Contributed by Andy Isaacson (Revision 1388331)

     Result = SUCCESS
eli : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1388331
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/DFSTestUtil.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDatanodeBlockScanner.java
, Integrated in Hadoop-Hdfs-trunk-Commit #2813 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk-Commit/2813/])
    HDFS-3931. TestDatanodeBlockScanner#testBlockCorruptionPolicy2 is broken. Contributed by Andy Isaacson (Revision 1388331)

     Result = SUCCESS
eli : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1388331
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/DFSTestUtil.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDatanodeBlockScanner.java
, Integrated in Hadoop-Mapreduce-trunk-Commit #2773 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk-Commit/2773/])
    HDFS-3931. TestDatanodeBlockScanner#testBlockCorruptionPolicy2 is broken. Contributed by Andy Isaacson (Revision 1388331)

     Result = FAILURE
eli : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1388331
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/DFSTestUtil.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDatanodeBlockScanner.java
, Integrated in Hadoop-Hdfs-trunk #1172 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1172/])
    HDFS-3931. TestDatanodeBlockScanner#testBlockCorruptionPolicy2 is broken. Contributed by Andy Isaacson (Revision 1388331)

     Result = SUCCESS
eli : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1388331
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/DFSTestUtil.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDatanodeBlockScanner.java
, Integrated in Hadoop-Mapreduce-trunk #1203 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1203/])
    HDFS-3931. TestDatanodeBlockScanner#testBlockCorruptionPolicy2 is broken. Contributed by Andy Isaacson (Revision 1388331)

     Result = SUCCESS
eli : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1388331
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/DFSTestUtil.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDatanodeBlockScanner.java
, Should we close this jira?, bq. Thanks for the explanation Andy. +1 to the latest patch. How about filing a jira to implement #2 so we can actually fix the issue so we don't have to work around it in the test?

I've filed HDFS-3982 to track the DN heartbeat replication report.

bq. Should we close this jira?

Now that I've filed the other jira to track the further work, yes.]