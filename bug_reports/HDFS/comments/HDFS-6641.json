[Hello, [~brahmareddy].  There is some discussion of this topic on the original concat issue: HDFS-222.  The concat destination file must still maintain the invariant that all blocks have the same length, except for possibly the last block, which may be partially filled.  If this invariant were not maintained, then it could cause unpredictable behavior later when a client attempts to read that file.

I'm resolving this issue as Not a Problem, because I believe this is all working as designed., Hi [~cnauroth] 

{quote}
The concat destination file must still maintain the invariant that all blocks have the same length, except for possibly the last block, which may be partially filled. If this invariant were not maintained, then it could cause unpredictable behavior later when a client attempts to read that file.
I'm resolving this issue as Not a Problem, because I believe this is all working as designed.
{quote}

you mean,last block should be filled when we go for concat(like pre condition)..?  I feel, this can addressed or else need to provide reason then we can close this jira..Please correct if i am wrong.., Yes, the pre-conditions of HDFS concat right now are:
# All source files must be in the same directory.
# Replication and block size must be the same for all source files.
# All blocks must be full in all source files except the last source file.
# In the last source file, all blocks must be full except the last block., So what if source file having only block which is not full ( which is happened in my case hence I raised this jira )?, The {{concat}} method takes 2 arguments.  The first is a single {{Path}}, and this is called the target.  The second is an array of multiple {{Path}} instances, and these are called the sources.  All of the sources will get appended to the target.  The {{Path}} referred to as target must have all of its blocks full.  Once again, this is intended to maintain the invariant that an HDFS file has a consistent block size, and all blocks are fully populated except the last one.]