[I reproduced this case with the debug points.

1) created a file and hsync'ed that file.
2) triggered on BR in separate thread and blocked this call in NN side just before aquiring the fsnamesystem lock.
3) triggered one recoverlease call from separate thread and completed the call.
4) after successfully completed #3 (after commitBlockSynchronization with new genstamp), started processing the blocked BR in #2.
5) since that old BR has older genstamp, that block is getting marked as corrupt.

will attach the colored logs. 
, attched the grepped logs., in this sence, delete data is very danger.it is very easy to loss data!

 solution that resolve this issue:

when namenode find replica with genstamp not match,the namenode require it's datanode re-report block reportï¼Œ
if it is still not match,the namenode mark it corrupt.

Are you right?, @Todd, Did you look at this issue?
Want to invite you on this issue for solution discussions. It looks like, it is hard to identify the block corruption at this situation. , Hi Folks

I thought of  some sample solution for this problem please give your inputs to the same.

When any blockrecovery happen, commitBlockSynchronization is called we can store the old and new generation stamp for this block in a map which is like 
historyMap = new HashMap<String, ArrayList<Long>>(). Here ArrayList is of size 2 which contain old and new GenerationStamp. 

For every recovery this map is updated with the block and Generation Stamps. 

Consider the scenario when BlockReport has arrived @ NN and delayed. 
Now if the any BlockRecovery completed (historyMap will have the entry of old and new Generation Stamps). 
Now the Blockreport processing started. Here 

{code}
case RWR: 
      if (!storedBlock.isComplete()) { 
        return null; // not corrupt 
      } else if (storedBlock.getGenerationStamp() != iblk.getGenerationStamp() &&
            !historyMap.get(iblk.getBlockId()).get(0) != iblk.getGenerationStamp() )) { 
        return new BlockToMarkCorrupt(storedBlock, 
            "reported " + reportedState + " replica with genstamp " + 
            iblk.getGenerationStamp() + " does not match COMPLETE block's " + 
            "genstamp in block map " + storedBlock.getGenerationStamp()); 
      } else { // COMPLETE block, same genstamp
{code}

Here we are checking like 
if (Block GenerationStamp from BlockMap != BlockReport's Block GenerationStamp and (blockGenerationStamp is newly changed due to recovery then check the) 
old GenerationStamp is not equal BlockReports Block GenerationStamp) then { // mark block as corrupt the block } 

Map is populated in CommitBlockSynchronization and cleared when BlockReport is processed for this block with new generationstamp

 

, Hi Nicholas,

Do you have any solution for this?

One work around could be that, if reported block is having less genstamp and NN is having higher then , how about adding them into some suspected corrupt list. On next block report if the block is having correct genstamp(newer genstamp), then we can just clean that block from suspectedCorruptMap. If block is having still less genstamp and that entry already presents in suspectedCorruptMap, then mark it as corrupt. But I am worrying to introduce one more datastructure here.

Any suggestion on this would be appreciated.

Thanks,
Uma, Hi Uma,

I may have missed something: at the time of processing BR, both the block stored in NN and the replica stored in DN have the newer genstamp.  We should have the following:

- NN side: NN has a newer genstamp but DN reported a replica with an older genstamp.  NN should tell DN to delete replica with the older genstamp and the stored block in NN remains unchanged.
- DN side: DN receives a replica-delete with the older genstamp from NN but the stored genstamp is newer.  So it ignores the replica-delete.

There may be some bugs in the implementation.  What happen after the block is marked as corrupted?  Will DN delete the replica?  Or will NN remove the DN from the block location list?, Thanks a lot Nicholas.

{quote}
- DN side: DN receives a replica-delete with the older genstamp from NN but the stored genstamp is newer.  So it ignores the replica-delete.
{quote}
In my case, this happened for all the blocks unfortunately. I have seen the logs, all blocks marked as corrupt almost at same time. So, it will just leave all the corrupt block as is.

 Yes, here is one bug I remember. HDFS-3157. NN will add the block as corrupt with NN genstamp rather than reported genstamp ( I will take a look on that patch again). This should solve this problem. But all DNs configured BR time same and happens for all means, all blocks will get marked as corrupt right?
, In our situation we had only 3 DN in test cluster, NN marked block (which has replication 3 ) has corrupt in same time, There is no command from NN to DN to invalidate the block

I guess this is because of the behaviour i.e, NN will try to replicate the corrupt block with a valid block first then invalidate the corrupt block.
, Hi Uma, please review HDFS-3157 when you have time., Hi Nicholas,

 I feel this issue is still valid after HDFS-3157 and when all blocks marked as corrupt.
Also we are seeing many race conditions with recovery and close, commitBlockSynchronization. see HDFS-3584 and HDFS-3585 just reported by Brahma. Once it corrupts all the blocks, leter even though DN sends with correct block, there is no use, as it already put them into corrupt. Also there will not be any replication as there is no live replicas.

Thanks
Uma

, Hi [~umamaheswararao],
Is this still an issue? I looked at the code and I think this got fixed sometime.
Here is the code snippet from BlockManager
{code}
case RWR:
      if (!storedBlock.isComplete()) {
        return null; // not corrupt
      } else if (storedBlock.getGenerationStamp() != reported.getGenerationStamp()) {
        final long reportedGS = reported.getGenerationStamp();
        return new BlockToMarkCorrupt(storedBlock, reportedGS,
            "reported " + reportedState + " replica with genstamp " + reportedGS
            + " does not match COMPLETE block's genstamp in block map "
            + storedBlock.getGenerationStamp(), Reason.GENSTAMP_MISMATCH);
      } else { // COMPLETE block, same genstamp
        if (reportedState == ReplicaState.RBW) {
          // If it's a RBW report for a COMPLETE block, it may just be that
          // the block report got a little bit delayed after the pipeline
          // closed. So, ignore this report, assuming we will get a
          // FINALIZED replica later. See HDFS-2791
          LOG.info("Received an RBW replica for " + storedBlock +
              " on " + dn + ": ignoring it, since it is " +
              "complete with the same genstamp");
          return null;
        } else {
          return new BlockToMarkCorrupt(storedBlock,
              "reported replica has invalid state " + reportedState,
              Reason.INVALID_STATE);
        }
      }
{code}

I will resolve this Jira as "Not a Problem" tomorrow unless someone wants to go some other way., Haven't heard anything yet. Resolving this issue. Feel free to reopen if anyone thinks the other way.]