[Hi Romain, is the request to expose additional fields in the [Java FileStatus object|https://github.com/apache/hadoop/blob/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FileStatus.java]? Or you want sorting on these different fields?

We do pagination right now based on the path since that's the primary key. I'd rather implement different sort orders on the client-side to avoid additional NN overhead., Sorting on the existing files. 

For example, if a client, let's say a Web server, wants to display the latest 100 files of a directory, and there are 100 000 files, it needs to pull all the files and sort it himself. If the users wants to sort on another criteria, the client needs to re-fetch all the 100 000 files and sort again (as Web is stateless). We lose the benefit of the future pagination HDFS-9366 at the same time. 

Hence the long term solution / advantage of doing everything at the source, especially if pagination is implemented (limited set to sort), the sorting should not add too much NN overhead (and we also skip the cost of the current massive LISTDIR calls).
, Greetings

I gave it a try on resolving his issue.
As I understand it, the WebHDFS is supposed to expose the methods of [org.apache.hadoop.fs.FileSystem|https://hadoop.apache.org/docs/current/api/org/apache/hadoop/fs/FileSystem.html]. As it stands, this class does not have a version of listStatus that supports ordering. Ideally, to solving this issue involves adding such method to this class. Adding this method was easy enough (take a look at [this patch|http://pastebin.com/raw/R4G5FjQq]).
The next step should be to modify the WebHDFS url to understand a new parameter, for instance:

{code:borderStyle=solid}
curl -i  "http://<HOST>:<PORT>/webhdfs/v1/<PATH>?op=LISTSTATUS[&orderBy=<ORDERBY>]"
{code}

Then it would be necessary to check if the parameter is set and call the appropriate version of listStatus.
Unfortunately I could not figure this part. I could verify that the request to the URL above is (at least partially) fulfilled by the class [org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods|https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/web/resources/NamenodeWebHdfsMethods.java]. Looking at the class [org.apache.hadoop.hdfs.web.WebHdfsFileSystem|https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java], I got the impression that this class somehow causes the code on NamenodeWebHdfsMethods to run. If that is what happens, I think I need to know which part of the code calls WebHdfsFileSystem.listStatus, and apply there the changes proposed on the previous paragraph.
Unfortunatelly I could not figure this out, specially as there is no documentation of the inner workings of the hadoop project.
To add to my confusion, there are also the classes at [org.apache.hadoop.http|https://github.com/apache/hadoop/tree/trunk/hadoop-hdfs-project/hadoop-hdfs-httpfs/src/main/java/org/apache/hadoop/fs/http], which I am not sure are related to WebHdfs or not (they also deal with http requests and hdfs).
Should I make no progress, at least this comment is a starting point for anyone who tries to address this issue.

PS. How do you guys package a new hadoop source? It takes me almost half an hour to package it with maven, even though I only change a few lines of a file., I've noticed the class FileSystem has been updated. Here is the [new patch|http://pastebin.com/raw/c9C56CE7] against the [latest commit|https://github.com/apache/hadoop/commit/01665e456de8d79000ce273dded5ea53aa62965a].]