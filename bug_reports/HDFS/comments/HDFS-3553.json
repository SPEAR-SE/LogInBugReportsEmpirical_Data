[Both hftp and webhdfs use the same code in {{JspHelper}} for token validation.  Hftp has always expected the ugi query param to be the current user, while webhdfs expects the ugi param to be the real user and uses a new doAs param for the current param.  This is semantically incompatible., As best I can tell, the checks are just sanity checks to ensure the proxy token's users are in sync with the users the client believes it's using.

After speaking with Nicholas, disabling one of the new user checks (introduced by HDFS-2539) is a less than ideal short-term fix.  It will not impact the functionality of hftp nor webhdfs., For the sake of discussion, the longer-term fixes may be:
# Streamline the logic to more closely match hftp's long standing convention
#* change webhdfs ugi query param to be the current user (instead of doAs param)
#* remove doAs param, replace with a realUser param, for specifying the real user
# Use context sensitive logic
#* ex. if doAs param is present, use webhdfs notion of ugi/doAs, else use hftp's notion of ugi

#1 is a simple change that standardizes the logic, but the con is a webhdfs incompatibility.  #2 maintains webhdfs compatibility, but feels fragile.  Comments?, WebHDFS is a bit different from Hftp in that users can directly interact with it using tools such as curl. The HTTP user in the request is naturally the actual user who is running the tool and proxy request will be something special. So, the current way feels more natural than what's proposed in #1 when it comes to direct user interactions.  

In Hftp, since HTTP requests are made only programmatically, wrapping a request in doAs seems consistent with the rest of the system. The fact that HTTP user = currentUser doesn't affect the usability, as it's all hidden from users.

#1 can be added to v2 of WebHDFS, but we will have to maintain compatibility for a version or two, so JspHelper will become perhaps even more messier than #2. 

Since this inconsistency fortunately does not cause any confusion to users, we should probably go with #2. We will get the better usability (maybe) and the compatibility at the price of some inconsistency/complexity in the code. How about doing #2 and leaving a block of well-written comment in the code? :)
, To avoid the messiness involved with #2 + #1 in a future webhdfs, I wonder if the presence of the doAs param is sufficient to alter the semantics of the user checks?, Canceling patch since problems runs deeper.  Hftp isn't correctly locating a TGT within a doAs., Problem is in both the hftp client and the NN.
# NN is trying to perform authorization checks on a proxy token.  Auth checks only apply to UGI when there is no token, else NN rejects proxy tokens from DNs.
# Real user does not need to be checked for a proxy token.  Task does not know the real user.  What's relevant is that the user has a token, not who vouched for the token.
# Hftp is trying to negotiate kerberos as the effective user, but the effective user of a proxy ugi has no TGT.  The real user has the TGT.

Patch has been tested with direct distcp &  oozie + distcp., Also of note, the patch makes the example code for Secure_Impersonation work under hftp.  I'm working on patches for the newer branches since the code has changed under spnego auth.  The problem appears to be there, but I haven't set up a spnego cluster to verify.  In the meantime, the patch really needs to go into 1.x.

Currently w/o the patch, oozie on 1.x cannot use hftp to any 1.x/2.x+ cluster.  Hftp on 1.x+ works with 20x only if the proxy token is acquired over hdfs.  This defeats the primary purpose of using hftp (immunity from rpc version mismatches).  Webhdfs may be similarly affected although that should be fixed under another jira if proven to be true., The patch looks generally good, but I have a few comments:

1. I don't think you can assume that the process has Kerberos tickets for the real user that was pull out of the ugi. I'd be happier if you were using the UserGroupInformation.getLoginUser.
2. I prefer the original structure of JspHelper.getUGI that first splits on security enable and then on whether there is a token. It doesn't seem like a good idea to merge the non-token secure and insecure cases. In particular, in the secure case I don't see where you are pulling the user from the connection.
3. Shouldn't you be able to have a proxy user with real user from the connection and ?ugi= for the effective user? I don't think that is allowed by your patch., Thanks for the quick feedback!
# I considered {{getLoginUser}}.  One concern is if loginUser can be abused within a nested doAs to have the loginUser vouching as the realUser.  Ie. "superuser -> lowly-user -> fake-user".  Isn't the lowly-user (realUser) vouching for the fake-user, not the superuser (loginUser) vouching for fake-user?  I can change it if there's not really a risk.
# Regarding the split, the logic was:{code}
if (security) {
  if (token) {
    use-token-ugi
  } else {
    create-ugi
  }
} else {
  create-ugi
}{code}.  I thought it was a bit more natural with less redundancy as:{code}
if (security && token) {
  use-token-ugi
} else {
  create-ugi
}{code}
bq.  in the secure case I don't see where you are pulling the user from the connection
{code}
final String remoteUser = request.getRemoteUser();
...
realUgi = UserGroupInformation.createRemoteUser(remoteUser);
{code}

# bq. Shouldn't you be able to have a proxy user with real user from the connection and ?ugi= for the effective user
I don't think so...?  It's not what it did before, and it would appear to cause inconsistencies in semantics depending on the security setting.  With security off, "?ugi" is the remote user (in lieu of auth) and "?doAs" creates a proxy user.  With security on, there is an additional check that "?ugi" is the authed remote user., -1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12534366/HDFS-3553-1.branch-1.0.patch
  against trunk revision .

    +1 @author.  The patch does not contain any @author tags.

    -1 tests included.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    -1 patch.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/2738//console

This message is automatically generated., # The patch doesn't apply cleanly to branch-1.1 (or branch-1.0).
# It has to be the login user, because the 'real' user is remote. The server doesn't have those credentials. The only credentials it has are its own login ones.
# To me, it reads easier the original branching structure than:
{code}
if (security && token) {
  use token
} else {
  if (security & !remote) {
    complain
  }
  create token
}
{code}
# Can you summarize the current and new url modifiers that will be accepted for hftp and webhdfs?, Change if logic to be closer to what it used to be, set the ugi auth type to token if from token, add a bunch of tests that were missing., -1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12537420/HDFS-3553-2.branch-1.0.patch
  against trunk revision .

    -1 patch.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/2881//console

This message is automatically generated., Actually, I think setting the auth type to token is wrong.  If it's a proxy token, then the real user is auth-ed as token, while the effective user is proxy auth.  The token ident's {{getUser()}} should be setting the auth type to token.  Will file another jira., Depends on HADOOP-8613 patch for correct ugi auth type from token, and adds more tests to verify the jsp returns a ugi with the correct auth type with or w/o token., -1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12537725/HDFS-3553-3.branch-1.0.patch
  against trunk revision .

    -1 patch.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/2895//console

This message is automatically generated., Daryn, the current patch looks good. Thanks!, -1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12537763/HDFS-3553.branch-23.patch
  against trunk revision .

    -1 patch.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/2898//console

This message is automatically generated., The trunk patch will not be as complete in DelegationTokenFetcher because kssl is removed from trunk.  The means for making authenticated url connections for spnego in fetchdt intersects the changes being made on HDFS-3509 for webhdfs proxy user support.  I'm going to leave it to that jira to handle making the spegno url authentication work for both webhdfs and fetchdt since the solution should be common/shared., Some tests will fail until the dependency HADOOP-8613 is integrated., -1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12537781/HDFS-3553.trunk.patch
  against trunk revision .

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 1 new or modified test files.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 eclipse:eclipse.  The patch built with eclipse:eclipse.

    +1 findbugs.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    -1 core tests.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.server.common.TestJspHelper
                  org.apache.hadoop.hdfs.server.blockmanagement.TestBlocksWithNotEnoughRacks

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/2900//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/2900//console

This message is automatically generated., This looks good, Daryn. +1, Integrated in Hadoop-Common-trunk-Commit #2529 (See [https://builds.apache.org/job/Hadoop-Common-trunk-Commit/2529/])
    HDFS-3553. Hftp proxy tokens are broken (daryn) (Revision 1366471)

     Result = SUCCESS
daryn : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1366471
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/common/JspHelper.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/common/TestJspHelper.java
, Integrated in Hadoop-Hdfs-trunk-Commit #2593 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk-Commit/2593/])
    HDFS-3553. Hftp proxy tokens are broken (daryn) (Revision 1366471)

     Result = SUCCESS
daryn : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1366471
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/common/JspHelper.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/common/TestJspHelper.java
, Integrated in Hadoop-Mapreduce-trunk-Commit #2549 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk-Commit/2549/])
    HDFS-3553. Hftp proxy tokens are broken (daryn) (Revision 1366471)

     Result = FAILURE
daryn : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1366471
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/common/JspHelper.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/common/TestJspHelper.java
, Recent kssl/SPNEGO changes have completely broken the branch-1 patch.  Will leave open until that branch is fixed., Integrated in Hadoop-Hdfs-0.23-Build #327 (See [https://builds.apache.org/job/Hadoop-Hdfs-0.23-Build/327/])
    HDFS-3553. Hftp proxy tokens are broken (daryn) (Revision 1366505)

     Result = SUCCESS
daryn : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1366505
Files : 
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/common/JspHelper.java
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DelegationTokenFetcher.java
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/common/TestJspHelper.java
, Integrated in Hadoop-Hdfs-trunk #1118 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1118/])
    HDFS-3553. Hftp proxy tokens are broken (daryn) (Revision 1366471)

     Result = FAILURE
daryn : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1366471
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/common/JspHelper.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/common/TestJspHelper.java
, Integrated in Hadoop-Mapreduce-trunk #1150 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1150/])
    HDFS-3553. Hftp proxy tokens are broken (daryn) (Revision 1366471)

     Result = FAILURE
daryn : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1366471
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/common/JspHelper.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/common/TestJspHelper.java
, 1.1.0 was released without this patch.  Changing the Target Version to 1.1.1.

However, is this really still needed in branch-1?  Or did Owen's latest SPNEGO patch for HFTP in 1.1.0 fix this issue too?, My apologies, I overlooked my previous statement about branch-1 before closing.  It does appear that proxy tokens cannot be used with hftp, unless that proxy token was obtained via hdfs.  HDFS-3509 is attempting to fix proxy tokens for webhdfs.  The two filesystems ultimately call into the same low level methods.  The branch-1 patch here should apply if that jira makes the appropriate changes., moved target version to 1.2.0 upon publishing 1.1.1 RC.

Is this still needed?, Probably, but I unfortunately do not have access to a secure 1.x cluster to verify.  I'd really appreciate it if someone could chip in and test if the problem remains, and possibly even update the patch., Any update on this? Thanks., I'll close this and open a new bug for branch-1 backport.]