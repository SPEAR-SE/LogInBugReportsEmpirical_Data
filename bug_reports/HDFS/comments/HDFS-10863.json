[According to your setup, I found  my linux user matched hdfs:
[hadoop@hadoop ~]$ ll  test
-rw-rw-r--. 1 hadoop hadoop 5 9月  20 14:25 test
[hadoop@hadoop ~]$ hdfs dfs -ls /tmp
Found 1 items
-rw-r--r--   1 hadoop hadoop          5 2016-09-20 14:30 /tmp/test
My OS is CentOS7, and hadoop version is hadoop 3.0.0, I don't think it is a bug. Could you show some more information about your environment and configuration?, Hi,

First of all, I classify this issue as a bug because I didn't know to put "need help" in the JIRA.

My env : Ubuntu 16.04, hadoop 2.7.2, 3 DataNode (a DataNode is 2.7.3 I want to test "compatibility").

$ uname -a
Linux jbd-vm01 4.4.0-36-generic #55-Ubuntu SMP Thu Aug 11 18:01:55 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux

$ hadoop version
Hadoop 2.7.2
Subversion https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41
Compiled by jenkins on 2016-01-26T00:08Z
Compiled with protoc 2.5.0
From source with checksum d0fda26633fa762bff87ec759ebe689c
This command was run using /home/hduser/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar

core-file:
<configuration>
  <property>
    <name>name</name>
    <value>MyDistrib@JBD-2.7.2</value>
  </property>
  <property>
    <name>fs.defaultFS</name>
    <value>hdfs://jbd-vm01.jbdata.fr:9000</value>
  </property>
  <property>
    <name>hadoop.tmp.dir</name>
    <!-- value>/srv/work/hadoop/tmp</value entre les 2, je choisis le moins mieux... -->
    <value>/srv/work/hdfs272/tmp</value>
  </property>
  <!-- A quoi sert ce paramétrage FTP ? Pas une trace dans les LOG -->
  <property>
    <name>fs.ftp.host</name>
    <value>jbd-vm03.jbdata.fr</value>
  </property>
  <property>
    <name>fs.ftp.host.port</name>
    <value>21</value>
  </property>
  <property>
    <name>ha.zookeeper.quorum</name>
    <value>jbd-vm01.jbdata.fr,jbd-vm03.jbdata.fr</value>
  </property>
  <property>
    <name>hadoop.registry.zk.quorum</name>
    <value>jbd-vm01.jbdata.fr:2181,jbd-vm03.jbdata.fr:2181</value>
  </property>
  <property>
    <name>hadoop.http.staticuser.user</name>
    <value>hduser</value>
  </property>
  <!-- NFS gateway -->
  <property>
    <name>hadoop.proxyuser.hduser.groups</name>
    <value>*</value>
  </property>
  <property>
    <name>hadoop.proxyuser.hduser.hosts</name>
    <value>*</value>
  </property>
</configuration>

hdfs-file
<configuration>
  <property>
    <name>dfs.replication</name>
    <!-- value>3</value -->
    <value>2</value>
  </property>
  <property>
    <name>dfs.permissions.superusergroup</name>
    <value>hadoop</value>
  </property>
  <!-- NNx1 -->
  <property>
    <name>dfs.namenode.http-address</name>
    <value>jbd-vm01.jbdata.fr:50070</value>
  </property>
  <property>
    <name>dfs.namenode.https-address</name>
    <value>jbd-vm01.jbdata.fr:50470</value>
  </property>
  <property>
    <name>dfs.namenode.name.dir</name>
    <value>file:/srv/data/hdfs272/nn1,file:/srv/data/hdfs272/nn2</value>
  </property>
  <!-- NN2x1 -->
  <property>
    <name>dfs.namenode.secondary.http-address</name>
    <value>jbd-vm03.jbdata.fr:50090</value>
  </property>
  <property>
    <name>dfs.namenode.secondary.https-address</name>
    <value>jbd-vm03.jbdata.fr:50091</value>
  </property>
  <property>
    <name>dfs.namenode.checkpoint.dir</name>
    <value>file:/srv/data/hdfs272/cp1,file:/srv/data/hdfs272/cp2</value>
  </property>

Need other thing ?

I'm "hard" testing the nfs gateway and I have the same kind of issue with the group, but it's maybe another JIRA to open.

$ ll /srv/hdfs_nfs/tmp/zk.tar
-rw-r--r-- 1 hduser 2584148964 41984000 Sep 21 06:01 /srv/hdfs_nfs/tmp/zk.tar

Maybe this issue disapear with the 3.0.0..., Hi,

First of all, I classify this issue as a bug because I didn't know to put
"need help" in the JIRA.

My env : Ubuntu 16.04, hadoop 2.7.2, 3 DataNode (a DataNode is 2.7.3 I want
to test "compatibility").

$ uname -a
Linux jbd-vm01 4.4.0-36-generic #55-Ubuntu SMP Thu Aug 11 18:01:55 UTC 2016
x86_64 x86_64 x86_64 GNU/Linux

$ hadoop version
Hadoop 2.7.2
Subversion https://git-wip-us.apache.org/repos/asf/hadoop.git -r
b165c4fe8a74265c792ce23f546c64604acf0e41
Compiled by jenkins on 2016-01-26T00:08Z
Compiled with protoc 2.5.0
From source with checksum d0fda26633fa762bff87ec759ebe689c
This command was run using
/home/hduser/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar

core-file:
<configuration>
<property>
<name>name</name>
<value>MyDistrib@JBD-2.7.2</value>
</property>
<property>
<name>fs.defaultFS</name>
<value>hdfs://jbd-vm01.jbdata.fr:9000</value>
</property>
<property>
<name>hadoop.tmp.dir</name>
<!-- value>/srv/work/hadoop/tmp</value entre les 2, je choisis le moins
mieux... -->
<value>/srv/work/hdfs272/tmp</value>
</property>
<!-- A quoi sert ce paramétrage FTP ? Pas une trace dans les LOG -->
<property>
<name>fs.ftp.host</name>
<value>jbd-vm03.jbdata.fr</value>
</property>
<property>
<name>fs.ftp.host.port</name>
<value>21</value>
</property>
<property>
<name>ha.zookeeper.quorum</name>
<value>jbd-vm01.jbdata.fr,jbd-vm03.jbdata.fr</value>
</property>
<property>
<name>hadoop.registry.zk.quorum</name>
<value>jbd-vm01.jbdata.fr:2181,jbd-vm03.jbdata.fr:2181</value>
</property>
<property>
<name>hadoop.http.staticuser.user</name>
<value>hduser</value>
</property>
<!-- NFS gateway -->
<property>
<name>hadoop.proxyuser.hduser.groups</name>
<value>*</value>
</property>
<property>
<name>hadoop.proxyuser.hduser.hosts</name>
<value>*</value>
</property>
</configuration>

hdfs-file
<configuration>
<property>
<name>dfs.replication</name>
<!-- value>3</value -->
<value>2</value>
</property>
<property>
<name>dfs.permissions.superusergroup</name>
<value>hadoop</value>
</property>
<!-- NNx1 -->
<property>
<name>dfs.namenode.http-address</name>
<value>jbd-vm01.jbdata.fr:50070</value>
</property>
<property>
<name>dfs.namenode.https-address</name>
<value>jbd-vm01.jbdata.fr:50470</value>
</property>
<property>
<name>dfs.namenode.name.dir</name>
<value>file:/srv/data/hdfs272/nn1,file:/srv/data/hdfs272/nn2</value>
</property>
<!-- NN2x1 -->
<property>
<name>dfs.namenode.secondary.http-address</name>
<value>jbd-vm03.jbdata.fr:50090</value>
</property>
<property>
<name>dfs.namenode.secondary.https-address</name>
<value>jbd-vm03.jbdata.fr:50091</value>
</property>
<property>
<name>dfs.namenode.checkpoint.dir</name>
<value>file:/srv/data/hdfs272/cp1,file:/srv/data/hdfs272/cp2</value>
</property>

Need other thing ?

I'm "hard" testing the nfs gateway and I have the same kind of issue with
the group, but it's maybe another JIRA to open.

$ ll /srv/hdfs_nfs/tmp/zk.tar
rw-rr- 1 hduser 2584148964 41984000 Sep 21 06:01 /srv/hdfs_nfs/tmp/zk.tar

Maybe this issue disapear with the 3.0.0...

@JBD <http://jbigdata.fr>



, Hi [~jbigdata.fr], thanks for reporting the issue. You can always post any question to user@hadoop.apache.org.

Please read {{Overview}} of [HDFS Permissions Guide (2.7.3)|https://hadoop.apache.org/docs/r2.7.3/hadoop-project-dist/hadoop-hdfs/HdfsPermissionsGuide.html]:

bq. When a file or directory is created, its owner is the user identity of the client process, and its group is the group of the parent directory (the BSD rule).

Property {{dfs.permissions.superusergroup}} sets the super user group whose members are all considered super users. In you case, any member of group {{hadoop}} becomes HDFS super user who will bypass any permission checking. Please set it with care.]