[Attaching the patch. Please review, {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12606736/HDFS-5299.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/5094//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/5094//console

This message is automatically generated., Nit:
{code}
cluster = new MiniDFSCluster.Builder(new Configuration())
+        .nnTopology(MiniDFSNNTopology.simpleHATopology()).numDataNodes(1)
+        .build();
{code}
Please reuse the existing conf object, you need not create new one for it.

Also please add small javadoc for the test.

{code}
 CacheEntryWithPayload cacheEntry = RetryCache.waitForCompletion(retryCache,
        null);
    if (cacheEntry != null && cacheEntry.isSuccess()) {
      return (String) cacheEntry.getPayload();
    }
    final FSPermissionChecker pc = getPermissionChecker();
{code}
Here if getPermissionChecker throws exception, then similar situation can occur for that call?  We will not retry for this exception I think, but the pattern to wait for retry cache and setting state should be proper order to avoid situations like this., Thanks for the fix Vinay! The patch looks great. Some minors:

# The patch requires rebase after HDFS-5300 got committed.
# The same comment with Uma about "getPermissionChecker". 
# Looks like after rebase there will be an extra "checkOperation(OperationCategory.WRITE)" in FSNamesystem#deleteSnapshot.
# In FSNamesystem#savenamespace, the checkSuperuserPrivilege call also needs to be moved before the retry cache operation., Since there are only some trivial changes required, I try to generate a rebased patch which also addresses Uma's comments. 

bq. Please reuse the existing conf object, you need not create new one for it.

Here I think Vinay's patch is correct. The conf object will be modified by the MiniDFSCluster and the HA conf setting will affect the following tests. So in the new patch, I reuse the conf object but put its creation in the setup method., +1. Patch looks good., {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12607029/HDFS-5299.000.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/5110//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/5110//console

This message is automatically generated., Thanks a lot Jing for addressing the comments.
+1 on the latest patch. Also thanks for the review Brandon., Thanks jing for the rebase and addressing uma's comment. I was out of station this weekend, so could not address uma's comment in time.  
Thanks also uma and brendon for reviews., SUCCESS: Integrated in Hadoop-trunk-Commit #4553 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/4553/])
HDFS-5299. DFS client hangs in updatePipeline RPC when failover happened. Contributed by Vinay. (jing9: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1529660)
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestNamenodeRetryCache.java
, Thanks again, Vinay, Uma, and Brandon! I've committed this to trunk, branch-2 and branch-2.1-beta., SUCCESS: Integrated in Hadoop-Yarn-trunk #355 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/355/])
HDFS-5299. DFS client hangs in updatePipeline RPC when failover happened. Contributed by Vinay. (jing9: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1529660)
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestNamenodeRetryCache.java
, SUCCESS: Integrated in Hadoop-Hdfs-trunk #1545 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1545/])
HDFS-5299. DFS client hangs in updatePipeline RPC when failover happened. Contributed by Vinay. (jing9: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1529660)
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestNamenodeRetryCache.java
, FAILURE: Integrated in Hadoop-Mapreduce-trunk #1571 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1571/])
HDFS-5299. DFS client hangs in updatePipeline RPC when failover happened. Contributed by Vinay. (jing9: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1529660)
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestNamenodeRetryCache.java
, Closing tickets that are already part of a release.]