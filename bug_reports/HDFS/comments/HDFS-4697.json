[If that's true, the sequence read in HBase, e.g. large scan is suboptimal, right?   nice finding!, The OS-level readahead will happen even without this for most sequential reads. The fadvise done by manageOsCache() helps triggering OS readahead, which may not happen for slow small reads. The gap between reads are worse for remote reads and that's where manageOsCache() would help most.  It does not, however, prolong the lifetime of cached data, so if the reader is slow and the memory pressure is high, the data may get thrown away before the reader gets to it. In such cases, it may actually lower the overall system throughput by causing extra reads. 

I agree that this needs to be fixed, but am also curious how much performance improvement can be obtained for short-circuit reads. If we have important use cases for the precise control of caching and disk activities, aio + direct i/o can be used.  What are the common and performance-critical access patterns of hbase? All I know from old days is that it does a lot of random reads of about 64KB., It is certainly true that the OS does some readahead of its own.  However, we found that doing manual readahead provided a performance boost in many scenarios, especially ones involving long sequential reads.  That's why the Datanode currently does readahead by default.  These settings should be honored when using short-circuit local reads, so that the behavior is consistent and configurable.

Most of HBase's reads are random reads.  Readahead will not benefit random reads.  The current readahead code in the DN will not do readahead when small, random reads are being done, and we should follow suit in {{BlockReaderLocal}}.  I do think HBase will see some benefit when doing long scans, and doing compactions.

As you mentioned, it's true that readahead is not always a win when memory pressure is extremely high.  However, when memory pressure is so high that sections that got read ahead have to be purged prior to use, the system usually has other problems that make it unstable and essentially unusable, like the OOM killer triggering., [~cmccabe] I think this was fixed by the BRL rewrite in HDFS-5634, are we good to close this out?, Hi [~cmccabe] are the short-circuit reads using readahead settings properly now?  If so this ticket is good to close, Short-circuit now honors {{dfs.datanode.readahead.bytes}}, since HDFS-5634.

However, if you want short-circuit the full 4 MB of readahead that the datanode is doing, you'll need to set {{dfs.client.read.shortcircuit.buffer.size}} to 4 megabytes in your configuration.  Its value is specified in bytes and it defaults to 1 megabyte.  The tradeoff is slightly increased memory consumption., Closing tickets that are already part of a release.]