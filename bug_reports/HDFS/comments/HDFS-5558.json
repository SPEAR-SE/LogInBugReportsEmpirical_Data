[{{LeaseManager}} might need to be made more robust, but more importantly, the last block shouldn't be completed if the penultimate block is not completed when closing a file.  In {{completeFileInternal()}}, {{checkFileProgress(pendingFile, false)}} needs to be called before calling {{commitOrCompleteLastBlock()}}.  If the penultimate block isn't going to be completed soon, the close will fail anyway. It should fail before doing more damage., We might need a slight addition to the patch for branch-0.23, as getAdditionalBlock has a very similar structure where it can commit/complete the last block before checking the state of the penultimate block.  If we get stuck in that state for a while or client abandons the file then the LeaseManager could hit the same condition if a block report completes the last block but not the penultimate block.  In trunk/branch-2 getAdditionalBlock calls analyzeFileState before it tries to commit/complete the block, and that will throw if the penultimate block has not completed., Posting the branch-0.23 version of the patch. PreCommit will fail on this., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12615446/HDFS-5558.branch-023.patch
  against trunk revision .

    {color:red}-1 patch{color}.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/5555//console

This message is automatically generated., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12615435/HDFS-5558.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/5552//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/5552//console

This message is automatically generated., I tried to reproduce the problem as mentioned with the help of test changes in HDFS-5557, but could not get the Invalid Cast Exception in trunk code. 
Instead, {color:red}*{{checkLeases()}} got stuck in infinite loop with fsn writelock held.*{color} Because checkLeases() will check repeatedly for the files until all files are renewed. Instead get all the expired leases and check once and return the call, check again after NAMENODE_LEASE_RECHECK_INTERVAL. if required this would be a separate Jira though.
As of now I am seeing only possible case could be HDFS-5557, which leads to this case., Is this related to HDFS-4882 ? It has been left there for a long time. , HDFS-4882 is more related to {{dfs.namenode.replication.min=2}} which is not taking care of adding extra datanode during PIPELINE_CLOSE_RECOVERY, 

I agree, not adding extra datanodes can cause {{checkLeases()}} into infiniate loop, but with the fix given in this jira that situation may not come. 
Now client's close() have timeout and fails after timeout., bq. I tried to reproduce the problem as mentioned with the help of test changes in HDFS-5557, but could not get the Invalid Cast Exception in trunk code. 

The test won't reproduce this issue because the client will lose every time.  In order to reproduce this, the client has to lose the race in HDFS-5557 for the penultimate block and the datanode has to win the race for the last block.  I.e. produce block layout [...][BlockInfoUnderConstruction:COMMITTED][BlockInfo:COMPLETE]., My understanding is that we can only get into this situation if there is another bug (such as HDFS-5557) causing an internal inconsistency.  With this in mind, I think the log message should be at ERROR level, not INFO, and should look different from the standard {{checkFileProgress}} log message.  It looks good aside from that., bq. My understanding is that we can only get into this situation if there is another bug (such as HDFS-5557) causing an internal inconsistency.

Faulty or busy data nodes might delay the incremental block report for the penultimate block of a file or crash before sending it. We have also seen in the past a name node getting overwhelmed with RPC calls and falling behind in processing incremental block reports. I think it was due to a user using a small block size and creating way too many blocks (before min block size fix). 

The block and replica state updates are asynchronous, so we cannot say it won't happen. In fact, we even have the close retry logic for this reason. Since it should be rare, how about making it WARN?, Thanks for the explanation.  Using WARN here is fine with me., The patch has been updated according to the review comment.  , +1  It sounds like you addressed Colin's concern.  And yes, I helped debug a case awhile back where the user accidentally set the block size to N-KB instead of N-MB for their jobs.  The NN was overwhelmed and the dfs client's request for another block was being processed before the prior block's updates., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12616609/HDFS-5558.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.server.balancer.TestBalancerWithNodeGroup

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/5612//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/5612//console

This message is automatically generated., FAILURE: Integrated in Hadoop-Hdfs-0.23-Build #809 (See [https://builds.apache.org/job/Hadoop-Hdfs-0.23-Build/809/])
HDFS-5558. LeaseManager monitor thread can crash if the last block is complete but another block is not. Contributed by Kihwal Lee. (kihwal: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1547197)
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java
, Thanks for the reviews. I've committed this to trunk, branch-2 and branch-0.23., SUCCESS: Integrated in Hadoop-trunk-Commit #4819 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/4819/])
HDFS-5558. LeaseManager monitor thread can crash if the last block is complete but another block is not. Contributed by Kihwal Lee. (kihwal: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1547393)
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java
, FAILURE: Integrated in Hadoop-Yarn-trunk #411 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/411/])
HDFS-5558. LeaseManager monitor thread can crash if the last block is complete but another block is not. Contributed by Kihwal Lee. (kihwal: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1547393)
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java
, FAILURE: Integrated in Hadoop-Mapreduce-trunk #1628 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1628/])
HDFS-5558. LeaseManager monitor thread can crash if the last block is complete but another block is not. Contributed by Kihwal Lee. (kihwal: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1547393)
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java
, SUCCESS: Integrated in Hadoop-Hdfs-trunk #1602 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1602/])
HDFS-5558. LeaseManager monitor thread can crash if the last block is complete but another block is not. Contributed by Kihwal Lee. (kihwal: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1547393)
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java
]