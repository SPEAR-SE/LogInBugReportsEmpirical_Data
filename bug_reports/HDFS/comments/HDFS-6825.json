[Submit patch 001 to address the issue. 

Two additional issues were found and fixed:
1. When snapshot for a file doesn't exist, FSNamespace.commitBlockSynchronization would thrown NPE,  because the blockCollection of the storedBlock was set to null by a delete operation. 
2. BlockInfoUnderConstruction.appendUCParts doesn't check whether "replicas" is null or not

Thanks for reviewing.
, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12660440/HDFS-6825.001.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 4 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.server.namenode.TestCommitBlockSynchronization

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/7584//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/7584//console

This message is automatically generated., Upload patch 002 to address test failure.
, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12660538/HDFS-6825.002.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 5 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover
                  org.apache.hadoop.hdfs.TestLeaseRecovery2

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/7590//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/7590//console

This message is automatically generated., The only change in 002 is some change in one test code to address 001 test failure,  the failed test in 002 run is a different test.  

Try 003 with minor change.
, BTW, rerun of the failed test with 002 locally is successful.
, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12660642/HDFS-6825.003.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 5 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/7593//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/7593//console

This message is automatically generated., Hi Yongjun, tricky bug, but this fix looks good. Just a few review comments:

* Could we also check that this works with a recursive delete on the containing folder of the open file?
* Adding a comment in FSN about delayed block removal would be nice
* Would also be nice if the exception text mentioned delayed block removal

Test:
* I'd rather not depend on the sleeps for the delete. I think we could also refactor the thread's run method into a helper method, and just call the helper, and avoid sleeping at all.

I'm +1 to commit this pending these fixes, but wouldn't mind a double check from [~atm] or [~cmccabe] too.,  Hi [~andrew.wang], thanks a lot for your review and comments! As we discussed offline, I will wait for @atm or [~cmccabe] a bit in case they have comments, and will address altogether. Thanks ATM and Colin., Hey Yongjun, thanks a lot for working on this. A few questions/comments for you:

# Please correct me if I'm wrong, but I don't think it's necessary for the test to use an HA minicluster, and instead a normal single NN minicluster would demonstrate this bug as well. If I'm right about that, please change the test. Making it HA distracts a bit from the actual bug, and makes the helper functions a tad more complex.
# I don't think that {{loopRecoverLease}} is actually called anywhere but TestPipelinesFailover, so no need to move it to DFSTestUtil.
# I don't follow why the change in TestCommitBlockSynchronization is necessary. Doesn't seem like it should be. Am I missing something?
# I agree with Andrew that using the {{DeleteThread}} in the test case seems like it's fragile and unnecessary., Hi [~andrew.wang] and [~atm],

Thanks a lot for the review and comments. I attached version 004 to address them.

To answer ATM's question 3: the code is necessary because otherwise commitBlockSynchronization would thrown FileNotFoundException
in TestCommitBlockSynchronization introduced by this fix (see https://builds.apache.org/job/PreCommit-HDFS-Build/7584//testReport/). The code added so isFileDeleted would return true for the file, thus the intended test can be done instead of the FileNotFoundException introduced with this fix. I had a comment in the the beginning of this change:
{code}
    // set file's parent and put the file to inodeMap, so FSNamesystem's
    // isFileDeleted() method will return false on this file
{code}

Thanks.
, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12661158/HDFS-6825.004.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 4 new or modified test files.

      {color:red}-1 javac{color}.  The applied patch generated 1260 javac compiler warnings (more than the trunk's current 1259 warnings).

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/7614//testReport/
Javac warnings: https://builds.apache.org/job/PreCommit-HDFS-Build/7614//artifact/trunk/patchprocess/diffJavacWarnings.txt
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/7614//console

This message is automatically generated., Uploaded 005 to address an important issue found based on Andrew's comment "Could we also check that this works with a recursive delete on the containing folder of the open file", if a hierarchy is recursively deleted, the isFileDeleted method may not catch it. I made a fix for this in 005. Thanks Andrew!

Hi [~andrew.wang] and [~atm], thanks again for the detailed and helpful review you guys did.  Hopefully all your review comments are addressed with this revision. Would you please help taking another look? thanks a lot.
, I think the latest patch looks good to me.

[~andrew.wang] - does it look OK to you as well?

[~kihwal] - if you're around, would love to hear your thoughts as well. If you don't have time to review this today or tomorrow, though, then I'll probably just go ahead and commit it., +1 from me as well, thanks for revving Yongjun. Let's wait a little while in case Kihwal wants to comment., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12661318/HDFS-6825.005.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 4 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/7621//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/7621//console

This message is automatically generated., I will take a look at it soon., > Could we also check that this works with a recursive delete on the containing folder of the open file?
I assume the change in {{isFileDeleted()}} is for this.  I believe the recursive check is not necessary. When a tree is deleted, everything under it is recursively processed while holding FSNamesystem and FSDirectory write lock. If it does not belong to any snapshot, its parent and block field will be cleared. If in a snapshot, it will be marked as deleted.  The only thing that is not cleared while in the lock and causing this issue is the block collection field of BlockInfo.  So {{isFileDeleted()}} does not need to walk up the tree. The rest of the patch looks good., Thanks [~kihwal]! and thanks [~andrew.wang] and [~atm] for the earlier review!
 , HI [~kihwal],

Thanks a lot for the review, we were doing the last update at the same time so I just saw your review comments.

The change is {{isFileDeleted}} is to handle recursive deletion. If we remove the change in this method, we can see the test I added fail.  Say, for a path "/a/b/c/file", if we do {{fs.delete("/a/b", true)}}, what I observed is different than what you stated: it only removes "b" from a's children when holding the write lock (and delayed other removal to later), thus the {{isFileDeleted}} returned false on "/a/b/c/file".

I just rerun to collect a log for your reference. This exception happens when the test restart NN to see if the editlog is corrupted or not. With the fix I introduced in {{isFileDeleted}}, it solves this problem:
{code}
Running org.apache.hadoop.hdfs.server.namenode.TestDeleteRace
Tests run: 5, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 40.297 sec <<< FAILURE! - in org.apache.hadoop.hdfs.server.namenode.TestDeleteRace
testDeleteAndCommitBlockSynchronizationRaceHasSnapshot(org.apache.hadoop.hdfs.server.namenode.TestDeleteRace)  Time elapsed: 7.101 sec  <<< ERROR!
java.io.FileNotFoundException: File does not exist: /testdir/testdir1/test-file
        at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:65)
        at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:55)
        at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.applyEditLogOp(FSEditLogLoader.java:412)
        at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadEditRecords(FSEditLogLoader.java:227)
        at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadFSEdits(FSEditLogLoader.java:136)
        at org.apache.hadoop.hdfs.server.namenode.FSImage.loadEdits(FSImage.java:820)
        at org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:678)
        at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:281)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:972)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:715)
        at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:533)
        at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:589)
        at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:756)
        at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:740)
        at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1425)
        at org.apache.hadoop.hdfs.MiniDFSCluster.restartNameNode(MiniDFSCluster.java:1696)
        at org.apache.hadoop.hdfs.MiniDFSCluster.restartNameNodes(MiniDFSCluster.java:1651)
        at org.apache.hadoop.hdfs.server.namenode.TestDeleteRace.testDeleteAndCommitBlockSynchronizationRace(TestDeleteRace.java:317)
        at org.apache.hadoop.hdfs.server.namenode.TestDeleteRace.testDeleteAndCommitBlockSynchronizationRaceHasSnapshot(TestDeleteRace.java:338)
{code}

Thanks.
, [~yzhangal] I've verified that you are correct.  The file deletion check in snapshot case was suggested in HDFS-6527 and I thought that was good enough. Apparently not. If the full path is re-resolved after this, that can detect the deletion, but in {{commitBlockSynchronization()}}, that seems to happen too late.  Also for all other uses of {{isFileClosed()}}, walking up the tree is the only sure way to tell whether the file is deleted. So your fix is correct.

[~daryn] Watch out for this in your fine-grained directory locking.

+1 for the patch. Good work!, HI [~kihwal],

Thanks a lot for verifying and confirming, really appreciate it! 

Thanks [~andrew.wang] again for the comment about checking out recursive deletion, the process of addressing this comment led to this more complete solution than previous revisions.

, Thanks Yongjun for the patch, ATM and Kihwal for reviewing. I've committed this to trunk and branch-2., Many thanks to you all!
, FAILURE: Integrated in Hadoop-trunk-Commit #6086 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/6086/])
HDFS-6825. Edit log corruption due to delayed block removal. Contributed by Yongjun Zhang. (wang: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1618684)
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockInfoUnderConstruction.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeDirectory.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/DFSTestUtil.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestCommitBlockSynchronization.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestDeleteRace.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestPipelinesFailover.java
, FAILURE: Integrated in Hadoop-Yarn-trunk #651 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/651/])
HDFS-6825. Edit log corruption due to delayed block removal. Contributed by Yongjun Zhang. (wang: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1618684)
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockInfoUnderConstruction.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeDirectory.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/DFSTestUtil.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestCommitBlockSynchronization.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestDeleteRace.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestPipelinesFailover.java
, FAILURE: Integrated in Hadoop-Hdfs-trunk #1842 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1842/])
HDFS-6825. Edit log corruption due to delayed block removal. Contributed by Yongjun Zhang. (wang: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1618684)
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockInfoUnderConstruction.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeDirectory.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/DFSTestUtil.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestCommitBlockSynchronization.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestDeleteRace.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestPipelinesFailover.java
, FAILURE: Integrated in Hadoop-Mapreduce-trunk #1868 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1868/])
HDFS-6825. Edit log corruption due to delayed block removal. Contributed by Yongjun Zhang. (wang: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1618684)
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockInfoUnderConstruction.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeDirectory.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/DFSTestUtil.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestCommitBlockSynchronization.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestDeleteRace.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestPipelinesFailover.java
]