[Stack from a jenkins build
{code}
ava.net.BindException: Port in use: 0.0.0.0:50075
	at sun.nio.ch.Net.bind(Native Method)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:126)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:59)
	at org.mortbay.jetty.nio.SelectChannelConnector.open(SelectChannelConnector.java:216)
	at org.apache.hadoop.http.HttpServer2.openListeners(HttpServer2.java:853)
	at org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:794)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.startInfoServer(DataNode.java:372)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:730)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:278)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:1871)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:1765)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.createDataNode(DataNode.java:1805)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.createDataNode(DataNode.java:1795)
	at org.apache.hadoop.hdfs.TestDatanodeConfig.testMemlockLimit(TestDatanodeConfig.java:133)
{code], Patch attached. Another test case in the file starts a DN and doesn't turn it off at the end, potentially taking the port. I changed it to turn this DN off in a try/finally. I also changed it to use port 0 for the data and HTTP port, a belt-and-suspenders approach to fixing the issue., {code}
+    conf.set(DFSConfigKeys.DFS_DATANODE_ADDRESS_KEY, "0.0.0.0:0");
{code}

Can you use {{localhost:0}} instead of {{0.0.0.0:0}}? On windows it is possible to trigger UAC when listening on all interfaces., Hmm, interesting. "0.0.0.0" is in DFSConfigKeys for DFS_DATANODE_ADDRESS_DEFAULT, so this patch doesn't make it any worse. If binding to 0.0.0.0 is problematic on Windows, isn't the scope of fixing this issue quite a bit larger than just this test?, bq. Hmm, interesting. "0.0.0.0" is in DFSConfigKeys for DFS_DATANODE_ADDRESS_DEFAULT, so this patch doesn't make it any worse.

This is two different issues. Though arguably it is usually okay to trigger UAC when starting a DataNode, but it is unfavorable to trigger UAC during automated testings. When fixing a test, I think it is better to make it robust (as this is a simple change) instead of deferring the fix to another jira., My point is that this is a broad issue. We either need to update basically wherever we start a minicluster, or come up with a more systematic way of fixing the issue.

I'm fine changing it in this one circumstance, but it feels like the little dutch boy with his finger in the dyke., New patch specifying "localhost" rather than "0.0.0.0", +1 pending jenkins., {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12641373/hdfs-6213-1.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/6693//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/6693//console

This message is automatically generated., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12641379/hdfs-6213-2.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.server.balancer.TestBalancerWithNodeGroup

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/6696//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/6696//console

This message is automatically generated., The balancer is a known flaky, so I'm declaring this Jenkins run clean. Thanks for the review Haohui and the report Steve, I'll commit this shortly., Merged to trunk and branch-2, thanks again folks., I typo'd this in the commit message as HDFS-5213, so no hudson emails will show up here.]