[I tested this by starting a secure DataNode with an address with port 1023., Indeed, this is correct:

{code}
➜  ~  python -m SimpleHTTPServer 1023
socket.error: [Errno 13] Permission denied
➜  ~  python -m SimpleHTTPServer 1024
Serving HTTP on 0.0.0.0 port 1024 ...
{code}

+1 pending jenkins., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12560261/HDFS-4295.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.server.balancer.TestBalancerWithNodeGroup

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/3627//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/3627//console

This message is automatically generated., +1, lgtm. Thanks Stephen., Committed to trunk and branch-2. Thanks Stephen., Integrated in Hadoop-trunk-Commit #3107 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/3107/])
    HDFS-4295. Using port 1023 should be valid when starting Secure DataNode. Contributed by Stephen Chu. (Revision 1419854)

     Result = SUCCESS
todd : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1419854
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/SecureDataNodeStarter.java
, Integrated in Hadoop-Yarn-trunk #62 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/62/])
    HDFS-4295. Using port 1023 should be valid when starting Secure DataNode. Contributed by Stephen Chu. (Revision 1419854)

     Result = FAILURE
todd : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1419854
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/SecureDataNodeStarter.java
, Integrated in Hadoop-Hdfs-trunk #1251 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1251/])
    HDFS-4295. Using port 1023 should be valid when starting Secure DataNode. Contributed by Stephen Chu. (Revision 1419854)

     Result = FAILURE
todd : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1419854
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/SecureDataNodeStarter.java
, Integrated in Hadoop-Mapreduce-trunk #1282 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1282/])
    HDFS-4295. Using port 1023 should be valid when starting Secure DataNode. Contributed by Stephen Chu. (Revision 1419854)

     Result = SUCCESS
todd : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1419854
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/SecureDataNodeStarter.java
, The jsvc program is used to start the DataNode listening on low port numbers, but DataNode cannot be started while running as no root user.
The exception as follow：
  Initializing secure datanode resources
java.lang.reflect.InvocationTargetException
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.commons.daemon.support.DaemonLoader.load(DaemonLoader.java:164)
Caused by: java.net.SocketException: Permission denied
	at sun.nio.ch.Net.bind(Native Method)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:126)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:59)
	at org.apache.hadoop.hdfs.server.datanode.SecureDataNodeStarter.init(SecureDataNodeStarter.java:76)
	... 5 more
Cannot load daemon

anything I missed? , You need to be root in order to bind to low ports, jsvc doesn't have anything to do with that. The DN uses jsvc so that it can start as root, bind to the low port, and then switch users to hdfs for the rest of its run. So, you need to start the DN as root when enabling security and running with jsvc - no way around that., Thanks Aaron for this workaround.

1. calls the SecureDataNodeStarter.init() method while running as root;
2. then calls SecureDataNodeStarter.start() method while running as hdfs;

how to execute the script for statrting the datanode?, Hi liuyang, we should really continue this conversation on the user@hadoop.apache.org mailing list, since it's not an issue with this bug/patch. The short answer to your question is: you have to start the DN as root, and make sure that the HADOOP_SECURE_DN_USER environment variable is set to 'hdfs' so that the DN knows which user to switch to.

If you have any more questions about this, please email user@hadoop.apache.org.]