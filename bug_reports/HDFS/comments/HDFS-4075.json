[We had a group of 40 nodes that were decommissioned then recommissioned. When they got recommissioned by refreshing nodes using dfsadmin, there were over 5M over-replicated blocks, so holding the write lock the NN (RPC handler) went through each of them and generated two log messages per block.  That took about 5 minutes and over 2GB of log were written.  Because of the locking, the namenode was unresponsive for the whole time.

I tested the commons-logging + log4j FileAppender family combination for its performance and it was clear that the above case was hitting the logging bottleneck. When comparing logging a single character vs. 400 bytes, time to finish logging 1,000,000 messages didn't seem much different. It was not IO bound, but CPU bound as the CPU stayed 100% the whole time. Changing FileAppender properties affected the timing a bit but not a lot.  It seems this is the inherent limit of this logging mechanism.

For a single character logging, each message took 19-23us. Or it could do about 42K logs/sec with CPU at 100%, almost no IO wait time.  We can see that the namenode in the case given above were spending almost all of its time logging. The IO overhead was not significant., On recommissioning, the dead nodes will not cause this overhead at that moment (i.e. not in the same write lock block). They will do their own share of logging storm when they rejoin and send in the full block reports, which would block the namenode for 6-7 seconds in the above example. They will at least let others run in between such block reports. Or the nodes can be brought up in a controlled manner to reduce the impact. E.g. two data node start-ups per minute.

But the live nodes at the time of recommissioning can cause problems, unless processing of potentially over-replicated blocks become asynchronous to recommissioning and also throttled. Doing invalidation inline but pausing and releasing the lock won't be ideal since it will prolong the duration of refreshNode command execution. Delaying this work using the mis-replicated blocks handling can make it asynchronous, but it cannot be throttled; at the next block report, all will be processed.

I think the simplest remedy is to disable the state change logging for block invalidation during recommissioning. 

On a busy namenode, the overhead of logging every block state change may not be negligible. We might want to add a capability to selectively disable certain class of state change logging. (There are already places that disables logging for every block)
, The patch demotes the logging level of over-replicated block invalidation to DEBUG. On recommissioning, it prints out the summary instead.

This patch does not cleanly apply to branch-0.23, but it is due to a simple context difference., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12549762/hdfs-4075.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/3366//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/3366//console

This message is automatically generated., No test was added for this only changes logging behavior., Filed HDFS-4080 for changing the logging behavior for all other block-level state change messages., Hi Kihwal!

The log message is

bq. LOG.info("Invalidated" + numOverReplicated + " over-replicated blocks on " +
bq.        srcNode + " during recommissioning");

which might mislead me to believe that the block invalidated was on srcNode, when it could be any one of the 4 nodes. Maybe something to the effect "Recommissioning of srcNode led to numOverReplicated over-replicated blocks to be invalidated"? 

Can you please also explain the change in DatanodeManager.java in this patch? node.isAlive will be updated only when the node heartbeats in. So when will blockManager.processOverReplicatedBlocksOnReCommission(node);
be called?

, If HDFS-4080 goes, we won't need this. Switching effort to HDFS-4080., bq. Can you please also explain the change in DatanodeManager.java in this patch? node.isAlive will be updated only when the node heartbeats in. So when will blockManager.processOverReplicatedBlocksOnReCommission(node);
be called?

When a node registers and sends in its first full block report, over-replicated blocks will be taken care of. So it is wasteful to go over the blocks owned by dead nodes on recommission.

I will revisit this issue after HDFS-3937 and HDFS-4080., I excluded the logging change since HDFS-4080 will take care of it. The patch lets the recommissioning skip the over-replication check for dead nodes and logs the total number overreplicated blocks per node.

I expect the future lock improvement will reduce the duration of namespace write locking., +1 I think it looks ok.  Eli, can you confirm?, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12551560/hdfs-4075.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/3434//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/3434//console

This message is automatically generated., +1 the patch looks good.  One minor comment: it is better to add a space after "Invalidated".

{code}
+    LOG.info("Invalidated" + numOverReplicated + " over-replicated blocks on " +
+        srcNode + " during recommissioning");
{code}, Added a space as Nicholas suggested., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12552275/hdfs-4075.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/3452//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/3452//console

This message is automatically generated., +1  Great job with the space! ;)  Will commit shortly., Integrated in Hadoop-trunk-Commit #2963 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/2963/])
    HDFS-4075. Reduce recommissioning overhead (Kihwal Lee via daryn) (Revision 1406278)

     Result = SUCCESS
daryn : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1406278
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java
, I've committed to trunk, branch 2 & 23.  Thanks Kihwal!, Integrated in Hadoop-Yarn-trunk #29 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/29/])
    HDFS-4075. Reduce recommissioning overhead (Kihwal Lee via daryn) (Revision 1406278)

     Result = SUCCESS
daryn : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1406278
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java
, Integrated in Hadoop-Hdfs-0.23-Build #428 (See [https://builds.apache.org/job/Hadoop-Hdfs-0.23-Build/428/])
    svn merge -c 1406278 FIXES: HDFS-4075. Reduce recommissioning overhead (Kihwal Lee via daryn) (Revision 1406290)

     Result = SUCCESS
daryn : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1406290
Files : 
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java
, Integrated in Hadoop-Hdfs-trunk #1219 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1219/])
    HDFS-4075. Reduce recommissioning overhead (Kihwal Lee via daryn) (Revision 1406278)

     Result = SUCCESS
daryn : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1406278
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java
, Integrated in Hadoop-Mapreduce-trunk #1249 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1249/])
    HDFS-4075. Reduce recommissioning overhead (Kihwal Lee via daryn) (Revision 1406278)

     Result = FAILURE
daryn : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1406278
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java
, {quote}
+1 I think it looks ok. Eli, can you confirm?
{quote}

+1 lgtm as well]