[Here's a patch with a unit test and a fix. Could people please review it?, \\
\\
| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | pre-patch |  14m 49s | Pre-patch trunk compilation is healthy. |
| {color:green}+1{color} | @author |   0m  0s | The patch does not contain any @author tags. |
| {color:green}+1{color} | tests included |   0m  0s | The patch appears to include 1 new or modified test files. |
| {color:green}+1{color} | javac |   7m 27s | There were no new javac warning messages. |
| {color:green}+1{color} | javadoc |   9m 41s | There were no new javadoc warning messages. |
| {color:green}+1{color} | release audit |   0m 23s | The applied patch does not increase the total number of release audit warnings. |
| {color:red}-1{color} | checkstyle |   2m 13s | The applied patch generated  27 new checkstyle issues (total was 1255, now 1257). |
| {color:green}+1{color} | whitespace |   0m  8s | The patch has no lines that end in whitespace. |
| {color:green}+1{color} | install |   1m 34s | mvn install still works. |
| {color:green}+1{color} | eclipse:eclipse |   0m 33s | The patch built with eclipse:eclipse. |
| {color:green}+1{color} | findbugs |   3m  5s | The patch does not introduce any new Findbugs (version 2.0.3) warnings. |
| {color:green}+1{color} | native |   3m 13s | Pre-build of native portion |
| {color:red}-1{color} | hdfs tests | 164m 36s | Tests failed in hadoop-hdfs. |
| | | 207m 48s | |
\\
\\
|| Reason || Tests ||
| Failed unit tests | hadoop.tracing.TestTraceAdmin |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12731225/HDFS-8344.01.patch |
| Optional Tests | javadoc javac unit findbugs checkstyle |
| git revision | trunk / daf3e4e |
| checkstyle |  https://builds.apache.org/job/PreCommit-HDFS-Build/10850/artifact/patchprocess/diffcheckstylehadoop-hdfs.txt |
| hadoop-hdfs test log | https://builds.apache.org/job/PreCommit-HDFS-Build/10850/artifact/patchprocess/testrun_hadoop-hdfs.txt |
| Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/10850/testReport/ |
| Java | 1.7.0_55 |
| uname | Linux asf904.gq1.ygridcore.net 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/10850/console |


This message was automatically generated., First of all I don't think reducing lease limit times like this is not acceptable. Transient conditions can easily cause clients to lose their lease.
{code}
-  long LEASE_SOFTLIMIT_PERIOD = 60 * 1000;
-  long LEASE_HARDLIMIT_PERIOD = 60 * LEASE_SOFTLIMIT_PERIOD;
+  long LEASE_SOFTLIMIT_PERIOD = 30 * 1000;
+  long LEASE_HARDLIMIT_PERIOD = 2 * LEASE_SOFTLIMIT_PERIOD;
{code}

Finalizing blocks without checking the actual replica state will very likely cause "corruption" later. , Thanks for your review [~kihwal] . I'm sorry [that change|https://issues.apache.org/jira/browse/HDFS-7342?focusedCommentId=14520401&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14520401] accidentally leaked into the patch. I was using that change to test easily. Here's another patch without that change and some more documentation.

bq. Finalizing blocks without checking the actual replica state will very likely cause "corruption" later. 
That is correct. However its unavoidable. e.g. If the client was writing with replication=1, and it dies, the lease would not be recovered for (by default) another 1 hour. If during this one hour, the datanode also failed, then we have genuinely lost the data (that we acked to the client before it crashed) and the file should be marked corrupt. I fail to see any point in keeping the lease open forever hoping that at some point we will be able to bring the block back. I'm completely open on how long we want to wait as long as its not forever. With this patch we wait until we have tried to set each possible replica to be the primary for 5 times. Would you prefer some other timeout? 
, bq. I'm completely open on how long we want to wait as long as its not forever.
That's fine as long as we can easily recover the data if the datanode comes back after the force-close. If blindly completed, the block size will probably be whatever was in the Receiving IBR, regardless of how much data was actually written. This will prevent clients from retrieving the data. Maybe we could explore setting to the default block size when doing this. Size won't match anyway, but we won't truncate and lose data this way.  , \\
\\
| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | pre-patch |  18m 40s | Pre-patch trunk compilation is healthy. |
| {color:green}+1{color} | @author |   0m  0s | The patch does not contain any @author tags. |
| {color:green}+1{color} | tests included |   0m  0s | The patch appears to include 1 new or modified test files. |
| {color:green}+1{color} | javac |   8m 56s | There were no new javac warning messages. |
| {color:green}+1{color} | javadoc |  11m  8s | There were no new javadoc warning messages. |
| {color:green}+1{color} | release audit |   0m 29s | The applied patch does not increase the total number of release audit warnings. |
| {color:red}-1{color} | checkstyle |   2m 46s | The applied patch generated  3 new checkstyle issues (total was 499, now 500). |
| {color:green}+1{color} | whitespace |   0m  0s | The patch has no lines that end in whitespace. |
| {color:green}+1{color} | install |   1m 50s | mvn install still works. |
| {color:green}+1{color} | eclipse:eclipse |   0m 34s | The patch built with eclipse:eclipse. |
| {color:green}+1{color} | findbugs |   3m 10s | The patch does not introduce any new Findbugs (version 2.0.3) warnings. |
| {color:green}+1{color} | native |   3m 17s | Pre-build of native portion |
| {color:red}-1{color} | hdfs tests |  75m 50s | Tests failed in hadoop-hdfs. |
| | | 126m 43s | |
\\
\\
|| Reason || Tests ||
| Failed unit tests | hadoop.hdfs.tools.TestHdfsConfigFields |
| Timed out tests | org.apache.hadoop.hdfs.TestSmallBlock |
|   | org.apache.hadoop.hdfs.TestDFSStorageStateRecovery |
|   | org.apache.hadoop.hdfs.TestRenameWhileOpen |
|   | org.apache.hadoop.hdfs.TestPread |
|   | org.apache.hadoop.hdfs.TestRollingUpgrade |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12732002/HDFS-8344.02.patch |
| Optional Tests | javadoc javac unit findbugs checkstyle |
| git revision | trunk / ea11590 |
| checkstyle |  https://builds.apache.org/job/PreCommit-HDFS-Build/10919/artifact/patchprocess/diffcheckstylehadoop-hdfs.txt |
| hadoop-hdfs test log | https://builds.apache.org/job/PreCommit-HDFS-Build/10919/artifact/patchprocess/testrun_hadoop-hdfs.txt |
| Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/10919/testReport/ |
| Java | 1.7.0_55 |
| uname | Linux asf904.gq1.ygridcore.net 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/10919/console |


This message was automatically generated., At the time that a client is streaming data to a pipeline, don't only two entities know the size of the block: the client and the datanodes? So if the client has died, do we have any choice but to trust the datanodes' IBR?

I would hope that once a Datanode has acked a packet, even if it immediately crashes after sending out the ack, then the size of the block that *it* would read on coming back up is till the last packet it acked. Isn't that so?, I guess the question is when do we consider data to be successfully written to HDFS? After the client has received and ack, or is it only after the client has successfully closed the file stream? Or something in between?, The initial IBR (receiving) usually has the size of the first packet, since that's what's sent during the creation of the block output stream. The final size is reported in the "received" IBR, which is sent after the block replica is finalized. The official size is set when the client commits the block with the gen stamp and the size.

Let's look at the block creation cycle.
{panel}
a. The NN serves addBlock() request for the client. The new block is added to the block collection (INode).
b. The client calls createBlockOutputStream() and write the first packet of the block.
c. The datanodes receive the first packet and send receiving IBR to the NN.
d. The client keeps writing.
e. The client send the last packet. The datanodes finalize the block and send received IBR to the NN.
f. Once the client receives ACK for the last packet, commits the block on the namenode (either by addBlock() or complete()).
{panel}

A cleint can fail at any time, but we are interested in the cases where the namenode has block locations but the client does not close the file. If the client fails right after {{a}}, no datanodes actually has the block. The size should be 0. If the client fails after {{b}} but before {{e}}, the size will be that of the first packet. 

I agree that such file should not be left dangling for a long time. Since we do not want unconditionally discarding the last block, let's first think about detecting and reporting such files. If block recovery fails n times, it can be reported in the metrics as well as the UI. Admins can bring back the node, truncate the file, or delete it.  If one kind of certain action is always preferred, that can be automated externally.  What do you think?, Thanks for the explanation Kihwal! I've been trying to find out in code where it does all these steps. 
a. [NameNodeRPCServer.addBlock|https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNodeRpcServer.java#L711]
b. [DataStreamer.nextBlockOutputStream()|https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DataStreamer.java#L1448] calls [DataStreamer.createBlockOutputStream|https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DataStreamer.java#L1470]
c. I see [DataStreamer.writeBlock|https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java#L809] -> [BlockReceiver.receiveBlock|https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java#L788] -> [BlockReceiver.receivePacket|https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java#L471] :( but I can't find the call of the first IBR. Could you please point me to it?
d. Inside [DataXceiver.writeBlock|https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java#L809] -> [blockReceiver.receiveBlock|https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java#L788]
e. Seems to happen on [DataXceiver.writeBlock|https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java#L833] -> [DataNode.closeBlock|https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java#L2242] -> [BPOfferService.notifyNamenodeReceivedBlock|https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BPOfferService.java#L242] -> [BPServiceActor.notifyNamenodeBlock|https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BPServiceActor.java#L338]
f. [DFSOutputStream.completeFile|https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java#L811]
, bq.  I can't find the call of the first IBR. Could you please point me to it?
This wasn't part of the original incremental BR work. It was later added by HDFS-2691., Thanks for the pointer Kihwal! When the Datanode first comes up, I see it is calling [BlockPoolSlice.validateIntegrityAndSetLength|https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/BlockPoolSlice.java#L604] for blocks that haven't been finalized. Need we do anything else?, Hi Kihwal! Here's a patch which improves the test to ensure that data that was once hsynced is read back correctly. Could you please review it?, \\
\\
| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | pre-patch |  14m 56s | Pre-patch trunk compilation is healthy. |
| {color:green}+1{color} | @author |   0m  0s | The patch does not contain any @author tags. |
| {color:green}+1{color} | tests included |   0m  0s | The patch appears to include 1 new or modified test files. |
| {color:green}+1{color} | javac |   7m 33s | There were no new javac warning messages. |
| {color:green}+1{color} | javadoc |   9m 44s | There were no new javadoc warning messages. |
| {color:green}+1{color} | release audit |   0m 24s | The applied patch does not increase the total number of release audit warnings. |
| {color:red}-1{color} | checkstyle |   2m 22s | The applied patch generated  3 new checkstyle issues (total was 488, now 489). |
| {color:green}+1{color} | whitespace |   0m  1s | The patch has no lines that end in whitespace. |
| {color:green}+1{color} | install |   1m 36s | mvn install still works. |
| {color:green}+1{color} | eclipse:eclipse |   0m 35s | The patch built with eclipse:eclipse. |
| {color:green}+1{color} | findbugs |   3m 10s | The patch does not introduce any new Findbugs (version 3.0.0) warnings. |
| {color:green}+1{color} | native |   3m 17s | Pre-build of native portion |
| {color:red}-1{color} | hdfs tests | 164m 35s | Tests failed in hadoop-hdfs. |
| | | 208m 17s | |
\\
\\
|| Reason || Tests ||
| Failed unit tests | hadoop.hdfs.TestAppendSnapshotTruncate |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12734291/HDFS-8344.03.patch |
| Optional Tests | javadoc javac unit findbugs checkstyle |
| git revision | trunk / 6329bd0 |
| checkstyle |  https://builds.apache.org/job/PreCommit-HDFS-Build/11066/artifact/patchprocess/diffcheckstylehadoop-hdfs.txt |
| hadoop-hdfs test log | https://builds.apache.org/job/PreCommit-HDFS-Build/11066/artifact/patchprocess/testrun_hadoop-hdfs.txt |
| Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/11066/testReport/ |
| Java | 1.7.0_55 |
| uname | Linux asf903.gq1.ygridcore.net 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/11066/console |


This message was automatically generated., Fixing checkstyle -1. The test failure is not because of this patch. I wasn't able to make the test fail. Using this simple change to kick the commit build again, \\
\\
| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | pre-patch |  14m 34s | Pre-patch trunk compilation is healthy. |
| {color:green}+1{color} | @author |   0m  0s | The patch does not contain any @author tags. |
| {color:green}+1{color} | tests included |   0m  0s | The patch appears to include 1 new or modified test files. |
| {color:green}+1{color} | javac |   7m 28s | There were no new javac warning messages. |
| {color:green}+1{color} | javadoc |   9m 34s | There were no new javadoc warning messages. |
| {color:green}+1{color} | release audit |   0m 22s | The applied patch does not increase the total number of release audit warnings. |
| {color:red}-1{color} | checkstyle |   2m 14s | The applied patch generated  2 new checkstyle issues (total was 488, now 488). |
| {color:green}+1{color} | whitespace |   0m  1s | The patch has no lines that end in whitespace. |
| {color:green}+1{color} | install |   1m 34s | mvn install still works. |
| {color:green}+1{color} | eclipse:eclipse |   0m 32s | The patch built with eclipse:eclipse. |
| {color:green}+1{color} | findbugs |   3m  5s | The patch does not introduce any new Findbugs (version 3.0.0) warnings. |
| {color:green}+1{color} | native |   3m 14s | Pre-build of native portion |
| {color:green}+1{color} | hdfs tests | 163m 51s | Tests passed in hadoop-hdfs. |
| | | 206m 32s | |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12734642/HDFS-8344.04.patch |
| Optional Tests | javadoc javac unit findbugs checkstyle |
| git revision | trunk / 4513761 |
| checkstyle |  https://builds.apache.org/job/PreCommit-HDFS-Build/11089/artifact/patchprocess/diffcheckstylehadoop-hdfs.txt |
| hadoop-hdfs test log | https://builds.apache.org/job/PreCommit-HDFS-Build/11089/artifact/patchprocess/testrun_hadoop-hdfs.txt |
| Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/11089/testReport/ |
| Java | 1.7.0_55 |
| uname | Linux asf909.gq1.ygridcore.net 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/11089/console |


This message was automatically generated., It also seems that hsync simply waits for the packets to be acknowledged. Which would imply that the data persistence guarantee we give to clients is when they get an ACK. Is that right?, Hi! Could I please get some review comments on this JIRA? I would like it to make it into 2.7.1 if it can. , Here's an upmerged patch that applies cleanly on trunk. Could someone please review it?, \\
\\
| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:red}-1{color} | pre-patch |  17m 52s | Pre-patch trunk has 1 extant Findbugs (version 3.0.0) warnings. |
| {color:green}+1{color} | @author |   0m  0s | The patch does not contain any @author tags. |
| {color:green}+1{color} | tests included |   0m  0s | The patch appears to include 1 new or modified test files. |
| {color:green}+1{color} | javac |   7m 34s | There were no new javac warning messages. |
| {color:green}+1{color} | javadoc |   9m 34s | There were no new javadoc warning messages. |
| {color:green}+1{color} | release audit |   0m 22s | The applied patch does not increase the total number of release audit warnings. |
| {color:red}-1{color} | checkstyle |   2m 11s | The applied patch generated  2 new checkstyle issues (total was 434, now 434). |
| {color:red}-1{color} | whitespace |   0m  0s | The patch has 2  line(s) that end in whitespace. Use git apply --whitespace=fix. |
| {color:green}+1{color} | install |   1m 33s | mvn install still works. |
| {color:green}+1{color} | eclipse:eclipse |   0m 32s | The patch built with eclipse:eclipse. |
| {color:green}+1{color} | findbugs |   3m 13s | The patch does not introduce any new Findbugs (version 3.0.0) warnings. |
| {color:green}+1{color} | native |   3m 17s | Pre-build of native portion |
| {color:red}-1{color} | hdfs tests | 161m 50s | Tests failed in hadoop-hdfs. |
| | | 208m  1s | |
\\
\\
|| Reason || Tests ||
| Failed unit tests | hadoop.hdfs.web.TestWebHDFSForHA |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12743751/HDFS-8344.05.patch |
| Optional Tests | javadoc javac unit findbugs checkstyle |
| git revision | trunk / fc92d3e |
| Pre-patch Findbugs warnings | https://builds.apache.org/job/PreCommit-HDFS-Build/11585/artifact/patchprocess/trunkFindbugsWarningshadoop-hdfs.html |
| checkstyle |  https://builds.apache.org/job/PreCommit-HDFS-Build/11585/artifact/patchprocess/diffcheckstylehadoop-hdfs.txt |
| whitespace | https://builds.apache.org/job/PreCommit-HDFS-Build/11585/artifact/patchprocess/whitespace.txt |
| hadoop-hdfs test log | https://builds.apache.org/job/PreCommit-HDFS-Build/11585/artifact/patchprocess/testrun_hadoop-hdfs.txt |
| Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/11585/testReport/ |
| Java | 1.7.0_55 |
| uname | Linux asf901.gq1.ygridcore.net 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/11585/console |


This message was automatically generated., The unit test and checkstyle problems are not because of this patch. I can upload a patch with the whitespace fix once someone reviews , +1, Hi, [~raviprak].

{code}
67	  private int recoveryAttemptsBeforeMarkingBlockMissing = 5;
{code}

Should this be configurable? I think infinite is conservative and preferable default value in order to avoid data loss and keep current behavior. 5 could be used as threshold to show warning message as [~kihwal] suggested.
, Hi Masatake! Thank you very much for the review. I'll make it a configurable. However I would prefer strongly to not keep the default at infinity. By the time this code gets exercised, the data loss has most likely already occurred. The nodes that were partially written to, are gone and have been gone for a while. At that point, we simply want the file leases to be recovered, and a notication (that data loss did indeed occur). Waiting forever would deprive us of those two benefits. I'll upload another patch soon, Here's a patch where the number of maximum attempts is configurable. [~iwasakims] Could you please review it?
Please also note that I wasn't able to find another instance where Block or its subclasses used something from Configuration. To avoid creating a Configuration object on the creation of every block I am getting that value from a static field in BlockManager., \\
\\
| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | pre-patch |  17m 13s | Pre-patch trunk compilation is healthy. |
| {color:green}+1{color} | @author |   0m  0s | The patch does not contain any @author tags. |
| {color:green}+1{color} | tests included |   0m  0s | The patch appears to include 1 new or modified test files. |
| {color:green}+1{color} | javac |   7m 40s | There were no new javac warning messages. |
| {color:green}+1{color} | javadoc |   9m 41s | There were no new javadoc warning messages. |
| {color:green}+1{color} | release audit |   0m 22s | The applied patch does not increase the total number of release audit warnings. |
| {color:red}-1{color} | checkstyle |   1m 24s | The applied patch generated  5 new checkstyle issues (total was 854, now 855). |
| {color:green}+1{color} | whitespace |   0m  1s | The patch has no lines that end in whitespace. |
| {color:green}+1{color} | install |   1m 23s | mvn install still works. |
| {color:green}+1{color} | eclipse:eclipse |   0m 33s | The patch built with eclipse:eclipse. |
| {color:red}-1{color} | findbugs |   2m 37s | The patch appears to introduce 1 new Findbugs (version 3.0.0) warnings. |
| {color:green}+1{color} | native |   3m  4s | Pre-build of native portion |
| {color:red}-1{color} | hdfs tests | 161m 46s | Tests failed in hadoop-hdfs. |
| | | 205m 47s | |
\\
\\
|| Reason || Tests ||
| FindBugs | module:hadoop-hdfs |
| Failed unit tests | hadoop.hdfs.TestDistributedFileSystem |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12745662/HDFS-8344.06.patch |
| Optional Tests | javadoc javac unit findbugs checkstyle |
| git revision | trunk / 1ba2986 |
| checkstyle |  https://builds.apache.org/job/PreCommit-HDFS-Build/11730/artifact/patchprocess/diffcheckstylehadoop-hdfs.txt |
| Findbugs warnings | https://builds.apache.org/job/PreCommit-HDFS-Build/11730/artifact/patchprocess/newPatchFindbugsWarningshadoop-hdfs.html |
| hadoop-hdfs test log | https://builds.apache.org/job/PreCommit-HDFS-Build/11730/artifact/patchprocess/testrun_hadoop-hdfs.txt |
| Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/11730/testReport/ |
| Java | 1.7.0_55 |
| uname | Linux asf900.gq1.ygridcore.net 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/11730/console |


This message was automatically generated., A quick question: What would make a good value of the configuration? It seems to me that making the retry time configurable does not solve the problem., The retry time is a reflection of how long the administrator is willing to wait before saying "I have waited so long to wait for the node to come back. But after this much time the node is surely not coming back" so I will mark this block as missing. I am completely open to how long the default value should be (as long as its not infinity). There are arguments to keeping this time short e.g. admins might want to know asap that a node they have removed from the cluster should be brought back to prevent data loss. Ofcourse there are arguments for keeping it long too., {code}
dfs.block.uc.max.recovery.attemps
{code}

Typo on the configuration entry.  Also, should probably be in hdfs-default.xml. , Thanks a lot for the careful review Allen! Here's another with the fixes., +1 lgtm, Then the question becomes what would be a good default value of configuration? Why does it require retrying on UC blocks for a number of times instead of just marking the block as missing when the hard limit expire?, Thanks for the review Allen, Kihwal, Masatake and Haohui. I've committed this to trunk and branch-2.

I just saw your comment Haohui. The datanode might be busy and recovery may fail the first time. I thought it best to try recovery a few times before giving up., SUCCESS: Integrated in Hadoop-trunk-Commit #8186 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/8186/])
HDFS-8344. NameNode doesn't recover lease for files with missing blocks (raviprak) (raviprak: rev e4f756260f16156179ba4adad974ec92279c2fac)
* hadoop-hdfs-project/hadoop-hdfs/src/main/resources/hdfs-default.xml
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSConfigKeys.java
* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockInfoUnderConstruction.java
* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestLeaseRecovery.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java
, -1. Can you please revert the commit?

I'm concerned with the complexity associated with the commit as well as the difficulty for the users to choose the right configuration. It's an internal implementation detail and it should not be exposed to users whenever it's possible. We intentionally keep the soft and hard limit not configurable to avoid the users shooting their foot.

bq. The datanode might be busy and recovery may fail the first time.

That's exactly what the hard limit / retries of leases is designed for. Again this is only one type of internal implementation towards the solution. The detail should not be exposed to the users., \\
\\
| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | pre-patch |  17m  1s | Pre-patch trunk compilation is healthy. |
| {color:green}+1{color} | @author |   0m  0s | The patch does not contain any @author tags. |
| {color:green}+1{color} | tests included |   0m  0s | The patch appears to include 1 new or modified test files. |
| {color:green}+1{color} | javac |   7m 39s | There were no new javac warning messages. |
| {color:green}+1{color} | javadoc |   9m 34s | There were no new javadoc warning messages. |
| {color:green}+1{color} | release audit |   0m 22s | The applied patch does not increase the total number of release audit warnings. |
| {color:red}-1{color} | checkstyle |   1m 20s | The applied patch generated  5 new checkstyle issues (total was 854, now 855). |
| {color:green}+1{color} | whitespace |   0m  0s | The patch has no lines that end in whitespace. |
| {color:green}+1{color} | install |   1m 20s | mvn install still works. |
| {color:green}+1{color} | eclipse:eclipse |   0m 33s | The patch built with eclipse:eclipse. |
| {color:red}-1{color} | findbugs |   2m 35s | The patch appears to introduce 1 new Findbugs (version 3.0.0) warnings. |
| {color:green}+1{color} | native |   3m  4s | Pre-build of native portion |
| {color:red}-1{color} | hdfs tests | 161m 17s | Tests failed in hadoop-hdfs. |
| | | 204m 48s | |
\\
\\
|| Reason || Tests ||
| FindBugs | module:hadoop-hdfs |
| Failed unit tests | hadoop.hdfs.TestRollingUpgrade |
|   | hadoop.hdfs.TestDistributedFileSystem |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12746170/HDFS-8344.07.patch |
| Optional Tests | javadoc javac unit findbugs checkstyle |
| git revision | trunk / 98c2bc8 |
| checkstyle |  https://builds.apache.org/job/PreCommit-HDFS-Build/11754/artifact/patchprocess/diffcheckstylehadoop-hdfs.txt |
| Findbugs warnings | https://builds.apache.org/job/PreCommit-HDFS-Build/11754/artifact/patchprocess/newPatchFindbugsWarningshadoop-hdfs.html |
| hadoop-hdfs test log | https://builds.apache.org/job/PreCommit-HDFS-Build/11754/artifact/patchprocess/testrun_hadoop-hdfs.txt |
| Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/11754/testReport/ |
| Java | 1.7.0_55 |
| uname | Linux asf909.gq1.ygridcore.net 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/11754/console |


This message was automatically generated., FAILURE: Integrated in Hadoop-Yarn-trunk-Java8 #263 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk-Java8/263/])
HDFS-8344. NameNode doesn't recover lease for files with missing blocks (raviprak) (raviprak: rev e4f756260f16156179ba4adad974ec92279c2fac)
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSConfigKeys.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/resources/hdfs-default.xml
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java
* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockInfoUnderConstruction.java
* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestLeaseRecovery.java
, SUCCESS: Integrated in Hadoop-Yarn-trunk #993 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/993/])
HDFS-8344. NameNode doesn't recover lease for files with missing blocks (raviprak) (raviprak: rev e4f756260f16156179ba4adad974ec92279c2fac)
* hadoop-hdfs-project/hadoop-hdfs/src/main/resources/hdfs-default.xml
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSConfigKeys.java
* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockInfoUnderConstruction.java
* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestLeaseRecovery.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java
, FAILURE: Integrated in Hadoop-Hdfs-trunk #2190 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/2190/])
HDFS-8344. NameNode doesn't recover lease for files with missing blocks (raviprak) (raviprak: rev e4f756260f16156179ba4adad974ec92279c2fac)
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java
* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* hadoop-hdfs-project/hadoop-hdfs/src/main/resources/hdfs-default.xml
* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestLeaseRecovery.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSConfigKeys.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockInfoUnderConstruction.java
, FAILURE: Integrated in Hadoop-Hdfs-trunk-Java8 #252 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk-Java8/252/])
HDFS-8344. NameNode doesn't recover lease for files with missing blocks (raviprak) (raviprak: rev e4f756260f16156179ba4adad974ec92279c2fac)
* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java
* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestLeaseRecovery.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/resources/hdfs-default.xml
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSConfigKeys.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockInfoUnderConstruction.java
, FAILURE: Integrated in Hadoop-Mapreduce-trunk-Java8 #260 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk-Java8/260/])
HDFS-8344. NameNode doesn't recover lease for files with missing blocks (raviprak) (raviprak: rev e4f756260f16156179ba4adad974ec92279c2fac)
* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockInfoUnderConstruction.java
* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestLeaseRecovery.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/resources/hdfs-default.xml
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSConfigKeys.java
, SUCCESS: Integrated in Hadoop-Mapreduce-trunk #2209 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/2209/])
HDFS-8344. NameNode doesn't recover lease for files with missing blocks (raviprak) (raviprak: rev e4f756260f16156179ba4adad974ec92279c2fac)
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockInfoUnderConstruction.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/resources/hdfs-default.xml
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSConfigKeys.java
* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestLeaseRecovery.java
, Very well [~wheat9]. I have reverted the changes. Could you please review version 5 of the patch (HDFS-8344.05.patch). [~iwasakims] Would you be fine with this configuration hard coded like the soft and hard lease expiry times?, FAILURE: Integrated in Hadoop-trunk-Commit #8195 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/8195/])
Revert "HDFS-8344. NameNode doesn't recover lease for files with missing blocks (raviprak)" (raviprak: rev 5137b388fc9d4d716f780daf6d04292feeb9df96)
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockInfoUnderConstruction.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java
* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestLeaseRecovery.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSConfigKeys.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/resources/hdfs-default.xml
* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
, Thanks for the update, [~raviprak].

I'm comfortable with just on/off switch to retain original behaviour or just showing WARN message some tries before giving up recovery attempt., FAILURE: Integrated in Hadoop-Yarn-trunk #994 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/994/])
Revert "HDFS-8344. NameNode doesn't recover lease for files with missing blocks (raviprak)" (raviprak: rev 5137b388fc9d4d716f780daf6d04292feeb9df96)
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSConfigKeys.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/resources/hdfs-default.xml
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java
* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestLeaseRecovery.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockInfoUnderConstruction.java
* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
, FAILURE: Integrated in Hadoop-Yarn-trunk-Java8 #264 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk-Java8/264/])
Revert "HDFS-8344. NameNode doesn't recover lease for files with missing blocks (raviprak)" (raviprak: rev 5137b388fc9d4d716f780daf6d04292feeb9df96)
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockInfoUnderConstruction.java
* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestLeaseRecovery.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSConfigKeys.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/resources/hdfs-default.xml
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java
, FAILURE: Integrated in Hadoop-Hdfs-trunk #2191 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/2191/])
Revert "HDFS-8344. NameNode doesn't recover lease for files with missing blocks (raviprak)" (raviprak: rev 5137b388fc9d4d716f780daf6d04292feeb9df96)
* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestLeaseRecovery.java
* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* hadoop-hdfs-project/hadoop-hdfs/src/main/resources/hdfs-default.xml
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockInfoUnderConstruction.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSConfigKeys.java
, FAILURE: Integrated in Hadoop-Hdfs-trunk-Java8 #253 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk-Java8/253/])
Revert "HDFS-8344. NameNode doesn't recover lease for files with missing blocks (raviprak)" (raviprak: rev 5137b388fc9d4d716f780daf6d04292feeb9df96)
* hadoop-hdfs-project/hadoop-hdfs/src/main/resources/hdfs-default.xml
* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestLeaseRecovery.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSConfigKeys.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockInfoUnderConstruction.java
* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
, Hi Masatake! An on/off switch would require reading from {{Configuration}} too (which Haohui is objecting to). Thanks for your suggestion to add an additional warning. I've done so in this latest patch. Could you please review it?, SUCCESS: Integrated in Hadoop-Mapreduce-trunk-Java8 #261 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk-Java8/261/])
Revert "HDFS-8344. NameNode doesn't recover lease for files with missing blocks (raviprak)" (raviprak: rev 5137b388fc9d4d716f780daf6d04292feeb9df96)
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockInfoUnderConstruction.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/resources/hdfs-default.xml
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSConfigKeys.java
* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestLeaseRecovery.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java
, SUCCESS: Integrated in Hadoop-Mapreduce-trunk #2210 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/2210/])
Revert "HDFS-8344. NameNode doesn't recover lease for files with missing blocks (raviprak)" (raviprak: rev 5137b388fc9d4d716f780daf6d04292feeb9df96)
* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestLeaseRecovery.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/resources/hdfs-default.xml
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java
* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockInfoUnderConstruction.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSConfigKeys.java
, \\
\\
| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | pre-patch |  26m 19s | Pre-patch trunk compilation is healthy. |
| {color:green}+1{color} | @author |   0m  0s | The patch does not contain any @author tags. |
| {color:green}+1{color} | tests included |   0m  0s | The patch appears to include 1 new or modified test files. |
| {color:green}+1{color} | javac |   9m 48s | There were no new javac warning messages. |
| {color:green}+1{color} | javadoc |  12m 26s | There were no new javadoc warning messages. |
| {color:green}+1{color} | release audit |   0m 25s | The applied patch does not increase the total number of release audit warnings. |
| {color:red}-1{color} | checkstyle |   1m 48s | The applied patch generated  4 new checkstyle issues (total was 432, now 434). |
| {color:green}+1{color} | whitespace |   0m  1s | The patch has no lines that end in whitespace. |
| {color:green}+1{color} | install |   1m 55s | mvn install still works. |
| {color:green}+1{color} | eclipse:eclipse |   0m 42s | The patch built with eclipse:eclipse. |
| {color:green}+1{color} | findbugs |   2m 57s | The patch does not introduce any new Findbugs (version 3.0.0) warnings. |
| {color:green}+1{color} | native |   3m  1s | Pre-build of native portion |
| {color:red}-1{color} | hdfs tests |  89m 18s | Tests failed in hadoop-hdfs. |
| | | 148m 44s | |
\\
\\
|| Reason || Tests ||
| Failed unit tests | hadoop.hdfs.TestDistributedFileSystem |
| Timed out tests | org.apache.hadoop.hdfs.TestDFSStorageStateRecovery |
|   | org.apache.hadoop.hdfs.TestPread |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12746550/HDFS-8344.08.patch |
| Optional Tests | javadoc javac unit findbugs checkstyle |
| git revision | trunk / 4025326 |
| checkstyle |  https://builds.apache.org/job/PreCommit-HDFS-Build/11787/artifact/patchprocess/diffcheckstylehadoop-hdfs.txt |
| hadoop-hdfs test log | https://builds.apache.org/job/PreCommit-HDFS-Build/11787/artifact/patchprocess/testrun_hadoop-hdfs.txt |
| Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/11787/testReport/ |
| Java | 1.7.0_55 |
| uname | Linux asf904.gq1.ygridcore.net 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/11787/console |


This message was automatically generated., Thanks, [~raviprak]. I tested the patch on pseudo distributed cluster and it worked as expected. I'm +1(non-binding).

The failure of TestDistributedFileSystem is not related to the patch and HDFS-8785 is addressing this. TestDFSStorageStateRecovery and TestPread are succeeded on my local environment., Thanks a lot Masatake! Much appreciated. [~wheat9] Could you too please review the latest patch?, Sorry for the delay. Will do it in the next couple days., After looking through the code, instead of retrying for n times, a better approach might be set a timeout instead of retrying n times during lease recovery. It might be possible that multiple clients can try to recover the leases and quickly use up all the numbers of retries, causing the file to be closed too quickly.

That way the whole lease recovery process is bounded by time (in addition to SOFT_LIMIT and HARD_LIMIT we have today). And it also can guarantee that the lease recovery process always terminates. Thoughts?, Hi Haohui! There are arguments on both sides (time based vs count based). e.g. I may take down the cluster and bring it back up after enough time to expire the timeout in which case we wouldn't have retried enough times. 
Please let me know if you feel strongly though, and I can add one more configuration for the timeout (in addition to the number of retries). It feels like we are over-designing now. This is a rare enough event (client dies, and before the lease expiration so do the nodes it wrote to)., If you take down the cluster and bring it back up. All writing pipeline will fail and should fail.

bq. I can add one more configuration for the timeout (in addition to the number of retries)

This is the exact reason where my previous -1 comes from. This is internal implementation details and I'm very reluctant to make it configurable because (1) it's difficult to determine the right value, and (2) users can easily shoot their foots and cause data loss when these numbers are misconfigured.

bq.  It feels like we are over-designing now.

I disagree. Having only one concept for detecting failures (i.e., time out) is simpler than two (i.e., time out and number of retries)., bq. If you take down the cluster and bring it back up. All writing pipeline will fail and should fail.
That is correct. This JIRA is for the case that data loss has already occurred. i.e. client died + the DNs to which it wrote already died. We are trying to recover the lease in this JIRA. My argument was that after client+DNs have died, if I only have a timeout, I could take down the cluster. When I bring the cluster back up after the timeout value, the lease will be recovered without trying all the DNs.
bq. This is internal implementation details and I'm very reluctant to make it configurable 
Perhaps I should have said "internal hard-coded" configuration? Similar to {{recoveryAttemptsBeforeMarkingBlockMissing}} of version 8 of the patch.

bq.  Having only one concept for detecting failures (i.e., time out) is simpler than two (i.e., time out and number of retries).
Even if its simpler, there's a chance that recovery is never attempted, and that is not acceptable IMHO.
, Here's a patch with timeout and number of retries, This has been a recurring problem for both HBase and Accumulo in test rigs. I don't think we care if the value is configurable so long as it is guaranteed to terminate and does so in a reasonably short (single-digit-seconds) period of time since it is in our recovery paths., bq. Even if its simpler, there's a chance that recovery is never attempted, and that is not acceptable IMHO.

Can you explain how the NN never try to recover the lease? All leases are periodically checked in {{LeaseManager#checkLease()}}, where the recovery happens., \\
\\
| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:red}-1{color} | patch |   0m  0s | The patch command could not apply the patch during dryrun. |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12750625/HDFS-8344.09.patch |
| Optional Tests | javadoc javac unit findbugs checkstyle |
| git revision | trunk / dc7a061 |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/12003/console |


This message was automatically generated., Thanks for the report Sean! The recovery time can be modified for tests if you set the timeout super low. e.g. in the unit test {{testLeaseRecoveryWithMissingBlocks}} I use these 2 lines
{noformat}
cluster.setLeasePeriod(LEASE_PERIOD, LEASE_PERIOD);
BlockInfoUnderConstruction.setRecoveryTimeout(1);
{noformat}
 
Haohui! By recovery, I meant recovery of a replica (not lease recovery). Please let me know if you think this sequence cannot happen:
1. Client writes data
2. Client dies
3. Datanodes A, B and C (on which data) was written die
4. Lease recovery tries to recover data from Datanodes A and B but fail (because datanodes are dead)
5. Cluster is taken down
6. Datanodes A or B are resurrected
7. The cluster is brought back up after {{RECOVERY_TIMEOUT}}
8. {{FSNamesystem.getShouldForciblyCompleteMissingUCBlock}} returns true because RECOVERY_TIMEOUT has expired
9. Block is forcibly marked complete and the file is labeled as having missing blocks

IF Datanode A or B were back, the data would be recovered. The only difference would be that the lease would have been forcefully recovered. , the issue where the other reports have been showing up is HDFS-8406. I believe in several cases we're doing burn in tests against cluster deployments, so if the config isn't something we'd have people run with we ought not do it.

IIRC, the lease failures were over pretty extended periods of time. > 15 minutes for the cases where it caused my HBase failures., Hi Haohui!
Could you please review the patch?

, The TestHadoop.java file I referenced in the description., Here's a patch for trunk, | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 0s {color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green} 0m 0s {color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 8m 16s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 0m 39s {color} | {color:green} trunk passed with JDK v1.8.0_66 {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 0m 41s {color} | {color:green} trunk passed with JDK v1.7.0_91 {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 20s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 0m 52s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 14s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 1m 52s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 5s {color} | {color:green} trunk passed with JDK v1.8.0_66 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 47s {color} | {color:green} trunk passed with JDK v1.7.0_91 {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 0m 45s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 0m 35s {color} | {color:green} the patch passed with JDK v1.8.0_66 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 0m 35s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 0m 38s {color} | {color:green} the patch passed with JDK v1.7.0_91 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 0m 38s {color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} checkstyle {color} | {color:red} 0m 20s {color} | {color:red} Patch generated 6 new checkstyle issues in hadoop-hdfs-project/hadoop-hdfs (total was 354, now 359). {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 0m 49s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 11s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green} 0m 0s {color} | {color:green} Patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 2m 1s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 4s {color} | {color:green} the patch passed with JDK v1.8.0_66 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 48s {color} | {color:green} the patch passed with JDK v1.7.0_91 {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 69m 2s {color} | {color:red} hadoop-hdfs in the patch failed with JDK v1.8.0_66. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 67m 4s {color} | {color:green} hadoop-hdfs in the patch passed with JDK v1.7.0_91. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green} 0m 22s {color} | {color:green} Patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 163m 6s {color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| JDK v1.8.0_66 Failed junit tests | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure140 |
|   | hadoop.hdfs.server.datanode.TestBlockScanner |
|   | hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:0ca8df7 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12780439/HDFS-8344.10.patch |
| JIRA Issue | HDFS-8344 |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux 32922abf4829 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 778146e |
| Default Java | 1.7.0_91 |
| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_66 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_91 |
| findbugs | v3.0.0 |
| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/14023/artifact/patchprocess/diff-checkstyle-hadoop-hdfs-project_hadoop-hdfs.txt |
| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/14023/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.8.0_66.txt |
| unit test logs |  https://builds.apache.org/job/PreCommit-HDFS-Build/14023/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.8.0_66.txt |
| JDK v1.7.0_91  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/14023/testReport/ |
| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |
| Max memory used | 75MB |
| Powered by | Apache Yetus 0.2.0-SNAPSHOT   http://yetus.apache.org |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/14023/console |


This message was automatically generated.

, Removing fix-version given the patch was reverted and waiting final-commit., I believe I saw a variant of this bug.
Symptom: HBase WAL file's last block went missing. These blocks are 83 bytes according to NameNode, and cannot be deleted, cannot be recovered via hdfs debug -recoverLease command.

I am aware of at least one scenario where this can happen, when performing volume hot-swap. I suppose other operations such as datanode decommissioning might also lead to the same symptom.

When this happens, the NameNode has log like this:
{quote}
2016-10-12 16:39:32,885 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Recovering [Lease.  Holder: DFSClient_NONMAPREDUCE_751860335_1, pendingcreates: 3], src=/hbase/WALs/hadoopdev6.example.com,60020,1465915112353-splitting/hadoopdev6.example.com%2C60020%2C1465915112353.null0.1471340470256
2016-10-12 16:39:32,885 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: recoverLease: [Lease.  Holder: DFSClient_NONMAPREDUCE_751860335_1, pendingcreates: 3], src=/hbase/WALs/hadoopdev6.example.com,60020,1465915112353-splitting/hadoopdev6.example.com%2C60020%2C1465915112353.null0.1471340470256 from client DFSClient_NONMAPREDUCE_751860335_1


2016-10-12 16:39:32,885 DEBUG org.apache.hadoop.ipc.Server: IPC Server handler 0 on 8020: org.apache.hadoop.hdfs.protocol.ClientProtocol.recoverLease from 192.168.4.86:35276 Call#708331 Retry#0 for RpcKind RPC_PROTOCOL_BUFFER
2016-10-12 16:39:32,885 DEBUG org.apache.hadoop.ipc.Server:  got #708331
2016-10-12 16:39:32,886 WARN BlockStateChange: BLOCK* BlockInfoUnderConstruction.initLeaseRecovery: No blocks found, lease removed.
2016-10-12 16:39:32,886 WARN org.apache.hadoop.hdfs.StateChange: DIR* NameSystem.internalReleaseLease: File /hbase/WALs/hadoopdev6.example.com,60020,1465915112353-splitting/hadoopdev6.example.com%2C60020%2C1465915112353.null0.1471340470256 has not been closed. Lease recovery is in progress. RecoveryId = 1099610544470 for block blk_1074528903_1099610239882{blockUCState=UNDER_RECOVERY, primary
NodeIndex=-1, replicas=[]}
2016-10-12 16:39:32,887 DEBUG org.apache.hadoop.ipc.Server: IPC Server handler 0 on 8020: responding to org.apache.hadoop.hdfs.protocol.ClientProtocol.recoverLease from 192.168.4.86:35276 Call#708331 Retry#0 Wrote 36 bytes.
2016-10-12 16:39:32,887 DEBUG org.apache.hadoop.ipc.Server: IPC Server handler 0 on 8020: responding to org.apache.hadoop.hdfs.protocol.ClientProtocol.recoverLease from 192.168.4.86:35276 Call#708331 Retry#0
2016-10-12 16:39:32,887 DEBUG org.apache.hadoop.ipc.Server: Served: recoverLease queueTime= 0 procesingTime= 2
{quote}

And the lease recover would repeat every one minute non-stop., Hi Wei-Chiu Chuang! FWIW, we have not seen this bug specifically since I merged a patch in our code similar to the one I had uploaded here. Although, strangely, I did see HDFS-8406 today (lolz, after months of silence.) , | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 25s{color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  7m 32s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 55s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 31s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  3s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 14s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 53s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 44s{color} | {color:green} trunk passed {color} |
| {color:red}-1{color} | {color:red} mvninstall {color} | {color:red}  0m 30s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:red}-1{color} | {color:red} compile {color} | {color:red}  0m 30s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:red}-1{color} | {color:red} javac {color} | {color:red}  0m 30s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 29s{color} | {color:orange} hadoop-hdfs-project/hadoop-hdfs: The patch generated 7 new + 344 unchanged - 0 fixed = 351 total (was 344) {color} |
| {color:red}-1{color} | {color:red} mvnsite {color} | {color:red}  0m 30s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 11s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  0m 24s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 38s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  0m 29s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 17s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 18m 38s{color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:a9ad5d6 |
| JIRA Issue | HDFS-8344 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12780439/HDFS-8344.10.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux eb76f9f6694a 3.13.0-96-generic #143-Ubuntu SMP Mon Aug 29 20:15:20 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / dcedb72 |
| Default Java | 1.8.0_111 |
| findbugs | v3.0.0 |
| mvninstall | https://builds.apache.org/job/PreCommit-HDFS-Build/17764/artifact/patchprocess/patch-mvninstall-hadoop-hdfs-project_hadoop-hdfs.txt |
| compile | https://builds.apache.org/job/PreCommit-HDFS-Build/17764/artifact/patchprocess/patch-compile-hadoop-hdfs-project_hadoop-hdfs.txt |
| javac | https://builds.apache.org/job/PreCommit-HDFS-Build/17764/artifact/patchprocess/patch-compile-hadoop-hdfs-project_hadoop-hdfs.txt |
| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/17764/artifact/patchprocess/diff-checkstyle-hadoop-hdfs-project_hadoop-hdfs.txt |
| mvnsite | https://builds.apache.org/job/PreCommit-HDFS-Build/17764/artifact/patchprocess/patch-mvnsite-hadoop-hdfs-project_hadoop-hdfs.txt |
| findbugs | https://builds.apache.org/job/PreCommit-HDFS-Build/17764/artifact/patchprocess/patch-findbugs-hadoop-hdfs-project_hadoop-hdfs.txt |
| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/17764/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/17764/testReport/ |
| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/17764/console |
| Powered by | Apache Yetus 0.4.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

, On a second thought -- I might have bumped into HDFS-10763., Move it to 2.9 as 2.8 RC is in progress., This problem still exists in trunk today. The same steps I listed in the description can be used to reproduce this issue., Interesting... [~raviprak] are you saying even after HDFS-11499 (Decommissioning stuck because of failing recovery) It still results in 
{quote}
The effect of this bug for us was that nodes could not be decommissioned cleanly.
{quote}
I am still not convinced it is the right way to force completing a block if its replicas are all missing...., | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 15s{color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 12m 23s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 47s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 38s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 50s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 13s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 42s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 38s{color} | {color:green} trunk passed {color} |
| {color:red}-1{color} | {color:red} mvninstall {color} | {color:red}  0m 24s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:red}-1{color} | {color:red} compile {color} | {color:red}  0m 26s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:red}-1{color} | {color:red} javac {color} | {color:red}  0m 26s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 35s{color} | {color:orange} hadoop-hdfs-project/hadoop-hdfs: The patch generated 8 new + 335 unchanged - 0 fixed = 343 total (was 335) {color} |
| {color:red}-1{color} | {color:red} mvnsite {color} | {color:red}  0m 26s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m  9s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  1s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  0m 22s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 38s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  0m 27s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 17s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 22m 23s{color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:a9ad5d6 |
| JIRA Issue | HDFS-8344 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12780439/HDFS-8344.10.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux e570a51fa931 3.13.0-106-generic #153-Ubuntu SMP Tue Dec 6 15:44:32 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / e06ff18 |
| Default Java | 1.8.0_121 |
| findbugs | v3.0.0 |
| mvninstall | https://builds.apache.org/job/PreCommit-HDFS-Build/18674/artifact/patchprocess/patch-mvninstall-hadoop-hdfs-project_hadoop-hdfs.txt |
| compile | https://builds.apache.org/job/PreCommit-HDFS-Build/18674/artifact/patchprocess/patch-compile-hadoop-hdfs-project_hadoop-hdfs.txt |
| javac | https://builds.apache.org/job/PreCommit-HDFS-Build/18674/artifact/patchprocess/patch-compile-hadoop-hdfs-project_hadoop-hdfs.txt |
| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/18674/artifact/patchprocess/diff-checkstyle-hadoop-hdfs-project_hadoop-hdfs.txt |
| mvnsite | https://builds.apache.org/job/PreCommit-HDFS-Build/18674/artifact/patchprocess/patch-mvnsite-hadoop-hdfs-project_hadoop-hdfs.txt |
| findbugs | https://builds.apache.org/job/PreCommit-HDFS-Build/18674/artifact/patchprocess/patch-findbugs-hadoop-hdfs-project_hadoop-hdfs.txt |
| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/18674/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/18674/testReport/ |
| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/18674/console |
| Powered by | Apache Yetus 0.5.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

, Hi [~jojochuang]! Sorry I just noticed your comment.

I ran the steps listed in the description on trunk at the time, and was able to reproduce the issue. I ran them again today and I seem to still see the issue. Is there another timeout I should wait for, for the lease to be recovered successfully? I don't see a configuration in HDFS-11499. Could you please try the steps?, Is this still on target for 2.9.0 ? If not, can we we push this out to the next major release ?, | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 18s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 14m 40s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 54s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 43s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  0s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 10m 16s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 41s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 41s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:red}-1{color} | {color:red} mvninstall {color} | {color:red}  0m 28s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:red}-1{color} | {color:red} compile {color} | {color:red}  0m 27s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:red}-1{color} | {color:red} javac {color} | {color:red}  0m 27s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 37s{color} | {color:orange} hadoop-hdfs-project/hadoop-hdfs: The patch generated 8 new + 319 unchanged - 0 fixed = 327 total (was 319) {color} |
| {color:red}-1{color} | {color:red} mvnsite {color} | {color:red}  0m 27s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:red}-1{color} | {color:red} shadedclient {color} | {color:red}  2m 50s{color} | {color:red} patch has errors when building and testing our client artifacts. {color} |
| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  0m 21s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 38s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  0m 29s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 15s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 36m 11s{color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:71bbb86 |
| JIRA Issue | HDFS-8344 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12780439/HDFS-8344.10.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |
| uname | Linux 2a03eee8b2c9 3.13.0-129-generic #178-Ubuntu SMP Fri Aug 11 12:48:20 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 373d0a5 |
| Default Java | 1.8.0_144 |
| findbugs | v3.1.0-RC1 |
| mvninstall | https://builds.apache.org/job/PreCommit-HDFS-Build/21450/artifact/patchprocess/patch-mvninstall-hadoop-hdfs-project_hadoop-hdfs.txt |
| compile | https://builds.apache.org/job/PreCommit-HDFS-Build/21450/artifact/patchprocess/patch-compile-hadoop-hdfs-project_hadoop-hdfs.txt |
| javac | https://builds.apache.org/job/PreCommit-HDFS-Build/21450/artifact/patchprocess/patch-compile-hadoop-hdfs-project_hadoop-hdfs.txt |
| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/21450/artifact/patchprocess/diff-checkstyle-hadoop-hdfs-project_hadoop-hdfs.txt |
| mvnsite | https://builds.apache.org/job/PreCommit-HDFS-Build/21450/artifact/patchprocess/patch-mvnsite-hadoop-hdfs-project_hadoop-hdfs.txt |
| findbugs | https://builds.apache.org/job/PreCommit-HDFS-Build/21450/artifact/patchprocess/patch-findbugs-hadoop-hdfs-project_hadoop-hdfs.txt |
| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/21450/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/21450/testReport/ |
| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/21450/console |
| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

, I'm sorry for the extremely late reply Arun, but I'm afraid I don't think I'll find the cycles to work on this in the next few months. I'm unassigning myself and removing the target field. Please set it back if you think this needs a fix., | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m  0s{color} | {color:blue} Docker mode activated. {color} |
| {color:red}-1{color} | {color:red} patch {color} | {color:red}  0m  6s{color} | {color:red} HDFS-8344 does not apply to trunk. Rebase required? Wrong Branch? See https://wiki.apache.org/hadoop/HowToContribute for help. {color} |
\\
\\
|| Subsystem || Report/Notes ||
| JIRA Issue | HDFS-8344 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12780439/HDFS-8344.10.patch |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/24256/console |
| Powered by | Apache Yetus 0.8.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

]