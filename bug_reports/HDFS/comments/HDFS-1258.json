[If someone validates this, we should probably mark this as a blocker for 0.21., Let's mark this as a blocker.  We have to resolve this before new releases anyway., Unfortunately, this seems true.
# start hdfs
# put a file
# clear / quota
# restart namenode
{noformat}
2010-06-22 22:22:16,337 ERROR org.apache.hadoop.hdfs.server.namenode.FSNamesystem: FSNamesystem initialization failed.
java.io.EOFException
        at java.io.DataInputStream.readFully(DataInputStream.java:180)
        at org.apache.hadoop.io.UTF8.readFields(UTF8.java:106)
        at org.apache.hadoop.hdfs.server.namenode.FSImage.readBytes(FSImage.java:1588)
        at org.apache.hadoop.hdfs.server.namenode.FSImage.readINodeUnderConstruction(FSImage.java:1227)
        at org.apache.hadoop.hdfs.server.namenode.FSImage.loadFilesUnderConstruction(FSImage.java:1205)
        at org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:959)
        at org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:807)
        at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:364)
        at org.apache.hadoop.hdfs.server.namenode.FSDirectory.loadFSImage(FSDirectory.java:87)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initialize(FSNamesystem.java:303)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:284)
        at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:201)
        at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:279)
        at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:956)
        at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:965)
2010-06-22 22:22:16,338 INFO org.apache.hadoop.ipc.Server: Stopping server on 9000
2010-06-22 22:22:16,339 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: java.io.EOFException
        at java.io.DataInputStream.readFully(DataInputStream.java:180)
        at org.apache.hadoop.io.UTF8.readFields(UTF8.java:106)
        at org.apache.hadoop.hdfs.server.namenode.FSImage.readBytes(FSImage.java:1588)
        at org.apache.hadoop.hdfs.server.namenode.FSImage.readINodeUnderConstruction(FSImage.java:1227)
        at org.apache.hadoop.hdfs.server.namenode.FSImage.loadFilesUnderConstruction(FSImage.java:1205)
        at org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:959)
        at org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:807)
        at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:364)
        at org.apache.hadoop.hdfs.server.namenode.FSDirectory.loadFSImage(FSDirectory.java:87)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initialize(FSNamesystem.java:303)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:284)
        at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:201)
        at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:279)
        at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:956)
        at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:965)
{noformat}
, This is serious, for sure, but I think we could release 0.21.0 without it. The point of 0.21.0 is to exercise the release process, and make a Hadoop release available to people who want to try newer features and help stabilize post-20 Hadoop, so that later 0.21 releases and the 0.22 release in November will be more widely usable. 0.21 already has known issues (e.g. HDFS-875), so this one too could be called out in the release notes, so folks are made aware of its seriousness., This patch doesn't actually solve the root problem of clearing the root directory quota causing a corrupt FS image, but it will prevent people from accidentally borking their file system in the mean time, until that gets fixed., Patch looks good. Can you reupload it with the --no-prefix option to git diff, and then change to "Patch Available" status so the Hudson QA bot runs?, Same patch, but with the --no-prefix option to git diff., Patch prevents user's from clearing namespace quota on "/"., Thanks for providing a patch assigning this to you., -1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12448268/clear-quota.patch
  against trunk revision 957669.

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 3 new or modified tests.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    -1 core tests.  The patch failed core unit tests.

    -1 contrib tests.  The patch failed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h2.grid.sp2.yahoo.net/208/testReport/
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h2.grid.sp2.yahoo.net/208/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h2.grid.sp2.yahoo.net/208/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h2.grid.sp2.yahoo.net/208/console

This message is automatically generated., Both of those test failures were failing in trunk before I created the patch., The test report web site is not available at the moment.  Will check it later.

Aaron, could you also provide patches for 0.20 and 0.21?, +1.  Looks good., > Both of those test failures were failing in trunk before I created the patch. 

The failed tests were TestBlockToken and TestJspHelper.  They are not related to this.

Once the 0.20 and 0.21 patches are available.  We can commit this., Patches for 0.20 and 0.21., I have committed this to 0.20, 0.20-append and above.  Thanks, Aaron!, Integrated in Hadoop-Hdfs-trunk-Commit #331 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-Hdfs-trunk-Commit/331/])
    HDFS-1258. Clearing namespace quota on "/" corrupts fs image.  Contributed by Aaron T. Myers
, I have merged this to 0.20-security., create HDFS-7133 to support clearing namespace quota]