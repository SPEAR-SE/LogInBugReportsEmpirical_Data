[Here's a trivial patch against the current trunk that fixes this issue., HBase uses 'mapred.task.id' to keep track of RS<->DFSClient.  It needs to be compatible with 0.20-append & 0.22.  Could this patch just be changed to:
{code}
String taskId = conf.get("mapreduce.task.attempt.id", conf.get("mapred.task.id"));
{code}
Which would avoid the warnings and provide deprecation on the HDFS side as well?, Since Java evaluates the second argument to {{conf.get()}} before calling it, the warning message is still emitted (I checked this).

The {{Configuration.get()}} method automatically fetches {{mapreduce.task.attempt.id}} when you try to get {{mapred.task.id}}.
See {{addDeprecatedKeys()}} in {{src/java/org/apache/hadoop/mapreduce/util/ConfigUtil.java}} in the MapReduce code-base and
{{get()}} and {{handleDeprecation()}} in {{src/java/org/apache/hadoop/conf/Configuration.java}} in the Common code-base., See the attached patch., Actually, the use of MR related configuration parameters (e.g. from upstream project) looks like a some sort of circular dependency to me. Isn't it?, bq. Actually, the use of MR related configuration parameters (e.g. from upstream project) looks like a some sort of circular dependency to me. Isn't it?

In this case, it isn't - it's merely used as a distinguishing identifier, if available; a random number is used otherwise. In
{{src/java/org/apache/hadoop/hdfs/DFSClient.java}} we have:
{code}
256     String taskId = conf.get("mapred.task.id");
257     if (taskId != null) {
258       this.clientName = "DFSClient_" + taskId;
259     } else {
260       this.clientName = "DFSClient_" + r.nextInt();
261     }
{code}, Yes, I have seen the code. It poses the problem nonetheless (and we already face it here): when a configuration parameter got deprecated in the upstream project (MR) we are forced to change downstream library. Pretty bad, I think., -1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12455481/HDFS-1418.patch
  against trunk revision 1051669.

    +1 @author.  The patch does not contain any @author tags.

    -1 tests included.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    -1 patch.  The patch command could not apply the patch.

Console output: https://hudson.apache.org/hudson/job/PreCommit-HDFS-Build/20//console

This message is automatically generated., I agree with Konstantin, it would have been a circular dependency on the projects if we used the respective MR constant for this parameter. But its is not if we treat it as an hdfs parameter. 
Suppose we had an HDFS parameter "dfs.client.id", which MR & HBASE populate from "mapreduce.task.attempt.id", then there is no dependency. We can think that "dfs.client.id" is just happened to have the same name as in MR and treat it as HDFS parameter. Or we can actually rename it now taking into account the compatibility issues.
, -1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12455481/HDFS-1418.patch
  against trunk revision 1068968.

    +1 @author.  The patch does not contain any @author tags.

    -1 tests included.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    -1 patch.  The patch command could not apply the patch.

Console output: https://hudson.apache.org/hudson/job/PreCommit-HDFS-Build/156//console

This message is automatically generated., -1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12455481/HDFS-1418.patch
  against trunk revision 1072023.

    +1 @author.  The patch does not contain any @author tags.

    -1 tests included.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    -1 patch.  The patch command could not apply the patch.

Console output: https://hudson.apache.org/hudson/job/PreCommit-HDFS-Build/186//console

This message is automatically generated., -1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12471542/HDFS-1418.patch
  against trunk revision 1072023.

    +1 @author.  The patch does not contain any @author tags.

    -1 tests included.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    -1 patch.  The patch command could not apply the patch.

Console output: https://hudson.apache.org/hudson/job/PreCommit-HDFS-Build/207//console

This message is automatically generated., The error in the logs is:

  [exec] /grid/0/hudson/hudson-slave/workspace/PreCommit-HDFS-Build/trunk/src/test/bin/test-patch.sh: line 275: /usr/bin/patch: No such file or directory

Filed HADOOP-7152 to track this issue., Yes, I agree with the Konstantins. Let's rename this to dfs.client.id at the same time as we make this fix., Yup, that seems to be reasonable way to go about it., This appears to be a duplicate of HDFS-1947, which has already been committed to trunk.]