[Is it a dupe of HDFS-7005?, there is no write timeout. why not add writeTimeout?, I updated the title to make it clear that write timeout is still missing.  HDFS-7005 already added read timeout., Post a patch for DFSClient newConnectedPeer write timeout., {code}
      socketTimeout = conf.getInt(DFS_CLIENT_SOCKET_TIMEOUT_KEY,
          HdfsServerConstants.READ_TIMEOUT);
{code}

Can we change this to use {{DFSConfigKeys#DFS_CLIENT_SOCKET_TIMEOUT_DEFAULT}} like the other configuration keys do, rather than {{HdfsServerConstants#READ_TIMEOUT}}?

Looks good other than that., Thanks [~cmccabe] for the review! I've updated patch based on the feedback. , Please let me know if I'm missing something, but it appears this patch would significantly alter the pre-existing write timeout behavior of the HDFS client.

Right now, write timeout is enforced not as a socket option, but instead enforced per operation by passing the timeout to {{SocketOutputStream}}, which uses it in the underlying NIO selector calls.  The exact write timeout value is not purely based on configuration.  It's also a function of the number of nodes in the write pipeline.  The details are implemented in {{DFSClient#getDatanodeWriteTimeout}}.  Under default configuration, this method would extend the configured timeout of 60 seconds to 75 seconds (additional 5 seconds per replica in the pipeline).  Extending the timeout proportional to the pipeline size is meant to make the client robust against the cumulative latency effects of every write in the pipeline.

This patch would set a 60 second write timeout (under default configuration) directly as a socket option.  I believe that effectively negates the extension time of up to 75 seconds that {{DFSClient#getDatanodeWriteTimeout}} was trying to allow.

I see the original problem reported in HDFS-7005 was related to lack of read timeout.  I'm wondering if there is actually no further change required for write timeout, given the above explanation.  Is anyone seeing an actual problem related to lack of write timeout?, Chris, I think you're absolutely right.  I vaguely remembered that there was an alternate method of setting write timeouts we used in places, but I was unable to find it in a few minutes of digging.  The fact that it's passed as a parameter to {{NetUtils#getOutputStream}} explains why looking for {{setWriteTimeout}} and similar didn't turn up anything.

However.  I still think this is broken, because we will do some writes to the socket prior to calling {{DFSClient#getDataNodeWriteTimeout}}.  For example, in {{RemoteBlockReader2#newBlockReader}}, we are writing stuff to the socket, all before ever calling {{DFSClient#getDataNodeWriteTimeout}}.

On a semi-related note, I think that the current configuration situation is highly confusing and unsatisfactory.  We have a configuration key called simply {{dfs.client.socket-timeout}}, which doesn't specify whether it applies to reads or writes.  I'm not even sure most HDFS developers could answer which one(s) this key does, if quizzed.  Meanwhile, the units are unspecified (is it seconds?  ms?) and the default value doesn't appear in {{DFSConfigKeys.java}}, unlike almost every other configuration key.

How about having {{dfs.client.datanode.socket.read.timeout.ms}} as an alias for {{dfs.client.socket-timeout}}, 
{{dfs.client.datanode.socket.write.timeout.ms}} for a base write timeout, and {{dfs.client.datanode.socket.write.timeout.extra.per.pipeline.node.ms}} to be an extra amount that we add for each DN in the pipeline?, [~cmccabe], thanks for double-checking me on this.  I'm also now starting to wonder if HDFS-7005 had unintended side effects.  By setting read timeout as a socket option in {{DFSClient#newConnectedPeer}}, the setting also would have applied for {{DFSOutputStream}}, and thus circumvented the extension time that {{DFSClient#getDatanodeReadTimeout}} wants to apply.

bq. For example, in RemoteBlockReader2#newBlockReader, we are writing stuff to the socket, all before ever calling DFSClient#getDataNodeWriteTimeout.

Yes, you're right.  I suppose a complete implementation, with retention of the "timeout extension" behavior, is going to require pushing the {{NetUtils}} socket wrapping calls up to those earlier layers, or setting the socket option at a point where we know the number of nodes in the pipeline, and therefore can calculate the extension.  I expect either of those are going to be much more invasive changes than the posted patch.

bq. I'm not even sure most HDFS developers could answer which one(s) this key does, if quizzed.

I sure couldn't without reading the code fresh again today.  :-)

+1 for your proposal for new, clearer configuration properties., \\
\\
| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:red}-1{color} | patch |   0m  0s | The patch command could not apply the patch during dryrun. |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12697602/HDFS-7608.1.patch |
| Optional Tests | javadoc javac unit findbugs checkstyle |
| git revision | trunk / 08f0ae4 |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/10888/console |


This message was automatically generated., +1 to revamp the timeout naming on DFSland, in the mean time I think this can be committed to trunk first and have another jira to deprecate the timeout properties., attached new patch rebased to trunk. cc:[~xyao], \\
\\
| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | pre-patch |  14m 33s | Pre-patch trunk compilation is healthy. |
| {color:green}+1{color} | @author |   0m  0s | The patch does not contain any @author tags. |
| {color:green}+1{color} | tests included |   0m  0s | The patch appears to include 1 new or modified test files. |
| {color:green}+1{color} | javac |   7m 30s | There were no new javac warning messages. |
| {color:green}+1{color} | javadoc |   9m 38s | There were no new javadoc warning messages. |
| {color:green}+1{color} | release audit |   0m 22s | The applied patch does not increase the total number of release audit warnings. |
| {color:red}-1{color} | checkstyle |   2m 16s | The applied patch generated  1 new checkstyle issues (total was 118, now 118). |
| {color:green}+1{color} | whitespace |   0m  0s | The patch has no lines that end in whitespace. |
| {color:green}+1{color} | install |   1m 38s | mvn install still works. |
| {color:green}+1{color} | eclipse:eclipse |   0m 33s | The patch built with eclipse:eclipse. |
| {color:green}+1{color} | findbugs |   3m  4s | The patch does not introduce any new Findbugs (version 2.0.3) warnings. |
| {color:green}+1{color} | native |   3m 14s | Pre-build of native portion |
| {color:red}-1{color} | hdfs tests | 165m  5s | Tests failed in hadoop-hdfs. |
| | | 207m 56s | |
\\
\\
|| Reason || Tests ||
| Failed unit tests | hadoop.hdfs.tools.TestHdfsConfigFields |
|   | hadoop.hdfs.TestDistributedFileSystem |
|   | hadoop.tracing.TestTraceAdmin |
|   | hadoop.hdfs.server.namenode.TestFileTruncate |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12732086/HDFS-7608.2.patch |
| Optional Tests | javadoc javac unit findbugs checkstyle |
| git revision | trunk / d6f6741 |
| checkstyle |  https://builds.apache.org/job/PreCommit-HDFS-Build/10923/artifact/patchprocess/diffcheckstylehadoop-hdfs.txt |
| hadoop-hdfs test log | https://builds.apache.org/job/PreCommit-HDFS-Build/10923/artifact/patchprocess/testrun_hadoop-hdfs.txt |
| Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/10923/testReport/ |
| Java | 1.7.0_55 |
| uname | Linux asf909.gq1.ygridcore.net 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/10923/console |


This message was automatically generated., [~esteban], thank you for rebasing, but this patch cannot be committed.  As I described here, it would potentially change the existing behavior much more than intended.

https://issues.apache.org/jira/browse/HDFS-7608?focusedCommentId=14314868&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14314868

I'm clicking Cancel Patch to make it clearer that this patch isn't ready., I agree with Chris on this one. We need to address the comments [~cmccabe] and [~cnauroth] above before commit it. I also remove the Bugbash label to avoid confusion. , Thanks [~cnauroth]. I think just changing newConnectedPeer() to use the one provided by  DFSClient.getDatanodeWriteTimeout() is good enough. In the DataStreamer we already use it and but we have set the number of nodes to 2. That should be fine and that gives at least the flexibility to tune it down if required. Also, I see that if we don't set a write timeout we can run into the issue that was mentioned in this JIRA and after adding the timeout in the peer I no longer experience this issue. I've noticed other issues like in Client() where we set up the connection and then the timeout but that can be addressed in another JIRA., [~cnauroth] I tried the approach using DFSClient.getDatanodeWriteTimeout() and doesn't seem there is a clear way for users to use the timeout, e.g. if you pass  a timeout of 1000ms then your final timeout will be 11000ms and that won't be straightforward. I think if you pass the socketTimeout is much more straightforward. More suggestions to address this are welcome [~cnauroth]., [~esteban], [~cnauroth]: I took another look at the patch and I think that it's correct as-is.

The confusing part about all of this is that the {{DFSInputStream}} uses the Peer classes to encapsulate sockets, whereas the {{DFSOutputStream}} simply uses "raw" socket objects.  The word "Peer" does not occur in {{DFSOutputStream.java}} or {{DataStreamer.java}}.  It only is used in the input stream code.  Therefore, since this patch only changes {{newConnectedPeer}}, it *only* affects {{DFSInputStream}}.

In contrast, the issue Chris brought up is actually *only* a {{DFSOutputStream}} issue.  Chris commented:

bq. Right now, write timeout is enforced not as a socket option, but instead enforced per operation by passing the timeout to SocketOutputStream, which uses it in the underlying NIO selector calls. The exact write timeout value is not purely based on configuration. It's also a function of the number of nodes in the write pipeline. The details are implemented in DFSClient#getDatanodeWriteTimeout

But {{DFSClient#getDatanodeWriteTimeout}} is less generic than it may seem.  It actually is only used by the {{DFSOutputStream}} (write path) code to calculate how long to set the timeout based on the number of nodes in the pipeline.  It is never called by the input stream code at all.  So I believe that this concern is not valid.

Chris asked:

bq. I see the original problem reported in HDFS-7005 was related to lack of read timeout. I'm wondering if there is actually no further change required for write timeout, given the above explanation. Is anyone seeing an actual problem related to lack of write timeout?

Good question.  Here is the scenario where we can run into problems in the {{DFSInputStream}} code:

{{DFSInputStream#getBlockReader}} uses {{BlockReaderFactory#build}} to create a new {{RemoteBlockReader2}}.  Ultimately {{BlockReaderFactory#nextTcpPeer}} calls into {{DFSClient#newConnectedPeer}}.  As you can see from this patch, this function sets a read timeout, but no write timeout.

I should also make an additional comment here: the Peer class we will be creating is {{NioInetPeer}}.  You can see that {{NioInetPeer.java}} contains a {{org.apache.hadoop.net.SocketOutputStream}} inside it.  This is the same class which {{DFSOutputStream}} is using to "simulate" socket write timeouts by using non-blocking I/O and selectors.  But whereas {{DFSOutputStream}} uses {{org.apache.hadoop.net.SocketOutputStream}} directly, {{DFSInputStream}} uses it "under the covers" by using the {{Peer}} class.  So the timeout mechanism is actually the same (Chris, I think this answers another question you raised.)

I always found it very confusing that {{org.apache.hadoop.net.SocketOutputStream}} is named the same as {{java.net.SocketOutputStream}}.  Just for anyone new to Hadoop reading this-- they are *very* different classes!

So {{RemoteBlockReader2#newBlockReader}} has this code:
{code} 
   // in and out will be closed when sock is closed (by the caller)
    final DataOutputStream out = new DataOutputStream(new BufferedOutputStream(
          peer.getOutputStream()));
    new Sender(out).readBlock(block, blockToken, clientName, startOffset, len,
        verifyChecksum, cachingStrategy);

    //
    // Get bytes in block
    //
    DataInputStream in = new DataInputStream(peer.getInputStream());

    BlockOpResponseProto status = BlockOpResponseProto.parseFrom(
        PBHelper.vintPrefixed(in));
    checkSuccess(status, peer, block, file);
    ReadOpChecksumInfoProto checksumInfo =
      status.getReadOpChecksumInfo();
{code}

You can see that there is a potential for things to get stuck here since we have not set a write timeout.  That's the case this patch fixes.  We're seeing this in production now so it's definitely more than a theoretical problem.

I am +1 on the patch.  [~cnauroth], can you take another look and verify that this answers your questions?  We will hold off on committing until that point., Ah, of course!  This is not "block write timeout".  This is "socket write timeout during block read operations".  Thanks for the detailed follow-up.

+1 for the patch.  Thank you, Xiaoyu, Esteban and Colin., committed to 2.8, thanks all, FAILURE: Integrated in Hadoop-trunk-Commit #8162 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/8162/])
HDFS-7608: hdfs dfsclient newConnectedPeer has no write timeout (Xiaoyu Yao via Colin P. McCabe) (cmccabe: rev 1d74ccececaefffaa90c0c18b40a3645dbc819d9)
* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDistributedFileSystem.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSClient.java
HDFS-7608: add CHANGES.txt (cmccabe: rev b7fb6ec4513de7d342c541eb3d9e14642286e2cf)
* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
, FAILURE: Integrated in Hadoop-Yarn-trunk-Java8 #257 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk-Java8/257/])
HDFS-7608: hdfs dfsclient newConnectedPeer has no write timeout (Xiaoyu Yao via Colin P. McCabe) (cmccabe: rev 1d74ccececaefffaa90c0c18b40a3645dbc819d9)
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSClient.java
* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDistributedFileSystem.java
HDFS-7608: add CHANGES.txt (cmccabe: rev b7fb6ec4513de7d342c541eb3d9e14642286e2cf)
* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
, FAILURE: Integrated in Hadoop-Yarn-trunk #987 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/987/])
HDFS-7608: hdfs dfsclient newConnectedPeer has no write timeout (Xiaoyu Yao via Colin P. McCabe) (cmccabe: rev 1d74ccececaefffaa90c0c18b40a3645dbc819d9)
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSClient.java
* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDistributedFileSystem.java
HDFS-7608: add CHANGES.txt (cmccabe: rev b7fb6ec4513de7d342c541eb3d9e14642286e2cf)
* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
, FAILURE: Integrated in Hadoop-Hdfs-trunk #2184 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/2184/])
HDFS-7608: hdfs dfsclient newConnectedPeer has no write timeout (Xiaoyu Yao via Colin P. McCabe) (cmccabe: rev 1d74ccececaefffaa90c0c18b40a3645dbc819d9)
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSClient.java
* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDistributedFileSystem.java
HDFS-7608: add CHANGES.txt (cmccabe: rev b7fb6ec4513de7d342c541eb3d9e14642286e2cf)
* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
, FAILURE: Integrated in Hadoop-Hdfs-trunk-Java8 #245 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk-Java8/245/])
HDFS-7608: hdfs dfsclient newConnectedPeer has no write timeout (Xiaoyu Yao via Colin P. McCabe) (cmccabe: rev 1d74ccececaefffaa90c0c18b40a3645dbc819d9)
* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDistributedFileSystem.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSClient.java
HDFS-7608: add CHANGES.txt (cmccabe: rev b7fb6ec4513de7d342c541eb3d9e14642286e2cf)
* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
, SUCCESS: Integrated in Hadoop-Mapreduce-trunk-Java8 #255 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk-Java8/255/])
HDFS-7608: hdfs dfsclient newConnectedPeer has no write timeout (Xiaoyu Yao via Colin P. McCabe) (cmccabe: rev 1d74ccececaefffaa90c0c18b40a3645dbc819d9)
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSClient.java
* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDistributedFileSystem.java
HDFS-7608: add CHANGES.txt (cmccabe: rev b7fb6ec4513de7d342c541eb3d9e14642286e2cf)
* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
, FAILURE: Integrated in Hadoop-Mapreduce-trunk #2203 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/2203/])
HDFS-7608: hdfs dfsclient newConnectedPeer has no write timeout (Xiaoyu Yao via Colin P. McCabe) (cmccabe: rev 1d74ccececaefffaa90c0c18b40a3645dbc819d9)
* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDistributedFileSystem.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSClient.java
HDFS-7608: add CHANGES.txt (cmccabe: rev b7fb6ec4513de7d342c541eb3d9e14642286e2cf)
* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
, can we get this backported to 2.6 and 2.7 please?]