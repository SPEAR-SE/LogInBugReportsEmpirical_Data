[More data:

The "Failed to cache... message" is issued due to a method returning -1.
This reserve() method from class UsedBytesCount from file FsDatasetCache.java is very simple :

    long reserve(long count) {
      count = rounder.round(count);
      while (true) {
        long cur = usedBytes.get();
        long next = cur + count;
        if (next > maxBytes) {
          return -1;
        }
        if (usedBytes.compareAndSet(cur, next)) {
          return next;
        }
      }

Adding some traces before and after the "if (next > maxBytes)e test,

here is what we see on x86_64:

@@reserve:: count: 4096 | cur: 0 | next: 4096 | maxBytes: 65536\0A
@@reserve:: count: 4096 | cur: 4096 | next: 8192 | maxBytes: 65536\0A
@@reserve:: count: 4096 | cur: 8192 | next: 12288 | maxBytes: 65536\0A
@@reserve:: count: 4096 | cur: 12288 | next: 16384 | maxBytes: 65536\0A
@@reserve:: count: 4096 | cur: 16384 | next: 20480 | maxBytes: 65536\0A
@@reserve:: count: 4096 | cur: 0 | next: 4096 | maxBytes: 65536\0A
@@reserve:: count: 4096 | cur: 0 | next: 4096 | maxBytes: 65536\0A
........ about 30 more lines
@@reserve:: count: 4096 | cur: 65536 | next: 69632 | maxBytes: 65536\0A
  <-------- ERROR -1
  <-------- ERROR -1
Failed to cache 1073741841_BP-798842898-127.0.1.1-1402491181446: could not reserve 4096 more bytes in the cache: dfs.datanode.max.locked.memory of 65536 exceeded.
Failed to cache 1073741842_BP-798842898-127.0.1.1-1402491181446: could not reserve 4096 more bytes in the cache: dfs.datanode.max.locked.memory of 65536 exceeded.

and on PPC64:

@@reserve:: count: 4096 | cur: 0 | next: 4096 | maxBytes: 65536\0A
@@reserve:: count: 4096 | cur: 4096 | next: 8192 | maxBytes: 65536\0A
@@reserve:: count: 4096 | cur: 8192 | next: 12288 | maxBytes: 65536\0A
@@reserve:: count: 4096 | cur: 8192 | next: 12288 | maxBytes: 65536\0A
@@reserve:: count: 4096 | cur: 12288 | next: 16384 | maxBytes: 65536\0A
@@reserve:: count: 4096 | cur: 16384 | next: 20480 | maxBytes: 65536\0A
@@reserve:: count: 65536 | cur: 0 | next: 65536 | maxBytes: 65536\0A
@@reserve:: count: 65536 | cur:65536 | next: 131072 | maxBytes: 65536\0A
  <-------- ERROR -1
@@reserve:: count: 65536 | cur: 0 | next: 65536 | maxBytes: 65536\0A
@@reserve:: count: 65536 | cur: 0 | next: 65536 | maxBytes: 65536\0A
  <-------- ERROR -1
Failed to cache 1073741825_BP-1511666005-127.0.1.1-1402063542502: could not reserve 65536 more bytes in the c ache: dfs.datanode.max.locked.memory of 65536 exceeded.

This requires much more investigation. I'm now trying to understand what the HDFS cache mecanism is supposed to do.

=================================

I noticed:
x86_64: @@reserve:: count: 4096 | cur: 0 | next: 4096 | maxBytes: 65536\0A
PPC64 : @@reserve:: count: 65536 | cur: 0 | next: 65536 | maxBytes: 65536\0A

count has not the same value.

Looking at CachingTask.run() method :
    public void run() {
      boolean success = false;
      FileInputStream blockIn = null, metaIn = null;
      MappableBlock mappableBlock = null;
      ExtendedBlock extBlk = new ExtendedBlock(key.getBlockPoolId(),
          key.getBlockId(), length, genstamp);
      LOG.warn("@@run:: key: "+key+" | blockFileName: "+blockFileName+" | length: "+length+" | genstamp: "+genstamp);
      long newUsedBytes = usedBytesCount.reserve(length);
and adding traces, I clearly see that, on PPC64, length changes from 512 to 65536, passing by 4096 and 16384, though it is always 512 or 4096 on x86_64.

PPC64 :
/finalized/blk_1073741825 | length: 512 | genstamp: 1001
/finalized/blk_1073741826 | length: 512 | genstamp: 1002
/finalized/blk_1073741828 | length: 512 | genstamp: 1004
/finalized/blk_1073741827 | length: 512 | genstamp: 1003
/finalized/blk_1073741829 | length: 512 | genstamp: 1005
/finalized/blk_1073741826 | length: 65536 | genstamp: 1002
/finalized/blk_1073741825 | length: 65536 | genstamp: 1001
/finalized/blk_1073741825 | length: 65536 | genstamp: 1001
/finalized/blk_1073741825 | length: 65536 | genstamp: 1001
/finalized/blk_1073741825 | length: 4096 | genstamp: 1001
/finalized/blk_1073741825 | length: 16384 | genstamp: 1001
/finalized/blk_1073741825 | length: 65536 | genstamp: 1001
/finalized/blk_1073741825 | length: 65536 | genstamp: 1001

x86_64:
/finalized/blk_1073741825 | length: 4096 | genstamp: 1001\0A
/finalized/blk_1073741826 | length: 4096 | genstamp: 1002\0A
/finalized/blk_1073741827 | length: 4096 | genstamp: 1003\0A
/finalized/blk_1073741828 | length: 4096 | genstamp: 1004\0A
/finalized/blk_1073741829 | length: 4096 | genstamp: 1005\0A
/finalized/blk_1073741825 | length: 4096 | genstamp: 1001\0A
/finalized/blk_1073741825 | length: 4096 | genstamp: 1001\0A
/finalized/blk_1073741826 | length: 4096 | genstamp: 1002\0A
/finalized/blk_1073741826 | length: 4096 | genstamp: 1002\0A
/finalized/blk_1073741827 | length: 4096 | genstamp: 1003\0A
/finalized/blk_1073741827 | length: 4096 | genstamp: 1003\0A
/finalized/blk_1073741828 | length: 4096 | genstamp: 1004\0A
/finalized/blk_1073741828 | length: 4096 | genstamp: 1004\0A
/finalized/blk_1073741829 | length: 4096 | genstamp: 1005\0A
/finalized/blk_1073741829 | length: 4096 | genstamp: 1005\0A
/finalized/blk_1073741825 | length: 4096 | genstamp: 1001\0A
/finalized/blk_1073741826 | length: 4096 | genstamp: 1002\0A
/finalized/blk_1073741827 | length: 4096 | genstamp: 1003\0A
/finalized/blk_1073741828 | length: 4096 | genstamp: 1004\0A
/finalized/blk_1073741829 | length: 4096 | genstamp: 1005\0A
/finalized/blk_1073741830 | length: 4096 | genstamp: 1006\0A
/finalized/blk_1073741831 | length: 4096 | genstamp: 1007\0A
/finalized/blk_1073741832 | length: 4096 | genstamp: 1008\0A
/finalized/blk_1073741833 | length: 4096 | genstamp: 1009\0A
/finalized/blk_1073741834 | length: 4096 | genstamp: 1010\0A
/finalized/blk_1073741835 | length: 4096 | genstamp: 1011\0A
/finalized/blk_1073741836 | length: 4096 | genstamp: 1012\0A
/finalized/blk_1073741837 | length: 4096 | genstamp: 1013\0A
/finalized/blk_1073741838 | length: 4096 | genstamp: 1014\0A
/finalized/blk_1073741839 | length: 4096 | genstamp: 1015\0A
/finalized/blk_1073741840 | length: 4096 | genstamp: 1016\0A
/finalized/blk_1073741841 | length: 4096 | genstamp: 1017\0A
/finalized/blk_1073741842 | length: 4096 | genstamp: 1018\0A
/finalized/blk_1073741843 | length: 4096 | genstamp: 1019\0A
/finalized/blk_1073741844 | length: 4096 | genstamp: 1020\0A
/finalized/blk_1073741825 | length: 4096 | genstamp: 1001\0A
/finalized/blk_1073741826 | length: 4096 | genstamp: 1002\0A
/finalized/blk_1073741827 | length: 4096 | genstamp: 1003\0A
/finalized/blk_1073741828 | length: 4096 | genstamp: 1004\0A
/finalized/blk_1073741829 | length: 4096 | genstamp: 1005\0A
/finalized/blk_1073741825 | length: 512 | genstamp: 1001\0A
/finalized/blk_1073741826 | length: 512 | genstamp: 1002\0A
/finalized/blk_1073741828 | length: 512 | genstamp: 1004\0A
/finalized/blk_1073741827 | length: 512 | genstamp: 1003\0A
/finalized/blk_1073741829 | length: 512 | genstamp: 1005\0A
/finalized/blk_1073741825 | length: 4096 | genstamp: 1001\0A
/finalized/blk_1073741826 | length: 4096 | genstamp: 1002\0A
/finalized/blk_1073741827 | length: 4096 | genstamp: 1003\0A
/finalized/blk_1073741829 | length: 4096 | genstamp: 1005\0A
/finalized/blk_1073741831 | length: 4096 | genstamp: 1007\0A
/finalized/blk_1073741833 | length: 4096 | genstamp: 1009\0A
/finalized/blk_1073741835 | length: 4096 | genstamp: 1011\0A
/finalized/blk_1073741837 | length: 4096 | genstamp: 1013\0A
/finalized/blk_1073741839 | length: 4096 | genstamp: 1015\0A
/finalized/blk_1073741828 | length: 4096 | genstamp: 1004\0A
/finalized/blk_1073741830 | length: 4096 | genstamp: 1006\0A
/finalized/blk_1073741841 | length: 4096 | genstamp: 1017\0A
/finalized/blk_1073741832 | length: 4096 | genstamp: 1008\0A
/finalized/blk_1073741834 | length: 4096 | genstamp: 1010\0A
/finalized/blk_1073741836 | length: 4096 | genstamp: 1012\0A
/finalized/blk_1073741838 | length: 4096 | genstamp: 1014\0A
/finalized/blk_1073741840 | length: 4096 | genstamp: 1016\0A
/finalized/blk_1073741825 | length: 4096 | genstamp: 1001\0A
/finalized/blk_1073741825 | length: 4096 | genstamp: 1001\0A


=================================================================


Here are the main classes & methods dealing with getting the length:

public class Block implements Writable, Comparable<Block> {
...
  public long getNumBytes() {
    return numBytes;
  }
...
}

public interface Replica {
...
}

abstract public class ReplicaInfo extends Block implements Replica {
...
}

public class FinalizedReplica extends ReplicaInfo {
  @Override
  public long getVisibleLength() {
    return getNumBytes(); // all bytes are visible
  }
}

class ReplicaMap {
...
  ReplicaInfo get(String bpid, long blockId) {
    checkBlockPool(bpid);
    synchronized(mutex) {
      Map<Long, ReplicaInfo> m = map.get(bpid);
      return m != null ? m.get(blockId) : null;
    }
  }
...
}

class FsDatasetImpl implements FsDatasetSpi<FsVolumeImpl {

final ReplicaMap volumeMap;

private void cacheBlock(String bpid, long blockId) {
...
    long length, genstamp;
...
   ReplicaInfo info = volumeMap.get(bpid, blockId);
...
   length = info.getVisibleLength();
...
    cacheManager.cacheBlock(blockId, bpid, blockFileName, length, genstamp, volumeExecutor);
...
}

cacheBlock(long blockId, String bpid, String blockFileName, long length, long genstamp, Executor volumeExecutor)
{
....
         volumeExecutor.execute(new CachingTask(key, blockFileName, length, genstamp));
}

public class FsDatasetCache {
...

private class CachingTask implements Runnable {
...
    private final long length;
...

    CachingTask(ExtendedBlockId key, String blockFileName, long length, long genstamp) {
...
      this.length = length;
...
    }

    @Override
    public void run() {
....
      ExtendedBlock extBlk = new ExtendedBlock(key.getBlockPoolId(), key.getBlockId(), length, genstamp);
, grep "waiting for " Issue3.testPageRounder.5 | grep cached

gives on PPC64:

(TestFsDatasetCache.java:get(530)) - waiting for 1 to be cached.   Right now only 0 blocks are cached.\0A
(TestFsDatasetCache.java:get(563)) - waiting for directive 2 to be cached.  stats = {bytesNeeded: 65536\2C bytesCached: 0\2C filesNeeded: 1\2C filesCached: 0\2C hasExpired: false}\0A
(TestFsDatasetCache.java:get(563)) - waiting for directive 2 to be cached.  stats = {bytesNeeded: 65536\2C bytesCached: 0\2C filesNeeded: 1\2C filesCached: 0\2C hasExpired: false}\0A
(TestFsDatasetCache.java:get(563)) - waiting for directive 2 to be cached.  stats = {bytesNeeded: 65536\2C bytesCached: 0\2C filesNeeded: 1\2C filesCached: 0\2C hasExpired: false}\0A

and on x86_64 :

(TestFsDatasetCache.java:get(530)) - waiting for 16 to be cached.   Right now only 0 blocks are cached.\0A
(TestFsDatasetCache.java:get(563)) - waiting for directive 2 to be cached.  stats = {bytesNeeded: 4096\2C bytesCached: 0\2C filesNeeded: 1\2C filesCached: 0\2C hasExpired: false}\0A
(TestFsDatasetCache.java:get(563)) - waiting for directive 2 to be cached.  stats = {bytesNeeded: 4096\2C bytesCached: 0\2C filesNeeded: 1\2C filesCached: 0\2C hasExpired: false}\0A
(TestFsDatasetCache.java:get(563)) - waiting for directive 2 to be cached.  stats = {bytesNeeded: 4096\2C bytesCached: 0\2C filesNeeded: 1\2C filesCached: 0\2C hasExpired: false}\0A

PPC64:   bytesNeeded: 65536
x86_64: bytesNeeded: 4096



nativeio.NativeIO (NativeIO.java:mlock(160)) - mlocking /home/tony/hadoop-3.X.Y-FromGitHub/hadoop-common/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-2013187742-127.0.1.1-1402063475487/current/finalized/blk_1073741825\0A

Using mlock() is done 10 times on PPC64 and 44 times on x86_64 ., As said on https://issues.apache.org/jira/browse/HDFS-6608, the bug might be related to the hard-coded limit maxBytes = 65536 bytes, assigned at the begining of the TestFsDatasetCache.java file as follows : 

// Most Linux installs allow a default of 64KB locked memory
private static final long CACHE_CAPACITY = 64 * 1024;
conf.setLong(DFSConfigKeys.DFS_DATANODE_MAX_LOCKED_MEMORY_KEY,
        CACHE_CAPACITY);

Then on FsDatasetCache we have

this.maxBytes = dataset.datanode.getDnConf().getMaxLockedMemory();
This call gets back the value.

So I actually tried to come with something like 
private static final long CACHE_CAPACITY = 16 * 64 * 1024;

Forking I indeed retrieve in the logs maxBytes : 1048576\0A !
But the count value is now capped at 4096, which is weird. So I finally get

verifyExpectedCacheUsage: have 20480/327680 bytes cached; 5/5 blocks cached. memlock limit = 1125899906842624.  Waiting...\0A

each time the supplier tries to check the cache is used as expected.
Though it seems all 5 blocks are cached, the osPageSize on the size of the cache is still 4096. Which is what should be changed !

public long round(long count) {
      long newCount = 
          (count + (osPageSize - 1)) / osPageSize;
      return newCount * osPageSize;
    }

private final long osPageSize =
        NativeIO.POSIX.getCacheManipulator().getOperatingSystemPageSize();

That should give 65536 again so when reserving 512 bytes, we should have newCount = 1, returning 65536 bytes to reserve.
Why is that not the case ? (First step is  @@reserve:: count : 4096 | next : 4096 | maxBytes : 1048576\0A)
, This patch does 2 things that should NOT modify the behavior before applying it when used with systems with a PAGE_SIZE of 4096 :

1 - Change in TestFsDatasetCache.java
\- private static final long CACHE_CAPACITY = 64 * 1024;
+ private static final long CACHE_CAPACITY = 16 * PAGE_SIZE;

2 - Change in NativeIO.java, class NoMlockCacheManipulator

\- public long getOperatingSystemPageSize() { return 4096; }
+ public long getOperatingSystemPageSize() { return NativeIO.getOperatingSystemPageSize(); }

The first change is motivated by the fact that on systems with a page size of, e.g. 65536 bytes, we could only reserve one page in the cache for testing. 

The second is motivated by the fact that on systems with a page size of, e.g. 65536 bytes, saying it is 4096 leaded method verifyExpectedCacheUsage to fail even when the suited number of blocks was reserved (i.e. leading to a timeout), Patch for the issue, see release notes, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12654094/HDFS-6515-1.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The following test timeouts occurred in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs:

org.apache.hadoop.http.TestHttpServer

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/7283//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/7283//console

This message is automatically generated., The test class that failed because of a timeout seems unreleated to my modifications as it does not seem to have anything to do with the filesystem. I cannot retrieve it on Jenkins test results, and on eclipse I see a TestHttpServer that is in the http package, not the hdfs one.

Other tests that were not skipped seem to path without any failure, but the console output log is disturbing as there are several weird exceptions. I wonder weither it is possible to resubmit the patch using -X option or not.

Errors I found are :

hdfsOpenFile(/tlhData0001/file1): FileSystem#open((Lorg/apache/hadoop/fs/Path;I)Lorg/apache/hadoop/fs/FSDataInputStream;) error
hdfsOpenFile(/tlhData0002/file1): FileSystem#open((Lorg/apache/hadoop/fs/Path;I)Lorg/apache/hadoop/fs/FSDataInputStream;) error
ERROR: cannot open an hdfs file in mode 0x3
java.io.FileNotFoundException: File does not exist: /tlhData0002/file1
ERROR: cannot open an hdfs file in mode 0x3
hdfsOpenFile(/tlhData0000/file1): FileSystem#open((Lorg/apache/hadoop/fs/Path;I)Lorg/apache/hadoop/fs/FSDataInputStream;) error

But these might not be what we are looking for.

On the other hand, the only reference to TestHttpServer is :

Running org.apache.hadoop.http.TestHttpServer

When running mvn -Dtest=TestHttpServer test -X on my ubuntu VB, and on my ppc (RHEL 6.5), it successfully builds on my side.
What kind of environment are you using for testing ?
, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12654094/HDFS-6515-1.patch
  against trunk revision caecd9f.

    {color:red}-1 patch{color}.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/8549//console

This message is automatically generated., Hello
Reading the console output, I see nothing related to the patch that could be the root cause of the failure.

The error seems to be around:

HDFS-6515 patch is being downloaded at Mon Oct 27 07:51:14 UTC 2014 from
http://issues.apache.org/jira/secure/attachment/12654094/HDFS-6515-1.patch
cp: cannot stat '/home/jenkins/buildSupport/lib/*': No such file or directory
The patch does not appear to apply with p0 to p2
PATCH APPLICATION FAILED

where the error deals with some lib stored in Jenkins directory.

On my side, I gonna check that the patch works fine on the branch 'trunk'., Patching the trunk of Hadoop Common trunk from official GitHub with the patch provided here works perfectly :

$ patch -p0 < ../HDFS-6515-1.patch 
patching file hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/nativeio/NativeIO.java
Hunk #1 succeeded at 166 (offset 1 line).
patching file hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestFsDatasetCache.java

I've checked the 2 files and they are OK., There is an issue on Hadoop Common GitHub Web page:
 downloading "ZIP File" from "Download ZIP" button generated a set of source code that is old, probably dated August 23th, since the latest commit displayed is said to be:
     Arpit Agarwal arp7 authored on 23 Aug     latest commit 42a61a4fbc

When getting Hadoop Common source code with "git clone", I see that the patch fails.

I've change the patch, and tested it on a "git clone", and that works.
I gonna push a new patch now., Source code of Hadoop has changed since the patch was produced.
I gonna provide a new version of the patch, that works with today's code., Previous patch has been updated to work with current Hadoop code.

$ patch -p0 < /tmp/HDFS-6515-2.patch 
patching file hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/nativeio/NativeIO.java
Hunk #1 succeeded at 171 (offset 6 lines).
patching file hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestFsDatasetCache.java

 git status
# On branch trunk
# Changes not staged for commit:
#   (use "git add <file>..." to update what will be committed)
#   (use "git checkout -- <file>..." to discard changes in working directory)
#
#	modified:   hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/nativeio/NativeIO.java
#	modified:   hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestFsDatasetCache.java
, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12677586/HDFS-6515-2.patch
  against trunk revision c9bec46.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:red}-1 findbugs{color}.  The patch appears to cause Findbugs (version 2.0.3) to fail.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in .

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/8567//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/8567//console

This message is automatically generated., Test report says:
  [INFO] BUILD SUCCESS
but there are errors after:
 - Determining number of patched Findbugs warnings :
  /home/jenkins/j/home/jenkins/jenkins-slave/workspace/PreCommit-HDFS-Build@2/dev-support/test-patch.sh: line 622:  2899 Killed enkins-slave/workspace/PreCommit-HDFS-Build@2/dev-support/test-patch.sh: line 622:  2899 Killed 
 - Running tests:
 /bin/grep: /home/jenkins/jenkins-slave/workspace/PreCommit-HDFS-Build@2/../patchprocess/patch: No such file or directory

 {color:red}-1 findbugs{color}.  The patch appears to cause Findbugs (version 2.0.3) to fail.

 - Checking the integrity of system test framework code.:
   mv: cannot stat '/home/jenkins/jenkins-slave/workspace/PreCommit-HDFS-Build@2/../patchprocess': No such file or directory

I'm now running:
   mvn clean test findbugs:findbugs -DskipTests -DHadoopPatchProcess
in my environment, with trunk patched with 6515, in order to understand what's wrong.

Result:
[INFO] Apache Hadoop Project POM ......................... FAILURE [1:20.245s]
[ERROR] Failed to execute goal org.codehaus.mojo:findbugs-maven-plugin:2.3.2:findbugs (default-cli) on project hadoop-project: Execution default-cli of goal org.codehaus.mojo:findbugs-maven-plugin:2.3.2:findbugs failed: Plugin org.codehaus.mojo:findbugs-maven-plugin:2.3.2 or one of its dependencies could not be resolved: Could not transfer artifact asm:asm-xml:jar:3.1 from/to central (http://repo.maven.apache.org/maven2): Read timed out -> [Help 1]

Retesting with -X and Oracle 1.7 JVM instead of IBM JVM:
Result of: 
    mvn -X test findbugs:findbugs -DskipTests -DHadoopPatchProcess -l mvn.findbugs.OpenJDK.res
in my environment (Ubuntu 14.04/Intel, Maven 3.0.4) is :
 BUILD SUCCESS, It seems that https://issues.apache.org/jira/browse/HADOOP-10926 is the root cause of this HDFS-6515 patch to fail.
Some Jenkins internal issue.
See: https://issues.apache.org/jira/browse/HADOOP-10926?focusedCommentId=14187146&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14187146
Hope this will be fixed soon., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12677586/HDFS-6515-2.patch
  against trunk revision 7179f94.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.server.blockmanagement.TestDatanodeManager
                  org.apache.hadoop.hdfs.TestEncryptionZonesWithKMS

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/9918//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/9918//console

This message is automatically generated., Above testcases are unrelated to this patch, Seems like a long standing test-issue. Moving out of 2.7 which is close., I am out of my office from September 26th till October 3rd.
, \\
\\
| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:red}-1{color} | pre-patch |  19m 34s | Pre-patch trunk has 4 extant Findbugs (version 3.0.0) warnings. |
| {color:green}+1{color} | @author |   0m  0s | The patch does not contain any @author tags. |
| {color:green}+1{color} | tests included |   0m  0s | The patch appears to include 1 new or modified test files. |
| {color:green}+1{color} | javac |   7m 56s | There were no new javac warning messages. |
| {color:green}+1{color} | javadoc |  10m  0s | There were no new javadoc warning messages. |
| {color:green}+1{color} | release audit |   0m 23s | The applied patch does not increase the total number of release audit warnings. |
| {color:green}+1{color} | checkstyle |   2m 36s | There were no new checkstyle issues. |
| {color:green}+1{color} | whitespace |   0m  0s | The patch has no lines that end in whitespace. |
| {color:green}+1{color} | install |   1m 29s | mvn install still works. |
| {color:green}+1{color} | eclipse:eclipse |   0m 32s | The patch built with eclipse:eclipse. |
| {color:green}+1{color} | findbugs |   4m 28s | The patch does not introduce any new Findbugs (version 3.0.0) warnings. |
| {color:green}+1{color} | common tests |  23m  1s | Tests passed in hadoop-common. |
| {color:red}-1{color} | hdfs tests | 161m 42s | Tests failed in hadoop-hdfs. |
| | | 231m 44s | |
\\
\\
|| Reason || Tests ||
| Failed unit tests | hadoop.hdfs.server.blockmanagement.TestPendingInvalidateBlock |
|   | hadoop.hdfs.server.namenode.TestDeleteRace |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12677586/HDFS-6515-2.patch |
| Optional Tests | javadoc javac unit findbugs checkstyle |
| git revision | trunk / eee0d45 |
| Pre-patch Findbugs warnings | https://builds.apache.org/job/PreCommit-HDFS-Build/12112/artifact/patchprocess/trunkFindbugsWarningshadoop-hdfs.html |
| hadoop-common test log | https://builds.apache.org/job/PreCommit-HDFS-Build/12112/artifact/patchprocess/testrun_hadoop-common.txt |
| hadoop-hdfs test log | https://builds.apache.org/job/PreCommit-HDFS-Build/12112/artifact/patchprocess/testrun_hadoop-hdfs.txt |
| Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/12112/testReport/ |
| Java | 1.7.0_55 |
| uname | Linux asf901.gq1.ygridcore.net 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/12112/console |


This message was automatically generated., I'm downgrading the priority of this issue, since lack of PPC support is not a regression., | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 12s {color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green} 0m 0s {color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue} 0m 14s {color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 6m 40s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 6m 0s {color} | {color:green} trunk passed with JDK v1.8.0_77 {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 6m 41s {color} | {color:green} trunk passed with JDK v1.7.0_95 {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 1m 6s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 51s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 27s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 3m 32s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 2m 2s {color} | {color:green} trunk passed with JDK v1.8.0_77 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 2m 51s {color} | {color:green} trunk passed with JDK v1.7.0_95 {color} |
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue} 0m 29s {color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 1m 27s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 5m 54s {color} | {color:green} the patch passed with JDK v1.8.0_77 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 5m 54s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 6m 44s {color} | {color:green} the patch passed with JDK v1.7.0_95 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 6m 44s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 1m 5s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 48s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 27s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green} 0m 0s {color} | {color:green} Patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 3m 53s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 58s {color} | {color:green} the patch passed with JDK v1.8.0_77 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 2m 53s {color} | {color:green} the patch passed with JDK v1.7.0_95 {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 7m 29s {color} | {color:red} hadoop-common in the patch failed with JDK v1.8.0_77. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 57m 13s {color} | {color:red} hadoop-hdfs in the patch failed with JDK v1.8.0_77. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 7m 47s {color} | {color:green} hadoop-common in the patch passed with JDK v1.7.0_95. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 52m 10s {color} | {color:red} hadoop-hdfs in the patch failed with JDK v1.7.0_95. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green} 0m 25s {color} | {color:green} Patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 184m 41s {color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| JDK v1.8.0_77 Failed junit tests | hadoop.ipc.TestRPC |
|   | hadoop.hdfs.server.blockmanagement.TestComputeInvalidateWork |
|   | hadoop.hdfs.TestFileAppend |
|   | hadoop.hdfs.shortcircuit.TestShortCircuitCache |
| JDK v1.7.0_95 Failed junit tests | hadoop.hdfs.server.namenode.TestDecommissioningStatus |
|   | hadoop.hdfs.TestHFlush |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:fbe3e86 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12677586/HDFS-6515-2.patch |
| JIRA Issue | HDFS-6515 |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux e71d87890843 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 14ab7a8 |
| Default Java | 1.7.0_95 |
| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_77 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_95 |
| findbugs | v3.0.0 |
| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/15248/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.8.0_77.txt |
| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/15248/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.8.0_77.txt |
| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/15248/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.7.0_95.txt |
| unit test logs |  https://builds.apache.org/job/PreCommit-HDFS-Build/15248/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.8.0_77.txt https://builds.apache.org/job/PreCommit-HDFS-Build/15248/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.8.0_77.txt https://builds.apache.org/job/PreCommit-HDFS-Build/15248/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.7.0_95.txt |
| JDK v1.7.0_95  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/15248/testReport/ |
| modules | C:  hadoop-common-project/hadoop-common   hadoop-hdfs-project/hadoop-hdfs  U: . |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/15248/console |
| Powered by | Apache Yetus 0.2.0   http://yetus.apache.org |


This message was automatically generated.

, | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 12s{color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 15s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 12m 59s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 10m 10s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m 33s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  2m  5s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 35s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  3m 17s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 33s{color} | {color:green} trunk passed {color} |
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 16s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m 28s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  9m 42s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  9m 42s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m 38s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  2m  0s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 38s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  3m 37s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 33s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  8m 17s{color} | {color:green} hadoop-common in the patch passed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 67m 53s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 35s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}131m 28s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.hdfs.server.namenode.ha.TestEditLogTailer |
| Timed out junit tests | org.apache.hadoop.hdfs.server.blockmanagement.TestBlockStatsMXBean |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:a9ad5d6 |
| JIRA Issue | HDFS-6515 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12677586/HDFS-6515-2.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux 286e68157eeb 3.13.0-103-generic #150-Ubuntu SMP Thu Nov 24 10:34:17 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 71a4acf |
| Default Java | 1.8.0_111 |
| findbugs | v3.0.0 |
| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/18086/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/18086/testReport/ |
| modules | C: hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs U: . |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/18086/console |
| Powered by | Apache Yetus 0.5.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

, | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 12s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 16s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 14m  0s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 14m 22s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m 58s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  2m 36s{color} | {color:green} trunk passed {color} |
| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  1m 50s{color} | {color:red} hadoop-hdfs-project/hadoop-hdfs in trunk has 10 extant Findbugs warnings. {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 38s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 14s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m 27s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 10m 52s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 10m 52s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m 56s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  2m 28s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  3m 27s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 36s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  8m 21s{color} | {color:red} hadoop-common in the patch failed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 66m 19s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 37s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}136m 50s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.net.TestClusterTopology |
|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting |
|   | hadoop.hdfs.TestDFSStripedInputStreamWithRandomECPolicy |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:14b5c93 |
| JIRA Issue | HDFS-6515 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12677586/HDFS-6515-2.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux 9379d19d37e4 3.13.0-119-generic #166-Ubuntu SMP Wed May 3 12:18:55 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 12c8fdc |
| Default Java | 1.8.0_131 |
| findbugs | v3.1.0-RC1 |
| findbugs | https://builds.apache.org/job/PreCommit-HDFS-Build/20236/artifact/patchprocess/branch-findbugs-hadoop-hdfs-project_hadoop-hdfs-warnings.html |
| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/20236/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common.txt |
| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/20236/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/20236/testReport/ |
| modules | C: hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs U: . |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/20236/console |
| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

, Is this still on target for 2.9.0 ? If not, can we we push this out to the next major release ?, | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 15s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 14s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 12m 15s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 13m 43s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m 45s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 46s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 11m 16s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 47s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 21s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 13s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m 16s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  9m 55s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  9m 55s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m 42s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 43s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green}  6m 56s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  3m 12s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 22s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  7m  2s{color} | {color:red} hadoop-common in the patch failed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 85m 28s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:red}-1{color} | {color:red} asflicense {color} | {color:red}  0m 25s{color} | {color:red} The patch generated 1 ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}161m 59s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.fs.shell.TestCopyFromLocal |
|   | hadoop.net.TestDNS |
|   | hadoop.security.TestRaceWhenRelogin |
|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting |
|   | hadoop.hdfs.web.TestWebHdfsTimeouts |
|   | hadoop.hdfs.server.datanode.TestNNHandlesCombinedBlockReport |
| Timed out junit tests | org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure |
|   | org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager |
|   | org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure140 |
|   | org.apache.hadoop.hdfs.qjournal.client.TestQJMWithFaults |
|   | org.apache.hadoop.hdfs.qjournal.client.TestEpochsAreUnique |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:71bbb86 |
| JIRA Issue | HDFS-6515 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12677586/HDFS-6515-2.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |
| uname | Linux 867963fe6d61 4.4.0-43-generic #63-Ubuntu SMP Wed Oct 12 13:48:03 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 373d0a5 |
| Default Java | 1.8.0_144 |
| findbugs | v3.1.0-RC1 |
| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/21452/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common.txt |
| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/21452/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/21452/testReport/ |
| asflicense | https://builds.apache.org/job/PreCommit-HDFS-Build/21452/artifact/patchprocess/patch-asflicense-problems.txt |
| modules | C: hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs U: . |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/21452/console |
| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

]