[Hi [~1028344078@qq.com]

The log already indicates there is a java OOM, why you still raise this as a bug?
 , [~cheersyang]
I know this is oom error.
Please to see  https://pan.baidu.com/s/1o7BE0cy, I am closing this as invalid. We encourage people to report bugs on JIRA but that needs at least some basic diagnosis so watchers know it is a code bug or an env/opt error. So if you believe this is a code bug but you don't know where the root cause is, you need to provide some reproducing steps with a common-setup or in UT. It's not efficient to discuss how to resolve issues via JIRA, better to try on Google or stack overflow etc. Hope that makes sense., [~cheersyang]
I search so many.
And i check the my env code(DataXceiverServer.java) with apache hadoop latest version code(DataXceiverServer.java), is the same.

But I can see the memory use only < 1000M.
Please to see https://pan.baidu.com/s/1o7BE0cy, *{ margin: 0; padding: 0; } font{ line-height: 1.6; } ul,ol{ padding-left: 20px; list-style-position: inside; }
Hi, Weiwei Yang
Can you have weixin? Let's have a chat,ok ?
Thanks,Jepson
a#ntes-pcmail-signature-default:hover { text-decoration: underline; color: #199cff; cursor: pointer; } a#ntes-pcmail-signature-default:active { text-decoration: underline; color: #246fce; cursor: pointer; } 
On 12/18/2017 17:14，[1]Weiwei Yang (JIRA)<jira@apache.org> wrote：
     [ https://issues.apache.org/jira/browse/HDFS-12936?page=com.atlassian.jira.plugin.system.issuetabpanels:all-tabpanel ]

Weiwei Yang resolved HDFS-12936.
--------------------------------
    Resolution: Not A Bug




--
This message was sent by Atlassian JIRA
(v6.4.14#64029)
----------------------------------------------------------------------------------------
[1] mailto:jira@apache.org
, Hey [~1028344078@qq.com]，this error usually means you didn't set your system limits appropriately.
There's lots of system limits may cause this issue, such max-threads-per-process, max-open-files-per-process, etc.
This [answer on stackoverflow | https://stackoverflow.com/questions/34452302/how-to-increase-maximum-number-of-jvm-threads-linux-64bit] is a great guideline for you to find out which limits is not set appropriately, hope it can help, [~alicezhangchen]
Thank you for quick response., [~1028344078@qq.com] Thanks for filing this issue. But as [~Weiwei Yang] and [~alicezhangchen] mentioned this is probably due to an enviormental issue in your data node. We usually use JIRA when we find a defect in the product, that is you need some code change. Could you please investigate the root issue on your machines and if you find a real defect please re-open this JIRA.  Till we know for sure that there is a code defect, I am going to resolve this JIRA. Please feel free to reopen if you have more information, like stack traces or line of code that you think is wrong. Once more, thank you very much for filing this JIRA and having a discussion with the community., [~anu] [~cheersyang] [~alicezhangchen] Thank you very much.

I turn up these parameters.
{code:java}
1.
echo "kernel.threads-max=196605" >> /etc/sysctl.conf
echo "kernel.pid_max=196605" >> /etc/sysctl.conf
echo "vm.max_map_count=393210" >> /etc/sysctl.conf
sysctl -p  

2.
/etc/security/limits.conf
* soft nofile 196605
* hard nofile 196605
* soft nproc 196605
* hard nproc 196605
{code}
]