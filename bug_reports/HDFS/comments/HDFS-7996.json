[The patch makes {{BlockReceiver#PackageResponder#finalizeBlock()}} and {{BlockReceiver#receiveBlock()}} call the internal {{close()}}, which does not release {{FsVolumeRef}}, because there are more I/Os on the volumes in these two functions.

Also change the test to verify that blocks are not removed from DN's memory before BlockReceiver is done., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12707652/HDFS-7996.000.patch
  against trunk revision 05499b1.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.server.blockmanagement.TestDatanodeManager
                  org.apache.hadoop.hdfs.qjournal.TestNNWithQJM

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/10092//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/10092//console

This message is automatically generated., Good find.

However, I don't like this approach of having multiple different close functions.  It's really messy.  Instead, if the PacketResponder wants to keep the volume open once the BlockReceiver no longer needs it, the PacketResponder should hold its own reference to the Volume., Thanks for the reviews, [~cmccabe]. 

In this patch, I changed {{close{boolean)}} to {{closeBlockAndCrcFile()}}, and call it from {{BlockReceiver#close()}}.  

If we let {{PacketReponder}} holds another reference, it requires {{ReplicaHandler}} to expose a function to get the underneath volume.  Additionally, the lifetime of {{PacketReponder}} should be within the lifetime of {{BlockReceiver}}, so I think that it might still be better to let {{BlockReceiver}} hold the volume reference.   Is it OK with you?, The {{BlockReceiver}} should either be closed, or not closed.  Having lots of subtly different close functions just makes it hard to think about.

It would be much better to add a function like {{BlockReceiver#claimReplicaHandler}} and have that function return {{BlockReceiver#replicaHandler}} (and set {{BlockReceiver#replicaHandler}} to null).  Then {{finalizeBlock}} can hold on to the {{replicaHandler}} and its associated volume for as long as it wants.

I also notice an existing bug in {{BlockReceiver#close}}... if there is an {{IOException}} closing the data or metadata streams, the volume reference will never be removed.  We should fix this with a finally block.  Similarly, if there is an IOE closing one stream, we should try to close the other stream rather than giving up.  Otherwise we have a file descriptor leak on IO error.  [Edit: actually, the streams will be closed on an IOE, but not on a RuntimeException/], {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12708235/HDFS-7996.001.patch
  against trunk revision d9ac5ee.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestLazyPersistFiles
                  org.apache.hadoop.hdfs.server.namenode.TestFileTruncate

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/10115//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/10115//console

This message is automatically generated., Thanks for the suggestions, [~cmccabe]. I made the changes accordingly. 

bq. if there is an IOException closing the data or metadata streams, the volume reference will never be removed.

{code}
   // close checksum file
    try {
        ...
        checksumOut.close();
        checksumOut = null;
      }
    } catch(IOException e) {
      ioe = e;
    }
    finally {
      IOUtils.closeStream(checksumOut);
    }
{code}

As shown in the existing code (above), the {{IOE}} is captured, so both streams and {{ReplicaHandler}} are closed if there is an IOE when closing the streams. , {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12708785/HDFS-7996.002.patch
  against trunk revision c94d594.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/10153//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/10153//console

This message is automatically generated., bq. As shown in the existing code (above), the IOE is captured, so both streams and ReplicaHandler are closed if there is an IOE when closing the streams.

Thanks for the correction.  You're right that the streams will be closed (and the volume unreferenced) when an IOE is thrown.  One case that isn't handled is if a RuntimeException is thrown.  I suppose arguably these exceptions should not occur from this code, though.  So it's probably fine as-is.
 
{code}
try (ReplicaHandler handler = BlockReceiver.this.claimReplicaHandler()) {
{code}

It's interesting that {{handler}} can be null here.  It looks like the java7 try-with-resources idiom handles this, by silently ignoring null resources.  See https://blogs.oracle.com/darcy/entry/project_coin_null_try_with

Thanks, Eddy.  +1, Thanks a lot for reviewing and committing this, [~cmccabe], SUCCESS: Integrated in Hadoop-trunk-Commit #7509 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/7509/])
HDFS-7996. After swapping a volume, BlockReceiver reports ReplicaNotFoundException (Lei (Eddy) Xu via Colin P. McCabe) (cmccabe: rev 023133cef9a7ca05364cefbcead57c921589eda7)
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java
* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDataNodeHotSwapVolumes.java
, FAILURE: Integrated in Hadoop-Yarn-trunk-Java8 #153 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk-Java8/153/])
HDFS-7996. After swapping a volume, BlockReceiver reports ReplicaNotFoundException (Lei (Eddy) Xu via Colin P. McCabe) (cmccabe: rev 023133cef9a7ca05364cefbcead57c921589eda7)
* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java
* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDataNodeHotSwapVolumes.java
, FAILURE: Integrated in Hadoop-Yarn-trunk #887 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/887/])
HDFS-7996. After swapping a volume, BlockReceiver reports ReplicaNotFoundException (Lei (Eddy) Xu via Colin P. McCabe) (cmccabe: rev 023133cef9a7ca05364cefbcead57c921589eda7)
* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDataNodeHotSwapVolumes.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java
, FAILURE: Integrated in Hadoop-Hdfs-trunk-Java8 #144 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk-Java8/144/])
HDFS-7996. After swapping a volume, BlockReceiver reports ReplicaNotFoundException (Lei (Eddy) Xu via Colin P. McCabe) (cmccabe: rev 023133cef9a7ca05364cefbcead57c921589eda7)
* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDataNodeHotSwapVolumes.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java
, SUCCESS: Integrated in Hadoop-Hdfs-trunk #2085 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/2085/])
HDFS-7996. After swapping a volume, BlockReceiver reports ReplicaNotFoundException (Lei (Eddy) Xu via Colin P. McCabe) (cmccabe: rev 023133cef9a7ca05364cefbcead57c921589eda7)
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java
* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDataNodeHotSwapVolumes.java
, FAILURE: Integrated in Hadoop-Mapreduce-trunk-Java8 #154 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk-Java8/154/])
HDFS-7996. After swapping a volume, BlockReceiver reports ReplicaNotFoundException (Lei (Eddy) Xu via Colin P. McCabe) (cmccabe: rev 023133cef9a7ca05364cefbcead57c921589eda7)
* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDataNodeHotSwapVolumes.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java
* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
, FAILURE: Integrated in Hadoop-Mapreduce-trunk #2103 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/2103/])
HDFS-7996. After swapping a volume, BlockReceiver reports ReplicaNotFoundException (Lei (Eddy) Xu via Colin P. McCabe) (cmccabe: rev 023133cef9a7ca05364cefbcead57c921589eda7)
* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDataNodeHotSwapVolumes.java
* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java
]