[An application wrote 200 bytes to a file but failed to close the file. The replicas all have 200 bytes of the file. The namenode still thinks that the filesize is zero bytes. When the hardlease expires, the namenode writes the OP_CLOSE record to the transaction log, the filelength for this block recorded  in the transaction log is zero. This by itself is not a bug. In hadoop 0.17, the namenode does not contact datanodes while doing lease recovery.

If the namenode is rebooted, the filesize continues to be displayed as zero. The block report from the datanodes sends the blocksize to be 200 bytes. But because of a bug in DatanodeDescriptor.reportDiff, this block size of 200 is ignored by the namenode. This, by itself is still not a bug because the file continues to be displayed as having zero size.

Now, if a datanode dies, the block of size 200 is replicated from one of the original datanodes to a new datanode. The new datanode sends a blockReceived command. The blockReceived command has the size 200 and the namenode accepts this value as the true size of the block and updates the block length to be 200 bytes. The file is now displayed as having 200 bytes.

If one restarts the namenode, the file goes back to being zero size until the time when the block needs to be replicated again and the file  shows up being of size 200. This is the cause of the mystery of the "fluctuating file size". , This patch is for 0.17, Is this fix applicable to 20.X also., This problem occurs only in 0.17 release of Hadoop. It problem does not exist in later hadoop versions., Could you please update the "Version/s" fields., We can't set the version since 17 isn't even listed anymore.  Since it's virtually impossible that another 0.17 branch will be released, I'm going to close this as won't fix.  Any 17 clusters out there that are still running that may hit this would be advised to upgrade, and barring that, apply the patch themselves.  If anyone disagrees with this resolution, feel free to re-open.]