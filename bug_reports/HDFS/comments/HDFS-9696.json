[{code:xml}
<INodeReferenceSection></INodeReferenceSection><SnapshotSection><snapshotCounter>0</snapshotCounter></SnapshotSection>
...
<SnapshotDiffSection><diff><inodeid>16385</inodeid></diff><diff><inodeid>43008443</inodeid><filediff><snapshotId>-1</snapshotId><size>0</size><name>action-data.seq</name></filediff>
</diff><diff><inodeid>43108392</inodeid><filediff><snapshotId>-1</snapshotId><size>302</size><name>some_random_file</name></filediff>
...
</SnapshotDiffSection>
{code}

The file with inode number 43008443 exists. As it is shown, there is no snapshot that SnapshotManager is aware of and the snapshot ID of all filediff entries are -1., Hi [~kihwal],

Thanks much for reporting this issue. I have been looking in to HDFS-9406 and observed the same. I have made progress on HDFS-9406 and am still working on.
, Hi Kihwal,

Since I am working on, do you mind if I assign it to myself?

Thanks.

, bq.  do you mind if I assign it to myself?
I don't. But I noticed that none of the original snapshot feature developers are watching HDFS-9406. At some point, we should call them out., Thanks Kihwal. Yes, agree. While I have been investigating, I indeed planned to ask the snapshot developers for help at some point.
, Ah, I intended to write the request message in my prior comment before reassigning, just found that I accidentally reassigned together with the request message.  Sorry about that.
, Currently I think HDFS-9406 and HDFS-9697 may both be caused by some lingering INode in the diff list. Both failed when loading INode from the inode Map. Compared with the logic for removing inodes from inode map, cleaning diff list is more complicated thus has higher chance to have bug., Yes [~jingzhao], your analysis is correct to me per my study in HDFS-9406. Thanks.

, And I have a solution for HDFS-9697, for the case I created. Yet to prove that it will work with all situations.

, Hi [~kihwal],

Thanks a lot for reporting the issue here. Upon investigation, we think it's likely duplicate of HDFS-9406, which is now resolved. I'm closing this jira for now. If you still see the problem after applying the fix HDFS-9406, please feel free to reopen.

Thanks.
 , Thanks, [~yzhangal]!, Very welcome [~kihwal]!
, It turns out that HDFS-9406 is not related to this issue.

The garbage snapshot filediffs with snapshotId=-1 were being generated by a bug fixed in HDFS-7056 by [~zero45]. 
{code}
   /** Is this inode in the latest snapshot? */
   public final boolean isInLatestSnapshot(final int latestSnapshotId) {
-    if (latestSnapshotId == Snapshot.CURRENT_STATE_ID) {
+    if (latestSnapshotId == Snapshot.CURRENT_STATE_ID ||
+        latestSnapshotId == Snapshot.NO_SNAPSHOT_ID) {
       return false;
     }
{code}
[~shv] explained,
{quote}
(7) Plamen says this is because Snapshot.findLatestSnapshot() may return NO_SNAPSHOT_ID, which breaks recordModification() if you don't have that additional check. We see it when commitBlockSynchronization() is called for truncated block.
{quote}

We have actually traced the generation of these filediff entries to {{commitBlockSynchronization()}} activities when the NN was running 2.5. This stops in 2.7 thanks to HDFS-7056.  However, the garbage lives on until those files are deleted.  Can we have a sanity check during snapshot diff loading so that these entries can be discarded?, Thanks for the info [~kihwal]!
, One basic sanity check can be done for cases where there is no snapshot. When saving snapshot diff section, we can call {{getNumSnapshots()}} to check whether there is any snapshot. If none, saving diff section can be skipped.
, Does something like this make sense?  Saving a diff section involves iterating the entire inode map. When there is no snapshot, we can potentially cut down fsimage saving time and reduce java object generation.
{code}
--- a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormatProtobuf.java
+++ b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormatProtobuf.java
@@ -496,7 +496,10 @@ private void saveInternal(FileOutputStream fout,
       Step step = new Step(StepType.INODES, filePath);
       prog.beginStep(Phase.SAVING_CHECKPOINT, step);
       saveInodes(b);
-      saveSnapshots(b);
+      if (context.getSourceNamesystem().getSnapshotManager()
+          .getNumSnapshots() > 0) {
+        saveSnapshots(b);
+      }
       prog.endStep(Phase.SAVING_CHECKPOINT, step);
{code}

If no one objects, I will add a test case and submit a patch., [~kihwal], the idea is simple and great!  Please submit a patch.  Thanks!, Attaching a patch containing a unit test. , | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 14s{color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  7m  0s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 43s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 25s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 51s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 12s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 42s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 56s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 47s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 43s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 43s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 23s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 58s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 10s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 52s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 51s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 56m 57s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 18s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 76m 14s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.hdfs.server.namenode.snapshot.TestCheckpointsWithSnapshots |
|   | hadoop.hdfs.server.namenode.snapshot.TestRenameWithSnapshots |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:9560f25 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12823518/HDFS-9696.patch |
| JIRA Issue | HDFS-9696 |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux 44f817c68730 3.13.0-92-generic #139-Ubuntu SMP Tue Jun 28 20:42:26 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 23c6e3c |
| Default Java | 1.8.0_101 |
| findbugs | v3.0.0 |
| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/16416/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/16416/testReport/ |
| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/16416/console |
| Powered by | Apache Yetus 0.4.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

, The test failures seem related.  Please take a look. :), It looks like these tests failed because the snapshot section wasn't present. When the existing namenode reloads such an image, the snapshot manager state may not be properly reset. I made it skip only the diff section and they seem to pass. , | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 17s{color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  7m 19s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 50s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 28s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 59s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 17s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 46s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m  0s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 49s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 47s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 47s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 26s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 53s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 10s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 51s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 55s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 90m 43s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 19s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}111m 12s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.hdfs.TestPersistBlocks |
| Timed out junit tests | org.apache.hadoop.hdfs.TestLeaseRecovery2 |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:9560f25 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12823548/HDFS-9696.v2.patch |
| JIRA Issue | HDFS-9696 |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux 6fa8fece0684 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 23c6e3c |
| Default Java | 1.8.0_101 |
| findbugs | v3.0.0 |
| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/16417/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/16417/testReport/ |
| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/16417/console |
| Powered by | Apache Yetus 0.4.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

, {noformat}
-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running org.apache.hadoop.hdfs.TestLeaseRecovery2
Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 88.065 sec - in org.apache.hadoop.hdfs.TestLeaseRecovery2
Running org.apache.hadoop.hdfs.TestPersistBlocks
Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 28.3 sec - in org.apache.hadoop.hdfs.TestPersistBlocks
{noformat}

The failed test cases all pass when rerun. {{TestPersistBlocks}} was reported in HDFS-5770. , +1 patch looks good.  Thanks Kihwal!, Thanks for the review, [~szetszwo]. I will commit it shortly., SUCCESS: Integrated in Jenkins build Hadoop-trunk-Commit #10272 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/10272/])
HDFS-9696. Garbage snapshot records linger forever. Contributed by (kihwal: rev 83e57e083f2cf6c0de8a46966c5492faeabd8f2a)
* (edit) hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestSaveNamespace.java
* (edit) hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormatProtobuf.java
, Committed all the way to branch-2.7. The same fix applies to branch-2.6, but the unit test needs to be rewritten. [~ctrezzo], do you want this for 2.6?, This seems to break {{TestOpenFilesWithSnapshot}} in branch-2.7., [~zhz]  I will take a look., I think it is broken by HDFS-10763 and a real bug. I will fix it soon. It is not an issue for trunk to branch-2.8, as the lease is inode ID based. , Thanks for looking into this [~kihwal]! Sorry about the wrong alarm. I merely verified the commit before this one and it passed. , [~kihwal] Do you think this is worth backporting to branch-2.6? If the unit test rewrite is small, it seems to make sense to me., I think it is worth having in branch-2.6. We would if we were still on 2.6. Attaching a patch for 2.6., FYR..Uploading the  branch-2.7 patch which was committed..Since there was conflict., Oh, branch-2.6 patch is same with branch-2.7., Committed it to 2.6.5., Add 2.8.0 and 2.9.0 in fix version given patch get landed there.]