[With this patch after restore storage:
[root@hd1-31851 ~]# lsof /volume1/
COMMAND   PID   USER   FD   TYPE DEVICE SIZE/OFF   NODE NAME
java    28831 hadoop   79uW  REG 252,32        0 393224 /volume1/nn/dfs/in_use.lock
java    28831 hadoop  113u   REG 252,32  1075255 393222 /volume1/nn/dfs/current/edits

, Some comments:
bq. When one of dfs.name.dir failed, namenode didn't close editlog and unlock the storage:
Are you saying for the failed directory, namenode didn't close editlog and unlock the storage or is it for all the storage directories?

If it is for the failed storage, if failure is due to a disk going bad, in most of the cases, we may not be able to do these cleanups., I'm saying for the failed directory.
Our case is due to no space on that disk. In this case, it need and should close those two files.
And I believe try to close won't make thing worse., Looks good. Fixes a bug seen in our clusters repeatedly.
+1.

Please review and commit.
, This is a rare enough problem that can be worked around by monitoring the available disk space. This part of the code has been quite brittle. Some of the changes in this area have resulted in more serious bugs and subsequent bug fixes for stabilization. My preference is to leave this as is, since monitoring disk space can avoid this issue.]