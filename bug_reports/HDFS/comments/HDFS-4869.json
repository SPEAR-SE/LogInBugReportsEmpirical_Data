[Prior to the refactoring of FsShell (HADOOP-7176), the get command supported the use of "-" to download a file and write its contents to stdout.  For example, see HADOOP-3175. Currently, this can be worked around by using -cat instead of -get. However, for consistency, both put and get should support "-" in place of stdin or stdout, respectively., This "feature" was intentionally removed 2 years ago.  As you point out it is duplicating the behavior of cat.  I don't think it can be cleanly re-added to the underlying base class for copying commands.  I'd prefer this to be a won't fix., From the jiras it wasn't clear that the change in the behavior of -get was intentional, so I thought it was a bug. In any case, I have a patch (for 0.23) that would re-implement the functionality without bloating the code too much. Daryn, can you take a look at the patch? If you think this is a good way to do it, then I can post patches for trunk and branch 2. I did try this patch with many different scenarios and it worked fine in all my tests., I don't think this will work when one of the sources is a directory, which illustrates issues associated with allowing a target of "–" to mean stdout.  The command either has to add a restriction barring directories for output to stdout which unbalances the command, ie. can't simply swap in "–" for the dest with any arguments.  Or further modified/hacked to allow recursing, skip the construction of a local path for the dest, checking existence and type of dest, creating dirs that don't exist, etc.  It starts to get complicated to fuse the existing behavior of cat into get/copyToLocal.

Unless there is a compelling need for this change, I'd still prefer won't fix., It's also deviating from the posix behavior to which FsShell tries to adhere., I tried these things and they all worked with the current patch:

hdfs dfs -get /path/to/aFile -
Result: file is printed to stdout

hdfs dfs -get /path/to/aDirWithTwoFiles/* -
Result: content of both files is printed to stdout

hdfs dfs -get /path/to/aFileThatDoesNotExist -
Result: error message "No such file or directory"

hdfs dfs -get /path/to/aFile* -
Result: prints the two files that match "aFile*" to stdout

hdfs dfs -get /path/to/aDirWithTwoFiles -
Result: error message: "Is a directory"

I guess you were referring to the last case in your comment. I thought this was the same behavior of the prior "-get aDir -" implementation, but I could be wrong about this.

In any case, I am OK with leaving it as won't fix; at least this jira now documents the fact that "-get aDir -" does not work in the current versions of Hadoop.

]