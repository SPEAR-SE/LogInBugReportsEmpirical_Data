[Attached logs from precommit run., Eddy expressed interest in fixing this, assigned to him., In {{TestBalancer#testBalancerWithStripedFile}},  it creates a file with 72 data blocks (20 * 12 * 3 / 10). Under RS(6, 3) coding, it is 72 / 6 * (6 + 3) = 108 blocks. 

And after 
{code}
      // add datanodes in new rack
      String newRack = "/rack" + (++numOfRacks);
      cluster.startDataNodes(conf, 2, true, null,
          new String[]{newRack, newRack}, null,
          new long[]{capacity, capacity});
{code}

There are 14 DataNodes before running {{Balancer}}. 

With some additional debug log, the log shows
{code}
17-05-23 18:17:23,186 [Thread-0] INFO  balancer.Balancer (Balancer.java:init(380)) - Above avg: 127.0.0.1:60027:DISK, util=50.000000, avg=40.000000, diff=10.000000, threshold=10.000000
{code}

So this DataNode: {{127.0.0.1:60027}} is not chose to be the source for balancing, because {{50.0 - 40.0 <= 10.0}}. But the actual average utilization is {{108 / 14 * 20}} = 38.57.   Thus in {{TestBalancer#waitForBalancer}}, it will fail because {{50.0 - 38.57 > 10.0}}.  This is due to that NN has not receive a new block report to reflect the moved blocks.



, Added retry logic to {{TestBalancer#waitForBalancer}}. , | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 38s{color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 15m 30s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 54s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 41s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  7s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 17s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 53s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 44s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 59s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 56s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 56s{color} | {color:green} the patch passed {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 37s{color} | {color:orange} hadoop-hdfs-project/hadoop-hdfs: The patch generated 1 new + 201 unchanged - 4 fixed = 202 total (was 205) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  3s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 13s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m  5s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 42s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 92m 22s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 24s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}122m 39s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure090 |
|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure160 |
|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting |
|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure150 |
|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:14b5c93 |
| JIRA Issue | HDFS-11682 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12869563/HDFS-11682.00.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux 78df8459bbab 3.13.0-108-generic #155-Ubuntu SMP Wed Jan 11 16:58:52 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 52661e0 |
| Default Java | 1.8.0_131 |
| findbugs | v3.1.0-RC1 |
| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/19572/artifact/patchprocess/diff-checkstyle-hadoop-hdfs-project_hadoop-hdfs.txt |
| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/19572/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/19572/testReport/ |
| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/19572/console |
| Powered by | Apache Yetus 0.5.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

, Fix checkstyle warnings. 

The test failures are not relevant. 

[~andrew.wang], [~manojg] could you take a look?, | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 15s{color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 13m 55s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 50s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 39s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 55s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 15s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 43s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 40s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 51s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 45s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 45s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 35s{color} | {color:green} hadoop-hdfs-project/hadoop-hdfs: The patch generated 0 new + 201 unchanged - 4 fixed = 201 total (was 205) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 50s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 12s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 46s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 37s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 64m 56s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 20s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 91m 23s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting |
|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure150 |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:14b5c93 |
| JIRA Issue | HDFS-11682 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12869700/HDFS-11682.01.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux 1065820e723b 3.13.0-106-generic #153-Ubuntu SMP Tue Dec 6 15:44:32 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 1c8dd6d |
| Default Java | 1.8.0_131 |
| findbugs | v3.1.0-RC1 |
| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/19594/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/19594/testReport/ |
| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/19594/console |
| Powered by | Apache Yetus 0.5.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

, Thanks for working on this Eddy!

I'm loath to make the balancer tests run even longer. 5 retries on what's already a 40s wait is really long. If the issue is out-of-date NN information, can we manually trigger HBs/ IBRs / BRs instead?, [~eddyxu],

{noformat}
  static void waitForBalancer(long totalUsedSpace, long totalCapacity,
      ClientProtocol client, MiniDFSCluster cluster, BalancerParameters p,
      int expectedExcludedNodes) throws IOException, TimeoutException {

    do {
      DatanodeInfo[] datanodeReport =
          client.getDatanodeReport(DatanodeReportType.ALL);
     .. ..
      }
      assertEquals(expectedExcludedNodes,actualExcludedNodeCount);
    } while (!balanced);
{noformat}

waitForBalancer() is already doing getDatanodeReport() in a loop and tries for 40seconds. When balancer moves around blocks, NameNode should be aware of the newer block allocations happening in other Datanodes and in this case without a resrtart, NN shouldn't be needing a block report to know DNs latest state. If NameNode not having the latest details about the Datanodes is the problem, how about triggering block report from all the Datanodes explicitly before/in the loop? Not sure if increasing the the wait time from 40seconds to 2 minutes will solve the problem as the default block report interval is 5hr and the test is not overriding it. Please explain if I got it wrong. , [~manojg], I should make it clearer, the problem is that there might not HB/BR between two _iterations_ in {{Balancer#runOneIteration}}. So that before we run {{waitForBalancer}}, the balancer task may have already finished, as the Balancer thought the avg utilization is {{40}}. As mentioned in the previous comments, the actual average utilization is {{38.7}}, so that the utilization of that particular DN {{50}} is just about larger than {{avgUtilization + threshold + delta (38.7 + 10 + 1)}} . The fix here is that, making sure that {{Balancer}} can run after another HB/BR with an accurate utilization number.  

[~andrew.wang], the miscalculation is due to the out-of-date NN blocks between _two iterations_ of {{Balancer#runOneIteration}}. So it is hard to trigger HB/BR with in the {{Balancer}} itself.  Alternatively, how about make {{timeout}} in {{TestBalancer#waitForBalancer}} shorter, i.e., 10s? So the execution time in the worst case is about the same.  

  , [~eddyxu],

From your explanation it looks like it is inevitable to run {{runBalancer}}  a couple of times with updated HB to trigger additional balancing if needed. +1 (non-binding) with one comment below.

{noformat}
942	    while (retry > 0) {
943	      // start rebalancing
944	      Collection<URI> namenodes = DFSUtil.getInternalNsRpcUris(conf);
945	      final int run = runBalancer(namenodes, p, conf);
.. ..
955	      waitForHeartBeat(totalUsedSpace, totalCapacity, client, cluster);
956	      LOG.info("  .");
957	      try {
958	        waitForBalancer(totalUsedSpace, totalCapacity, client, cluster, p,
959	            excludedNodes);
960	      } catch (TimeoutException e) {
961	        // See HDFS-11682. NN may not get heartbeat to reflect the newest
962	        // block changes.
963	        retry--;
964	        if (retry == 0) {
965	          throw e;
966	        }
967	        LOG.warn("The cluster has not balanced yet, retry...");
968	        continue;
969	      }
970	      break;
971	    }
{noformat}

{{waitForHeartBeat}} in the above loop can also timeout and throw {{TimeoutException}} which is not caught like in {{waitForBalancer}}. So, the caller could fail because of this., Hi, [~manojg] Thanks for taking care of reviewing.

Catching {{TimeoutException}} around {{waitForBalancer}} only, because if {{waitForHeartBeat()}} throws Timeout, it is not due to the mis-calculation of disk usage. So it should not be ignored.

, LGTM +1 thanks Eddy, Thanks for the reviews, [~manojg] and [~andrew.wang]. Committed., SUCCESS: Integrated in Jenkins build Hadoop-trunk-Commit #11870 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/11870/])
HDFS-11682. TestBalancer.testBalancerWithStripedFile is flaky. (lei) (lei: rev 3f5108723c6272d2fded8d3563c4b793e1d88f8b)
* (edit) hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/balancer/TestBalancer.java
]