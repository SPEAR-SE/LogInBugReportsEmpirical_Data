[The issue here, I believe, is that fuse_dfs is always putting the file into /user/root/.Trash/Current, whereas it should be putting it into {{/user/${USERNAME}/.Trash/Current}}.

We can get username from the fuse_context.  Although it comes as a UID, we can map it back to a string.  This patch does that., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12590559/HDFS-4913.002.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/4592//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/4592//console

This message is automatically generated., Here's a new version which uses asprintf rather than creating my own function to do the same thing, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12643626/HDFS-4913.003.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/6839//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/6839//console

This message is automatically generated., Nice work, I just have nits:

* Are the fprintf's to stderr intentional? They look like they're for debugging.
* Doc for get_parent_dir, "*parent dir" is missing an underscore, params aren't correct.
* Code comments in get_parent_dir would be nice, it seems like the goal is to basically put a null in the last slash that's not the end of the path, then return each part.
* Mention that trash_base is malloc'd? Could also provide an example path that would be returned.
* hdfsRename failure case, move {{ret = errno}} down for consistency
* Can you comment on manual testing?

+1 once addressed, bq. Are the fprintf's to stderr intentional? They look like they're for debugging.

yeah, those were for debugging.  removed.

bq. Doc for get_parent_dir, "*parent dir" is missing an underscore, params aren't correct.

Fixed

bq. Code comments in get_parent_dir would be nice, it seems like the goal is to basically put a null in the last slash that's not the end of the path, then return each part.

I added some more comments to the doxygen.

bq. Mention that trash_base is malloc'd? Could also provide an example path that would be returned.

added

bq. hdfsRename failure case, move ret = errno down for consistency

I can't do that, unfortunately.  The log message may clear the thread-local {{errno}} value.  This is one reason why errno-based APIs suck :(

bq. Can you comment on manual testing?

I did some manual testing on this with trash enabled, updated patch.  I did some more manual testing, One small difference I notice between fuse_dfs and the FsShell is that the latter now pulls its trash configuration from the NameNode ("server-side trash"), but {{fuse_dfs}} still requires you to specify the {{use_trash}} option when starting FUSE.  I think this is probably OK, though.  Existing {{fuse_dfs}} configurations will continue to work, and I expect use of the trash to fade away gradually, as people use snapshots instead., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12645087/HDFS-4913.004.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:red}-1 findbugs{color}.  The patch appears to introduce 1 new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.server.datanode.TestBPOfferService

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/6910//testReport/
Findbugs warnings: https://builds.apache.org/job/PreCommit-HDFS-Build/6910//artifact/trunk/patchprocess/newPatchFindbugsWarningshadoop-hdfs.html
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/6910//console

This message is automatically generated., +1, thanks Colin. We can definitely punt server-side trash support to a separate JIRA., The FindBugs warning is clearly bogus since this patch doesn't change any Java code (and findbugs only operates on java).  Similarly with the {{TestBPOfferService}} test failure.

Thanks for the reviews-- committing..., SUCCESS: Integrated in Hadoop-trunk-Commit #5606 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/5606/])
HDFS-4913. Deleting file through fuse-dfs when using trash fails, requiring root permissions (cmccabe) (cmccabe: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1595371)
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/native/fuse-dfs/fuse_trash.c
, FAILURE: Integrated in Hadoop-Yarn-trunk #562 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/562/])
HDFS-4913. Deleting file through fuse-dfs when using trash fails, requiring root permissions (cmccabe) (cmccabe: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1595371)
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/native/fuse-dfs/fuse_trash.c
, FAILURE: Integrated in Hadoop-Hdfs-trunk #1754 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1754/])
HDFS-4913. Deleting file through fuse-dfs when using trash fails, requiring root permissions (cmccabe) (cmccabe: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1595371)
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/native/fuse-dfs/fuse_trash.c
, FAILURE: Integrated in Hadoop-Mapreduce-trunk #1780 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1780/])
HDFS-4913. Deleting file through fuse-dfs when using trash fails, requiring root permissions (cmccabe) (cmccabe: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1595371)
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/native/fuse-dfs/fuse_trash.c
]