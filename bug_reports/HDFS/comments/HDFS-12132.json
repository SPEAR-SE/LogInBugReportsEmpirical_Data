[This happened because you configured {{dfs.namenode.servicerpc-address}} after upgrade. Before upgrade ZKFC used {{dfs.namenode.rpc-address}} address to store in zookeeper for active namenode. Now in fencing it trying to compare new address {{dfs.namenode.servicerpc-address}} with old active namenode address from ZK and it is not matching. 

It should be fine once you format the zkfc. This is not a issue., Thank you for your response. I understand what you mean. ZKFC let NN2 also become standby, and the whole HDFS is not available, which leads to Yarn and HBase are also not available. so the consequences are too serious. The better solution is that the ZKFC throws exception and exits, and  Active NameNode keep active state., [~surendrasingh]  What do you think of the above idea？, bq. The better solution is that the ZKFC throws exception and exits, and Active NameNode keep active state.

What if your old active Namenode(NN1) is not healthy and its not starting because of some reason like disk failure ?. ZKFC should not exit, it should retry to make local namenode active.

[~yangjiandan], we will check with others also their opinion.

[~arpitagarwal], [~andrew.wang], [~vinayrpet] Please can you give your opinion ? 
How to handle fail-over if user configured {{dfs.namenode.servicerpc-address}} address after cluster installation ? , Surendra was right. Reformatting the zkfc is the correct answer., meet this problem and mark,  delete znode store in zookeeper /hadoop-ha/hacluster/*  will also be ok.]