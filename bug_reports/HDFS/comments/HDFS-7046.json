[Stack trace from an internal 2.5.1-ish build.  Line numbers may be off, but demonstrates a delete adjusted safe mode block totals, triggering exit of safe mode, which called {{startSecretManagerIfNecessary}} which only starts if {{getEditLog().isOpenForWrite()}} is true.  The edit log stream is actually null.

{noformat}
[IPC Server handler 84 on 8020] ERROR namenode.FSEditLogLoader: Encountered exception on operation DeleteOp [length=0, path=..., timestamp=1410390000919,
RpcClientId=..., RpcCallId=..., opCode=OP_DELETE, txid=...]
java.lang.NullPointerException
        at org.apache.hadoop.hdfs.server.namenode.FSEditLog.logEdit(FSEditLog.java:410)
        at org.apache.hadoop.hdfs.server.namenode.FSEditLog.logUpdateMasterKey(FSEditLog.java:954)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.logUpdateMasterKey(FSNamesystem.java:6842)
        at org.apache.hadoop.hdfs.security.token.delegation.DelegationTokenSecretManager.logUpdateMasterKey(DelegationTokenSecretManager.java:378)
        at org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager.updateCurrentKey(AbstractDelegationTokenSecretManager.java:232)
        at org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager.startThreads(AbstractDelegationTokenSecretManager.java:116)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startSecretManager(FSNamesystem.java:990)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startSecretManagerIfNecessary(FSNamesystem.java:1004)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.access$1200(FSNamesystem.java:294)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.leave(FSNamesystem.java:5208)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.checkMode(FSNamesystem.java:5283)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.setBlockTotal(FSNamesystem.java:5320)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.adjustBlockTotals(FSNamesystem.java:5509)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeInfo.access$2100(FSNamesystem.java:5054)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.adjustSafeModeBlockTotals(FSNamesystem.java:5654)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.removeBlocksAndUpdateSafemodeTotal(FSNamesystem.java:3646)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.removePathAndBlocks(FSNamesystem.java:3610)
        at org.apache.hadoop.hdfs.server.namenode.FSDirectory.unprotectedDelete(FSDirectory.java:1196)
        at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.applyEditLogOp(FSEditLogLoader.java:506)
        at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadEditRecords(FSEditLogLoader.java:228)
{noformat}
, Good find, Daryn. Given that you marked this as affecting 2.5.0, do you have reason to believe that this does not affect earlier versions?, I actually do not know when the issue was introduced.  Earlier versions may very well be affected., We've had 2 incidents.  Both were delete ops.  One was of a directory, one was of a file.

Luckily, restarting the NN allows it to recover.  Apparently the issue doesn't manifest if the edit logs are finalized., Looks like the incremental tracking of block that is only active for HA is causing the problem, or at least is part of the problem., Incremental tracking is okay. Even during transition to active, the block counts need to be updated in order to leave safe mode after the transition.  The problem is, it is trying to leave safe mode in the middle of replaying edits as part of catch-up during transition to active.  A simple solution will be adding following to {{checkMode()}}.

{code}
       if (inTransitionToActive()) {
        return;
      }
{code}

Leaving safe mode in the middle of replaying edits while still in standby state should be okay., Since the secret manager is the one who is trying to edit-log while replaying edits, this will not cause a failure if security is off., Attaching a patch with a test case that reproduces the execution path.  On transitioning to active, the standby can come out of safe mode in the middle of replaying edits.  The patch also includes partial fix for demonstration purpose.

The test case will fail, because with the partial fix, it does not enter safe mode extension and the safe mode message is different.  If the partial fix in FSNamesystem.java is removed, the test will pass since it is already coming out of safe mode.

The complete fix will include {{checkSafeMode()}} call at the end of transitioning, so that it can come out of same mode even if the cluster is completely idle., Attaching a patch with the final fix., +1 Kihwal and I thought through the problem very thoroughly and this is the simplest fix possible.  It's unfortunate there's no test but it would be extremely difficult to write.  [~atm], are you ok with the patch?, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12668368/HDFS-7046.patch
  against trunk revision 78b0483.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/8007//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/8007//console

This message is automatically generated., Thanks for working on this, [~kihwal] and [~daryn].

One minor concern of the current solution is that, if we move checkSafeMode from the middle of transition to the end of transition, the actual service down time may increase (if SBN is in safemode during the failover), especially considering we still have the 30s safemode extension time. So instead, can we add an {{!inTransitionToActive()}} check for the {{startSecretManagerIfNecessary}} call inside of {{SafeModeInfo#leave}}?, Replaying last edit segment won't take much time anyway. So even if the decision for leaving safe mode is made in the middle, it will still have to wait more than 20 seconds in safe mode extension. So I don't think the suggested change will help much.  If a user really cares about failover latency, the safe mode extension should be set to 0 or a very small value., Modifying the startup of the secret manager feels hacky.  Changing active state in the very middle of processing an edit op seems pretty dangerous and wrong.  Even if it works today.  It's not something I would have ever expected the NN to do.

If the NN is allowed to exit safemode before finishing the edits replay then effectively it's exiting due to consistency "at some point in the past", instead of consistent "right now". , I agree with Kihwal and Daryn that the benefit of starting the process of leaving safemode while edits are still being processed seems negligible, so it's better to be safe here and just wait for the transition to active to complete. In a steady state cluster it's very unlikely for the standby to be in safemode anyway, since the NN will not enter safemode on its own except immediately after startup, and there's little or no reason for the admin to ever put the standby in safemode anyway.

+1, the patch makes sense to me. I agree that it would be pretty difficult to write a test for this case, and now that the issue is pointed out the fix is quite straightforward, so I'm OK committing this without a test., Thanks for the review, Aaron.
[~jingzhao], are you okay with the patch?, Yeah, your analysis makes sense to me. +1., SUCCESS: Integrated in Hadoop-Yarn-trunk #686 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/686/])
HDFS-7046. HA NN can NPE upon transition to active. Contributed by (kihwal: rev 9e355719653c5e7b48b601090634882e4f29a743)
* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java
, FAILURE: Integrated in Hadoop-Hdfs-trunk #1877 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1877/])
HDFS-7046. HA NN can NPE upon transition to active. Contributed by (kihwal: rev 9e355719653c5e7b48b601090634882e4f29a743)
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java
* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
, FAILURE: Integrated in Hadoop-Mapreduce-trunk #1902 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1902/])
HDFS-7046. HA NN can NPE upon transition to active. Contributed by (kihwal: rev 9e355719653c5e7b48b601090634882e4f29a743)
* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java
]