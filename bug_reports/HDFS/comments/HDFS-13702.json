[Removing all the HTrace stuff from the block reader path improved the performance of TeraValidate by about 20%, reduced CPU consumption of the job in LocalJobRunner mode by about 36%.

We could attempt to use the HTrace APIs in a fancier way to detect when tracing is not enabled, but I think we may be better off just removing it entirely. HTrace as a project is being retired. If we choose to re-introduce tracing (eg using OpenTracing) we should make sure to benchmark it more thoroughly. [~stack] what do you think?, Here are some perf results based on a 180GB teravalidate on a small cluster, as well as a 1GB teravalidate on LocalJobRunner (against a remote HDFS)
{code}
3.0.x original
------------------------------------
Avg map: 18sec
CPU time spent (ms)    2,208,950
GC time elapsed (ms)    68,153
 Performance counter stats for './run-validate.sh' (5 runs):

      22357.081985      task-clock (msec)         #    2.688 CPUs utilized            ( +-  6.78% )
            21,573      context-switches          #    0.965 K/sec                    ( +-  2.58% )
             1,300      cpu-migrations            #    0.058 K/sec                    ( +-  4.82% )
           425,146      page-faults               #    0.019 M/sec                    ( +-  4.52% )
    63,809,409,850      cycles                    #    2.854 GHz                      ( +-  6.56% )
    66,580,182,677      instructions              #    1.04  insn per cycle           ( +-  2.28% )
    13,489,574,848      branches                  #  603.369 M/sec                    ( +-  4.58% )
       158,670,595      branch-misses             #    1.18% of all branches          ( +-  0.35% )

       8.317048233 seconds time elapsed                                          ( +-  0.10% )


3.0.x patched:
--------------------------------------------------------------------------------
Avg map time: 14sec
CPU time spent (ms)       1,750,180
GC time elapsed (ms)     42,468

 Performance counter stats for './run-validate.sh' (5 runs):

      14466.559412      task-clock (msec)         #    2.006 CPUs utilized            ( +-  3.18% )
            21,666      context-switches          #    0.001 M/sec                    ( +-  0.55% )
             1,180      cpu-migrations            #    0.082 K/sec                    ( +-  1.91% )
           234,159      page-faults               #    0.016 M/sec                    ( +-  0.60% )
    41,793,452,250      cycles                    #    2.889 GHz                      ( +-  2.77% )
    55,219,815,925      instructions              #    1.32  insn per cycle           ( +-  1.67% )
     9,837,238,534      branches                  #  679.998 M/sec                    ( +-  2.57% )
       161,071,903      branch-misses             #    1.64% of all branches          ( +-  0.62% )

       7.210730451 seconds time elapsed                                          ( +-  0.25% )
{code}, bq. ....what do you think?

I think we need to be able to trace end-to-end where time is being spent.

I think that if htrace is not enabled, it should not add friction.

I think harley-davidson's are awful motorcycles but even they don't deserve the abuse they are getting.

I think those numbers you posted for the difference your patch makes  in throughput stripping htrace are radical.

Poor htrace has been added to the apache attic. It got no loving.

htace in hdfs got no loving either post inital-commit; it was added and then let fester.

I think we should commit this patch, +1, and  then we can file another to review how to move forward with tracing in light of recent developments in htrace project; i.e. purge all other htrace references, look into alternatives, etc., | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 39s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 4 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 11s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 28m 39s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 16m 57s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 14s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  2m  8s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 13m 42s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  4m 40s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 20s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 10s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:red}-1{color} | {color:red} mvninstall {color} | {color:red}  0m 40s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:red}-1{color} | {color:red} compile {color} | {color:red}  1m 15s{color} | {color:red} hadoop-hdfs-project in the patch failed. {color} |
| {color:red}-1{color} | {color:red} javac {color} | {color:red}  1m 15s{color} | {color:red} hadoop-hdfs-project in the patch failed. {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m  9s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} mvnsite {color} | {color:red}  0m 36s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:red}-1{color} | {color:red} shadedclient {color} | {color:red}  3m  6s{color} | {color:red} patch has errors when building and testing our client artifacts. {color} |
| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  0m 20s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 11s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  1m 29s{color} | {color:green} hadoop-hdfs-client in the patch passed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  0m 36s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 21s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 80m 54s{color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:abb62dd |
| JIRA Issue | HDFS-13702 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12929253/hdfs-13702.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |
| uname | Linux b0df8745d820 3.13.0-143-generic #192-Ubuntu SMP Tue Feb 27 10:45:36 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 3e58633 |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_171 |
| findbugs | v3.1.0-RC1 |
| mvninstall | https://builds.apache.org/job/PreCommit-HDFS-Build/24501/artifact/out/patch-mvninstall-hadoop-hdfs-project_hadoop-hdfs.txt |
| compile | https://builds.apache.org/job/PreCommit-HDFS-Build/24501/artifact/out/patch-compile-hadoop-hdfs-project.txt |
| javac | https://builds.apache.org/job/PreCommit-HDFS-Build/24501/artifact/out/patch-compile-hadoop-hdfs-project.txt |
| mvnsite | https://builds.apache.org/job/PreCommit-HDFS-Build/24501/artifact/out/patch-mvnsite-hadoop-hdfs-project_hadoop-hdfs.txt |
| findbugs | https://builds.apache.org/job/PreCommit-HDFS-Build/24501/artifact/out/patch-findbugs-hadoop-hdfs-project_hadoop-hdfs.txt |
| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/24501/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/24501/testReport/ |
| Max. process+thread count | 289 (vs. ulimit of 10000) |
| modules | C: hadoop-hdfs-project/hadoop-hdfs-client hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/24501/console |
| Powered by | Apache Yetus 0.8.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

, {quote}
I think we should commit this patch, +1, and then we can file another to review how to move forward with tracing in light of recent developments in htrace project; i.e. purge all other htrace references, look into alternatives, etc.
{quote}

please be sure to link the follow-on jira to this one. probably should get a DISCUSS thread on common-dev@, | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 35s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 4 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 11s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 32m 16s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 20m 49s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 17s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  2m 21s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 15m 32s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  4m 52s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 37s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 13s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  2m 24s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 19m 49s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 19m 49s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 11s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 53s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 12m 17s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  3m 44s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 27s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  1m 33s{color} | {color:green} hadoop-hdfs-client in the patch passed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  0m 38s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 25s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}122m 34s{color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:abb62dd |
| JIRA Issue | HDFS-13702 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12929270/hdfs-13702.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |
| uname | Linux abd8325e84cd 3.13.0-143-generic #192-Ubuntu SMP Tue Feb 27 10:45:36 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / b69ba0f |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_171 |
| findbugs | v3.1.0-RC1 |
| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/24502/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/24502/testReport/ |
| Max. process+thread count | 336 (vs. ulimit of 10000) |
| modules | C: hadoop-hdfs-project/hadoop-hdfs-client hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/24502/console |
| Powered by | Apache Yetus 0.8.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

, Not sure what's up with the above precommit. It appears like it didn't apply the latest patch, even though the console log shows it downloading from the latest URL. When I apply the patch locally and build in a clean tree, it builds OK. Any ideas?, Why do you think it didn't apply the latest patch?  the reported URL is the latest one AFAICT., Todd got me to the log

{code}

[INFO] -------------------------------------------------------------
[INFO] -------------------------------------------------------------
[ERROR] COMPILATION ERROR : 
[INFO] -------------------------------------------------------------
[ERROR] /testptch/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/erasurecode/StripedBlockReader.java:[128,30] error: method newBlockReader in class BlockReaderRemote cannot be applied to given types;
[INFO] 1 error
[INFO] -------------------------------------------------------------
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 26.030 s
[INFO] Finished at: 2018-06-27T00:06:25+00:00
[INFO] Final Memory: 27M/570M
[INFO] ------------------------------------------------------------------------
[WARNING] The requested profile "native" could not be activated because it does not exist.
[WARNING] The requested profile "yarn-ui" could not be activated because it does not exist.
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.1:compile (default-compile) on project hadoop-hdfs: Compilation failure
[ERROR] /testptch/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/erasurecode/StripedBlockReader.java:[128,30] error: method newBlockReader in class BlockReaderRemote cannot be applied to given types;
{code}

we've been chatting and it definitely looks like we run against the wrong artifact. Todd has a plausible theory that maybe a concurrent run of the snapshot publisher happens to land in the asf snapshot repo between when we did test-compile and here.

I'm going to rerun in debug., Looked into this a bit more and found the issue: the build happened to run around midnight UTC, so the "patch javadoc" build downloaded a new SNAPSHOT build of the 'hadoop-hdfs-client' jar into the local repo. Then, when it ran the hadoop-hdfs tests, they ran against the trunk snapshot build rather than the patched snapshot build, and failed to compile. Sean's going to file a YETUS JIRA about this and re-submit the patch build here., well I started another run but the Hadoop related precommit jobs don't have a debug flag so I'll need to add one., {quote}
Then, when it ran the hadoop-hdfs tests, they ran against the trunk snapshot build rather than the patched snapshot build, and failed to compile. Sean's going to file a YETUS JIRA about this and re-submit the patch build here.
{quote}

I wanna take a look at Hadoop's pom. ideally we shouldn't have the ASF snapshot repo as a source of artifacts at all. I'm not sure there's a way for yetus to proactively defend against it. (maybe use maven's {{--offline}} for build steps after the one where we say we're downloading the world?), Perhaps using '-nsu' on all the patch builds? Would be nice if there were a way to get the equivalent of 'nsu' but specifying a particular glob of artifact IDs, etc., This is something to talk about at a broader level than a JIRA; 

Stack said

> I think we should commit this patch, +1, 

=0 

I do want a trace layer in there; I do want it broader than just HDFS, and I do want it to be used from the layers above. I don't want stuff taken from DFSClient until there's a better story there. Otherwise: it'll get cut, nobody will replace it, and it'll get lost in folklore.
, {quote}I do want a trace layer in there; I do want it broader than just HDFS, and I do want it to be used from the layers above. I don't want stuff taken from DFSClient until there's a better story there. Otherwise: it'll get cut, nobody will replace it, and it'll get lost in folklore.
 {quote}

Sure, I agree tracing is nice. I recently worked on adding OpenTracing support to the HMS (HIVE-19685). I think we could do the same here. That said, regardless of trace framework, I think we can all agree that the current code path is too expensive as written today. I don't have time to do the heavy lifting of moving entirely to some new tracing framework, so in the meantime I think we should fix this perf issue by removing this heavy code path. I didn't remove all the other FS-operation-level trace annotations (eg open/close/listStatus/etc) since those are likely to be less high throughput and therefore overhead not an issue.
, bq. I do want a trace layer in there; I do want it broader than just HDFS, and I do want it to be used from the layers above. 

Me too.

bq. Otherwise: it'll get cut, nobody will replace it, and it'll get lost in folklore.

Better this than a dead, disabled lib burning everyone's CPU to no end. Even when enabled, as is, it is of little to no value. Trace in hdfs is in need of work but it has been suffering neglect since Colin's add.

bq. This is something to talk about at a broader level than a JIRA;

I can start a thread. Suggest this discussion not block this patch? Or, add in placeholders/comments for the trace points removed here?

Thanks [~stevel@apache.org]




, | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 19s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 4 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m  8s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 24m  0s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 15m 26s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 14s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 33s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 11m 30s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  3m  6s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m  4s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m  8s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m 28s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 15m 25s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 15m 25s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m  7s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 22s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green}  9m 44s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  3m 14s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m  0s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  1m 25s{color} | {color:green} hadoop-hdfs-client in the patch passed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red}115m 16s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 22s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}206m 33s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.hdfs.web.TestWebHdfsTimeouts |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:abb62dd |
| JIRA Issue | HDFS-13702 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12929270/hdfs-13702.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |
| uname | Linux fc9dd14165bc 4.4.0-64-generic #85-Ubuntu SMP Mon Feb 20 11:50:30 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / aaf03cc |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_171 |
| findbugs | v3.1.0-RC1 |
| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/24509/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/24509/testReport/ |
| Max. process+thread count | 3545 (vs. ulimit of 10000) |
| modules | C: hadoop-hdfs-project/hadoop-hdfs-client hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/24509/console |
| Powered by | Apache Yetus 0.8.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

, The test failure seems unrelated. Given I have a +1 on this from Stack and only a =0 from [~stevel@apache.org] I'll plan to commit this tomorrow unless someone objects. I think we can continue the discussion about HTrace removal in HADOOP-15566., bq,  I didn't remove all the other FS-operation-level trace annotations (eg open/close/listStatus/etc) since those are likely to be less high throughput and therefore overhead not an issue.

OK, if it's low level read() stuff which is chattiest and most expensive, then +1 to cutting this now, while we can worry about how to do it better.

BTW, does anyone have a public set of traces of IO patterns of apps/queries?, +1 LGTM as well, committing on behalf of Todd to trunk, branch-3.1, branch-3.0. Thanks for the patch Todd, and reviews from Stack and Steve. Let's take the continued tracing discussion to common-dev., SUCCESS: Integrated in Jenkins build Hadoop-trunk-Commit #14508 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/14508/])
HDFS-13702. Remove HTrace hooks from DFSClient to reduce CPU usage. (wang: rev 5d748bd056a32f2c6922514cd0c5b31d866a9919)
* (edit) hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/client/impl/BlockReaderFactory.java
* (edit) hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSClient.java
* (edit) hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/erasurecode/StripedBlockReader.java
* (edit) hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDataNodeVolumeFailure.java
* (edit) hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/client/impl/TestBlockReaderLocal.java
* (edit) hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/client/impl/BlockReaderRemote.java
* (edit) hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java
* (edit) hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NamenodeFsck.java
* (edit) hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/client/impl/BlockReaderTestUtil.java
* (edit) hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestBlockTokenWithDFS.java
* (edit) hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/client/impl/BlockReaderLocalLegacy.java
* (edit) hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/client/impl/BlockReaderLocal.java
]