[For standby bootstrapping, HDFS-3284 made it work but HDFS-3438 broke it again. In general the proxy object for a protocol should be created with the config that has the correct server principle set.  For example, standby namenode talks to active namenode via NamenodeProtocol, where the server principal key is defined as DFS_NAMENODE_USER_NAME_KEY, "dfs.namenode.kerberos.principal".  The standby bootstrapping and checkpointing fail because the namenode proxy object has a conf with DFS_NAMENODE_USER_NAME_KEY set to itself. The RPC address is correctly set, but the wrong server principle is used.

When I modified the code to create the proxy with "other NN config", everything worked. 

I haven't checked thoroughly, but ConfiguredFailoverProxyProvider may have a similar issue., It seems client side is okay., It works by using "user@/_HOST@relm" as principal. But then what's the point of having dfs.namenode.kerberosprincipal.<nsid>.<nnid>?
Since there is a workaround, I will lower the priority., The only use case I can see for different keys is if the NNs are running as different users.  However the current implementation doesn't support that.  It assumes any remote NN's principal can be constructed via its own configured principal, so yes, use of _HOST is currently mandatory., By requiring "_HOST" to be used, we rely on the rpc server address to guess the server principal. This is fine as long as all use cases can be supported.  The ability to set separate principal for each namenode in HA config can be misleading, but does not hurt. Resolving as "won't fix".]