[Use the following steps to repro:

1. Create a situation where node A has several blocks with replication factor equal to 1.
2. Start to decommission node A. Right after the decommission process starts, kill the DN JVM on node A.
3. Wait until NN marks node A dead. After that, NN will mark the node as decommissioned. That is because when there is no block left for the DN, decommission is considered done. Given node A hasn't finished copying its blocks, there will be missing blocks at this point.

{noformat}
BlockManager.java
  boolean isReplicationInProgress(DatanodeDescriptor srcNode) {
    boolean status = false;
...
    final Iterator<? extends Block> it = srcNode.getBlockIterator();
    while(it.hasNext()) {
...
// set status if there is block under replication
    }
...
    return status;
}
{noformat}

4. Restart the node A. Upon datanode registration, given the node is already in decommissioned state, no decommission is performed. So node A will be in decommissioned state and its blocks aren't copied to other nodes.


Some ideas on how to fix it,

1. When a DN becomes dead during decommission, NN can continue to mark the DN "decommission-in-progress". That will allow the DN to resume the decommission process when it rejoins the cluster.

2. Another approach could be to relax the definition of "decommissioned" state so that when BlockManager choose source datanode for replication, it could choose "decommissioned" under special condition, e.g., there is no other datanode available.

Suggestions?
, The patch keeps the node in DECOMMISSION_INPROGRESS state if the node becomes dead during decommission. In that way, the decommission can resume when the node rejoins the cluster later., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12659022/HDFS-6791.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/7520//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/7520//console

This message is automatically generated., Thanks for working on this, [~mingma]! I also think the approach 1 should be useful and safe: the DataNode should continue its decommission process after coming back, and the admin can still use refreshNodes to stop its decommission afterwards.

The current patch looks good to me. Some nits:
# Looks like the variable addr has been used in testDecommissionStatusAfterDNRestart
# In the following code, if the replication monitor thread in the block manager gets delayed and only starts its first scan after calling refreshNodes, the decommission may finish before stopping the DN. Maybe we can also disable the heartbeats of DNs to make sure the replication never succeeds? But this is a very rare case with very low possibility, thus this change can be optional.
{code}
+    decommissionNode(fsn, localFileSys, dnName);
+    dm.refreshNodes(conf);
+
+    // Stop the DN when decommission is in progress.
+    DataNodeProperties dataNodeProperties = cluster.stopDataNode(dnName);
{code}, Thanks, Jing.

Here is the updated patch that fixed the unused variable issue.

For the rare condition where the decommission might have been completed by the time stopDataNode is called, the patch set DFS_DATANODE_BALANCE_BANDWIDTHPERSEC_KEY to 1 so it is going to longer time for the decommission to complete before the test time outs. Will that work?, Yeah, looks good to me. +1 pending Jenkins., Updated patch to make the test more robust. After the node is considered dead by DatanodeManager, make sure all blocks have been removed for that node and BlockManager gets a chance to update decommission state. After all that, the test will verify the decommission status of the node., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12659931/HDFS-6791-2.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover
                  org.apache.hadoop.hdfs.server.namenode.TestCacheDirectives
                  org.apache.hadoop.hdfs.server.namenode.ha.TestDFSUpgradeWithHA

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/7563//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/7563//console

This message is automatically generated., {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12659955/HDFS-6791-3.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 2 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/7564//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/7564//console

This message is automatically generated., I've committed this to trunk and branch-2. Thanks for the contribution, [~mingma]!, FAILURE: Integrated in Hadoop-trunk-Commit #6024 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/6024/])
HDFS-6791. A block could remain under replicated if all of its replicas are on decommissioned nodes. Contributed by Ming Ma. (jing9: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1616306)
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManagerTestUtil.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestDecommissioningStatus.java
, FAILURE: Integrated in Hadoop-Yarn-trunk #636 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/636/])
HDFS-6791. A block could remain under replicated if all of its replicas are on decommissioned nodes. Contributed by Ming Ma. (jing9: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1616306)
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManagerTestUtil.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestDecommissioningStatus.java
, FAILURE: Integrated in Hadoop-Hdfs-trunk #1830 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1830/])
HDFS-6791. A block could remain under replicated if all of its replicas are on decommissioned nodes. Contributed by Ming Ma. (jing9: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1616306)
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManagerTestUtil.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestDecommissioningStatus.java
, SUCCESS: Integrated in Hadoop-Mapreduce-trunk #1856 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1856/])
HDFS-6791. A block could remain under replicated if all of its replicas are on decommissioned nodes. Contributed by Ming Ma. (jing9: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1616306)
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManagerTestUtil.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestDecommissioningStatus.java
]