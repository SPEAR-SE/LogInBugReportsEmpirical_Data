[Patch 1 adds a new hdfs-site property which allows the user to specify which nameservices are *not* part of the cluster. This allows configuration information to be supplied for other clusters so that clients can resolve their locations., Note that the patch was developed against CDH5 source., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12644500/HDFS-6376-patch-1.patch
  against trunk revision .

    {color:red}-1 patch{color}.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/6881//console

This message is automatically generated., Patch 2 against the 2.4 branch, Cancelling patch-1, renamed patch, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12646823/HDFS-6376-branch-2.4.patch
  against trunk revision .

    {color:red}-1 patch{color}.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/6977//console

This message is automatically generated., This is becoming laborious., Built locally with
{noformat}
dev-support/test-patch.sh ../hadoop-patches/HDFS-6376-3-branch-2.4.patch
{noformat}

resulted in:
{noformat}
-1 overall.  

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 3 new or modified tests.

    -1 javadoc.  The javadoc tool appears to have generated 11 warning messages.

    -1 javac.  The patch appears to cause tar ant target to fail.

    -1 eclipse:eclipse.  The patch failed to build with eclipse:eclipse.

    +1 findbugs.  The patch does not introduce any new Findbugs (version ) warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

{noformat}, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12646826/HDFS-6376-3-branch-2.4.patch
  against trunk revision .

    {color:red}-1 patch{color}.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/6978//console

This message is automatically generated., Jenkins build failing with:
HDFS-6376 patch is being downloaded at Mon May 26 23:54:17 UTC 2014 from
http://issues.apache.org/jira/secure/attachment/12646826/HDFS-6376-3-branch-2.4.patch
cp: cannot stat `/home/jenkins/buildSupport/lib/*': No such file or directory
The patch does not appear to apply with p0 to p2
PATCH APPLICATION FAILED
, forgot --no-prefix in patch 3, fix patch, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12647011/HDFS-6376-4-branch-2.4.patch
  against trunk revision .

    {color:red}-1 patch{color}.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/6989//console

This message is automatically generated., New patch against trunk, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12647824/HDFS-6376-5-trunk.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.TestClientReportBadBlock

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/7025//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/7025//console

This message is automatically generated., Test failed due to read timeout on socket. Don't think my patch caused this. Also, I had a fix for the ClusterJSPHelper in the 2.x branch, but this appears to be gone in 3.x. If someone can tell me where this was moved to, then I will patch it also., Realized that I need to make a change in DFSUtil also., Includes change to DFSUtils., {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12649984/HDFS-6376-6-trunk.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 2 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/7092//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/7092//console

This message is automatically generated., ready for review., I don't like the behavior of the change in DFSUtil in Patch 6. I will be reverting to patch 5, Backed out changes to DFSUtil., {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12655460/HDFS-6376-7-trunk.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/7333//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/7333//console

This message is automatically generated., In the case of secured clusters, even a separate configuration is not sufficient to allow distcp to function -- Yarn is unable to resolve the namespace as it uses it's own local configuraiton (at least for delegation tokens). This makes distcp between secure HA clusters impossible without this issue being fixed., [~dlmarion], have you tested your patch for distcp between real clusters? It will be great if you can generally mention how you patch works for  both secured and insecure HA clusters., Besides the comment about testing in real clusters, the patch looks good to me. Maybe we can rename the new configuration from "dfs.nameservice.cluster.excludes" to something like "dfs.nameservices.cluster.outside"? Another nit is that we need to fix indents in the new unit test., Thanks for reviewing this. I thought this was dead and that I would forever have to patch Hadoop for our application. Out of curiosity, have others started running into this issue?

bq. have you tested your patch for distcp between real clusters?

Yes. I have been running a version of this patch for about 2 months on a test cluster. We are using Hadoop 2 so the patch that I am applying is a little different. My Hadoop 2 patch also includes a change in the dfsclusterhealth.jsp file so that only NameNodes in "this" cluster are shown. I could not find the same jsp file in the Hadoop 3 source. Generally speaking, I think I have fixed all locations in the code that need to be fixed, but I could be missing something that I don't know about. As you can see from the patch history, I thought I had to make a change DFSUtil, but it broke some things and I had to revert those changes.

bq. It will be great if you can generally mention how you patch works for both secured and insecure HA clusters.

We are not using secured HA, it has not been tested in that manner

bq.  Another nit is that we need to fix indents in the new unit test.

I'm happy to fix.

bq. Maybe we can rename the new configuration from "dfs.nameservice.cluster.excludes" to something like "dfs.nameservices.cluster.outside"

I have no issues with changing the name. In my situation I have multiple HDFS nameservices defined in hdfs-site.xml and I want to explicitly state which ones are not part of "this" cluster. Exclude seemed like a good term for that., Thanks for the response, [~dlmarion].

bq. I have been running a version of this patch for about 2 months on a test cluster. We are using Hadoop 2 so the patch that I am applying is a little different. 

Cool. Then could you also post an updated patch for hadoop 2 since we will finally merge the patch to branch-2?

bq. Exclude seemed like a good term for that.

Sounds good to me. Let's keep the current name then.

Some other comments (sorry I should have posted them yesterday...):
# Minor: it may be better to wrap the logic of the following code into a new method in DFSUtil since we use it in multiple places.
{code}
+    Map<String, Map<String, InetSocketAddress>> newAddressMap =
+        DFSUtil.getNNServiceRpcAddresses(conf);
+
+    for (String exclude : nameServiceExcludes)
+      newAddressMap.remove(exclude);
{code}
# Currently DFSUtil#getOnlyNameServiceIdOrNull returns null if there are more than two nameservices specified. There are a couple of places called this method, and looks like DFSHAAdmin#resolveTarget may hit some issue if no -ns option is specified by HAAdmin. Thus I think we may also need to add the exclude logic in DFSUtil#getOnlyNameServiceIdOrNull. And we need to add more tests for this new feature, e.g., to cover its usage in DFSHAAdmin., Tested slightly modified version of patch against 2.2.0. Verified that distcp between two secure HA clusters works as expected., Since the remaining work is trivial, I will just update the patch for [~dlmarion]. The changes included:
# Wrap the exclusion logic in DFSUtil#getNNServiceRpcAddressesIncluded, # Use {{getTrimmedStringCollection}} instead of {{getStringCollection}}
# Rename the new conf property to "dfs.remote.cluster.nameservices"
# Add more unit tests
, I think it might make more sense to explicitly specify the name service that the DNs should report to. Since the changes are trivial, I'll provide another patch., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12663768/HDFS-6376.008.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 3 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The following test timeouts occurred in hadoop-hdfs-project/hadoop-hdfs:

org.apache.hadoop.fs.TestEnhancedByteBufferAccess

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/7729//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/7729//console

This message is automatically generated., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12663801/HDFS-6376.000.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 3 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover
                  org.apache.hadoop.hdfs.TestFileCreation
                  org.apache.hadoop.hdfs.web.TestWebHdfsFileSystemContract
                  org.apache.hadoop.security.TestRefreshUserMappings
                  org.apache.hadoop.hdfs.server.datanode.TestBlockPoolManager

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/7733//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/7733//console

This message is automatically generated., Comments on the new 000 patch:
# In the following code, when {{parentNameServices}} is empty, there is no need to compare {{parentNameServices}} and {{availableNameServices}}.
{code}
+    Collection<String> parentNameServices = conf.getTrimmedStringCollection
+            (DFSConfigKeys.DFS_INTERNAL_NAMESERVICES_KEY);
+
+    if (parentNameServices.isEmpty()) {
+      parentNameServices = conf.getTrimmedStringCollection
+              (DFSConfigKeys.DFS_NAMESERVICES);
+    }
+
+    Set<String> availableNameServices = Sets.newHashSet(conf
+            .getTrimmedStringCollection(DFSConfigKeys.DFS_NAMESERVICES));
+    for (String nsId : parentNameServices) {
+      if (!availableNameServices.contains(nsId)) {
+        throw new IOException("Unknown nameservice: " + nsId);
+      }
+    }
{code}
# Please generally describe your system test results (when applying the 000 patch for distcp between two HA clusters).
# Some code needs to fix indent.

bq. I think it might make more sense to explicitly specify the name service that the DNs should report to. 
I do not have a strong feeling between the "include" and the "exclude" logic here. Actually the original exclusive logic looks even simpler to me, since it does not need to handle the incompatibility issue (i.e., no extra handling when the new configuration property is not specified)., Besides, we may need a better name for {{getNNServiceRpcAddressesForMyCluster}}., It looks like some folks have picked this up and moved it forward, is there a need for me to do anything? From my earlier comments, there are some changes in dfsclusterhealth.jsp in the Hadoop2 branch so that only NN's associated with "this" cluster are listed. Not sure where that jsp file is for Hadoop 3., bq. I think it might make more sense to explicitly specify the name service that the DNs should report to. Since the changes are trivial, I'll provide another patch.

I agree. I think there is a deficiency in the configuration properties. With federation, an HDFS cluster is a set of nameservices (ns1, ns2, ns3, ns4). However, I don't think you can define an alias for the overall cluster such that cluster1 contains ns1 and ns2, and cluster2 contains n3 and ns4. In hdfs-site.xml, all of the nameservices are listed and the DN tries to connect to all of them, with the downside that the first one that responds to the DN assigns the cluster id. My patch took the non-invasive approach as I am not familiar with the code base and all of the affected components. I think a better long term implementation would be to specify the clusters (cluster1, cluster2) and their associated nameservices and specify which cluster is "this" cluster., bq. Currently DFSUtil#getOnlyNameServiceIdOrNull returns null if there are more than two nameservices specified. There are a couple of places called this method, and looks like DFSHAAdmin#resolveTarget may hit some issue if no -ns option is specified by HAAdmin. Thus I think we may also need to add the exclude logic in DFSUtil#getOnlyNameServiceIdOrNull. And we need to add more tests for this new feature, e.g., to cover its usage in DFSHAAdmin.

I tried a change in DFSUtil in my patch6 (see below). I had to back it out as it caused problems. I have had to use -ns in the admin commands and am use to using it now. My point here is that if you have a complex configuration, then you may need to be more specific in the commands that you execute. I think its fair to force the user to specify the -ns argument.

{code}
+++ hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSUtil.java
@@ -527,7 +527,12 @@ public static String path2String(final Object path) {
    * @return collection of nameservice Ids, or null if not specified
    */
   public static Collection<String> getNameServiceIds(Configuration conf) {
-    return conf.getTrimmedStringCollection(DFS_NAMESERVICES);
+    Collection<String> nameServices =
+      conf.getTrimmedStringCollection(DFSConfigKeys.DFS_NAMESERVICES);
+    Collection<String> nameServiceExcludes =
+      conf.getTrimmedStringCollection(DFSConfigKeys.DFS_NAMESERVICE_CLUSTER_EXCLUDES_KEY);
+    nameServices.removeAll(nameServiceExcludes);
+    return nameServices;
   }
{code}, bq. My point here is that if you have a complex configuration, then you may need to be more specific in the commands that you execute. I think its fair to force the user to specify the -ns argument.

This makes sense to me. Let's require admins to explicitly specify the NS name., The v9 patch addresses Jing's comments. I have tested the patch on two insecure HA clusters and it worked as expected.

The configuration needs to make the following changes:

# {{dfs.nameservices}} to include both clusters
# {{dfs.internal.nameservices}} to specify the nameservice that the DN belongs to.
# {{dfs.namenode.rpc-address.<cluster>.<nn>}} to specify the address of the NN for both clusters.
# {{dfs.client.failover.proxy.provider.<cluster>}} for both clusters.

, bq. It looks like some folks have picked this up and moved it forward, is there a need for me to do anything? From my earlier comments, there are some changes in dfsclusterhealth.jsp in the Hadoop2 branch so that only NN's associated with "this" cluster are listed. Not sure where that jsp file is for Hadoop 3.

It would be great if you can test the patch in your environment as well. The JSP UI has been deprecated in hadoop 2 and removed from trunk., bq. My patch took the non-invasive approach as I am not familiar with the code base and all of the affected components. I think a better long term implementation would be to specify the clusters (cluster1, cluster2) and their associated nameservices and specify which cluster is "this" cluster.

There are no fundamental differences between having an exclude and include lists for the clusters. It is somewhat easier to predict what NNs that the DNs are going to report just based on the configuration. I agree that having the ability to specify what a cluster is will simplify the configuration.

bq. I tried a change in DFSUtil in my patch6 (see below). I had to back it out as it caused problems. I have had to use -ns in the admin commands and am use to using it now. My point here is that if you have a complex configuration, then you may need to be more specific in the commands that you execute. I think its fair to force the user to specify the -ns argument.

Agree. I think it is fair to require the users to specify the nameservice in this complex settings., The latest 010 patch looks good to me. +1. Thanks for the contribution, [~dlmarion] and [~wheat9]!

[~dlmarion], do you want to try the current patch in your cluster?, I don't see an entry in hdfs-site.xml for this new property. This is useful for users and integrators. I will start applying the patch to our Hadoop distribution tomorrow and hope to test it on the cluster in the next few days. Thanks to both of you for help in getting this committed., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12664225/HDFS-6376.010.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 3 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.server.balancer.TestBalancerWithSaslDataTransfer
                  org.apache.hadoop.security.TestRefreshUserMappings
                  org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover
                  org.apache.hadoop.hdfs.server.datanode.TestBlockPoolManager

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/7755//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/7755//console

This message is automatically generated., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12664219/HDFS-6376.009.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 3 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.web.TestWebHdfsFileSystemContract
                  org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover
                  org.apache.hadoop.hdfs.server.datanode.TestBlockPoolManager

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/7752//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/7752//console

This message is automatically generated., I was going to apply the latest patch to CDH 5.1.0, but I noticed that 5.1.2 has been released. I'll start on that. Curious if the TestBlockPoolManager failure is caused by the new patch., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12664710/HDFS-6376.011.patch
  against trunk revision b03653f.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 3 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.security.TestRefreshUserMappings

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/7858//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/7858//console

This message is automatically generated., [~jingzhao] Manually applied patch 11 to CDH 5.1.2 and deployed to our test cluster. Everything came up fine, which is a really good sign. We will see what it looks like tomorrow., Patch 11 appears to be working fine. I am happy with it. Will this make it into 2.6? , Thanks for testing the patch, [~dlmarion]! Yes, we will commit it into 2.6., I've committed this into trunk and branch-2. Thanks for the contribution, [~dlmarion] and [~wheat9]!, SUCCESS: Integrated in Hadoop-Yarn-trunk #672 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/672/])
HDFS-6376. Distcp data between two HA clusters requires another configuration. Contributed by Dave Marion and Haohui Mai. (jing: rev c6107f566ff01e9bfee9052f86f6e5b21d5e89f3)
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSConfigKeys.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSUtil.java
* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSUtil.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockPoolManager.java
* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestBlockPoolManager.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/GetConf.java
* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestGetConf.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/resources/hdfs-default.xml
, FAILURE: Integrated in Hadoop-Mapreduce-trunk #1888 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1888/])
HDFS-6376. Distcp data between two HA clusters requires another configuration. Contributed by Dave Marion and Haohui Mai. (jing: rev c6107f566ff01e9bfee9052f86f6e5b21d5e89f3)
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSConfigKeys.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSUtil.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/resources/hdfs-default.xml
* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSUtil.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockPoolManager.java
* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestGetConf.java
* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestBlockPoolManager.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/GetConf.java
, SUCCESS: Integrated in Hadoop-Hdfs-trunk #1863 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1863/])
HDFS-6376. Distcp data between two HA clusters requires another configuration. Contributed by Dave Marion and Haohui Mai. (jing: rev c6107f566ff01e9bfee9052f86f6e5b21d5e89f3)
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSUtil.java
* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSUtil.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSConfigKeys.java
* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestBlockPoolManager.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/resources/hdfs-default.xml
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/GetConf.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockPoolManager.java
* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestGetConf.java
, > ... Users can use a new configuration property "dfs.internal.nameservices" to explicitly specify the name services belonging to the local cluster, while continue using the configuration property "dfs.nameservices" to specify all the name services in the local and remote clusters. 

Is this an incompatible change?  Balancer does not work with such setting since it will use all the NN specified in dfs.nameservices.  As a result, it will try to balance both the local and the remote clusters., SUCCESS: Integrated in Hadoop-trunk-Commit #9849 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/9849/])
HDFS-9365. Balaner does not work with the HDFS-6376 HA setup. (szetszwo: rev 15ed080e3610b7526eff12391de780948a75fa7b)
* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/balancer/TestBalancerWithNodeGroup.java
* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSUtil.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/mover/Mover.java
* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/mover/TestMover.java
* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/balancer/TestBalancerWithHANameNodes.java
* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/mover/TestStorageMover.java
* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/balancer/TestBalancerWithMultipleNameNodes.java
* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/balancer/TestBalancer.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSUtil.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/balancer/Balancer.java
]