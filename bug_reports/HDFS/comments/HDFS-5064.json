[A long read lock against FSNamesystem should be avoided. Even on ANN, repeated getContentSummary() calls against big directory trees can degrade the performance significantly. I complained about the fairness setting, but realized that it can get worse without it. 

I think most of writers on SBN are datanodes. If this is true, separating FSN and BlockManager locking will help. Last time I checked, we wanted a facility to enforce lock hierarchy before attempting to do this.

Or we could resort to a SBN-scpecific solution, since it probably only needs to block EditLogTailer and perhaps prevent concurrent checkpointing., bq. I think most of writers on SBN are datanodes. If this is true, separating FSN and BlockManager locking will help. Last time I checked, we wanted a facility to enforce lock hierarchy before attempting to do this.

Yes, this would be great. I took a look into this and concluded that it would be a pretty complex change as it currently stands. I also think that it won't necessarily completely address the issue, since there are several threads which periodically wake up in the NN and try to get the FSNS write lock, and if this occurs while the FSNS read lock is held for a long time, we'll be right back in this situation.

bq. Or we could resort to a SBN-scpecific solution, since it probably only needs to block EditLogTailer and perhaps prevent concurrent checkpointing.

This is what I was thinking. I chatted about this offline with Todd Lipcon, and we came up with the following idea:

* Add new methods {{FSNS#readLock(boolean longRead)}} and {{FSNS#readUnlock(boolean longRead)}}. When these are called, if the argument longRead is true, an AtomicInteger will be incremented or decremented to indicate that the read lock may be held by this thread for a long time.
* We change {{FSNS#writeLock()}} to check if the aforementioned counter is greater than zero, which would indicate that there's a long reader currently holding the lock. In this case, instead of immediately trying to get the write lock, the thread will {{wait(...)}} in a loop until the counter returns to zero.
* We will change the handful of places in the SBN where we know the read lock may be held for a long time to indicate that these are long reads. The edit log tailer and the checkpointing thread are the two places that come to mind, as Kihwal mentioned.
* All other operations will still take the (short) read lock as normal.

This should allow short reads to proceed concurrently with the reads which we have now identified in the code as potentially taking a long time.

What do you think of this proposal, Kihwal?, Here's a patch which attempts to address the issue using roughly what I described above, but instead of using an atomic counter we introduce a new {{ReentrantLock}} in the FSNS to synchronize access between long readers and all writes before those operations even try to take the normal FSNS read/write lock. I then made the {{StandbyCheckpointer}} take the long read lock.

I didn't change the edit log tailer to use this new system since that actually needs to take the FSNS _write_ lock. I think this should be OK since in the common case the edit log tailer shouldn't take very long, whereas writing out a checkpoint can often take several minutes in the common case.

After writing this patch I discovered that I also needed to remove the synchronization from {{FSImage#getMostRecentCheckpointTxId}}, since this is called by the metrics displayed in the {{/jmx}} output, and {{FSImage#saveFSImageInAllDirs}} is synchronized. I think this should be OK since all of the places which mutate this value are themselves synchronized so it shouldn't be possible to see this flop back and forth. In the worst case this will just return an old value. I've left a comment to this effect in the code as well.

Please have a look., {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12613269/HDFS-5064.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/5392//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/5392//console

This message is automatically generated., Hi ATM, I looked at this patch. It needs a small rebase for the lock fairness change, but I was still able to review. I have just one nit: 64-bit reads are not atomic in the current Java memory model, so we need to slap a volatile on {{NNStorage#mostRecentCheckpointId}} since the getter is no longer synchronized.

At a high-level, this makes sense to me as an intermediate solution for the specific issue of the SbNN and checkpointing, until we actually separate out block management from the namespace. Kihwal, do you have any reservations about this approach?

Otherwise, I'm +1 for this change pending rebase and Jenkins., Thanks a lot for the review, Andrew. Here's an updated patch which is rebased on trunk.

bq. I have just one nit: 64-bit reads are not atomic in the current Java memory model, so we need to slap a volatile on NNStorage#mostRecentCheckpointId since the getter is no longer synchronized.

I'm assuming you mean {{NNStorage#mostRecentCheckpointTxId}}? If so, that was already marked volatile by the original patch. Or were you perhaps referring to something else?

Kihwal, do you have any further thoughts on this change?, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12630906/HDFS-5064.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.server.namenode.TestCacheDirectives

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/6229//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/6229//console

This message is automatically generated., I'm confident that the failed test is unrelated. It's been flaky the last few weeks., Restating my +1, going to commit this shortly., Committed to trunk, branch-2, branch-2.4. I had to do a very minor fixup for a test in the trunk patch because the merge of HDFS-5535 changed the signature of saveNamespace., SUCCESS: Integrated in Hadoop-trunk-Commit #5286 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/5286/])
HDFS-5064. Standby checkpoints should not block concurrent readers. Contributed by Aaron Twining Myers. (wang: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1575448)
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystemLock.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NNStorage.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/ha/StandbyCheckpointer.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/util/RwLock.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestStandbyCheckpoints.java
, SUCCESS: Integrated in Hadoop-Yarn-trunk #503 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/503/])
HDFS-5064. Standby checkpoints should not block concurrent readers. Contributed by Aaron Twining Myers. (wang: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1575448)
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystemLock.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NNStorage.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/ha/StandbyCheckpointer.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/util/RwLock.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestStandbyCheckpoints.java
, FAILURE: Integrated in Hadoop-Hdfs-trunk #1695 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1695/])
HDFS-5064. Standby checkpoints should not block concurrent readers. Contributed by Aaron Twining Myers. (wang: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1575448)
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystemLock.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NNStorage.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/ha/StandbyCheckpointer.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/util/RwLock.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestStandbyCheckpoints.java
, SUCCESS: Integrated in Hadoop-Mapreduce-trunk #1720 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1720/])
HDFS-5064. Standby checkpoints should not block concurrent readers. Contributed by Aaron Twining Myers. (wang: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1575448)
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystemLock.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NNStorage.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/ha/StandbyCheckpointer.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/util/RwLock.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestStandbyCheckpoints.java
, Does this effectively emulate an unfair rw lock for the fsn?  Or is there an extra twist?, Hi Daryn,

It's an unfair RW lock with a slight twist. Rather than just having readers and writers, we have short reads, long reads, and writes. During a long read, we let short reads jump ahead of waiting writers and enter the critical section. This lets us get read concurrency during these long read ops when otherwise a single waiting writer would block all readers from entering.]