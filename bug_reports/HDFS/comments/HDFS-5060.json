[This will be a fine feature, as long as it can be turned off for the people who have their own monitoring set up. Users would probably prefer receiving alerts, so they can fix the issue without any service disruption. Short of a standard monitoring and alert system for Hadoop, we could at least display a warning on the web UI, if no checkpointing was done during the last checkpointing period, regardless of its auto saveNameSpace setting., Adding to what Kihwal said, this should be turned off by default. I think disrupting a running service is a big problem with the proposed approach. How often have you seen this issue that warrants a change like this? Why cannot bringing up a secondary/standby be a solution?

The issue that I have seen (quite infrequently though) is, secondary not being able to checkpoint due to editlog corruption. I created HDFS-4923 for this; if an operator forgets to manually save the namespace, during shutdown time the system could save the namespace automatically. This solves several issues mentioned in the jira.
, bq. Adding to what Kihwal said, this should be turned off by default.

I'm not so sure about that. What if it were set to a very high threshold by default, say 50 GB of outstanding edit logs? Your concern seems to be about not forcing operators who keep a close on their system from being affected, but in a properly-functioning, well-monitored system, this threshold should never be hit, and thus having the feature off entirely seems like overkill to me. If you get to the point where you have tens or hundreds of gigabytes of edit logs outstanding, you're likely looking at a multi-hour restart if things go down.

bq. I think disrupting a running service is a big problem with the proposed approach. How often have you seen this issue that warrants a change like this?

Just a handful of times, but when this issue occurs the event is so severe that I think it warrants doing something to address it. We shouldn't let people shoot themselves in the foot.

bq. Why cannot bringing up a secondary/standby be a solution?

Of course that's a solution, and the proper long-term solution to this problem. This is certainly not meant to replace that. The issue is that I've observed several times folks allowing the checkpointing node to be down for an inordinately long time, and even with a monitoring solution in place that's alerting them to this issue, folks don't fully understand the ramifications of stale checkpoints and a large number of outstanding uncheckpointed edits.

bq. The issue that I have seen (quite infrequently though) is, secondary not being able to checkpoint due to editlog corruption. I created HDFS-4923 for this; if an operator forgets to manually save the namespace, during shutdown time the system could save the namespace automatically. This solves several issues mentioned in the jira.

That's a fine idea as well, but obviously won't help in the event that the shutdown isn't clean, so it won't completely alleviate this issue.]