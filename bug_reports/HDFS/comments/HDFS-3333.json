[name node logs:

2012-04-27 10:02:07,453 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* addStoredBlock: blockMap updated: 10.18.52.55:50010 is added to blk_5358037144179192664_118193{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.18.52.55:50010|RBW]]} size 0
2012-04-27 10:02:07,454 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 2 to reach 3
For more information, please enable DEBUG level logging on the org.apache.hadoop.hdfs.server.namenode.FSNamesystem logger.
2012-04-27 10:02:07,454 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/root/lwr/test31.txt. BP-1941047897-10.18.40.154-1335419775245 blk_-5430945475809539701_118194{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.18.52.55:50010|RBW]]}
2012-04-27 10:02:07,466 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* addStoredBlock: blockMap updated: 10.18.52.55:50010 is added to blk_-5430945475809539701_118194{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.18.52.55:50010|RBW]]} size 0
2012-04-27 10:02:07,467 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 2 to reach 3
For more information, please enable DEBUG level logging on the org.apache.hadoop.hdfs.server.namenode.FSNamesystem logger.
2012-04-27 10:02:07,467 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/root/lwr/test31.txt. BP-1941047897-10.18.40.154-1335419775245 blk_7179050910888663641_118195{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.18.52.55:50010|RBW]]}
2012-04-27 10:02:07,479 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* addStoredBlock: blockMap updated: 10.18.52.55:50010 is added to blk_7179050910888663641_118195{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.18.52.55:50010|RBW]]} size 0
2012-04-27 10:02:07,480 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 2 to reach 3
For more information, please enable DEBUG level logging on the org.apache.hadoop.hdfs.server.namenode.FSNamesystem logger.
2012-04-27 10:02:07,480 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/root/lwr/test31.txt. BP-1941047897-10.18.40.154-1335419775245 blk_5515331497909593936_118196{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.18.52.55:50010|RBW]]}
2012-04-27 10:02:07,490 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* addStoredBlock: blockMap updated: 10.18.52.55:50010 is added to blk_5515331497909593936_118196{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.18.52.55:50010|RBW]]} size 0
2012-04-27 10:02:07,491 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 2 to reach 3
For more information, please enable DEBUG level logging on the org.apache.hadoop.hdfs.server.namenode.FSNamesystem logger.
2012-04-27 10:02:07,491 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/root/lwr/test31.txt. BP-1941047897-10.18.40.154-1335419775245 blk_6362697618477922316_118197{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.18.52.55:50010|RBW]]}
2012-04-27 10:02:07,503 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* addStoredBlock: blockMap updated: 10.18.52.55:50010 is added to blk_6362697618477922316_118197{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.18.52.55:50010|RBW]]} size 0
2012-04-27 10:02:07,503 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 2 to reach 3
For more information, please enable DEBUG level logging on the org.apache.hadoop.hdfs.server.namenode.FSNamesystem logger.
2012-04-27 10:02:07,503 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /user/root/lwr/test31.txt. BP-1941047897-10.18.40.154-1335419775245 blk_454857163161775943_118198{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.18.52.55:50010|RBW]]}
2012-04-27 10:02:07,591 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 3 to reach 3
For more information, please enable DEBUG level logging on the org.apache.hadoop.hdfs.server.namenode.FSNamesystem logger.
2012-04-27 10:02:07,595 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:l00110880 (auth:SIMPLE) cause:java.io.IOException: File /user/root/lwr/test31.txt could only be replicated to 0 nodes instead of minReplication (=1).  There are 3 datanode(s) running and 3 node(s) are excluded in this operation.
2012-04-27 10:02:07,596 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 9000, call org.apache.hadoop.hdfs.protocol.ClientProtocol.addBlock from 10.18.47.134:3284: error: java.io.IOException: File /user/root/lwr/test31.txt could only be replicated to 0 nodes instead of minReplication (=1).  There are 3 datanode(s) running and 3 node(s) are excluded in this operation.
java.io.IOException: File /user/root/lwr/test31.txt could only be replicated to 0 nodes instead of minReplication (=1).  There are 3 datanode(s) running and 3 node(s) are excluded in this operation.
        at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget(BlockManager.java:1259)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:1916)
        at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:472)
        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:292)
        at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:42602)
        at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:428)
        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:905)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1688)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1684)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1205)
                                                                                                                                           17405,1       99%
, Hi,

I had a similar problem, but the reason was because port was not opened between the client host and the datanode. since port was not open, the connection was getting timed out and ended up blacklisting each datanode. (i was using amazon ec2 instances where ports are not open by default.), Hi,this issue is diffrent yours,the first,Data is wrriten Nomal, After a while,it throw this exception., I guess that this is not a problem anymore.  Please feel free to reopen this if I am wrong.  Resolving ...]