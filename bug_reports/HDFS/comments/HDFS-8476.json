[[~tongshiquan], thanks for reporting the issue. I tried the scenario with a single node cluster with a 150MB file and slightly smaller quota size 400MB but cannot repro it. 

{code}
$ hdfs dfs -mkdir /HOT
$ hdfs dfs -put hadoop-3.0.0-SNAPSHOT.tar.gz /HOT/FILE1
$ hdfs dfsadmin -setSpaceQuota 400M -storageType DISK /HOT
$ hdfs storagepolicies -setStoragePolicy -path /HOT -policy HOT
Set storage policy HOT on /HOT
$ hdfs dfs -count -q -h -v -t DISK /HOT
   DISK_QUOTA    REM_DISK_QUOTA PATHNAME
        400 M           256.6 M /HOT
$ hdfs dfs -put hadoop-3.0.0-SNAPSHOT.tar.gz /HOT/FILE2
$ hdfs dfs -count -q -h -v -t DISK /HOT
   DISK_QUOTA    REM_DISK_QUOTA PATHNAME
        400 M           113.3 M /HOT
$ hdfs dfs -put hadoop-3.0.0-SNAPSHOT.tar.gz /HOT/FILE3
put: Quota by storage type : DISK on path : /HOT is exceeded. quota = 400 MB but space consumed = 414.71 MB
{code}, Xiaoyu Yao, My cluster have 3 nodes, 2NN and 3DN, HA mode. Each file have 3 replicas, maybe it's one of the reason.

Have add screenshot, removed kanaka kumar avvaru by mistake, assign again, [~tongshiquan], do you still see this problem?  If yes, could post the output of "hadoop version"?, Un-assigning as couldn't make time for this JIRA.]