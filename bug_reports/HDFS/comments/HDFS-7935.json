[Have you tried HADOOP-9789?  For example, you can configure "dfs.namenode.kerberos.principal.pattern" on the client side to make it accept a SPN that is different from the connecting namenode address., [~kihwal], Yup looks like that would work. I guess then.. that the only thing remaining is a minor fix for https://issues.apache.org/jira/browse/HDFS-4448 which would allow one to deploy NN in HA with security in a multi-homed env., Secure HA NN does come up with dfs.namenode.http-address.<logical_name>.<nn_id> set to 0.0.0.0:port. The clients should of course have a vaild address. The kerberos principal used by the two name nodes comes from dfs.web.authentication.kerberos.principal, but SPNEGO will work with any SPN found in its keytab after HADOOP-10322.  So I guess HDFS-4448 is fixed?, Im running Hadoop 2.6.0, I still get this when trying to start NN in HA though

{noformat}
2015-03-14 20:34:35,197 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: Error encountered requiring NN shutdown. Shutting down immediately.
java.io.IOException: Cannot use a wildcard address with security. Must explicitly set bind address for Kerberos
	at org.apache.hadoop.hdfs.DFSUtil.substituteForWildcardAddress(DFSUtil.java:1177)
	at org.apache.hadoop.hdfs.DFSUtil.getInfoServerWithDefaultHost(DFSUtil.java:1138)
	at org.apache.hadoop.hdfs.server.namenode.ha.StandbyCheckpointer.getHttpAddress(StandbyCheckpointer.java:116)
	at org.apache.hadoop.hdfs.server.namenode.ha.StandbyCheckpointer.setNameNodeAddresses(StandbyCheckpointer.java:100)
	at org.apache.hadoop.hdfs.server.namenode.ha.StandbyCheckpointer.<init>(StandbyCheckpointer.java:90)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startStandbyServices(FSNamesystem.java:1353)
	at org.apache.hadoop.hdfs.server.namenode.NameNode$NameNodeHAContext.startStandbyServices(NameNode.java:1728)
	at org.apache.hadoop.hdfs.server.namenode.ha.StandbyState.enterState(StandbyState.java:58)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:812)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:792)
{noformat}

And I have the following properties in *hdfs-site.xml*

{noformat}
 <property>
    <name>dfs.namenode.servicerpc-address.nameservice1.namenode14</name>
    <value>0.0.0.0:8022</value>
  </property>
 <property>
    <name>dfs.namenode.http-address.nameservice1.namenode14</name>
    <value>0.0.0.0:20101</value>
  </property>
  <property>
    <name>dfs.namenode.https-address.nameservice1.namenode14</name>
    <value>0.0.0.0:20102</value>
  </property>
{noformat}

So looks like , Hit enter by mistake... 

Continuing..
So looks like we still need the HDFS-4448 fix (I guess it needs a minor rebasing though..), We have been running like this for quite some time. Most clusters are running 2.6. I will see what's causing this., [~kihwal], were you able to verify this ? in anycase, I was thinking HDFS-4448 be committed, considering that all it does is remove a now invalid check]