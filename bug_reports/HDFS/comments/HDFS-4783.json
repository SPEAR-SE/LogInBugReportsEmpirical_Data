[This patch fixes the problem by reconstructing the addresses used for testing and forcing the host name to "localhost", so no host name resolution by the OS is required.

The test previously failed in the second for loop after the call to SecurityUtilTestHelper.setTokenServiceUseIp(false).  I verified that the test passes on Mac and Windows with this patch., This patch can go to both trunk and branch-2.  There are no dependencies on other Windows-specific code that only resides in trunk., {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12581275/HDFS-4783.1.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/4348//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/4348//console

This message is automatically generated., Might want to test if {{NetUtils.addStaticResolution("127.0.0.1", "localhost")}} will resolve this recurring issue., I tried static resolution, but unfortunately, it didn't work.  Eventually, we get to a point inside the RPC {{Server#Listener}} constructor where we pass through a {{ServerSocketChannel}}.  This seems to always drop the host name from the address and re-resolve, so on Windows, this drops "localhost" in favor of "127.0.0.1".

{code}
    public Listener() throws IOException {
      address = new InetSocketAddress(bindAddress, port);
      // Create a new server socket and set to non blocking mode
      acceptChannel = ServerSocketChannel.open();
      acceptChannel.configureBlocking(false);

      // Bind the server socket to the local host and port
      bind(acceptChannel.socket(), address, backlogLength, conf, portRangeConfig);
{code}

In the above code, even if {{bindAddress}} is "localhost" (thanks to static resolution), the end result is still an address with host name "127.0.0.1".

Here is a very simplified version of what happens inside the bind method:

{code}
    InetSocketAddress localhost = new InetSocketAddress("localhost", 12345);
    System.out.println("localhost = " + localhost + ", w/hostname = " + localhost.getHostName());
    ServerSocketChannel ssc = ServerSocketChannel.open();
    ssc.socket().bind(localhost);
    InetSocketAddress addr = (InetSocketAddress)ssc.socket().getLocalSocketAddress();
    System.out.println("addr = " + addr + ", w/hostname = " + addr.getHostName());
{code}

Running this code on non-Windows prints:
{code}
localhost = localhost/127.0.0.1:12345, w/hostname = localhost
addr = /127.0.0.1:12345, w/hostname = localhost
{code}

And on Windows:
{code}
localhost = localhost/127.0.0.1:12345, w/hostname = localhost
addr = /127.0.0.1:12345, w/hostname = 127.0.0.1
{code}
, +1

I think changing the test case to use "localhost" is acceptable here.
I checked {{HAUtil.cloneDelegationTokenForLogicalUri()}} usage in ConfiguredFailoverProxyProvider.
The hostname passed in was from a configuration, i.e. dfs.namenode.rpc-address; so we don't have the issue that the host was get from {{getNameNodeAddress()}}.
If there are similar problems elsewhere, they should be separate problems, and we don't need to address the host name difference here in this JIRA.
The above analysis is really useful and should help us understanding future problems if there is any., Sigh, this is technically masking an underlying bug of a double fwd/rev resolve which can return a different hostname and foul the use of CNAMES.  Fixing it is probably more complex than it seems, so +0.5., Daryn, is there an issue for that underlying bug, or should we file a new one?

I'm planning on committing this, but I'll wait until end of day in case there are any other objections.
, Integrated in Hadoop-trunk-Commit #3922 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/3922/])
    HDFS-4783. TestDelegationTokensWithHA#testHAUtilClonesDelegationTokens fails on Windows. Contributed by Chris Nauroth. (Revision 1493149)

     Result = SUCCESS
cnauroth : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1493149
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestDelegationTokensWithHA.java
, I committed this to trunk, branch-2, and branch-2.1-beta.  Thanks to Chuan and Daryn for reviews.

[~daryn], let me take a stab at describing the underlying issue that you mentioned:

# {{NameNode#initialize}} starts initializing namenode from given {{Configuration}}.
# {{NameNodeRpcServer}} constructor builds RPC server, binding to address specified in {{Configuration}}.  Resulting address may differ from what is in {{Configuration}} if using any address (0.0.0.0) or ephemeral port.
# {{NameNodeRpcServer}} then sets value of address back in {{Configuration}} to the real resulting address.  By side effect, the forward lookup and then reverse lookup may result in an unexpected hostname in {{Configuration}}, if there are multiple names for the host (i.e. CNAME records).

Does this accurately describe what you had in mind?  If so, let me know, and I'll paste it into a new issue.

I'm not yet sure what we could do about it, but it might help to start tracking it.  I recently saw this behavior cause some confusion for a deployment that was resolving the NN to an unexpected address., Integrated in Hadoop-Yarn-trunk #241 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/241/])
    HDFS-4783. TestDelegationTokensWithHA#testHAUtilClonesDelegationTokens fails on Windows. Contributed by Chris Nauroth. (Revision 1493149)

     Result = SUCCESS
cnauroth : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1493149
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestDelegationTokensWithHA.java
, Integrated in Hadoop-Hdfs-trunk #1431 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1431/])
    HDFS-4783. TestDelegationTokensWithHA#testHAUtilClonesDelegationTokens fails on Windows. Contributed by Chris Nauroth. (Revision 1493149)

     Result = FAILURE
cnauroth : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1493149
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestDelegationTokensWithHA.java
, Integrated in Hadoop-Mapreduce-trunk #1458 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1458/])
    HDFS-4783. TestDelegationTokensWithHA#testHAUtilClonesDelegationTokens fails on Windows. Contributed by Chris Nauroth. (Revision 1493149)

     Result = FAILURE
cnauroth : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1493149
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestDelegationTokensWithHA.java
]