[Both {{FileContext.getLinkTarget()}} and {{ClientProtocol.getLinkTarget()}} claim it should throw "IOException - If the given path does not refer to a symlink". Not returning null as in your patch.
Why don't we start committing obvious bugs rather than merging them into big jira., Hi Konstantin,

Sure, let's just get this one fixed. Probably shouldn't have lumped it in as a subtask, sorry. Feel free to move it out to HDFS if you like.

As a bit of background, {{ClientProtocol#getLinkTarget}} is only called during symlink resolution. It's unfortunate that there's a method with the same name in {{FileContext}}. I also agree this isn't the right fix, I saw the {{return null}} at the end of the method and assumed it was handled, but in fact it should never hit that.

I think {{NameNodeRpcServer#getLinkTarget}} confused {{HdfsFileStatus}} with {{FileStatus}}, which has a {{#getSymlink}} method which does actually throw an IOException. I think the right fix here though is having {{NameNodeRpcServer#getLinkTarget}} do the {{isSymlink()}} check then throw an {{IOException}} itself. This is essentially what other usages of this method do.

Patch attached that tries to clean this up., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12574606/hadoop-9415-2.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2345//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2345//console

This message is automatically generated., I think it is the right thing to throw FileNotFoundException if the link path does not exist. You are changing the semantics of {{nn.getLinkTarget()}} to never return null, but nobody seems relied on it.
A small thing. The preferred format for {{FileNotFoundException}} is
{code}
new FileNotFoundException("File does not exist: " + f)
{code}
With the path in the end rather than in the middle. People didn't follow this convention lately, let's keep it with your change., Forgot to mention it makes sense to convert this jira to HDFS one., Thanks Konst, I changed the exception text.

I think subtasks unfortunately can't be moved into a new project. If you'd rather have this as an HDFS jira, feel free to create a new one and dupe this one, and we can repost the patch., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12574868/hadoop-9415-3.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.server.blockmanagement.TestBlocksWithNotEnoughRacks
                  org.apache.hadoop.hdfs.server.balancer.TestBalancerWithNodeGroup

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2350//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2350//console

This message is automatically generated., +1 if test failures are not related.

> I think subtasks unfortunately can't be moved into a new project.

You should be able to first "Convert to Issue", then "Move"., Great, was unaware of the JIRA-fu.

I believe the test failures are unrelated, considering that we had a clean test run before, and that those tests are known to be flaky. Thanks again for the reviews., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12574868/hadoop-9415-3.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/4134//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/4134//console

This message is automatically generated., Rebased on trunk. Hoping I can squeeze a commit from [~cmccabe] or [~shv] :), pressed the wrong key -- apparently jira has keyboard shortcuts now, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12587502/hdfs-4626-1.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/4510//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/4510//console

This message is automatically generated., This seems like something we should be able to unit test easily.  If nothing else, why not create a DFSClient and verify that getLinkTarget on a non-existent path throws an exception?, Thanks for the review, Colin. Attaching new patch with unit tests for both of the exception cases., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12587911/hdfs-4626-2.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.server.balancer.TestBalancerWithNodeGroup

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/4522//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/4522//console

This message is automatically generated., Balancer tests have historically been flaky, and I believe the failure is unrelated to this patch., Looks good to me.  +1., Integrated in Hadoop-trunk-Commit #3959 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/3959/])
    HDFS-4626. ClientProtocol#getLinkTarget should throw an exception for non-symlink and non-existent paths.  (Andrew Wang via cmccabe) (Revision 1493980)

     Result = SUCCESS
cmccabe : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1493980
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNodeRpcServer.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestResolveHdfsSymlink.java
, Integrated in Hadoop-Yarn-trunk #244 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/244/])
    HDFS-4626. ClientProtocol#getLinkTarget should throw an exception for non-symlink and non-existent paths.  (Andrew Wang via cmccabe) (Revision 1493980)

     Result = SUCCESS
cmccabe : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1493980
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNodeRpcServer.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestResolveHdfsSymlink.java
, Integrated in Hadoop-Hdfs-trunk #1434 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1434/])
    HDFS-4626. ClientProtocol#getLinkTarget should throw an exception for non-symlink and non-existent paths.  (Andrew Wang via cmccabe) (Revision 1493980)

     Result = FAILURE
cmccabe : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1493980
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNodeRpcServer.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestResolveHdfsSymlink.java
, Integrated in Hadoop-Mapreduce-trunk #1461 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1461/])
    HDFS-4626. ClientProtocol#getLinkTarget should throw an exception for non-symlink and non-existent paths.  (Andrew Wang via cmccabe) (Revision 1493980)

     Result = SUCCESS
cmccabe : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1493980
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNodeRpcServer.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestResolveHdfsSymlink.java
, Resolving since it's been committed to trunk and branch-2. Thanks for the reviews, Colin and Konst.]