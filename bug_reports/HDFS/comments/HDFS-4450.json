[This is working as expected. The two instances of datanodes are different. On restart of the namenode the previous instance of datanode will no longer be tracked/show on web UI by the namenode., I view the other versions of the code will not have this problem, In addition practical use impossible to restart namenode when maintenance datanode。, Now the code, the removal of the a redundant node's code is there, but it will never be called to.
{code}
    DatanodeDescriptor nodeN = getDatanodeByHost(nodeReg.getXferAddr());
      //nodeN is always null.
    if (nodeN != null && nodeN != nodeS) {
      NameNode.LOG.info("BLOCK* NameSystem.registerDatanode: "
                        + "node from name: " + nodeN);
      // nodeN previously served a different data storage, 
      // which is not served by anybody anymore.
      removeDatanode(nodeN);
      // physically remove node from datanodeMap
      wipeDatanode(nodeN);
      nodeN = null;
    }
{code}, bq. I view the other versions of the code will not have this problem, In addition practical use impossible to restart namenode when maintenance datanode

You are right about the behavior. I had forgotten the previous discussion related to this from the comment I had posted:
https://issues.apache.org/jira/browse/HDFS-3224?focusedCommentId=13472817&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13472817

Looking at the description of this jira, the Host2NodesMap always has {{key = ipAddress}} and {{value = DatanodeDescriptor}}. So add() method is doing the correct thing. If you look at {{host2DatanodeMap.getDatanodeByXferAddr()}}, it does look up the host by the ipAddress. It then compares the xferAddress to that of the transfer address of the DatanodeDescriptor stored as value.

Can you post the logs for this issue?
, Looks like this issue HDFS-3224 is the same problem.Patch HDFS-3224.PATH still does not solve the Host2NodesMap.getDatanodeByHost (String ipAddr) and Host2NodesMap.add() inconsistent.This seems to be a hidden danger., bq. PATH still does not solve the Host2NodesMap.getDatanodeByHost (String ipAddr) and Host2NodesMap.add() inconsistent.This seems to be a hidden danger.
I do not quite follow. Where getDatanodeByHost() is used, it might be okay for the purpose it is used.

It would be good if you can you respond back to my previous comments? For convenience here they are:

The description of this jira might not be pointing to an issue. Methods add() and getDatanodeByXferAddr() are doing the correct thing. See for details my above comment.

What is the branch corresponding to the comment https://issues.apache.org/jira/browse/HDFS-4450?focusedCommentId=13566050&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13566050

Are you seeing duplicate datanode issue? If so, please post the logs. Per HDFS-3224, as long as the ipaddr + xfer port remains the same, even if the storage ID changes, duplicate datanode entry should not occur., {quote}
Are you seeing duplicate datanode issue? If so, please post the logs. Per HDFS-3224, as long as the ipaddr + xfer port remains the same, even if the storage ID changes, duplicate datanode entry should not occur.
{quote}

1.I deploy a test cluster，have 2 namenodes(active/standby), 3 datanodes.
  Under normal circumstances datanodes such as normal.bmp

2.Fomart datanode dn0 and restart it. hdfs web UI such as exception.bmp.  

3.Namenode not found opteration for remove old datanode. 
2013-02-01 10:11:10,522 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.registerDatanode: node registration from DatanodeRegistration(10.28.176.234, storageID=DS-685519412-10.28.176.234-50010-1359684666375, infoPort=50075, ipcPort=50020, storageInfo=lv=-40;cid=CID-fe3b5079-a34a-4912-b8a8-50443d038749;nsid=1321646662;c=0) storage DS-685519412-10.28.176.234-50010-1359684666375
2013-02-01 10:11:10,555 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.28.176.234:50010 after becoming active. Its block contents are no longer considered stale.
2013-02-01 10:11:10,555 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* processReport: from DatanodeRegistration(10.28.176.234, storageID=DS-685519412-10.28.176.234-50010-1359684666375, infoPort=50075, ipcPort=50020, storageInfo=lv=-40;cid=CID-fe3b5079-a34a-4912-b8a8-50443d038749;nsid=1321646662;c=0), blocks: 0, processing time: 0 msecs
, Thank you for more details. Can you post the lines from the logs that corresponds to datanode dn0 registration corresponding to before format and after format?, {quote}
Thank you for more details. Can you post the lines from the logs that corresponds to datanode dn0 registration corresponding to before format and after format?
{quote}

1.shutdown dataonode dn0
2013-02-01 10:56:49,667 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG:
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at dn0/10.28.176.234
************************************************************/

2.remove data files of datanode.

3.restart datganode

2013-02-01 10:59:46,123 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /home/data/geminifs_datanode/current
2013-02-01 10:59:46,131 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2013-02-01 10:59:46,135 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1359687909135 with interval 21600000
2013-02-01 10:59:46,137 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1769818311-192.168.0.2-1359357823687
2013-02-01 10:59:46,144 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1769818311-192.168.0.2-1359357823687 (storage id DS-685519412-10.28.176.234-50010-1359684666375) service to nnmaster/192.168.0.1:9000 beginning handshake with NN
2013-02-01 10:59:46,151 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1769818311-192.168.0.2-1359357823687 (storage id DS-685519412-10.28.176.234-50010-1359684666375) service to nnmaster/192.168.0.1:9000 successfully registered with NN
2013-02-01 10:59:46,151 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode nnmaster/192.168.0.1:9000 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec Initial delay: 0msec; heartBeatInterval=3000
2013-02-01 10:59:46,176 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-1769818311-192.168.0.2-1359357823687 (storage id DS-685519412-10.28.176.234-50010-1359684666375) service to nnmaster/192.168.0.1:9000 trying to claim ACTIVE state with txid=3142
2013-02-01 10:59:46,176 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-1769818311-192.168.0.2-1359357823687 (storage id DS-685519412-10.28.176.234-50010-1359684666375) service to nnmaster/192.168.0.1:9000, bq. Can you post the lines from the logs that corresponds to datanode dn0 registration corresponding to before format and after format?

I should have been more clear. What I asked for is, from the namenode logs, please get the two registration requests from dn0, one before you shut it down and one after you restart. The log lines should look like:

{noformat}
2013-02-01 10:11:10,522 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.registerDatanode: node registration from DatanodeRegistration(10.28.176.234, storageID=DS-685519412-10.28.176.234-50010-1359684666375, infoPort=50075, ipcPort=50020, storageInfo=lv=-40;cid=CID-fe3b5079-a34a-4912-b8a8-50443d038749;nsid=1321646662;c=0) storage DS-685519412-10.28.176.234-50010-1359684666375
{noformat}
, Also please provide from your configuration, what you have set to the parameter "dfs.datanode.address" to?s, WenJin, any updates on this. Can you provide the information I asked for?, {quote}
Also please provide from your configuration, what you have set to the parameter "dfs.datanode.address" to?s
{quote}

I do not have to configure it.

, I have verified as mentioned 
1. HA cluster with 3 Datanodes
2. Remove the data directories of one datanode and restart datanode.
3. After restart, NameNode was displaying only one datanode for that host.

I didn't find any duplicate datanodes.
]