[Is this still a problem?, Thanks a lot, Nicholas for reminding me. I will check this., Yes, Nicholas. I looked at the code. This should be fixed., We need to remove blocks after logSync., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12663663/HDFS-2975.001.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/7726//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/7726//console

This message is automatically generated., Thanks a lot for working on this JIRA, Yi!
Following code just remove the blocks from blockManager.
{code}
 if (!collectedBlocks.getToDeleteList().isEmpty()) {
+      removeBlocks(collectedBlocks);
+      collectedBlocks.clear();
+    }
{code}

This triggered me a question that, original removePathAndBlocks actually deleting blocks from blocks manager and additionally adjusting safeblock counts as well. But now, where we update that? I think case may apply for current delete as well If I am right here.
Is yes, then getting the BLOCK_DELETION_INCREMENT related logic to removeBlocksAndUpdateSafemodeTotal should help in addressing this case. I will check little more on this tomorrow.
, Thanks [~umamaheswararao] for the review. You are right, but in delete, it also only uses
{code}
removeBlocks(collectedBlocks); // Incremental deletion of blocks
collectedBlocks.clear();
{code}
So I keep it same. OK. let's use {{removeBlocksAndUpdateSafemodeTotal}} instead., Feel free to file different bug for delete API on validating the issue there.

Original code what we fixed in delete is:
 {code}
 deleteNow = collectedBlocks.size() <= BLOCK_DELETION_INCREMENT;
-      if (deleteNow) { // Perform small deletes right away
-        removeBlocks(collectedBlocks);
-      }
     } finally {
       writeUnlock();
     }
@@ -1990,9 +1985,7 @@
 
     writeLock();
     try {
-      if (!deleteNow) {
-        removeBlocks(collectedBlocks); // Incremental deletion of blocks
-      }
+      removeBlocks(collectedBlocks); // Incremental deletion of blocks
{code}

But now, other APIs using removeBlocksAndUpdateSafeBlock on delete via rename with overwrite or so.
Lets validate carefully whether this change really not needed for delete or it is a introduce bug by other changes later.
Feel free to file separate Bug.
, Thanks Uma for review and comment. Your consideration is reasonable.
After think more, we need to track blocks incrementally if HA enabled and in safe-mode. 
* While loading the editlog, for delete (or rename with overwrite) Op, we need to track blocks incrementally and can call {{removeBlocksAndUpdateSafemodeTotal}}.
* While HDFS client calls delete (or rename with overwrite) Op, NN is not in safe-mode, and we don't need to track blocks incrementally.  We can do incremental deletion of blocks directly.

So current delete is correct. And for rename with overwrite, we have called {{removeBlocksAndUpdateSafemodeTotal}} which loading editlog. 
So the behavior in the patch is exact what we expect. , Yi,  Thanks a lot for the explanation.
+1 on the patch. [~vinayrpet], Do you have any comments?, Thanks a lot for the patch [~hitliuyi],
+1 from me too., Thanks [~umamaheswararao] and [~vinayrpet] for the review., Yi, seems like a conflict with recent commits. Do you mind rebasing it., Sure, rebase and make a git patch, I have just committed this to trunk and branch-2. Thanks a lot for the patch Yi.
Also thanks a lot, Vinay for the review!, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12666224/HDFS-2975.002.patch
  against trunk revision 08a9ac7.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/7882//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/7882//console

This message is automatically generated., FAILURE: Integrated in Hadoop-Yarn-trunk #670 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/670/])
HDFS-2975. Rename with overwrite flag true can make NameNode to stuck in safemode on NN (crash + restart). (Yi Liu via umamahesh) (umamahesh: rev 3425ae5d7eaa27b2526d0e0c07bdfea9440359f8)
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java
* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSRename.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java
* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
, FAILURE: Integrated in Hadoop-Hdfs-trunk #1861 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1861/])
HDFS-2975. Rename with overwrite flag true can make NameNode to stuck in safemode on NN (crash + restart). (Yi Liu via umamahesh) (umamahesh: rev 3425ae5d7eaa27b2526d0e0c07bdfea9440359f8)
* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSRename.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java
* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
, FAILURE: Integrated in Hadoop-Mapreduce-trunk #1886 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1886/])
HDFS-2975. Rename with overwrite flag true can make NameNode to stuck in safemode on NN (crash + restart). (Yi Liu via umamahesh) (umamahesh: rev 3425ae5d7eaa27b2526d0e0c07bdfea9440359f8)
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java
* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSRename.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java
]