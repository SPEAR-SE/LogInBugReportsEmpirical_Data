[If Infosecport is 0 , then fall back to InfoPort. , Branch-2 / trunk has moved to a new HTML5-based web UI by default. I believe that this problem no longer exists in the new Web UI. See HDFS-5333 for more details., Thanks for the info. But if there will be cases when old UI has to be used -  when webhdfs is not enabled or when the JS support is limited. 
So I believe , this issue should be fixed.

, Can you be more specific about your use cases? When JS support is limited, you can use dfsadmin -report, or use a third-party tool available at https://github.com/haohui/dfshealth-cli to get the information.

Speaking of the patch, I'm yet to be convinced this is the right direction to go. First it seems that the particular use case you reported is no longer valid anymore, since hadoop.ssl.enabled has been deprecated. Second, falling back to the InfoPort is problematic -- you can't tell whether the datanode is speaking http or https. We used to put if statements in the code to choose whether InfoPort() or InfoSecurePort() will be used, but it becomes so error-prone that we eventually move to the HTML5 web UI to fully address this problem., FYI, see HDFS-5305 for the discussion on HTTPS support for HDFS., We are on Hadoop 2.2  which has the patch HDFS-5306  which introduces infosecure port.  
We enable HTTPS for all the external facing urls using hadoop.ssl.enabled instead of specifying ports for each server.

All this patch does is to maintain backward compatibility so that the addition of infosecureport does not break a feature which was working before.

, The bug no longer exists after 2.2.

bq. All this patch does is to maintain backward compatibility so that the addition of infosecureport does not break a feature which was working before.

Based on my understanding enabling hadoop.ssl.enabled is broken in 2.2 in a number of ways (see https://issues.apache.org/jira/browse/HADOOP-8581?focusedCommentId=13784332&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13784332 for details). HDFS-5305 and related jiras tracks the effort of fixing this in HDFS. For example, HDFS-5536 and HDFS-5629 allow you to configure dfs.http.policy to enable HTTP or HTTPS servers independently.

I would recommend that you use dfs.https.enable instead of hadoop.ssl.enabled in 2.2, and move towards dfs.http.policy in newer versions., I will try using  dfs.https.enable to see if there is way out. 

Could you please look at HDFS-5661 ? That is applicable with dfs.https.enable also ., I can get HDFS SSL work using  dfs.https.enable  and 3 additional configs ( NN port , DN port and keystore config.) 
With this scheme, two ports on NN and each data node will be opened. These additional ports will not be used in our case. 
I am doing all these steps just so that infosecurePort is set to 1006  which is essentially what this patch does. 

, This is the expected behavior. Again, the bug no longer exists in 2.2. I suggest closing this bug as invalid., The bug exists in 2.2 .
The bug was introduced by HDFS-5307  which changed the redirectPort  to infosecurePort  when HTTPS is enabled.
But infoSecurePort is valid  only when dfs.https.enable  is true . if you set  only hadoop.ssl.enabled to true, infoSecurePort  is 0.
If you are in 2,.2, you need this patch to make things work as it used to work. 
I believe , the bug doesn't exist in trunk by looking at the code., Sorry, what I meant was the bug had no longer existed after 2.2.

bq. If you are in 2,.2, you need this patch to make things work as it used to work.

hadoop.ssl.enabled is introduced in the 2.2 and it is considered broken at the very first day. It will be removed in the next subsequent release so this is a clearly wontfix to me. 

Popping up one level, even if this bug should be fixed, I don't think it will fit in anywhere. Obviously it won't go into trunk / branch-2, I don't think it'll be picked up by branch-2.3 either, as it intends to contain only critical fixes for 2.2., Resolving this issue as Won't Fix since the bug is not applicable  on trunk]