[{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12666906/HDFS-6948.201409052147.txt
  against trunk revision 21c0cde.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/7921//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/7921//console

This message is automatically generated., We may not need this change in {{createRbw()}}, which is for new block creation. We see this kind of conflict after block creation. A copy is attempted as part of pipeline recovery, replication after closing or balancing. So there shouldn't be any conflict during initial creation of a block.  I think we only need to clean-up in {{createTemporary()}}.

What happens if the thread writing using older gen stamp is still running? We can kill the thread as it is done in {{recoverRbw()}}., [~kihwal], thank you very much for reviewing this patch.

bq. We may not need this change in {{createRbw()}}
I have removed the check for older GS from {{createRbw}} and removed the related unit tests for this method.

bq. What happens if the thread writing using older gen stamp is still running? We can kill the thread as it is done in {{recoverRbw()}}.
I have added the {{stopWriter()}} call in {{createTemporary()}} when GS for block is newer than GS for temporary replica.

The failed test case for {{TestPipelinesFailover#testPipelineRecoveryStress}} works for me in my environment. I think it is related to HDFS-6694., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12667226/HDFS-6948.201409081817.txt
  against trunk revision 6a84f88.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/7953//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/7953//console

This message is automatically generated., I think you should use instanceof to verify it's a {{ReplicaInPipeline}} before casting it and stopping it., Thanks [~daryn] and [~kihwal]. 

bq. use instanceof to verify it's a {{ReplicaInPipeline}}

I have updated the patch with this change., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12667796/HDFS-6948.201409101802.txt
  against trunk revision b67d5ba.

    {color:red}-1 patch{color}.  Trunk compilation may be broken.

Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/7986//console

This message is automatically generated., Something went wrong. Started the precommit build again., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12667796/HDFS-6948.201409101802.txt
  against trunk revision 3122daa.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.web.TestWebHdfsFileSystemContract
                  org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover
                  org.apache.hadoop.hdfs.server.namenode.TestNameEditsConfigs

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/8008//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/8008//console

This message is automatically generated., +1 the latest patch looks good., I've committed this to trunk and cherry-picked to branch-2. Thanks for working on the fix, Eric., SUCCESS: Integrated in Hadoop-Yarn-trunk #686 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/686/])
HDFS-6948. DN rejects blocks if it has older UC block. Contributed by (kihwal: rev f02d934fedf00f0ce43d6f3f9b06d89ccc6851a5)
* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java
* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/TestWriteToReplica.java
, FAILURE: Integrated in Hadoop-Hdfs-trunk #1877 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1877/])
HDFS-6948. DN rejects blocks if it has older UC block. Contributed by (kihwal: rev f02d934fedf00f0ce43d6f3f9b06d89ccc6851a5)
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java
* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/TestWriteToReplica.java
, FAILURE: Integrated in Hadoop-Mapreduce-trunk #1902 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1902/])
HDFS-6948. DN rejects blocks if it has older UC block. Contributed by (kihwal: rev f02d934fedf00f0ce43d6f3f9b06d89ccc6851a5)
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java
* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/TestWriteToReplica.java
* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
]