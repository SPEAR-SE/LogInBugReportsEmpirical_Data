[Attached the patch to fix it by 3 (flushing an empty buffer periodically). I'll test the patch in my environment., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12672284/HDFS-7175.patch
  against trunk revision 17d1202.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:red}-1 findbugs{color}.  The patch appears to introduce 1 new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.TestEncryptionZonesWithKMS
                  org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover
                  org.apache.hadoop.hdfs.TestRollingUpgradeRollback

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/8288//testReport/
Findbugs warnings: https://builds.apache.org/job/PreCommit-HDFS-Build/8288//artifact/patchprocess/newPatchFindbugsWarningshadoop-hdfs.html
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/8288//console

This message is automatically generated., Patch looks good to me.

Can you please address the test case failure?
, These tests look unrelated to the patch. Several jiras track these failures.
* TestEncryptionZonesWithKMS: BUILDS-17 (failed by "Too many open files")
* TestPipelinesFailover: HDFS-6694
* TestRollingUpgradeRollback: no jira, Attaching the same patch to confirm TestRollingUpgradeRollback passes., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12672484/HDFS-7175.patch
  against trunk revision 9e40de6.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:red}-1 javac{color:red}.  The patch appears to cause the build to fail.

Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/8294//console

This message is automatically generated., Doing this every 100 is way too frequent.  Every write to that socket blocks the fsck.  For a large enough HDFS where this is a problem, that's easily 200k+ pauses!, bq. Doing this every 100 is way too frequent.
I agree that doing this every 100 causes slowdown. Updated the patch to do this every 10K. [~aw], every 10K is good for you?
Since fsck should not fail by SocketTimeoutException in any environment and the timeout is not configurable (hard-coded to 60 sec), I'm thinking every 100K~ is not a good idea., bq. I'll test the patch in my environment.
I've tested on my VM and confirmed flushing an empty buffer prevents SocketTimeoutException., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12672511/HDFS-7175.2.patch
  against trunk revision 9e40de6.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:red}-1 javac{color:red}.  The patch appears to cause the build to fail.

Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/8297//console

This message is automatically generated., I would go back to pre- HDFS-2538 behavior (i.e. flush every 100 files)., Thanks [~mcvsubbu] for comment. [~aw], I'm thinking there are two options:
# apply v1 patch (i.e. flush every 100 files) and file a separate jira to change the frequency for flush.
# discuss what frequency is the best and create a patch

Since this issue is to fix SocketTimeoutException, the first option makes sense to me., As a feature request, I am wondering if it's possible to make this a configurable option for the OPS folks (either based on the elapsed time since the last flush OR number of files)?, bq. I would go back to pre- HDFS-2538 behavior (i.e. flush every 100 files).

Any particular reason as to why?

In any case, I think this could be handled in such a way that:

if (showprogress) {
  every 100 print a period and flush
} else {
 every 10k flush
}

... which accomplishes both goals.  I get the impression that [~ajisakaa] is trying to reduce code duplication, but I'm not that concerned about it given the size of the code here. :)

bq. As a feature request, I am wondering if it's possible to make this a configurable option for the OPS folks (either based on the elapsed time since the last flush OR number of files)?

We'd still have to have reasonable defaults. Also, elapsed time since the last flush adds a whole new level of complexity.  , Below changes could serve the purpose mentioned by [~aw], with one line duplication ;)
{code}--- hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NamenodeFsck.java
+++ hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NamenodeFsck.java
@@ -376,6 +376,9 @@ void check(String parent, HdfsFileStatus file, Result res) throws IOException {
     if ((showprogress) && res.totalFiles % 100 == 0) {
       out.println();
       out.flush();
+    } else if (res.totalFiles % 10000 == 0) {
+      // flush the buffer periodically to prevent SocketTimeoutException
+      out.flush();
     }
     int missing = 0;
     int corrupt = 0;{code} , Thanks [~aw] and [~vinayrpet] for comments.
Attaching a patch as Vinayakumar B suggested., bq. elapsed time since the last flush adds a whole new level of complexity.
I agree. In addition, calculating elapsed time seems costly., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12673576/HDFS-7175.3.patch
  against trunk revision 1efd9c9.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication
                  org.apache.hadoop.hdfs.server.balancer.TestBalancer

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/8350//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/8350//console

This message is automatically generated., It'd be good to hear from LinkedIn to see if the current patch fixes the issue for them. 

I'm +1 on the current patch and will commit after some confirmation., I understand the complexity of adding the "time based" flush(), but could we at least considering making "number of files" a configurable option (with a reasonable default value of course)  as a feature..., bq.  could we at least considering making "number of files" a configurable option (with a reasonable default value of course) as a feature...

Probably better to handle that as a separate JIRA given that there will likely be lots of discussion around options, etc.  Plus that is a feature request whereas the current code here is all bug fix., The number 10000 does not work in our large cluster. (Sorry for the delay in verification, the problem is reproduced only in our large clusters, and we need to co-ordinate to schedule some time to test this). We will try with 1000 or 100 and see if they work., Let me clarify that we see the same timeout issue by flushing every 10k files. , I apologize for the delay in verification of this bug.

I have now verified that no matter what the value is for frequency of flush, the solution does NOT work. Basically, the flush() call has no effect since there are no bytes to flush.

Here is what I did to verify this:
* Brought up a single node cluster.
* I changed the frequency of flush to 1 (instead of 10k or 100k).
* Ran fsck on a small directory with 10 files, both with and without -showprogress option.
* Ran tcpdump on the namenode port to capture packets during the session.

I could see that the dots were sent out in in the channel when -showprogress was specified, but the channel was quiet when it was not.

So, we need to think of another way to solve the problem., One way to fix this may be to put out the "." on the server even if -showprogress is not specified, and then filter it out in the client (if the option is not specified). Seems like a hacky solution, though., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12673576/HDFS-7175.3.patch
  against trunk revision 0a05ae1.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.server.datanode.TestBlockScanner

                                      The following test timeouts occurred in hadoop-hdfs-project/hadoop-hdfs:

org.apache.hadoop.hdfs.TestDatanodeDeath

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/9351//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/9351//console

This message is automatically generated., What are the chances this is a JDK7 vs. JDK8 change in behavior?, The problem that we face is that if we turn on showprogress, then the fsck command takes much longer (about 50% longer), not to mention the gazillion dots printed out.

If we disable the dots, the timeout problem happens. 

We did some quick performance analysis on what is causing the 50% extra time, and it turns out that it is actually printing dots to the tty. 

From my earlier experiment with the tcpdump, it seems that we need to send something on the channel to keep it alive. So, here is a proposed solution:
* Change the server to disregard the showprogress option, and send out dots every N (=10) seconds no matter what.
* Change the client to filter out any line that has only dots in it, if the showprogress option is not specified.
* Maybe take as N an additional option (e.g. progressFrequencySec), or make it configurable in hdfs-site.xml, or leave it at 10 (for now at least).

If this sounds fine, I can work on a patch to do this. I am also fine if Akira wants to work on the patch, or has alternative solutions., I'm talking specifically about the null not getting sent across the socket, since it sounds like it a) it did work for [~ajisakaa] and b) I know that LI has mostly transitioned over to JDK8., I tried on jdk7.

Note that the timeout happens only on large clusters (that take more than a minute to scan). [~ajisakaa] did you try out tcpdump?, bq. I could see that the dots were sent out in in the channel when -showprogress was specified, but the channel was quiet when it was not.
I tried tcpdump and confirmed this in JDK7. I'll try this with JDK8., Tried tcpdump with JDK8. The channel was quiet without -showprogress option.
bq. If this sounds fine, I can work on a patch to do this. I am also fine if Akira wants to work on the patch, or has alternative solutions.
Yeah, you can work on a patch :) One comment:
bq. Change the server to disregard the showprogress option, and send out dots every N (=10) seconds no matter what.
I want to reduce network load, so would you send a dot per 100 files if -showprogress option is not specified? If you scan 1G files, the server will send extra 1GB to client.]