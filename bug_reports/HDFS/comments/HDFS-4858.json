[{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12593997/HDFS-4858.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:red}-1 eclipse:eclipse{color}.  The patch failed to build with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/4723//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/4723//console

This message is automatically generated., I am concerned that we might not even be able to write a Unit Test for this bug.

The essential sequence of events for this bug is this:

1. Datanode should be connected to both Active and Standby NNs
2. Standby NN should die without sending the TCP RST to the DataNode. If the RST is sent out, then the DataNode thread waiting on this Socket will get a SocketException, and all is fine. It will keep trying to re-connect to the SNN, and will succeed when the SNN comes back to life. This is fine. The problem really happens only when the network interface dies abruptly. In this case, the TCP RST does not go out, so the DN side of the TCP connection never knows that the SNN rebooted. This is not such an unusual occurrence - an unexpected power loss for the SNN would cause exactly this situation

Note the following:
1. Kill -9 of the SNN will cause a TCP RST to be sent out
2. Reboot of the SNN machine will also cause a TCP RST to be sent out

How can we mock such a death of the SNN?
, > How can we mock such a death of the SNN?
I would try ifdown or cable pulling. It might be possible to simulate this through SocketFactory.
, Manually, this is quite easy to simulate. I have been using ifdown to recreate this problem consistently. My question is for simulating this in a unit test. If the TCP stack on the Secondary Name Node machine is alive, then it will send out a RST if the NN process dies. The only way to cut off all communications related to the socket is by killing the network interface, and I don't believe that this can be accomplished from Java (I would be happy to be corrected in this regard)., The patch is still applicable to the trunk. 
Considering that the solution is correct but the test can't be easily developed, I am 
  +1 on the patch
And will commit it shortly into trunk and 2.3 unless I hear otherwise in the next hour or so., One quick question: the current patch uses "RetryPolicies.TRY_ONCE_THEN_FAIL" as the connection retry policy. Originally if we pass in null we will use a RetryUpToMaximumCountWithFixedSleep policy? Shall we still follow the old retry behavior here?
, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12593997/HDFS-4858.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.TestDFSClientRetries

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/5873//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/5873//console

This message is automatically generated., Wasn't able to reproduce TestDFSClientRetries failure locally., I presume we need to look a bit more into this problem, because of the test failure. Thanks for bring it up [~jingzhao]., The problem with TestDFSClientRetries timeout is
{code}
org.apache.hadoop.ipc.Client.getTimeout(conf),
{code}
will set rpcTimeout to -1 unless ipc.client.ping is set to false., So, looks like you know how to fix it? Great!, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12626217/HDFS-4858.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.server.namenode.TestNameNodeHttpServer
                  org.apache.hadoop.hdfs.server.namenode.TestCacheDirectives

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/5996//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/5996//console

This message is automatically generated., Retesting, +1 one on the patching pending test results, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12626217/HDFS-4858.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.server.namenode.TestCacheDirectives
                  org.apache.hadoop.hdfs.server.namenode.TestAuditLogs

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/6056//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/6056//console

This message is automatically generated., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12626217/HDFS-4858.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/6061//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/6061//console

This message is automatically generated., There's no new test in the patch as the existing ones are sufficient to cover the scope of the change., This fix will solve the issue for the DataNode but there is a far more generic issue in the code: writes do not time out in the Client. The write should use the same timeout as the read. If I do not have a rpcTimeout set and have pingInterval the pingInterval will still cause a timeout on read (see around line 600). The same should happen for writes. 

The Client class is used by more than just the Datanode. It is also used by the TaskTracker for example. Not having a timeout on write affects the failover of the TaskTracker in a high availability scenario. Fixing it once for all users of the Client would be an easier and quicker solution.

With the change that is proposed the default value for the client ping (via IPC_CLIENT_PING_DEFAULT) is also changing from true to false. This will have flow on effects too., I agree with Wilfred. Seems like we have a more generic problem here than just the DN, and I don't think we should be changing the default behavior of whether or not to do pings., I thought the client timeout problem was solved by HDFS-4646. It's been working fine for us since then.  Is it a different problem you are talking about?

> see around line 600

Line 600 of what?

> It is also used by the TaskTracker 

Are you referring to cdh4, as trunk and Hadoop 2 don't have TaskTracker.

Sorry, I didn't understand the general problem from your descriptions, guys. If you could tell how to reproduce it or better propose a fix. The DataNode problem is real though, because fail-overs fail when the DN thread gets stuck. It would be good to fix it in the next release., >I thought the client timeout problem was solved by HDFS-4646. It's been working fine for us since then. Is it a different problem you are talking about?

There are other parts of the code that use the ipc client. It is not just limited to the datanode. The tasktracker, as mentioned is one example for MR1. The fact that the client does not timeout for a write is still there. You now need to find every single place where you use the client and make sure that you fix it. I tried to point that out.
Instead of pulling the time out for writes out of the client code (Client.java) it should be handled transparently for the caller in the Client code. 

>> see around line 600
>Line 600 of what?

Line 600 of the Client.java code, If rpcTimeout is not set (0 or -1) then the pingInterval will be used to make sure that the read times out. A similar construct should also be used for the write side to make sure that you do not have  rpcTimeout set. The solution maintains a different behaviour for read and write timeouts while this would be a chance to fix that.

>> It is also used by the TaskTracker
> Are you referring to cdh4, as trunk and Hadoop 2 don't have TaskTracker.

The TaskTracker was used as an example. Purely used to point to the fact that there are, or could be, more users of the client code that exhibit the same issue.

>Sorry, I didn't understand the general problem from your descriptions, guys. If you could tell how to reproduce it or better propose a fix. The DataNode problem is real though, because fail-overs fail when the DN thread gets stuck. It would be good to fix it in the next release.

The issue is real for each user of the client code. Write on a socket does not time out (normal behaviour). When a hardware failure occurs on a network layer this becomes apparent (unplug a cable, server HW failure, switch failure etc). Steps to reproduce are given in this bug and in HDFS-4646. They all work. TCP timeout and retry are the underlying cause of this 'hang' and faster fails can be achieved by changing the tcp_retries2 parameter at the kernel level.
Instead of looking outside the Client.java code why do we not time out the write itself? Currently the code just waits forever for the write to return, a simple change would be to change that wait. I can attach a diff for the change if that makes it easier to see what I mean.
, I understand now what you mean. So this is the same problem, but you want to fix it in a generic way.
It may seem a simple fix, but you are absolutely right this will affect everything that is using Client.java, and there is a lot of things our there, such as your TaskTracker, which we don't know about, but can break them because of that. Why don't we open a separate jira for your proposal.
Are you OK with committing this?

My +1, Even if we choose to not fix this in a more general way in this JIRA, I don't think we should be changing the default behavior of whether or not to do client pings in this patch. That change also has the potential to affect things well beyond HDFS., Ok, sounds like you don't want it fixed in this release., bq. It may seem a simple fix, but you are absolutely right this will affect everything that is using Client.java, and there is a lot of things our there, such as your TaskTracker, which we don't know about, but can break them because of that. Why don't we open a separate jira for your proposal.

If you want to do a small fix that is just isolated to the DN, and has no farther-reaching implications, then my suggestion would be to remove the changes to {{Client}} from this patch and change the call to {{Client#getTimeout}} in {{DatanodeProtocolClientSideTranslatorPB#createNamenode}} to instead call {{Client#getPingInterval}}. This should have the same net effect for DN RPCs without possibly impacting anything else., I agree with Aaron: the change could be a simple change confined to the DatanodeProtocolClientSideTranslatorPB and leave the Client as is. That will remove the change of regressions in other areas that rely on the Client.
Whether you want to use Client#getTimeout or Client#getPingInterval that is up to you to decide., This latest patch looks good to me. +1 pending Jenkins., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12628333/HDFS-4858.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/6112//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/6112//console

This message is automatically generated., +1, no automated testing for this patch, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12628333/HDFS-4858.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/6116//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/6116//console

This message is automatically generated., SUCCESS: Integrated in Hadoop-trunk-Commit #5152 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/5152/])
HDFS-4858. HDFS DataNode to NameNode RPC should timeout. Contributed by Henry Wang. (shv: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1567535)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Client.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolClientSideTranslatorPB.java
, I just committed this. Thank you Henry., SUCCESS: Integrated in Hadoop-Yarn-trunk #479 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/479/])
HDFS-4858. HDFS DataNode to NameNode RPC should timeout. Contributed by Henry Wang. (shv: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1567535)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Client.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolClientSideTranslatorPB.java
, SUCCESS: Integrated in Hadoop-Hdfs-trunk #1671 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1671/])
HDFS-4858. HDFS DataNode to NameNode RPC should timeout. Contributed by Henry Wang. (shv: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1567535)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Client.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolClientSideTranslatorPB.java
, SUCCESS: Integrated in Hadoop-Mapreduce-trunk #1696 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1696/])
HDFS-4858. HDFS DataNode to NameNode RPC should timeout. Contributed by Henry Wang. (shv: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1567535)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Client.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolClientSideTranslatorPB.java
]