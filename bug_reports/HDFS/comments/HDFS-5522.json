[One option will be to move the check to a new or existing thread and decouple checks from request handling., In this patch, I have created new thread which will check for disk errors when there is request fro disk error check every 5 seconds., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12643378/HDFS-5522.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/6817//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/6817//console

This message is automatically generated., Broke testcase: , Attached a new patch fixing the broken test case, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12643801/HDFS-5522-v2.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.server.namenode.TestNameNodeRespectsBindHostKeys
                  org.apache.hadoop.TestRefreshCallQueue

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/6846//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/6846//console

This message is automatically generated., It looks like both test failures are due to the flaw in MiniDFSCluster and its usage. I will file a jira for it., The patch looks okay, except few minor cosmetic issues. 
* Move the second {{catch()}} next to  the "\}" in the previous line. There is one more like this.  
* Typo, "occured".
* It will be nice if start and termination are logged. For start, log it outside the synchronized block after staring the thread. If the disk containing the file system where log is stored is failing, the logging action may hang. We want disk check to start before this happens.

A possible future improvement will be to make the disk check ({{mkdir()}}) to timeout. This will require another thread to monitor the disk check activity and interrupt the disk check thread if a check is taking too long.  Since I/O timeout is usually very long (e.g. 15-20 minutes), the common I/O hang condition can make a lot of user requests timeout/fail before a faulty disk is marked bad.  With the timeout/interrupt feature, the fault detection latency can be made shorter.  This is beyond the scope of this jira, of course., Will work on Kihwaal comments and post a new patch, Thanks Kihwal for your comments.
I incorporated your first and second comment.
For the third comment, I agree that start and termination of checkDiskError Thread should be logged. But for your suggestion to place outside synchronized block, I think that will not be good place since it will log whenever checkDiskError() is called.
So I logged inside the synchronized block.
Let me know if you have more comments., Submitting a new patch incorporating Kihwals comments., {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12644147/HDFS-5522-v3.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/6869//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/6869//console

This message is automatically generated., + 1 lgtm, Thanks for working on this, Rushabh. I've committed this to branch-2 and trunk.  This feature makes disk check asynchronous, so handlers(DataXceiver) won't get blocked while checking disks.  , FAILURE: Integrated in Hadoop-trunk-Commit #5604 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/5604/])
HDFS-5522. Datanode disk error check may be incorrectly skipped. Contributed by Rushabh Shah. (kihwal: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1594055)
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDiskError.java
, FAILURE: Integrated in Hadoop-Yarn-trunk #561 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/561/])
HDFS-5522. Datanode disk error check may be incorrectly skipped. Contributed by Rushabh Shah. (kihwal: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1594055)
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDiskError.java
, FAILURE: Integrated in Hadoop-Mapreduce-trunk #1779 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1779/])
HDFS-5522. Datanode disk error check may be incorrectly skipped. Contributed by Rushabh Shah. (kihwal: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1594055)
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDiskError.java
, FAILURE: Integrated in Hadoop-Hdfs-trunk #1753 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1753/])
HDFS-5522. Datanode disk error check may be incorrectly skipped. Contributed by Rushabh Shah. (kihwal: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1594055)
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDiskError.java
, I know this has been closed for a while, but wanted to get some clarification:

{quote}
If I/O hangs for a long time, network read/write may timeout first and the peer may close the connection. Although the error was caused by a faulty local disk, disk check is not being carried out in this case
{quote}

It seems like this JIRA applied a rather heavy hammer for a specific case that could be better identified in another way. After applying this patch, it seems that DNs will run checkDiskError when any other node experiences an issue. So, if one node is down (eg due to a rolling restart or a crash) all of the other nodes are very soon running checkDiskError for no particularly good reason. Coupled with HDFS-7489, this failure can also cascade.

Can you describe in more detail the scenario you were facing that inspired this JIRA? Would it not make more sense to actually look for the underlying symptom (by adding a timer around the I/O, perhaps?) and running checkDiskError in the specific scenarios we're looking for, rather than all network errors?, bq. So, if one node is down (eg due to a rolling restart or a crash) all of the other nodes are very soon running checkDiskError for no particularly good reason. Coupled with HDFS-7489, this failure can also cascade
Yes, samething has been experienced in one of our customer's cluster. 
Due to some nodes' n/w issue, all other datanodes (connected in pipeline) started checkdisk. And without HDFS-8845 (2.7.2), all Datanode's disk I/O hit 100%.
By the time first round of diskcheck is done, some other exception requested for diskcheck again. This continued for more than 40 hours slowing down every other application.
]