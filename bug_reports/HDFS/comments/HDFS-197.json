[The patch for this can be found on http://github.com/kohsuke/hadoop/commit/27273cd0515e598b51eed48a1d0c87fc16ca995f, > The patch for this can be found on http://github.com/kohsuke [ ...] 

Can you please attach your patch directly to this issue in Jira, checking the license checkbox if you wish your work to be includable in an Apache release.  Thanks!, Patch, Does the TestDU unit test fail on Windows without this?  If not, can we easily modify it so that it does?
, Please revive this effort.  Thanks!, (Assigning to self, will try a test case and update patch accordingly.), (Still lack a windows setup locally to test this. Unassigning for now to not block.), I'm also getting this error when using MiniDFSCluster in an acceptance test. Is this issue related?

17:24:40.288 [main] ERROR o.a.h.h.server.namenode.FSNamesystem - FSNamesystem initialization failed.
java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DF.parseExecResult(DF.java:117) ~[hadoop-core-0.20.2-cdh3u2.jar:na]
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:237) ~[hadoop-core-0.20.2-cdh3u2.jar:na]
	at org.apache.hadoop.util.Shell.run(Shell.java:182) ~[hadoop-core-0.20.2-cdh3u2.jar:na]
	at org.apache.hadoop.fs.DF.getFilesystem(DF.java:63) ~[hadoop-core-0.20.2-cdh3u2.jar:na]
	at org.apache.hadoop.hdfs.server.namenode.NameNodeResourceChecker.addDirsToCheck(NameNodeResourceChecker.java:93) ~[hadoop-core-0.20.2-cdh3u2.jar:na]
	at org.apache.hadoop.hdfs.server.namenode.NameNodeResourceChecker.<init>(NameNodeResourceChecker.java:73) ~[hadoop-core-0.20.2-cdh3u2.jar:na]
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initialize(FSNamesystem.java:348) ~[hadoop-core-0.20.2-cdh3u2.jar:na]
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:327) ~[hadoop-core-0.20.2-cdh3u2.jar:na]
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:271) [hadoop-core-0.20.2-cdh3u2.jar:na]
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:465) [hadoop-core-0.20.2-cdh3u2.jar:na]
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1239) [hadoop-core-0.20.2-cdh3u2.jar:na]
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:278) [hadoop-test-0.20.2-cdh3u2.jar:na]
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:125) [hadoop-test-0.20.2-cdh3u2.jar:na]
	at com.redowlanalytics.reveal.test.integration.hadoop.HadoopIntegrationTest.setUp(HadoopIntegrationTest.java:48) [test-classes/:na]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.7.0_01]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) ~[na:1.7.0_01]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.7.0_01]
	at java.lang.reflect.Method.invoke(Method.java:601) ~[na:1.7.0_01]
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:44) [junit-4.9.jar:na]
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15) [junit-4.9.jar:na]
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:41) [junit-4.9.jar:na]
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:27) [junit-4.9.jar:na]
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:31) [junit-4.9.jar:na]
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263) [junit-4.9.jar:na]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:69) [junit-4.9.jar:na]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:48) [junit-4.9.jar:na]
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231) [junit-4.9.jar:na]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60) [junit-4.9.jar:na]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229) [junit-4.9.jar:na]
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50) [junit-4.9.jar:na]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222) [junit-4.9.jar:na]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:292) [junit-4.9.jar:na]
	at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:50) [.cp/:na]
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38) [.cp/:na]
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467) [.cp/:na]
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683) [.cp/:na]
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390) [.cp/:na]
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197) [.cp/:na], I found out that the "du.exe" version that is ran by default is the one located at "%SystemRoot%\system32\" and the output is very different from the one in Cygwin's "bin" directory, actually it is not the expected output because the first line is blank.

The options I came up with are:
1. Setting up the %PATH% so that Cygwin's "bin" directory is read before "%SystemRoot%\system32" (dangerous for the whole system IMO)
2. Overwriting "du.exe" with Cygwin's version (dangerous for part of the system IMO)
3. Somehow setting in Hadoop's config files the path from where to read the right binaries, in this case "du.exe"

I don't know if option 3 is available right now (I'm new to Hadoop), but I hope this info helps solve the problem.

, MS has fixed Windows support. Closing as stale.]