[{code}  /**
   * Client is reporting some bad block locations.
   */
  void reportBadBlocks(LocatedBlock[] blocks) throws IOException {
    checkOperation(OperationCategory.WRITE);
    NameNode.stateChangeLog.info("*DIR* reportBadBlocks");
    writeLock();
    try {
      checkOperation(OperationCategory.WRITE);
      for (int i = 0; i < blocks.length; i++) {
        ExtendedBlock blk = blocks[i].getBlock();
        DatanodeInfo[] nodes = blocks[i].getLocations();
        String[] storageIDs = blocks[i].getStorageIDs();
        for (int j = 0; j < nodes.length; j++) {
          blockManager.findAndMarkBlockAsCorrupt(blk, nodes[j],
              storageIDs == null ? null: storageIDs[j], 
              "client machine reported it");
        }
      }
    } finally {
      writeUnlock();
    }
  }{code}

According to above code snippet from FSNamesystem responsible for handling bad blocks, there is no safemode check. And hence No SafeModeException expected.
Whether check is really required? IMO, NO, since this is not any update on filesystem, but just marking the block as corrupt. 

Agree [~kihwal]  and [~yzhangal] ?, bq.  IMO, NO, since this is not any update on filesystem, but just marking the block as corrupt. 
Agreed. It's like block reports, which is processed while in safe mode under the write lock., Thanks [~vinayrpet] and [~kihwal].

I created this jira really because I was worried there might be exceptions other than StandbyException wrapped by RemoteException, and if they need to be treated differently. My bad that I did not dig the code earlier. I looked at the code a bit more, and don't see other exceptions except runtime ones.  

I'm closing this jira. If someone add a new exception in the future in the code flow that need to be handled differently than StandbyException w.r.t HDFS-7916, we need to be aware of the handling here .

Thanks.

]