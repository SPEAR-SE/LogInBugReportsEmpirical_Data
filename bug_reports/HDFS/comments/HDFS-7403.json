[Submitted patch 001, thanks for reviewing.
, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12681796/HDFS-7403.001.patch
  against trunk revision 198fb58.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:red}-1 findbugs{color}.  The patch appears to introduce 1 new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/8757//testReport/
Findbugs warnings: https://builds.apache.org/job/PreCommit-HDFS-Build/8757//artifact/patchprocess/newPatchFindbugsWarningshadoop-hdfs.html
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/8757//console

This message is automatically generated., I noticed the following code in BlockManager.java, which means even if a block doesn't have enough replicas, it can still be marked as complete:

 /**
   * Force the given block in the given file to be marked as complete,
   * regardless of whether enough replicas are present. This is necessary
   * when tailing edit logs as a Standby.
   */
  public BlockInfo forceCompleteBlock(final BlockCollection bc,
      final BlockInfoUnderConstruction block) throws IOException {
    block.commitBlock(block);
    return completeBlock(bc, block, true);
  }
that calls 
{code}
 /**
   * Convert a specified block of the file to a complete block.
   * @param bc file
   * @param blkIndex  block index in the file
   * @throws IOException if the block does not have at least a minimal number
   * of replicas reported from data-nodes.
   */
  private BlockInfo completeBlock(final BlockCollection bc,
      final int blkIndex, boolean force) throws IOException {
    if(blkIndex < 0)
      return null;
    BlockInfo curBlock = bc.getBlocks()[blkIndex];
    if(curBlock.isComplete())
      return curBlock;
    BlockInfoUnderConstruction ucBlock = (BlockInfoUnderConstruction)curBlock;
    int numNodes = ucBlock.numNodes();
    if (!force && numNodes < minReplication)
      throw new IOException("Cannot complete block: " +
          "block does not satisfy minimal replication requirement.");
    if(!force && ucBlock.getBlockUCState() != BlockUCState.COMMITTED)
      throw new IOException(
          "Cannot complete block: block has not been COMMITTED by the client");
    BlockInfo completeBlock = ucBlock.convertToCompleteBlock();
    // replace penultimate block in file
    bc.setBlock(blkIndex, completeBlock);
    
    // Since safe-mode only counts complete blocks, and we now have
    // one more complete block, we need to adjust the total up, and
    // also count it as safe, if we have at least the minimum replica
    // count. (We may not have the minimum replica count yet if this is
    // a "forced" completion when a file is getting closed by an
    // OP_CLOSE edit on the standby).
    namesystem.adjustSafeModeBlockTotals(0, 1);
    namesystem.incrementSafeBlockCount(
        Math.min(numNodes, minReplication));
    
    // replace block in the blocksMap
    return blocksMap.replaceBlock(completeBlock);
  }
{code}

Well, the javadoc of COMPLETE says it means "The block has at least one", thus it is still confusing. I was thinking about changing the COMPLETE javadoc to be something like
{code}
In common case, COMPLETE means that the block need to have >= minimal replication replicas" (link to minimalReplica def). However, a block may be forced to COMPLETE state even if it doesn't have any replica. (link to the above method)
{code}

, Upload patch 002 per my last comment.
, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12682776/HDFS-7403.002.patch
  against trunk revision eb4045e.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/8797//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/8797//console

This message is automatically generated., I think original code mentions at least "one", because the default of {{DFS_NAMENODE_REPLICATION_MIN_KEY}} is one.
The modification looks good to me. Just one comment, some javadoc line length is > 80., Yongjun, BTW, I think we don't need the link, we may describe using words.  It looks strange we link like this in a common class., Hi Yi,

Thanks a lot for your review and comments! Just uploaded rev 003 to address your comments, hope it looks good to you.



, +1.  
Will hold to commit until tomorrow and wait to see if there are other comments., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12682836/HDFS-7403.003.patch
  against trunk revision c298a9a.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/8800//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/8800//console

This message is automatically generated., Commit to trunk and branch-2, thanks Yongjun for the contribution., FAILURE: Integrated in Hadoop-trunk-Commit #6592 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/6592/])
HDFS-7403. Inaccurate javadoc of  BlockUCState#COMPLETE state. (Yongjun Zhang via yliu) (yliu: rev 555fa2d9d0dbb3bf2b209a953eb07a59bbfe3197)
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/common/HdfsServerConstants.java
* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
, Thanks a lot Yi!
, FAILURE: Integrated in Hadoop-Yarn-trunk-Java8 #15 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk-Java8/15/])
HDFS-7403. Inaccurate javadoc of  BlockUCState#COMPLETE state. (Yongjun Zhang via yliu) (yliu: rev 555fa2d9d0dbb3bf2b209a953eb07a59bbfe3197)
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/common/HdfsServerConstants.java
* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
, SUCCESS: Integrated in Hadoop-Yarn-trunk #753 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/753/])
HDFS-7403. Inaccurate javadoc of  BlockUCState#COMPLETE state. (Yongjun Zhang via yliu) (yliu: rev 555fa2d9d0dbb3bf2b209a953eb07a59bbfe3197)
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/common/HdfsServerConstants.java
* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
, SUCCESS: Integrated in Hadoop-Hdfs-trunk #1943 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1943/])
HDFS-7403. Inaccurate javadoc of  BlockUCState#COMPLETE state. (Yongjun Zhang via yliu) (yliu: rev 555fa2d9d0dbb3bf2b209a953eb07a59bbfe3197)
* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/common/HdfsServerConstants.java
, SUCCESS: Integrated in Hadoop-Hdfs-trunk-Java8 #15 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk-Java8/15/])
HDFS-7403. Inaccurate javadoc of  BlockUCState#COMPLETE state. (Yongjun Zhang via yliu) (yliu: rev 555fa2d9d0dbb3bf2b209a953eb07a59bbfe3197)
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/common/HdfsServerConstants.java
* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
, FAILURE: Integrated in Hadoop-Mapreduce-trunk-Java8 #15 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk-Java8/15/])
HDFS-7403. Inaccurate javadoc of  BlockUCState#COMPLETE state. (Yongjun Zhang via yliu) (yliu: rev 555fa2d9d0dbb3bf2b209a953eb07a59bbfe3197)
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/common/HdfsServerConstants.java
* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
, FAILURE: Integrated in Hadoop-Mapreduce-trunk #1967 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1967/])
HDFS-7403. Inaccurate javadoc of  BlockUCState#COMPLETE state. (Yongjun Zhang via yliu) (yliu: rev 555fa2d9d0dbb3bf2b209a953eb07a59bbfe3197)
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/common/HdfsServerConstants.java
* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
]