[I guess it depends on actual definition of getPermission(). Assuming defininition is similar to Unix system call stat(), I think this like requiring stat() to return different values for permissions based on whether the file system is mounted read-only or read-write (say, for a file with permissions "rw-rw-r--"), no?
, The use case of dfs.permissions=false was better explained to me yesterday.  It is intended to permit admins to set permissions after upgrade while leaving the filesystem available for use.  If this use case is really important, then we should mark this "won't fix".

Nigel expressed concerns about displaying permissions in "ls" that are not enforced would be confusing to users, that returning 777 would be better for that reason too.  But if dfs.permissions is only meant to be used during transition, this may not be a serious issue.

I'm beginning to think that dfs.permissions should be 'true' by default, and that the default permission on upgrade should be 777.  That is back-compatible.  Then, if folks like, they can set more prohibitive permissions and/or disable permission checking.  If this is the default behavior then I am okay marking this issue "won't fix".  Currently dfs.permissions is 'false' by default, so perhaps that should change.  I am not yet certain what the default file permission is after an upgrade..., Okay, I found it: the default permissions on upgrade are 777, with both user and group set to HadoopAnonymous.  So I'm now leaning towards switching to dfs.permissions=true by default., > Okay, I found it: the default permissions on upgrade are 777, with both user and group set to HadoopAnonymous. So I'm now leaning towards switching to dfs.permissions=true by default.

The information above is out-dated.  The current situation is:
- dfs.permissions=*true* by default

For upgrade,
- default owner: *fsOwner*, which is the user who run NameNode
- default group: *supergroup*, which is the value set in dfs.permissions.supergroup
- default permission: *777*

So, shell we mark this issue "won't fix"?, +1 for closing., Closing this issue since it has long gone stale, and it's unlikely there are still users out there running versions of Hadoop which don't have permissions support. :)]