[If all datanodes in the pipleline are dead, then the application cannot write anymore to the file. (This can be improved, of course). Are you saying that throwing exceptions to the write/close call (after all datanodes in pipeline have failed) is a problem? 

Or are you saying that when all datanodes in the pipeline fail, all resources associated with that OutputStream should be automatically released?
, Throwing exception at future close() and write() is perfectly fine.

I am saying the second one. 
Also the file will leave in incomplete/being create state if that DfsClient  instance does not get a chance to close. (which is common for many daemon apps which use hdfs as the backend). , What version are you seeing this issue in? I noticed something similar when producing HDFS-915 on trunk, but haven't seen it on 0.20.1, @Todd,
The problem was seen in hadoop-0.19.2, not sure about 0.20.1, Btw, the code line in the description is from trunk. It seems the problem is still there in the client code., I'm not quite understanding what you're describing, I think.

If all of the datanodes fail, the last block is in an indeterminate state - we don't know what length ever made it to the DNs, so we can't really close the file properly. I suppose we could use the length from the last acked seqno, but the DNs will still have the replicas in the "rbw" state. There is some kind of state transition for recovery of rbw replicas described in the HDFS-265 document - I don't recall off the top of my head if it will function if none of the DNs are up.

If you wait an hour for the hard lease limit, does the file end up in some kind of state that you expect?, >>If all of the datanodes fail, the last block is in an indeterminate state
Yes, i knew this is main problem.  i think there should be some policy for handling that.
>>If you wait an hour for the hard lease limit
i am not sure if i get what i expect after one hour. But it will be not nice at all for users with respect their user experience. for example, if you upload a file to a website and you get to know sth after 1 hour, how that would be? (this is just an example, and of course there are workarounds for this example.), > Also the file will leave in incomplete/being create state if that DfsClient instance does not get a chance to close.
> But it will be not nice at all for users with respect their user experience. 
Agreed. 

I come across this problem, DFSClient should complete those creating files when IOExceptions encoutered. 

But Normally we could not complete these files successfully before all blocks of creating files are reported to NameNode, In short: the last block is in indeterminate state at this time.

in this case, the only one option I think is delete the last failing block and then complete/close the file., This is actually more general that just a hang-on-close. A writer will not be able to allocate a new block for a file if a  previous (penultimate) block does not have any good replica. this case does happen in real-life if all the existing replicas of a block happen to fail, thus making the application hang indefinitely. can we somehow allow the application to get an IO error and bail out from the write/close call?, I guess that this is not a problem anymore. Please feel free to reopen this if I am wrong. Resolving ...]