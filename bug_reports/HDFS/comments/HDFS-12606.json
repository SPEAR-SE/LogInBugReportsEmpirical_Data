[

I saw a single static global variable {{isaLoader}} in {{isal_loader.h}} providing access to {{ISA-L}} library.  One simple way is to make {{NativeRSRawDecoder}}, but it will limits the parallelism of encoding / decoding on DN. [~Kai], [~Sammi]  Could you give some thoughts about this? 
, Thanks for the ping Eddy. By design we can have multiple coder instances for concurrent coding tasks, and no global static variable should block this except bugs. We guard isal codes in Java, not relying on its thread model. We can investigate it when back to office, next Monday., Found out that this was due to {{DFSStripedInputStream#close}} being called more than once. 

{code:Title=core dump}
Thread 105026: (state = IN_NATIVE)
 - org.apache.hadoop.io.erasurecode.rawcoder.NativeRSRawDecoder.destroyImpl() @bci=0 (Interpreted frame)
 - org.apache.hadoop.io.erasurecode.rawcoder.NativeRSRawDecoder.release() @bci=1, line=50 (Interpreted frame)
 - org.apache.hadoop.hdfs.DFSStripedInputStream.close() @bci=56, line=191 (Interpreted frame)
 - java.io.FilterInputStream.close() @bci=4, line=181 (Interpreted frame)
 - java.io.FilterInputStream.close() @bci=4, line=181 (Interpreted frame)
 - org.apache.hadoop.hdfs.NNBench.analyzeResults() @bci=458, line=352 (Interpreted frame)
 - org.apache.hadoop.hdfs.NNBench.run(java.lang.String[]) @bci=34, line=608 (Interpreted frame)
 - org.apache.hadoop.util.ToolRunner.run(org.apache.hadoop.conf.Configuration, org.apache.hadoop.util.Tool, java.lang.String[]) @bci=61, line=76 (Interpreted frame)
 - org.apache.hadoop.util.ToolRunner.run(org.apache.hadoop.util.Tool, java.lang.String[]) @bci=8, line=90 (Interpreted frame)
 - org.apache.hadoop.hdfs.NNBench.main(java.lang.String[]) @bci=8, line=580 (Interpreted frame)
 - sun.reflect.NativeMethodAccessorImpl.invoke0(java.lang.reflect.Method, java.lang.Object, java.lang.Object[]) @bci=0 (Interpreted frame)
 - sun.reflect.NativeMethodAccessorImpl.invoke(java.lang.Object, java.lang.Object[]) @bci=100, line=62 (Interpreted frame)
 - sun.reflect.DelegatingMethodAccessorImpl.invoke(java.lang.Object, java.lang.Object[]) @bci=6, line=43 (Interpreted frame)
 - java.lang.reflect.Method.invoke(java.lang.Object, java.lang.Object[]) @bci=56, line=498 (Interpreted frame)
 - org.apache.hadoop.util.RunJar.run(java.lang.String[]) @bci=453, line=239 (Interpreted frame)
 - org.apache.hadoop.util.RunJar.main(java.lang.String[]) @bci=8, line=153 (Interpreted frame)
{code}

The {{close()}} should be idempotent to be safer. , Add a test to verify the crash. 

Without the fix,  running {{mvn test -Pnative -Dtest=TestDFSStripedInputStream}} can crash JVM. , Nice find Eddy. Does the output stream also suffer from the same issue? I don't see a null check wrapping encoder.release() in DFSStripedOutputStream#closeImpl. Maybe we should fix the output stream at HDFS-12612 since it's a very similar issue.

Related to this patch, would it be better if we did this null check/set in the native code? This makes the API simpler to use. We should also add some javadoc about the idempotency (or non-idempotency) of these APIs.

Also, what's the behavior of release() for the Java coder implementation?, Hi, [~andrew.wang]

bq. Maybe we should fix the output stream at HDFS-12612 since it's a very similar issue.

HDFS-12612 has IOE from streams in the context, I will take closer look of the difference between it and this one. Will work separately on HDFS-12612.

bq. Related to this patch, would it be better if we did this null check/set in the native code? This makes the API simpler to use.

Good point. I feel that it'd be another separated effort to solid implementation of the native code. However, it is still a good practice to set decoder to null in close(), similar to setting other fields in the same {{close()}}, so that it can be orthogonal to the implementations of EC coder.   I will file follow on JIRA to take care of the native code part. 

bq. what's the behavior of release() for the Java coder implementation?

You meant in non-native coder ?  {{release()}} are only implemented {{NativeRSRawDecoder}} and {{NativeXORRawDecoder}}, which free the memory of the coder struct in C.
, Hi Eddy,

bq. Good point. I feel that it'd be another separated effort to solid implementation of the native code. However, it is still a good practice to set decoder to null in close(), similar to setting other fields in the same close(), so that it can be orthogonal to the implementations of EC coder. I will file follow on JIRA to take care of the native code part.

Sure, the belt-and-suspenders approach to safety :)

bq. You meant in non-native coder ? release() are only implemented NativeRSRawDecoder and NativeXORRawDecoder, which free the memory of the coder struct in C.

Yea, so the empty inherited implementation is idempotent.

I'm +1 on this change, as long as in the follow-on we also update the javadoc to clarify the idempotency of these APIs and have appropriate unit tests., | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 18s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m  8s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 15m  9s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m 43s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 43s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 41s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 11m 33s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  3m 32s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 10s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m  8s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m 35s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m 42s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  1m 42s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 41s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 40s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green}  9m 33s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  3m 27s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 59s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  1m 13s{color} | {color:green} hadoop-hdfs-client in the patch passed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 91m 57s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 24s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}148m 15s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:71bbb86 |
| JIRA Issue | HDFS-12606 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12890830/HDFS-12606.00.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |
| uname | Linux b00ee514a997 3.13.0-117-generic #164-Ubuntu SMP Fri Apr 7 11:05:26 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 2b08a1f |
| Default Java | 1.8.0_144 |
| findbugs | v3.1.0-RC1 |
| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/21577/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/21577/testReport/ |
| modules | C: hadoop-hdfs-project/hadoop-hdfs-client hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/21577/console |
| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

, Thanks for the reviews, [~andrew.wang]

Committed to trunk and branch-3.0, SUCCESS: Integrated in Jenkins build Hadoop-trunk-Commit #13052 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/13052/])
HDFS-12606. When using native decoder, DFSStripedStream.close crashes (lei: rev 46644319e1b3295ddbc7597c060956bf46487d11)
* (edit) hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSStripedInputStream.java
* (edit) hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSStripedInputStream.java
]