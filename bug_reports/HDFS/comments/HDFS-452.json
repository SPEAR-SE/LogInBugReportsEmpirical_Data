[\-count current requires rx permission for directories.  It is nothing to do with who is the owner.  If the permission of /user/rphulari/temp is rwxr-x---, then user rphulari will have permission to do -count.
, This should probably behave like unix's du command, where unreadable directories cause an error message to be printed to standard error, but the command continues to run and compute the sum excluding unreadable things., 
The root cause of the problem is fundamental to how permissions are seperated from actual access in HDFS. In this case, HDFS first verifies that user has read permissions for the entire tree _before_ actually starting the counting. This is just one of issues of separating permissions checking (apart from iterating multiple times).

Ideally command should do what what du does. To do that, the simplest I can think of is to  move the recursive counting from FSDirectory into FSNamesystem (where it has correct permissions). 

For 0.20.1, permission checking could be fixed at least for directories where quota is set : i.e. if /user/xxx has a quota set, HDFS does not iterate over the tree.. inode for /user/xxx already has this info. So NameNode should check read permissions just for this directory.

, > This should probably behave like unix's du command, ...
"fs -count" originally was implemented for counting files and directories, which was different from any unix command (please correct me if I was wrong).  The closest unix command is "ls -r" because both of them traverse namespace sub-trees, and so we require rx permission for the directory and all its sub-directories.  Later on, we added space counting and quota features to -count.  These features made it looks like unix du.  Note that we indeed have a "fs -du" command.  We should minimize the similarity between -count and -du.

Raghu has suggested the following:  When quota is set in the directory, quota and count information are stored in an INode subclass, called INodeDirectoryWithQuota.  So the tree traversal may not be necessary.  "fs -count" may just return the stored information in the INodeDirectoryWithQuota.  Then, -count only needs the required permission on the directory but not its sub-directories since there is no traversal.

Both ideas sound good to me.  It seems that both of them are incompatible to the current implementation.
, Additional information -- 
fs -du  also  throws similar exception in such scenario .

{code}

[rphulari@some-host ~]$ hadoop fs -ls
Found 3 items
d------rwx   - rphulari users          0 2009-06-29 22:37 /user/rphulari/tdir
drwxr--r--   - rphulari users          0 2009-05-06 22:02 /user/rphulari/temp2
drwxr--r--   - rphulari users          0 2009-04-21 00:56 /user/rphulari/validation

[rphulari@some-host ~]$ hadoop fs -du 
Found 3 items
du: org.apache.hadoop.security.AccessControlException: Permission denied: user=rphulari, access=READ_EXECUTE, inode="tdir":rphulari:users:------rwx

{code}  , I suspect this is no longer an issue on trunk and can be closed.

Ravi or Raghu, can you confirm?, From trunk as of 8a795812e79033cb5b91389cc0e7e110deacbe0e

{code}
hdfs dfs -count /
count: Permission denied: user=root, access=READ_EXECUTE, inode="/user":aw:hdfs:drwx------


hdfs dfs -du /
du: Permission denied: user=root, access=READ_EXECUTE, inode="/copy":aw:hdfs:drwxr-x---
du: Permission denied: user=root, access=READ_EXECUTE, inode="/system":aw:hdfs:drwxr-x---
du: Permission denied: user=root, access=READ_EXECUTE, inode="/user":aw:hdfs:drwx------
0  /benchmarks

{code}

]