[Hi [~fireling]

This is not a bug, this is how HDFS works. A file (if less than block size) is always stored in a block but that doesn't mean this file will take a block size from the system. Datanode has a background thread to calculate the disk usage and report that back to NN in certain interval, which is defined by "fs.du.interval". So it needs a while until NN acknowledges the actual space utilized. I am closing this as INVALID. Next time, you can try raise your question in user mailing list before filing a jira. Feel free to reopen if you disagree. Thank you., Hi [~cheersyang]
Thank you for the answer, Iâ€™ve got it.]