[[~alexfo] When creating jiras, please keep the description brief and add the details in a subsequent comment.

Have you duplicated the problem on Apache releases? If not, please follow up on CDH mailing lists. Usually a corresponding Apache jira is created, if needed., I will close this jira if you are not able to produce this on Apache releases., The error can certainly be improved but what its telling you is that you have 1 disk configured but you also have {{dfs.datanode.failed.volumes.tolerated}} set to 1. Toleration value of disk failures should be strictly less than the total number of configured {{dfs.datanode.data.dir}} values, for a DN cannot run disk-less.

This isn't a bug, but we'd gladly accept a patch to improve the error message. Would you be interested in submitting one yourself? We have steps outlined for Apache Hadoop contributions at http://wiki.apache.org/hadoop/HowToContribute, and you can ping the dev lists if you have further questions in the process.

Like Suresh has already pointed it out to you, in future, make sure to file JIRAs on Apache JIRA here only if you are sure it is also an Apache Hadoop release issue and not a CDH-specfic issue. For CDH specific issues, you should file a JIRA on their own bug trackers (link: https://issues.cloudera.org/browse/DISTRO) or ping its lists for clarification., Thanks [~qwertymaniac] for the pointers to log the jira at the right place., see also http://wiki.apache.org/hadoop/InvalidJiraIssues, Ok, understood. Thank you for the tolerated volumes thing to know

, Yes, that's a duplicate of HDFS-4201. Let me close this one and work on HDFS-4201.]