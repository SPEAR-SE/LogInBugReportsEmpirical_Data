[Hi [~kihwal], 
I wanted to give this jira a try but I can't assign jiras in HDFS to myself. 

Is the fix for this jira a matter of allowing the thread to sleep longer? I tried the test on my laptop and it passes.

Patch as follows:

{code}
diff --git hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestRenameWhileOpen.java hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestRenameWhileOpen.java
index 949fc74..f06383f 100644
--- hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestRenameWhileOpen.java
+++ hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestRenameWhileOpen.java
@@ -188,7 +188,7 @@ public void testWhileOpenRenameParentToNonexistentDir() throws IOException {
       // restart cluster with the same namenode port as before.
       // This ensures that leases are persisted in fsimage.
       cluster.shutdown();
-      try {Thread.sleep(2*MAX_IDLE_TIME);} catch (InterruptedException e) {}
+      try {Thread.sleep(8*MAX_IDLE_TIME);} catch (InterruptedException e) {}
       cluster = new MiniDFSCluster.Builder(conf).nameNodePort(nnport)
                                                 .format(false)
                                                 .build();
@@ -255,7 +255,7 @@ public void testWhileOpenRenameToExistentDirectory() throws IOException {
       // restart cluster with the same namenode port as before.
       // This ensures that leases are persisted in fsimage.
       cluster.shutdown();
-      try {Thread.sleep(2*MAX_IDLE_TIME);} catch (InterruptedException e) {}
+      try {Thread.sleep(8*MAX_IDLE_TIME);} catch (InterruptedException e) {}
       cluster = new MiniDFSCluster.Builder(conf).nameNodePort(nnport)
                                                 .format(false)
                                                 .build();
@@ -319,7 +319,7 @@ public void testWhileOpenRenameToNonExistentDirectory() throws IOException {
       // restart cluster with the same namenode port as before.
       // This ensures that leases are persisted in fsimage.
       cluster.shutdown();
-      try {Thread.sleep(2*MAX_IDLE_TIME);} catch (InterruptedException e) {}
+      try {Thread.sleep(8*MAX_IDLE_TIME);} catch (InterruptedException e) {}
       cluster = new MiniDFSCluster.Builder(conf).nameNodePort(nnport)
                                                 .format(false)
                                                 .build();
{code}
, Hi, [~vrushalic], I am not sure if this is the best way for fixing this. Maybe we need to know why the cluster was not shutdown completely., Hmm yes, the test runs fine on my local machine. Do you have a link handy to the failures in the precommit build? I tried looking but couldn't find any related to this one. , It is more likely that another process grabbed the port. In general it is not a good idea to hard-code or reuse the same port number in unit tests. We had to fix a lot of such test cases in the past. The jenkins slave can run multiple jobs at the same time and also hdfs tests can run in parallel., Here is the log from a failed test run. , I see, got you. Let me see if I can change the port number. , I updated the test to use a random port number. The test output that I see is as follows:

{code}
[machine-channapattan hadoop-hdfs (trunk)]$ grep -rni -A2 "nnport=" target/surefire-reports/org.apache.hadoop.hdfs.TestRenameWhileOpen-output.txt
target/surefire-reports/org.apache.hadoop.hdfs.TestRenameWhileOpen-output.txt:2:Will now start MiniDFSCluster with nnport=58999
target/surefire-reports/org.apache.hadoop.hdfs.TestRenameWhileOpen-output.txt-3-2016-08-05 11:51:56,081 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(465)) - starting cluster: numNameNodes=1, numDataNodes=1
target/surefire-reports/org.apache.hadoop.hdfs.TestRenameWhileOpen-output.txt-4-2016-08-05 11:51:56,319 [main] DEBUG namenode.NameNode (NameNode.java:initializeGenericKeys(1670)) - Setting fs.defaultFS to hdfs://127.0.0.1:58999
--
target/surefire-reports/org.apache.hadoop.hdfs.TestRenameWhileOpen-output.txt:1592:Will now start MiniDFSCluster with nnport=7009
target/surefire-reports/org.apache.hadoop.hdfs.TestRenameWhileOpen-output.txt-1593-2016-08-05 11:52:09,583 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(465)) - starting cluster: numNameNodes=1, numDataNodes=1
target/surefire-reports/org.apache.hadoop.hdfs.TestRenameWhileOpen-output.txt-1594-2016-08-05 11:52:09,587 [main] DEBUG namenode.NameNode (NameNode.java:initializeGenericKeys(1670)) - Setting fs.defaultFS to hdfs://127.0.0.1:7009
--
target/surefire-reports/org.apache.hadoop.hdfs.TestRenameWhileOpen-output.txt:2523:Will now start MiniDFSCluster with nnport=17516
target/surefire-reports/org.apache.hadoop.hdfs.TestRenameWhileOpen-output.txt-2524-2016-08-05 11:52:20,090 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(465)) - starting cluster: numNameNodes=1, numDataNodes=1
target/surefire-reports/org.apache.hadoop.hdfs.TestRenameWhileOpen-output.txt-2525-2016-08-05 11:52:20,093 [main] DEBUG namenode.NameNode (NameNode.java:initializeGenericKeys(1670)) - Setting fs.defaultFS to hdfs://127.0.0.1:17516
--
target/surefire-reports/org.apache.hadoop.hdfs.TestRenameWhileOpen-output.txt:3450:Will now start MiniDFSCluster with nnport=28234
target/surefire-reports/org.apache.hadoop.hdfs.TestRenameWhileOpen-output.txt-3451-2016-08-05 11:52:30,808 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(465)) - starting cluster: numNameNodes=1, numDataNodes=1
target/surefire-reports/org.apache.hadoop.hdfs.TestRenameWhileOpen-output.txt-3452-2016-08-05 11:52:30,811 [main] DEBUG namenode.NameNode (NameNode.java:initializeGenericKeys(1670)) - Setting fs.defaultFS to hdfs://127.0.0.1:28234
[machine-channapattan hadoop-hdfs (trunk)]$
{code}

So I still can't upload a patch to HDFS jiras. Hence pasting my patch here:

{code}
[machine-channapattan hadoop (trunk)]$ cat ../HDFS-10723.001.patch
diff --git hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestRenameWhileOpen.java hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestRenameWhileOpen.java
index 949fc74..9d6b127 100644
--- hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestRenameWhileOpen.java
+++ hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestRenameWhileOpen.java
@@ -55,10 +55,16 @@ public void testWhileOpenRenameParent() throws IOException {
     conf.setInt(DFSConfigKeys.DFS_HEARTBEAT_INTERVAL_KEY, 1);
     conf.setInt(DFSConfigKeys.DFS_NAMENODE_SAFEMODE_THRESHOLD_PCT_KEY, 1);
     conf.setInt(DFSConfigKeys.DFS_BLOCK_SIZE_KEY, TestFileCreation.blockSize);
+    System.out.println("Test 1*****************************");

+    // try to get a random port number < 65535
+    // hence take mod 65534
+    final int nnport = (int) (System.currentTimeMillis() % 65534);
+    System.out.println("Will now start MiniDFSCluster with nnport=" + nnport);
     // create cluster
-    System.out.println("Test 1*****************************");
-    MiniDFSCluster cluster = new MiniDFSCluster.Builder(conf).build();
+    MiniDFSCluster cluster = new MiniDFSCluster.Builder(conf)
+        .nameNodePort(nnport).format(true).build();
+
     FileSystem fs = null;
     try {
       cluster.waitActive();
@@ -72,8 +78,6 @@ public void testWhileOpenRenameParent() throws IOException {
       doNothing().when(spyLog).endCurrentLogSegment(Mockito.anyBoolean());
       DFSTestUtil.setEditLogForTesting(cluster.getNamesystem(), spyLog);

-      final int nnport = cluster.getNameNodePort();
-
       // create file1.
       Path dir1 = new Path("/user/a+b/dir1");
       Path file1 = new Path(dir1, "file1");
@@ -155,13 +159,18 @@ public void testWhileOpenRenameParentToNonexistentDir() throws IOException {
     conf.setInt(DFSConfigKeys.DFS_NAMENODE_SAFEMODE_THRESHOLD_PCT_KEY, 1);
     System.out.println("Test 2************************************");

+    // try to get a random port number < 65535
+    // hence take mod 65534
+    final int nnport = (int) (System.currentTimeMillis() % 65534);
+    System.out.println("Will now start MiniDFSCluster with nnport=" + nnport);
     // create cluster
-    MiniDFSCluster cluster = new MiniDFSCluster.Builder(conf).build();
+    MiniDFSCluster cluster = new MiniDFSCluster.Builder(conf)
+        .nameNodePort(nnport).format(true).build();
+
     FileSystem fs = null;
     try {
       cluster.waitActive();
       fs = cluster.getFileSystem();
-      final int nnport = cluster.getNameNodePort();

       // create file1.
       Path dir1 = new Path("/user/dir1");
@@ -230,13 +239,18 @@ public void testWhileOpenRenameToExistentDirectory() throws IOException {
     conf.setInt(DFSConfigKeys.DFS_NAMENODE_SAFEMODE_THRESHOLD_PCT_KEY, 1);
     System.out.println("Test 3************************************");

+    // try to get a random port number < 65535
+    // hence take mod 65534
+    final int nnport = (int) (System.currentTimeMillis() % 65534);
+    System.out.println("Will now start MiniDFSCluster with nnport=" + nnport);
     // create cluster
-    MiniDFSCluster cluster = new MiniDFSCluster.Builder(conf).build();
+    MiniDFSCluster cluster = new MiniDFSCluster.Builder(conf)
+        .nameNodePort(nnport).format(true).build();
+
     FileSystem fs = null;
     try {
       cluster.waitActive();
       fs = cluster.getFileSystem();
-      final int nnport = cluster.getNameNodePort();

       // create file1.
       Path dir1 = new Path("/user/dir1");
@@ -295,13 +309,18 @@ public void testWhileOpenRenameToNonExistentDirectory() throws IOException {
     conf.setInt(DFSConfigKeys.DFS_NAMENODE_SAFEMODE_THRESHOLD_PCT_KEY, 1);
     System.out.println("Test 4************************************");

+    // try to get a random port number < 65535
+    // hence take mod 65534
+    final int nnport = (int) (System.currentTimeMillis() % 65534);
+    System.out.println("Will now start MiniDFSCluster with nnport=" + nnport);
     // create cluster
-    MiniDFSCluster cluster = new MiniDFSCluster.Builder(conf).build();
+    MiniDFSCluster cluster = new MiniDFSCluster.Builder(conf)
+        .nameNodePort(nnport).format(true).build();
+
     FileSystem fs = null;
     try {
       cluster.waitActive();
       fs = cluster.getFileSystem();
-      final int nnport = cluster.getNameNodePort();

       // create file1.
       Path dir1 = new Path("/user/dir1");
[machine-channapattan hadoop (trunk)]$
{code}

Would appreciate your feedback., Gentle ping [~kihwal] and [~linyiqun] for your thoughts on the patch posted above. Also, if you could please add me to the contributors list, then I can assign the jira to myself. , When a {{MiniDFSCluster}} is brought up without setting the rpc port, it will binds to a random available port. There is no need to find and specify one. So making it bind to a random port is easy. Take a look at other test cases.

The test might be trying to use the same port for a specific reason. If this is the case, fixing it will be a bit more complicated., Hi, [~vrushalic], some comments from me:

1.We can just removed the method {{nameNodePort(nnport)}} for here as [~kihwal] said if the test is not trying to use the same port. But in this test, I am not so sure for that, because it show this:
{code}
      // restart cluster with the same namenode port as before.
      // This ensures that leases are persisted in fsimage.
{code}
So we may be to confirm for this.

2.I see there were some similar failed test in {{TestFileCreationDelete}}(https://builds.apache.org/job/PreCommit-HDFS-Build/16290/testReport/). If we can also fix in this jira, it will be better. These two tests seems very similar.

3.Just attach your patch and trigger the button {{submit patch}}. If your patch was accepted by the commiters, they will assign this jira to you.

Thanks., Yes, the test does seem to require binding to the previously bound port in that test. My guess is that when the port is set free after the mini cluster is brought down and the test is trying to bind to the same port again, some other process grabs that port in the meantime. I am wondering how this can be controlled. Need to look deeper into how available ports are returned for bind calls with port 0. ]