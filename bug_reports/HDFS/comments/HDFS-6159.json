[{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12636935/HDFS-6159.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/6513//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/6513//console

This message is automatically generated., The balancer will create a balancer.id file (about 10B in sieze) in /system (HDFS) directory when it starts and delete it after it is done. However, this balancer.id file affects cluster's average utilization if a cluster is made of datanodes with limited capacities. In the TestBalancerWithNodeGroup class, each datanode only has 500B total capacity for HDFS and the data block size is 10B. I propose to increase datanode capacity up to 6000B and data block size to 100B.

 Here are the reasons:
1) Increasing datanode capacity can reduce the fluctuation caused by the balancer.id file;
2) To avoid increasing the number of blocks that the balancer needs to move, I increase the block size accordingly.

Patch is available for reviewing., By running this unit test 3 times, The execution time of running TestBalancerWithNodeGroup.testBalancerWithNodeGroup is 29 seconds (timeout is 40s) on my laptop. , Resubmitting the same patch to kick the precommit., {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12638724/HDFS-6159-v2.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/6588//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/6588//console

This message is automatically generated., +1 The patch looks good., I've committed this to trunk and branch-2. Thanks for working on this, Chen., SUCCESS: Integrated in Hadoop-trunk-Commit #5459 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/5459/])
HDFS-6159. TestBalancerWithNodeGroup.testBalancerWithNodeGroup fails if there is block missing after balancer success. Contributed by Chen He. (kihwal: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1584900)
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/balancer/TestBalancerWithNodeGroup.java
, SUCCESS: Integrated in Hadoop-Yarn-trunk #530 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/530/])
HDFS-6159. TestBalancerWithNodeGroup.testBalancerWithNodeGroup fails if there is block missing after balancer success. Contributed by Chen He. (kihwal: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1584900)
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/balancer/TestBalancerWithNodeGroup.java
, FAILURE: Integrated in Hadoop-Mapreduce-trunk #1748 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1748/])
HDFS-6159. TestBalancerWithNodeGroup.testBalancerWithNodeGroup fails if there is block missing after balancer success. Contributed by Chen He. (kihwal: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1584900)
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/balancer/TestBalancerWithNodeGroup.java
, FAILURE: Integrated in Hadoop-Hdfs-trunk #1722 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1722/])
HDFS-6159. TestBalancerWithNodeGroup.testBalancerWithNodeGroup fails if there is block missing after balancer success. Contributed by Chen He. (kihwal: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1584900)
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/balancer/TestBalancerWithNodeGroup.java
, Sorry for just notice this JIRA as it seems more frequently the test get failed recently.
bq. By running this unit test 3 times, The execution time of running TestBalancerWithNodeGroup.testBalancerWithNodeGroup is 29 seconds (timeout is 40s) on my laptop.
Usually for this test, we run 50+ or more iterations to make sure the unit test can pass without failure. Please refer: HDFS-5580 or other JIRAs. , The fix in the patch has some issue:
bq. I propose to increase datanode capacity up to 6000B and data block size to 100B.
{code}
  static final int DEFAULT_BLOCK_SIZE = 100;
{code}
this variable is not used anywhere, change it does not change block size, hence capacity is changed to 6000, block size remains 10 bytes actually leads more blocks needs to be moved, hence increase the total balancer running time, more likely to cause timeout.
, Hi [~djp], 
Run it 100 times. No error reports. Sometimes, failures depend on the run-time environment of the machine that runs the tests.
, This test is failing again.
https://builds.apache.org/job/PreCommit-HDFS-Build/7045//testReport/
[~airbots], can you take a look on this pre-commit?, My pleasure., [~decster], would you take a look at the test failure too?, The test error log:
Rebalancing expected avg utilization to become 0.16, but on datanode 127.0.0.1:55468 it remains at 0.02 after more than 40000 msec.
bug from the balancer log:
{noformat}
2014-06-06 18:15:51,681 INFO  balancer.Balancer (Balancer.java:dispatch(370)) - Successfully moved blk_1073741834_1010 with size=100 from 127.0.0.1:49159 to 127.0.0.1:55468 through 127.0.0.1:49159
2014-06-06 18:15:51,683 INFO  balancer.Balancer (Balancer.java:dispatch(370)) - Successfully moved blk_1073741833_1009 with size=100 from 127.0.0.1:49159 to 127.0.0.1:55468 through 127.0.0.1:49159
2014-06-06 18:15:51,683 INFO  balancer.Balancer (Balancer.java:dispatch(370)) - Successfully moved blk_1073741830_1006 with size=100 from 127.0.0.1:49159 to 127.0.0.1:55468 through 127.0.0.1:49159
2014-06-06 18:15:51,683 INFO  balancer.Balancer (Balancer.java:dispatch(370)) - Successfully moved blk_1073741831_1007 with size=100 from 127.0.0.1:49159 to 127.0.0.1:55468 through 127.0.0.1:49159
2014-06-06 18:15:51,682 INFO  balancer.Balancer (Balancer.java:dispatch(370)) - Successfully moved blk_1073741832_1008 with size=100 from 127.0.0.1:49159 to 127.0.0.1:55468 through 127.0.0.1:49159
2014-06-06 18:15:54,702 INFO  balancer.Balancer (Balancer.java:dispatch(370)) - Successfully moved blk_1073741827_1003 with size=100 from 127.0.0.1:49159 to 127.0.0.1:55468 through 127.0.0.1:49159
2014-06-06 18:15:54,702 INFO  balancer.Balancer (Balancer.java:dispatch(370)) - Successfully moved blk_1073741828_1004 with size=100 from 127.0.0.1:49159 to 127.0.0.1:55468 through 127.0.0.1:49159
2014-06-06 18:15:54,701 INFO  balancer.Balancer (Balancer.java:dispatch(370)) - Successfully moved blk_1073741829_1005 with size=100 from 127.0.0.1:49159 to 127.0.0.1:55468 through 127.0.0.1:49159
We can see than there are 8 blocks(800 bytes) moved to 127.0.0.1:55468, the utilization of this datanode should be 0.16(800/5000).
{noformat}
But at the same time, those blocks are deleted by block manager:
{noformat}
2014-06-06 18:15:54,706 INFO  BlockStateChange (BlockManager.java:chooseExcessReplicates(2711)) - BLOCK* chooseExcessReplicates: (127.0.0.1:55468, blk_1073741833_1009) is added to invalidated blocks set
2014-06-06 18:15:54,709 INFO  BlockStateChange (BlockManager.java:chooseExcessReplicates(2711)) - BLOCK* chooseExcessReplicates: (127.0.0.1:55468, blk_1073741834_1010) is added to invalidated blocks set
2014-06-06 18:15:56,421 INFO  BlockStateChange (BlockManager.java:invalidateWorkForOneNode(3242)) - BLOCK* BlockManager: ask 127.0.0.1:55468 to delete [blk_1073741833_1009, blk_1073741834_1010]
2014-06-06 18:15:57,717 INFO  BlockStateChange (BlockManager.java:chooseExcessReplicates(2711)) - BLOCK* chooseExcessReplicates: (127.0.0.1:55468, blk_1073741832_1008) is added to invalidated blocks set
2014-06-06 18:15:57,720 INFO  BlockStateChange (BlockManager.java:chooseExcessReplicates(2711)) - BLOCK* chooseExcessReplicates: (127.0.0.1:55468, blk_1073741827_1003) is added to invalidated blocks set
2014-06-06 18:15:57,721 INFO  BlockStateChange (BlockManager.java:chooseExcessReplicates(2711)) - BLOCK* chooseExcessReplicates: (127.0.0.1:55468, blk_1073741830_1006) is added to invalidated blocks set
2014-06-06 18:15:57,722 INFO  BlockStateChange (BlockManager.java:chooseExcessReplicates(2711)) - BLOCK* chooseExcessReplicates: (127.0.0.1:55468, blk_1073741831_1007) is added to invalidated blocks set
2014-06-06 18:15:57,723 INFO  BlockStateChange (BlockManager.java:chooseExcessReplicates(2711)) - BLOCK* chooseExcessReplicates: (127.0.0.1:55468, blk_1073741829_1005) is added to invalidated blocks set
2014-06-06 18:15:59,422 INFO  BlockStateChange (BlockManager.java:invalidateWorkForOneNode(3242)) - BLOCK* BlockManager: ask 127.0.0.1:55468 to delete [blk_1073741827_1003, blk_1073741829_1005, blk_1073741830_1006, blk_1073741831_1007, blk_1073741832_1008]
2014-06-06 18:16:02,423 INFO  BlockStateChange (BlockManager.java:invalidateWorkForOneNode(3242)) - BLOCK* BlockManager: ask 127.0.0.1:55468 to delete [blk_1073741845_1021]
{noformat}
At last, only block blk_1073741828_1004 is left on 127.0.0.1:55468, so the final utilizition is(100/5000=0.02)
Those blocks are newly moved by balancer and should not be invalidated by block manager. Most likely some logic in BlockManager.java invalidate blocks is broken? Look at the svn log, recently there are some change in BlockManager invalidate block. (HDFS-6424, HDFS-6362).
Perhaps [~jingzhao] or [~arpitagarwal] can help look at this? , Thanks [~decster] for investigation on it. I will ping [~arpitagarwal] at HDFS-6362 for this., Hi [~djp], looks unrelated to HDFS-6362 from a quick look. I also took a quick look at HDFS-6424 and it appears unrelated.

Please feel free a separate Jira for the test failure and attach the logs/analysis., Thanks [~djp] and [~arpitagarwal] for the comments, I create  HDFS-6506 to track this. ]