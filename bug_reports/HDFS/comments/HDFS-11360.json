[It was originally done that way for the federation feature.  Whatever approach you take should not break it., Hi [~cltlfcjin],

Did you try "dfs.internal.nameservices" ?, Yes, "dfs.internal.nameservices" has been set to of of them "one-nn-ha".
No data transferred between them by searching the log but the Balancer worked two jobs., Found the log below:
{code}
INFO org.apache.hadoop.hdfs.server.balancer.Balancer: namenodes  = [hdfs://one-nn-ha, hdfs://two-nn-ha]
{code}

Is this design on purpose or a bug?
In the run method of Balancer.Cli, it just uses DFSUtil class to get the namenode list. The getNsServiceRpcUris method uses "dfs.nameservices". 
{code:java}
        final Collection<URI> namenodes = DFSUtil.getNsServiceRpcUris(conf);
{code}

And it create a Balancer instance for each: (in the run of Balancer)
{code:java}
    Collections.shuffle(connectors);
        for(NameNodeConnector nnc : connectors) {
          final Balancer b = new Balancer(nnc, p, conf);
          final Result r = b.runOneIteration();
          ...
{code}

I am afraid that most of user cases of Balancer need to set different configuration and to start independency instance., In the official document https://hadoop.apache.org/docs/r2.7.2/hadoop-project-dist/hadoop-hdfs/Federation.html#Balancer
The Balancer has been changed to work with multiple Namenodes.
And we can set the datanode policy or blockpool policy. Whatever policy set, one Balancer instance always takes charge of all nameservices.

BTW, the default policy is datanode policy:
{code}
    // Defaults
    private BalancingPolicy policy = BalancingPolicy.Node.INSTANCE;
{code}

But our use case isn't the federation cluster. Two nameservices set in hdfs-site.xml is just for using distcp. 
So the actual behavior in two clusters degrades into blockpool policy from default datanode one (Block removing only occurs in the same cluster).

So I think if we need to add a configuration to setting a decided nameservice when start a Balancer instance., Hi [~cltlfcjin]

//To find namenodes in the cluster

final Collection<URI> namenodes = DFSUtil.getNsServiceRpcUris(conf);
 If DFS_INTERNAL_NAMESERVICES_KEY is set, the above method returns only namenode that belong to this cluster.

 

As in your case it is not federated cluster, you can set dfs.internal.nameservices to avoid the above scenario you have mentioned.

As, DFSUtil.getInternalNsRpcUris(), calls getInternalNameServices(), which will return the value of dfs.internal.nameservices value if it is set, otherwise it will use dfs.nameservices and return all the nameservices. So, if dfs.internal.nameservices is set, it will only create one NameNodeConnector.

 

Could you please let me know if i am missing something here., Actually, the bug has been fixed in HDFS-9365 now.
In the run() method of Balancer.Cli.
{code}
        final Collection<URI> namenodes = DFSUtil.getInternalNsRpcUris(conf);
{code}

Closed]