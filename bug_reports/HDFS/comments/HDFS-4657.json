[The issue is that in {{BlockManager#processReport}} we use the following logic to determine whether or not a block report is the initial block report from a DN:

{code}
if (node.numBlocks() == 0) {
  // The first block report can be processed a lot more efficiently than
  // ordinary block reports.  This shortens restart times.
  processFirstBlockReport(node, newReport);
} else {
  processReport(node, newReport);
}
{code}

However in the DN code which actually performs the block report ({{BPServiceActor#blockReport}}) we always send the incremental report before doing the full report:

{code}
// Flush any block information that precedes the block report. Otherwise
// we have a chance that we will miss the delHint information
// or we will report an RBW replica after the BlockReport already reports
// a FINALIZED one.
reportReceivedDeletedBlocks();

// Create block report
long brCreateStartTime = now();
BlockListAsLongs bReport = dn.getFSDataset().getBlockReport(
    bpos.getBlockPoolId());

// Send block report
long brSendStartTime = now();
StorageBlockReport[] report = { new StorageBlockReport(
    new DatanodeStorage(bpRegistration.getStorageID()),
    bReport.getBlockListAsLongs()) };
cmd = bpNamenode.blockReport(bpRegistration, bpos.getBlockPoolId(), report);
{code}

Most of the time when the NN is starting up the DN won't have any pending received or deleted blocks since the NN will have been down and couldn't have been allocating new blocks for clients or issuing deletes. However, in the HA case, the active NN may have been up and running just fine allocating blocks while the standby NN was down. In this case when the standby NN starts up it will receive an incremental block report first and if any of these blocks are not queued for later processing (i.e. the standby has received the edit logs containing the block allocation) it will result in the first full BR being identified as a non-initial BR, thus logging the addition of every block.

I can think of a few solutions to this issue:

# We could try to ensure that a DN never sends an incremental block report after registering with an NN before a full block report is sent.
# We could change the logic at the NN for determining whether or not a full BR is the initial full BR. Instead of checking whether or not any blocks have yet been reported for the node, we could add a boolean per-DN that expressly signifies whether or not a full BR has been processed by this NN for this DN yet.
# We could make it so that full block reports, regardless of whether or not they are the initial block report from a DN, do not log every block. On one hand this may be overkill since the only time I've seen this cause a problem is during SBN restart, but on the other hand it doesn't seem like a good idea to me to ever log every block reported by a DN, whether it's the initial full BR or a later full BR.

I think I'm leaning toward option #3.

Thoughts?, I agree something like #3 makes sense. Let's just put a limit on the number of blocks logged in any BR (something like 1000 or even 10000)., Here's a quick patch which implements option #3. No tests are included since this just amounts to a logging change., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12591790/HDFS-4657.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/4626//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/4626//console

This message is automatically generated., I agree.  Putting a limit on the number of blocks we print out to the log seems sensible.

The patch looks good, too.

+1.  Will commit shortly if there are no more comments., committed to branch-2 and trunk, SUCCESS: Integrated in Hadoop-trunk-Commit #4093 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/4093/])
HDFS-4657.  Limit the number of blocks logged by the NN after a block report to a configurable value.  (Aaron Twinning Meyers via Colin Patrick McCabe) (cmccabe: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1503862)
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSConfigKeys.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java
, SUCCESS: Integrated in Hadoop-Yarn-trunk #273 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/273/])
HDFS-4657.  Limit the number of blocks logged by the NN after a block report to a configurable value.  (Aaron Twinning Meyers via Colin Patrick McCabe) (cmccabe: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1503862)
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSConfigKeys.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java
, FAILURE: Integrated in Hadoop-Hdfs-trunk #1463 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1463/])
HDFS-4657.  Limit the number of blocks logged by the NN after a block report to a configurable value.  (Aaron Twinning Meyers via Colin Patrick McCabe) (cmccabe: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1503862)
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSConfigKeys.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java
, SUCCESS: Integrated in Hadoop-Mapreduce-trunk #1490 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1490/])
HDFS-4657.  Limit the number of blocks logged by the NN after a block report to a configurable value.  (Aaron Twinning Meyers via Colin Patrick McCabe) (cmccabe: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1503862)
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSConfigKeys.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java
, SUCCESS: Integrated in Hadoop-trunk-Commit #4668 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/4668/])
move HDFS-4657 to branch-2.2.1 (cmccabe: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1536887)
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
, SUCCESS: Integrated in Hadoop-Yarn-trunk #378 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/378/])
move HDFS-4657 to branch-2.2.1 (cmccabe: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1536887)
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
, FAILURE: Integrated in Hadoop-Hdfs-trunk #1568 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1568/])
move HDFS-4657 to branch-2.2.1 (cmccabe: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1536887)
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
, FAILURE: Integrated in Hadoop-Mapreduce-trunk #1594 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1594/])
move HDFS-4657 to branch-2.2.1 (cmccabe: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1536887)
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
]