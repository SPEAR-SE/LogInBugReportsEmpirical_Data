[I suspect we'll need to arrange for the edit log loading code path to call {{FSDirectory#unprotectedSetCacheReplication}} instead.  This is similar to how {{OP_SET_REPLICATION}} is handled.

I wondered why {{TestCacheReplicationManager#testCacheManagerRestart}} didn't catch this problem.  It turns out this is because the test only adds cache directives for paths that don't exist, so on restart, {{CacheManager#unprotectedAddEntry}} skips the call to {{FSNamesystem#setCacheReplicationInt}}.  I see this in my test logs:

{code}
2013-10-06 15:09:13,843 WARN  namenode.CacheManager (CacheManager.java:unprotectedAddEntry(180)) - Path /party-0 is not a file
{code}

I suggest that we update the test so that it really creates those files.

I also wondered why I didn't catch this in my earlier manual testing of HDFS-5119.  I suspect I masked the problem by running {{hdfs dfsadmin -saveNamespace}} to force a checkpoint.

Following is the full stack trace showing where this blocks.  

{code}
"main" prio=10 tid=0x00007fc344010000 nid=0x1238 waiting on condition [0x00007fc34c14f000]
   java.lang.Thread.State: TIMED_WAITING (parking)
        at sun.misc.Unsafe.park(Native Method)
        - parking to wait for  <0x00000000c214a868> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:226)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2173)
        at org.apache.hadoop.hdfs.server.namenode.FSDirectory.waitForReady(FSDirectory.java:247)
        at org.apache.hadoop.hdfs.server.namenode.FSDirectory.setCacheReplication(FSDirectory.java:1108)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.setCacheReplicationInt(FSNamesystem.java:1945)
        at org.apache.hadoop.hdfs.server.namenode.CacheManager.unprotectedAddEntry(CacheManager.java:178)
        at org.apache.hadoop.hdfs.server.namenode.CacheManager.unprotectedAddDirective(CacheManager.java:253)
        at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.applyEditLogOp(FSEditLogLoader.java:647)
        at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadEditRecords(FSEditLogLoader.java:205)
        at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadFSEdits(FSEditLogLoader.java:118)
        at org.apache.hadoop.hdfs.server.namenode.FSImage.loadEdits(FSImage.java:730)
        at org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:644)
        at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:261)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:812)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:590)
        at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:445)
        at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:493)
        at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:691)
        at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:676)
        at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1265)
        at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1331)
{code}
, This code path is changing in HDFS-5096 to fix this and other issues, so we should probably dupe this JIRA to that one., FYI, I'll retest this while reviewing HDFS-5096 (and likely resolve as duplicate)., I've confirmed that HDFS-5096 fixes this bug.]