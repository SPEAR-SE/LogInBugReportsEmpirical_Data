[ After deeper look into this issue.
To fix this,thinking like following
  1) ByteRangeInputStream (can be handledled as part of HDFS-3671) or
  2) Test code ( like HDFS-3577)

Seen Earlier Jira's ( HDFS-3577,HDFS-3671 and HDFS-3788) handled by [~szetszwo],[~daryn],[~eli]  and [~tucu00], do you have any inputs for this jira..?

Please correct me,If I am wrong.., [~szetszwo],[~daryn]rp,[~eli],[~tucu00] and [~ajisakaa] any thoughts on this..?, Looks like content-length header is not included in 206 (Partial Content) response. I'm thinking we should parse Content-Range header to get the content length in the following code if content-length header is missing and response code is 206.
{code:title=ByteRangeInputStream.java}
      final String cl = connection.getHeaderField(HttpHeaders.CONTENT_LENGTH);
      if (cl == null) {
        throw new IOException(HttpHeaders.CONTENT_LENGTH + " is missing: "
            + headers);
      }
{code}, Thanks [~ajisakaa] for response.. Initially I also thought like this,But I faced number format exception while getting the  streamlength(since content length will come as "bytes 7-9/10").

{code}final long streamlength = Long.parseLong(cl);{code}

Then I thought of doing like following...

 {code}
InputStream in = connection.getInputStream();
    if (cl != null) {
      // Java has a bug with >2GB request streams.  It won't bounds check
      // the reads so the transfer blocks until the server times out
      in = new BoundedInputStream(in, Long.parseLong(cl));
     }
 {code}, bq. But I faced number format exception while getting the streamlength(since content length will come as "bytes 7-9/10").
I'm thinking we can parse it by the method as follows:
{code}
private static long getLengthFromRange(String range) {
  String[] str = range.substring(6).split("[-/]");
  return Long.parseLong(str[1]) - Long.parseLong(str[0]) + 1;
}
{code}, Yes,this should be fine.. Attached patch..Kindly review the same.., Applied attached patch and ran the testcases, all are passing...:), {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12705082/HDFS-7881.patch
  against trunk revision 7179f94.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/9919//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/9919//console

This message is automatically generated., Test failures are unrelated this jira.., Thanks [~brahmareddy] for creating the patch! Two high-level comments:
* Would you create a method to get the stream length for improving readability for {{#openInputStream}}? I'd like to make the code as follows:
{code}
    } else {
      long streamLength = getStreamLength(connection);
      fileLength = startPos + streamLength;

      // Java has a bug...
      in = ...
    }
(snip)
  }

  private static long getStreamLength(HttpURLConnection connection)
      throws IOException {
    ...
  }
{code}
* The code for parsing the range can throw {{NumberFormatException}} and {{ArrayIndexOutOfBoundsException}}, which are unchecked. I'd like to catch these unchecked exception and throw checked {{IOException}} to notify "failed to get content length by parsing the content range".

Other comments:
{code}
        if (connection.getResponseCode() == 206) {
{code}
* 206 should be {{HttpStatus.SC_PARTIAL_CONTENT}}.
* It would be better to add a comment "why we parse the content range". The example is:
{code}
        // Try to get the content length by parsing the content range
        // because HftpFileSystem does not return the content length
        // if the content is partial.
{code}

{code}
    String[] str = range.substring(6).split("[-/]");
    return Long.parseLong(str[1]) - Long.parseLong(str[0]) + 1;
{code}
* It would be better to comment what input is expected and how it is parsed. (Hint: The input is expected to be created by {{org.mortbay.jetty.InclusiveByteRange#toHeaderRangeString}}.), [~ajisakaa] thanks a lot for review...Updated the patch based on your review comments...Kindly review the same.., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12705543/HDFS-7881-002.patch
  against trunk revision 93d0f4a.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.tracing.TestTracing

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/9974//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/9974//console

This message is automatically generated., Thanks [~brahmareddy] for the update. Mostly looks good to me. Some minor comments:

{code}
  // Try to get the content length by parsing the content range
  // because HftpFileSystem does not return the content length
  // if the content is partial.
{code}
1. I'm thinking it's better to add the above comment  between
{code}
    if (cl == null) {
{code}
and
{code}
      if (connection.getResponseCode() == HttpStatus.SC_PARTIAL_CONTENT) {
{code}
.
{code}
    } catch (Exception ie) {
{code}
2. {{ie}} should be {{e}} since the expected exceptions are not {{IOException}}.

{code}
      throw new IOException(
          "failed to get content length by parsing the content range");
{code}
3. Would you add {{range}} and the original error message ({{e.getMessage()}}) to the error message?, Updated the patch based on your comments.Kindly review.thanks!!, Updated the patch based on your comments.Kindly review.thanks!!, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12706360/HDFS-7881-003.patch
  against trunk revision 4335429.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.tracing.TestTracing

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/10021//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/10021//console

This message is automatically generated., Testcase failures are unrelated this jira, Thanks [~brahmareddy] for the update. Three minor nits:
1. Would you remove TODO comments?
{code}
+          "failed to get content length by parsing the content range: " + cl + " " + e.getMessage());
{code}
2. Would you render the line within 80 characters?
{code}
+  private static  long getStreamLength(HttpURLConnection connection,
{code}
3. Would you please remove a whitespace between static and long?
I'm +1 if these are addressed., Updated the Patch..Thanks!!!, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12706557/HDFS-7881-004.patch
  against trunk revision 82eda77.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.tracing.TestTracing
                  org.apache.hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA

                                      The following test timeouts occurred in hadoop-hdfs-project/hadoop-hdfs:

org.apache.hadoop.hdfs.server.blockmanagement.TestDatanodeManager

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/10031//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/10031//console

This message is automatically generated., +1. Committed this to branch-2 and branch-2.7. Thanks [~brahmareddy] for the contribution., These test failures look unrelated to the patch., Thanks a lot !!!!]