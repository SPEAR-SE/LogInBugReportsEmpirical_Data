[If the same user (i.e. the same UGI instance) talks to the same namenode via RPC, a connection will be shared.  If the files system cache is disabled, the sharing cannot happen. Are those requests being made by separate processes?, You quoted {{ClientDatanodeProtocol}}, so I guess they are the connections made to datanodes. That's different.

Please explain what your patch does, if you don't want to post it. The design probably assumed a typical client consuming small number of files.  We need to re-evaluate the design. I do think it is worth fixing., Correct. This issue (new connection for every call) only happens to Hbase RS --> local DataNode connections. RS --> NameNode connections are always reused., I don't understand why the client needs to make a dummy UGI to access datanode, so I made it to use the current UGI and do not reset maxIdleTime. My hack is probably not correct but there you go:

{code}
diff --git a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/ClientDatanodeProtocolTranslatorPB.java b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/ClientDatanodeProtocolTranslatorPB.java
index 19ef9ec0155..660b4e902ce 100644
--- a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/ClientDatanodeProtocolTranslatorPB.java
+++ b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/ClientDatanodeProtocolTranslatorPB.java
@@ -164,14 +164,15 @@ static ClientDatanodeProtocolPB createClientDatanodeProtocolProxy(
     // This is a temporary fix: callers should really achieve this by using
     // RPC.stopProxy() on the resulting object, but this is currently not
     // working in trunk. See the discussion on HDFS-1965.
-    Configuration confWithNoIpcIdle = new Configuration(conf);
+    /*Configuration confWithNoIpcIdle = new Configuration(conf);
     confWithNoIpcIdle.setInt(CommonConfigurationKeysPublic
         .IPC_CLIENT_CONNECTION_MAXIDLETIME_KEY, 0);
-
-    UserGroupInformation ticket = UserGroupInformation
-        .createRemoteUser(locatedBlock.getBlock().getLocalBlock().toString());
+    */
+    UserGroupInformation ticket = UserGroupInformation.getCurrentUser();
+        /*UserGroupInformation
+        .createRemoteUser(locatedBlock.getBlock().getLocalBlock().toString());*/
     ticket.addToken(locatedBlock.getBlockToken());
-    return createClientDatanodeProtocolProxy(addr, ticket, confWithNoIpcIdle,
+    return createClientDatanodeProtocolProxy(addr, ticket, conf,
         NetUtils.getDefaultSocketFactory(conf), socketTimeout);
   }
{code}
I applied the patch on a cluster and ran ycsb, which seems to run just fine., Thanks [~jojochuang] for working on this issue.

Hi [~jnp] and [~kzhang],

You guys worked on HDFS-992 which introduced the code to create a UGI each time the code Wai-Chiu modified above. Would you please share the reason why we have to create a new UGI here?

If we create a new UGI each time (like how the current code looks like), and a new Subject instance is created within the UGI construction, it made the connection sharing impossible, even for the same user when accessing the same DataNode.   Notice that another jira HDFS-1965 [~tlipcon] did is based on the observation that the connections can not be shared here.

On the other hand, Wei-Chiu's change to use {{UserGroupInformation.getCurrentUser()}} seems to make sense to me, this way, the connection for the same user can be shared. 

Would you please help to comment here?

Very much appreciated.

,    BlockTokenSelector uses only Token-Kind to match the token, therefore you would need to either change the selector, or make sure the UGI has only one token. The current-user could be trying to read/write multiple files in parallel, and therefore, dealing with multiple tokens at an instant. 
   
   , Many thanks [~jnp], that make sense!

If we could make the BlockTokenSelector also check block id, when finding it's a block token, it would help, but it looks not an easy thing to do at all.




, [~yzhangal], The block token is also being used to authorize the access to a block. Therefore, a connection context must be established using that particular block token. 
   In method {{DataNode#checkReadAccess}}. The block-id from the token-identifier in the UGI is used to authorize the access. Therefore, sharing of connections for different block tokens will likely expose a security risk. , In the data transfer protocol we just pass tokens with each operation. Could the relevant RPCs just be modified to take tokens as parameters rather than using them as part of the connection context?, Thanks a lot [~jnp] and [~tlipcon]!

I did some study and figure out this: Connection is associated with a Socket, which allows only one input stream and one output stream, if we really want to share the same Connection to a DN for multiple blocks, we need to handle multiplexing, which we don't do.

So I think we can conclude that the current design is, one Connection can only be used for one block at the same time. 

If we are to implement multiplexing in the future, can either take Todd's suggestion of passing tokens as parameter, or modify Token Selector to select not only token type, but also block id for BlockToken.

Thanks.


, Not following what you mean by "implement multiplexing in the future" -- it's already the case that we share a single connection from multiple proxies so long as the UGI matches, isn't it? The ipc.Client class has a Map<ConnectionId, Connection> and the UGI makes up part of the ConnectionId. So simply using a non-block-token-based UGI and then passing the token as a call parameter ought to be sufficient to share a single connection.]