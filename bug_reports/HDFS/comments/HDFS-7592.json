[We fixed the bug as followsing patch., We fix the bug as followsing patch https://issues.apache.org/jira/secure/attachment/12690738/blocksmap-2015-01-08.patch, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12690738/blocksmap-2015-01-08.patch
  against trunk revision a6ed489.

    {color:red}-1 patch{color}.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/9153//console

This message is automatically generated., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12690806/HDFS-7592.patch
  against trunk revision a6ed489.

    {color:red}-1 patch{color}.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/9154//console

This message is automatically generated., I use git diff command to regenerate the patch file
:https://issues.apache.org/jira/secure/attachment/12690806/HDFS-7592.patch, I use git diff command to regenerate the patch:
https://issues.apache.org/jira/secure/attachment/12690806/HDFS-7592.patch
This patch is for hadoop branch-0.21., Thanks for the report JichengSong. I'm not sure how your patch could fix a memory leak if it was there. http://docs.oracle.com/javase/7/docs/api/java/util/Map.html#put%28K,%20V%29 states
bq.  If the map previously contained a mapping for the key, the old value is replaced by the specified value. 
Could you please explain?, When DFSClient finish writing and close a file, NameNode will call NameNode.complete(String src, String clientName, Block last)  to replace last BlockInfoUnderConstruction to a new BlockInfoï¼Œ which needs replacing BlocksMap Entry<oldBlock,oldBlock> to Entry<newBlock,newBlock>. But newBlock has the same hashcode with oldBlock and oldBlock.equals to newBlock due to current implementation of hashcode() and equals() method which is overrided in Block.  When BlocksMap.replaceBlock(newBlock) calls map.put(newBlock,newBlock), the Entry<oldBlock,oldBlock> changes to Entry<oldBlock,newBlock> instead of Entry<newBlock,newBlock>.  And oldBlock is not freed which leads to a memory leak.
In JDK1.6, HashMap.put(K key, V value) just replace the value when key hit.
--------------------------HashMap.put-------------------------------------------
    public V put(K key, V value) {
        if (key == null)
            return putForNullKey(value);
        int hash = hash(key.hashCode());
        int i = indexFor(hash, table.length);
        for (Entry<K,V> e = table[i]; e != null; e = e.next) {
            Object k;
            if (e.hash == hash && ((k = e.key) == key || key.equals(k))) {
                V oldValue = e.value;
                //note: only replace the value.
                e.value = value;
                e.recordAccess(this);
                return oldValue;
            }
        }

        modCount++;
        addEntry(hash, key, value, i);
        return null;
    }, This is no longer an issue as BlockUnderConstruction has become a feature class after the merge of EC branch.]