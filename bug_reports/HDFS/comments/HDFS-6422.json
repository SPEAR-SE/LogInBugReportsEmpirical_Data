[I've attached a patch that addresses this issue.
, Hey Charles, thanks for working on this. I had a few review comments:

* I see you did some cleanup in XAttrCommands. I think we need to move the {{out.println(header)}} in the first if statement up by one line. We should still print the header as long as the file exists, even if it doesn't have any xattrs.
* There are a couple issues with the exception logic in FSNamesystem. One is if the user asks for an xattr in either an unknown or disallowed namespace. Another is if the user asks for multiple xattrs and one of them is not present. The filtering makes sense for the {{getAll}} case, but for the other case, we need to throw if a specifically requested xattr is not available or present.
* We could actually do the bulk of this testing in the Java API, since the shell sets the error code on an exception. The Java API is better since it's faster, more concise, and lets us more easily verify expected exceptions and return values. We could have a short sanity test with the shell, but it can't handle things like requesting multiple xattrs right now., [~andrew.wang] and I discussed this offline. We also ran some tests on the ext4 extended attribute functions. It appears that getfattr always returns names and values. listfattr ionly returns names. The new HDFS listxattr api will be covered separately under HDFS-6375. The attached diff covers getting HDFS getfattr to mimic the Linux/ext4 functionality. To wit:

Throw an exception if:
.  the caller requests an attribute that doesn't exist,
.  the caller requests an attribute and they don't have proper permissions, 
.  the caller requests an attribute and they don't have permission to the namespace. This applies to the trusted namespace.
.  the caller specifies an unknown namespace.

The gist of Linux extended attribute permissions is that you need access to the inode to read/write xattr names and you need access to the entity itself (i.e. a file or directory) to read/write xattr values. The former is determined by the parent directory permissions and the latter by the entity's permissions (i.e. the thing on which the extended attributes are associated).

You need scan/execute permissions on the parent (owning) directory to access extended attribute names. You need read permission on the entity itself to read extended attribute values and you need write permission to modify them.

The patch purports to implement those semantics and adds appropriate unit tests for the same.
, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12645658/HDFS-6422.2.patch
  against trunk revision .

    {color:red}-1 patch{color}.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/6949//console

This message is automatically generated., rebased., Hey Charles, thanks for the patch. I had some review comments:

* Rather than adding a boolean return type to FSDirectory#removeXAttr, why not just throw an exception? It'll bubble all the way up.
* FSNamesystem, for the comments, would "EXECUTE on the" and "WRITE on the" read better?

FSN#getXAttrs
* We might be able to get rid of {{filteredXAttrs}} since it looks like it's just {{xAttrs}} now. It's somewhat misnamed now too, since the provided list is no longer filtered by the PermissionFilter, it's checked.
* We shouldn't shortcut out if {{filteredXAttrs.isEmpty()}}, this didn't really make sense in the first place since an exception should be thrown if you don't have access to the path even if all your xattrs are filtered out. This should be moved down to the {{else}} block after the permission checks.
* Line over 80 chars.
* When would {{toGet.size()}} be zero? I ask because I'd rather just inline the Exception message than making it a constant. I think Java does the right thing automatically, so there's no efficiency gain by pulling it out.

Tests:
* s/doSetXattr/doSetXAttr/. This function also moved in the diff for some reason.
* TestDFSShell, Not sure what's going on here, the diff is hard to read. Was removing testSetXAttrPermissionAsDifferentOwner intentional?
* If my comment about the incorrect shortcut is correct, it'd be good to have tests on a no-permission and/or non-existent path to make sure that these always throw an exception.
* I believe that the permission type is called "search" not "scan". It's typically called "execute" for files and "search" for directories (see {{man chmod(1)}})., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12646119/HDFS-6422.3.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 2 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.web.TestWebHDFSXAttr

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/6951//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/6951//console

This message is automatically generated., I talked with Charles about this, and we're blocked until the WebHDFS XAttr methods also throw an exception in the case where the names are not present. Right now the entire list is passed to the client side and then filtered, which is not the best choice since it's inefficient and precludes us from doing server-side smarts on par with the Java APIs. We can either fix that here, or do it in another JIRA first., Thanks Andrew, and Charles, I create HDFS-6464 to "add xattr.names parameter for WebHDFS getXAttrs.", and will fix it in the two days. Then you can continue., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12646119/HDFS-6422.3.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 2 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.web.TestWebHDFSXAttr

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/7000//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/7000//console

This message is automatically generated., [~clamb], would you like to resume the work here? Bug - HDFS-6464 committed., [~yi.a.liu], [~umamaheswararao],

Given Uma's work on HDFS-6556, I want to clarify what remains to be done on this patch. Earlier in the comments, I said:

{quote} 
Throw an exception if:
. the caller requests an attribute that doesn't exist,
. the caller requests an attribute and they don't have proper permissions,
. the caller requests an attribute and they don't have permission to the namespace. This applies to the trusted namespace.
. the caller specifies an unknown namespace.

The gist of Linux extended attribute permissions is that you need access to the inode to read/write xattr names and you need access to the entity itself (i.e. a file or directory) to read/write xattr values. The former is determined by the parent directory permissions and the latter by the entity's permissions (i.e. the thing on which the extended attributes are associated).

You need scan/execute permissions on the parent (owning) directory to access extended attribute names. You need read permission on the entity itself to read extended attribute values and you need write permission to modify them.
{quote}

Do you believe you have the permissions checking correct now and that only the exception throwing needs to be fixed or is there still more work to be done on read permissions? Specifically, that we should be validating xattr name access based on scan permission on the inode's owning directory and xattr value access based on the inode's permission?
, Thanks for summarizing pending things.
{quote}
 that we should be validating xattr name access based on scan permission on the inode's owning directory and xattr value access based on the inode's permission?
{quote}
For writing Xattrs, the current permissions covered. From your comment in list Xattrs, we may need owner's check as well I think.
{code}
 /* To access xattr names, you need EXECUTE in the owning directory. */
 checkParentAccess(pc, src, FsAction.EXECUTE);
{code}
current check validates only execute permissions on parent dir. But it is not caring whether you are owner for the current directory or not. What do you say?
For getXattrs, it will actually get the values there and it has pathaccess check on inode. So, this should be fine. SetXattrs, RemoveXattrs treated as writing xattrs and covered the permission checks appropriately as documented for namespace categories. , Thanks [~umamaheswararao].

So I'll add code to throw exceptions as previously specified and checking the owner for listXAttrs.
, [~umamaheswararao]

Actually, I don't think checking the owner for listXAttrs is correct. In linux, since the equivalent of listXAttrs only requires scan permission on the owning directory, I think we should do the same. Therefore, instead of checkOwner, I think we want to do checkParentAccess(EXECUTE).

Are you ok with that?

, [~clamb], I am ok with existing behavior. Only I put my comment based on the comment in code "/* To access xattr names, you need EXECUTE in the *owning directory*. */", This patch is not completely done yet. I am submitting it to see what the jenkins run looks like so please don't review it yet., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12655867/HDFS-6474.4.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 2 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover
                  org.apache.hadoop.hdfs.TestLeaseRecovery2
                  org.apache.hadoop.hdfs.tools.TestDFSAdminWithHA
                  org.apache.hadoop.hdfs.web.TestWebHDFSXAttr

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/7361//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/7361//console

This message is automatically generated., The failures appear to be unrelated. I have run TestLeaseRecovery2 on my local machine and it passes.

[~umamaheswararao], please feel free to review the .4 patch at your convenience.

, Hey Charles, the TestWebHDFSXAttr test failures are reproducible for me. Looks like a new exception is being thrown. The expected exception text looks nicer, maybe rely on that check instead?, I looked into this more with [~clamb] and there's a compatibility concern with some code in WebHDFS / XAttrNameParam:

{code}
  private static Domain DOMAIN = new Domain(NAME, 
      Pattern.compile("^(user\\.|trusted\\.|system\\.|security\\.).+"));
{code}

Doing client-side validation of the namespace means we can't later add new namespaces and have them also be accessible by an old client. Since we already do server-side validation, I think we can just remove this check.

Let's fix this before we release 2.5.0. Raising priority to a blocker since it's a compat concern and should be easy to fix., I'm submitting this .005 patch for a jenkins run.

Some notes:

This patch changes XAttrNameParam.DOMAIN to match anything rather than try to check the xattr namespace.

This causes the same exception string to be thrown from the xattr namespace check when webhdfs is used as when the regular HDFS client is used.

Here are a few notes for the historical record:

Since WebHDFS doesn't unwrap exceptions, what is thrown is a RemoteException wrapping a HadoopIllegalArgumentException. Using the regular HDFS client, a HadoopIllegalArgumentException is thrown. Any exception translation would/should take place in WebHdfsFileSystem#runWithRetry.

The actual exception is generated server side in XAttrHelper.buildXAttr., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12656165/HDFS-6422.005.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 2 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover
                  org.apache.hadoop.hdfs.tools.TestDFSAdminWithHA
                  org.apache.hadoop.hdfs.web.resources.TestParam

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/7366//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/7366//console

This message is automatically generated., Fixed org.apache.hadoop.hdfs.web.resources.TestParam.testXAttrNameParam failure (the other failures were spurious). Also cleaned up one minor unnecessary whitespace change that was left in .005. Ready for review., {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12656331/HDFS-6422.006.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 3 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/7375//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/7375//console

This message is automatically generated., Thank you, Charles for the patch. Please find my feedback as follows.

 FSNamesystem.java:
- logAuditEvent(false, "getXAttr", src); --> logAuditEvent(false, "getXAttrs", src);


-  .
{code}
} else {
+        throw new IOException("No matching attributes found");
{code}
One suggestion to tell "No matching attributes found to remove"
And this condition makes me to think on retryCache. I hope it is done here let me see there.
Example first call may succeed internally but restarted/disconnected, in that case idempotent API will be retried from client. So, next call may fail as it was already removed. Do you think, we need to mark this as ATMostOnce?
Let me know, if you agree for it, I would be happy to help in fixing that.

- I think below exception message can be refined something like "Some/all attributes does not match to get"? Feel free to think on some other good message as well.
Because the code below throws exception immediately when we don't find even one attribute does not match. So, there may be some attributes matched but we still throw exception.
 {code}
for (XAttr xAttr : xAttrs) {
          boolean foundIt = false;
          for (XAttr a : filteredAll) {
            if (xAttr.getNameSpace() == a.getNameSpace()
                && xAttr.getName().equals(a.getName())) {
              toGet.add(a);
              foundIt = true;
              break;
            }
          }
          if (!foundIt) {
            throw new IOException("No matching attributes found");
          }
        }
{code}

TestDFSShell.java:

- From the below code, we don't need out.toString as we did not asserted anything.
{code}
 {
+        final int ret = ToolRunner.run(fshell, new String[] {
+            "-setfattr", "-n", "user.a1", "-v", "1234", "/foo"});
+        assertEquals("Returned should be 0", 0, ret);
+        final String str = out.toString();
+        out.reset();
+      }
{code}


- We need to shutdown the mini cluster as well.
{code}
} finally {
+      if (bakErr != null) {
+        System.setErr(bakErr);
+      }
+    }
{code}

 FSXAttrBaseTest.java:

- Please handle only specific exceptions. If it throws unexpected exception let it throwout, we need not assert and throw.
{code}
} catch (HadoopIllegalArgumentException e) {
+    } catch (Exception e) {
{code}


- if an an xattr --> if an xattr


- Please do handle specific exceptions.
{code}
 } catch (Exception e) {
+      GenericTestUtils.assertExceptionContains
+          ("An XAttr name must be prefixed with user/trusted/security/system, " +
+           "followed by a '.'",
+          e);
+    }
+
{code}

- XattrNameParam.java:

- 
{code}
private static Domain DOMAIN = new Domain(NAME,
+      Pattern.compile(".*"));
{code}
I understand that we try to eliminate the client validation as we will not have flexibility to add more namespaces in future. But that pattern can be same as <Namespace>. right.
So, how about validating pattern? Please check with Andrew as well what he says. But I have no strong feeling on that. It is a suggestion.


, bq. logAuditEvent(false, "getXAttr", src); --> logAuditEvent(false, "getXAttrs", src);

fixed.

{code}
    } else {
    +        throw new IOException("No matching attributes found");
{code}
Changed to "No matching attributes found for remove operation"

bq.  And this condition makes me to think on retryCache. I hope it is done here let me see there.  Example first call may succeed internally but restarted/disconnected, in that case idempotent API will be retried from client. So, next call may fail as it was already removed. Do you think, we need to mark this as ATMostOnce?

Good catch. You're right that my changes require removeXAttr to
become AtMostOnce. I've changed the code to reflect that.

bq. I think below exception message can be refined something like "Some/all attributes does not match to get"?

I've chnages this to "At least one of the attributes provided was not found."

TestDFSShell.java:

bq. From the below code, we don't need out.toString as we did not asserted anything.

removed.

bq. We need to shutdown the mini cluster as well.

Done.

FSXAttrBaseTest.java:

bq. Please handle only specific exceptions. If it throws unexpected exception let it throwout, we need not assert and throw.

All of this is due to WebHDFS throwing a different exception from the regular path. WebHDFS throws a RemoteException which wraps a HadoopIllegalArgumentException. In other words, the WebHDFS client does not unwrap the exception. You'll see in the diff that I've changed the exception handling to catch both RemoteException and HadoopIllegalArgumentException. In the former case, I check to see that the underlying exception is a HIAE.

XattrNameParam.java:

{code}
    private static Domain DOMAIN = new Domain(NAME,
    +      Pattern.compile(".*"));
{code}

bq. I understand that we try to eliminate the client validation as we will not have flexibility to add more namespaces in future. But that pattern can be same as <Namespace>. right. So, how about validating pattern? Please check with Andrew as well what he says. But I have no strong feeling on that. It is a suggestion.

I understand your concern. The problem is that WebHDFS would then be doing client side checking and the exception would be generated and thrown from two different places. We wanted to unify all of the xattr Namespace checking into one place on the server side so that there would only be one place where the exception would be generated. I talked to Andrew and he's ok with leaving it like it is in the patch.
, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12656959/HDFS-6422.007.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 3 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.server.namenode.TestNamenodeCapacityReport
                  org.apache.hadoop.hdfs.server.namenode.TestNamenodeRetryCache
                  org.apache.hadoop.hdfs.web.TestWebHDFS
                  org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover
                  org.apache.hadoop.hdfs.TestDFSShell
                  org.apache.hadoop.hdfs.server.blockmanagement.TestBlockTokenWithDFS
                  org.apache.hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/7411//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/7411//console

This message is automatically generated., Broken tests were fixed. [~umamaheswararao], it should be ready for review., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12657026/HDFS-6422.008.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 5 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover
                  org.apache.hadoop.hdfs.server.namenode.TestAuditLogs
                  org.apache.hadoop.hdfs.tools.offlineEditsViewer.TestOfflineEditsViewer

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/7415//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/7415//console

This message is automatically generated., Update to handle the OEV failure (editsStored included). Also rebased to latest changes to fs-encryption.

All other test failures from the latest jenkins run were unrelated., Patch looks good to me. Only my last finding/suggestion is, we should have added one test for removeXattr with TestRetryCacheWithHA?

See the test added for setXattr.
{code}
@Test (timeout=60000)
  public void testSetXAttr() throws Exception {
    DFSClient client = genClientWithDummyHandler();
    AtMostOnceOp op = new SetXAttrOp(client, "/setxattr");
    testClientRetryWithFailover(op);
  }
{code}

+1 on addressing this. Assuming jenkins will report +1 too., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12657129/HDFS-6422.009.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 6 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.tools.offlineEditsViewer.TestOfflineEditsViewer

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/7424//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/7424//console

This message is automatically generated., [~umamaheswararao],

Thanks for the review. I agree with your suggestion to add a test for remove xattr in TestRetryCacheWIthHA and the latest patch does that. Jenkins passed everything except that test because there is no way to have it apply the binary file so once that's checked in it should all pass.
, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12657167/HDFS-6422.010.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 6 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.tools.offlineEditsViewer.TestOfflineEditsViewer
                  org.apache.hadoop.hdfs.TestDatanodeConfig
                  org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover
                  org.apache.hadoop.hdfs.server.namenode.TestNamenodeCapacityReport

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/7425//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/7425//console

This message is automatically generated., The TestOfflineEditsViewer test will continue to fail until we checkin editsStored (the test passes for me on my local machine). The other tests appear to be unrelated.
, Thanks a lot, Charles for addressing all the feedback.

+1, latest patch looks good to me. I will commit the patch shortly., I have just committed this to trunk and branch-2. Thanks a lot Charles for the patch., FAILURE: Integrated in Hadoop-trunk-Commit #5953 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/5953/])
HDFS-6422. getfattr in CLI doesn't throw exception or return non-0 return code when xattr doesn't exist. (Charles Lamb via umamahesh) (umamahesh: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1612922)
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/ClientProtocol.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLog.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogLoader.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOp.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/XAttrPermissionFilter.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/resources/XAttrNameParam.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSShell.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/FSXAttrBaseTest.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestNamenodeRetryCache.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestRetryCacheWithHA.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/resources/TestParam.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/resources/editsStored
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/resources/editsStored.xml
, FAILURE: Integrated in Hadoop-Yarn-trunk #622 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/622/])
HDFS-6422. getfattr in CLI doesn't throw exception or return non-0 return code when xattr doesn't exist. (Charles Lamb via umamahesh) (umamahesh: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1612922)
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/ClientProtocol.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLog.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogLoader.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOp.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/XAttrPermissionFilter.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/resources/XAttrNameParam.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSShell.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/FSXAttrBaseTest.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestNamenodeRetryCache.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestRetryCacheWithHA.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/resources/TestParam.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/resources/editsStored
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/resources/editsStored.xml
, FAILURE: Integrated in Hadoop-Hdfs-trunk #1814 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1814/])
HDFS-6422. getfattr in CLI doesn't throw exception or return non-0 return code when xattr doesn't exist. (Charles Lamb via umamahesh) (umamahesh: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1612922)
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/ClientProtocol.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLog.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogLoader.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOp.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/XAttrPermissionFilter.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/resources/XAttrNameParam.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSShell.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/FSXAttrBaseTest.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestNamenodeRetryCache.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestRetryCacheWithHA.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/resources/TestParam.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/resources/editsStored
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/resources/editsStored.xml
, SUCCESS: Integrated in Hadoop-Mapreduce-trunk #1841 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1841/])
HDFS-6422. getfattr in CLI doesn't throw exception or return non-0 return code when xattr doesn't exist. (Charles Lamb via umamahesh) (umamahesh: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1612922)
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/ClientProtocol.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLog.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogLoader.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOp.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/XAttrPermissionFilter.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/resources/XAttrNameParam.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSShell.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/FSXAttrBaseTest.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestNamenodeRetryCache.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestRetryCacheWithHA.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/resources/TestParam.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/resources/editsStored
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/resources/editsStored.xml
]