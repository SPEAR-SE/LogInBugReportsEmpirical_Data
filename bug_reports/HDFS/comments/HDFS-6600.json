[See below for the warnings and stack trace that show up in the NameNode log.  Using -delete instead of -move still works, because that's going straight through the {{NameNodeRpcServer}} for a metadata operation instead of requiring a full client (and therefore authentication of that client).

{code}
2014-06-24 19:09:07,009 WARN  ipc.Client (Client.java:run(672)) - Exception encountered while connecting to the server : org.apache.hadoop.security.AccessControlException: Client cannot authenticate via:[TOKEN, KERBEROS]
2014-06-24 19:09:07,012 WARN  namenode.NameNode (NamenodeFsck.java:lostFoundInit(708)) - Cannot initialize /lost+found .
2014-06-24 19:09:07,012 ERROR namenode.NameNode (NamenodeFsck.java:copyBlocksToLostFound(562)) - copyBlocksToLostFound: error processing /user/vagrant/hello
java.io.IOException: failed to initialize lost+found
        at org.apache.hadoop.hdfs.server.namenode.NamenodeFsck.copyBlocksToLostFound(NamenodeFsck.java:506)
        at org.apache.hadoop.hdfs.server.namenode.NamenodeFsck.check(NamenodeFsck.java:460)
        at org.apache.hadoop.hdfs.server.namenode.NamenodeFsck.fsck(NamenodeFsck.java:233)
        at org.apache.hadoop.hdfs.server.namenode.FsckServlet$1.run(FsckServlet.java:67)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1557)
        at org.apache.hadoop.hdfs.server.namenode.FsckServlet.doGet(FsckServlet.java:58)
        at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
        at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
        at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:511)
        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1221)
        at org.apache.hadoop.security.authentication.server.AuthenticationFilter.doFilter(AuthenticationFilter.java:392)
        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)
        at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1192)
        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)
        at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)
        at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)
        at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:399)
        at org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216)
        at org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:182)
        at org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:766)
        at org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:450)
        at org.mortbay.jetty.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:230)
        at org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)
        at org.mortbay.jetty.Server.handle(Server.java:326)
        at org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:542)
        at org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:928)
        at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:549)
        at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:212)
        at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404)
        at org.mortbay.io.nio.SelectChannelEndPoint.run(SelectChannelEndPoint.java:410)
        at org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:582)
{code}
, Please review the patch

{color:green}+1 overall{color}.  
    {color:green}+1 @author{color}.  The patch does not contain any @author tags.
    {color:green}+1 tests included{color}.  The patch appears to include 2 new or modified test files.
    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.
    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.
    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.
    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 3.0.0) warnings.
    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings., {color:green}+1 overall{color}.  

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 2 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 3.0.0) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.
, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12726715/HDFS-6600.1.PATCH
  against trunk revision c92f6f3.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-common hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient:

                  org.apache.hadoop.mapreduce.v2.app.TestMRApp
                  org.apache.hadoop.mapreduce.v2.app.job.impl.TestTaskAttempt
                  org.apache.hadoop.mapreduce.v2.TestMROldApiJobs
                  org.apache.hadoop.mapreduce.lib.output.TestJobOutputCommitter

                                      The following test timeouts occurred in hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-common hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient:

org.apache.hadoop.mapred.TestJobCleanup
org.apache.hadoop.mapreduce.v2.TestMRJobsWithProfiler

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/10324//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/10324//console

This message is automatically generated., Hello [~krish.dey].  Thank you for taking up this long-standing issue.

I'm curious if this can work by using {{UserGroupInformation.getLoginUser().doAs(...)}} without re-login from the keytab.  The process was already logged in as the NameNode principal during NameNode startup, so I'd expect this to work.  Have you tried testing with the {{SecurityUtil#login}} line removed?

This patch is significantly larger because of reformatting changes.  Thank you for cleaning up the code, but could you please omit reformatting changes from this patch?  That helps reviewers focus on the logic changes.  If you'd still like to contribute clean-up work, then that would be welcome on a separate jira.

Longer term, I really wonder if fsck would benefit from having a private API that simply reassociates blocks to a new path/inode.  This would be something like {{concat}}, except instead of working on a source file path/inode, it would work on a source set of blocks.  It would be a pure metadata operation, so we wouldn't pay the network bandwidth cost of copying file content., HI Chris Nauroth,

I think I have tried using UserGroupInformation.getLoginUser().doAs(...) but will try that once more and let you know.
Will revert the clean up/formatting on the classes and resubmit it.

I agree on the thought of using private API and associates the block to new path/Inode
Thanks
Krish

, +1 overall

 __________ 
< Success! >
 ---------- 
 \     /\  ___  /\
  \   // \/   \/ \\
     ((    O O    ))
      \\ /     \ //
       \/  | |  \/ 
        |  | |  |  
        |  | |  |  
        |   o   |  
        | |   | |  
        |m|   |m| 

| Vote |           Subsystem |  Runtime   | Comment
============================================================================
|   0  |          pre-patch  |  13m 50s   | Pre-patch trunk compilation is 
|      |                     |            | healthy.
|  +1  |            @author  |  0m 00s    | The patch does not contain any 
|      |                     |            | @author tags.
|  +1  |     tests included  |  0m 00s    | The patch appears to include 2 new 
|      |                     |            | or modified test files.
|  +1  |              javac  |  5m 27s    | There were no new javac warning 
|      |                     |            | messages.
|  +1  |            javadoc  |  7m 04s    | There were no new javadoc warning 
|      |                     |            | messages.
|  +1  |      release audit  |  0m 25s    | The applied patch does not increase 
|      |                     |            | the total number of release audit
|      |                     |            | warnings.
|  +1  |         checkstyle  |  1m 09s    | There were no new checkstyle 
|      |                     |            | issues.
|  +1  |         whitespace  |  0m 00s    | The patch has no lines that end in 
|      |                     |            | whitespace.
|  +1  |            install  |  1m 18s    | mvn install still works. 
|  +1  |    eclipse:eclipse  |  0m 41s    | The patch built with 
|      |                     |            | eclipse:eclipse.
|  +1  |           findbugs  |  2m 04s    | The patch does not introduce any 
|      |                     |            | new Findbugs (version 3.0.0)
|      |                     |            | warnings.
|      |                     |  32m 00s   | , Hi Chris,

I have made the modification and the formatting has been reverted.

Please review and let me know.

Thanks
Krish, Hi,
  Did we do anything further with this patch ? Right now its spawning a lot of problems for us.

Thanks,
Amitabha., This is unfortunate. I am still able to reproduce this bug on a Hadoop 3 cluster.

Interestingly, while -move doesn't work in such a case, -delete works.
If you look at the code,  -delete simply calls NameNodeRpc API as the current user
{code:title=NameNodeFsck#deleteCorruptedFile}
private void deleteCorruptedFile(String path) {
    try {
      namenode.getRpcServer().delete(path, true);
      LOG.info("Fsck: deleted corrupt file " + path);
    } catch (Exception e) {
      LOG.error("Fsck: error deleting corrupted file " + path, e);
      internalError = true;
    }
  }
{code}
whereas -move starts a dfs client and copy the file. Since NameNode APIs doesn't implement file copy, fsck has to start a client and copy the file explicitly. Why does it called '-move" when it actually does copy?

I am not quite sure if the attached patch is the right approach to fix the problem. Fsck doesn't check for super user permission by itself. So if you force fsck to run as login user (which has superuser perm), any user could run fsck and move the file to list+found., Hi Wei,

 

Thanks for reporting this.

Its been a long time and i will look into the code again.

But its not copy but the move of the path to the lost+found.

Allow me sometime.

 

Thanks

Krish]