[shouldCheckForEnoughRacks can be eliminated since HDFS-3256.

Attached 01 patch. Please review.

no tests included. It'll be fine if passes existed tests. (especially TestBlocksWithNotEnoughRacks, TestBlockManager#testBlocksAreNotUnderreplicatedInSinglerack), \\
\\
| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:red}-1{color} | pre-patch |  18m 59s | Pre-patch trunk has 1 extant Findbugs (version 3.0.0) warnings. |
| {color:green}+1{color} | @author |   0m  0s | The patch does not contain any @author tags. |
| {color:red}-1{color} | tests included |   0m  0s | The patch doesn't appear to include any new or modified tests.  Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. |
| {color:green}+1{color} | javac |   8m  0s | There were no new javac warning messages. |
| {color:green}+1{color} | javadoc |  10m  1s | There were no new javadoc warning messages. |
| {color:green}+1{color} | release audit |   0m 23s | The applied patch does not increase the total number of release audit warnings. |
| {color:red}-1{color} | checkstyle |   2m 24s | The applied patch generated  1 new checkstyle issues (total was 171, now 169). |
| {color:green}+1{color} | whitespace |   0m  0s | The patch has no lines that end in whitespace. |
| {color:green}+1{color} | install |   1m 39s | mvn install still works. |
| {color:green}+1{color} | eclipse:eclipse |   0m 35s | The patch built with eclipse:eclipse. |
| {color:green}+1{color} | findbugs |   3m 32s | The patch does not introduce any new Findbugs (version 3.0.0) warnings. |
| {color:green}+1{color} | native |   3m 21s | Pre-build of native portion |
| {color:red}-1{color} | hdfs tests | 160m 22s | Tests failed in hadoop-hdfs. |
| | | 209m 20s | |
\\
\\
|| Reason || Tests ||
| Failed unit tests | hadoop.hdfs.TestHDFSFileSystemContract |
|   | hadoop.hdfs.web.TestWebHdfsFileSystemContract |
|   | hadoop.hdfs.server.balancer.TestBalancer |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12742494/HDFS-8688.01.patch |
| Optional Tests | javadoc javac unit findbugs checkstyle |
| git revision | trunk / fde20ff |
| Pre-patch Findbugs warnings | https://builds.apache.org/job/PreCommit-HDFS-Build/11530/artifact/patchprocess/trunkFindbugsWarningshadoop-hdfs.html |
| checkstyle |  https://builds.apache.org/job/PreCommit-HDFS-Build/11530/artifact/patchprocess/diffcheckstylehadoop-hdfs.txt |
| hadoop-hdfs test log | https://builds.apache.org/job/PreCommit-HDFS-Build/11530/artifact/patchprocess/testrun_hadoop-hdfs.txt |
| Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/11530/testReport/ |
| Java | 1.7.0_55 |
| uname | Linux asf907.gq1.ygridcore.net 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/11530/console |


This message was automatically generated., The failed test is a bit complicated.
I'll fix the failed test at HDFS-8700., 02 patch fixes the failed test. (without HDFS-8700), \\
\\
| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:red}-1{color} | pre-patch |  17m 55s | Pre-patch trunk has 1 extant Findbugs (version 3.0.0) warnings. |
| {color:green}+1{color} | @author |   0m  0s | The patch does not contain any @author tags. |
| {color:green}+1{color} | tests included |   0m  0s | The patch appears to include 1 new or modified test files. |
| {color:green}+1{color} | javac |   7m 30s | There were no new javac warning messages. |
| {color:green}+1{color} | javadoc |   9m 37s | There were no new javadoc warning messages. |
| {color:green}+1{color} | release audit |   0m 23s | The applied patch does not increase the total number of release audit warnings. |
| {color:red}-1{color} | checkstyle |   2m 15s | The applied patch generated  1 new checkstyle issues (total was 171, now 169). |
| {color:green}+1{color} | whitespace |   0m  0s | The patch has no lines that end in whitespace. |
| {color:green}+1{color} | install |   1m 34s | mvn install still works. |
| {color:green}+1{color} | eclipse:eclipse |   0m 34s | The patch built with eclipse:eclipse. |
| {color:green}+1{color} | findbugs |   3m 15s | The patch does not introduce any new Findbugs (version 3.0.0) warnings. |
| {color:green}+1{color} | native |   3m 16s | Pre-build of native portion |
| {color:red}-1{color} | hdfs tests | 163m 49s | Tests failed in hadoop-hdfs. |
| | | 210m 12s | |
\\
\\
|| Reason || Tests ||
| Failed unit tests | hadoop.hdfs.TestAppendSnapshotTruncate |
|   | hadoop.hdfs.server.namenode.ha.TestStandbyIsHot |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12743003/HDFS-8688.02.patch |
| Optional Tests | javadoc javac unit findbugs checkstyle |
| git revision | trunk / 532e38c |
| Pre-patch Findbugs warnings | https://builds.apache.org/job/PreCommit-HDFS-Build/11556/artifact/patchprocess/trunkFindbugsWarningshadoop-hdfs.html |
| checkstyle |  https://builds.apache.org/job/PreCommit-HDFS-Build/11556/artifact/patchprocess/diffcheckstylehadoop-hdfs.txt |
| hadoop-hdfs test log | https://builds.apache.org/job/PreCommit-HDFS-Build/11556/artifact/patchprocess/testrun_hadoop-hdfs.txt |
| Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/11556/testReport/ |
| Java | 1.7.0_55 |
| uname | Linux asf909.gq1.ygridcore.net 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/11556/console |


This message was automatically generated., failed tests is not related and passed locally., Thanks [~walter.k.su]! Overall it looks good.

{{ScriptBasedMapping#isSingleSwitch}} still checks if the script name is null. But it appears that method is only used by test codes. Does that mean {{AbstractDNSToSwitchMapping#isSingleSwitch}} isn't necessary anymore? Try to understand if all the "the script name == null implies single rack" assumptions in the code can be removed.
, Thanks [~mingma] for review!

I checked 《Hadoop: The Definitive Guide》 about rackawareness/DNSToSwitchMapping. "switch" and "rack" are a little different.
(I didn't fully read the book, what I said may have some error. Following are my understanding, not from the book)

Suppose our configuration is "typical two-level netowrk architecture", I'll assume "switch" and "rack" are the same.
"the script name == null implies single rack" ,,,, That's true.
However if scriptName !=null, we can't tell if it's a single switch/rack. So {{ScriptBasedMapping#isSingleSwitch()}} is flawed. It need a fix.

As I said before, "switch" and "rack" are a little different.
"switch" is a logic in DNSToSwitchMapping
"rack" is a logic in NetworkTopology
We can't assume every user uses "typical two-level netowrk architecture". That's first reason we had better keep isSingleSwitch() API.
The API is provided by hadoop-common, that's the second reason.



, Thanks [~walter.k.su] for the investigation. According to the description of DNSToSwitchMapper.java, the switch means the layer above rack. But according to AbstractDNSToSwitchMapping description, isSingleSwitch is used to decide if it is single rack or multi racks, in that sense they are the same. My main question is which component actually uses isSingleSwitch API. [~stevel@apache.org] added this in HADOOP-7777 and might have some input.

Regardless we don't need to deal with that in this jira. For this patch, there is a scenario where it might change the behavior.

* Script file is defined.
* There is only one rack in the cluster.
* All blocks' replicas are corrupted.

Before this patch, blockHasEnoughRacks will return false. After this patch blockHasEnoughRacks will return true. So maybe we can just remove the check of {{this.shouldCheckForEnoughRacks}} at the beginning of the function?, if live nodes less than expected, we don't call {{blockHasEnoughRacks}}, especially live noes ==0 (if a block has no nodes, it must has no racks)
For example:
{code}
  boolean isNeededReplication(BlockInfo storedBlock, int expected,
      int current) {
    return current < expected || !blockHasEnoughRacks(storedBlock, expected);
  }
{code}

The logic of the original code is correct. The patch doesn't change the logic.

>..All blocks' replicas are corrupted.
At first, it won't go into {{blockHasEnoughRacks}}.


>...After this patch blockHasEnoughRacks will return true. 
Assume it doesgo into {{blockHasEnoughRacks}}. It returns false after this patch. The patch doesn't change the logic.

-----------

bq. My main question is which component actually uses isSingleSwitch API. Steve Loughran added this in HADOOP-7777 and might have some input.
No component of hadoop uses it. I don't know if there is other apache project which depends on hadoop-common use it. But
{code}
<property>
  <name>net.topology.node.switch.mapping.impl</name>
  <value>org.apache.hadoop.net.ScriptBasedMapping</value>
</property>
{code}
And also {{NetworkTopology}}, {{BlockPlacementPolicy}} can be custom designed by user. I think the API is useless to user also. But since it is already exposed to user, maybe hard to remove it.
, Thanks [~walter.k.su]. Your explanation makes sense. But I still want to clarify if there is any behavior change. {{isNeededReplication}} can be called by {{addStoredBlock}} with {{numCurrentReplica}} which isn't {{liveReplicas}} as it includes pending replications as well. So you can have a scenario where you decommission all replica nodes and you end up with 0 liveReplicas and {{numCurrentReplica}} is the same as expected replication. So in the case all replicas are in decommission_inprogress state, {{blockHasEnoughRacks}} might still be called. If so, {{blockHasEnoughRacks}} currently returns false as it couldn't find any live replica; but with the patch, it returns true.

There are several other places that call {{blockHasEnoughRacks}} directly only if there is no pending replications for that block.  Maybe we can do the same for {{addStoredBlock}} case in addition to the current patch. In that way,  we make sure {{blockHasEnoughRacks}} will be called only when there is enough {{liveReplicas}}.

Alternatively we can just remove the {{this.shouldCheckForEnoughRacks}} check to keep {{blockHasEnoughRacks}}'s behavior. Thought?
, bq. So in the case all replicas are in decommission_inprogress state, blockHasEnoughRacks might still be called. If so, blockHasEnoughRacks currently returns false as it couldn't find any live replica; but with the patch, it returns true.
Oh, I see. You are right. Thanks for the explanation. , bq. There are several other places that call blockHasEnoughRacks directly only if there is no pending replications for that block. Maybe we can do the same for addStoredBlock case in addition to the current patch. In that way, we make sure blockHasEnoughRacks will be called only when there is enough liveReplicas.
Agree.
If pendingReplication not null, we don't need check blockHasEnoughRacks(). We wait pendingReplication to be finished, and we check blockHasEnoughRacks() again later.
That's the appropriate way.

---------
bq. There are several other places that call blockHasEnoughRacks directly only if there is no pending replications for that block. Maybe we can do the same for addStoredBlock case in addition to the current patch. In that way, we make sure blockHasEnoughRacks will be called only when there is enough liveReplicas.

1. >...if there is pendingReplications, NN still calls blockHasEnoughRacks() in addStoredBlock.
Yes. Good catch!
2. >...we can do the same for addStoredBlock ...
No, we don't have to.
{code}
2703     if (!isNeededReplication(storedBlock, fileReplication, numCurrentReplica)) {
2704       neededReplications.remove(storedBlock, numCurrentReplica,
2705           num.decommissionedAndDecommissioning(), fileReplication);
2706     } else {
2707       updateNeededReplications(storedBlock, curReplicaDelta, 0);
2708     }
{code}

You must be confused why line 2703 uses {{numCurrentReplica}} but not live nodes. In fact the logic is correct. Because line 2704 is neededReplications.remove(..). If the number of racks already meet, it's natrual to remove from neededReplications.
line 2707 take effect only if in safemode.

In general, addStoredBlock will NOT add block to neededReplications. We don't have to change anything about it., By the way, the patch changes the logic in the special case as you said before.
The change/patch is valid.


Assume live nodes=0. It must be in needReplications or pendingReplications. It's ok blockHasEnoughRacks() return true ( and only if there is only one rack in cluster. The returned value is meaningless in this case)
Assume one replica got copied from decommissioned nodes, Now live nodes=1. The logic is the same as before the patch. (Both return true, Because they both check hasClusterEverBeenMultiRack() ), Sorry, My previous comment has big mistake.
-line 2707 take effect only if in safemode.-
-In general, addStoredBlock will NOT add block to neededReplications. We don't have to change anything about it.-

*line 2707 will take effect when out of safemode.*

--------

bq. we make sure blockHasEnoughRacks will be called only when there is enough liveReplicas.
when there is enough liveReplicas, but blockHasEnoughRacks() returns false. The bock belongs to QUEUE_REPLICAS_BADLY_DISTRIBUTED level. It should be updated in needReplications. Sorry I don't get your point., The task is really small. Doesn't worth a separated jira. I'll close this. And [~brahmareddy] will take care of HDFS-8647. I haven't start work on that yet.

Thanks [~mingma] for review and discussion. I learned a lot. Let's continue discussion in HDFS-8647., [~walter.k.su] appreciate your effort!]