[ *Test Code to reproduce this bug* 
{code}
public void testDeadDatanodeForBlockLocation() throws Exception {
    Configuration conf = new HdfsConfiguration();
    conf.setInt(DFSConfigKeys.DFS_NAMENODE_HEARTBEAT_RECHECK_INTERVAL_KEY, 500);
    conf.setLong(DFSConfigKeys.DFS_HEARTBEAT_INTERVAL_KEY, 1L);
    cluster = new MiniDFSCluster.Builder(conf).numDataNodes(3).build();
    cluster.waitActive();
    
    String poolId = cluster.getNamesystem().getBlockPoolId();
    // wait for datanode to be marked live
    DataNode dn = cluster.getDataNodes().get(0);
    DatanodeRegistration reg = 
        DataNodeTestUtils.getDNRegistrationForBP(dn, poolId);
    
    DFSTestUtil.waitForDatanodeState(cluster, reg.getDatanodeUuid(), true, 20000);
    
    // Shutdown and wait for data node to be marked dead
    dn.shutdown();
    DFSTestUtil.waitForDatanodeState(cluster, reg.getDatanodeUuid(), false, 20000);
    System.out.println("Dn downXXX: " + dn.getDisplayName());
    
    Path file = new Path("afile");
    try (FSDataOutputStream outputStream = cluster.getFileSystem().create(file))
    {
      outputStream.writeChars("testContent");
    }
    
    
    BlockLocation block = cluster.getFileSystem().getFileBlockLocations(file, 0, 10)[0];
    System.out.println("Dn down: " + dn.getDisplayName());
    for(String node : block.getNames())
    {
      System.out.println(node);
      if(node.equals(dn.getDisplayName()))
          {
            fail("Not expecting the block in a dead node");
          }
    }
  }
{code}
 *Impact which I seen* 
{color:red}The cluster have 9 Datanodeï¼Œnow stop 5. dfs.replications=3. Put files to HDFS continuously, but some operations failed.{color} 


I think, Here we can deadnodes also... 

{code}
if (isGoodTarget(storage, blockSize, maxNodesPerRack, considerLoad,
        results, avoidStaleNodes, storageType)) {
      results.add(storage);
      // add node and related nodes to excludedNode
      return addToExcludedNodes(storage.getDatanodeDescriptor(), excludedNodes);
    }
{code}, Currently only stale nodes are excluded but here we can consider deadnodes also .., Workaround can be done by  enabling " *dfs.name.avoid.write.stale.datanode* " where node is considered as stale( if there is no heartbeat in 30 sec's bydefault)..such that it's not allocated for the write...Anyone have some other thoughts..?, Thanks [~brahmareddy] for reporting this.
This will come, if the NameNode have the list of deadnodes, and block allocation request comes from the same machine as of DeadNode, then dead node is being chosen as localnode irrespective of whether its part of the cluster or not. Adding one check in {{BlockPlacementPolicyDefault.java#choseLocalStorage(..)}} will be the fix for this.

Regarding the test proposed above, it will not fail always, since its a minidfscluster test, and all datanodes will be on the same machine And Probabiity of deadnode being chosen as localstorage is not guaranteed., [~vinayrpet] thanks a lot for taking a look into this issue.. Added the one check in {{BlockPlacementPolicyDefault.java#choseLocalStorage(..)}} and corrected the testcase.. Kindly Review, \\
\\
| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | pre-patch |  18m  3s | Pre-patch trunk compilation is healthy. |
| {color:green}+1{color} | @author |   0m  0s | The patch does not contain any @author tags. |
| {color:green}+1{color} | tests included |   0m  0s | The patch appears to include 1 new or modified test files. |
| {color:green}+1{color} | javac |   7m 39s | There were no new javac warning messages. |
| {color:green}+1{color} | javadoc |   9m 48s | There were no new javadoc warning messages. |
| {color:green}+1{color} | release audit |   0m 23s | The applied patch does not increase the total number of release audit warnings. |
| {color:green}+1{color} | checkstyle |   2m 18s | There were no new checkstyle issues. |
| {color:red}-1{color} | whitespace |   0m  0s | The patch has 1  line(s) that end in whitespace. Use git apply --whitespace=fix. |
| {color:green}+1{color} | install |   1m 31s | mvn install still works. |
| {color:green}+1{color} | eclipse:eclipse |   0m 33s | The patch built with eclipse:eclipse. |
| {color:green}+1{color} | findbugs |   3m 17s | The patch does not introduce any new Findbugs (version 3.0.0) warnings. |
| {color:green}+1{color} | native |   3m 17s | Pre-build of native portion |
| {color:green}+1{color} | hdfs tests | 158m 22s | Tests passed in hadoop-hdfs. |
| | | 205m 15s | |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12741218/HDFS-8586.patch |
| Optional Tests | javadoc javac unit findbugs checkstyle |
| git revision | trunk / 41ae776 |
| whitespace | https://builds.apache.org/job/PreCommit-HDFS-Build/11444/artifact/patchprocess/whitespace.txt |
| hadoop-hdfs test log | https://builds.apache.org/job/PreCommit-HDFS-Build/11444/artifact/patchprocess/testrun_hadoop-hdfs.txt |
| Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/11444/testReport/ |
| Java | 1.7.0_55 |
| uname | Linux asf907.gq1.ygridcore.net 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/11444/console |


This message was automatically generated., [~vinayrpet] kindly review the attached patch!!! thanks, Thanks a lot [~brahmareddy] for the patch.
+1 LGTM.
Will commit soon., Committed to trunk and branch-2.
Thanks for the contribution [~brahmareddy]., Thanks a lot [~vinayrpet] for review and commit!!, FAILURE: Integrated in Hadoop-trunk-Commit #8083 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/8083/])
HDFS-8586. Dead Datanode is allocated for write when client is from deadnode (Contributed by Brahma Reddy Battula) (vinayakumarb: rev 88ceb382ef45bd09cf004cf44aedbabaf3976759)
* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestDeadDatanode.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyDefault.java
, SUCCESS: Integrated in Hadoop-Yarn-trunk-Java8 #243 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk-Java8/243/])
HDFS-8586. Dead Datanode is allocated for write when client is from deadnode (Contributed by Brahma Reddy Battula) (vinayakumarb: rev 88ceb382ef45bd09cf004cf44aedbabaf3976759)
* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyDefault.java
* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestDeadDatanode.java
, SUCCESS: Integrated in Hadoop-Yarn-trunk #973 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/973/])
HDFS-8586. Dead Datanode is allocated for write when client is from deadnode (Contributed by Brahma Reddy Battula) (vinayakumarb: rev 88ceb382ef45bd09cf004cf44aedbabaf3976759)
* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestDeadDatanode.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyDefault.java
* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
, FAILURE: Integrated in Hadoop-Hdfs-trunk #2171 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/2171/])
HDFS-8586. Dead Datanode is allocated for write when client is from deadnode (Contributed by Brahma Reddy Battula) (vinayakumarb: rev 88ceb382ef45bd09cf004cf44aedbabaf3976759)
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyDefault.java
* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestDeadDatanode.java
, FAILURE: Integrated in Hadoop-Hdfs-trunk-Java8 #232 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk-Java8/232/])
HDFS-8586. Dead Datanode is allocated for write when client is from deadnode (Contributed by Brahma Reddy Battula) (vinayakumarb: rev 88ceb382ef45bd09cf004cf44aedbabaf3976759)
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyDefault.java
* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestDeadDatanode.java
, SUCCESS: Integrated in Hadoop-Mapreduce-trunk #2189 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/2189/])
HDFS-8586. Dead Datanode is allocated for write when client is from deadnode (Contributed by Brahma Reddy Battula) (vinayakumarb: rev 88ceb382ef45bd09cf004cf44aedbabaf3976759)
* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestDeadDatanode.java
* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyDefault.java
, SUCCESS: Integrated in Hadoop-Mapreduce-trunk-Java8 #241 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk-Java8/241/])
HDFS-8586. Dead Datanode is allocated for write when client is from deadnode (Contributed by Brahma Reddy Battula) (vinayakumarb: rev 88ceb382ef45bd09cf004cf44aedbabaf3976759)
* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestDeadDatanode.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyDefault.java
* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
]