[This bug is founded in the light of [HDFS-12897|https://issues.apache.org/jira/browse/HDFS-12897]
As suggested by [~xiaochen], create this new issue to resolve it.
, Attach the patch and welcome for review.
As previous discussion with [~xiaochen], the check logic added by [~jingzhao] and [~szetszwo]  in {{TestBlockStoragePolicy#testSetStoragePolicyWithSnapshot}} may be a miss because the file/directory shouldn't have the change after the snapshot is already taken. So I modified the check logic and hope there is no omission or miss., | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 17s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 15m 11s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m  9s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 39s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 54s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 10m  1s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 39s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 46s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 54s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 47s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 47s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 32s{color} | {color:green} hadoop-hdfs-project/hadoop-hdfs: The patch generated 0 new + 315 unchanged - 3 fixed = 315 total (was 318) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 53s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  1s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 10m  2s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 52s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 46s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:red}-1{color} | {color:red} unit {color} | {color:red}121m 13s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 23s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}167m 40s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.hdfs.web.TestWebHdfsTimeouts |
|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:5b98639 |
| JIRA Issue | HDFS-13021 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12906537/HDFS-13021.001.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |
| uname | Linux a4dc7d0c0c1f 4.4.0-64-generic #85-Ubuntu SMP Mon Feb 20 11:50:30 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / a68e445 |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_151 |
| findbugs | v3.1.0-RC1 |
| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/22693/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/22693/testReport/ |
| Max. process+thread count | 4076 (vs. ulimit of 5000) |
| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/22693/console |
| Powered by | Apache Yetus 0.8.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

, unit test failure seems not related, all fails by TimeOut or OOM., Thanks [~GeLiXin] for reporting the issue and providing a patch. Looks like there are some unnecessary space-only changes (e.g. FSDirStatAndListingOp), could you get rid of them in the next rev? No need to roll a version only for this though.

 

Thinking about this more, this appear to be trickier than EC / EZ since the blocks may be moved, but OTOH snapshots are supposed to be immutable. And if a block is only in snapshot then it will not be moved because the mover can't see it from the file name.

Hi [~szetszwo],

What's your take on this one? Is this behavior by design or should be improved in some way?, Thanks [~xiaochen] for reviewing this.
bq.Looks like there are some unnecessary space-only changes
I make these space-only changes to fix 3 checkstyle warnings left over by history in passing. If this is not recommended,  I will get rid of them in the next rev, of course., bq. space-only changes to fix checkstyle warnings left over by history
If you're changing a line of code that had style issue, correcting it in that line is recommended.
However, changing lines that are not related to the code change is _not_ recommended, because it would make (this, and potentially future) backports more difficult.

Let's wait to see if [~szetszwo] can comment on the behavior. I think keeping snapshots immutable is more important, and the storage policy on snapshot files are just solely a state of the original file., The behavior is by design as it stated in TestBlockStoragePolicy.
{code:java}
// check the policy for /dir/.snapshot/s1/foo/f1. Note we always return
// the latest storage policy for a file/directory.
{code}
The problem is: what should HDFS do if the old and new storage policies are different?, Thanks for the comment [~szetszwo].

Since it's by design then maybe we can convert this into a doc jira. Didn't find any mentions of this behavior in [http://hadoop.apache.org/docs/r3.0.0/hadoop-project-dist/hadoop-hdfs/ArchivalStorage.html,] please comment if I'm missing it from some other docs.
{quote}what should HDFS do if the old and new storage policies are different?
{quote}
Agree this is tricky. Current behavior makes the difference impossible, and as it's by design, changing it would be incompatible. As I can see from HDFS-6911 and related jiras, mover already has the logic to handle snapshots, so doc Jira should be cool.

M2c on the problem itself is, storage policies on snapshots can be interpreted as just part of the file metadata's snapshots. So old policies (on snapshot) may not be accurately reflecting how the blocks are placed (even without snapshot, it may also not be accurate, for example if it's changed and mover not run yet), but they can be accurate on what the metadata was when the snapshot was created, and immutable., Personally，It's a hassle to deal with snapshot more or less, not only in distributed file system like HDFS, but also in local file systems. Even so, we still have to deal with it, or just to explain it clearly :)
 FYI, some personnal opinions:


 First of all, the definition of HDFS snapshots in [hadoop wiki |https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/HdfsSnapshots.html] are *read-only, point-in-time* copies of the file system. If the file/directory status in a snapshot changes with the origin file/directory, it breaks the semantic of *read-only* and *point-in-time* to some extent.


 Secondly, It may bring some confusions to the admin users. For example, people set a directory's storage policy to {{All_SSD}} to store it in SSD for better performance and take a snapshot. Afterwards the policy changed back to {{Hot}} for some reason, and months later the admin forgets the {{All_SSD}} policy exist in the past(or just is another admin) and want to find out why the SSD is full of data, he looks over all the directories include the snapshots, only to find {{HOT}} policy which will not use the SSD, and there is no clue or document to remind him to run the mover for a try – seems like a bug.]