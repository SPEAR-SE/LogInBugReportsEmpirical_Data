[Attaching an initial patch., looks a good initial patch; we just need to get consent from the HDFS team that
# the faulting rename action is the one we want
# its OK to drop the log.warn message. Given it's a client-side failure, dropping the warning seems the right choice.

We are changing HDFS semantics slightly -we'll need to mention that iin the release nodes, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12641075/HDFS-6262.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.TestHDFSFileSystemContract
                  org.apache.hadoop.hdfs.server.namenode.TestNamenodeRetryCache
                  org.apache.hadoop.hdfs.web.TestWebHdfsFileSystemContract
                  org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshot

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/6686//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/6686//console

This message is automatically generated., Thanks [~stevel@apache.org] for the review. I update the patch to 
# fix the test failures
# drop the log.warn message if the source of the rename does not exist

bq. we just need to get consent from the HDFS team
I'm +1 (non-binding) to slightly change the behavior., HADOOP-6240 is a closely related JIRA.  Isn't the already fixed?, The problematic rename methods were deprecated by HDFS-654 for a long time.  Should we simply remove them?, [~szetszwo], I agree with you. I'll update the patch to remove the deprecated methods., Nicholas -problem exists in trunk; the HADOOP-9361 tests show this, as does the patch. Currently the namenode logs at warn and returns 0 if the source is missing, everything else throws FileNotFoundException, I'm thinking the problem is rename(src, dst) calls deprecated FSDirectory.renameTo(src, dst), which doesn't throw FileNotFoundException even if src does not exist.
I suggest rename(src, dst) to call FSDirectory.renameTo(src, dst, Rename.NONE)., bq. I suggest rename(src, dst) to call FSDirectory.renameTo(src, dst, Rename.NONE).
I tried, but got a lot of errors.
{code}
Tests in error:
 TestHDFSFileSystemContract>FileSystemContractBaseTest.testRenameFileMoveToNonExistentDirectory:358->FileSystemContractBaseTest.rename:489 » FileNotFound
 TestHDFSFileSystemContract>FileSystemContractBaseTest.testRenameFileAsExistingFile:378->FileSystemContractBaseTest.rename:489 » FileAlreadyExists
 TestHDFSFileSystemContract>FileSystemContractBaseTest.testRenameFileAsExistingDirectory:388->FileSystemContractBaseTest.rename:489 » Remote
 TestHDFSFileSystemContract>FileSystemContractBaseTest.testRenameDirectoryMoveToNonExistentDirectory:399->FileSystemContractBaseTest.rename:489 » FileNotFound
 TestHDFSFileSystemContract>FileSystemContractBaseTest.testRenameDirectoryAsExistingFile:431->FileSystemContractBaseTest.rename:489 » Remote
 TestHDFSFileSystemContract>FileSystemContractBaseTest.testRenameDirectoryAsExistingDirectory:444->FileSystemContractBaseTest.rename:489 » FileAlreadyExists
 TestHDFSFileSystemContract>FileSystemContractBaseTest.testRenameRootDirForbidden:598->FileSystemContractBaseTest.rename:489 » Remote
 TestHDFSFileSystemContract>FileSystemContractBaseTest.testRenameChildDirForbidden:617->FileSystemContractBaseTest.rename:489 » Remote
 TestHDFSFileSystemContract>FileSystemContractBaseTest.testRenameDirToSelf:649->FileSystemContractBaseTest.rename:489 » FileAlreadyExists
 TestHDFSFileSystemContract>FileSystemContractBaseTest.testMoveDirUnderParent:667 » FileAlreadyExists
 TestHDFSFileSystemContract>FileSystemContractBaseTest.testRenameFileToSelf:681->FileSystemContractBaseTest.rename:489 » FileAlreadyExists
 TestHDFSFileSystemContract>FileSystemContractBaseTest.testMoveFileUnderParent:695->FileSystemContractBaseTest.rename:489 » FileAlreadyExists
{code}
The suggestion will change some other behaviors. I think it's better to make the behavior changes smaller for this JIRA, and now I suggest the v2 patch.
[~stevel@apache.org] and [~szetszwo], what do you think?, {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12641192/HDFS-6262.2.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 5 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/6690//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/6690//console

This message is automatically generated., it looks OK to me, but one of the HDFS experts has to vote on the details.

What happens if you apply the HADOOP-9361 patch, with its HDFS test failing, and then apply this? As those are my rename behaviour tests?, [~sureshms], since you have worked on HADOOP-6240 and HDFS-654, could you take a look?, [~stevel@apache.org], given rename had different behaviors on different file systems, we did not want to change it and leave it alone (as discussed in HADOOP-6240). That way applications that are dealing with or dependent different behaviors of the file systems continue to work. I think we should deprecate old rename and and not test it for consistent behavior. Lets only test the new rename for consistency across FileSystems., Suresh, thanks for the link to HADOOP-6240 -I hadn't seen that. But: *every other filesystem* considers renaming a file that doesn't exist to be an error.

Do we have any examples where failing to fault on renaming a nonexistent file is NOT an error to flag up? 

Looking at the hadoop production source
* {{org.apache.hadoop.fs.shell.MoveCommands}} says "we have no way to know the actual error..." and throws a {{PathIOException}}
* {{org.apache.hadoop.fs.shell.CommandWithDestination}} says "too bad we don't know why it failed" and does the same
* {{org.apache.hadoop.io.MapFile}} raises an IOException
* {{org.apache.hadoop.tools.mapred.CopyCommitter}} raises an IOE, as does {{org.apache.hadoop.tools.mapred.RetriableFileCopyCommand}}

Similar behaviour for: 
{code}
LocalContainerLauncher, DistCpV1
org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
org.apache.hadoop.mapreduce.v2.hs.HistoryServerFileSystemStateStoreService, 
...
{code}

and those that blindly assume that rename's return value doesn't need checking
{code}
JobHistoryEventHandler
TaskLog (on localFS though)
org.apache.hadoop.mapreduce.task.reduce.OnDiskMapOutput
org.apache.hadoop.yarn.applications.distributedshell.ApplicationMaster
org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.AppLogAggregatorImpl
org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore

{code}

In fact. the only bit of code I can see that converts the false return code to a warning is {{org.apache.hadoop.tools.mapred.lib.DynamicInputChunk}}

To summarise, in the Hadoop production code, in all but one case the handling of a false return code takes two forms
# triggers the throwing of a "that failed but we don't know why" {{IOException}}
# is blissfully ignorant that the operation has failed, and has so far been lucky in avoiding concurrency problems with their source being renamed while they weren't looking.

All of these uses benefit from having rename consistently throw a FileNotFoundException if the source file isn't there


, bq.  But: every other filesystem considers renaming a file that doesn't exist to be an error.
I agree. However, some of our methods have two ways to indicate failure - return false or thrown an exception and there lies the problem.

Given that applications must handle exception being thrown from these methods, changing the behavior for HDFS should be okay. But we do not how all the apps use this API and I suspect we will break some applications. Especially case 2 you pointed in your comments. One thing I was thinking of was to possibly have a hidden configuration to revert back to old behavior in HDFS. But that is pretty ugly.

Again, I feel we should leave the method as is in HDFS. But I am okay if you want to go ahead and make this change. We should perhaps document it and hope that not too many applications break.
, \\
\\
| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:red}-1{color} | patch |   0m  0s | The patch command could not apply the patch during dryrun. |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12641192/HDFS-6262.2.patch |
| Optional Tests | javadoc javac unit findbugs checkstyle |
| git revision | trunk / f1a152c |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/10632/console |


This message was automatically generated., \\
\\
| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:red}-1{color} | patch |   0m  0s | The patch command could not apply the patch during dryrun. |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12641192/HDFS-6262.2.patch |
| Optional Tests | javadoc javac unit findbugs checkstyle |
| git revision | trunk / f1a152c |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/10654/console |


This message was automatically generated., [~ajisakaa],

Any update on this ticket? Will it be closed or fixed?

My thoughts:
Based on my previous experience with rename related issues (HADOOP-13082) it seems the ecosystem strongly based on the current behavior of rename methods even they are not consistent. Changing in rename behavior can definitely break compatibility (another discussion is HDFS-10385, I have just close it as Later). Please check the linked issues.

I am asking because I am going through the points of HDFS-303 and the 3rd point is covered by this ticket. 

Thanks in advance., | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m  0s{color} | {color:blue} Docker mode activated. {color} |
| {color:red}-1{color} | {color:red} patch {color} | {color:red}  0m  5s{color} | {color:red} HDFS-6262 does not apply to trunk. Rebase required? Wrong Branch? See https://wiki.apache.org/hadoop/HowToContribute for help. {color} |
\\
\\
|| Subsystem || Report/Notes ||
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12641192/HDFS-6262.2.patch |
| JIRA Issue | HDFS-6262 |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/16291/console |
| Powered by | Apache Yetus 0.4.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

, | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m  0s{color} | {color:blue} Docker mode activated. {color} |
| {color:red}-1{color} | {color:red} patch {color} | {color:red}  0m  5s{color} | {color:red} HDFS-6262 does not apply to trunk. Rebase required? Wrong Branch? See https://wiki.apache.org/hadoop/HowToContribute for help. {color} |
\\
\\
|| Subsystem || Report/Notes ||
| JIRA Issue | HDFS-6262 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12641192/HDFS-6262.2.patch |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/17588/console |
| Powered by | Apache Yetus 0.4.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

, Closing this as "Won't Fix". Please check the [related comment|https://issues.apache.org/jira/browse/HDFS-303?focusedCommentId=15677026&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-15677026]., I concur. the newer rename, which in FileSystem is marked as @Deprecated, does do the check and has a more consistent model. We can undeprecate it (it was deprecated because it was "transitionary" to FileContext), move code to it]