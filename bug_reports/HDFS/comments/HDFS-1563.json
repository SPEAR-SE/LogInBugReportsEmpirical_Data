[Unittest to reveal the bug., Unittest that reveals the bug., -1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12467154/unittest.diff
  against trunk revision 1053214.

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 3 new or modified tests.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    -1 release audit.  The applied patch generated 1 release audit warnings (more than the trunk's current 0 warnings).

    -1 core tests.  The patch failed these core unit tests:
                  org.apache.hadoop.hdfs.server.datanode.TestBlockReport
                  org.apache.hadoop.hdfs.server.namenode.TestStorageRestore
                  org.apache.hadoop.hdfs.TestFileConcurrentReader
                  org.apache.hadoop.hdfs.TestLocalDFS

    -1 contrib tests.  The patch failed contrib unit tests.

    +1 system test framework.  The patch passed system test framework compile.

Test results: https://hudson.apache.org/hudson/job/PreCommit-HDFS-Build/59//testReport/
Release audit warnings: https://hudson.apache.org/hudson/job/PreCommit-HDFS-Build/59//artifact/trunk/patchprocess/patchReleaseAuditProblems.txt
Findbugs warnings: https://hudson.apache.org/hudson/job/PreCommit-HDFS-Build/59//artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Console output: https://hudson.apache.org/hudson/job/PreCommit-HDFS-Build/59//console

This message is automatically generated., I found the cause of the problem. The startFileInternal method is the one that acquires the FSnamesystem writelock and then deletes and recreates the file, all within the lock.

The problem however is that FSNamesystem.getHdfsFileInfo() does not acquire the FSNamesystem lock. Thus, when the client does an FileSystem.exists(), it issues a FSNamesystem.getHdfsFileInfo call which finds that the directory does not contain the specified file.

There are two options for us:
1. make the create(overwrite == true) call be atomic. That means that FSNamessytem.getHdfsFileInfo, getListing() and getPreferredBlockSize(), getContentSummary() all acquire the FSNamesystem.readLock.
2. declare that the create(overwrite == true) is not atomic. 

guangHao: can you pl explain  the behaviour of ur application that is depending on the atomicity of the create(overwrite=true) call?, I vote that we keep the semantics of the create(overwrite==true) the same as it is now. Please reopen this JIRA if you strongly feel otherwise.]