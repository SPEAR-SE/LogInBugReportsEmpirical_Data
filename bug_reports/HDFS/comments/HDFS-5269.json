[Here is a transcript of attempting to add and then remove a cache directive:

{code}
[cnauroth@ubuntu:pts/0] hadoop-deploy-trunk                                                                         
> hadoop-3.0.0-SNAPSHOT/bin/hdfs dfsadmin -addCachePool pool1
Successfully added cache pool pool1.
[cnauroth@ubuntu:pts/0] hadoop-deploy-trunk                                                                         
> hadoop-3.0.0-SNAPSHOT/bin/hdfs cacheadmin -addPath -path /hello -pool pool1
Added PathBasedCache entry 1
[cnauroth@ubuntu:pts/0] hadoop-deploy-trunk                                                                         
> hadoop-3.0.0-SNAPSHOT/bin/hdfs cacheadmin -listPaths
Found 1 entry
 ID POOL   PATH   
  1 pool1  /hello 
[cnauroth@ubuntu:pts/0] hadoop-deploy-trunk                                                                         
> hadoop-3.0.0-SNAPSHOT/bin/hdfs cacheadmin -removePath 1
Exception in thread "main" java.lang.NullPointerException
	at com.google.common.base.Preconditions.checkNotNull(Preconditions.java:187)
	at org.apache.hadoop.hdfs.protocol.PathBasedCacheDirective.<init>(PathBasedCacheDirective.java:44)
	at org.apache.hadoop.hdfs.protocol.PathBasedCacheDescriptor.<init>(PathBasedCacheDescriptor.java:36)
	at org.apache.hadoop.hdfs.tools.CacheAdmin$RemovePathBasedCacheDirectiveCommand.run(CacheAdmin.java:147)
	at org.apache.hadoop.hdfs.tools.CacheAdmin.main(CacheAdmin.java:312)
{code}

This was introduced in HDFS-5236, which switched from passing just the ID to passing the descriptor object.  The descriptor object constructor enforces precondition checks, so attempting to construct with just an ID fails.

{code}
@@ -153,18 +144,10 @@ public int run(List<String> args) throws IOException {
         return 1;
       }
       DistributedFileSystem dfs = getDFS();
-      List<Long> ids = new LinkedList<Long>();
-      ids.add(id);
-      List<Fallible<Long>> results = dfs.removePathBasedCacheDescriptors(ids);
-      try {
-        Long resultId = results.get(0).get();
-        System.out.println("Removed PathBasedCache entry " + resultId);
-        return 0;
-      } catch (IOException e) {
-        System.err.println("Error removing cache directive " + id + ": " +
-          e.getMessage());
-        return 1;
-      }
+      dfs.removePathBasedCacheDescriptor(new PathBasedCacheDescriptor(id, null,
+          null));
+      System.out.println("Removed PathBasedCache directive " + id);
+      return 0;
     }
   }
{code}

I can volunteer to patch this.  [~cmccabe] and [~andrew.wang], I see a few possible approaches:

# Remove the precondition checks completely.  (This is probably undesirable, because the precondition checks are nice for enforcing guarantees at other layers.)
# Provide an alternate constructor accepting just ID, and don't enforce the preconditions in that code path.  (It's stricter than #1, but you still have the risk of code paths accidentally getting passed a partially-initialized object.)
# Go back to an API design accepting just the ID instead of the cache directive object.

My preference is #3, because it still maintains the invariant that a cache directive object used anywhere in the codebase is fully initialized.  There could be advantages to an API accepting a richer object as a filter for deleting multiple directives (potentially helpful for discussion on HDFS-5203), but I'd argue that such a filter object is something different in the domain model than the actual {{PathBasedCacheDescriptor}}., Hey Chris, thanks for the report. I folded in a fix for this in HDFS-5190 since I was already poking around in {{CacheAdmin}}. I went with {{DistributedFileSystem}} taking a {{PathBasedCacheDescriptor}}, which it then unpacks it into a {{long}} to pass to the {{DFSClient}} API. {{CacheAdmin}} then calls the {{DFSClient}} API directly. Let me know if this works for you (a full review on HDFS-5190 would also be appreciated!)., Thanks, [~andrew.wang].  I took a quick look at the HDFS-5190 patch, and I agree that it makes sense to fold the fix in there.  I'm resolving HDFS-5269 as duplicate of HDFS-5190.]