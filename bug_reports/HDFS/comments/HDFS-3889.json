[Good find.  Or perhaps have an option that checks CRCs but just logs. I imagine the motivation for this was to not stop a large distcp job because one call to getFileChecksum failed (though it's robust, eg checks multiple DNs, so that should probably be rare)., I guess I need to look more into why {{getFileChecksum}} would fail.  If the block file simply had no checksum to begin with, then skipping it is clearly fine.  I think that's the case this was designed to handle (although I could be wrong here.)  However, if we expected it to have a checksum and it didn't, then that should be a red flag., A couple of comments on this bug, for context:

Checksums are checked in two spots in the code:
* When deciding whether to perform a copy if the "-update" option is used
* When checking that a copy succeeded (that's the code changed in HDFS-3054).

I think error checking should behave differently for each of those.

In the first case, we're interested in whether a copy should be made or not; if we fail to read the checksum, I think the best would be to treat that as an indication that the file should be copied to the destination (which is what the code does today).

In the second case, if we fail to read the checksum, it means we can't verify that the copy is correct. That case, I think, should result in an exception.

As a plus, I think the "-skipcrccheck" option should not apply to the first case above (deciding whether to update a remote file). CRCs should always be checked in that case; otherwise the equality check is simply based on file size and block size, which I don't think is enough to say the files are the same., Let's call case #1 the "pre-copy check," and case #2 the "post-copy check."

The problem with trying to force everyone to do the pre-copy check unconditionally is that not everyone can do it efficiently.  What if the source and destination clusters have different checksum types, or one of the checksums is missing?  You have to fall back on a slow strategy of computing your own checksum on one or both sides., bq. What if the source and destination clusters have different checksum types, or one of the checksums is missing?

That means that you can't reasonably detect whether both files are equal, so the code should fall back to the safe path, which is to assume they are not equal and that a copy should be performed. Since manually computing the checksums (by reading both source and destination files) and just copying the file would be about the same performance-wise, it should be fine.

"-update" is an optimization to avoid copying redundant data. Nothing will break if you just overwrite the target data with the source, it will just be slower than if the checksum checks were possible., bq. As a plus, I think the "-skipcrccheck" option should not apply to the first case above (deciding whether to update a remote file). CRCs should always be checked in that case; otherwise the equality check is simply based on file size and block size, which I don't think is enough to say the files are the same.

In the absence of CRCs, it should also be based on modtime and other file metadata, not just size.

{{rsync}} provides a way to compare files only based on metadata attributes and not checksums.  Are we going to provide less functionality than {{rsync}}?

(Just playing devil's advocate here-- you might very well be right.), bq. In the absence of CRCs, it should also be based on modtime and other file metadata, not just size.

If the goal is to just provide the same functionality as rsync, then sure. Although I consider those less reliable (or just as bad) as file size alone. They require the metadata to be kept in sync between source and destination, something that I don't think is very common for mod time or access time, for example., bq. If the goal is to just provide the same functionality as rsync, then sure. Although I consider those less reliable (or just as bad) as file size alone. They require the metadata to be kept in sync between source and destination, something that I don't think is very common for mod time or access time, for example.

I believe that the modification time is set based on the NN, not the clients.  So nothing needs to be kept in sync.  It's true that time can sometimes go backwards on the NN (due to server misconfiguration, NTP, or other things) but it's not exactly common.

Still, I could go either way on this point.  It's nice to know that you're doing the safe thing, and refusing to skip pre-copy checksum definitely is the safe thing.

Also, we currently aren't doing as much checking as we should do.  We don't consider the mtime and owner, group, etc at the moment.  This makes skipping the checksum a lot more unsafe than it needs to be., bq. I believe that the modification time is set based on the NN, not the clients. So nothing needs to be kept in sync.

You have two NNs. The metadata on the the target NN needs to be in sync with the source NN for the metadata-based check to do the right thing.

In the end, my opinion is just that metadata-based checks are a very poor substitute for checksums, and can much more easily generate false positives (i.e. say that files are equal when they're not). But if it's a feature that people find useful, why not. The false negative case is not such a big problem, since it would just waste bandwidth by forcing the copy.]