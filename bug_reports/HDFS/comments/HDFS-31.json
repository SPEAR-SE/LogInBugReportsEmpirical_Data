[This really needs to get fixed., Yes, that would be nice.

I was using hftp to copy from a 0.20.1 cluster to CDH3 cluster (starting distcp on CDH3 cluster), and I ran into the same 500 error.  It seems that the url escaping mechanism is making the final fetch url incorrect.

e.g.

file in HDFS: 
/test/twitteruserout2/_logs/history/mi-prod-app01.ec2.biz360.com_1269013964063_job_201003190852_17784_hadoop_twitter+users+extraction+from+source+on+Tue+Apr+20

fetch filename:
/test/twitteruserout2/_logs/history/mi-prod-app01.ec2.biz360.com_1269013964063_job_201003190852_17784_hadoop_twitter users extraction from source on Tue Apr 20

Error from specific machine:
2010-08-16 14:33:06,765 WARN org.mortbay.log: /streamFile: java.io.IOException: Cannot open filename /test/twitteruserout2/_logs/history/mi-prod-app01.ec2.biz360.com_1269013964063_job_201003190852_17784_hadoop_twitter users extraction from source on Tue Apr 20


Trying to run from http:

http://mi-prod-app28:50075/streamFile?filename=/test/twitteruserout2/_logs/history/mi-prod-app01.ec2.biz360.com_1269013964063_job_201003190852_17784_hadoop_twitter+users+extraction+from+source+on+Tue+Apr+20&ugi=hadoop,hadoop

Doesn't work and will give same error as above.
However, if I replace the + with %2B then the get works., This should be fixed by HDFS-1109.  Could you check again?, Closing as invalid.  Please feel free to reopen if the problem still exists.]