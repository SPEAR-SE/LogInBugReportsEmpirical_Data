[I believe the audit log was supposed to capture failed operations as well. I'd be inclined to close this JIRA as WON'T FIX, Agreed., I think it is not a failed operation., Closing this as Won't Fix, bq. I believe the audit log was supposed to capture failed operations as well. I'd be inclined to close this JIRA as WON'T FIX

I can see why you might think this, but no, the audit log should not capture failed operations.  Check out the discussion at HDFS-9395 for more details about this.

bq. It's not a failed operation if the directory already exists.

Yeah, I agree.

bq. Closing this as Won't Fix

Sounds good., Cool! Thanks for the pointer Colin! I knew there were inconsistencies but I wasn't aware of a JIRA that tackled it systematically. Thanks :-), Rushabh! Do you want to re-open this ticket if it doesn't conform to the policy set in HDFS-9395?, Thanks, [~raviprak].  It's always good to have more people looking at this.

Since the mkdir operation succeeded, it seems like it should be in the audit log, according to the policy set in HDFS-9395... perhaps I missed something., Thanks Colin!

That's interesting then. {{hdfs dfs -mkdir /dirAlreadyExists}} returns a non-zero return code. I assumed a non-zero error code == a failed operation. Obviously I was wrong., bq. That's interesting then. hdfs dfs -mkdir /dirAlreadyExists returns a non-zero return code. I assumed a non-zero error code == a failed operation. Obviously I was wrong.

A non-zero error code on the shell does indicate a failed operation.  You can see that FsShell explicitly checks to see whether the path exists and exits with an error code if so.  The code is in ./hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/Mkdir.java  I don't think this has anything to do with what hdfs should put in the audit log, since in this case, FsShell doesn't even call mkdir.]