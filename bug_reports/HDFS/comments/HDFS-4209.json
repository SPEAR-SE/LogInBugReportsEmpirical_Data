[h4209_20121118.patch: 1st patch., h4209_20121118b.patch: remove UNKNOWN_DISK_SPACE and clean up INodeDirectoryWithQuota., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12554104/h4209_20121118.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.cli.TestHDFSCLI

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/3536//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/3536//console

This message is automatically generated., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12554106/h4209_20121118b.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.cli.TestHDFSCLI

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/3537//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/3537//console

This message is automatically generated., This looks good.  I especially like how you replaced a lot of places where we were checking for {{!symlink && !directory}} with checking for {{file}} directly.

{code}
  void addToParentForImage(INodeDirectory parent, INode newNode)
{code}

Does it make sense to call this {{addToParentUnlocked}}, or something like that?  I mean every directory we add is "for the image" since that's where directories live.  But most functions take the writeLock, and this one doesn't.

{code}
-  void setQuota(String src, long nsQuota, long dsQuota) 
-    throws FileNotFoundException, QuotaExceededException,
-    UnresolvedLinkException { 
+  void setQuota(String src, long nsQuota, long dsQuota) throws IOException  { 
{code}

It seems like the new throw specification provides less information to the caller than the old one.  Considering that people often rely on throw specs as a kind of documentation about how the function can fail, are we sure we want to remove this?, Colin, thanks for taking a look.

> Does it make sense to call this addToParentUnlocked, or something like that? ...

Let's call it addToParentForImageLoading since it also adds blocks to the block map.  It is specific to image loading.

> It seems like the new throw specification provides less information to the caller than the old one. ...

Okay, I will keep the QuotaExceededException and UnresolvedLinkException., h4209_20121119.patch: 
- fixes TestHDFSCLI;
- removes the pos parameter from removeChild and renames it to removeLastINode, similarly for addChild and addChildNoQuotaCheck;
- fixes a bug in adding symlink; it should re-throw but not ignore QuotaExceededException., {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12554241/h4209_20121119.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 2 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/3544//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/3544//console

This message is automatically generated., Looks good to me., Comments:
# FSDirectory.java - Reading the namenode cache threshold is moved? There is also call to reset(). The need for this is not obvious to me.
# addToParentForImageLoading - I would use the same convention as currently exists unprotectedAddToParent(). While this may not be a great method name, at least it does not make the method name relevant only for image loading. In the future the method may be used for something other than image loading. Please update the javadoc to say, one example where this method is called is during image loading...
# addToParentForImageLoading silently ignores failure to addChild to the parent. This is not a code introduced by this patch. We should address this in a separate jira.
# FSDirectory.java changes could have been divided into smaller jiras. 
#* New methods for processing the last inode of inodesInPath could have been seaprate from this jira. But given I have gone through the review you could leave it in this jira. Up to you.
#* If possible move the fixes where settimg parent's mtime correctly etc. into another jira. 
# Instead of throwing generic IOException, we should throw specific exception in Inode*.valueOf() methods. This could be done in another jira.
, {quote}fixes a bug in adding symlink; it should re-throw but not ignore QuotaExceededException.{quote}

Nice find Nicholas. Mind adding a test case to TestFcHdfsSymlink for this?
, Let's split the patch since it involves quite a few different issues., > addToParentForImageLoading - I would use the same convention as currently exists unprotectedAddToParent(). ...

Unlike other unprotected methods, this method is only used in image loading but not rpc call.  (e.g. unprotectedSetPermission is used by both image loading and setPermission RPC call.)  So I call it addToParentForImageLoading.  A better way is to move it to FSImageFormat.

I split this part to HDFS-4215., > FSDirectory.java - Reading the namenode cache threshold is moved? There is also call to reset(). The need for this is not obvious to me.

I want to reuse the code for creating the root so that I use reset().  It is probably better to create a new createRoot method., > ... Mind adding a test case to TestFcHdfsSymlink for this?

Sure.  Let me have the symlink fix and the test in HDFS-4216., Revised Summary and Description., h4209_20121121.patch:
- It adds PathException for path related exception such as not-a-file, directory-not-found, etc.
- fsDir.getParent(pathComponents) is only used by image loading but it holds the read lock., {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12554580/h4209_20121121.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 2 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/3555//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/3555//console

This message is automatically generated., Comments:
# Please see HDFS-4228. I would rather use the Path*Exception instead of introducing PathException here.
# INodeDirect#getParent() no longer needs to throw FileNotFoundException.
# Earlier where FileNotFoundException was thrown now some other exception might be thrown. This could break existing applications that might be catching FileNotFoundException? Should we throw FileNotFoundException in INodeDirectory, INodeFileUnderConstruction valueOf method? We do throw FileNotFoundException when a directory was not found in other methods.
# INodeFile#valueOf() no need to throw PathException
, h4209_20121126.patch: updated with the path exceptions in fs., BTW, the patch keep throwing FileNotFoundException for directory not found.

> INodeFile#valueOf() no need to throw PathException

It actually needs to declare it since INodeFileUnderConstruction.valeOf() throws it., Minor comment: INodeFile#valueOf() unnecessarily throws PathIOException

+1 with that change and Jenkins +1., h4209_20121126b.patch: uses FileNotFoundException in INodeFileUnderConstruction.valueOf(..) for simplicity., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12554945/h4209_20121126.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 2 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.server.namenode.TestINodeFile

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/3564//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/3564//console

This message is automatically generated., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12554949/h4209_20121126b.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 2 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.server.namenode.TestINodeFile

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/3565//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/3565//console

This message is automatically generated., h4209_20121127.patch: updates TestINodeFile., +1 for the patch, with Jenkins +1., {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12555056/h4209_20121127.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 2 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/3568//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/3568//console

This message is automatically generated., I have committed this., Integrated in Hadoop-trunk-Commit #3064 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/3064/])
    HDFS-4209. Clean up the addNode/addChild/addChildNoQuotaCheck methods in FSDirectory and INodeDirectory. (Revision 1414447)

     Result = SUCCESS
szetszwo : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1414447
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSUtil.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeDirectory.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFileUnderConstruction.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestINodeFile.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/resources/testHDFSConf.xml
, Integrated in Hadoop-Yarn-trunk #50 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/50/])
    HDFS-4209. Clean up the addNode/addChild/addChildNoQuotaCheck methods in FSDirectory and INodeDirectory. (Revision 1414447)

     Result = SUCCESS
szetszwo : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1414447
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSUtil.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeDirectory.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFileUnderConstruction.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestINodeFile.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/resources/testHDFSConf.xml
, I merged this change to branch-2.]