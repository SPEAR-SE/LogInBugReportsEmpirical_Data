[From Suresh:

I am adding information about the design, the way I understand it. Let me know if I got it wrong.
*Upgrade preparation:*
# New bits are installed on the cluster nodes.
# The cluster is brought down.

*Upgrade:* For HA setup, choose one of the namenodes to initiate upgrade on and start it with -upgrade flag.
# NN performs preupgrade for all non shared storage directories by moving current to previous.tmp and creating new current.
#* Failure here is fine. NN start up fails. Next attempt at upgrade the storage directories are recovered.
# NN performs preupgrade of shared edits (NFS/JournalNodes) over RPC. JournalNodes current moved to previous.tmp and new current is created.
#* If one of the JN preupgrade fails and upgrade is reattempted, editlog directory could be lost on the JN. Restarting the JN does not fix the issue.
# NN performs upgrade of non shared edits by writing new CTIME to current and moving previous.tmp to previous.
#* If one of the JN preupgrade fails and upgrade is reattempted, editlog directory could be lost on the JN. Restarting the JN does not fix the issue.
# NN performs upgrade of shared edits (NFS/JournalNodes) over RPC. JournalNodes current has new CTIM and previous.tmp is moved to previous.
# We need to document that all the JournalNodes must be up. If a JN is irrecoverably lost, configuration must be changed to exclude the JN.

*Rollback:* NN is started with rollback flag
# For all the non shared directories, the NN checks for canRollBack, essentially ensures that previous directory with the right layout version exists.
# For all the shared directories, the NN checks for canRollBack, essentially ensures that previous directory with the right layout version exists.
# NN performs rollback for shared directories (moving previous to current)
#* If rollback of one of the JN fails, then directories are in inconsistent state. I think any attempt at retrying rollback will fail and will require manually moving files around. I do not think restarting JN fixes this.
# We need to document that all the JournalNodes must be up. If a JN is irrecoverably lost, configuration must be changed to exclude the JN.

*Finalize:* DFSAdmin command is run to finalize the upgrade.
# Active NN performs finalizing of editlog. If JN's fail to finalize, active NN fails to finalize. However it is possible that standby finalizes, leaving the cluster in an inconsistent state.
# We need to document that all the JournalNodes must be up. If a JN is irrecoverably lost, configuration must be changed to exclude the JN.

Comments on the code in the patch (this is almost complete):
Comments:
# Minor nit: there are some white space changes
# assertAllResultsEqual - for loop can just start with i = 1? Also if the collection objects is of size zero or one, the method can return early. Is there a need to do object.toArray() for these early checks? With that, perhaps the findbugs exclude may not be necessary.
# Unit test can be added for methods isAtLeastOneActive, getRpcAddressesForNameserviceId and getProxiesForAllNameNodesInNameservice (I am okay if this is done in a separate jira)
# Finalizing upgrade is quite tricky. Consider the following scenarios:
#* One NN is active and the other is standby - works fine
#* One NN is active and the other is down or all NNs - finalize command throws exception and the user will not know if it has succeeded or failed and what to do next
#* No active NN - throws an exception cannot finalize with no active
#* BlockPoolSliceStorage.java change seems unnecessary
# Why is {{throw new AssertionError("Unreachable code.");}} in QuorumJournalManager.java methods?
# FSImage#doRollBack() - when canRollBack is false after checking if non-share directories can rollback, an exception must be immediately thrown, instead of checking shared editlog. Also printing Log.info when storages can be rolled back will help in debugging.
# FSEditlog#canRollBackSharedLog should accept StorageInfo instead of Storage
# QuorumJournalManager#canRollBack and getJournalCTime can throw AssertionError (from DFSUtil.assertAllResultsEqual()). Is that the right exception to expose or IOException?
# Namenode startup throws AssertionError with -rollback option. I think we should throw IOException, which is how all the other failures are indicated., Attaching a patch which should address all of the individual comments:

bq. assertAllResultsEqual - for loop can just start with i = 1? Also if the collection objects is of size zero or one, the method can return early. Is there a need to do object.toArray() for these early checks? With that, perhaps the findbugs exclude may not be necessary.

Good thinking re: starting the loop at 1 and exiting early. Even with that, I don't think the findbugs exclude can be removed. The issue is this: "{{(currElement == null && currElement != lastElement)}}". In that code we know that currElement is equal to null, and then we compare the known-null value to something else. This is correct, and even though I could have explicitly compared lastElement to null, this seemed clearer to me. Let me know if you disagree.

bq. Unit test can be added for methods isAtLeastOneActive, getRpcAddressesForNameserviceId and getProxiesForAllNameNodesInNameservice (I am okay if this is done in a separate jira)

Done. I added a single unit test which wouldn't work if any of the three of these were broken, since isAtLeastOneActive by definition uses the other two.

bq. Finalizing upgrade is quite tricky. Consider the following scenarios:

See below for comments on this.

bq. Why is throw new AssertionError("Unreachable code."); in QuorumJournalManager.java methods?

These methods have to have to either return something or unconditionally throw an exception. In fact this method will always either return a value (when all JNs are up and responsive) or else will throw an exception. However, the compiler can't discern this, so I put in these exceptions to placate it. It was Todd's suggestion to throw AssertionError specifically. See his comment on HDFS-5138 on 2014/01/07.

bq. FSImage#doRollBack() - when canRollBack is false after checking if non-share directories can rollback, an exception must be immediately thrown, instead of checking shared editlog. 

I don't think I agree with this. Imagine a scenario where an earlier rollback attempt had succeeded for all the local storage dirs, but not the shared edit log. Shouldn't we continue the rollback in this case?

bq. Also printing Log.info when storages can be rolled back will help in debugging.

Good thinking. Done.

bq. FSEditlog#canRollBackSharedLog should accept StorageInfo instead of Storage

Good catch. Done.

bq. QuorumJournalManager#canRollBack and getJournalCTime can throw AssertionError (from DFSUtil.assertAllResultsEqual()). Is that the right exception to expose or IOException?

I don't think it actually makes a functional difference, since in either case we bail out of the process, but I've changed it nonetheless since we tend to favor IOExceptions throughout the codebase.

bq. Namenode startup throws AssertionError with -rollback option. I think we should throw IOException, which is how all the other failures are indicated.

Note that this code shouldn't be reachable anymore from actually running the command since NameNode#doRollback doesn't actually start the NN daemon anymore - just performs the rollback and shuts down. I only left this in there to make sure that in the future we don't inadvertently reintroduce the old behavior somehow. Given this, I think we should leave it as an AssertionError. Do you agree?

I've also updated the documentation as you suggested.

As for handling the partial upgrade failure as you've described, I'd like to add one more RPC call to the JournalManager to initiate analysis/recovery of the storage dirs upon first contact, and then refactor the contents of FSImage#recoverStorageDirs into NNUpgradeUtil just like was done with the other upgrade-related procedures. If this sounds OK to you, I'll go ahead and add that stuff and appropriate tests., {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12628708/HDFS-5840.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/6140//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/6140//console

This message is automatically generated., [~atm], sorry for the late reply. I had lost track of this.

{quote}
As for handling the partial upgrade failure as you've described, I'd like to add one more RPC call to the JournalManager to initiate analysis/recovery of the storage dirs upon first contact, and then refactor the contents of FSImage#recoverStorageDirs into NNUpgradeUtil just like was done with the other upgrade-related procedures. If this sounds OK to you, I'll go ahead and add that stuff and appropriate tests.
{quote}
Why not always recover in preupgrade step, instead of adding another RPC?

With rolling upgrade getting ready, some of the functionality added in that may be useful. For partial failures related to JournalNodes, the choice made in that feature to make the operation to rollback JournalNode idempotent. It looks like lot of rolling upgrade related code can be leveraged here, since upgrade is a special case of rolling upgrade. Should we explore that?, [~atm], realized my previous comment is incorrect. We cannot use the rolling upgrade functionality. We should perhaps fix the issues that this jira was targeting., bq. Why not always recover in preupgrade step, instead of adding another RPC?

That seems fine to me, and would certainly make this patch more straightforward. I'll work on that.

bq. Aaron T. Myers, realized my previous comment is incorrect. We cannot use the rolling upgrade functionality. We should perhaps fix the issues that this jira was targeting.

I agree with this as well., [~atm], this needs to be fixed in 2.4. Are you going to be working on this?, Hey Suresh, I haven't had a chance to get to this since I posted that initial patch. I can hopefully get something out late this week or early next, but if someone else beats me to it I won't object, and will happily review something., [~atm], most of us are swamped with wrapping up rolling upgrades and testing it. Can you please look into this?, Sorry, got swamped this week. Will try to get to it early next., [~sureshms] / [~atm] - Should this be a blocker for 2.4? Thanks., [~atm], any updates on this. [~jingzhao], found some issues and posted comments on HDFS-5138 as well., Rebase [~atm]'s patch. Also add storage recovery logic for JN based on the discussion in the comments., [~jingzhao], thanks for doing the patch.

Should JN throw an exception, if pre-upgrade or upgrade is retried, that upgrade is already in progress, restart the journal node before attempting namenode upgrade again?, Thanks for the comments, Suresh! Will update the patch to address the comments., Update the patch to address Suresh's comments. The patch also switch the sequence of the doUpgrade calls on shared edits and on local storage.

Now with the patch we have the following:
# If the doPreUpgrade call on JNs fail (i.e., not all the JNs succeed), we can restart NN and JNs for recovery, and NN and JNs will go back to the status before upgrade.
# If the doUpgrade call on JNs fail, some JNs may have both previous and current directories. Restarting JN cannot solve the issue. The issue has to be manually fixed. But the probability of this kind of failure is relatively low considering the doPreUpgrade call succeeds on all the JNs., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12636424/HDFS-5840.001.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 2 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.TestSafeMode
                  org.apache.hadoop.hdfs.qjournal.TestNNWithQJM

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/6479//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/6479//console

This message is automatically generated., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12636462/HDFS-5840.002.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 2 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.server.namenode.TestCacheDirectives

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/6481//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/6481//console

This message is automatically generated., Thanks a lot for taking this across the finish line, Jing. The updated patch you posted looks pretty good to me.

Suresh, does it look OK to you as well? If so, +1 from my perspective., +1 for the patch. I imported DFSUtil and minor edit to fix the javadoc link error to DFSUtil#getRpcAddressesForNameserviceId., Thanks for the review, Suresh and Aaron! +1 for the 003 patch. I will commit it soon., I've committed this., SUCCESS: Integrated in Hadoop-trunk-Commit #5397 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/5397/])
HDFS-5840. Follow-up to HDFS-5138 to improve error handling during partial upgrade failures. Contributed by Aaron T. Myers, Suresh Srinivas, and Jing Zhao. (jing9: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1581260)
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSUtil.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/client/QuorumJournalManager.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/JNStorage.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/Journal.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/JournalNode.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLog.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NNUpgradeUtil.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/site/apt/HDFSHighAvailabilityWithQJM.apt.vm
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/qjournal/server/TestJournal.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestHAStateTransitions.java
, FAILURE: Integrated in Hadoop-Yarn-trunk #520 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/520/])
HDFS-5840. Follow-up to HDFS-5138 to improve error handling during partial upgrade failures. Contributed by Aaron T. Myers, Suresh Srinivas, and Jing Zhao. (jing9: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1581260)
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSUtil.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/client/QuorumJournalManager.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/JNStorage.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/Journal.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/JournalNode.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLog.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NNUpgradeUtil.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/site/apt/HDFSHighAvailabilityWithQJM.apt.vm
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/qjournal/server/TestJournal.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestHAStateTransitions.java
, FAILURE: Integrated in Hadoop-Mapreduce-trunk #1737 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1737/])
HDFS-5840. Follow-up to HDFS-5138 to improve error handling during partial upgrade failures. Contributed by Aaron T. Myers, Suresh Srinivas, and Jing Zhao. (jing9: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1581260)
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSUtil.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/client/QuorumJournalManager.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/JNStorage.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/Journal.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/JournalNode.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLog.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NNUpgradeUtil.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/site/apt/HDFSHighAvailabilityWithQJM.apt.vm
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/qjournal/server/TestJournal.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestHAStateTransitions.java
, FAILURE: Integrated in Hadoop-Hdfs-trunk #1712 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1712/])
HDFS-5840. Follow-up to HDFS-5138 to improve error handling during partial upgrade failures. Contributed by Aaron T. Myers, Suresh Srinivas, and Jing Zhao. (jing9: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1581260)
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSUtil.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/client/QuorumJournalManager.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/JNStorage.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/Journal.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/JournalNode.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLog.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NNUpgradeUtil.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/site/apt/HDFSHighAvailabilityWithQJM.apt.vm
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/qjournal/server/TestJournal.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestHAStateTransitions.java
]