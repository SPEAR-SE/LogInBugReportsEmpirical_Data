[Here's a relevant SNN log
{noformat}
2011-07-19 23:07:30,466 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2011-07-19 23:07:30,467 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Secondary Web-server up at: virtual.somehost.com:50090
2011-07-19 23:07:30,467 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Secondary image servlet up at: virtual.somehost.com:50490
2011-07-19 23:07:30,467 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :60 secs (1 min)
2011-07-19 23:07:30,467 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :2048000000 bytes (2000000 KB)
2011-07-19 23:08:30,982 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 7576 bytes.
2011-07-19 23:08:30,993 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 30 bytes.
2011-07-19 23:08:31,093 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: defaultReplication = 3
2011-07-19 23:08:31,093 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: maxReplication = 50
2011-07-19 23:08:31,093 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: minReplication = 1
2011-07-19 23:08:31,093 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: maxReplicationStreams = 2
2011-07-19 23:08:31,093 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: shouldCheckForEnoughRacks = true
2011-07-19 23:08:31,099 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2011-07-19 23:08:31,099 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 273.85625 MB
2011-07-19 23:08:31,099 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^25 = 33554432 entries
2011-07-19 23:08:31,099 INFO org.apache.hadoop.hdfs.util.GSet: recommended=33554432, actual=33554432
2011-07-19 23:08:31,291 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=hdfs/virtual.somehost.com@somerealm.com
2011-07-19 23:08:31,291 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=hdfs
2011-07-19 23:08:31,291 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=true
2011-07-19 23:08:31,305 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=1000
2011-07-19 23:08:31,305 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isBlockTokenEnabled=true blockKeyUpdateInterval=600 min(s), blockTokenLifetime=600 min(s)
2011-07-19 23:08:31,333 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2011-07-19 23:08:31,349 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loading image file /tmp/hadoop-someuser/dfs/namesecondary/current/fsimage using no compression
2011-07-19 23:08:31,349 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Number of files = 71
2011-07-19 23:08:31,370 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Number of files under construction = 0
2011-07-19 23:08:31,375 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file of size 7576 loaded in 0 seconds.
2011-07-19 23:08:31,386 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-someuser/dfs/namesecondary/current/edits of size 30 edits # 2 loaded in 0 seconds.
2011-07-19 23:08:31,388 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2011-07-19 23:08:31,398 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Saving image file /tmp/hadoop-someuser/dfs/namesecondary/current/fsimage using no compression
2011-07-19 23:08:31,408 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file of size 7600 saved in 0 seconds.
2011-07-19 23:08:31,417 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Posted URL somehost.com:50470putimage=1&port=50490&machine=virtual.somehost.com&token=-35:1272447189:0:13111169
10000:1311116479833:4396bbd3f5b9947166068f39b1307441:CID-1c3abcd4-60e7-4b3c-be9a-420e9df14b74:BP-1333203313-98.137.97.97-1311113548658&newChecksum=5650481e7cb891340dbcc1b22db43eb5
2011-07-19 23:08:31,628 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 7600
2011-07-19 23:09:31,687 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2011-07-19 23:09:31,703 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2011-07-19 23:09:31,720 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2011-07-19 23:09:31,721 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: defaultReplication = 3
2011-07-19 23:09:31,721 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: maxReplication = 50
2011-07-19 23:09:31,721 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: minReplication = 1
2011-07-19 23:09:31,721 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: maxReplicationStreams = 2
2011-07-19 23:09:31,721 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: shouldCheckForEnoughRacks = true
2011-07-19 23:09:31,721 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2011-07-19 23:09:31,721 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 273.85625 MB
2011-07-19 23:09:31,721 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^25 = 33554432 entries
2011-07-19 23:09:31,721 INFO org.apache.hadoop.hdfs.util.GSet: recommended=33554432, actual=33554432
2011-07-19 23:09:31,909 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=hdfs/virtual.somehost.com@somerealm.com
2011-07-19 23:09:31,909 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=hdfs
2011-07-19 23:09:31,909 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=true
2011-07-19 23:09:31,909 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=1000
2011-07-19 23:09:31,909 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isBlockTokenEnabled=true blockKeyUpdateInterval=600 min(s), blockTokenLifetime=600 min(s)
2011-07-19 23:09:31,909 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2011-07-19 23:09:31,911 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-someuser/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2011-07-19 23:09:31,911 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2011-07-19 23:09:31,914 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Saving image file /tmp/hadoop-someuser/dfs/namesecondary/current/fsimage using no compression
2011-07-19 23:09:31,918 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file of size 107 saved in 0 seconds.
2011-07-19 23:09:31,927 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Posted URL somehost.com:50470putimage=1&port=50490&machine=virtual.somehost.com&token=-35:1272447189:0:13111169
71000:1311116911612:5650481e7cb891340dbcc1b22db43eb5:CID-1c3abcd4-60e7-4b3c-be9a-420e9df14b74:BP-1333203313-98.137.97.97-1311113548658&newChecksum=fab43b7e4a607aa4611d16d20e1b261c
2011-07-19 23:09:31,971 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 107
{noformat}

As you can see, the image size which was 7600 shrunk to 107 in the very next checkpoint. (Checkpointing was configured to be every 60 seconds). This was exactly the same time as the namenode was shutdown and restarted., Hi Ravi, can you reproduce this reliably? Can you write a test to exercise this case consistently?, After more investigation it was determined that when the edits log is empty and checkpointing takes place it makes the image file empty as well. This is has no relation to the restart. So may be we should change the title?


Also does it make sense to investigate this post all the changes needed for HDFS-1073, bq. After more investigation it was determined that when the edits log is empty and checkpointing takes place it makes the image file empty as well. This is has no relation to the restart. So may be we should change the title?

We should certainly change the title if you're confident that this is the observed behavior.

bq. Also does it make sense to investigate this post all the changes needed for HDFS-1073

Certainly worth re-investigating in trunk post HDFS-1073 merge, but we should look into this as well for the 0.22 (and perhaps prior) branches., I believe the reason the restart of the namenode is necessary to see the issue as it re reads the image file back in memory thus showing the users an empty namespace. However restart does not play any role in making the edits log empty., Hi Aaron, Arpit had written a test which reliably reproduces this on a 10 node cluster. I'm trying to reproduce this on a single node cluster but haven't been successful so far., bq. Arpit had written a test which reliably reproduces this on a 10 node cluster. I'm trying to reproduce this on a single node cluster but haven't been successful so far.

I'm surprised cluster size would be a factor, given that this is an NN/2NN-only issue.

Ideally you would create a test case using the unit test framework in the project. This might make it easier to formulate said test case since you could precisely control the timing/interleaving of NN and 2NN interactions using mockito, etc. I suspect creating a test to reliably exercise this case on a running cluster will be very difficult., The version of HDFS running on the 10 node clusters was remotes/origin/MR-279. I wasn't able to reproduce this issue on trunk (which was running on my single node cluster). On MR-279 ( e3d9a2bcbcab817043b1c4c41efb7036ce00904f ) its pretty easy. I'm attaching a test you can use to replicate the behavior on a single node cluster. I'm not going to work on this any longer (investigate why its happening) because this issue wasn't on trunk (already been fixed?).

To run the test:
1. Please set your checkpoint period (dfs.namenode.checkpoint.period) to 10 seconds. 
2. The idea is to make the NN shutdown at exactly the time the SNN is doing a checkpoint. On my machine the fillHDFS function takes exactly the time to cause that. You might have to adjust the sleep times while looking at the NN and SNN logs to replicate this.
3. The test fills up /tmp to create a big edits file. I'm not sure if that is necessary.]