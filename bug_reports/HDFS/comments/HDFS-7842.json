[Observation:
===========
Logs after Step 5
{noformat}
Namenode Log:
=============
15/02/25 13:10:59 INFO hdfs.StateChange: BLOCK* allocate blk_1073741830_1006{UCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-da5955d6-d021-4576-aa43-6caf70fcfd17:NORMAL:XXXXXXXXXXX:50010|RBW]]} for /File_1._COPYING_
15/02/25 13:10:59 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: XXXXXXXXXXX:50010 is added to blk_1073741830_1006{UCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-da5955d6-d021-4576-aa43-6caf70fcfd17:NORMAL:XXXXXXXXXXX:50010|RBW]]} size 11526
15/02/25 13:10:59 INFO hdfs.StateChange: DIR* completeFile: /File_1._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1004187273_1

Datanode Log:
=============
2015-02-25 13:10:59,222 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1954121396-XXXXXXXXXXX-1424840820188:blk_1073741830_1006 src: /XXXXXXXXXXX:34363 dest: /XXXXXXXXXXX:50010
2015-02-25 13:10:59,295 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1954121396-XXXXXXXXXXX-1424840820188:blk_1073741830_1006, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
{noformat}

Logs after step 12

{noformat}
Namenode Log:
============
15/02/25 13:15:51 INFO BlockStateChange: BLOCK* InvalidateBlocks: add blk_1073741830_1006 to XXXXXXXXXXX:50010

15/02/25 13:16:04 INFO hdfs.StateChange: BLOCK* allocate blk_1073741830_1006{UCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-f560cc10-74e8-4ea8-a8d9-6959fe5c1104:NORMAL:XXXXXXXXXXX:50010|RBW]]} for /File_2._COPYING_
15/02/25 13:16:05 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: XXXXXXXXXXX:50010 is added to blk_1073741830_1006{UCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-da5955d6-d021-4576-aa43-6caf70fcfd17:NORMAL:XXXXXXXXXXX:50010|FINALIZED]]} size 0
15/02/25 13:16:05 INFO hdfs.StateChange: DIR* completeFile: /File_2._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1317707332_1

Datanode Log:
=============
2015-02-25 13:15:51,831 INFO org.apache.hadoop.hdfs.server.common.Storage: Enabled trash for bpid BP-1954121396-XXXXXXXXXXX-1424840820188
2015-02-25 13:15:54,801 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741830_1006 file /mnt/tmp1/current/BP-1954121396-XXXXXXXXXXX-1424840820188/current/finalized/subdir0/subdir0/blk_1073741830 for deletion
2015-02-25 13:15:54,805 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1954121396-XXXXXXXXXXX-1424840820188 blk_1073741830_1006 file /mnt/tmp1/current/BP-1954121396-XXXXXXXXXXX-1424840820188/current/finalized/subdir0/subdir0/blk_1073741830

2015-02-25 13:16:05,074 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1954121396-XXXXXXXXXXX-1424840820188:blk_1073741830_1006 src: /XXXXXXXXXXX:34528 dest: /XXXXXXXXXXX:50010
2015-02-25 13:16:05,138 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /XXXXXXXXXXX:34528, dest: /XXXXXXXXXXX:50010, bytes: 6324, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1317707332_1, offset: 0, srvID: e33b81ce-8820-4343-955f-8726965d1917, blockid: BP-1954121396-XXXXXXXXXXX-1424840820188:blk_1073741830_1006, duration: 50371413
2015-02-25 13:16:05,141 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1954121396-XXXXXXXXXXX-1424840820188:blk_1073741830_1006, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
{noformat}

Log after Step 14
{noformat}
Datanode Log:
=============
2015-02-25 13:18:06,796 INFO org.apache.hadoop.hdfs.server.common.Storage: Restoring /mnt/tmp1/current/BP-1954121396-XXXXXXXXXXX-1424840820188/trash/finalized/subdir0/subdir0/blk_1073741832_1008.meta to /mnt/tmp1/current/BP-1954121396-XXXXXXXXXXX-1424840820188/current/finalized/subdir0/subdir0
2015-02-25 13:18:06,797 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 4 block files from trash.

Namenode Log:
============
15/02/25 13:18:07 INFO BlockStateChange: BLOCK NameSystem.addToCorruptReplicasMap: blk_1073741830 added as corrupt on XXXXXXXXXXX:50010 by host-10-177-112-123/XXXXXXXXXXX  because block is COMPLETE and reported length 11526 does not match length in block map 6324
15/02/25 13:18:07 INFO BlockStateChange: BLOCK* processReport: from storage DS-da5955d6-d021-4576-aa43-6caf70fcfd17 node DatanodeRegistration(XXXXXXXXXXX, datanodeUuid=e33b81ce-8820-4343-955f-8726965d1917, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-dd48fb1f-1d88-4d65-90c3-a7535053f4e1;nsid=2021392782;c=0), blocks: 5, hasStaleStorage: false, processing time: 0 msecs
{noformat}


Suggession :
===========
Restoring blocks from trash after downgrade can be avoided.

Please review and give your opinion on this issue. If it sounds good ill give a patch on this., AFAIK  {{-rollingUpgrade downgrade}} no longer availble,, Please check following link for same..

https://issues.apache.org/jira/browse/HDFS-7302?focusedCommentId=14335036&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14335036

{quote}
Restoring blocks from trash after downgrade can be avoided.
{quote}
I feel,HDFS-7645 will solve this.., > Restoring blocks from trash after downgrade can be avoided.

I agree that it is a bug to restore blocks from trash for downgrade.  Let's see if HDFS-7645 could solve this as Brahma suggested., Closing this issue as it is already been fixed as part of HDFS-7645]