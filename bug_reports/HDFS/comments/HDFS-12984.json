[Hi [~revans2], thanks for reporting this issue. I tried to recreate this issue by setting up {{MiniDFSCluster}} in a loop. It eventually runs out of heap memory but i don't see it happening due to {{BlockPoolSlice}}. (I took 15+ heap dumps on OOM and didn't found single instance of {{BlockPoolSlice}} in any of them). However there is genuine problem of OOM when {{MiniDFSCluster}} is built and shutdown periodically in loop. In {{MiniDFSCluster#shutdown}} we are calling {{ShutdownHookManager#clearShutdownHooks}} which removes all the shutdown hooks before they are called by {{Runtime}}. I think is not correct as it defeats the purpose of ShutdownHook. I will attach a initial patch for review on this. On bigger issue if OOM in {{MiniDFSCluster}} heap dumps shows that 80-90% memory is retained by entries in BlockMap which has references in multiple classes. , [~ajayydv],

I also ran into issues trying to reproduce this in some environments.  Specifically I could never make it happen on my MBP and I don't know why.  But if you look at the code inside the BlockPoolSlice 

https://github.com/apache/hadoop/blob/01f3f2167ec20b52a18bc2cf250fb4229cfd2c14/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/BlockPoolSlice.java#L165-L173

If an instance of this is ever created it can never be collected.  I am not sure why BlockPoolSlice instances are created some times by a MiniDFSCluster and not others.  I am not that familiar with the internals of the DataNode to say off the top of my head.  Glad to see you going in the right direction, and I agree that removing everything from the ShutdownHooksManager is far from ideal, but I didn't see this happening, at least not with 2.7.5 and 2.6.2., [~revans2] thanks for the info. Attaching a patch to address issue you raised. OOM i am getting in MiniDFSCluster seems to be another issue altogether. Will create separate jira for  it., Thanks [~ajayydv],

Looks good to me I am +1

[~kihwal],

It has been a long time since I checked anything into Hadoop.  Would you be willing to merge this in, and preferably take a look at it too?, +1 pending Jenkins., | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 21s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 19m 30s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m  6s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 51s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 20s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 13m 19s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 10s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m  1s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m 18s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m  3s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  1m  3s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 43s{color} | {color:green} hadoop-hdfs-project/hadoop-hdfs: The patch generated 0 new + 16 unchanged - 1 fixed = 16 total (was 17) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 10s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 12m  8s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 19s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 51s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:red}-1{color} | {color:red} unit {color} | {color:red}111m  9s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 22s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}170m  6s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.hdfs.server.namenode.TestReconstructStripedBlocks |
|   | hadoop.hdfs.server.namenode.TestReencryptionWithKMS |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:5b98639 |
| JIRA Issue | HDFS-12984 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12905169/HDFS-12984.001.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |
| uname | Linux 7410a0c9d868 3.13.0-135-generic #184-Ubuntu SMP Wed Oct 18 11:55:51 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 12d0645 |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_151 |
| findbugs | v3.1.0-RC1 |
| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/22638/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/22638/testReport/ |
| Max. process+thread count | 3032 (vs. ulimit of 5000) |
| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/22638/console |
| Powered by | Apache Yetus 0.7.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

, [~revans2],[~arpitagarwal] thanks for review. test failures are unrelated. both of them passed locally., [~revans2], any objections if I commit this? Lgtm., +1 for committing it., I've committed this. Thanks for reporting and reviewing this Robert.

Thanks for the fix Ajay., SUCCESS: Integrated in Jenkins build Hadoop-trunk-Commit #13485 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/13485/])
HDFS-12984. BlockPoolSlice can leak in a mini dfs cluster. Contributed (arp: rev b278f7b29305cb67d22ef0bb08b067c422381f48)
* (edit) hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/BlockPoolSlice.java
, [~revans2] thanks for reporting and review. [~arpitagarwal] thanks for review and commit.]