[Another possibility would be to rate-limit these scans so that we never do more than 1 per half hour (or whatever).  It seems like if we hit a lot of I/O errors on a failing drive (a common scenario for a failing drive), we'll be constantly doing these scans and discovering nothing interesting.  I also don't understand why the scan happens on all drives rather than just the failing one-- does anyone have some background on that?, Since HDFS-8845 is in, which actually addresses solution #1 in the description,
still do you think this jira should be kept open?, [~vinayrpet] sounds good we can close it as dup. But I think we still need to rate-limit the DiskChecker., bq. But I think we still need to rate-limit the DiskChecker.
After HDFS-8845, number of IO done by diskchecker is really low. So I dont think its required anymore to rate-limit DiskChecker. At least for datanode usecase., [~vinayrpet] I'm sure I've seen a couple of cases after HDFS-8845 where I noticed some IO spikes and for applications like HBase where users have strict SLAs it can have an impact in the 99th percentile or even in the 90th, so rate-limiting can be good to avoid some additional IO., Are you sure HDFS-8845 was there in case you have seen? because its still not part of any release., I had patched Hadoop 2.6 with HDFS-8845 in order to avoid running into this problem and I still noticed some IO spikes. I remember I even tuned vm.vfs_cache_pressure to try to cache as much as possible all inode and dentries but just the current directory traversal is too expensive when we haven't cached that dir or if the cache has been evicted. For sure I can confirm that HDFS-8845 has been helpful and the frequency of the spikes has reduced but scanning up to 64k directories can be really IO intensive.

, [~esteban] there are a few disk checkers in addition to {{BlockPoolSlice#checkDirs()}}.
VolumeScanner is one (which is disabled by default though), and DU is another one which runs every 10 minutes by default. Do you think that could be the potential source of I/O spikes?, Hi [~jojochuang],

The VolumeScanner class is part of the BlockScanner, which is not disabled by default in branch-2 (and in the latest cloudera releases as well.)  I agree that DU could be another potential source of load spikes., [~cmccabe] Colin, you're right. The docs about BlockScanner was wrong about it. It's run periodically by default 5 weeks. IMO, 5 weeks in between makes it hardly the replacement for BlockPoolSlice.checkDirs()., I'm sorry for confusion. This refers to the comments in HDFS-8845., bq. I'm sorry for confusion. This refers to the comments in HDFS-8845.

That's OK, [~jojochuang].  This is an area that could use some better documentation.

bq. It's run periodically by default 5 weeks. IMO, 5 weeks in between makes it hardly the replacement for BlockPoolSlice.checkDirs().

{{BlockScanner}} is certainly not intended as a "replacement" for {{checkDirs}}.  The main purpose of {{BlockScanner}} is to find blocks that have gone bad over time on the disk, but haven't been accessed in a while.]