[

Started cluster and after sometime SNN is not switching to Active state..

Then Checked zkfc logs,zkfc got hang while reading error Stream while executing above command i.e nc -z ,Hence SNN is not switching to Active state..


There are no logs getting logged but zkfc is running. Then checked threaddump and observed "StreamPumper for STDERR" is in timed waiting and not coming out for ever.

{noformat}
2012-07-06 11:45:44,698 INFO org.apache.hadoop.ha.SshFenceByTcpPort.jsch: SSH_MSG_SERVICE_REQUEST sent
2012-07-06 11:45:44,698 INFO org.apache.hadoop.ha.SshFenceByTcpPort.jsch: SSH_MSG_SERVICE_ACCEPT received
2012-07-06 11:45:44,709 INFO org.apache.hadoop.ha.SshFenceByTcpPort.jsch: Authentications that can continue: publickey,keyboard-interactive,password
2012-07-06 11:45:44,709 INFO org.apache.hadoop.ha.SshFenceByTcpPort.jsch: Next authentication method: publickey
2012-07-06 11:45:46,500 INFO org.apache.hadoop.ha.SshFenceByTcpPort.jsch: Authentication succeeded (publickey).
2012-07-06 11:45:46,501 INFO org.apache.hadoop.ha.SshFenceByTcpPort: Connected to *****-233
2012-07-06 11:45:48,021 INFO org.apache.hadoop.ha.SshFenceByTcpPort: Looking for process running on port 8020
2012-07-06 11:45:49,635 INFO org.apache.hadoop.ha.SshFenceByTcpPort: Indeterminate response from trying to kill service. Verifying whether it is running using nc...
{noformat}


Thought problem with nc -z but observed samething in logs where it was read error stream and processed by making SNN as active..(this is what I raised as issue)

{noformat}
2012-07-06 01:24:08,921 INFO org.apache.hadoop.ha.SshFenceByTcpPort.jsch: Authentication succeeded (publickey).
2012-07-06 01:24:08,921 INFO org.apache.hadoop.ha.SshFenceByTcpPort: Connected to HOST-*****-233
2012-07-06 01:24:08,982 INFO org.apache.hadoop.ha.SshFenceByTcpPort: Looking for process running on port 8020
2012-07-06 01:24:09,654 INFO org.apache.hadoop.ha.SshFenceByTcpPort: Indeterminate response from trying to kill service. Verifying whether it is running using nc...
2012-07-06 01:24:09,771 WARN org.apache.hadoop.ha.SshFenceByTcpPort: nc -z HOST-*****-233 8020 via ssh: bash: nc: command not found
2012-07-06 01:24:09,773 INFO org.apache.hadoop.ha.SshFenceByTcpPort: Verified that the service is down.
2012-07-06 01:24:09,773 INFO org.apache.hadoop.ha.SshFenceByTcpPort.jsch: Disconnecting from HOST-*****-233 port 22
2012-07-06 01:24:09,778 INFO org.apache.hadoop.ha.NodeFencer: ====== Fencing successful by method org.apache.hadoop.ha.SshFenceByTcpPort(null) ======
2012-07-06 01:24:09,778 INFO org.apache.hadoop.ha.ActiveStandbyElector: Writing znode /hadoop-ha/mycluster/ActiveBreadCrumb to indicate that the local node is the most recent active...
2012-07-06 01:24:09,790 INFO org.apache.hadoop.ha.SshFenceByTcpPort.jsch: Caught an exception, leaving main loop due to Socket closed
2012-07-06 01:24:09,835 INFO org.apache.hadoop.ha.ZKFailoverController: Trying to make NameNode at HOST-*****-20/*****.20:8020 active...
2012-07-06 01:24:29,959 INFO org.apache.hadoop.ha.ZKFailoverController: Successfully transitioned NameNode at HOST-*****-20/*****.20:8020 to active state
{noformat}

 
Here one more doubt is,initial it is able to read error stream and going head but later it got hang..? 

then gone through following link and got java behavior

http://oreilly.com/pub/h/1092

When reading any stream the java methods will block when nothing is available and the stream is left open..

Please correct me If I am going wrong..










, Attaching ZKfc logs and threaddumps, Good catch, Brahma.

How about changing the summary of this JIRA to something like "SSH fencing option may incorrectly succeed if netcat command not present" ?, Hi Aaron T.Myers

Thanks for looking at this issue.I have changed summary., We should treat that as fence failed, in 'command not found' case.

In other part, I am wordering why it is hanging? Because, StreamPumper is just uses BufferedReader. ReadLine will wait for the input on comsole. It should print command not found message right?
Untill it reads line, it will wait there. 

We may have to read the line only when it is really ready, can we make use of BufferedReader#ready api?
Within the fenceTimeout, if the stream is not ready then, we can return false instead of waiting for the input forever?, Eli, what is your opinion on this, above comment make sense to you, or you have any other suggestions to handle it?, Bhrahma, Uma,

Good find, isn't the issue here is that we're turning all non-zero return values from execCommand into failures? Ie we're not actually verifying the command executed successfully. Looks like we return ChannelExec#getExitStatus, which may return non-zero values, eg -1.

{code}
        rc = execCommand(session, "nc -z " + serviceAddr.getHostName() +
            " " + serviceAddr.getPort());
        if (rc == 0) {
          // the service is still listening - we are unable to fence
          LOG.warn("Unable to fence - it is running but we cannot kill it");
          return false;
        } else {
          LOG.info("Verified that the service is down.");
          return true;          
        }
{code}, Hi Eli, Thanks a lot for taking a look.

 I think we have to handle 127 and 126 code separateltly and return false as they indicate command not exist or doesn't have permissions.http://theory.uwinnipeg.ca/localfiles/infofiles/bash/bashref_43.html#SEC50

{quote}
Looks like we return ChannelExec#getExitStatus, which may return non-zero values, eg -1.
{quote}
When I checked the changeLog of JSCh, I observed below change.

{quote}
â€¢feature: added 'Channel.isClosed()'. Channel.getExitStatus() should be invoked after Channel.isClosed()==true.
{quote}

Looking at our code, we are not calling in that way right?
After calling status only we are disconnecting in finally.

{code}
  return exec.getExitStatus();
    } finally {
      cleanup(exec);
    }
{code}

I found a case where we have to call ChannelExec#getExitStatus after Channel.isClosed()==true
 do you think we have to hanlde this case?, * Regarding StreamPumper thread getting hanged:
I tried to reproduce issue by creating a small pause using debug point before starting the thread for reading streams inside {{SshFenceByTcpPort.execCommand(Session, String)}}, before executing {{errPumper.start();}}.
By the time I release the debug point, {{exec}} was closed. And {{errPumper}} got hanged.
*# We can start the threads for reading streams only if {{exec}} is not closed.
*# We can wait till {{exec}} is closed before getting exitStatus.

* Regarding nc command not found case I think we can handle as following
*# If the command present and process running with specified port, then nc exit code will be 0
*# Command present and no process is running with that port, then nc exit code will be 1.
*# If command itself will not present then exit code will be 127.
*# If command dont have permissions then exit code will be 126 ( as Uma mentioned)
Here we need to treat only return code 1 as success, others should be treated as failed.
One configuration we can introduce to specify the alternative {{nc}} command (netcat) in case its not present in the machine.

, Attaching the patch, Made "nc" command configurable "dfs.ha.fencing.ssh.nc-command". In cases if this command is replaced with netcat in the linux of cluster, that can be configured using this configuration., +1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12542404/HDFS-3618.patch
  against trunk revision .

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 1 new or modified test files.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 eclipse:eclipse.  The patch built with eclipse:eclipse.

    +1 findbugs.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    +1 core tests.  The patch passed unit tests in hadoop-common-project/hadoop-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-site.

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/3096//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/3096//console

This message is automatically generated., {code}
 if (!exec.isClosed()) {
+        outPumper.start();
+        errPumper.start();
{code}
Even after check passed, command can be closed. So, this threads can hang again?
Introducing timeout for commands should be the option and check thread  is alive or not? (I think we did this in our internal brnach also right?), Posting updated patch, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12597724/HDFS-3618.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:red}-1 javadoc{color}.  The javadoc tool appears to have generated 2 warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:red}-1 findbugs{color}.  The patch appears to introduce 2 new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.ha.TestSshFenceByTcpPort
                  org.apache.hadoop.hdfs.server.balancer.TestBalancerWithNodeGroup

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/4811//testReport/
Findbugs warnings: https://builds.apache.org/job/PreCommit-HDFS-Build/4811//artifact/trunk/patchprocess/newPatchFindbugsWarningshadoop-common.html
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/4811//console

This message is automatically generated., Updated test, Findbug and javadoc warnings are unrelated. I am seeing these on every patch submitted. may be some problem with QA?, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12597900/HDFS-3618.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:red}-1 findbugs{color}.  The patch appears to introduce 2 new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/4820//testReport/
Findbugs warnings: https://builds.apache.org/job/PreCommit-HDFS-Build/4820//artifact/trunk/patchprocess/newPatchFindbugsWarningshadoop-common.html
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/4820//console

This message is automatically generated., \\
\\
| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:red}-1{color} | patch |   0m  0s | The patch command could not apply the patch during dryrun. |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12597900/HDFS-3618.patch |
| Optional Tests | javadoc javac unit findbugs checkstyle site |
| git revision | trunk / f1a152c |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/10549/console |


This message was automatically generated., \\
\\
| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:red}-1{color} | patch |   0m  0s | The patch command could not apply the patch during dryrun. |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12597900/HDFS-3618.patch |
| Optional Tests | javadoc javac unit findbugs checkstyle site |
| git revision | trunk / f1a152c |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/10560/console |


This message was automatically generated., Rebased the patch against latest trunk code., \\
\\
| (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | pre-patch |  22m 15s | Pre-patch trunk compilation is healthy. |
| {color:green}+1{color} | @author |   0m  0s | The patch does not contain any @author tags. |
| {color:green}+1{color} | tests included |   0m  0s | The patch appears to include 1 new or modified test files. |
| {color:green}+1{color} | javac |   7m 27s | There were no new javac warning messages. |
| {color:green}+1{color} | javadoc |   9m 38s | There were no new javadoc warning messages. |
| {color:green}+1{color} | release audit |   0m 22s | The applied patch does not increase the total number of release audit warnings. |
| {color:green}+1{color} | site |   2m 58s | Site still builds. |
| {color:green}+1{color} | checkstyle |   3m 18s | There were no new checkstyle issues. |
| {color:green}+1{color} | whitespace |   0m  0s | The patch has no lines that end in whitespace. |
| {color:green}+1{color} | install |   1m 33s | mvn install still works. |
| {color:green}+1{color} | eclipse:eclipse |   0m 33s | The patch built with eclipse:eclipse. |
| {color:green}+1{color} | findbugs |   5m  4s | The patch does not introduce any new Findbugs (version 3.0.0) warnings. |
| {color:green}+1{color} | common tests |  22m 51s | Tests passed in hadoop-common. |
| {color:green}+1{color} | hdfs tests | 160m 59s | Tests passed in hadoop-hdfs. |
| | | 237m  1s | |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12737535/HDFS-3618-04.patch |
| Optional Tests | javadoc javac unit findbugs checkstyle site |
| git revision | trunk / e830207 |
| hadoop-common test log | https://builds.apache.org/job/PreCommit-HDFS-Build/11231/artifact/patchprocess/testrun_hadoop-common.txt |
| hadoop-hdfs test log | https://builds.apache.org/job/PreCommit-HDFS-Build/11231/artifact/patchprocess/testrun_hadoop-hdfs.txt |
| Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/11231/testReport/ |
| Java | 1.7.0_55 |
| uname | Linux asf907.gq1.ygridcore.net 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/11231/console |


This message was automatically generated., I like the idea of making ssh fencing command configurable.

* Is it vulnerable to remote command injection?
* Some Linux distro do not support nc with -z option. Should we also make that configurable? Like for example, make default value of {{dfs.ha.fencing.ssh.nc-command}} as {{nc -z}}.

Please also consider making it more portable for other Linux distros or other platforms, so that it's easier to workaround recurring future issues like this :), The "-z" option is supported by the plain old BSD implementation of netcat. It looks like newer distros are moving to NMAP's netcat replacement, which does not support "-z".

Someone suggested an equivalent of "-z" for nmap-ncat.
http://unix.stackexchange.com/questions/296023/whats-the-gnu-netcats-z-equivalent-option-in-nmap-ncat

A lazy way out is simply making the entire command configurable.  One could also make it detect which variant is available.  {{nc -z 127.0.0.1 1234}} will return 2 if the host has nmap-ncat and 0 or 1 if bsd nc. , | (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 16s{color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 35s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 14m  5s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 10m 36s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m 36s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  2m  6s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 37s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  3m 30s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 36s{color} | {color:green} trunk passed {color} |
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 15s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m 33s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 10m 22s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 10m 22s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m 41s{color} | {color:green} root: The patch generated 0 new + 15 unchanged - 1 fixed = 15 total (was 16) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  2m  5s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 37s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  3m 52s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 41s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  8m 22s{color} | {color:green} hadoop-common in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 77m 44s{color} | {color:green} hadoop-hdfs in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 37s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}144m 58s{color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:a9ad5d6 |
| JIRA Issue | HDFS-3618 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12737535/HDFS-3618-04.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux c3970d7c6780 3.13.0-95-generic #142-Ubuntu SMP Fri Aug 12 17:00:09 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / e692316 |
| Default Java | 1.8.0_111 |
| findbugs | v3.0.0 |
|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/18129/testReport/ |
| modules | C: hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs U: . |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/18129/console |
| Powered by | Apache Yetus 0.5.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

]