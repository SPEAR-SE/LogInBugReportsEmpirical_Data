[Hello [~odelalleau].

I answered your question on Stack Overflow.  I'm pasting the answer here too.  After using the techniques I described to configure a path with a drive spec, I expect you won't see these errors anymore.  In the future, the best forum for questions like this is the user@hadoop.apache.org mailing list.

You can specify a drive spec in {{hadoop.tmp.dir}} in core-site.xml by prepending a '/' in front of the absolute path, and using '/' as the path separator instead of '\' for all path elements.  For example, if the desired absolute path is D:\tmp\hdp, then it would look like this:

{code}
    <property>
        <name>hadoop.tmp.dir</name>
        <value>/D:/tmp/hadoop</value>
    </property>
{code}

The reason this works is that the default values for many of the HDFS directories are configured to be file://${hadoop.tmp.dir}/suffix.  See the default definitions of {{dfs.namenode.name.dir}}, {{dfs.datanode.data.dir}} and {{dfs.namenode.checkpoint.dir}} here:

http://hadoop.apache.org/docs/r2.7.1/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml

Substituting the above value for {{hadoop.tmp.dir}} yields a valid {{file:}} URL with a drive spec and no authority, which satisfies the requirements for the HDFS configuration.  It's important to use '/' instead of '\', because a bare unencoded '\' character is not valid in URL syntax.

http://www.ietf.org/rfc/rfc1738.txt

If you prefer not to rely on this substitution behavior, then it's also valid to override all configuration properties that make use of {{hadoop.tmp.dir}} within your hdfs-site.xml file.  Each value must be a full {{file:}} URL.  For example:

{code}
    <property>
        <name>dfs.namenode.name.dir</name>
        <value>file:///D:/tmp/hadoop/dfs/name</value>
    </property>

    <property>
        <name>dfs.datanode.data.dir</name>
        <value>file:///D:/tmp/hadoop/dfs/data</value>
    </property>

    <property>
        <name>dfs.namenode.checkpoint.dir</name>
        <value>file:///D:/tmp/hadoop/dfs/namesecondary</value>
    </property>
{code}

You might find this more readable overall., Thanks, I appreciate the help!

I wonder how this is not a bug though, even if there exists a workaround. But not a big deal., [~odelalleau], glad to hear this helped!

bq. I wonder how this is not a bug though, even if there exists a workaround. But not a big deal.

I agree that the configuration file can end up looking non-intuitive on Windows.  Unfortunately, I don't see a way to do any better while maintaining the feature that everything defaults to using {{hadoop.tmp.dir}} for quick dev deployments.  This is a side effect of the fact that a Windows file system path is not always valid as a URL.  On Linux, a file system path will always be a valid URL (assuming the individual path names stick to the characters that don't require escaping).  I typically advise using a full {{file:}} URL in production configurations to make everything clearer for operators.]