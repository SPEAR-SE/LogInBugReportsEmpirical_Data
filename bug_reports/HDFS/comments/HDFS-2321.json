[Please check below for more details.

[INFO] Executing tasks

main:
    [mkdir] Created dir: E:\Hadoop_common\hadoop-hdfs-project\hadoop-hdfs\target
\downloads\commons-daemon
      [get] Getting: http://archive.apache.org/dist/commons/daemon/binaries/1.0.
3/${commons.daemon.os.name}/commons-daemon-1.0.3-bin-${commons.daemon.os.name}-$
{commons.daemon.os.arch}.tar.gz
      [get] To: E:\Hadoop_common\hadoop-hdfs-project\hadoop-hdfs\target\download
s\commons-daemon\commons-daemon-1.0.3-bin-${commons.daemon.os.name}-${commons.da
emon.os.arch}.tar.gz
      [get] Error opening connection java.io.FileNotFoundException: http://archi
ve.apache.org/dist/commons/daemon/binaries/1.0.3/${commons.daemon.os.name}/commo
ns-daemon-1.0.3-bin-${commons.daemon.os.name}-${commons.daemon.os.arch}.tar.gz
      [get] Error opening connection java.io.FileNotFoundException: http://archi
ve.apache.org/dist/commons/daemon/binaries/1.0.3/${commons.daemon.os.name}/commo
ns-daemon-1.0.3-bin-${commons.daemon.os.name}-${commons.daemon.os.arch}.tar.gz
      [get] Error opening connection java.io.FileNotFoundException: http://archi
ve.apache.org/dist/commons/daemon/binaries/1.0.3/${commons.daemon.os.name}/commo
ns-daemon-1.0.3-bin-${commons.daemon.os.name}-${commons.daemon.os.arch}.tar.gz
      [get] Can't get http://archive.apache.org/dist/commons/daemon/binaries/1.0
.3/${commons.daemon.os.name}/commons-daemon-1.0.3-bin-${commons.daemon.os.name}-
${commons.daemon.os.arch}.tar.gz to E:\Hadoop_common\hadoop-hdfs-project\hadoop-
hdfs\target\downloads\commons-daemon\commons-daemon-1.0.3-bin-${commons.daemon.o
s.name}-${commons.daemon.os.arch}.tar.gz
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Summary:
[INFO]
[INFO] Apache Hadoop Project POM ......................... SUCCESS [3.716s]
[INFO] Apache Hadoop Annotations ......................... SUCCESS [5.678s]
[INFO] Apache Hadoop Project Dist POM .................... SUCCESS [0.445s]
[INFO] Apache Hadoop Assemblies .......................... SUCCESS [0.416s]
[INFO] Apache Hadoop Auth ................................ SUCCESS [8.029s]
[INFO] Apache Hadoop Auth Examples ....................... SUCCESS [11.643s]
[INFO] Apache Hadoop Common .............................. SUCCESS [1:59.933s]
[INFO] Apache Hadoop Common Project ...................... SUCCESS [0.044s]
[INFO] Apache Hadoop HDFS ................................ FAILURE [36.363s]
[INFO] Apache Hadoop HDFS Project ........................ SKIPPED
[INFO] hadoop-yarn-api ................................... SKIPPED
[INFO] hadoop-yarn-common ................................ SKIPPED
[INFO] hadoop-yarn-server-common ......................... SKIPPED
[INFO] hadoop-yarn-server-nodemanager .................... SKIPPED
[INFO] hadoop-yarn-server-resourcemanager ................ SKIPPED
[INFO] hadoop-yarn-server-tests .......................... SKIPPED
[INFO] hadoop-yarn-server ................................ SKIPPED
[INFO] hadoop-yarn ....................................... SKIPPED
[INFO] hadoop-mapreduce-client-core ...................... SKIPPED
[INFO] hadoop-mapreduce-client-common .................... SKIPPED
[INFO] hadoop-mapreduce-client-shuffle ................... SKIPPED
[INFO] hadoop-mapreduce-client-app ....................... SKIPPED
[INFO] hadoop-mapreduce-client-hs ........................ SKIPPED
[INFO] hadoop-mapreduce-client-jobclient ................. SKIPPED
[INFO] hadoop-mapreduce-client ........................... SKIPPED
[INFO] hadoop-mapreduce .................................. SKIPPED
[INFO] Apache Hadoop Main ................................ SKIPPED
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------, I am proceeding with below conditions in my local environment as a workaround.

  <condition property="commons.daemon.os.name" value="linux">
                   <os family="windows"/>
  </condition>
  <condition property="commons.daemon.os.arch" value="i686">
                    <os family="windows"/>
  </condition>

Here our building env is in windows, because of that we are getting this error for every updation. 

Alejandro, Do you have any better suggestion here to handle this?
 it will be problem if target os is solaris and building env is windows.

Thanks
Uma
, -D options also would work fine.
E:\Trunk-Common>mvn clean install -DskipTests -Dcommons.daemon.os.arch=i686 -Dco
mmons.daemon.os.name=linux, Uma, I wouldn't force the os.arch/os.name to linux, instead I'd skip that download as per patch HDFS-2322, Hi Alejandro,

 Thanks a lot for taking a look.
 If you skip downloading itself, then how jsvc file will be copied to release?
 
Thanks
Uma, Duplicated with HDFS-2322]