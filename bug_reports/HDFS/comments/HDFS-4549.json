[I've attached my patch. The 'content-length' field has been added to the HTTP response in order to workaround the Jetty issue. This patch includes a backported HDFS-3318., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12571993/HDFS-4549.1.patch
  against trunk revision .

    {color:red}-1 patch{color}.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/4039//console

This message is automatically generated., Could I get somebody to look at this?, Hi Mark, trunk uses OpenEntity (HDFS-3577) for specifying content-length.  How about we backport HDFS-3577 and the related JIRAs to branch-1 so that it is easier to maintain the code?, That seems like a reasonable idea. I'll look into that., I've backported HDFS-3577, HDFS-3318, and HDFS-3788 as best as possible. However, I'm seeing performance problems above 2GB. It looks like when the MessageBodyWriter reports a length greater than 2GB, Jersey is reverting to chunked transfer, causing the previously seen performance problems with Jetty.

I tested this on a 2.0.3 deployment and got the same results (chunked transfer above a certain size).

[~szetszwo], can you expand on the motivation for using MessageBodyWriter and OpenEntity instead of manually setting the header values? Would it be problematic to make all branches use the method of my first patch? It seems that Jersey is taking the MessageBodyWriter information only as a suggestion., I think we should leave Jersey to decide what to use, chunk encoding or not. If we always force the content-length, we can run into issues in clients (I believe Java HTTP does -or used to do this-) that try to allocate a buffer in memory for the full content-length. By using chunk encoding, you are forcing the client to fallback on partial-caching/flushing.

Is the Jetty version use by Hadoop 1 that has issues with chunk encoding?

Also, if we don't see the problem in trunk/branch-2, why change it there? not broken, don't fix it. 
, @Mark, the motivation for using MessageBodyWriter is that manually setting the Content-Length header may cause problems such as Jersey may add the another Content-Length header.  It seems that MessageBodyWriter is a standard way in Jersey.

BTW, do you see any performance problem in trunk/2.0.3?, bq. I think we should leave Jersey to decide what to use, chunk encoding or not.

I agree that that would usually be best, however this is causing significant performance problems, so I think it needs to be handled somehow. I just took a look at the memory usage when pulling a 1GB file (which does use content-length) and didn't see any memory usage increase. I'll look into this further though.

{quote}
Is the Jetty version use by Hadoop 1 that has issues with chunk encoding?
Also, if we don't see the problem in trunk/branch-2, why change it there? not broken, don't fix it.
{quote}

The issue has been observed in 6.1.26, which is used by branch-1, branch-2, and trunk. This problem was first seen (chunked encoding being used, leading to performance loss) in branch-1 (1.0.4 to be precise) for files of any size. I didn't see it on branch-2/trunk because I didn't test larger files. When I was backporting though, I noticed that it was still slow above 2GB, and it turns out the same is true for branch-2/trunk (I've attached logs for a demonstration of this issue using 2.0.3-alpha)., [~szetszwo], that makes sense. Yes, I see performance issues above 2GB on 2.0.3., @Mark, Since there are also performance problem in trunk, let's first backport the patch to branch-1 and then fix all the branch the same way.  If manually setting content-length works well, we may set it when the file size is >= 2GB.

Let me create another JIRA for backporting and continue the performance improvement here., Filed HDFS-4715 for backporting.  I will review the branch-1 patch., Before changing to remove chunk encoding, can we try the following?

http://stackoverflow.com/questions/9031311/slow-transfers-in-jetty-with-chunked-transfer-encoding-at-certain-buffer-size
, Mark, any update?  Are you still working on this?]