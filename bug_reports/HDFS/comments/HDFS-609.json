[I will take a first pass at it., Is there anything left to do here? Looks like #1 and #2 are already addressed on trunk., I disagree - I don't think these are addressed in trunk.

#1) the APPEND flag seems to track through to startFileInternal in FSNamesystem, which as Hairong mentioned just converts the INode but does not properly pass back a LocatedBlock for the last block, or convert it to underconstruction status.
#2) There still doesn't seem to be any checks that prevent a user from passing blocksize or replication when CreateFlag.APPEND is specified, Thanks for the clarification Todd. I was looking at the FileSystem#append APIs looks like those didn't get removed when they were merged with create and apparently create with append was checked in without a test?, So are we saying that append doesn't work when calling create() with the append flag, but it works when calling append()? For the 0.21 release we could either fix this (any volunteers?) or throw an unsupported exception for create with the append flag., Updating fix version since this needs to be fixed on trunk as well., Updated HADOOP-5438, seems like we need to figure out the right create/append API before we put it in a release., This is the HDFS portion of HADOOP-6826., Code changes look fine. , I've committed this. (I ran test-patch before doing so, which passed.), test-patch does not run tests. We should keep following common practices and go through patch available stage, shouldn't we., Konstantin, This was one of those situations where the changes for this JIRA had to be applied at the same time as its parent HADOOP-5438, so wasn't possible to have Hudson check this patch either before or after HADOOP-5438 was committed, so I did it manually. You're right about the tests. I should have mentioned that I did run tests at the time I posted the patch - I'm re-running them now to be sure I didn't miss anything. , Thanks Tom for clarifying. There was no comments about running tests.]