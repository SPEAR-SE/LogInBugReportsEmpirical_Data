[For reference, this results in an error like the following:

{quote}
java.lang.NullPointerException
at org.apache.hadoop.hdfs.web.JsonUtil.toDatanodeInfo(JsonUtil.java:305)
at org.apache.hadoop.hdfs.web.JsonUtil.toDatanodeInfoArray(JsonUtil.java:348)
at org.apache.hadoop.hdfs.web.JsonUtil.toLocatedBlock(JsonUtil.java:377)
at org.apache.hadoop.hdfs.web.JsonUtil.toLocatedBlockList(JsonUtil.java:413)
at org.apache.hadoop.hdfs.web.JsonUtil.toLocatedBlocks(JsonUtil.java:446)
at org.apache.hadoop.hdfs.web.WebHdfsFileSystem.getFileBlockLocations(WebHdfsFileSystem.java:1063)
at org.apache.hadoop.fs.FileSystem$4.next(FileSystem.java:1812)
at org.apache.hadoop.fs.FileSystem$4.next(FileSystem.java:1797)
{quote}, Here's a patch which addresses the issue by checking for a {{null}} value in {{JsonUtil}} when deserializing the response from WebHdfs and providing a default if it is null. I used the same default (0) as what's in the PB definition., This change looks good, thanks Aaron. What do you think about doing the same treatment for other optional fields in DatanodeInfoProto, e.g. {{capacity}}, {{dfsUsed}}, etc? Right now I know we set them to dummy values on the NN so this doesn't come up, but we really should try to make our JSON parsing consistent with our PB defs., While I agree in principle, would you mind if we did that in a separate JIRA? I'd really like to keep this fix small and isolated. If that's amenable to you, I'll go ahead and file another one., Sure, +1 pending Jenkins. Thanks Aaron., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12609746/HDFS-5403.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:red}-1 eclipse:eclipse{color}.  The patch failed to build with eclipse:eclipse.

    {color:red}-1 findbugs{color}.  The patch appears to introduce 1 new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/5255//testReport/
Findbugs warnings: https://builds.apache.org/job/PreCommit-HDFS-Build/5255//artifact/trunk/patchprocess/newPatchFindbugsWarningshadoop-hdfs.html
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/5255//console

This message is automatically generated., I'm pretty confident the eclipse failure was unrelated to this change.

The findbugs warning was just using "new Long(0)" instead of "0l". The difference between this patch and the last is just the following:

{code}
diff --git hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/JsonUtil.java hadoop-hdfs-project/hadoo
index 0238469..db4adc5 100644
--- hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/JsonUtil.java
+++ hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/JsonUtil.java
@@ -304,7 +304,7 @@ static DatanodeInfo toDatanodeInfo(final Map<?, ?> m) {
     
     Object infoSecurePort = m.get("infoSecurePort");
     if (infoSecurePort == null) {
-      infoSecurePort = new Long(0); // same as the default value in hdfs.proto
+      infoSecurePort = 0l; // same as the default value in hdfs.proto
     }
 
     return new DatanodeInfo(
{code}

I'll commit this based on Andrew's +1 if Jenkins comes back clean., {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12609806/HDFS-5403.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/5260//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/5260//console

This message is automatically generated., SUCCESS: Integrated in Hadoop-trunk-Commit #4649 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/4649/])
HDFS-5403. WebHdfs client cannot communicate with older WebHdfs servers post HDFS-5306. Contributed by Aaron T. Myers. (atm: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1535056)
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/JsonUtil.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestJsonUtil.java
, I've just committed this to trunk, branch-2, and branch-2.2.

Thanks a lot for the review, Andrew. Here's the more comprehensive followup JIRA we discussed: HDFS-5408, SUCCESS: Integrated in Hadoop-Yarn-trunk #372 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/372/])
HDFS-5403. WebHdfs client cannot communicate with older WebHdfs servers post HDFS-5306. Contributed by Aaron T. Myers. (atm: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1535056)
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/JsonUtil.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestJsonUtil.java
, FAILURE: Integrated in Hadoop-Hdfs-trunk #1562 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1562/])
HDFS-5403. WebHdfs client cannot communicate with older WebHdfs servers post HDFS-5306. Contributed by Aaron T. Myers. (atm: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1535056)
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/JsonUtil.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestJsonUtil.java
, FAILURE: Integrated in Hadoop-Mapreduce-trunk #1588 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1588/])
HDFS-5403. WebHdfs client cannot communicate with older WebHdfs servers post HDFS-5306. Contributed by Aaron T. Myers. (atm: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1535056)
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/JsonUtil.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestJsonUtil.java
]