[There are 6 test suites that fail on Windows due to this problem.  Perhaps the native code in HADOOP-9056 will help resolve this?

{code}
testSelectInputStreamsMajorityDown(org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager)  Time elapsed: 1203 sec  <<< ERROR!
org.apache.hadoop.hdfs.qjournal.client.QuorumException: Could not format one or more JournalNodes. 2 successful responses:
127.0.0.1:64731: null [success]
127.0.0.1:64721: null [success]
1 exceptions thrown:
127.0.0.1:64711: The process cannot access the file because another process has locked a portion of the file
	at java.io.RandomAccessFile.read(Native Method)
	at java.io.RandomAccessFile.readLine(RandomAccessFile.java:871)
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.tryLock(Storage.java:664)
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.lock(Storage.java:629)
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:457)
	at org.apache.hadoop.hdfs.qjournal.server.JNStorage.analyzeStorage(JNStorage.java:190)
	at org.apache.hadoop.hdfs.qjournal.server.JNStorage.<init>(JNStorage.java:70)
	at org.apache.hadoop.hdfs.qjournal.server.Journal.<init>(Journal.java:133)
	at org.apache.hadoop.hdfs.qjournal.server.JournalNode.getOrCreateJournal(JournalNode.java:78)
	at org.apache.hadoop.hdfs.qjournal.server.JournalNodeRpcServer.format(JournalNodeRpcServer.java:138)
	at org.apache.hadoop.hdfs.qjournal.protocolPB.QJournalProtocolServerSideTranslatorPB.format(QJournalProtocolServerSideTranslatorPB.java:119)
	at org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$QJournalProtocolService$2.callBlockingMethod(QJournalProtocolProtos.java:14016)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:474)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1018)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1763)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1759)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1437)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1757)

	at org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:213)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.format(QuorumJournalManager.java:200)
	at org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager.setup(TestQuorumJournalManager.java:94)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:44)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:41)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:27)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:31)
	at org.junit.runners.BlockJUnit4ClassRunner.runNotIgnored(BlockJUnit4ClassRunner.java:79)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:71)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:49)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:193)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:52)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:191)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:42)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:184)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:236)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)
{code}
, This usually means that someone did not close a handle (stream) on the file. The fix is to find a place where the stream is not closed. Native code only helps with some concurrent scenarios, IIRC, if someone wanted to delete a file while it is open (...not 100% sure though).

Hope this helps, So, for the failure we post, I think, is because in the previous test TestQuorumJournalManager #testOneJNMissingSegments, we called the function cluster.restartJournalNode, and this function is defined like this. It created a new JournalNode object, and call the start. But after the test, when we call shutdown function, in windows environment, we did not explicitly stop this new created object, that is cause the failure. So, what we can do is :
option 1: At MiniJournalCluster.class, we can create a arrayList<JournalNode> to hold all the restartedNode, and at shutdown function, we stop all the nodes including the nodes in this arraylist.
option 2: At MiniJournalCluster.class, In function restartJournalNode, we do not actually create a new journalNode object, just reuse the node ID which we restarted. What we can do is :
    nodes[i] = new JournalNode();
    nodes[i].setConf(conf);
    nodes[i].start()
instead of :
    JournalNode jt = new JournalNode();
    jt.setConf(conf);
    jt.start().
Both of two methods can fix that test case., But for next following test case, there are still other failures. For example, when we run test testOutOfSyncAtBeginningOfSegment0,testOutOfSyncAtBeginningOfSegment1 and testOutOfSyncAtBeginningOfSegment2 together, we will get test failure on testOutOfSyncAtBeginningOfSegment2.

org.apache.hadoop.hdfs.qjournal.client.QuorumException: Could not format one or more JournalNodes. 2 successful responses:
127.0.0.1:52891: null [success]
127.0.0.1:52901: null [success]
1 exceptions thrown:
127.0.0.1:52911: Couldn't rename log C:\hadoop\hadoop-hdfs-project\hadoop-hdfs\build\test\data\dfs\journalnode-2\test-journal\current\edits_inprogress_0000000000000000004 to C:\hadoop\hadoop-hdfs-project\hadoop-hdfs\build\test\data\dfs\journalnode-2\test-journal\current\edits_inprogress_0000000000000000004.empty
	at org.apache.hadoop.hdfs.server.namenode.FileJournalManager$EditLogFile.renameSelf(FileJournalManager.java:505)
	at org.apache.hadoop.hdfs.server.namenode.FileJournalManager$EditLogFile.moveAsideEmptyFile(FileJournalManager.java:478)
	at org.apache.hadoop.hdfs.qjournal.server.Journal.scanStorageForLatestEdits(Journal.java:188)
	at org.apache.hadoop.hdfs.qjournal.server.Journal.<init>(Journal.java:142)
	at org.apache.hadoop.hdfs.qjournal.server.JournalNode.getOrCreateJournal(JournalNode.java:78)
	at org.apache.hadoop.hdfs.qjournal.server.JournalNodeRpcServer.format(JournalNodeRpcServer.java:138)
	at org.apache.hadoop.hdfs.qjournal.protocolPB.QJournalProtocolServerSideTranslatorPB.format(QJournalProtocolServerSideTranslatorPB.java:119)
	at org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$QJournalProtocolService$2.callBlockingMethod(QJournalProtocolProtos.java:14016)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:474)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1018)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1778)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Unknown Source)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1444)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1771)

	at org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:213)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.format(QuorumJournalManager.java:200)
	at org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager.setup(TestQuorumJournalManager.java:100)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
	at java.lang.reflect.Method.invoke(Unknown Source)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:44)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:41)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:27)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:31)
	at org.junit.runners.BlockJUnit4ClassRunner.runNotIgnored(BlockJUnit4ClassRunner.java:79)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:71)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:49)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:193)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:52)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:191)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:42)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:184)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:236)
	at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:50)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)

, I tried several ways to fix this failure:
1. I used the ShellUtil instead of java.file.renameto() function, but I got this 127.0.0.1:53050: mv: cannot move `C:/hadoop/hadoop-hdfs-project/hadoop-hdfs/build/test/data/dfs/journalnode-2/test-journal/current/edits_inprogress_0000000000000000004' to `C:/hadoop/hadoop-hdfs-project/hadoop-hdfs/build/test/data/dfs/journalnode-2/test-journal/current/edits_inprogress_0000000000000000004.empty': Permission denied error
2. I checked before we try to rename the file, does we grab the lock ? Actually, we did grab the lock based on the log information.
3. After I further track the error down, I found the part of code which throws out the exception is :
2012-12-12 17:43:11,677 ERROR security.UserGroupInformation (UserGroupInformation.java:doAs(1447)) - PriviledgedActionException as:Administrator (auth:SIMPLE) cause:java.io.IOException: Couldn't rename log C:\hadoop\hadoop-hdfs-project\hadoop-hdfs\build\test\data\dfs\journalnode-2\test-journal\current\edits_inprogress_0000000000000000004 to C:\hadoop\hadoop-hdfs-project\hadoop-hdfs\build\test\data\dfs\journalnode-2\test-journal\current\edits_inprogress_0000000000000000004.empty
.
So, I am not sure why this happens , I think this issue has gone out of date, so I'm resolving it.  Many of the file locking problems found earlier have been fixed.  {{TestQuorumJournalManager}} is still a problem, and I expect to post a patch on HDFS-4748 for that shortly.]