[Attaching a patch for the same. Please review, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12666446/HDFS-6995-001.patch
  against trunk revision 8f1a668.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.server.blockmanagement.TestReplicationPolicyConsiderLoad
                  org.apache.hadoop.hdfs.web.TestWebHdfsFileSystemContract
                  org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover
                  org.apache.hadoop.hdfs.server.namenode.TestMetaSave

                                      The following test timeouts occurred in hadoop-hdfs-project/hadoop-hdfs:

org.apache.hadoop.hdfs.server.namenode.ha.TestDFSZKFailoverController

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/7894//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/7894//console

This message is automatically generated., fixed test failure of TestReplicationPolicyConsiderLoad.
TestMetaSave passed on local.
Remaining are unrelated., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12666662/HDFS-6995-002.patch
  against trunk revision 6104520.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 2 new or modified test files.

      {color:red}-1 javac{color}.  The applied patch generated 1264 javac compiler warnings (more than the trunk's current 1215 warnings).

    {color:red}-1 javadoc{color}.  The javadoc tool appears to have generated 9 warning messages.
        See https://builds.apache.org/job/PreCommit-HDFS-Build/7909//artifact/trunk/patchprocess/diffJavadocWarnings.txt for details.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover

                                      The following test timeouts occurred in hadoop-hdfs-project/hadoop-hdfs:

org.apache.hadoop.hdfs.server.balancer.TestBalancTests
org.apache.hadoop.hdfs.server.datanode.TestMultipleNNDataBlockScanner

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/7909//testReport/
Javac warnings: https://builds.apache.org/job/PreCommit-HDFS-Build/7909//artifact/trunk/patchprocess/diffJavacWarnings.txt
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/7909//console

This message is automatically generated., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12666662/HDFS-6995-002.patch
  against trunk revision ee21b13.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 2 new or modified test files.

      {color:red}-1 javac{color}.  The applied patch generated 1265 javac compiler warnings (more than the trunk's current 677 warnings).

    {color:red}-1 javadoc{color}.  The javadoc tool appears to have generated 109 warning messages.
        See https://builds.apache.org/job/PreCommit-HDFS-Build/8079//artifact/trunk/patchprocess/diffJavadocWarnings.txt for details.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.crypto.random.TestOsSecureRandom
                  org.apache.hadoop.ha.TestZKFailoverControllerStress
                  org.apache.hadoop.hdfs.TestEncryptionZonesWithKMS
                  org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover
                  org.apache.hadoop.hdfs.server.namenode.TestMetaSave

                                      The following test timeouts occurred in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs:

org.apache.hadoop.hdfs.server.namenode.TestDecommissioningStatus

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/8079//testReport/
Javac warnings: https://builds.apache.org/job/PreCommit-HDFS-Build/8079//artifact/trunk/patchprocess/diffJavacWarnings.txt
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/8079//console

This message is automatically generated., Rebased the patch, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12669760/HDFS-6995-003.patch
  against trunk revision 6434572.

    {color:red}-1 patch{color}.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/8099//console

This message is automatically generated., Rebased again after merge of HDFS-6584, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12669940/HDFS-6995-004.patch
  against trunk revision 6fe5c6b.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 2 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.TestDatanodeBlockScanner
                  org.apache.hadoop.hdfs.TestEncryptionZonesWithKMS

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/8105//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/8105//console

This message is automatically generated., Both failures are not related., hi [~umamaheswararao], can you take a look at the patch ? thanks., Thanks Vinay for  working on this.
I am reviewing this patch. Please find a comment on this.

When the client node is not part of any rack configured, then it will be treated as default rack. What if no node found with default rack as we assigned all nodes with some racks configured.
In this case, node will try to get from clusterMap with the specified scope of default rack. But as we don't have any node exist we may get them as null.

{noformat}
java.lang.NullPointerException
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRandom(BlockPlacementPolicyDefault.java:516)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRandom(BlockPlacementPolicyDefault.java:481)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseLocalRack(BlockPlacementPolicyDefault.java:411)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseLocalStorage(BlockPlacementPolicyDefault.java:372)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:271)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:212)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:121)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:136)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget(BlockManager.java:1504)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:3033)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:619)
	at org.apache.hadoop.hdfs.server.namenode.TestBlockPlacementPolicy.testLocalRackPlacement(TestBlockPlacementPolicy.java:72)
{noformat}

Before due to local node null, it was going to chooseRandom by passing scope as ROOT. So, no issue before this hange in this scenario.
So, if we can't choose any random node with the scope of client nodes rack scope, then we can consider writer as null itself. So, we can choose random with ROOT scope.?

I will continue reviewing and post further comments later today if any., Hi [~umamaheswararao], thanks for reviewing.
Scenario mentioned is very much possible. 
It was throwing NPE because, target selection was happened even though there was no node with "/default-rack". 
This is because, {{clusterMap.countNumOfAvailableNodes(
        scope, excludedNodes)}} was returning 1, for the scope of "/default-rack", it should return 0 as no nodes available with "/default-rack".
I have posted a patch for the same in HADOOP-10131, along with one more scenario where {{NetworkTopology#countNumOfAvailableNodes(..)}} was returning wrong value.
    Till now this API was not called as writer was considered as null if no DN exists in clients machine.
   Please review HADOOP-10131 patch, once thats in, then a remote rack will be chosen in the above mentioned case., Right, Thanks for handling this case in HADOOP-10131. I will take a look at that issue later today., Just added a test to cover the above mentioned case.
Added test passes now, after commit of HADOOP-10131., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12670371/HDFS-6995-005.patch
  against trunk revision 9721e2c.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 2 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.server.balancer.TestBalancer
                  org.apache.hadoop.hdfs.TestEncryptionZonesWithKMS
                  org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/8141//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/8141//console

This message is automatically generated., Thanks a lot Vinay for update on patch!

Here I have some few nits:
- .
{code}
   for (int i = 0; i < 5; i++) {
+      String src = "/test-" + i;
+      // Create the file with client machine
+      HdfsFileStatus fileStatus = namesystem.startFile(src, perm,
+          clientMachine, clientMachine, EnumSet.of(CreateFlag.CREATE), true,
+          REPLICATION_FACTOR, DEFAULT_BLOCK_SIZE, null);
+      LocatedBlock locatedBlock = nameNodeRpc.addBlock(src, clientMachine,
+          null, null, fileStatus.getFileId(), null);
+
+      assertEquals("First datanode should be rack local", "/RACK2",
+          locatedBlock.getLocations()[0].getNetworkLocation());
+
+      nameNodeRpc.abandonBlock(locatedBlock.getBlock(), fileStatus.getFileId(),
+          src, clientMachine);
+    }
{code}
Seems like this peice of code is duplicate except assertion. Could we refactor a bit to avoid this?

- Test name should say thsi test for Default placement policy?

- .
{code}
perm = new PermissionStatus("TestNamenodeRetryCache", null,
+        FsPermission.getDefault());
{code}
Seems like copies this line from other tests. changing string name to current test will looks good. But not a big deal.

, Updated the patch according to [~umamaheswararao]'s comments, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12671750/HDFS-6995-006.patch
  against trunk revision b38e52b.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 2 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:red}-1 findbugs{color}.  The patch appears to introduce 1 new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/8249//testReport/
Findbugs warnings: https://builds.apache.org/job/PreCommit-HDFS-Build/8249//artifact/PreCommit-HADOOP-Build-patchprocess/newPatchFindbugsWarningshadoop-hdfs.html
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/8249//console

This message is automatically generated., Findbug is unrelated to current patch, Thanks Vinay for the patch, it looks good to me., Latest patch looks good to me.  I have one tiny nit to address in tests.

extracted testPlacement method could take clinetRack as param and do assert with that instead of true/false and Rack2 assumption always.

+1 on addressing this. ( after jenkins +1), Updated as per [~umamaheswararao]'s comments., Seems some problem with jenkins.. 
git pull is failing with below exceptions

{noformat}FATAL: Failed to fetch from https://git-wip-us.apache.org/repos/asf/hadoop.git
hudson.plugins.git.GitException: Failed to fetch from https://git-wip-us.apache.org/repos/asf/hadoop.git
	at hudson.plugins.git.GitSCM.fetchFrom(GitSCM.java:623)
	at hudson.plugins.git.GitSCM.retrieveChanges(GitSCM.java:855)
	at hudson.plugins.git.GitSCM.checkout(GitSCM.java:880)
	at hudson.model.AbstractProject.checkout(AbstractProject.java:1414)
	at hudson.model.AbstractBuild$AbstractBuildExecution.defaultCheckout(AbstractBuild.java:671)
	at jenkins.scm.SCMCheckoutStrategy.checkout(SCMCheckoutStrategy.java:88)
	at hudson.model.AbstractBuild$AbstractBuildExecution.run(AbstractBuild.java:580)
	at hudson.model.Run.execute(Run.java:1676)
	at hudson.model.FreeStyleBuild.run(FreeStyleBuild.java:43)
	at hudson.model.ResourceController.execute(ResourceController.java:88)
	at hudson.model.Executor.run(Executor.java:231)
Caused by: hudson.plugins.git.GitException: Failed to connect to https://git-wip-us.apache.org/repos/asf/hadoop.git (exception: java.net.UnknownHostException: git-wip-us.apache.org: Name or service not known)
	at org.jenkinsci.plugins.gitclient.CliGitAPIImpl.checkCredentials(CliGitAPIImpl.java:1960){noformat}, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12671997/HDFS-6995-007.patch
  against trunk revision 17d1202.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 2 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:red}-1 findbugs{color}.  The patch appears to introduce 1 new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.TestEncryptionZonesWithKMS
                  org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover

                                      The following test timeouts occurred in hadoop-hdfs-project/hadoop-hdfs:

org.apache.hadoop.hdfs.utilTests
oTests
org.apache.hadoop.tools.TestJMXGet

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/8286//testReport/
Findbugs warnings: https://builds.apache.org/job/PreCommit-HDFS-Build/8286//artifact/patchprocess/newPatchFindbugsWarningshadoop-hdfs.html
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/8286//console

This message is automatically generated., Test failures are not related to this patch., Will commit the patch soon., committed to trunk and branch-2.

Thanks [~umamaheswararao] and [~hitliuyi] for the reviews, FAILURE: Integrated in Hadoop-trunk-Commit #6196 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/6196/])
HDFS-6995. Block should be placed in the client's 'rack-local' node if 'client-local' node is not available (vinayakumarb) (vinayakumarb: rev ed841dd9a96e54cb84d9cae5507e47ff1c8cdf6e)
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java
* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestReplicationPolicyConsiderLoad.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyDefault.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java
* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
, FAILURE: Integrated in Hadoop-Yarn-trunk #703 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/703/])
HDFS-6995. Block should be placed in the client's 'rack-local' node if 'client-local' node is not available (vinayakumarb) (vinayakumarb: rev ed841dd9a96e54cb84d9cae5507e47ff1c8cdf6e)
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyDefault.java
* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestReplicationPolicyConsiderLoad.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java
, SUCCESS: Integrated in Hadoop-Hdfs-trunk #1893 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1893/])
HDFS-6995. Block should be placed in the client's 'rack-local' node if 'client-local' node is not available (vinayakumarb) (vinayakumarb: rev ed841dd9a96e54cb84d9cae5507e47ff1c8cdf6e)
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyDefault.java
* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java
* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestReplicationPolicyConsiderLoad.java
, FAILURE: Integrated in Hadoop-Mapreduce-trunk #1918 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1918/])
HDFS-6995. Block should be placed in the client's 'rack-local' node if 'client-local' node is not available (vinayakumarb) (vinayakumarb: rev ed841dd9a96e54cb84d9cae5507e47ff1c8cdf6e)
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java
* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestReplicationPolicyConsiderLoad.java
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyDefault.java
* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java
, FAILURE: Integrated in Hadoop-trunk-Commit #6278 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/6278/])
HDFS-6995. Block should be placed in the client's 'rack-local' node if 'client-local' node is not available (vinayakumarb) (vinayakumarb: rev cba1f9e3896c0526fa748cd1bb13470d5fae584a)
* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestDefaultBlockPlacementPolicy.java
, I am in the business trip to US. Expect my delayed responses in this period.

, FAILURE: Integrated in Hadoop-Mapreduce-trunk #1929 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1929/])
HDFS-6995. Block should be placed in the client's 'rack-local' node if 'client-local' node is not available (vinayakumarb) (vinayakumarb: rev cba1f9e3896c0526fa748cd1bb13470d5fae584a)
* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestDefaultBlockPlacementPolicy.java
, SUCCESS: Integrated in Hadoop-Yarn-trunk #716 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/716/])
HDFS-6995. Block should be placed in the client's 'rack-local' node if 'client-local' node is not available (vinayakumarb) (vinayakumarb: rev cba1f9e3896c0526fa748cd1bb13470d5fae584a)
* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestDefaultBlockPlacementPolicy.java
, FAILURE: Integrated in Hadoop-Hdfs-trunk #1905 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1905/])
HDFS-6995. Block should be placed in the client's 'rack-local' node if 'client-local' node is not available (vinayakumarb) (vinayakumarb: rev cba1f9e3896c0526fa748cd1bb13470d5fae584a)
* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestDefaultBlockPlacementPolicy.java
, I noticed that this patch is in branch-2, but not branch-2.6.  The fix version on the jira is 2.6.0.  Is this supposed to go to branch-2.6?, Yes Chris. Missed the commit. I will merge to branch-2.6 soon., I have cherry-picked from branch-2 and pushed to branch-2.6.
Thanks [~cnauroth] for finding out.]