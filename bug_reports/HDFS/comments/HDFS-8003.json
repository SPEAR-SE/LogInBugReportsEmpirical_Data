[I think "export CLASSPATH" also can be removed...

and add like following after immediate if statement  HADOOP_OPTS="${HADOOP_OPTS} ${HADOOP_NAMENODE_OPTS} Or ${HADOOP_CLIENT_OPTS}"

Please correct me, If I am wrong..., bq.Please correct me, If I am wrong...

Yup, you are. ;)

, To be more precise, there are a bunch of problems here, but those aren't them:

* CLASSPATH hasn't been exported yet so that needs to happen
* HADOOP_OPTS has *already* been finalized, so adding other option strings breaks the contract

There are a bunch of things we *could* do here:

a) Just put the necessary disable lines in shut shellcheck up
b) run the equivalent hdfs commands instead of pretending that our environment is correct and running the classes directly

B is probably the best fix.  But frankly, this seems like we're working around a problem in the Java code by patching it at the shell level., Thanks for fixing this, [~aw] and [~brahmareddy].

bq. this seems like we're working around a problem in the Java code by patching it at the shell level

Our initial proposal was to put this checkpoint verification logic only into the server side (e.g., through NameNode shutdown hook). However, since the saving namespace process can take minutes or even throw exception, there is no way to guarantee the NN can correctly verify/do checkpoint before getting stopped.

Instead if we add this functionality outside of NN (i.e., into the stopping NN shell), we can make sure the checkpoint verification happens/finishes before stopping NameNode, and the RPC timeout can provide a time bound of the operation.

Any suggestion here, [~aw]?, bq. However, since the saving namespace process can take minutes or even throw exception, there is no way to guarantee the NN can correctly verify/do checkpoint before getting stopped.

You can always catch the exceptions and trap the signal from within the namenode.  

In fact, given the above scenario... 

bq. Instead if we add this functionality outside of NN (i.e., into the stopping NN shell), we can make sure the checkpoint verification happens/finishes before stopping NameNode, and the RPC timeout can provide a time bound of the operation.

... doing it in the shell program is even worse.  If it gets an exception, it's just going to assume that the previous command worked and continue on its way.  The whole thing that this hack is supposed to prevent is going to happen anyway, because there is no way within the shell code that it can guarantee that the checkpoint is valid.

Here's a key question: if the checkpoint isn't valid, what is the shell code supposed to do about it?, Thanks for the comments, [~aw]. The description of HDFS-6353 states the main motivation scenario:

bq. One of the failure patterns I have seen is, in some rare circumstances, due to some inconsistency the secondary or standby fails to consume editlog. The only solution when this happens is to save the namespace at the current active namenode. But sometimes when this happens, unsuspecting admin might end up restarting the namenode, requiring more complicated solution to the problem (such as ignore editlog record that cannot be consumed etc.).

Thus the feature aims to prevent users from stopping namenode while the standby/secondary NN failed to checkpoint due to corruption. With new changes in HDFS-7991, if the feature is on, the shell code will exit if the checkpoint fails and the NN will not be stopped.
, Duping this to HDFS-7991.]