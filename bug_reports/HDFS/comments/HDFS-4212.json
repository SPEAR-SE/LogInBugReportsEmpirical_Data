[I write a test case and run it against with the trunk code. I did not found the status you mentioned above. Is this error can only happen in hadoop 1.* rather than 2.* or higher one? or my test case is not correct to describe your condition? , Sorry, Yanbo. I though I replied your comment. This is a problem identified in branch-1 in a few deployed environments. I will try your tests with trunk and get back to you soon.

Part of the problem here is that getAdditionalBlock()(and thus addBlock()) is not real idempotent. When the client or namenode or the network between them causes error, it can leave an assigned blockID but not block created on datanode.

If addBlock() is really idempotent, the namenode can identified and delete the dangling blockID when it gets the repeated addBlock() request. To make this api idempotent is to add the offset as input parameter, so namenode can check the offset to validate if it's a repeated request. I will upload a patch for that., Brandon. The problem mentioned in your original description seems not to be a problem at all. Because client never knows whether block was created or not until it gets a reply from NN. If NN crashes before replying the block will be correctly reported as missing on restart if it was created. This is the nature of distributed computing. 
I'd advocate closing this jira as not a problem.
The problem you describe in your last comment is a [very] different problem related to race condition in getAdditionalBlock(). Tried to explain it in details in HDFS-4452 just half an hour before your comment. If you are working on it please do. Let's just not mix things and be clear what problem is being solved., bq. Brandon. The problem mentioned in your original description seems not to be a problem at all. Because client never knows whether block was created or not until it gets a reply from NN. If NN crashes before replying the block will be correctly reported as missing on restart if it was created. This is the nature of distributed computing.

Actually it is a problem related to HDFS-4452. When a client does not get response for getAdditionalBlock(), it retries. As getAdditionalBlock() stands currently, since it is really not idempotent, new blocks can be allocated. This causes the issue of namenode reporting corruption for open files. I think changing getAdditionalBlock and adding an offset as suggested by Brandon will make it idempotent. On retry, for the same offset, from the same client, namenode can return the block that has already been allocated, instead of creating new ones., > Actually it is a problem related to HDFS-4452.

Which problem? The original description of NN crashing before replying to the client is not a problem and not related to HDFS-4452.
The problem in comment 2 here is exactly the problem I am talking, but posted after HDFS-4452 was created.
If you knew the problem since November why didn't you report it correctly, it would have saved me and others a lot of time...
How should I understand you were talking about getAdditionalBlock() and what in the hell "a never-created block" means, if it is in fsimage., {quote}
If you knew the problem since November why didn't you report it correctly, it would have saved me and others a lot of time...
How should I understand you were talking about getAdditionalBlock() and what in the hell "a never-created block" means, if it is in fsimage.
{quote}
Relax :-)

We had reported the problem that we had found long back during HA testing. Few week back we had discussed about the solution (thanks to [~sanjay.radia] for suggesting this) of making getAdditionalBlock() truly idempotent and were thinking of fixing it soon. 
, @Konstantin, never-created block is the block with the blockId assigned by NameNode but never created on datanode. NameNode reports this block as missing, and can't delete it from any DataNode. I mentioned this in HDFS-4212 and HDFS-4280, but maybe I should have made it more obvious in the description.

This could happen when the client couldn't get the addBlock() response from NameNode.

I am totally OK if you want to use HDFS-4452 to track this problem since it has much clearer description., not HDFS-4280, it's HDFS-4208., Brandon I checked both issues. They seem to be dealing with the consequences of the problem.
From what I hear Sanjay's assessment is right.
The closest by description issue I found so far is HDFS-3031.

Let's use HDFS-4452 since it addresses the problem directly.
I want to make a patch ready this week. LMK if you can work on it now.

To accelerate we can split the work. I have getAdditionalBlock() impl almost ready. But there is much more: RPC, DFSClient, and tests. I can get you a diff of FSNamesystem. You can merge it and submit the patch under HDFS-4452., Konstantin, let me resolve this JIRA as a dup of HDFS-4452. Please feel free to work a full patch to HDFS-4452 since two people working on a small issue will only slow down the progress. :-)]