[Attaching a patch., {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12639355/HDFS-6194.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/6628//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/6628//console

This message is automatically generated., {code}
+  @VisibleForTesting
+  protected ByteRangeInputStream(URLOpener o, URLOpener r, boolean connect)
+      throws IOException {
+    this.originalURL = o;
+    this.resolvedURL = r;
+    if (connect) {
+      getInputStream();
+    }
+  }
+
{code}

Please remove it. See the discussion in HDFS-6143 for more details.

For {{MockByteRangeInputStream}} and {{MockHttpURLConnection}}, please write them with Mockito directly. The code should not need to use the {{spy()}} call at all., Thanks [~wheat9] for the comment! I updated the patch., {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12639543/HDFS-6194.2.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/6638//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/6638//console

This message is automatically generated., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12639551/HDFS-6194.2.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.TestDistributedFileSystem
                  org.apache.hadoop.hdfs.server.balancer.TestBalancerWithNodeGroup

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/6639//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/6639//console

This message is automatically generated., {code}
+    doNothing().when(mockConnection).connect();
+    doNothing().when(mockConnection).disconnect();
{code}

They are no-ops.

{code}
+    Whitebox.setInternalState(bris, "resolvedURL", rMock);
+    Whitebox.setInternalState(bris, "startPos", 0);
+    Whitebox.setInternalState(bris, "currentPos", 0);
+    Whitebox.setInternalState(bris, "status",
+                              ByteRangeInputStream.StreamStatus.SEEK);

+    assertEquals("Initial call made incorrectly (offset check)",
+        0, bris.startPos);
{code}

The high level goal is to verify that the seek() method is written correctly. The test code should not depend on the internal state of the {{ByteRangeInputStream}}. Instead, it should verify {{seek()}} calls the methods underlying objects (i.e., {{URLOpener}}, {{URLConnection}}) correctly. Please see check how this is done before HDFS-5570., Thanks for the comment.
bq. The test code should not depend on the internal state of the {{ByteRangeInputStream}}.
Removed some initializations.
{code}
+    Whitebox.setInternalState(bris, "status",
+                              ByteRangeInputStream.StreamStatus.SEEK);
{code}
This setting is required. If {{status}} is not initialized, {{getInputStream()}} will fail by NPE., {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12640002/HDFS-6194.3.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/6658//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/6658//console

This message is automatically generated., {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12640003/HDFS-6194.4.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/6659//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/6659//console

This message is automatically generated., bq. This setting is required. If status is not initialized, getInputStream() will fail by NPE.

This is because the code mocked the class that is supposed to be tested:
{code}
+    ByteRangeInputStream bris =
+        mock(ByteRangeInputStream.class, CALLS_REAL_METHODS);
{code}

What it should have done is to mock the dependency of {{ByteRangeInputStream}}, and to test the functionality of {{ByteRangeInputStream}}, but not to mock {{ByteRangeInputStream}} itself., bq. but not to mock {{ByteRangeInputStream}} itself.
Do you mean we should create the mock class extends {{ByteRangeInputStream}} and call the method of it? I updated the patch to remove the initialization from {{testByteRange()}}., {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12640219/HDFS-6194.5.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/6667//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/6667//console

This message is automatically generated., +1, I've committed the patch to trunk and branch-2. Thanks [~ajisakaa] for the contribution., SUCCESS: Integrated in Hadoop-trunk-Commit #5520 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/5520/])
HDFS-6194. Create new tests for ByteRangeInputStream. Contributed by Akira Ajisaka. (wheat9: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1587660)
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestByteRangeInputStream.java
, Thanks [~wheat9] for the reviews and the commit!, SUCCESS: Integrated in Hadoop-Yarn-trunk #542 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/542/])
HDFS-6194. Create new tests for ByteRangeInputStream. Contributed by Akira Ajisaka. (wheat9: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1587660)
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestByteRangeInputStream.java
, SUCCESS: Integrated in Hadoop-Hdfs-trunk #1734 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1734/])
HDFS-6194. Create new tests for ByteRangeInputStream. Contributed by Akira Ajisaka. (wheat9: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1587660)
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestByteRangeInputStream.java
, SUCCESS: Integrated in Hadoop-Mapreduce-trunk #1759 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1759/])
HDFS-6194. Create new tests for ByteRangeInputStream. Contributed by Akira Ajisaka. (wheat9: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1587660)
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestByteRangeInputStream.java
, Hi [~wheat9], did you merge the new test to branch-2? the commit is there, but contains no code change, did I miss anything?
$ git ll | grep HDFS-6194
d7583e2 HDFS-6194. Merge r1587660 from trunk
$ git show d7583e2
commit d7583e206d59394510d62387bda688b9fa85d169
Author: Haohui Mai <wheat9@apache.org>
Date:   Tue Apr 15 18:15:36 2014 +0000

    HDFS-6194. Merge r1587660 from trunk
    
    git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/branch-2@1587665 13f79535-47bb-0310-9956-ffa450ed

diff --git a/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt b/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
index c64fe75..1e7cea6 100644
--- a/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
+++ b/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
@@ -46,6 +46,9 @@ Release 2.5.0 - UNRELEASED
     HDFS-6224. Add a unit test to TestAuditLogger for file permissions
     passed to logAuditEvent. (Charles Lamb via wang)
 
+    HDFS-6194. Create new tests for ByteRangeInputStream.
+    (Akira Ajisaka via wheat9)
+
   OPTIMIZATIONS
 
   BUG FIXES 
, Thanks [~jyu@cloudera.com] for the report. I think the patch should be committed to trunk only.
[~wheat9], would you please revert the commit in branch-2 and modify the fix version?, why not branch-2? 
btw, the old test that use HftpFileSystem fails in branch-2 due to fix of HDFS-6143, Sorry for the confusion.

It looks like that the motivation of this jira was to reintroduce the tests removed by HDFS-5570 to trunk, making the test between trunk and branch-2 consistent. As a result, when merging to branch-2 svn skipped all the code changes (as they were identical) automatically.

, it's not just reintroduce, the tests are also re-written. they are different in trunk and branch-2.
Anyway, the problem is the test fails in branch-2. Could we merge the new test to branch-2 to fix the test failure?, Sure. Please feel free to create a jira to track the issue.]