[[~jojochuang], I met this problem in apache-2.7.1, IIUC, it may be relevant to HDFS-10453, FYI., Thanks [~hexiaoqiao] for the hint sorry it took a while to circle back.
The relevant code is here. Too bad I lost NameNode log.
{code:java|title=BlockManager#removeBlock()}
public void removeBlock(BlockInfo block) {
    assert namesystem.hasWriteLock();
    // No need to ACK blocks that are being removed entirely
    // from the namespace, since the removal of the associated
    // file already removes them from the block map below.
    block.setNumBytes(BlockCommand.NO_ACK);
{code}

Quote HDFS-10453:
bq. (2) FSNamesystem#delete invoked to delete blocks then clear the reference in blocksmap, needReplications, etc. the block's NumBytes will set NO_ACK(Long.MAX_VALUE) which is used to indicate that the block deletion does not need explicit ACK from the node. 

If this is the case, then there's no need to worry about DataNode marking the replica as corrupt due to length being 9223372036854775807., Okay I think this is fixed by HDFS-10453. Resolve this jira. Thanks [~hexiaoqiao]!]