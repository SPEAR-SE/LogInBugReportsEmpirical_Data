[Patch attached. Tested via firing up a two node cluster (1 NN and 1 DN) with wildcard addresses configured. Checked the file browser (which worked), and visually the URL now has a proper IP address., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12568146/hdfs-4471-1.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/3952//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/3952//console

This message is automatically generated., It'd might be better to use the host/port in the request context., Hey Daryn, thanks for looking this over. I'm not that familiar with JSP, but it looks like the NN is being pulled out of the {{context}} parameter, which I then use to get the address and port:

{code}
    final NameNode nn = NameNodeHttpServer.getNameNodeFromContext(context);
<snip>
    InetSocketAddress connectAddr =
        NetUtils.getConnectAddress(nn.getNameNodeAddress());
    String addr = connectAddr.getAddress().getHostAddress()
        + ":" + connectAddr.getPort();
{code}

Is this the request context you were talking about?, {{NetUtils.getConnectAddress}} is going to just return the first interface on the machine, which is non-deterministic.  It might be the loopback, a vpn tunnel, an ethernet interface, etc.  What you really want to do is return exactly the same authority the client used to contact the server.  This is completely untested, but probably will do the trick:
{code}
String addr = URI.create(request.getRequestURL().toString()).getAuthority();
{code}
, Thanks, your explanation makes sense. New patch attached.

I had to adapt your code snippet slightly to use the RPC port rather than the HTTP port. Tested manually once again., If the getConnectAddress method is broken we should fix the other use of it that was introduced in HDFS-3932 while we're at it, otherwise we have this correct fix with another incorrect fix so we're broken anyway.

However, NetUtils#getConnectAddress is deterministic, it uses InetAddress.html#getLocalHost which is based on the host configuration (a lot of apps would break if that was non-deterministic!). I think request#getRequestURL works when everyone binds to the wildcard but I think this breaks when the NN rpc addr is _not_ bound to the wildcard but the http address is (because it assumes the NN is listening on the same IP the http request was handled on, which isn't necessarily true)., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12568301/hdfs-4471-2.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/3954//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/3954//console

This message is automatically generated., bq. but I think this breaks when the NN rpc addr is not bound to the wildcard but the http address is (because it assumes the NN is listening on the same IP the http request was handled on, which isn't necessarily true).

Hmm, you're right, I overlooked that this is the rpc addr and not the http addr.  I'm not sure exactly how to handle that correctly.  {{InetAddress.getLocalHost()}} isn't deterministic across machines since it's dependent on the ordering of the network interfaces.  I guess you'd have to do something like assume a wildcard means use the interface used by the http client:
{code}
InetSocketAddress rpcAddr = nn.getNameNodeAddress();
String rpcHost = rpcAddr.getAddress().isAnyLocalAddress())
  ? URI.create(request.getRequestURL().toString()).getHost()
  : rpcAddr.getHost();
String addr = rpcHost + ":" + rpcAddr.getPort();
{code}  

I don't think there really is a way to fix {{NetUtils.getConnectAddress}} w/o providing a default hostname.  Luckily it looks like it's only called in {{MiniRPCBenchmark}} and {{ContainerManagerImpl}}.
, Hey Daryn, I think you make a good point. I think the best fix would probably be to not pass an address at all from the NN to the DN, but instead just pass the NN's nameservice ID and have the DN look up in its own configs what address(es) to connect to. This would be a somewhat more involved change, though.

How about this - given that the proper fix is more involved, and fixing this issue this way will fix the web UI for many (most?) users, how about we commit this as-is and file a follow-up JIRA to fix this properly at a later date. Does this sound OK by you?, Agreed, using the nameservice id is probably the cleanest solution.  In the meantime, I'd be more comfortable with the snippet I posted above (assuming it works).  A Eli points out, the current patch will break anyone that listens on one interface for http, but another for rpc.  We've got NNs listening for http on the wildcard, but a specific ip for rpc., Thanks Daryn. Patch attached with your newest proposed fix., +1 Assuming it works. :), {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12568463/hdfs-4471-3.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/3956//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/3956//console

This message is automatically generated., To finish this off, tested via configuring a wildcard address and browsing the filesystem via the NN web UI (which worked successfully)., Thanks a lot for the patch, testing, and discussion, all. I'm going to commit this momentarily., I've just committed this to trunk and branch-2.

Thanks a lot for the contribution, Andrew., Integrated in Hadoop-trunk-Commit #3344 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/3344/])
    HDFS-4471. Namenode WebUI file browsing does not work with wildcard addresses configured. Contributed by Andrew Wang. (Revision 1443807)

     Result = SUCCESS
atm : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1443807
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NamenodeJspHelper.java
, Integrated in Hadoop-Yarn-trunk #121 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/121/])
    HDFS-4471. Namenode WebUI file browsing does not work with wildcard addresses configured. Contributed by Andrew Wang. (Revision 1443807)

     Result = SUCCESS
atm : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1443807
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NamenodeJspHelper.java
, Integrated in Hadoop-Hdfs-trunk #1310 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1310/])
    HDFS-4471. Namenode WebUI file browsing does not work with wildcard addresses configured. Contributed by Andrew Wang. (Revision 1443807)

     Result = FAILURE
atm : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1443807
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NamenodeJspHelper.java
, Integrated in Hadoop-Mapreduce-trunk #1338 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1338/])
    HDFS-4471. Namenode WebUI file browsing does not work with wildcard addresses configured. Contributed by Andrew Wang. (Revision 1443807)

     Result = FAILURE
atm : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1443807
Files : 
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NamenodeJspHelper.java
]