[Facing same issue when I Rollback (after rolling upgrade) from Hadoop 2.7.2 to 2.5.2; Could any one please tell, is this a known bug?

Based on below logs, please suggest can we consider this issue as a new bug,

My Name node log details:

|C:\SDK\Hadoop\bin>hdfs namenode -rollingUpgrade rollback
16/10/18 18:58:25 INFO namenode.NameNode: STARTUP_MSG:
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = myserver/192.168.10.1
STARTUP_MSG:   args = [-rollingUpgrade, rollback]
STARTUP_MSG:   version = 2.5.2
STARTUP_MSG:   classpath = ...
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'Dinesh' on 2016-01-14T11:05Z
STARTUP_MSG:   java = 1.7.0_51
************************************************************/
16/10/18 18:58:25 INFO namenode.NameNode: createNameNode [-rollingUpgrade, rollback]
16/10/18 18:58:25 INFO impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
16/10/18 18:58:25 INFO impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
16/10/18 18:58:25 INFO impl.MetricsSystemImpl: NameNode metrics system started
16/10/18 18:58:25 INFO namenode.NameNode: fs.defaultFS is hdfs://hacluster
16/10/18 18:58:25 INFO namenode.NameNode: Clients are to use hacluster to access this namenode/service.
16/10/18 18:58:26 INFO hdfs.DFSUtil: Starting web server as: ${dfs.web.authentication.kerberos.principal}
16/10/18 18:58:26 INFO hdfs.DFSUtil: Starting Web-server for hdfs at: http://myserver.root.Dinesh.lan:50070
16/10/18 18:58:26 INFO mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
16/10/18 18:58:26 INFO http.HttpRequestLog: Http request log for http.requests.namenode is not defined
16/10/18 18:58:26 INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
16/10/18 18:58:26 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
16/10/18 18:58:26 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
16/10/18 18:58:26 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
16/10/18 18:58:26 INFO http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
16/10/18 18:58:26 INFO http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
16/10/18 18:58:26 INFO http.HttpServer2: Jetty bound to port 50070
16/10/18 18:58:26 INFO mortbay.log: jetty-6.1.26
16/10/18 18:58:26 WARN server.AuthenticationFilter: 'signature.secret' configuration not set, using a random value as secret
16/10/18 18:58:26 INFO mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@myserver.root.Dinesh.lan:50070
16/10/18 18:58:26 WARN namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
16/10/18 18:58:26 INFO namenode.FSNamesystem: fsLock is fair:true
16/10/18 18:58:26 INFO blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
16/10/18 18:58:26 INFO blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
16/10/18 18:58:26 INFO blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
16/10/18 18:58:26 INFO blockmanagement.BlockManager: The block deletion will start around 2016 Oct 18 18:58:26
16/10/18 18:58:26 INFO util.GSet: Computing capacity for map BlocksMap
16/10/18 18:58:26 INFO util.GSet: VM type       = 64-bit
16/10/18 18:58:26 INFO util.GSet: 2.0% max memory 910.5 MB = 18.2 MB
16/10/18 18:58:26 INFO util.GSet: capacity      = 2^21 = 2097152 entries
16/10/18 18:58:26 INFO blockmanagement.BlockManager: dfs.block.access.token.enable=false
16/10/18 18:58:26 INFO blockmanagement.BlockManager: defaultReplication         = 3
16/10/18 18:58:26 INFO blockmanagement.BlockManager: maxReplication             = 512
16/10/18 18:58:26 INFO blockmanagement.BlockManager: minReplication             = 1
16/10/18 18:58:26 INFO blockmanagement.BlockManager: maxReplicationStreams      = 2
16/10/18 18:58:26 INFO blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
16/10/18 18:58:26 INFO blockmanagement.BlockManager: replicationRecheckInterval = 3000
16/10/18 18:58:26 INFO blockmanagement.BlockManager: encryptDataTransfer        = false
16/10/18 18:58:26 INFO blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
16/10/18 18:58:26 INFO namenode.FSNamesystem: fsOwner             = SYSTEM (auth:SIMPLE)
16/10/18 18:58:26 INFO namenode.FSNamesystem: supergroup          = Users
16/10/18 18:58:26 INFO namenode.FSNamesystem: isPermissionEnabled = false
16/10/18 18:58:26 INFO namenode.FSNamesystem: Determined nameservice ID: hacluster
16/10/18 18:58:26 INFO namenode.FSNamesystem: HA Enabled: true
16/10/18 18:58:26 INFO namenode.FSNamesystem: Append Enabled: true
16/10/18 18:58:26 INFO util.GSet: Computing capacity for map INodeMap
16/10/18 18:58:26 INFO util.GSet: VM type       = 64-bit
16/10/18 18:58:26 INFO util.GSet: 1.0% max memory 910.5 MB = 9.1 MB
16/10/18 18:58:26 INFO util.GSet: capacity      = 2^20 = 1048576 entries
16/10/18 18:58:26 INFO namenode.NameNode: Caching file names occuring more than 10 times
16/10/18 18:58:26 INFO util.GSet: Computing capacity for map cachedBlocks
16/10/18 18:58:26 INFO util.GSet: VM type       = 64-bit
16/10/18 18:58:26 INFO util.GSet: 0.25% max memory 910.5 MB = 2.3 MB
16/10/18 18:58:26 INFO util.GSet: capacity      = 2^18 = 262144 entries
16/10/18 18:58:26 INFO namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
16/10/18 18:58:26 INFO namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
16/10/18 18:58:26 INFO namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
16/10/18 18:58:26 INFO namenode.FSNamesystem: Retry cache on namenode is enabled
16/10/18 18:58:26 INFO namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
16/10/18 18:58:26 INFO util.GSet: Computing capacity for map NameNodeRetryCache
16/10/18 18:58:26 INFO util.GSet: VM type       = 64-bit
16/10/18 18:58:26 INFO util.GSet: 0.029999999329447746% max memory 910.5 MB = 279.7 KB
16/10/18 18:58:26 INFO util.GSet: capacity      = 2^15 = 32768 entries
16/10/18 18:58:26 INFO namenode.NNConf: ACLs enabled? false
16/10/18 18:58:26 INFO namenode.NNConf: XAttrs enabled? true
16/10/18 18:58:26 INFO namenode.NNConf: Maximum size of an xattr: 16384
16/10/18 18:58:26 INFO common.Storage: Lock on \Metadata\data\dfs\namenode\in_use.lock acquired by nodename 8804@myserver
16/10/18 18:58:26 WARN namenode.FSNamesystem: Encountered exception loading fsimage
org.apache.hadoop.hdfs.server.common.IncorrectVersionException: Unexpected version of storage directory C:\Metadata\data\dfs\namenode. Reported: -63. Expecting = -57.
        at org.apache.hadoop.hdfs.server.common.StorageInfo.setLayoutVersion(StorageInfo.java:178)
        at org.apache.hadoop.hdfs.server.common.StorageInfo.setFieldsFromProperties(StorageInfo.java:131)
        at org.apache.hadoop.hdfs.server.namenode.NNStorage.setFieldsFromProperties(NNStorage.java:608)
        at org.apache.hadoop.hdfs.server.common.StorageInfo.readProperties(StorageInfo.java:228)
        at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverStorageDirs(FSImage.java:323)
        at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:202)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:955)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:700)
        at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:529)
        at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:585)
        at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:751)
        at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:735)
        at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1407)
        at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1473)
16/10/18 18:58:26 INFO mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@myserver.root.Dinesh.lan:50070
16/10/18 18:58:26 INFO impl.MetricsSystemImpl: Stopping NameNode metrics system...
16/10/18 18:58:26 INFO impl.MetricsSystemImpl: NameNode metrics system stopped.
16/10/18 18:58:26 INFO impl.MetricsSystemImpl: NameNode metrics system shutdown complete.
16/10/18 18:58:26 FATAL namenode.NameNode: Exception in namenode join
org.apache.hadoop.hdfs.server.common.IncorrectVersionException: Unexpected version of storage directory C:\Metadata\data\dfs\namenode. Reported: -63. Expecting = -57.
        at org.apache.hadoop.hdfs.server.common.StorageInfo.setLayoutVersion(StorageInfo.java:178)
        at org.apache.hadoop.hdfs.server.common.StorageInfo.setFieldsFromProperties(StorageInfo.java:131)
        at org.apache.hadoop.hdfs.server.namenode.NNStorage.setFieldsFromProperties(NNStorage.java:608)
        at org.apache.hadoop.hdfs.server.common.StorageInfo.readProperties(StorageInfo.java:228)
        at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverStorageDirs(FSImage.java:323)
        at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:202)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:955)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:700)
        at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:529)
        at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:585)
        at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:751)
        at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:735)
        at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1407)
        at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1473)
16/10/18 18:58:26 INFO util.ExitUtil: Exiting with status 1
16/10/18 18:58:26 INFO namenode.NameNode: SHUTDOWN_MSG:
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at myserver/192.168.10.1
*************************************************************|, [~andreina], have you seen this kind of issue in rollback?

From the trace, it looks like it is having problem after reading in the VERSION file in NN storage directory. The VERSION file must contain the new layout version and somehow the rollback is not being able to deal with it., I think this was fixed automatically by HDFS-7185. which is present in 2.6.0

After the rollingUpgrade to version with layoutVersion change, upgraded VERSION file will contain new version.
Without HDFS-7185, setting of layout version will fail as VERSION file contains new layout version.

After HDFS-7185, while loading the rollback image, "layoutVersion" will be ignored from VERSION file and set same as Software's VERSION, but it will be checked strictly from image file.

Following changes in NNStorage.java will do the this.
{code}  void readProperties(StorageDirectory sd, StartupOption startupOption)
      throws IOException {
    Properties props = readPropertiesFile(sd.getVersionFile());
    if (HdfsServerConstants.RollingUpgradeStartupOption.ROLLBACK.matches
        (startupOption)) {
      int lv = Integer.parseInt(getProperty(props, sd, "layoutVersion"));
      if (lv > getServiceLayoutVersion()) {
        // we should not use a newer version for rollingUpgrade rollback
        throw new IncorrectVersionException(getServiceLayoutVersion(), lv,
            "storage directory " + sd.getRoot().getAbsolutePath());
      }
      props.setProperty("layoutVersion",
          Integer.toString(HdfsServerConstants.NAMENODE_LAYOUT_VERSION));
    }
    setFieldsFromProperties(props, sd);
  }{code}


But in 2.8.0 in HDFS-8432, updating the VERSION file on rolling upgrade is avoided., If it is indeed the VERSION file issue, you can workaround it by manually editing the VERSION file to put the old layout version, after making backups, of course., Hi [~kihwal],

*With journal nodes and zookeeper instances running, changed value from -63 to -57. Rollback failed with the following exception*
|16/10/19 13:43:19 WARN namenode.FSNamesystem: Encountered exception loading fsimage
org.apache.hadoop.hdfs.server.common.IncorrectVersionException: Unexpected version of storage directory \Metadata\data\dfs\namenode. Reported: -57. Expecting = -63.
        at org.apache.hadoop.hdfs.server.namenode.NNStorage.readProperties(NNStorage.java:633)
        at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverStorageDirs(FSImage.java:339)
        at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:215)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:975)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:681)
        at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:584)
        at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:644)
        at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:811)
        at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:795)
        at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1488)
        at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1554)|

*Changed version back to -63 and executed -rollingUpgrade rollback command. Now faced the following exception*
|16/10/19 13:43:43 ERROR namenode.FSImage: Failed to load image from FSImageFile(file=\Metadata\data\dfs\namenode\current\fsimage_rollback_0000000000000004951, cpktTxId=0000000000000004951)
java.io.IOException: Image version -57 is not equal to the software version -63
        at org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf$Loader.loadInternal
(FSImageFormatProtobuf.java:196)
        at org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf$Loader.load(FSImageFormatProtobuf.java:179)
        at org.apache.hadoop.hdfs.server.namenode.FSImageFormat$LoaderDelegator.load(FSImageFormat.java:226)
        at org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:957)
        at org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:941)
        at org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImageFile(FSImage.java:740)
        at org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:676)
        at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:294)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:975)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:681)
        at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:584)
        at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:644)
        at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:811)
        at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:795)
        at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1488)
        at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1554)
16/10/19 13:43:43 WARN namenode.FSNamesystem: Encountered exception loading fsimage
java.io.IOException: Failed to load an FSImage file!
        at org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:687)
        at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:294)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:975)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:681)
        at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:584)
        at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:644)
        at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:811)
        at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:795)
        at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1488)
        at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1554)
16/10/19 13:43:43 INFO mortbay.log: Stopped|, Were you issuing rollback with 2.7.2?, Hi [~kihwal],

Yes. Did by mistake. Let me change version in both name nodes and do rollback with older version 2.5.2 and get back to you.

Thanks,
Dinesh Kumar P]