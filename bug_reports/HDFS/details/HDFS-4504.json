{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12632534","self":"https://issues.apache.org/jira/rest/api/2/issue/12632534","key":"HDFS-4504","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":"2013-04-18T00:40:26.051+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Sat May 02 04:50:48 UTC 2015","customfield_12310420":"313030","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-4504/watchers","watchCount":40,"isWatching":false},"created":"2013-02-15T06:40:00.548+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":["BB2015-05-TBR"],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"10.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[],"issuelinks":[{"id":"12367443","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12367443","type":{"id":"10032","name":"Blocker","inward":"is blocked by","outward":"blocks","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10032"},"outwardIssue":{"id":"12642109","key":"HDFS-4688","self":"https://issues.apache.org/jira/rest/api/2/issue/12642109","fields":{"summary":"DFSClient should not allow multiple concurrent creates for the same file","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12369556","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12369556","type":{"id":"12310000","name":"Duplicate","inward":"is duplicated by","outward":"duplicates","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/12310000"},"inwardIssue":{"id":"12649574","key":"HDFS-4855","self":"https://issues.apache.org/jira/rest/api/2/issue/12649574","fields":{"summary":"DFSOutputStream reference should be cleared from DFSClient#filesBeingWritten if the file closure fails.","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12391195","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12391195","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"inwardIssue":{"id":"12726482","key":"HDFS-6652","self":"https://issues.apache.org/jira/rest/api/2/issue/12726482","fields":{"summary":"RecoverLease cannot succeed and file cannot be closed under high load","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/4","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/minor.svg","name":"Minor","id":"4"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2015-05-06T03:33:20.801+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/10002","description":"A patch for this issue has been uploaded to JIRA by a contributor.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/document.png","name":"Patch Available","id":"10002","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/4","id":4,"key":"indeterminate","colorName":"yellow","name":"In Progress"}},"components":[],"timeoriginalestimate":null,"description":"{{DFSOutputStream#close}} can throw an {{IOException}} in some cases.  One example is if there is a pipeline error and then pipeline recovery fails.  Unfortunately, in this case, some of the resources used by the {{DFSOutputStream}} are leaked.  One particularly important resource is file leases.\n\nSo it's possible for a long-lived HDFS client, such as Flume, to write many blocks to a file, but then fail to close it.  Unfortunately, the {{LeaseRenewerThread}} inside the client will continue to renew the lease for the \"undead\" file.  Future attempts to close the file will just rethrow the previous exception, and no progress can be made by the client.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12324031","id":"12324031","description":"2.1.0-beta release","name":"2.1.0-beta","archived":false,"released":true,"releaseDate":"2013-08-22"}],"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12579233","id":"12579233","filename":"HDFS-4504.001.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-04-17T23:25:21.365+0000","size":12187,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12579233/HDFS-4504.001.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12579431","id":"12579431","filename":"HDFS-4504.002.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-04-18T21:43:48.768+0000","size":10513,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12579431/HDFS-4504.002.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12596972","id":"12596972","filename":"HDFS-4504.007.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-08-08T22:59:16.329+0000","size":28558,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12596972/HDFS-4504.007.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12597009","id":"12597009","filename":"HDFS-4504.008.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-08-09T02:12:55.809+0000","size":30700,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12597009/HDFS-4504.008.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12597191","id":"12597191","filename":"HDFS-4504.009.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-08-09T22:42:32.495+0000","size":30800,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12597191/HDFS-4504.009.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12597529","id":"12597529","filename":"HDFS-4504.010.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-08-12T18:50:09.957+0000","size":31950,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12597529/HDFS-4504.010.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12597800","id":"12597800","filename":"HDFS-4504.011.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-08-13T20:01:00.746+0000","size":33311,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12597800/HDFS-4504.011.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12598096","id":"12598096","filename":"HDFS-4504.014.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-08-14T23:50:09.501+0000","size":67599,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12598096/HDFS-4504.014.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12598294","id":"12598294","filename":"HDFS-4504.015.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-08-15T21:08:05.828+0000","size":71863,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12598294/HDFS-4504.015.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12599081","id":"12599081","filename":"HDFS-4504.016.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-08-21T02:00:41.865+0000","size":69370,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12599081/HDFS-4504.016.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"313376","customfield_12312823":null,"summary":"DFSOutputStream#close doesn't always release resources (such as leases)","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12632534/comment/13578996","id":"13578996","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"body":"Here is the code for {{DFSOutputStream#close}}:\n\n{code}\n  /**\n   * Closes this output stream and releases any system \n   * resources associated with this stream.\n   */\n  @Override\n  public synchronized void close() throws IOException {\n    if (closed) {\n      IOException e = lastException;\n      if (e == null)\n        return;\n      else\n        throw e;\n    }\n\n    try {\n      flushBuffer();       // flush from all upper layers\n\n      if (currentPacket != null) { \n        waitAndQueueCurrentPacket();\n      }\n\n      if (bytesCurBlock != 0) {\n        // send an empty packet to mark the end of the block\n        currentPacket = new Packet(0, 0, bytesCurBlock, \n            currentSeqno++, this.checksum.getChecksumSize());\n        currentPacket.lastPacketInBlock = true;\n        currentPacket.syncBlock = shouldSyncBlock;\n      }\n\n      flushInternal();             // flush all data to Datanodes\n      // get last block before destroying the streamer\n      ExtendedBlock lastBlock = streamer.getBlock();\n      closeThreads(false);\n      completeFile(lastBlock);\n      dfsClient.endFileLease(src);\n    } finally {\n      closed = true;\n    }\n  }\n{code}\n\nAs you can see, if {{DFSOutputStream#flushBuffer}} throws an {{IOException}}, {{DFSOutputStream#closed}} will be set to true, but we'll never call {{dfsClient.endFileLease}}.  Future attempts to close the {{DFSOutputStream}} will just hit the if statement which rethrows {{lastException}}.\n\nThe file can never be closed until we take down the whole client-- which is a problem for long-lived clients like HBase, Flume, etc.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-02-15T06:43:32.373+0000","updated":"2013-02-15T06:43:32.373+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12632534/comment/13578998","id":"13578998","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"body":"Another issue we could hit here is that if we temporarily can't talk to the NameNode, we could get an IOException when calling {{DFSOutputStream#completeFile}}.  This is another case where we will \"leak\" the lease.\n\nWe should retry the complete RPC periodically in case we are going through e.g. a NameNode failover, or just general network problems.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-02-15T06:47:55.045+0000","updated":"2013-02-15T06:47:55.045+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12632534/comment/13634686","id":"13634686","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"body":"> We should retry the complete RPC periodically in case we are going through e.g. a NameNode failover, or just general network problems.\n\nRPC retry should be done in RPC level.  Please don't add retry to DFSClient.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-04-18T00:40:26.051+0000","updated":"2013-04-18T00:40:26.051+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12632534/comment/13634733","id":"13634733","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12579233/HDFS-4504.001.patch\n  against trunk revision .\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:red}-1 findbugs{color}.  The patch appears to introduce 1 new Findbugs (version 1.3.9) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:\n\n                  org.apache.hadoop.hdfs.server.balancer.TestBalancerWithNodeGroup\n                  org.apache.hadoop.hdfs.server.datanode.TestBlockRecovery\n                  org.apache.hadoop.hdfs.TestHFlush\n                  org.apache.hadoop.hdfs.TestFileCreation\n                  org.apache.hadoop.hdfs.TestFileAppend4\n                  org.apache.hadoop.hdfs.TestQuota\n                  org.apache.hadoop.hdfs.server.namenode.TestSaveNamespace\n                  org.apache.hadoop.cli.TestHDFSCLI\n                  org.apache.hadoop.hdfs.TestDFSClientRetries\n\n    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/4272//testReport/\nFindbugs warnings: https://builds.apache.org/job/PreCommit-HDFS-Build/4272//artifact/trunk/patchprocess/newPatchFindbugsWarningshadoop-hdfs.html\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/4272//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2013-04-18T01:23:16.096+0000","updated":"2013-04-18T01:23:16.096+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12632534/comment/13635672","id":"13635672","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"body":"bq. RPC retry should be done in RPC level. Please don't add retry to DFSClient.\n\nOK.  I will remove this in the next patch.\n\nI suppose lease recovery will take care of un-completed files eventually.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-04-18T20:47:43.329+0000","updated":"2013-04-18T20:47:43.329+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12632534/comment/13635731","id":"13635731","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"body":"* remove manual retry (allow RPC retry to do this job)\n\n* remove debug messages\n\n* TestBlockRecovery: set lower RPC timeout so that we give up on close prior to the test timeout.\n\n* If both {{completeFile}} and the block data flush fail, throw a {{MultipleIOException}} with information about both failures.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-04-18T21:43:48.771+0000","updated":"2013-04-18T21:43:48.771+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12632534/comment/13635834","id":"13635834","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:green}+1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12579431/HDFS-4504.002.patch\n  against trunk revision .\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:green}+1 tests included{color}.  The patch appears to include 2 new or modified test files.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.\n\n    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/4275//testReport/\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/4275//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2013-04-18T23:33:57.561+0000","updated":"2013-04-18T23:33:57.561+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12632534/comment/13640937","id":"13640937","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"Does this fully solve the problem, given that leases are per-client, not per-file? ie so long as the long-lived client has any other open files for write, it will keep calling {{renewLease()}} and the file will be stuck open and un-recovered forever.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2013-04-24T20:50:11.107+0000","updated":"2013-04-24T20:50:11.107+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12632534/comment/13640985","id":"13640985","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"body":"bq. Does this fully solve the problem, given that leases are per-client, not per-file? ie so long as the long-lived client has any other open files for write, it will keep calling renewLease() and the file will be stuck open and un-recovered forever.\n\nThanks for pointing that out.  I think this is a real problem with my current patch and is likely to lead to the kind of scenario we've seen in the field in the past, where a long-lived HDFS client program like Flume gets some files in limbo after transient network problems during a close operation.\n\nThe only way around that I can think of is to keep around a list of uncompleted, but closed files.  The lease renewer thread can call complete on them prior to renewing the lease with the NameNode.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-04-24T21:32:47.010+0000","updated":"2013-04-24T21:32:47.010+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12632534/comment/13669636","id":"13669636","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"body":"If the datanodes didn't get the last packet of the last block or they died before reporting to NN of the completion, completeFile() may never work. I can think of several ways.\n\n* Delete the incomplete file. It will remove the lease. This will violate the data durability semantics, so it's not feasible to do it in DFSClient. Apps may do this if close() throws an exception.\n* Introduce a new ClientProtocol method, releaseLease(), which triggers immediate block recovery if necessary. This is an incompatible change, so less desirable.\n* Extend complete() by adding an optional boolean arg, \"force\". Things will stay compatible. If a new client is talking to an old NN, the file may not get completed right away, but this is no worse than current behavior. The client (lease renewer) can keep trying periodically. Probably less often than the lease renewal. We may only allow this when lastBlock is present, since the acked block length will reduce the risk of truncating valid data.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"created":"2013-05-29T19:55:50.220+0000","updated":"2013-05-29T19:55:50.220+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12632534/comment/13669684","id":"13669684","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"body":"I think the vast majority of these cases will simply be handled by block recovery.  The other part of the time, block recovery has gotten into a state where it will never succeed, and we simply need to deal with that situation.  Probably the best way is adding the force flag to {{completeFile}}.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-05-29T20:21:58.065+0000","updated":"2013-05-29T20:21:58.065+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12632534/comment/13697624","id":"13697624","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks Colin, for working on this issue. \nJust to summarize:\nPer my understanding here there are 2 issues, 1.leaving stale refernces when there is failures in close call. 2. For long lived client, if cmpleFile fails, no one will recover is as client will renewLease\n\nfor #1, fix would little straight forward.\nfor #2, Kihwal brought some cases above.\n\n{quote}\n•Extend complete() by adding an optional boolean arg, \"force\". Things will stay compatible. If a new client is talking to an old NN, the file may not get completed right away, but this is no worse than current behavior. The client (lease renewer) can keep trying periodically. Probably less often than the lease renewal. We may only allow this when lastBlock is present, since the acked block length will reduce the risk of truncating valid data.\n{quote}\nSince the current close call already closes streamer, where we maintain this last block? you mean we will introduce another structure for it and check periodially in renewer/anyother thread?\n\n(or) How about checking the filesBeingWritten file state. If the FileBeingWritten state is closed from Clinet perspective but completFile/flushbuffer failed. So, we will not remove that references staright away from DFsClient. In this case, Renewer will check such files(closed) and check real file status from NN. If the file closed from NN(isFileClosed added in trunk I guess) , then remove from the fileBeingWritten list directly. Otherwise make a call ourselves recoverLease (as we know no one is going to do recover for such files).\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-07-02T09:24:24.091+0000","updated":"2013-07-02T09:24:24.091+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12632534/comment/13698487","id":"13698487","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"body":"That's an interesting idea-- calling recoverLease from the client itself.  It might have the advantage of requiring less new code, compared to adding a new flag to {{complete()}}.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-07-03T01:42:19.383+0000","updated":"2013-07-03T01:42:19.383+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12632534/comment/13734151","id":"13734151","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"body":"This patch creates a background thread for handling uncloseable files.  Streams get placed into the {{ZombieStreamManager}} when close() fails to contact the NameNode.  It uses an {{ExecutorService}}, so the OS thread will be properly disposed of when it's not in use.\n\nThe client can figure out when the file is closed on the NameNode by polling {{DFSOutputStream#close}}.  When the lease recovery succeeds, {{DFSOutputStream#close}} will stop throwing an {{IOException}}.  At that point, the client can re-open that file if it wishes.  This is a lot better than the current situation, where the client doesn't know when, or if, the file will ever be safe to re-open.\n\n{{TestHdfsClose}} test a few different cases: all of the DataNodes going down, all of the NameNodes going down, and the client calling {{DistributedFileSystem#abort}}.  In every case, we should be able to keep going after an error and not run into uncloseable files.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-08-08T23:08:53.537+0000","updated":"2013-08-08T23:08:53.537+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12632534/comment/13734281","id":"13734281","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12596972/HDFS-4504.007.patch\n  against trunk revision .\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:red}-1 findbugs{color}.  The patch appears to introduce 3 new Findbugs (version 1.3.9) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:\n\n                  org.apache.hadoop.hdfs.TestCrcCorruption\n                  org.apache.hadoop.hdfs.server.datanode.TestBlockRecovery\n\n    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/4787//testReport/\nFindbugs warnings: https://builds.apache.org/job/PreCommit-HDFS-Build/4787//artifact/trunk/patchprocess/newPatchFindbugsWarningshadoop-hdfs.html\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/4787//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2013-08-09T00:53:40.354+0000","updated":"2013-08-09T00:53:40.354+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12632534/comment/13734332","id":"13734332","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"body":"* fix findbugs warning about {{equals}}() needing to check for {{null}}.  Suppress bogus warnings about serializing the {{ZombieStreamManager}}\n\n* fix two tests that were assuming that {{DFSOutputStream#close}} did not actually call {{completeFile}} if the flush failed.  In both cases, the test just wanted to test that (h)flush failed, so do that instead.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-08-09T02:12:55.812+0000","updated":"2013-08-09T02:12:55.812+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12632534/comment/13734380","id":"13734380","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12597009/HDFS-4504.008.patch\n  against trunk revision .\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:green}+1 tests included{color}.  The patch appears to include 3 new or modified test files.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:\n\n                  org.apache.hadoop.hdfs.TestFileCreation\n                  org.apache.hadoop.hdfs.server.balancer.TestBalancerWithNodeGroup\n\n    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/4789//testReport/\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/4789//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2013-08-09T04:20:26.860+0000","updated":"2013-08-09T04:20:26.860+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12632534/comment/13735085","id":"13735085","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"body":"The TestBalancerWithNodeGroup test timeout is HDFS-4376.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-08-09T18:08:56.848+0000","updated":"2013-08-09T18:08:56.848+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12632534/comment/13735425","id":"13735425","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"body":"in some cases, {{DFSOutputStream#close}} and {{DFSOutputStream#lastException}} will be set by the {{DataStreamer}}, prior to {{DFSOutputStream#close}} being called.  In those cases, we need to throw an exception from close prior to clearing the exception.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-08-09T22:42:32.498+0000","updated":"2013-08-09T22:42:32.498+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12632534/comment/13735594","id":"13735594","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:green}+1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12597191/HDFS-4504.009.patch\n  against trunk revision .\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:green}+1 tests included{color}.  The patch appears to include 3 new or modified test files.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.\n\n    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/4797//testReport/\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/4797//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2013-08-10T00:36:34.603+0000","updated":"2013-08-10T00:36:34.603+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12632534/comment/13736680","id":"13736680","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinayrpet","name":"vinayrpet","key":"vinayrpet","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinayakumar B","active":true,"timeZone":"Asia/Kolkata"},"body":"{quote}DFSOutputStream#close can throw an IOException in some cases. One example is if there is a pipeline error and then pipeline recovery fails. Unfortunately, in this case, some of the resources used by the DFSOutputStream are leaked. One particularly important resource is file leases.{quote}\nAccording to desctription, this patch suppose to handle pipeline recovery case, but it misses mainly that case.\n\nI am not sure how in jenkins this passing, {{TestHdfsClose.testCloseWithDatanodeDown()}} always failing for me. last {{out.close()}} in the test always throws error, according to code thats how it is.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinayrpet","name":"vinayrpet","key":"vinayrpet","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinayakumar B","active":true,"timeZone":"Asia/Kolkata"},"created":"2013-08-12T08:11:29.638+0000","updated":"2013-08-12T08:11:29.638+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12632534/comment/13736859","id":"13736859","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jlowe","name":"jlowe","key":"jlowe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jason Lowe","active":true,"timeZone":"America/Chicago"},"body":"There was a build failure in the test build because TestDFSClientRetries either timed out or called System.exit, but Jenkins missed it due to HADOOP-9583.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jlowe","name":"jlowe","key":"jlowe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jason Lowe","active":true,"timeZone":"America/Chicago"},"created":"2013-08-12T13:32:55.354+0000","updated":"2013-08-12T13:32:55.354+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12632534/comment/13737214","id":"13737214","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"body":"*  {{TestDFSClientRetries#testNotYetReplicatedErrors}} was assuming that close didn't actually call complete() on the NameNode when there was an I/O error.  I fixed this assumption by adding a complete() method which returned true on the mock NameNode object used in the test.\n\n* {{DFSOutputStream#close}} needed to set {{lastException}} to {{null}} after successfully stopping the I/O threads.  The reason is that IOExceptions are handled in the throw clause already, so there is no need to rethrow the next time {{DFSOutputStream#close}} is called.  Only when {{complete}} fails do we want to keep the exception around.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-08-12T18:50:09.959+0000","updated":"2013-08-12T18:50:09.959+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12632534/comment/13737219","id":"13737219","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12597529/HDFS-4504.010.patch\n  against trunk revision .\n\n    {color:red}-1 patch{color}.  Trunk compilation may be broken.\n\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/4803//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2013-08-12T18:53:36.685+0000","updated":"2013-08-12T18:53:36.685+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12632534/comment/13737627","id":"13737627","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=andrew.wang","name":"andrew.wang","key":"andrew.wang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=andrew.wang&avatarId=19230","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=andrew.wang&avatarId=19230","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=andrew.wang&avatarId=19230","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=andrew.wang&avatarId=19230"},"displayName":"Andrew Wang","active":true,"timeZone":"America/Los_Angeles"},"body":"Some light review comments, I'd prefer if someone more experienced with the write path also reviewed this before committing.\n\n{code}\n+      // We couldn't contact the NameNode (or it refused to close the file.)\n{code}\n\nNit: period goes outside the parenthesis.\n\n* TreeMaps are memory inefficient, so I'd prefer to use something else unless we need ordering. I believe {{ConcurrentHashMap}} has safe concurrent iteration behavior.\n* Any reason for the StreamInfo class over a Long?\n* TestHdfsClose: should use {{GenericTestUtils#assertExceptionContains}} when catching an expected IOException.\n* Unrelated to this patch, but {{DFSClient#endFileLease}} is poorly named, since it doesn't actually end the lease. Maybe rename it to {{stopLeaseRenewal}}?\n* I noticed that {{endFileLease}} is now called before {{completeFile}}, could the lease expire between these two calls? I guess it'll still get cleaned up okay by the ZSM, but this is extra work.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=andrew.wang","name":"andrew.wang","key":"andrew.wang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=andrew.wang&avatarId=19230","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=andrew.wang&avatarId=19230","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=andrew.wang&avatarId=19230","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=andrew.wang&avatarId=19230"},"displayName":"Andrew Wang","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-08-13T00:35:22.858+0000","updated":"2013-08-13T00:35:22.858+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12632534/comment/13737737","id":"13737737","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"body":"bq. TreeMaps are memory inefficient, so I'd prefer to use something else unless we need ordering. I believe ConcurrentHashMap has safe concurrent iteration behavior.\n\nA balanced tree should take up effectively no memory when it's empty, which this tree will be almost all of the time.  In contrast, a hash table needs to pre-reserve a chunk of memory to avoid collisions.  Minimum capacity for java.util.HashMap seems to be 16, which means you'll have to spend 16 * sizeof(pointer to jobject) = 128 bytes just to do nothing (which is what you'll be doing most of the time).  Also, we do need ordering here.  Finally, iterating over hash maps is slow because you have to check all the null entries.\n\nA hash map would be a really terrible thing to use here, because if it did ever grow, that would be just a transitory event.  And then it would never shrink again, but just continue using that memory forever.  Check HashMap.java if you are curious.\n\nbq. Any reason for the StreamInfo class over a Long?\n\nStreamInfo is mutable; Long is not.  Although I could remove and re-insert the element into the map, it seems unnecessary.\n\nbq. Unrelated to this patch, but DFSClient#endFileLease is poorly named, since it doesn't actually end the lease. Maybe rename it to stopLeaseRenewal?\n\nOK, I'll change it to stopLeaseRenewal.\n\nbq. TestHdfsClose: should use GenericTestUtils#assertExceptionContains when catching an expected IOException.\n\nIt's clearly going to throw some IOException, because the DataNode/NameNode/etc are down, but I don't think the message inside the IOException is important.\n\nbq. I noticed that endFileLease is now called before completeFile, could the lease expire between these two calls? I guess it'll still get cleaned up okay by the ZSM, but this is extra work.\n\nI suppose I might as well wait until after completeFile to end the lease renewal.  As you've already inferred, it's extremely unlikely to make a difference, since if there are absolutely any other files open by the client, the lease will still be renewed.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-08-13T02:42:23.689+0000","updated":"2013-08-13T02:42:23.689+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12632534/comment/13738134","id":"13738134","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinayrpet","name":"vinayrpet","key":"vinayrpet","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinayakumar B","active":true,"timeZone":"Asia/Kolkata"},"body":"{quote}In some cases, DFSOutputStream#close and DFSOutputStream#lastException will be set by the DataStreamer, prior to DFSOutputStream#close being called. In those cases, we need to throw an exception from close prior to clearing the exception.{quote}\nI assume these cases were never handled. Without handling pipeline failure cases, this patch will be incomplete.\nPipeline failures while writing data are also most likely to happen.\n\nIn case of pipeline failures {{closed}} will be marked {{true}} by DataStreamer thread itself (as mentioned already in [~cmccabe] comment). On first call to close() will throw the pipeline failure exception, but next calls to close() just returns. *So Stream will never be marked as zombie, also resources will never be released.*\n\nYou can verify by changing your test {{testCloseWithDatanodeDown}} as follows\n{code}+      out.write(100);\n+      cluster.stopDataNode(0);{code}\n\nto \n{code}+      out.write(100);\n+      out.hflush();\n+      out.write(100);\n+      cluster.stopDataNode(0);{code}\n\nPlease check. \n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinayrpet","name":"vinayrpet","key":"vinayrpet","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinayakumar B","active":true,"timeZone":"Asia/Kolkata"},"created":"2013-08-13T12:29:37.562+0000","updated":"2013-08-13T12:29:37.562+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12632534/comment/13738646","id":"13738646","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"body":"You're right-- we're going to need a solution for ensuring that completeFile is called when the stream closes itself due to IOException.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-08-13T18:40:41.674+0000","updated":"2013-08-13T18:40:41.674+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12632534/comment/13738749","id":"13738749","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"body":"* rename DFSClient#endFileLease to DFSClient#stopRenewingFileLease\n\n* add DFSOutputStream#closeCalled as a separate boolean from DFSOutputStream#close.  This ensures that the first time a user calls DFSOutputStream#close, we actually call completeFile.\n\n* Call completeFile before stopping renewing the file lease, not after.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-08-13T20:01:00.749+0000","updated":"2013-08-13T20:01:00.749+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12632534/comment/13738888","id":"13738888","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12597800/HDFS-4504.011.patch\n  against trunk revision .\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:green}+1 tests included{color}.  The patch appears to include 4 new or modified test files.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:red}-1 core tests{color}.  The following test timeouts occurred in hadoop-hdfs-project/hadoop-hdfs:\n\norg.apache.hadoop.hdfs.TestFileCreationDelete\norg.apache.hadoop.hdfs.TestHFlush\norg.apache.hadoop.hdfs.TestFileCreationClient\n\n    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/4814//testReport/\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/4814//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2013-08-13T21:56:00.600+0000","updated":"2013-08-13T21:56:00.600+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12632534/comment/13739162","id":"13739162","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"body":"It looks like there are a few more unit tests that need to be fixed.  I have some fixes, will post later today.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-08-14T02:35:09.821+0000","updated":"2013-08-14T02:35:09.821+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12632534/comment/13739168","id":"13739168","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"I don't think {{recoverLease}} is the right API here.. here's an example where it could cause problems:\n\n- Process A is writing /file, and loses its network connection right before calling close(). Thus it gets registered as a zombie.\n- Process B calls append() on the file after the soft lease has expired. This allows B to keep appending where A left off.\n- Process A recovers its network. The recoverLease() call will then kick process B out from writing.\n\nGiven that these RPCs are also pathname-based, it could even kick a writer off of a new file that just happened to share the file path.\n\nIt seems to me like it would be better to call completeFile() or perhaps some new abortFile() RPC, which would first verify that the client name trying to abort the lease is the same as the current lease holder.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2013-08-14T02:52:54.912+0000","updated":"2013-08-14T02:52:54.912+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12632534/comment/13739204","id":"13739204","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"body":"The problem with calling completeFile is that it may never succeed.  If the last block can't be replicated adequately, completeFile will return false forever.  I had a change previously which at first called completeFile, but then switched to recoverLease after a few tries.  But it seemed like such a corner csae for a corner case that it wasn't worth doing.\n\nI agree that there are some thorny issues surrounding leases and multiple clients.  I looked at this for a long time and concluded that it's impossible to solve these problems without switching the lease mechanism to use (our globally unique) inode numbers.\n\nOne example is: suppose you have two threads, T1 and T2.  They both have a client name of C.\n\nT1 creates a file /foo/bar, writes some stuff, and tries to close.  But he fails and becomes a zombie.\n\nAt some point later, T2 creates /baz/bar.  Now, /baz is a symlink to /foo.  So now the NameNode recovers the lease.  But will the zombie recovery thread stomp on T2?  It definitely might.\n\nThe problem is that a close attempt needs to be associated with a particular file creation attempt.  Right now, all we have is a path and a client name, and these aren't enough to uniquely identify the file creation.  Your point is that we should be stricter in matching the client name in create with the client name in completeFile/recoverLease.  But even being stricter there won't close all the holes.\n\nMaybe a good compromise in the meantime is to expose basically expose recoverLeaseInternal(force=false), by adding an optional boolean parameter to the recoverLease protobuf.  In the long term, we eventually need a more extensive rework of the leases to be inode-based, which would fix a lot of other sore spots as well (like the rename of open files issue.)","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-08-14T04:23:24.994+0000","updated":"2013-08-14T04:23:24.994+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12632534/comment/13739215","id":"13739215","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"body":"OK, I thought about this a little more.  Since we handle symlinks by throwing {{UnresolvedLinkException}}, maybe the scenario I outlined can't happen.  The client would get {{UnresolvedLinkException}} when trying to create {{/baz/bar}}, and the resolve it to {{/foo/bar}}.  At that point, we could reasonably detect that it was the same file as the one in the first thread.\n\nWe might reasonably be able to just do something very similar to recoverLease, but checking that the client name is the same as the one on the lease.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-08-14T04:40:10.361+0000","updated":"2013-08-14T04:40:10.361+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12632534/comment/13739288","id":"13739288","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinayrpet","name":"vinayrpet","key":"vinayrpet","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinayakumar B","active":true,"timeZone":"Asia/Kolkata"},"body":"bq. It seems to me like it would be better to call completeFile() or perhaps some new abortFile() RPC, which would first verify that the client name trying to abort the lease is the same as the current lease holder.\nThis looks good. Seems this would take lot of code changes and also lot of cases to handle. But may be difficult to handle \"suppose you have two threads, T1 and T2. They both have a client name of C.\" case since client is same.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinayrpet","name":"vinayrpet","key":"vinayrpet","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinayakumar B","active":true,"timeZone":"Asia/Kolkata"},"created":"2013-08-14T06:31:05.365+0000","updated":"2013-08-14T06:31:05.365+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12632534/comment/13739293","id":"13739293","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"body":"I don't think adding a new RPC would be too bad.  It would be very similar to recoverLease.\n\nbq. But may be difficult to handle \"suppose you have two threads, T1 and T2. They both have a client name of C.\" case since client is same.\n\nI think we should do this in HDFS-4688 rather than trying to solve it here.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-08-14T06:39:27.782+0000","updated":"2013-08-14T06:39:27.782+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12632534/comment/13740434","id":"13740434","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"body":"The latest patch:\n* when reaping zombie files, don't use recoverLease.  Instead, add a \"force\" flag to completeFile.\n* add {{dfs.client.close.timeout.ms}}, to specify how long we should wait inside close() before making the file a zombie.  Previously, we used {{ipc.ping.interval}} to determine how long to wait.  Having a configuration option for this makes a lot of unit tests that want to test \"close + unresponsive namenode\" much simpler to do.\n* {{FSNamesystem#completeFile}} should issue a different log message on failure than on success.\n* {{TestHFlush#testHFlushInterrupted}}: Thread#interrupted is a static function; refer to it statically to avoid Java warning.  Clear interrupted status when appropriate.\n\nSince this is a bigger change, I added small whitespace changes in hadoop-mapreduce-client, hadoop-yarn, and hadoop-tools to get a full test run, so that we can become aware of any issues.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-08-14T23:49:42.467+0000","updated":"2013-08-14T23:49:42.467+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12632534/comment/13740546","id":"13740546","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12598096/HDFS-4504.014.patch\n  against trunk revision .\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:green}+1 tests included{color}.  The patch appears to include 10 new or modified test files.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app hadoop-tools/hadoop-distcp hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client:\n\n                  org.apache.hadoop.hdfs.server.namenode.TestSaveNamespace\n                  org.apache.hadoop.hdfs.server.namenode.ha.TestHAStateTransitions\n                  org.apache.hadoop.hdfs.TestHdfsClose\n                  org.apache.hadoop.hdfs.TestFileAppend4\n                  org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover\n\n                                      The following test timeouts occurred in hadoop-hdfs-project/hadoop-hdfs hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app hadoop-tools/hadoop-distcp hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client:\n\norg.apache.hadoop.hdfs.TestFileAppend3\n\n    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/4827//testReport/\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/4827//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2013-08-15T01:30:55.342+0000","updated":"2013-08-15T01:30:55.342+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12632534/comment/13741480","id":"13741480","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"body":"A few tests needed to be fixed, since they were assuming that a single {{IOException}} would cause {{DFSOutputStream#close}} to give up immediately, whereas that is no longer the case.  Setting {{DFSConfigKeys.DFS_CLIENT_CLOSE_TIMEOUT_MS}} to a low value allows the tests to complete in a reasonable amount of time.\n\n{{FSNamesystem#completeInternal(force=true)}} needed to call {{internalReleaseLease}} to properly finalize the last block in the file.  Failure to do this could put us in a situation where the NameNode thinks the block is finalized, but the DataNode(s) do not.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-08-15T21:07:53.446+0000","updated":"2013-08-15T21:07:53.446+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12632534/comment/13741676","id":"13741676","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12598294/HDFS-4504.015.patch\n  against trunk revision .\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:green}+1 tests included{color}.  The patch appears to include 12 new or modified test files.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:red}-1 core tests{color}.  The following test timeouts occurred in hadoop-hdfs-project/hadoop-hdfs hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app hadoop-tools/hadoop-distcp hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client:\n\norg.apache.hadoop.hdfs.TestHFlush\n\n    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/4834//testReport/\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/4834//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2013-08-15T23:36:38.285+0000","updated":"2013-08-15T23:36:38.285+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12632534/comment/13743546","id":"13743546","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinayrpet","name":"vinayrpet","key":"vinayrpet","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinayakumar B","active":true,"timeZone":"Asia/Kolkata"},"body":"In the latest patch, some unnecessary (Only space) file changes from Mapreduce, tools and Yarn project got added. I assume these added by mistake. Can you please remove them..","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinayrpet","name":"vinayrpet","key":"vinayrpet","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinayakumar B","active":true,"timeZone":"Asia/Kolkata"},"created":"2013-08-19T05:38:15.529+0000","updated":"2013-08-19T05:38:15.529+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12632534/comment/13743586","id":"13743586","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi Colin, Nice work on this issue.\n\n{code}\n List<IOException> ioExceptions = new LinkedList<IOException>();\n    if (!closed) {\n      try {\n        flushBuffer();       // flush from all upper layers\n  \n        if (currentPacket != null) { \n          waitAndQueueCurrentPacket();\n        }\n  \n        if (bytesCurBlock != 0) {\n          // send an empty packet to mark the end of the block\n          currentPacket = new Packet(0, 0, bytesCurBlock, \n              currentSeqno++, this.checksum.getChecksumSize());\n          currentPacket.lastPacketInBlock = true;\n          currentPacket.syncBlock = shouldSyncBlock;\n        }\n  \n        flushInternal();             // flush all data to Datanodes\n      } catch (IOException e) {\n        DFSClient.LOG.error(\"unable to flush buffers during file close \" +\n              \"for \" + src, e);\n        ioExceptions.add(e);\n      } finally {\n        closed = true;\n      }\n    }\n    // get last block before destroying the streamer\n    ExtendedBlock lastBlock = streamer.getBlock();\n    closeThreads(false);\n{code}\n\nI think above peice of code can be problematic in case of hflush failure + close call.\non sync failure, closeThreads called and streamer becomes null there. closed flag also will marked here.\nWhen user calls close, unconditionally we will try to closeThreads again and also we are trying to get lastblock from streamer.\n\nI think in pipeline failure case, if we don't  get last block(because of streamer closure in pipeline failure), force closing may not be a good choice as if we don't get last block correctly from client.\n\nMe and Vinay was thinking on this issue. How about simply informing NN about zombie situation for a file and change that client holder name to ZombieFile(intension is just make sure client is not renewing unintended files)? so, that ensure renewLease will not renew such files and closing will happen normally as NN does before viq hardlimit expiry. or renewLease call tell the ZombieFiles list which should be skipped from renewing from this client.\n\n\n\n ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-08-19T06:46:02.932+0000","updated":"2013-08-19T06:54:51.367+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12632534/comment/13744144","id":"13744144","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"body":"bq. In the latest patch, some unnecessary (Only space) file changes from Mapreduce, tools and Yarn project got added. I assume these added by mistake. Can you please remove them..\n\nI did that because I wanted a test run on all projects.  I will remove them for the next patch, since the other projects came up fine with this.\n\nbq. I think above peice of code can be problematic in case of hflush failure + close call.  on sync failure, closeThreads called and streamer becomes null there. closed flag also will marked here.\n\nThanks, that's a good catch.  I will check that streamer is not null in closeThreads.\n\nbq. How about simply informing NN about zombie situation for a file...\n\nIn a lot of cases when close fails, the NameNode is not reachable.  The behavior I implemented in the patch is designed to let long-running clients handle these transient problems gracefully.  Currently, uncloseable files get created, and a client restart is needed to get rid of them.  For example, you might have to restart your Flume daemon, your NFS gateway, etc.  The client wants to be able to tell when the file is actually closed in case it needs to reopen or move it.  Currently, there is no way to do this.  With this patch, it can do this by continuing to call close until it no longer throws an exception.\n\nIt seems like the case you are concerned about is the case where we fail to get the last block, because of a streamer failure.  This is already a problem, and I don't think this patch makes it worse (although it doesn't make it better, either).  If you have ideas for how to improve this case, maybe we should file a follow-on JIRA?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-08-19T19:54:08.115+0000","updated":"2013-08-19T19:54:08.115+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12632534/comment/13744704","id":"13744704","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinayrpet","name":"vinayrpet","key":"vinayrpet","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinayakumar B","active":true,"timeZone":"Asia/Kolkata"},"body":"{quote}In a lot of cases when close fails, the NameNode is not reachable. The behavior I implemented in the patch is designed to let long-running clients handle these transient problems gracefully. Currently, uncloseable files get created, and a client restart is needed to get rid of them. For example, you might have to restart your Flume daemon, your NFS gateway, etc. The client wants to be able to tell when the file is actually closed in case it needs to reopen or move it. Currently, there is no way to do this. With this patch, it can do this by continuing to call close until it no longer throws an exception.{quote}\nAnyway, for gracefully closing the file also namenode should be reachable even after file is considered as zombie. So Uma and me discussed about the following possible scenarios and we came to the conclusion mentioned in the above comment.\n\n In case of pipeline failure, all datanodes may not be complete and they will not report to namenode. So even graceful closure of the file may result in failure in such cases. Recovery of the lastblock in all those datanodes required, then only proper closure of the file can be done. One way to do this is to call {{recoverLease}}, but as todd pointed out, this also may lead to some other problem.\n\n As you told, for the long living clients, such as Flume, etc. recovery of these files will be done only in case of client restart. \n\nSo what we are trying to propose here is, \nAt client side, instead of trying for the graceful closure of the file in {{ZombieStreamManager}} or {{DFSOS.close()}} which may fail everytime,\n\n What we are trying propose here is as follows\n\n# In ZombieStreamManager, periodically check for the streams from {{DFSClient.filesBeingWritten}} which are marked as closed, but still not removed from this map. Obviously these will be Zombie streams. This period can be reasonable. \n# While handling the Zombie stream, ZombieStreamManager can report to NameNode via some new RPC as this stream is zombie. Then NN can check and re-assign the lease if the client is still having the lease on that file. Here target lease can be anything.. So that after hardlimit expiry, NN will automatically recover the file.\n# So once the reporting zombie stream to NN is success, then DFSOS can be removed from the {{DFSClient.filesBeingWritten}} map.\n\nSo this way, we can avoid more changes in the patch.\n\n{quote}It seems like the case you are concerned about is the case where we fail to get the last block, because of a streamer failure. This is already a problem, and I don't think this patch makes it worse (although it doesn't make it better, either){quote}\nI agree, but  before your patch, {{close()}} call was never allowed till we get NPE. So there was no issue.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinayrpet","name":"vinayrpet","key":"vinayrpet","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinayakumar B","active":true,"timeZone":"Asia/Kolkata"},"created":"2013-08-20T04:38:44.900+0000","updated":"2013-08-20T04:38:44.900+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12632534/comment/13745691","id":"13745691","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"body":"Vinay wrote:\nbq. While handling the Zombie stream, ZombieStreamManager can report to NameNode via some new RPC as this stream is zombie.\n\nA DFSOutputStream is a zombie for one of two reasons:\n1. The client can't contact the NameNode (perhaps because of a network problem)\n2. The client asked the NameNode to complete the file and it refused, because the NN does not (yet?) have a record that all of the file's blocks are present and complete.\n\nIn scenario #1, we can't tell the NameNode anything because we can't talk to it.\n\nIn scenario #2, the NameNode already knows everything it needs to know about the file.  It doesn't care whether we consider the file a zombie or not-- why would it?  All it knows is that the file isn't complete yet.\n\nThe big picture for this change is that we're trying to prevent a scenario where the DFSOutputStream is never closeable and leaks resources forever.  In order to do that, we sometimes have to make some unpleasant choices.  One of them is that if there was a data streamer failure, we complete the file anyway after a configurable time period (currently 2 minutes).  If you don't like this policy, you can just set the period so long that it corresponds to the lease recovery period.\n\nAs I said before, the current code doesn't do anything special in the case of a data streamer failure in DFSOutputStream#close.  It just throws up its hands and says \"oh well, guess that data's gone!\"  After the hard-lease period expires, we will complete the file anyway.  So it's exactly the same behavior with this patch as without it-- only the timeout is different.\n\nIt sounds like what you want to do is somehow \"try harder\" to fix the data streamer failure when you know the file is being closed.  This might be a good idea, but we should do it in a future JIRA.  This patch is big enough, and changes enough things already.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-08-21T01:23:28.540+0000","updated":"2013-08-21T01:23:28.540+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12632534/comment/13745716","id":"13745716","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"body":"This revision fixes the \"attempt to close null datastreamer\" problem that Vinay spotted","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-08-21T02:00:41.867+0000","updated":"2013-08-21T02:00:41.867+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12632534/comment/13745804","id":"13745804","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinayrpet","name":"vinayrpet","key":"vinayrpet","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinayakumar B","active":true,"timeZone":"Asia/Kolkata"},"body":"Please check this test\n{code:java}  @Test\n  public void testPipelineFailureWithZombie() throws Exception {\n    Configuration conf = new Configuration();\n    conf.setInt(DFSConfigKeys.DFS_BLOCK_SIZE_KEY, BLOCK_SIZE);\n    conf.setInt(DFSConfigKeys.DFS_CLIENT_CLOSE_TIMEOUT_MS, 5000);\n    MiniDFSCluster cluster = new MiniDFSCluster.Builder(conf).numDataNodes(1)\n        .build();\n    DistributedFileSystem fs = cluster.getFileSystem();\n    FSDataOutputStream fos = fs.create(new Path(\"/test\"));\n    boolean closed = false;\n    DataNodeProperties dn = null;\n    try {\n      fos.writeBytes(\"Hello\");\n      fos.hflush();\n      dn = cluster.stopDataNode(0);\n      fos.writeBytes(\"Hello again\");\n      fos.close();\n      closed=true;\n    }catch(Exception e){\n      // Ignore as of now\n    }\n    finally {\n      try {\n        fos.close();\n        closed=true;\n      } catch (IOException e) {\n        // Ignore as close will not be able to complete\n      }\n    }\n    if (!closed) {\n      // just to check the activity by ZombieStreamManager\n      Thread.sleep(10000);\n      cluster.restartDataNode(dn, true);\n      Thread.sleep(Long.MAX_VALUE);\n    }\n  }{code}\n\nIn this case, Since the streamer is not made null, then complete call is called with lastBlock, which has changed the state of the Block to COMMITTED and expects minReplication.\nSo this will never be satisfied, and also force complete and recoverLease also fails saying minReplication for COMMITTED blocks not met.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinayrpet","name":"vinayrpet","key":"vinayrpet","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinayakumar B","active":true,"timeZone":"Asia/Kolkata"},"created":"2013-08-21T05:49:30.709+0000","updated":"2013-08-21T05:49:30.709+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12632534/comment/13745848","id":"13745848","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"body":"Looks like this is good problem scenario pointed by Vinay here.\nClient should not call complete without knowing that he receives ack for last packet. Otherwise DN might be there with RBW state block and NN block state may become committed as client called to complete. Now states will become inconsistent and internalRecoverLease also will not be allowed because committedBlock did not get minreplicas reported by DN.\n\n{code}\n case COMMITTED:\n      // Close file if committed blocks are minimally replicated\n      if(penultimateBlockMinReplication &&\n          blockManager.checkMinReplication(lastBlock)) {\n        finalizeINodeFileUnderConstruction(src, pendingFile,\n            iip.getLatestSnapshot(), false);\n        NameNode.stateChangeLog.warn(\"BLOCK*\"\n          + \" internalReleaseLease: Committed blocks are minimally replicated,\"\n          + \" lease removed, file closed.\");\n        return true;  // closed!\n      }\n      // Cannot close file right now, since some blocks \n      // are not yet minimally replicated.\n      // This may potentially cause infinite loop in lease recovery\n      // if there are no valid replicas on data-nodes.\n      String message = \"DIR* NameSystem.internalReleaseLease: \" +\n          \"Failed to release lease for file \" + src +\n          \". Committed blocks are waiting to be minimally replicated.\" +\n          \" Try again later.\";\n      NameNode.stateChangeLog.warn(message);\n{code}\n\nideally block is committed means, DN must have finalyzed also. SO, DN will report finalysed block state in that case. Here, DN has RBW state only as it was failed in between. Due to that failure, it got added to zombie and it will try to complete the file without knowing whether he receives really last packet ack or not.\n\nIn normal recovery case, block will be finalysed by normal recovery flow as below:\n\n{code}\n   case UNDER_CONSTRUCTION:\n   case UNDER_RECOVERY:\n      final BlockInfoUnderConstruction uc = (BlockInfoUnderConstruction)lastBlock;\n      // setup the last block locations from the blockManager if not known\n      if (uc.getNumExpectedLocations() == 0) {\n        uc.setExpectedLocations(blockManager.getNodes(lastBlock));\n      }\n      // start recovery of the last block for this file\n      long blockRecoveryId = nextGenerationStamp(isLegacyBlock(uc));\n      lease = reassignLease(lease, src, recoveryLeaseHolder, pendingFile);\n      uc.initializeBlockRecovery(blockRecoveryId);\n      leaseManager.renewLease(lease);\n      // Cannot close file right now, since the last block requires recovery.\n      // This may potentially cause infinite loop in lease recovery\n      // if there are no valid replicas on data-nodes.\n      NameNode.stateChangeLog.warn(\n                \"DIR* NameSystem.internalReleaseLease: \" +\n                \"File \" + src + \" has not been closed.\" +\n               \" Lease recovery is in progress. \" +\n                \"RecoveryId = \" + blockRecoveryId + \" for block \" + lastBlock);\n      break;\n    }\n{code}\nthis will make DN blocks to finalyze if they are in RBW state. But here if we change the state already to committed, then recovery flow will be diverted and no one will finalyze the block at DN. I am affraid that, this changes may cause the problems like this. So, better to do recovery with NN only I think by just just informing the zombie files to NN when NN available. Once we inform to NN successfully about zombie file successfully then we can remove such file entries from his list. untill that try informing to NN about zombie files. This may be better choice which may avoid the risks like above scenarios.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-08-21T07:41:07.762+0000","updated":"2013-08-21T07:52:05.178+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12632534/comment/13745868","id":"13745868","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinayrpet","name":"vinayrpet","key":"vinayrpet","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinayakumar B","active":true,"timeZone":"Asia/Kolkata"},"body":"{quote}A DFSOutputStream is a zombie for one of two reasons:\n1. The client can't contact the NameNode (perhaps because of a network problem)\n2. The client asked the NameNode to complete the file and it refused, because the NN does not (yet?) have a record that all of the file's blocks are present and complete.{quote}\nYou cannot ignore DataStreamer failure as not zombie. Thats the potential one and can happen frequently too. As already described in the above test, trying to close file, in case of DataStreamer failure, could lead to potential problem. Force complete also fails though.\n\n{quote}As I said before, the current code doesn't do anything special in the case of a data streamer failure in DFSOutputStream#close. It just throws up its hands and says \"oh well, guess that data's gone!\" After the hard-lease period expires, we will complete the file anyway. So it's exactly the same behavior with this patch as without it-- only the timeout is different.{quote}\nIn case of DataStreamer failure due to pipeline failure, \nWithout patch, complete() call wont be called, so no changes of block state at NN side, hence recovery of the file will succeed. *No data will be lost*\nWith patch, complete() call marks the block state to COMMITTED, which will block recovery/force complete until block is reported by DN, which will not. *So data lost*\n\n{quote} This might be a good idea, but we should do it in a future JIRA. This patch is big enough, and changes enough things already.{quote}\nYes, thats correct. To avoid too many changes in this patch itself, we suggesting to just try to report zombie to NN instead of force complete. This covers all cases you mentioned.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinayrpet","name":"vinayrpet","key":"vinayrpet","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinayakumar B","active":true,"timeZone":"Asia/Kolkata"},"created":"2013-08-21T08:28:36.843+0000","updated":"2013-08-21T08:28:36.843+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12632534/comment/13746907","id":"13746907","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks for thinking of this.  Let me see if I can summarize the issue.  If there is a streamer failure, and the DFSClient calls {{completeFile}}, the last block in the file will transition from state {{UNDER_CONSTRUCTION}} to state {{COMMITTED}}.  This, in turn, will prevent later calls made by the client to {{recoverLease}} from working, since we only do block recovery on blocks in state {{UNDER_CONSTRUCTION}} or {{UNDER_RECOVERY}}.  The {{ZombieStreamCloser}} will not be able to run block recovery either, for the same reason.  Is that a fair summary?\n\nReally, the question is what is the right behavior in {{DFSOutputStream#close}} after a streamer failure?  Calling {{completeFile(force=false)}} seems wrong.  We need to perform block recovery in this scenario, as you said.  Calling {{completeFile(force=true)}} will start block recovery (it calls FSNamesystem#internalReleaseLease}}.  That seems like the right thing to do.\n\nIt might make sense to create a new RPC with a different name than {[completeFile}}, to avoid confusion with the other function of {{completeFile}}.  But fundamentally, starting block recovery is what we need to do here, and we might as well do it from {{DFSOutputStream#close}}.  I think this will solve the problem.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-08-21T22:05:36.510+0000","updated":"2013-08-21T22:05:36.510+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12632534/comment/13747288","id":"13747288","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"body":"{quote}\nThanks for thinking of this. Let me see if I can summarize the issue. If there is a streamer failure, and the DFSClient calls completeFile, the last block in the file will transition from state UNDER_CONSTRUCTION to state COMMITTED. This, in turn, will prevent later calls made by the client to recoverLease from working, since we only do block recovery on blocks in state UNDER_CONSTRUCTION or UNDER_RECOVERY. The ZombieStreamCloser will not be able to run block recovery either, for the same reason. Is that a fair summary?\n{quote}\nYes.\n\n{quote}\nReally, the question is what is the right behavior in DFSOutputStream#close after a streamer failure? Calling completeFile(force=false) seems wrong. We need to perform block recovery in this scenario, as you said. Calling completeFile(force=true) will start block recovery (it calls FSNamesystem#internalReleaseLease}}. That seems like the right thing to do.\n{quote}\nWhere we are not sure that clinet received last packet ack,  we should not call completeFile. here complete file doing commit block thinking clinet already got ack for last packet that means DN also would have finalized and for sure it will report in some time. So, in such cases we should not go with completeFile and should do recover file lease  some how that should initiate finalization at DN also. Please not that we tweak here for falling into that case what Todd pointed earlier. May be better thing to check holder name. if file holder is current holder, then only we should do recover file lease with new API.\n\n{quote}\nIt might make sense to create a new RPC with a different name than {[completeFile}}, to avoid confusion with the other function of completeFile. But fundamentally, starting block recovery is what we need to do here, and we might as well do it from DFSOutputStream#close. I think this will solve the problem.\n{quote}\n\nI think it may solve, But IMO, more simpler thing would be to just reassign lease holder at NN with some name for this Zombie streams. In this case, NN will take care of recovering them correctly. current clients renewLease will not renew the lease for this files. We can think once on this option for more simplicity and less risk I feel.\nZombieStreameManger should just ensure it has informed successfully to NN about Zombie stream instead of calling complete and others things can be same. We can think more if any other impacts with this.\n\nCurrently I think(guess, but need to look once on this) if same holder is trying to recoverLease from client, it may not allow as same client is trying to recover where same client was the holder for that file. If yes, we need to allow this with above proposal by some indication.\n\n\n\n\n\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-08-22T06:30:06.335+0000","updated":"2013-08-22T06:30:06.335+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12632534/comment/13749660","id":"13749660","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12599081/HDFS-4504.016.patch\n  against trunk revision .\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:green}+1 tests included{color}.  The patch appears to include 12 new or modified test files.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:red}-1 core tests{color}.  The following test timeouts occurred in hadoop-hdfs-project/hadoop-hdfs:\n\norg.apache.hadoop.hdfs.TestFileAppend3\norg.apache.hadoop.hdfs.TestHFlush\n\n    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/4882//testReport/\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/4882//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2013-08-25T14:56:03.583+0000","updated":"2013-08-25T14:56:03.583+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12632534/comment/13912360","id":"13912360","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=azuryy","name":"azuryy","key":"azuryy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Fengdong Yu","active":true,"timeZone":"Etc/UTC"},"body":"[~cmccabe] this was opened for a long time. please go back. \n\ncan you also add these new configurable items to the hdfs-default.xml? Thanks.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=azuryy","name":"azuryy","key":"azuryy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Fengdong Yu","active":true,"timeZone":"Etc/UTC"},"created":"2014-02-26T01:09:03.818+0000","updated":"2014-02-26T01:09:03.818+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12632534/comment/13912475","id":"13912475","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12599081/HDFS-4504.016.patch\n  against trunk revision .\n\n    {color:red}-1 patch{color}.  The patch command could not apply the patch.\n\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/6241//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2014-02-26T03:36:16.913+0000","updated":"2014-02-26T03:36:16.913+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12632534/comment/14056945","id":"14056945","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12599081/HDFS-4504.016.patch\n  against trunk revision .\n\n    {color:red}-1 patch{color}.  The patch command could not apply the patch.\n\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/7313//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2014-07-10T00:21:51.871+0000","updated":"2014-07-10T00:21:51.871+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12632534/comment/14524859","id":"14524859","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"\\\\\n\\\\\n| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:red}-1{color} | patch |   0m  0s | The patch command could not apply the patch during dryrun. |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Patch URL | http://issues.apache.org/jira/secure/attachment/12599081/HDFS-4504.016.patch |\n| Optional Tests | javadoc javac unit findbugs checkstyle |\n| git revision | trunk / f1a152c |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/10633/console |\n\n\nThis message was automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2015-05-02T04:43:42.894+0000","updated":"2015-05-02T04:43:42.894+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12632534/comment/14524893","id":"14524893","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"\\\\\n\\\\\n| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:red}-1{color} | patch |   0m  0s | The patch command could not apply the patch during dryrun. |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Patch URL | http://issues.apache.org/jira/secure/attachment/12599081/HDFS-4504.016.patch |\n| Optional Tests | javadoc javac unit findbugs checkstyle |\n| git revision | trunk / f1a152c |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/10648/console |\n\n\nThis message was automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2015-05-02T04:50:48.366+0000","updated":"2015-05-02T04:50:48.366+0000"}],"maxResults":57,"total":57,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-4504/votes","votes":1,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i1i0pz:"}}