{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12730649","self":"https://issues.apache.org/jira/rest/api/2/issue/12730649","key":"HDFS-6776","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12327181","id":"12327181","description":"2.6.0 release","name":"2.6.0","archived":false,"released":true,"releaseDate":"2014-11-18"}],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2014-07-29T23:44:08.237+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Fri Sep 12 15:51:00 UTC 2014","customfield_12310420":"408722","customfield_12312320":null,"customfield_12310222":"10002_*:*_1_*:*_3328015267_*|*_1_*:*_1_*:*_322741956_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2014-09-10T05:26:31.378+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-6776/watchers","watchCount":19,"isWatching":false},"created":"2014-07-29T23:20:34.219+0000","customfield_12310192":null,"customfield_12310191":[{"self":"https://issues.apache.org/jira/rest/api/2/customFieldOption/10343","value":"Reviewed","id":"10343"}],"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"20.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12325255","id":"12325255","description":"2.3.0 release","name":"2.3.0","archived":false,"released":true,"releaseDate":"2014-02-20"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12326264","id":"12326264","description":"2.5.0 release","name":"2.5.0","archived":false,"released":true,"releaseDate":"2014-08-11"}],"issuelinks":[],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2014-12-01T03:10:42.952+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[],"timeoriginalestimate":null,"description":"Issuing distcp command at the secure cluster side, trying to copy stuff from insecure cluster to secure cluster, and see the following problem:\n{code}\nhadoopuser@yjc5u-1 ~]$ hadoop distcp webhdfs://<insure-cluster>:<port>/tmp hdfs://<sure-cluster>:8020/tmp/tmptgt\n14/07/30 20:06:19 INFO tools.DistCp: Input Options: DistCpOptions{atomicCommit=false, syncFolder=false, deleteMissing=false, ignoreFailures=false, maxMaps=20, sslConfigurationFile='null', copyStrategy='uniformsize', sourceFileListing=null, sourcePaths=[webhdfs://<insecure-cluster>:<port>/tmp], targetPath=hdfs://<secure-cluster>:8020/tmp/tmptgt, targetPathExists=true}\n14/07/30 20:06:19 INFO client.RMProxy: Connecting to ResourceManager at <secure-clister>:8032\n14/07/30 20:06:20 WARN ssl.FileBasedKeyStoresFactory: The property 'ssl.client.truststore.location' has not been set, no TrustStore will be loaded\n14/07/30 20:06:20 WARN security.UserGroupInformation: PriviledgedActionException as:hadoopuser@xyz.COM (auth:KERBEROS) cause:java.io.IOException: Failed to get the token for hadoopuser, user=hadoopuser\n14/07/30 20:06:20 WARN security.UserGroupInformation: PriviledgedActionException as:hadoopuser@xyz.COM (auth:KERBEROS) cause:java.io.IOException: Failed to get the token for hadoopuser, user=hadoopuser\n14/07/30 20:06:20 ERROR tools.DistCp: Exception encountered \njava.io.IOException: Failed to get the token for hadoopuser, user=hadoopuser\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.lang.reflect.Constructor.newInstance(Constructor.java:526)\n\tat org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:106)\n\tat org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:95)\n\tat org.apache.hadoop.hdfs.web.WebHdfsFileSystem.toIOException(WebHdfsFileSystem.java:365)\n\tat org.apache.hadoop.hdfs.web.WebHdfsFileSystem.access$600(WebHdfsFileSystem.java:84)\n\tat org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.shouldRetry(WebHdfsFileSystem.java:618)\n\tat org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.runWithRetry(WebHdfsFileSystem.java:584)\n\tat org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.access$100(WebHdfsFileSystem.java:438)\n\tat org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner$1.run(WebHdfsFileSystem.java:466)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:415)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)\n\tat org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.run(WebHdfsFileSystem.java:462)\n\tat org.apache.hadoop.hdfs.web.WebHdfsFileSystem.getDelegationToken(WebHdfsFileSystem.java:1132)\n\tat org.apache.hadoop.hdfs.web.WebHdfsFileSystem.getDelegationToken(WebHdfsFileSystem.java:218)\n\tat org.apache.hadoop.hdfs.web.WebHdfsFileSystem.getAuthParameters(WebHdfsFileSystem.java:403)\n\tat org.apache.hadoop.hdfs.web.WebHdfsFileSystem.toUrl(WebHdfsFileSystem.java:424)\n\tat org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractFsPathRunner.getUrl(WebHdfsFileSystem.java:640)\n\tat org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.runWithRetry(WebHdfsFileSystem.java:565)\n\tat org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.access$100(WebHdfsFileSystem.java:438)\n\tat org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner$1.run(WebHdfsFileSystem.java:466)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:415)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)\n\tat org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.run(WebHdfsFileSystem.java:462)\n\tat org.apache.hadoop.hdfs.web.WebHdfsFileSystem.getHdfsFileStatus(WebHdfsFileSystem.java:781)\n\tat org.apache.hadoop.hdfs.web.WebHdfsFileSystem.getFileStatus(WebHdfsFileSystem.java:796)\n\tat org.apache.hadoop.fs.Globber.getFileStatus(Globber.java:57)\n\tat org.apache.hadoop.fs.Globber.glob(Globber.java:248)\n\tat org.apache.hadoop.fs.FileSystem.globStatus(FileSystem.java:1623)\n\tat org.apache.hadoop.tools.GlobbedCopyListing.doBuildListing(GlobbedCopyListing.java:77)\n\tat org.apache.hadoop.tools.CopyListing.buildListing(CopyListing.java:81)\n\tat org.apache.hadoop.tools.DistCp.createInputFileListing(DistCp.java:342)\n\tat org.apache.hadoop.tools.DistCp.execute(DistCp.java:154)\n\tat org.apache.hadoop.tools.DistCp.run(DistCp.java:121)\n\tat org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)\n\tat org.apache.hadoop.tools.DistCp.main(DistCp.java:390)\nCaused by: org.apache.hadoop.ipc.RemoteException(java.io.IOException): Failed to get the token for hadoopuser, user=hadoopuser\n\tat org.apache.hadoop.hdfs.web.JsonUtil.toRemoteException(JsonUtil.java:159)\n\tat org.apache.hadoop.hdfs.web.WebHdfsFileSystem.validateResponse(WebHdfsFileSystem.java:334)\n\tat org.apache.hadoop.hdfs.web.WebHdfsFileSystem.access$200(WebHdfsFileSystem.java:84)\n\tat org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.runWithRetry(WebHdfsFileSystem.java:570)\n\t... 30 more\n[hadoopuser@yjc5u-1 ~]$ \n{code}\n\n","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12664181","id":"12664181","filename":"dummy-token-proxy.js","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wheat9","name":"wheat9","key":"wheat9","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Haohui Mai","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-25T18:09:12.469+0000","size":1729,"mimeType":"text/javascript","content":"https://issues.apache.org/jira/secure/attachment/12664181/dummy-token-proxy.js"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12659481","id":"12659481","filename":"HDFS-6776.001.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-02T16:53:56.922+0000","size":3234,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12659481/HDFS-6776.001.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12659511","id":"12659511","filename":"HDFS-6776.002.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-02T23:25:54.405+0000","size":4864,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12659511/HDFS-6776.002.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12659555","id":"12659555","filename":"HDFS-6776.003.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-03T17:12:30.290+0000","size":4968,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12659555/HDFS-6776.003.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12662086","id":"12662086","filename":"HDFS-6776.004.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-15T15:47:57.129+0000","size":3755,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12662086/HDFS-6776.004.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12661931","id":"12661931","filename":"HDFS-6776.004.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-14T23:25:50.783+0000","size":3755,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12661931/HDFS-6776.004.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12662349","id":"12662349","filename":"HDFS-6776.005.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-17T02:49:06.481+0000","size":3766,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12662349/HDFS-6776.005.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12662514","id":"12662514","filename":"HDFS-6776.006.NullToken.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-18T16:57:55.469+0000","size":4232,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12662514/HDFS-6776.006.NullToken.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12662355","id":"12662355","filename":"HDFS-6776.006.NullToken.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-17T07:01:30.648+0000","size":4232,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12662355/HDFS-6776.006.NullToken.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12662677","id":"12662677","filename":"HDFS-6776.007.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-19T02:44:21.843+0000","size":5180,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12662677/HDFS-6776.007.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12662862","id":"12662862","filename":"HDFS-6776.008.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-19T21:47:56.739+0000","size":5650,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12662862/HDFS-6776.008.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12664395","id":"12664395","filename":"HDFS-6776.009.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-26T14:30:33.254+0000","size":7295,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12664395/HDFS-6776.009.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12664836","id":"12664836","filename":"HDFS-6776.010.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-28T05:58:27.233+0000","size":7893,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12664836/HDFS-6776.010.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12666403","id":"12666403","filename":"HDFS-6776.011.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-09-04T02:53:03.361+0000","size":11300,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12666403/HDFS-6776.011.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12667216","id":"12667216","filename":"HDFS-6776.012.nomsgparsing.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-09-08T19:27:15.029+0000","size":9757,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12667216/HDFS-6776.012.nomsgparsing.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12667262","id":"12667262","filename":"HDFS-6776.013.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wheat9","name":"wheat9","key":"wheat9","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Haohui Mai","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-09-08T22:33:00.979+0000","size":4114,"content":"https://issues.apache.org/jira/secure/attachment/12667262/HDFS-6776.013.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12667308","id":"12667308","filename":"HDFS-6776.014.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wheat9","name":"wheat9","key":"wheat9","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Haohui Mai","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-09-09T00:54:26.136+0000","size":6427,"content":"https://issues.apache.org/jira/secure/attachment/12667308/HDFS-6776.014.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12667335","id":"12667335","filename":"HDFS-6776.015.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-09-09T03:26:08.352+0000","size":6768,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12667335/HDFS-6776.015.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12667422","id":"12667422","filename":"HDFS-6776.016.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-09-09T14:34:19.487+0000","size":6688,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12667422/HDFS-6776.016.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12667435","id":"12667435","filename":"HDFS-6776.017.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-09-09T16:03:38.279+0000","size":7118,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12667435/HDFS-6776.017.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"408721","customfield_12312823":null,"summary":"Using distcp to copy data between insecure and secure cluster via webdhfs doesn't work","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14078627","id":"14078627","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=aw","name":"aw","key":"aw","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=aw&avatarId=23681","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=aw&avatarId=23681","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=aw&avatarId=23681","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=aw&avatarId=23681"},"displayName":"Allen Wittenauer","active":true,"timeZone":"America/Tijuana"},"body":"Historically, that's intentional.\n\nInstead, the expected movement is to pull data to the secure cluster from the insecure cluster.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=aw","name":"aw","key":"aw","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=aw&avatarId=23681","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=aw&avatarId=23681","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=aw&avatarId=23681","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=aw&avatarId=23681"},"displayName":"Allen Wittenauer","active":true,"timeZone":"America/Tijuana"},"created":"2014-07-29T23:44:08.237+0000","updated":"2014-07-29T23:44:08.237+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14078637","id":"14078637","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks a lot [~aw]! Would you please share some more information about the recommended way to pull data from insecure cluster to the secure cluster without using distcp? thanks.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-07-29T23:50:40.689+0000","updated":"2014-07-29T23:50:40.689+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14078677","id":"14078677","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=aw","name":"aw","key":"aw","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=aw&avatarId=23681","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=aw&avatarId=23681","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=aw&avatarId=23681","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=aw&avatarId=23681"},"displayName":"Allen Wittenauer","active":true,"timeZone":"America/Tijuana"},"body":"You should still be able to use distcp, you just have to run it on the secure cluster with the source being the insecure cluster. (and if they are incompatible versions, use WebHDFS!) If it doesn't work, that's a regression (HDFS-3905 and related).","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=aw","name":"aw","key":"aw","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=aw&avatarId=23681","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=aw&avatarId=23681","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=aw&avatarId=23681","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=aw&avatarId=23681"},"displayName":"Allen Wittenauer","active":true,"timeZone":"America/Tijuana"},"created":"2014-07-30T00:19:19.612+0000","updated":"2014-07-30T00:19:19.612+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14078719","id":"14078719","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks Allen, sorry I did not describe it clear earlier, what you described is exactly what I was trying to report here.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-07-30T00:53:52.491+0000","updated":"2014-07-30T00:53:52.491+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14080393","id":"14080393","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tthompso","name":"tthompso","key":"tthompso","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tthompso&avatarId=21659","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tthompso&avatarId=21659","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tthompso&avatarId=21659","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tthompso&avatarId=21659"},"displayName":"Travis Thompson","active":true,"timeZone":"America/Los_Angeles"},"body":"Also seeing this in 2.3.0 so it looks like it's been broken for a while!\n\nWith hdfs://\n{noformat}\n$ hadoop distcp -i /tmp/motd hdfs://insecure-namenode:9000/tmp/motd\n14/07/30 23:45:20 INFO tools.DistCp: Input Options: DistCpOptions{atomicCommit=false, syncFolder=false, deleteMissing=false, ignoreFailures=true, maxMaps=20, sslConfigurationFile='null', copyStrategy='uniformsize', sourceFileListing=null, sourcePaths=[/tmp/motd], targetPath=hdfs://insecure-namenode:9000/tmp/motd}\n14/07/30 23:45:21 INFO client.RMProxy: Connecting to ResourceManager at secure-resourcemanager/xxx.xxx.xxx.xxx:8032\n14/07/30 23:45:22 ERROR tools.DistCp: Exception encountered \njava.io.IOException: Failed on local exception: java.io.IOException: Server asks us to fall back to SIMPLE auth, but this client is configured to only allow secure connections.; Host Details : local host is: \"secure-gateway/xxx.xxx.xxx.xxx\"; destination host is: \"insecure-namenode\":9000; \n        at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)\n        at org.apache.hadoop.ipc.Client.call(Client.java:1410)\n        at org.apache.hadoop.ipc.Client.call(Client.java:1359)\n        at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)\n        at com.sun.proxy.$Proxy11.getFileInfo(Unknown Source)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:606)\n        at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:186)\n        at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)\n        at com.sun.proxy.$Proxy11.getFileInfo(Unknown Source)\n        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getFileInfo(ClientNamenodeProtocolTranslatorPB.java:671)\n        at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:1746)\n        at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:1112)\n        at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:1108)\n        at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)\n        at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1108)\n        at org.apache.hadoop.fs.FileSystem.isFile(FileSystem.java:1425)\n        at org.apache.hadoop.tools.SimpleCopyListing.validatePaths(SimpleCopyListing.java:69)\n        at org.apache.hadoop.tools.CopyListing.buildListing(CopyListing.java:79)\n        at org.apache.hadoop.tools.GlobbedCopyListing.doBuildListing(GlobbedCopyListing.java:90)\n        at org.apache.hadoop.tools.CopyListing.buildListing(CopyListing.java:80)\n        at org.apache.hadoop.tools.DistCp.createInputFileListing(DistCp.java:327)\n        at org.apache.hadoop.tools.DistCp.execute(DistCp.java:151)\n        at org.apache.hadoop.tools.DistCp.run(DistCp.java:118)\n        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)\n        at org.apache.hadoop.tools.DistCp.main(DistCp.java:375)\nCaused by: java.io.IOException: Server asks us to fall back to SIMPLE auth, but this client is configured to only allow secure connections.\n        at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:734)\n        at org.apache.hadoop.ipc.Client$Connection.access$2700(Client.java:367)\n        at org.apache.hadoop.ipc.Client.getConnection(Client.java:1458)\n        at org.apache.hadoop.ipc.Client.call(Client.java:1377)\n        ... 26 more\n{noformat}\n\nWith webhdfs://\n{noformat}\n$ hadoop distcp -i /tmp/motd webhdfs://insecure-namenode:50070/tmp/motd\n14/07/31 00:27:42 INFO tools.DistCp: Input Options: DistCpOptions{atomicCommit=false, syncFolder=false, deleteMissing=false, ignoreFailures=true, maxMaps=20, sslConfigurationFile='null', copyStrategy='uniformsize', sourceFileListing=null, sourcePaths=[/tmp/motd], targetPath=webhdfs://insecure-namenode:50070/tmp/motd}\n14/07/31 00:27:42 INFO client.RMProxy: Connecting to ResourceManager at secure-resourcemanager/xxx.xxx.xxx.xxx:8032\n14/07/31 00:27:44 ERROR tools.DistCp: Exception encountered \njava.io.IOException: Failed to get the token for tthompso, user=tthompso\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.lang.reflect.Constructor.newInstance(Constructor.java:526)\n\tat org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:106)\n\tat org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:95)\n\tat org.apache.hadoop.hdfs.web.WebHdfsFileSystem.toIOException(WebHdfsFileSystem.java:341)\n\tat org.apache.hadoop.hdfs.web.WebHdfsFileSystem.access$600(WebHdfsFileSystem.java:105)\n\tat org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.shouldRetry(WebHdfsFileSystem.java:573)\n\tat org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.run(WebHdfsFileSystem.java:539)\n\tat org.apache.hadoop.hdfs.web.WebHdfsFileSystem.run(WebHdfsFileSystem.java:424)\n\tat org.apache.hadoop.hdfs.web.WebHdfsFileSystem.getDelegationToken(WebHdfsFileSystem.java:953)\n\tat org.apache.hadoop.hdfs.web.TokenAspect.ensureTokenInitialized(TokenAspect.java:143)\n\tat org.apache.hadoop.hdfs.web.WebHdfsFileSystem.getDelegationToken(WebHdfsFileSystem.java:227)\n\tat org.apache.hadoop.hdfs.web.WebHdfsFileSystem.getAuthParameters(WebHdfsFileSystem.java:381)\n\tat org.apache.hadoop.hdfs.web.WebHdfsFileSystem.toUrl(WebHdfsFileSystem.java:402)\n\tat org.apache.hadoop.hdfs.web.WebHdfsFileSystem$FsPathRunner.getUrl(WebHdfsFileSystem.java:652)\n\tat org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.init(WebHdfsFileSystem.java:485)\n\tat org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.run(WebHdfsFileSystem.java:531)\n\tat org.apache.hadoop.hdfs.web.WebHdfsFileSystem.run(WebHdfsFileSystem.java:424)\n\tat org.apache.hadoop.hdfs.web.WebHdfsFileSystem.getHdfsFileStatus(WebHdfsFileSystem.java:678)\n\tat org.apache.hadoop.hdfs.web.WebHdfsFileSystem.getFileStatus(WebHdfsFileSystem.java:689)\n\tat org.apache.hadoop.fs.FileSystem.isFile(FileSystem.java:1425)\n\tat org.apache.hadoop.tools.SimpleCopyListing.validatePaths(SimpleCopyListing.java:69)\n\tat org.apache.hadoop.tools.CopyListing.buildListing(CopyListing.java:79)\n\tat org.apache.hadoop.tools.GlobbedCopyListing.doBuildListing(GlobbedCopyListing.java:90)\n\tat org.apache.hadoop.tools.CopyListing.buildListing(CopyListing.java:80)\n\tat org.apache.hadoop.tools.DistCp.createInputFileListing(DistCp.java:327)\n\tat org.apache.hadoop.tools.DistCp.execute(DistCp.java:151)\n\tat org.apache.hadoop.tools.DistCp.run(DistCp.java:118)\n\tat org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)\n\tat org.apache.hadoop.tools.DistCp.main(DistCp.java:375)\nCaused by: org.apache.hadoop.ipc.RemoteException(java.io.IOException): Failed to get the token for tthompso, user=tthompso\n\tat org.apache.hadoop.hdfs.web.JsonUtil.toRemoteException(JsonUtil.java:157)\n\tat org.apache.hadoop.hdfs.web.WebHdfsFileSystem.validateResponse(WebHdfsFileSystem.java:318)\n\tat org.apache.hadoop.hdfs.web.WebHdfsFileSystem.access$700(WebHdfsFileSystem.java:105)\n\tat org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.getResponse(WebHdfsFileSystem.java:628)\n\tat org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.run(WebHdfsFileSystem.java:535)\n\t... 22 more\n{noformat}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tthompso","name":"tthompso","key":"tthompso","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tthompso&avatarId=21659","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tthompso&avatarId=21659","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tthompso&avatarId=21659","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tthompso&avatarId=21659"},"displayName":"Travis Thompson","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-07-31T02:02:38.855+0000","updated":"2014-07-31T02:02:38.855+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14080404","id":"14080404","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi [~tthompso]\nThanks for your input. The scenarios you described seem to copy from secure to insecure cluster, which is reported as HADOOP-10016 etc, that are still open issues. What I'm trying to capture is when the copy src is insecure cluster and the copy destination is secure cluster. Thanks.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-07-31T02:34:16.560+0000","updated":"2014-07-31T02:34:16.560+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14080458","id":"14080458","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tthompso","name":"tthompso","key":"tthompso","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tthompso&avatarId=21659","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tthompso&avatarId=21659","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tthompso&avatarId=21659","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tthompso&avatarId=21659"},"displayName":"Travis Thompson","active":true,"timeZone":"America/Los_Angeles"},"body":"Yes but HADOOP-10016 is H1 (secure) -> H2 (insecure) (which on that note, I've also tried and it doesn't work).  This shows that secure talking to insecure is flat out broken, source or destination.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tthompso","name":"tthompso","key":"tthompso","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tthompso&avatarId=21659","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tthompso&avatarId=21659","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tthompso&avatarId=21659","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tthompso&avatarId=21659"},"displayName":"Travis Thompson","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-07-31T04:02:19.710+0000","updated":"2014-07-31T04:02:19.710+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14080479","id":"14080479","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Yes, indeed HADOOP-10016 is still open and both directions are broken. Thanks for trying.\n\n\n\n \n\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-07-31T04:35:49.971+0000","updated":"2014-07-31T04:35:49.971+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14083628","id":"14083628","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Submit patch 001 for webhdfs in trunk. Will add hftp fix for branch-2 later. \n\nTested with real clusters to see that it fails before the fix and works after the fix. Thanks for reviewing.\n\n\n ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-02T16:59:36.168+0000","updated":"2014-08-02T16:59:36.168+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14083692","id":"14083692","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12659481/HDFS-6776.001.patch\n  against trunk revision .\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.\n                        Please justify why no new tests are needed for this patch.\n                        Also please list what manual steps were performed to verify this patch.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:red}-1 findbugs{color}.  The patch appears to introduce 1 new Findbugs (version 2.0.3) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:\n\n                  org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts\n\n    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/7540//testReport/\nFindbugs warnings: https://builds.apache.org/job/PreCommit-HDFS-Build/7540//artifact/trunk/patchprocess/newPatchFindbugsWarningshadoop-hdfs.html\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/7540//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2014-08-02T20:04:14.147+0000","updated":"2014-08-02T20:04:14.147+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14083790","id":"14083790","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Version 002 to address test failure.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-02T23:25:54.410+0000","updated":"2014-08-02T23:25:54.410+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14083846","id":"14083846","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12659511/HDFS-6776.002.patch\n  against trunk revision .\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:red}-1 findbugs{color}.  The patch appears to introduce 1 new Findbugs (version 2.0.3) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:\n\n                  org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover\n\n    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/7542//testReport/\nFindbugs warnings: https://builds.apache.org/job/PreCommit-HDFS-Build/7542//artifact/trunk/patchprocess/newPatchFindbugsWarningshadoop-hdfs.html\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/7542//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2014-08-03T02:22:26.856+0000","updated":"2014-08-03T02:22:26.856+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14084035","id":"14084035","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Version 003 to address findbugs issue.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-03T17:12:30.296+0000","updated":"2014-08-03T17:12:30.296+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14084122","id":"14084122","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12659555/HDFS-6776.003.patch\n  against trunk revision .\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:\n\n                  org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover\n\n    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/7548//testReport/\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/7548//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2014-08-03T20:12:07.857+0000","updated":"2014-08-03T20:12:07.857+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14085232","id":"14085232","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"The posted patch also supports distcp from secure cluster to insecure cluster (as long as both clusters are hadoop 2, and issue the command from secure cluster side). \n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-04T20:26:39.608+0000","updated":"2014-08-04T20:26:39.608+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14089247","id":"14089247","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=daryn","name":"daryn","key":"daryn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Daryn Sharp","active":true,"timeZone":"America/Chicago"},"body":"Sorry, but this patch is completely wrong.\n# If security is enabled and an {{IOException}} happens for any reason - transient or legit - while acquiring a token, the client will continue to \"work\" because of spnego but if a job is submitted the tasks will all fail due to no token.\n# Webhdfs should be using the same insecure fallback policy as RPC.\n# Insecure RPC services return null if a token is requested.  Like DFSClient, the webhdfs client should be able to handle that condition instead of throwing the exception you see.\n# Issuing a malformed OPEN call is not ok...\n# Although irrelevant in like of the above, connection.connect() isn't doing what you think.  It proved the client could open a connection and send the request.  It doesn't prove the server allowed/authenticated the request.  The you read the response, the server should have been angry you issued an invalid open.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=daryn","name":"daryn","key":"daryn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Daryn Sharp","active":true,"timeZone":"America/Chicago"},"created":"2014-08-07T14:17:36.070+0000","updated":"2014-08-07T14:17:36.070+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14089372","id":"14089372","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"HI [~daryn], thank you so much for the very helpful comments. I will look into addressing them in next revision.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-07T15:59:04.445+0000","updated":"2014-08-07T15:59:04.445+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14097907","id":"14097907","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi [~daryn],\n\nThanks a lot for your earlier review and sorry for the delaying in addressing them, got some other critical issue to handle.\n\nI just uploaded a new revision. This version tries to catch the null token case in a different way. I wish there is a NullTokenException type, right now I check the message content to see if the token is null.  If necessary, I can possibly introduce a new exception type, however, that means incompatibility.\n\nWould you please help taking another look to see if this fix makes sense? Thanks.\n\n\n\n\n\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-14T23:31:36.842+0000","updated":"2014-08-14T23:31:36.842+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14098126","id":"14098126","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12661931/HDFS-6776.004.patch\n  against trunk revision .\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.\n                        Please justify why no new tests are needed for this patch.\n                        Also please list what manual steps were performed to verify this patch.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs:\n\n                  org.apache.hadoop.security.token.delegation.web.TestWebDelegationToken\n                  org.apache.hadoop.ipc.TestDecayRpcScheduler\n                  org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover\n                  org.apache.hadoop.hdfs.server.balancer.TestBalancerWithSaslDataTransfer\n\n                                      The following test timeouts occurred in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs:\n\norg.apache.hadoop.hdfs.TestRollingUpgradeRollback\norg.apache.hadoop.hdfs.tools.TestDFSHAAdminMiniCluster\norg.apache.hadoop.hdfs.server.namenode.ha.TestStandbyCheckpoints\norg.apache.hadoop.hdfs.server.namenode.ha.TestHAMetrics\norg.apache.hadoop.hdfs.server.namenode.ha.TestHAStateTransitions\norg.apache.hadoop.hdfs.server.namenode.TestValidateConfigurationSettings\norg.apache.hadoop.hdfs.TestHDFSServerPorts\n\n    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/7639//testReport/\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/7639//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2014-08-15T04:27:47.491+0000","updated":"2014-08-15T04:27:47.491+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14098205","id":"14098205","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"I'd like to elaborate a bit how my latest patch addressed Daryn's comments:\n{quote}\n    If security is enabled and an IOException happens for any reason - transient or legit - while acquiring a token, the client will continue to \"work\" because of spnego but if a job is submitted the tasks will all fail due to no token.\n{quote}\nWith the latest patch (004), only the IOException thrown by DelegationTokenSecretManager.createCredentials}} method WHEN the token is null is interpreted as \"the cluster is insecure\". Because the null token is only returned by FSNamesystem when no secret manager is running (insecure cluster).  With this change, hopefully all other comments are addressed.\n\nThe patch currently parses the IOException message to detect null token. One other option is to let the server return null delegation token instead of throwing exception. Another option is to introduce a NullTokenException. \n\nThanks.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-15T05:45:38.835+0000","updated":"2014-08-15T05:45:38.835+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14098685","id":"14098685","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"I ran the failed tests locally several times and don't see them fail. Uploading the same patch and try again.\nThanks.\n\n  ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-15T15:47:40.311+0000","updated":"2014-08-15T15:47:40.311+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14098711","id":"14098711","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tucu00","name":"tucu00","key":"tucu00","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Alejandro Abdelnur","active":true,"timeZone":"Europe/Madrid"},"body":"{{NullTokenMsgHeader}} constant name should be all capitals.\n\nI'm not sure I like looking for a string occurrence in the IOException message to detect the issue. I thought WebHdfs was recreating exceptions on the client side but it doesn't seem the case for these DT calls.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tucu00","name":"tucu00","key":"tucu00","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Alejandro Abdelnur","active":true,"timeZone":"Europe/Madrid"},"created":"2014-08-15T16:10:18.599+0000","updated":"2014-08-15T16:10:18.599+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14098722","id":"14098722","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks a lot [~tucu00]! I will address your comments in next rev.\n\nI'm currently using message parsing to detect null token returned from server due to lack of right exception. There is an advantage of this fix: we only need to patch secure cluster side, and it will work. To introduce a new exception means compatibility issue, if we decide to do so, we can file a follow-up jira for release 3.0? Thanks.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-15T16:20:14.574+0000","updated":"2014-08-15T16:20:14.574+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14099078","id":"14099078","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12662086/HDFS-6776.004.patch\n  against trunk revision .\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.\n                        Please justify why no new tests are needed for this patch.\n                        Also please list what manual steps were performed to verify this patch.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs:\n\n                  org.apache.hadoop.metrics2.impl.TestMetricsSystemImpl\n                  org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover\n\n                                      The following test timeouts occurred in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs:\n\norg.apache.hadoop.hdfs.TestHDFSServerPorts\norg.apache.hadoop.hdfs.server.datanode.TestFsDatasetCache\norg.apache.hadoop.hdfs.server.namenode.ha.TestStandbyCheckpoints\norg.apache.hadoop.hdfs.server.namenode.ha.TestHAMetrics\norg.apache.hadoop.hdfs.server.namenode.ha.TestHAStateTransitions\norg.apache.hadoop.hdfs.server.namenode.ha.TestDelegationTokensWithHA\norg.apache.hadoop.hdfs.server.namenode.TestValidateConfigurationSettings\n\n    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/7647//testReport/\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/7647//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2014-08-15T20:33:12.253+0000","updated":"2014-08-15T20:33:12.253+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14099861","id":"14099861","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Uploaded 005 to address Alejandro's first comment.  In addition I replaced \"contains\" with \"startsWith\".\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-17T02:51:01.724+0000","updated":"2014-08-17T02:51:01.724+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14099898","id":"14099898","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Upload version 006 that introduces NullToken exception, which hopefully is better than earlier versions that uses msg parsing.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-17T07:01:30.656+0000","updated":"2014-08-17T07:01:30.656+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14099900","id":"14099900","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12662349/HDFS-6776.005.patch\n  against trunk revision .\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.\n                        Please justify why no new tests are needed for this patch.\n                        Also please list what manual steps were performed to verify this patch.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs:\n\n                  org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover\n\n                                      The following test timeouts occurred in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs:\n\norg.apache.hadoop.hdfs.TestHDFSServerPorts\norg.apache.hadoop.hdfs.server.namenode.ha.TestStandbyCheckpoints\norg.apache.hadoop.hdfs.server.namenode.ha.TestHAMetrics\norg.apache.hadoop.hdfs.server.namenode.ha.TestHAStateTransitions\norg.apache.hadoop.hdfs.server.namenode.ha.TestDelegationTokensWithHA\norg.apache.hadoop.hdfs.server.namenode.TestValidateConfigurationSettings\n\n    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/7652//testReport/\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/7652//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2014-08-17T07:16:08.436+0000","updated":"2014-08-17T07:16:08.436+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14099936","id":"14099936","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12662355/HDFS-6776.006.NullToken.patch\n  against trunk revision .\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.\n                        Please justify why no new tests are needed for this patch.\n                        Also please list what manual steps were performed to verify this patch.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs:\n\n                  org.apache.hadoop.metrics2.impl.TestMetricsSystemImpl\n                  org.apache.hadoop.hdfs.server.namenode.ha.TestDFSZKFailoverController\n\n                                      The following test timeouts occurred in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs:\n\norg.apache.hadoop.hdfs.server.namenode.TestValidateConfigurationSettings\norg.apache.hadoop.hdfs.server.namenode.ha.TestHAStateTransitions\norg.apache.hadoop.hdfs.server.namenode.ha.TestStandbyCheckpoints\norg.apache.hadoop.hdfs.server.namenode.ha.TestHAMetrics\norg.apache.hadoop.hdfs.server.namenode.ha.TestDelegationTokensWithHA\norg.apache.hadoop.hdfs.server.blockmanagement.TestReplicationPolicyWithNodeGroup\norg.apache.hadoop.hdfs.TestHDFSServerPorts\n\n    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/7654//testReport/\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/7654//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2014-08-17T11:44:01.576+0000","updated":"2014-08-17T11:44:01.576+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14100383","id":"14100383","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"I investigated the test failures and identified that they are caused by the recent commit of HDFS-6783, for which a new fix will be committed soon. \n\nPatch 006 introduces NullToken Exception, and is a more robust solution. Hi [~tucu00] and [~daryn], thanks for your earlier review, I'd really appreciate if you can take a look at 006. thanks a lot.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-18T07:24:20.263+0000","updated":"2014-08-18T07:24:20.263+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14100854","id":"14100854","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Now the HDFS-6783 addendum fix is in trunk, submitting HDFS-6776.006.NullToken.patch again for a new test run.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-18T16:59:34.640+0000","updated":"2014-08-18T16:59:34.640+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14101231","id":"14101231","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12662514/HDFS-6776.006.NullToken.patch\n  against trunk revision .\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.\n                        Please justify why no new tests are needed for this patch.\n                        Also please list what manual steps were performed to verify this patch.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs:\n\n                  org.apache.hadoop.ha.TestActiveStandbyElector\n                  org.apache.hadoop.ha.TestZKFailoverController\n                  org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover\n\n    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/7665//testReport/\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/7665//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2014-08-18T20:35:05.829+0000","updated":"2014-08-18T20:35:05.829+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14101354","id":"14101354","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tucu00","name":"tucu00","key":"tucu00","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Alejandro Abdelnur","active":true,"timeZone":"Europe/Madrid"},"body":"[~yzhangal], how about  the following:\n\n* introduce a new exception on the server side \n* on the client side, catch this new exception (this will work against a cluster with the fix) and catch IOException looking for the string occurrence in the message (this will work against a cluster without the fix).\n\nBTW, testcases seem unrelated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tucu00","name":"tucu00","key":"tucu00","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Alejandro Abdelnur","active":true,"timeZone":"Europe/Madrid"},"created":"2014-08-18T21:37:01.750+0000","updated":"2014-08-18T21:37:01.750+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14101370","id":"14101370","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks a lot Alejandro! What you suggested is a combined approach of 005 and 006 revisions I uploaded. I will have a revised patch later today. \nHi [~daryn], it would be great if you could help taking a look, and your advice here is very much appreciated. Thanks.\n\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-18T21:46:23.758+0000","updated":"2014-08-18T21:46:23.758+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14101770","id":"14101770","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi [~tucu00] and [~daryn],\n\nI uploaded version 007 to address Alejandro's last comment. Basically it's a combined solution of 005 and 006. Thanks for reviewing.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-19T02:45:45.121+0000","updated":"2014-08-19T02:45:45.121+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14102825","id":"14102825","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tucu00","name":"tucu00","key":"tucu00","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Alejandro Abdelnur","active":true,"timeZone":"Europe/Madrid"},"body":"latest patch  looks good to me just a minor thing:\nCan you please add a comment in the catch of the IOException indicating why we are doing that (to support older clusters that do not throw the NullToken?\n\n+1 from my side after this. \n\n[~daryn], are you OK with the current approach?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tucu00","name":"tucu00","key":"tucu00","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Alejandro Abdelnur","active":true,"timeZone":"Europe/Madrid"},"created":"2014-08-19T20:56:46.694+0000","updated":"2014-08-19T21:08:41.792+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14102904","id":"14102904","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wheat9","name":"wheat9","key":"wheat9","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Haohui Mai","active":true,"timeZone":"America/Los_Angeles"},"body":"I'm unsure that fixing on the filesystem itself is the right approach to take. Based on the above comments (and please correct me if I'm wrong), I'm assuming that distcp is pulling data from a secure cluster to an insecure cluster.\n\n# What happens if the {{WebHdfsFileSystem}} intends to connect to a secure cluster but the attacker has somehow disabled the security of the cluster or successfully launch a MITM attack which keep returning {{NullToken}}? Instead of ignoring the failures, I think that {{WebHdfsFileSystem}} should fail explicitly because that the system is compromised. This is important as copying from a secure cluster to an insecure cluster can unintentionally breach the confidentiality.\n\nOn the implementation:\n\n# It looks like that {{WebHdfsFileSystem}} will issue a {{GET_DELEGATION_TOKEN}} request for each request since in catching {{NullToken}} nullifies {{delegationToken}}, which significantly affects the performance. \n\nI have encountered this issue in production. What I have done is to put the fix on the server side instead of the client side. I asked the NN of the insecure cluster to issue a dummy token, which works across all filesystems. That way at the very least the user has to be informed instead of allowing the data silently flowing from secure to insecure clusters.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wheat9","name":"wheat9","key":"wheat9","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Haohui Mai","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-19T21:44:54.231+0000","updated":"2014-08-19T21:44:54.231+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14102909","id":"14102909","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks Alejandro. Uploaded version 008 to address the last comment of yours.\n ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-19T21:47:56.744+0000","updated":"2014-08-19T21:47:56.744+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14102922","id":"14102922","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"HI [~wheat9],\n\nThanks for your review and comments. The main goal of this jira is to support pull data from insecure cluster to secure cluster, which is not the same as you assumed. You can only issue the distcp command at the secure cluster side. However, it also works when you try to copy data from secure cluster to insure cluster, as long as you issue the command from the secure cluster side. So I think your comment 1 is not relevant here. Please correct me if I'm wrong.\n\nAbout the comment 2, canRefreshDelegationToken is set to false for insecure cluster, thus WebHdfsFileSystem will not issue a GET_DELEGAtTION_TOKEN request for each request. See method {{protected synchronized Token<?> getDelegationToken() }}. \n\nThanks.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-19T21:56:20.454+0000","updated":"2014-08-19T21:56:20.454+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14103348","id":"14103348","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12662862/HDFS-6776.008.patch\n  against trunk revision .\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.\n                        Please justify why no new tests are needed for this patch.\n                        Also please list what manual steps were performed to verify this patch.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs:\n\n                  org.apache.hadoop.crypto.key.TestValueQueue\n                  org.apache.hadoop.ipc.TestIPC\n                  org.apache.hadoop.ipc.TestCallQueueManager\n                  org.apache.hadoop.hdfs.server.datanode.TestBPOfferService\n                  org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover\n\n                                      The following test timeouts occurred in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs:\n\norg.apache.hadoop.hdfs.TestIsMethodSupported\n\n    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/7685//testReport/\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/7685//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2014-08-20T04:11:45.302+0000","updated":"2014-08-20T04:11:45.302+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14103621","id":"14103621","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12662862/HDFS-6776.008.patch\n  against trunk revision .\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.\n                        Please justify why no new tests are needed for this patch.\n                        Also please list what manual steps were performed to verify this patch.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs:\n\n                  org.apache.hadoop.crypto.key.TestValueQueue\n                  org.apache.hadoop.ipc.TestDecayRpcScheduler\n                  org.apache.hadoop.ipc.TestCallQueueManager\n                  org.apache.hadoop.hdfs.server.datanode.TestBPOfferService\n                  org.apache.hadoop.hdfs.server.blockmanagement.TestRBWBlockInvalidation\n\n    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/7687//testReport/\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/7687//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2014-08-20T08:37:09.080+0000","updated":"2014-08-20T08:37:09.080+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14104596","id":"14104596","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wheat9","name":"wheat9","key":"wheat9","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Haohui Mai","active":true,"timeZone":"America/Los_Angeles"},"body":"bq. So I think your comment 1 is not relevant here.\n\nAs pointed out that distcp has to be initiated from the secure cluster, but with this approach distcp / webhdfsfilesystem silently succeeds even if the other side is an insecure cluster. It is undesirable since it can easily lead to security incident.\n\nbq. canRefreshDelegationToken is set to false for insecure cluster, thus WebHdfsFileSystem will not issue a GET_DELEGAtTION_TOKEN request for each request. See method {{protected synchronized Token<?> getDelegationToken() }}.\n\nAs distcp is always started at the secure cluster, which means that the {{WebHdfsFileSystem}} object is created inside the secure cluster, thus {{canRefreshDelegationToken}} should be true.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wheat9","name":"wheat9","key":"wheat9","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Haohui Mai","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-20T21:11:25.982+0000","updated":"2014-08-20T21:11:25.982+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14104712","id":"14104712","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"HI [~wheat9],\n\nI will address your second comment later. \n\nFor your first one (distcp / webhdfsfilesystem silently succeeds), that's a good point. Right now, after security is examined, then there is the permission control, whoever issue the distcp command need to have right permission. Do you think we should disable copying stuff from secure cluster to insecure cluster, or to have another level of control? Thanks.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-20T22:29:25.483+0000","updated":"2014-08-20T22:29:25.483+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14104986","id":"14104986","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"[~wheat9]. for your second comment,  please look at WebHdfsSystem.getDelegationToken(), \n{code}\n        if (token != null) {\n          LOG.debug(\"Fetched new token: \" + token);\n        } else { // security is disabled\n          canRefreshDelegationToken = false;\n        }\n{code}\n\nOnce a null token is taken, then canRefreshDelegationToken is set to false, no longer need to issue GET_DELEGATION_TOKEN request.\n\nThanks.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-21T03:17:23.127+0000","updated":"2014-08-21T03:17:23.127+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14104996","id":"14104996","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"BTW, the test failures of the last runs appear to be flaky.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-21T03:31:30.655+0000","updated":"2014-08-21T03:31:30.655+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14107405","id":"14107405","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"HI [~wheat9], may I know if my replies addressed your comments? thanks.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-22T20:09:22.465+0000","updated":"2014-08-22T20:09:22.465+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14107448","id":"14107448","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wheat9","name":"wheat9","key":"wheat9","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Haohui Mai","active":true,"timeZone":"America/Los_Angeles"},"body":"bq. Right now, after security is examined, then there is the permission control, whoever issue the distcp command need to have right permission. Do you think we should disable copying stuff from secure cluster to insecure cluster, or to have another level of control? Thanks.\n\nI'm not sure what you refer to. Copying between secure and insecure clusters is a valid use case. What I have been saying that {{WebHdfsFileSystem}} is not the right place to change since the use case and having a security breach becomes indistinguishable.\nFor this use case you might need to look at changing distcp or to ask the insecure cluster to issue dummy token.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wheat9","name":"wheat9","key":"wheat9","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Haohui Mai","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-22T20:35:49.378+0000","updated":"2014-08-22T20:35:49.378+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14107645","id":"14107645","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"HI [~wheat9],  thanks for the elaboration. I assume you are talking about \n{quote}\nWhat happens if the WebHdfsFileSystem intends to connect to a secure cluster but the attacker has somehow disabled the security of the cluster or successfully launch a MITM attack which keep returning NullToken? Instead of ignoring the failures, I think that WebHdfsFileSystem should fail explicitly because that the system is compromised. This is important as copying from a secure cluster to an insecure cluster can unintentionally breach the confidentiality.\n{quote}\nIf secure HDFS can be attacked to return NullToken all the time, I wonder whether it can also be attacked to return a dummy token? \n\nHi [~daryn] and [~tucu00], would you please comment? many thanks.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-22T22:52:48.618+0000","updated":"2014-08-22T22:52:48.618+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14107917","id":"14107917","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"HI [~wheat9], I would like share some more thoughts in addition to my last reply.\n\nIf the attacker has somehow disabled the security of the cluster, that means the cluster is compromised, damage could happen. I certainly agree that great effort should be taken to avoid the damage here.  But can WebHdfsFileSysem really tell whether it's compromised or not? that's my doubt. My previous reply was, if attacker can make the cluster keep return NullToken, it can make the cluster the return dummy token too. \n\nIf there is a good way to detect whether a cluster is compromised easily, we should have a demon running somewhere all the time to do the checking constantly and report the situation to administrator immediately if it happens, instead of waiting for someone to issue a distcp command and catch it. \n\nMy point is, we certainly should try our best to prevent the cluster from being attacked. Returning NullToken (notice here we are throwing an NullToken exception rather than returning null Token) or dummyToken does not seem to make much difference here. \n\nThis is my limited understanding. More discussion is welcome.\n\nThanks.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-23T07:35:51.946+0000","updated":"2014-08-23T07:35:51.946+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14107935","id":"14107935","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wheat9","name":"wheat9","key":"wheat9","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Haohui Mai","active":true,"timeZone":"America/Los_Angeles"},"body":"bq. Returning NullToken (notice here we are throwing an NullToken exception rather than returning null Token) or dummyToken does not seem to make much difference here.\n\nThe key difference is whether the user is aware of that there are potential security issues.\n\nNote that the users know some information about the remote cluster, for example, whether the remote cluster is secure or not. If the user is connecting to a insecure cluster, he / she has to have the consent because there could be security concerns in this use case. Any solutions have to meet this requirement.\n\nJust for references, if you looks at how distcp works when copying between secure / insecure clusters using rpc (i.e. {{hdfs://}}), there is configuration to tweak whether connecting to insecure clusters is allowed. Users can reject these connections for maximum security. If distcp over webhdfs / swebhdfs between secure / insecure works, then the user should be able to specify the same security requirement.\n\nThere are many ways to approach this requirement. For example, maybe you can add a parameter in distcp, or add a new configuration so that the remote cluster can return a dummy token? I think this requirement has to be addressed before this patch can go in.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wheat9","name":"wheat9","key":"wheat9","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Haohui Mai","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-23T08:36:46.233+0000","updated":"2014-08-23T08:36:46.233+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14108194","id":"14108194","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"HI [~wheat9],\n\nThanks for the more info. What about I add a config similar like the RPC one you mentioned\n{code}\n{\nthis.fallbackAllowed = conf.getBoolean(CommonConfigurationKeys.IPC_CLIENT_FALLBACK_TO_SIMPLE_AUTH_ALLOWED_KEY,\n        CommonConfigurationKeys.IPC_CLIENT_FALLBACK_TO_SIMPLE_AUTH_ALLOWED_DEFAULT);\n{code}\nand take NullToken exception as insecure only when the fallback is allowed?\n\nWe can make the new property WEB_CLIENT_FALLACK_TO_SIMPLE_AUTH_ALLOWED_KEY.\n\nNow with this config introduced, and since we dedicate NullToken exception to be thrown when insecure cluster is asked for delegation token,  there is not much functionality difference between NullToken or dummy token. \n\nAgree?\n\nThanks.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-23T23:31:51.807+0000","updated":"2014-08-23T23:31:51.807+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14108209","id":"14108209","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wheat9","name":"wheat9","key":"wheat9","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Haohui Mai","active":true,"timeZone":"America/Los_Angeles"},"body":"bq. Now with this config introduced, and since we dedicate NullToken exception to be thrown when insecure cluster is asked for delegation token, there is not much functionality difference between NullToken or dummy token.\n\nWebHdfsFileSystem is the wrong place to have this configuration. If distcp fails to work with other filesystems that have the same issue, are you modifying all of them that get delegation tokens from insecure clusters and throwing NullToken for every possible filesystem implementation?\n\nJust to clarify, I'm not necessarily pushing the dummy token proposal. It is just something that I've tried and worked. Can you please look at whether you can fix distcp? To me this is the right place to fix, though it might be nontrivial because yarn / mr require DTs as well.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wheat9","name":"wheat9","key":"wheat9","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Haohui Mai","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-24T00:25:57.939+0000","updated":"2014-08-24T00:25:57.939+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14108227","id":"14108227","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Hello [~wheat9],\n\nWebHdfsFileSystem, HftpFileSystem etc each has its own method to get delegation (derived from the FileSystem.getDelegationToken method). I do see that the different file systems need to fixed to handle null token.\n\nI think it'd preferred for each file system to have its own property similar like IPC_CLIENT_FALLBACK_TO_SIMPLE_AUTH_ALLOWED_KEY, thus we have a granularity control on each file system.\n\nDistcp is just a mapreduce job that access multiple filesystems via their APIs, other mapreduce jobs might have the same need and they would have similar problem. Basically a files ystem need to tell the client whether it's secure or not. The control is up to the the file system, not the client (distcp in this case). \n\nJust my thoughts.\n\nThanks.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-24T02:54:36.593+0000","updated":"2014-08-24T02:54:36.593+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14108428","id":"14108428","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Addition to my previous thoughts - [~wheat9]:\n\nThis jira is about not being able to pull data from insecure HDFS cluster into secure HDFS cluster. You pointed out how \"distcp hdfs:// hdfs://\" current works with fallback controlled by the FALLBACK property, which is quite helpful here. Given that how \"hdfs://\" works, we are applying the same property to \"webhdfs://\". Only a couple of more (http, hftp@branch-2) that I expect we need similar fix (may I know what others are in your mind?). \n\nAs you mentioned, another alternative is to fix Distcp but it'd be nontrivial (For this alternative, we still need to decide where the fallback property need to be defined. I think the property should be defined in the file system side, you can comment on my previous comment). \n\nFor general problems, we tend to find simple solutions rather than complicated solutions.  If we don't have many places to fix with a simple solution, why would we choose a more complicated solution? I think you meant if we fix on the distcp side, then adding a new filesystem won't need a fix for this issue. Am I understanding you correctly? If not, would you please provide more info? Otherwise, I can also argue that with my proposed patch, adding new application like distcp won't need a fix for this issue, plus the proposed patch is simpler.\n\nThanks.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-24T15:12:20.755+0000","updated":"2014-08-24T15:12:20.755+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14109426","id":"14109426","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wheat9","name":"wheat9","key":"wheat9","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Haohui Mai","active":true,"timeZone":"America/Los_Angeles"},"body":"bq. we are applying the same property to \"webhdfs://\". Only a couple of more (http, hftp@branch-2) that I expect we need similar fix (may I know what others are in your mind?).\n\nThe fallback happens in the negotiation phase. I think other filesystems need to have negotiation between clients and server if this is the route to take. It can happen in a later jira.\n\nbq. For general problems, we tend to find simple solutions rather than complicated solutions. If we don't have many places to fix with a simple solution, why would we choose a more complicated solution?\n\nbq. Otherwise, I can also argue that with my proposed patch, adding new application like distcp won't need a fix for this issue, plus the proposed patch is simpler.\n\nWhat do you exactly mean by simplicity? Simplicity can mean few changes, or a clean design, or favorably both.\n\nTo me throwing a NullToken is more like a hack instead of an informed design choice. Let me just echo the differences between the NullToken and dummy token solution:\n\n# Throwing a NullToken requires fixing every filesystems. Will NullToken later to leak into the FileSystem API? In contrast,  returning dummy tokens does not have this problem by design.\n# Tokens are designed to be capability objects, thus returning dummy tokens matches the design rationales.\n# It also only requires few changes as well.\n\nbq.  I think you meant if we fix on the distcp side, then adding a new filesystem won't need a fix for this issue. Am I understanding you correctly?\n\nThis rationale is that distcp is the application, which is the only one able to tell for a particular cluster, whether it should go and get a delegation token. The benefit of not fixing any filesystems, is the effect rather than the cause.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wheat9","name":"wheat9","key":"wheat9","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Haohui Mai","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-25T18:08:06.381+0000","updated":"2014-08-25T18:08:06.381+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14109427","id":"14109427","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wheat9","name":"wheat9","key":"wheat9","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Haohui Mai","active":true,"timeZone":"America/Los_Angeles"},"body":"This is a simple http proxy that issues a dummy token for an insecure cluster.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wheat9","name":"wheat9","key":"wheat9","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Haohui Mai","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-25T18:09:12.473+0000","updated":"2014-08-25T18:09:12.473+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14109436","id":"14109436","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12664181/dummy-token-proxy.js\n  against trunk revision .\n\n    {color:red}-1 patch{color}.  The patch command could not apply the patch.\n\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/7748//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2014-08-25T18:14:02.472+0000","updated":"2014-08-25T18:14:02.472+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14109478","id":"14109478","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"HI [~wheat9], \n\nThanks for the more info. Would you please indicate what are the other file systems in your mind that we need to fix if we go with NullToken approach? I can see very few here, thus the change is quite little.  Thanks.\n\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-25T18:40:02.415+0000","updated":"2014-08-25T18:40:02.415+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14109575","id":"14109575","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"I'm revisiting some comments you made earlier [~wheat9]\n\n{quote}\nWhat do you exactly mean by simplicity? Simplicity can mean few changes, or a clean design, or favorably both.\n{quote}\n\n{quote}\nJust to clarify, I'm not necessarily pushing the dummy token proposal. It is just something that I've tried and worked. Can you please look at whether you can fix distcp? To me this is the right place to fix, though it might be nontrivial because yarn / mr require DTs as well.\n{quote}\nThe above statement  indicate that the solution to fix distcp does not satisfy the simplicity criteria you listed.\n\n{quote}\nThis rationale is that distcp is the application, which is the only one able to tell for a particular cluster, whether it should go and get a delegation token. The benefit of not fixing any filesystems, is the effect rather than the cause.\n{quote}\nOne thing you didn't state above, is that distcp as an application, it doesn't know whether the target cluster is secure or not, so it does NOT know whether it need to get a delegation. I wish there were an API to tell whether a cluster is secure or not, so the client can know whether it needs to  ask the cluster for delegation token.  Without this API,  the client has to do trial and fail, the cluster can choose to return either NullToken or dummy token to indicate it's not secure, but both would work. I thought that's why you stated \"I'm not necessarily pushing on the dummy token proposal\". \n \nI think NullToken is a reasonable approach that achieves both function correctness and simplicity. Except we need to have a property to alert user of the potential effect of accessing insecure cluster, as you suggested earlier.\n\nThanks.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-25T19:13:01.309+0000","updated":"2014-08-25T19:13:01.309+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14109640","id":"14109640","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tucu00","name":"tucu00","key":"tucu00","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Alejandro Abdelnur","active":true,"timeZone":"Europe/Madrid"},"body":"Today, with HTTP APIs, we don't have an 'allow fallback to simple auth' switch. It is something we should add.\n\nStill, I don't think that will help address the usecase this JIRA tries to solve, distcp-ing from an insecure cluster to a secure cluster. For this usecase we will need to leave the switch in TRUE, which is today's current behavior (without the switch).\n\nI would suggest, we fix the current usecase, and we follow it up with a JIRA adding the switch to the configuration and another to distcp. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tucu00","name":"tucu00","key":"tucu00","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Alejandro Abdelnur","active":true,"timeZone":"Europe/Madrid"},"created":"2014-08-25T19:55:55.632+0000","updated":"2014-08-25T19:55:55.632+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14109657","id":"14109657","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks [~tucu00].\n\nI actually already worked out a version with a config property for webhdfs (defaulted to false). I was just trying to address [~wheat9]'s comments before posting it. With this property, user need to change the config from \"false\" to \"true\" before being able to copy from insecure cluster to secure cluster.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-25T20:18:33.814+0000","updated":"2014-08-25T20:18:33.814+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14109855","id":"14109855","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=daryn","name":"daryn","key":"daryn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Daryn Sharp","active":true,"timeZone":"America/Chicago"},"body":"I've tried to quickly scan the discussion.  I don't see how use of \"NullToken\" really helps.\n\nWhy isn't this patch achieving parity with hdfs vs. webhdfs?  RPC returns null for token requests when security is disabled.  Webhdfs should too instead of throwing an exception.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=daryn","name":"daryn","key":"daryn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Daryn Sharp","active":true,"timeZone":"America/Chicago"},"created":"2014-08-25T22:18:13.441+0000","updated":"2014-08-25T22:18:13.441+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14110031","id":"14110031","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"HI [~daryn], thanks for your comments. \n\nWhen client doesn't know whether a target cluster is secure or not, and issued GET_DELEGATION_TOKEN request, there are three ways for the insecure cluster to respond:\n\n- throw NullToken exception\n- return dummy token\n- return \"null\" token to be parsed in the respsonse.\n\nIn terms of functionality, they are pretty equivalent. But to achieving parity with hdfs,  I can try to work out a revision to return \"null\" token instead of throwing NullToken exception.\n\nThanks.\n\nHi [~wheat9], while I'm working on a new revision, would you please comment on this change? and my questions above? thanks.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-26T00:13:09.155+0000","updated":"2014-08-26T00:13:09.155+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14110758","id":"14110758","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Uploaded patch 009. This version passes real \"null\" delegation token for webhdfs, when an insecure cluster is asked for deleagation token. Hope this addresses, In addition, I included a config property which has to be turn on to support fallback.\n\nHI [~daryn] and [~wheat9], thanks a lot for your earlier comments, and hopefully this addressed them. Thanks.\n\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-26T14:34:07.442+0000","updated":"2014-08-26T14:34:07.442+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14110805","id":"14110805","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"BTW, I'd like to restrict the solution of the jira for webhdfs only, and I modified the title of this jira to reflect that. At least with the fix, we can enable distcping between secure and insecure cluster. As we know, right now it's broken. For other interface, like hftp in branch-2. I will file follow-up jira to resolve them. Thanks.\n\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-26T15:18:26.835+0000","updated":"2014-08-26T15:18:26.835+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14110949","id":"14110949","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12664395/HDFS-6776.009.patch\n  against trunk revision .\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.\n                        Please justify why no new tests are needed for this patch.\n                        Also please list what manual steps were performed to verify this patch.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:\n\n                  org.apache.hadoop.security.TestRefreshUserMappings\n                  org.apache.hadoop.hdfs.web.TestWebHdfsFileSystemContract\n                  org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover\n\n    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/7768//testReport/\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/7768//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2014-08-26T17:04:23.619+0000","updated":"2014-08-26T17:04:23.619+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14110950","id":"14110950","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12664394/HDFS-6776.009.patch\n  against trunk revision .\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.\n                        Please justify why no new tests are needed for this patch.\n                        Also please list what manual steps were performed to verify this patch.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:\n\n                  org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover\n\n    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/7767//testReport/\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/7767//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2014-08-26T17:04:23.752+0000","updated":"2014-08-26T17:04:23.752+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14111530","id":"14111530","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"I'd like to emphasize that with the latest patch of using \"null\" token instead of NullToken exception, user has to apply the same patch to both source and target cluster. With the prior revision that Alejandro commented, that combines NullToken and message parsing,, user just need to patch the secure cluster.\n\nThanks.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-26T23:11:53.762+0000","updated":"2014-08-26T23:11:53.762+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14111578","id":"14111578","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tucu00","name":"tucu00","key":"tucu00","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Alejandro Abdelnur","active":true,"timeZone":"Europe/Madrid"},"body":"IMO, enabling to work with an unpatched cluster (via message parsing) is a desirable capability as it does not require users to upgrade older clusters if they are just reading data from them.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tucu00","name":"tucu00","key":"tucu00","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Alejandro Abdelnur","active":true,"timeZone":"Europe/Madrid"},"created":"2014-08-26T23:42:48.121+0000","updated":"2014-08-26T23:42:48.121+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14112713","id":"14112713","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"If all agree, I can still make the client side catch the IOException and parse the message, on top of the \"null\" token solution version 009.\nThe advantage of doing so is that we don't have to upgrade the insecure cluster that distcp is reading from.\nThanks.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-27T19:43:55.720+0000","updated":"2014-08-27T19:43:55.720+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14112768","id":"14112768","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wheat9","name":"wheat9","key":"wheat9","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Haohui Mai","active":true,"timeZone":"America/Los_Angeles"},"body":"bq. I've tried to quickly scan the discussion. I don't see how use of \"NullToken\" really helps.\nWhy isn't this patch achieving parity with hdfs vs. webhdfs? RPC returns null for token requests when security is disabled. Webhdfs should too instead of throwing an exception.\n\nAgree. This sounds quite reasonable to me.\n\nCompared to other proposal, I think the NullToken solution is way too hacky and I'm opposed to it. The earlier comments elaborated the rationales.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wheat9","name":"wheat9","key":"wheat9","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Haohui Mai","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-27T20:22:05.689+0000","updated":"2014-08-27T20:22:05.689+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14112938","id":"14112938","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi [~wheat9], rev 009 was already done to address this comment. Would you please take a look?\n\nI'm aware of one place that I can drop the check for IsSecurityEnabled() below in 009.\n{code}\n+      if (UserGroupInformation.isSecurityEnabled() && !fallbackAllowed) {\n+        throw new IOException(FALLBACK_MSG);\n+      }\n{code}\n\nThe remaining question is, on top of 009, do we need to add the handling of catching IOException(\"Failed to get the token...\") from the client side, so user doesn't need to upgrade the insecure cluster in order to pull data from it with distcp.\n\nThanks.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-27T22:10:14.476+0000","updated":"2014-08-27T22:10:14.476+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14113049","id":"14113049","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=atm","name":"atm","key":"atm","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=atm&avatarId=14136","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=atm&avatarId=14136","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=atm&avatarId=14136","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=atm&avatarId=14136"},"displayName":"Aaron T. Myers","active":true,"timeZone":"America/Los_Angeles"},"body":"I think the latest patch looks pretty good to me, and does indeed seem to address Daryn's earlier suggestion of just returning {{null}} as is currently done for RPC requests to get a delegation token.\n\nI also agree with Tucu that it'd be nice to implement both the exception parsing scheme, as well as returning null, so that we have to upgrade fewer clusters to get distcp to work. Yes, it's a bit hacky, but having to upgrade a whole cluster in order to get distcp to work is pretty darn heavy weight. Haohui/Daryn - do you object to doing both, which would both get us going in the right direction as far as design _and_ make life easier for current users?\n\nMy only other suggestions are the following minor ones:\n\n# I think you can indeed get rid of the {{isSecurityEnabled}} check as you suggested in your last comment, Yongjun.\n# I think we shouldn't introduce a new config setting to allow fallback for webhdfs, but rather should just use the existing config setting to also allow fallback for WebHDFS. I can't think of any reason that users would be willing to allow insecure fallback for one interface but not another.\n\nI'd personally be +1 once these are addressed.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=atm","name":"atm","key":"atm","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=atm&avatarId=14136","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=atm&avatarId=14136","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=atm&avatarId=14136","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=atm&avatarId=14136"},"displayName":"Aaron T. Myers","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-27T23:20:16.017+0000","updated":"2014-08-27T23:20:16.017+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14113387","id":"14113387","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi [~atm], thanks a lot for the review and comments. I just uploaded rev 010 to address them.\n\nI usually test against real clusters before I upload new rev, but my clusters are down now. I will test out tomorrow.\n\nThanks.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-28T06:00:45.361+0000","updated":"2014-08-28T06:00:45.361+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14114708","id":"14114708","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12664836/HDFS-6776.010.patch\n  against trunk revision ab638e7.\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.\n                        Please justify why no new tests are needed for this patch.\n                        Also please list what manual steps were performed to verify this patch.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs:\n\n                  org.apache.hadoop.security.TestRefreshUserMappings\n\n    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/7846//testReport/\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/7846//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2014-08-29T01:13:03.298+0000","updated":"2014-08-29T01:13:03.298+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14114854","id":"14114854","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi [~atm],\n\nI filed HDFS-6972 for the test failure and uploaded a quick patch. Since the fix for HDFS-6972 is pretty trivial, would you please help reviewing that too?\n\nAnd would you please take a look at rev 010 here to see it all your comments are addressed?\n\nThanks a lot.\n\n\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-29T04:45:52.174+0000","updated":"2014-08-29T04:45:52.174+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14115880","id":"14115880","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=atm","name":"atm","key":"atm","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=atm&avatarId=14136","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=atm&avatarId=14136","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=atm&avatarId=14136","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=atm&avatarId=14136"},"displayName":"Aaron T. Myers","active":true,"timeZone":"America/Los_Angeles"},"body":"This latest patch looks good to me. +1 on my end.\n\nTucu/Haohui/Daryn - does this look OK to you?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=atm","name":"atm","key":"atm","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=atm&avatarId=14136","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=atm&avatarId=14136","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=atm&avatarId=14136","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=atm&avatarId=14136"},"displayName":"Aaron T. Myers","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-29T21:41:22.939+0000","updated":"2014-08-29T21:41:22.939+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14115891","id":"14115891","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tucu00","name":"tucu00","key":"tucu00","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Alejandro Abdelnur","active":true,"timeZone":"Europe/Madrid"},"body":"LGTM","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tucu00","name":"tucu00","key":"tucu00","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Alejandro Abdelnur","active":true,"timeZone":"Europe/Madrid"},"created":"2014-08-29T21:48:37.726+0000","updated":"2014-08-29T21:48:37.726+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14115960","id":"14115960","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wheat9","name":"wheat9","key":"wheat9","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Haohui Mai","active":true,"timeZone":"America/Los_Angeles"},"body":"{code}\n+      if (token != null) {\n+        token.setService(tokenServiceName);\n+      } else if (!fallbackAllowed) {\n+        throw new IOException(FALLBACK_MSG);\n       }\n-    }.run();\n-    token.setService(tokenServiceName);\n-    return token;\n+      return token;\n+    } catch (IOException ioe) {\n+      if (ioe.getMessage().startsWith(SecurityUtil.NULL_TOKEN_MSG_HEADER)) {\n+        // cluster that is insecure and doesn't have the fix of HDFS-6776\n+        // throws IOException with msg that starts with\n+        // SecurityUtil.NULL_TOKEN_MSG_HEADER when requested for delegation\n+        // token. Catch it here and return null delegation token if \n+        // fallback is allowed\n+        if (!fallbackAllowed) {\n+          throw new IOException(FALLBACK_MSG, ioe);\n+        }\n+        return null;\n+      }\n+      throw ioe;\n+    }\n   }\n{code}\n\nThis is too fragile. I'm unconvinced that this should happen in WebHdfsFileSystem.\n\nHowever, it's okay to me to return a null here so the behavior is similar to DistributedFileSystem. The actual fallback logic can happen at the distcp side when building the file list, but maybe we can defer it to another jira.\n\nPlease add new unit tests to cover this behavior.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wheat9","name":"wheat9","key":"wheat9","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Haohui Mai","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-29T22:26:57.393+0000","updated":"2014-08-29T22:26:57.393+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14115985","id":"14115985","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Thank you all for the review, thanks [~atm] and [~tucu00] for the +1!\n\nI tested in between two real clusters when the secure cluster has the fix, and the insecure one has AND doesn't have, all of them appear to work.\n\nHI [~wheat9], to create a testcase with two clusters, one has kerberos enabled is going to be a challenge here. Given that I have tested with real clusters, with and without the fix, I wonder if it'd be ok with you that we don't have a test for this. Thanks.\n\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-29T22:45:03.560+0000","updated":"2014-08-29T22:45:03.560+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14116238","id":"14116238","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi [~wheat9], I checked and my understanding is that it is not possible to start a minicluster with kerberos today, so any this kind of testing has to be using two real clusters, and this is what I have done. Please correct me if I'm wrong.  Thanks.\n\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-30T05:22:34.532+0000","updated":"2014-08-30T05:22:34.532+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14120333","id":"14120333","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=atm","name":"atm","key":"atm","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=atm&avatarId=14136","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=atm&avatarId=14136","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=atm&avatarId=14136","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=atm&avatarId=14136"},"displayName":"Aaron T. Myers","active":true,"timeZone":"America/Los_Angeles"},"body":"[~wheat9], if I'm understanding you correctly it seems like though this isn't your ideal solution, you're alright with it.\n\nI agree with Yongjun that writing a unit test would be pretty difficult for this, and I'm personally satisfied with the level of manual testing that he's done.\n\nUnless there's an objection in the next hour or two I'm going to go ahead and commit the latest patch, so please speak up if you're not OK with that.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=atm","name":"atm","key":"atm","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=atm&avatarId=14136","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=atm&avatarId=14136","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=atm&avatarId=14136","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=atm&avatarId=14136"},"displayName":"Aaron T. Myers","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-09-03T19:56:07.693+0000","updated":"2014-09-03T19:56:07.693+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14120358","id":"14120358","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wheat9","name":"wheat9","key":"wheat9","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Haohui Mai","active":true,"timeZone":"America/Los_Angeles"},"body":"bq.  if I'm understanding you correctly it seems like though this isn't your ideal solution, you're alright with it.\n\nJust to reiterate my last comments:\n\n1. The fallback logic of the latest patch is too fragile. I'm still uncomfortable with it. I suggest for this jira just return {{null}} directly. That way it should allow the distcp to work. We can defer the discussion of fallback logic in another jira.\n2. I agree that it would be difficult to write an end-to-end test, but at the very least there should be a unit test cover the new behavior of WebHdfsFileSystem, that is, testing whether WebHdfsFileSystem can get a null from an insecure cluster.\n\nPlease address the comments before committing the patch.\n\nI'm sorry that I have slightly longer delay than I usually do, but please wait for my +1 before committing the patch.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wheat9","name":"wheat9","key":"wheat9","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Haohui Mai","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-09-03T20:10:32.685+0000","updated":"2014-09-03T20:10:32.685+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14120758","id":"14120758","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=atm","name":"atm","key":"atm","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=atm&avatarId=14136","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=atm&avatarId=14136","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=atm&avatarId=14136","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=atm&avatarId=14136"},"displayName":"Aaron T. Myers","active":true,"timeZone":"America/Los_Angeles"},"body":"[~wheat9] - I'm assuming you're saying it's fragile because the latest patch is parsing some exception text. I agree that that sort of thing is in general fragile, and should be avoided. However, in this case, the alternative is to require that the remote cluster have its software upgraded to the newer version that contains the changed behavior. In my opinion (and, it seems, Tucu's and Yongjun's, as well) having to do that is so onerous for the operator as to warrant this (admittedly somewhat hacky) message parsing solution.\n\nDo you have some alternative that will allow for this fixed distcp to work with a cluster which is not running this change? Because if not, I think we should go ahead and go with this solution, fragile as it may be, so as to potentially save users a whole heck of a lot of pain.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=atm","name":"atm","key":"atm","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=atm&avatarId=14136","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=atm&avatarId=14136","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=atm&avatarId=14136","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=atm&avatarId=14136"},"displayName":"Aaron T. Myers","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-09-04T00:31:07.185+0000","updated":"2014-09-04T00:31:07.185+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14120892","id":"14120892","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi Guys, Thanks a lot for the review and feedback. Uploaded rev 001 with two testcases added (with fallback enabled and disabled) to address Haohui's comments.\n\nHello [~wheat9],\n\n Thanks for your review to drive to a more complete solution (now we have the unit tests).\n\nAbout your comment #1, I think both Alejandro and ATM stated the benefit of having the a bit hacking message parsing to save the lots of pain of users otherwise, and I certainly agree with that. So I still included it. \n\nAs of today, users have the pain not being able to distcp from insecure cluster to secure cluster. The symptom is the message as reported in this jira. With the patch, now we can return and detect null token and do distcp. The additional hacky meachnism to save user's pain is to parse and understand the message reported in the issue' symptom, it at least is not a regression (user used to just see exception thrown). When old versions which issue that messages are obsoleted in the future, we can certainly drop this hacky message parsing.\n\nThanks again.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-09-04T03:09:01.371+0000","updated":"2014-09-04T03:09:01.371+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14120988","id":"14120988","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12666403/HDFS-6776.011.patch\n  against trunk revision 8f1a668.\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs:\n\n                  org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover\n\n    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/7892//testReport/\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/7892//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2014-09-04T06:02:51.582+0000","updated":"2014-09-04T06:02:51.582+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14121719","id":"14121719","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wheat9","name":"wheat9","key":"wheat9","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Haohui Mai","active":true,"timeZone":"America/Los_Angeles"},"body":"bq. I'm assuming you're saying it's fragile because the latest patch is parsing some exception text. I agree that that sort of thing is in general fragile, and should be avoided.\n\nI'm glad that we have a consensus here.\n\nI do understand the concerns of upgrading the cluster. I handled the exact type of support case before, and I sincerely want the issue to be fixed. I even have no problem of putting in hacks.\n\n\nWhat I've been opposing in all my comments is to land this hack in {{WebHdfsFileSystem}}. That seems a very bad idea to me.\n\n\nPlease note that {{WebHdfsFileSystem}} has much wide audiences than distcp alone -- do you agree that the impact of the hack should be minimized, so that it won't complicate the contract of {{WebHdfsFileSystem}} too much and make it harder to maintain down the road?\n\nbq. Do you have some alternative that will allow for this fixed distcp to work with a cluster which is not running this change?\n\nDisclaimer: I haven't tried out the solutions below, but I think it should work. :-)\n\nDistcp collects the DTs when doing the listings. Later operations use these DTs to access the files. What can be done is to put the hack there, and to inject a corresponding token into token cache so that the filesystem no longer need to get the DT from the server. Conceptually you can think it as distcp grants itself a capability to access the insecure cluster.\n\nThat way (1) the fix can be restricted in distcp only, and (2) it is applicable for both webhdfs and hftp. \n\nPlease take a look at {{DistCp#createInputFileListing}}, {{SimpleCopyListing#validatePaths}}, and {{TokenCache.obtainTokensForNamenodes()}} for more details.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wheat9","name":"wheat9","key":"wheat9","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Haohui Mai","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-09-04T18:25:07.102+0000","updated":"2014-09-04T18:25:07.102+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14122524","id":"14122524","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"HI [~wheat9],\n\nThanks for the comments. A recap of what we discussed so far:\n\n1. I think you agreed that returning null token is the right/reasonable approach. And sounds to me that you would be willing to give +1 if two comments are addressed: a), remove the message parsing hack,  b) add simplified tests about \n{quote}\ntesting whether WebHdfsFileSystem can get a null from an insecure cluster.\n{quote}\n\n2. We argued that although having the message parsing is hacky, we still want to do it to save big user pain. I think you are convinced about the need for this hack, except that you think the better place to add this hack is in distcp.  \n\nGiven that it's a hack for insecure cluster that's not upgraded with this fix, and we will remove this hack in the future when we don't need it, I prefer the simplicity of having this hack in webhdfs. \n\nYou stated if we fix distcp as you suggested (which you also said to be non-trivial earlier), then we don't have to change hftp.  In my opinion, changing hftp is trivial, and hftp seems to be the only other place we need to add a similar fix as webhdfs - which I planned to file another jira for that as mentioned before.  Actually hftp was already removed from trunk, and it only exists in branch-2.\n\n3. The latest patch rev (011) added the tests - thanks to your suggestion - and I think it's a more complete solution now. What about we file follow up jira for more discussion, given that a)  you  agreed on the null token solution if we remove the hack,  b) you agreed we do need a hack somewhere, and c) I think the hack will be removed when it's the time? \n\nThanks.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-09-05T06:56:35.474+0000","updated":"2014-09-05T06:56:35.474+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14123050","id":"14123050","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Some additional info [~wheat9]. Sorry for long post, but hopefully this gives more clarity. And I'd really appreciate that you could comment on my last and this comment at your earliest convenience.\n\n4.\n{quote}\nPlease note that WebHdfsFileSystem has much wide audiences than distcp alone – do you agree that the impact of the hack should be minimized, so that it won't complicate the contract of WebHdfsFileSystem too much and make it harder to maintain down the road?\n{quote}\nAbout the webhdfs contract you were referring to in the above comment:  we are supposed to be able to access insecure cluster from secure cluster side even if it's not distcp, is this not true?\n\nAssuming it's true, the problem is that, we currently see Exception with \"Failed to get the token ...\" message . In my opinion. this is not what the webhdfs contract should be, it's actually the bug we are dealing with. Fixing the bug at webhdfs (instead of throwing the exception, trying to understand that the exception meant null token thus insecure cluster) actually seems necessary to me. So I don't understand why this complicates the contract of webhdfs. We had consensus that the hack is needed to save user's big pain. Again, this msg-parsing hack is only executed when accessing cluster not upgraded with this fix, and the hack will be removed in the future, so the impact seems minimum to me. \n\nIf you disagree, would you please describe a specific example scenario that this would make it harder to maintain?\n\n5. \n{quote}\nDistcp collects the DTs when doing the listings. Later operations use these DTs to access the files. What can be done is to put the hack there, and to inject a corresponding token into token cache so that the filesystem no longer need to get the DT from the server. Conceptually you can think it as distcp grants itself a capability to access the insecure cluster.\n{quote}\nI think you were suggesting the dummy token approach rather than null token. Or maybe you meant to insert null token to token cache. You made the earlier comment saying we can have another jira for this discussion as quoted below, so I think we can do what you said, unless you changed mind:\n\n{quote}\nHowever, it's okay to me to return a null here so the behavior is similar to DistributedFileSystem. The actual fallback logic can happen at the distcp side when building the file list, but maybe we can defer it to another jira.\n{quote}\n\nThanks.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-09-05T15:33:29.326+0000","updated":"2014-09-05T15:33:29.326+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14123232","id":"14123232","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wheat9","name":"wheat9","key":"wheat9","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Haohui Mai","active":true,"timeZone":"America/Los_Angeles"},"body":"I've made it very clear that I'm opposed to put fragile hacks into {{WebHdfsFileSystem}}, though I'm okay if it's done at the application level (e.g. distcp). Unless this is addressed, I cannot give my +1.\n\nIf you are not familiar with the distcp code, I'll take a look and see whether I can post a patch for it.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wheat9","name":"wheat9","key":"wheat9","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Haohui Mai","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-09-05T17:46:27.087+0000","updated":"2014-09-05T17:47:51.342+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14123333","id":"14123333","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi [~wheat9], \n\nI know that you are opposed to put the msg-parsing hack to webhdfs. However, you also have said:\n{quote}\nHowever, it's okay to me to return a null here so the behavior is similar to DistributedFileSystem. The actual fallback logic can happen at the distcp side when building the file list, but maybe we can defer it to another jira.\n{quote}\n\nI had quite some questions for you in my last two comments, I'd appreciate that you could comment on them. That way, we can understand more about your concern why it's so fragile as you said. \n\nDo you agree that a correct webhdfs contract is not to fail with the exception when accessing insecure cluster, rather, it should be able to access insecure cluster? This is a very important question that I hope you could answer.\n\nWe agree that the msg-parsing is a bit hacky, but why hack in webhdfs is so much worse than in distcp, given webhdfs doesn't work without a fix?\n\nBTW, FYI, not to say that it's good thing to do so, there was already code doing msg parsing in webhdfs:\n{code}\n      // extract UGI-related exceptions and unwrap InvalidToken\n      // the NN mangles these exceptions but the DN does not and may need\n      // to re-fetch a token if either report the token is expired\n      if (re.getMessage().startsWith(\"Failed to obtain user group information:\")) {\n        String[] parts = re.getMessage().split(\":\\\\s+\", 3);\n        re = new RemoteException(parts[1], parts[2]);\n        re = ((RemoteException)re).unwrapRemoteException(InvalidToken.class);\n      }\n{code}\nDo you consider this fragile?\n\nDisclaimer, In the patch I did here, it's not because there was existing code like quoted above. Rather it's because the solution has its simplicity which we discussed earlier.\n\nThanks.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-09-05T18:31:54.335+0000","updated":"2014-09-05T18:31:54.335+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14124537","id":"14124537","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Hello [~wheat9],\n\nAccessing insecure cluster via webhdfs from secure cluster is broken today, I claimed this should not be the right webhdfs contract (instead a bug) in my earlier comments. This problem is not just about distcp, but other applications too. Fixing webhdfs itself has the advantage that we don't have to fix all applications. I argued about this along the way, and would like to emphasize. \n\nI'd like to give an example here: if you issue \"hadoop fs -lsr webhdfs://<insecurecluster>\" from secure cluster side, you would see it fail the same way.  Fixing distcp as you proposed would not solve this, but my proposed solution does.\n\nThanks.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-09-06T15:39:46.968+0000","updated":"2014-09-06T15:39:46.968+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14124935","id":"14124935","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"[~wheat9],\n\nHope the example I gave is convincing that webhdfs is the right place to fix. I think we wouldn't want to tell user that \"sorry, webhdfs contract doesn't allow accessing insecure cluster from secure cluster, if you need to, please hack your application like how distcp does\". Would you please comment at your earliest convenience? Thanks.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-09-07T15:48:17.799+0000","updated":"2014-09-07T15:48:17.799+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14125800","id":"14125800","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wheat9","name":"wheat9","key":"wheat9","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Haohui Mai","active":true,"timeZone":"America/Los_Angeles"},"body":"bq. Hope the example I gave is convincing that webhdfs is the right place to fix.\n\nJust to reiterate, given the fact that {{WebHdfsFileSystem}} has much wider audiences other than {{distcp}}, the decision should be made by the application not by {{WebHdfsFileSystem}}. This is a design decision and it should not be violated by a hack, if you want to avoid long term pain.\n\nSee https://issues.apache.org/jira/browse/HDFS-6776?focusedCommentId=14121719&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14121719\n\nNote that I've mentioned this issue explicitly for multiple times -- and again, I cannot +1 until this is addressed.\n\nbq.  \"sorry, webhdfs contract doesn't allow accessing insecure cluster from secure cluster, if you need to, please hack your application like how distcp does\"\n\nSee https://issues.apache.org/jira/browse/HDFS-6776?focusedCommentId=14121719&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14121719\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wheat9","name":"wheat9","key":"wheat9","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Haohui Mai","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-09-08T17:40:00.955+0000","updated":"2014-09-08T17:40:00.955+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14125814","id":"14125814","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wheat9","name":"wheat9","key":"wheat9","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Haohui Mai","active":true,"timeZone":"America/Los_Angeles"},"body":"I suggest the following route to proceed on this jira:\n\n# Implement [~daryn]'s suggestion, that is, making {{WebHdfsFileSystem}} the same of {{DistributedFileSystem}} w.r.t. returning null in insecure clusters. This should be the ideal fix and at least allow distcp to work in clusters with this patch. I can +1 this fix.\n# Create another jira to discuss how to implement the fallback mechanism.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wheat9","name":"wheat9","key":"wheat9","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Haohui Mai","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-09-08T17:48:52.310+0000","updated":"2014-09-08T17:48:52.310+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14125871","id":"14125871","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Hello [~wheat9],\n\nJust want to clarify, I have already implemented [~daryn]'s suggestion in rev 011. Rev 011 also included the message parsing. What you are suggesting is, to take out the message parsing part. Would you please quickly confirm?\n\nI can certainly do that.  But just to reiterate, with what you suggested, in order to see the fix work, user need to upgrade both source and destination cluster with this fix, which could be quite a pain on user side.\n\nThanks.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-09-08T18:27:28.340+0000","updated":"2014-09-08T18:27:28.340+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14125872","id":"14125872","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jingzhao","name":"jingzhao","key":"jingzhao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jing Zhao","active":true,"timeZone":"America/Los_Angeles"},"body":"Since [~yzhangal]'s latest patch already contains the correct fix in #1, and this is very useful fix, maybe we can separate the fallback mechanism out and commit the fix first? In this way we can make faster progress I guess.\n\nFor the fallback mechanism, to keep it in WebHdfsFileSystem may be an overkill since currently in HDFS the main use case for accessing data across clusters in distcp. But we can discuss it in a separate jira.\n\nWhat do you think [~yzhangal]?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jingzhao","name":"jingzhao","key":"jingzhao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jing Zhao","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-09-08T18:30:01.561+0000","updated":"2014-09-08T18:30:01.561+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14125927","id":"14125927","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"HI [~jingzhao],\n\nThanks for your review and comment. Some more info here to share.\n\nIn rev 011, I did implement #1 (returning null token from insecure cluster). In addition, rev 011 contains fallback logic in webhdfs based on #1 (the null token returned from insecure cluster). \n\nOn top of that, a message parsing was added as part of the fallback logic, such that user doesn't have to upgrade insecure cluster. I agree that the the message parsing is a bit hacky and removing it is a cleaner solution. However, the trade-off is what we have been debating: to have the hack or to force user to upgrade insecure cluster. \n\nI certainly can drop the message parsing part if that's what we have to do here, although I think it doesn't hurt much to have this hack for the lots of user pain we could have saved (please also refer to HDFS-7026 which I created to make an existing msg parsing better). \n\nThanks a lot.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-09-08T19:03:25.580+0000","updated":"2014-09-08T19:03:25.580+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14125963","id":"14125963","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi [~wheat9],\n\nI just uploaded rev 012 which removed the msg parsing. Would you please take a look at it?\n\nI will file follow-up jira for fallback logic and other stuff, e.g., even issuing \"hadoop fs -lsr webhdfs://<insecureCluster>\" from secure cluster fails the same way.\n\nThanks.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-09-08T19:30:23.847+0000","updated":"2014-09-08T19:30:23.847+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14126222","id":"14126222","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12667216/HDFS-6776.012.nomsgparsing.patch\n  against trunk revision df8c84c.\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs:\n\n                  org.apache.hadoop.ha.TestActiveStandbyElectorRealZK\n                  org.apache.hadoop.ipc.TestCallQueueManager\n                  org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover\n                  org.apache.hadoop.hdfs.server.balancer.TestBalancerWithEncryptedTransfer\n\n    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/7952//testReport/\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/7952//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2014-09-08T22:34:22.577+0000","updated":"2014-09-08T22:34:22.577+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14126225","id":"14126225","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wheat9","name":"wheat9","key":"wheat9","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Haohui Mai","active":true,"timeZone":"America/Los_Angeles"},"body":"Since the remaining work is trivial, I just posted a patch so that webhdfs returns null for {{getDelegationToken()}} when security is disabled.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wheat9","name":"wheat9","key":"wheat9","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Haohui Mai","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-09-08T22:34:53.456+0000","updated":"2014-09-08T22:34:53.456+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14126339","id":"14126339","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12667262/HDFS-6776.013.patch\n  against trunk revision d989ac0.\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:\n\n                  org.apache.hadoop.hdfs.TestQuota\n                  org.apache.hadoop.hdfs.web.TestWebHdfsFileSystemContract\n\n    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/7957//testReport/\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/7957//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2014-09-09T00:00:46.128+0000","updated":"2014-09-09T00:00:46.128+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14126361","id":"14126361","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"HI [~wheat9],\n\nI noticed that you took out the config property that enables the fix. So distcp will silently accepts copy between secure and insecure cluster. Would anyone please comment if  this is acceptable? This property was actually initially brought up by you here and I like the idea, it reminds user what s/he is doing.\n\nI also noticed that you made some simplification to some code, I will take it as as a review suggestion with next rev.\n\nThanks.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-09-09T00:13:00.946+0000","updated":"2014-09-09T00:13:00.946+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14126388","id":"14126388","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=atm","name":"atm","key":"atm","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=atm&avatarId=14136","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=atm&avatarId=14136","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=atm&avatarId=14136","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=atm&avatarId=14136"},"displayName":"Aaron T. Myers","active":true,"timeZone":"America/Los_Angeles"},"body":"It's not acceptable to allow secure clients to fall back from secure to insecure communication without a configuration option to explicitly enable that. When we've discovered behavior such as this in the past, we've treated it as a security vulnerability. In fact, the config option that Yongjun referenced earlier was introduced in response to such a vulnerability. You can find more info about that here:\n\nhttp://web.nvd.nist.gov/view/vuln/detail?vulnId=CVE-2013-2192\n\nI'm fine going with the \"HDFS-6776.012.nomsgparsing.patch\" patch that Yongjun posted earlier. That contains a simple fix for the acute issue, doesn't include message text parsing that Haohui finds unacceptable, and does support configurably disabling the fallback.\n\nJing/Haohui - is that alright with you?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=atm","name":"atm","key":"atm","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=atm&avatarId=14136","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=atm&avatarId=14136","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=atm&avatarId=14136","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=atm&avatarId=14136"},"displayName":"Aaron T. Myers","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-09-09T00:33:14.503+0000","updated":"2014-09-09T00:33:14.503+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14126413","id":"14126413","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wheat9","name":"wheat9","key":"wheat9","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Haohui Mai","active":true,"timeZone":"America/Los_Angeles"},"body":"The v14 patch is a minimized version of the v12 patch from Yongjun.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wheat9","name":"wheat9","key":"wheat9","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Haohui Mai","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-09-09T00:55:36.558+0000","updated":"2014-09-09T00:55:36.558+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14126417","id":"14126417","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=atm","name":"atm","key":"atm","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=atm&avatarId=14136","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=atm&avatarId=14136","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=atm&avatarId=14136","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=atm&avatarId=14136"},"displayName":"Aaron T. Myers","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks, Haohui.\n\nYongjun - does this latest patch look OK to you?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=atm","name":"atm","key":"atm","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=atm&avatarId=14136","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=atm&avatarId=14136","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=atm&avatarId=14136","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=atm&avatarId=14136"},"displayName":"Aaron T. Myers","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-09-09T00:58:24.984+0000","updated":"2014-09-09T00:58:24.984+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14126538","id":"14126538","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi [~atm], thanks for commenting on the fallback config thing. I'm glad that we have an agreement here.\n\nHi [~wheat9], \n\nThanks for the patches you posted. Great to see that we are getting so close to commit now. I saw one issue with the test code in rev 014, I posted rev 015 to address it. The issue is, if other IOException than the one we expect is thrown (for example, when building the cluster), the test would still succeed.\n\nThanks again for your earlier comments which helped to drive to a more complete solution here.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-09-09T03:38:45.666+0000","updated":"2014-09-09T03:38:45.666+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14126552","id":"14126552","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12667308/HDFS-6776.014.patch\n  against trunk revision 7498dd7.\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:\n\n                  org.apache.hadoop.hdfs.server.balancer.TestBalancerWithSaslDataTransfer\n\n    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/7962//testReport/\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/7962//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2014-09-09T03:50:12.855+0000","updated":"2014-09-09T03:50:12.855+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14126598","id":"14126598","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12667335/HDFS-6776.015.patch\n  against trunk revision 7498dd7.\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:\n\n                  org.apache.hadoop.hdfs.web.TestWebHdfsFileSystemContract\n\n    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/7964//testReport/\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/7964//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2014-09-09T04:55:24.428+0000","updated":"2014-09-09T04:55:24.428+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14127045","id":"14127045","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi [~wheat9] and [~jingzhao],\n\nI just uploaded rev 016 for another minor change. I just found that [~atm] is on vacation today. Would you please take a look to see if it looks good to you and help commit if so? thanks a lot.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-09-09T14:42:59.336+0000","updated":"2014-09-09T14:42:59.336+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14127116","id":"14127116","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=daryn","name":"daryn","key":"daryn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Daryn Sharp","active":true,"timeZone":"America/Chicago"},"body":"Instead of an {{IOException}}, it should probably throw {{AccessControlException}} to avoid unnecessary retries that are doomed to fail.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=daryn","name":"daryn","key":"daryn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Daryn Sharp","active":true,"timeZone":"America/Chicago"},"created":"2014-09-09T15:36:42.378+0000","updated":"2014-09-09T15:36:42.378+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14127150","id":"14127150","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi [~daryn], thanks for the good suggestion. Uploaded rev 017 to address it!\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-09-09T16:04:39.691+0000","updated":"2014-09-09T16:04:39.691+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14127262","id":"14127262","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12667422/HDFS-6776.016.patch\n  against trunk revision 90c8ece.\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:\n\n                  org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover\n\n    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/7966//testReport/\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/7966//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2014-09-09T17:25:10.721+0000","updated":"2014-09-09T17:25:10.721+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14127399","id":"14127399","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12667435/HDFS-6776.017.patch\n  against trunk revision 90c8ece.\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:\n\n                  org.apache.hadoop.hdfs.server.blockmanagement.TestBlockTokenWithDFS\n                  org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover\n\n    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/7967//testReport/\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/7967//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2014-09-09T18:56:26.983+0000","updated":"2014-09-09T18:56:26.983+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14127543","id":"14127543","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tucu00","name":"tucu00","key":"tucu00","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Alejandro Abdelnur","active":true,"timeZone":"Europe/Madrid"},"body":"+1. Patch v17 LGTM. \n\nIMO it will be a pita for users with multiple clusters the fact that we are not parsing the exception message. Please lets have a follow up JIRA for it.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tucu00","name":"tucu00","key":"tucu00","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Alejandro Abdelnur","active":true,"timeZone":"Europe/Madrid"},"created":"2014-09-09T21:01:05.287+0000","updated":"2014-09-09T21:01:05.287+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14127545","id":"14127545","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tucu00","name":"tucu00","key":"tucu00","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Alejandro Abdelnur","active":true,"timeZone":"Europe/Madrid"},"body":"[~wheat9], do you have any concern with the patch v17? Else I'd like to commit it by EOD PST today.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tucu00","name":"tucu00","key":"tucu00","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Alejandro Abdelnur","active":true,"timeZone":"Europe/Madrid"},"created":"2014-09-09T21:02:24.866+0000","updated":"2014-09-09T21:02:24.866+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14127557","id":"14127557","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks [~tucu00]!\n\nHi  [~wheat9], [~jingzhao], thanks for your review and comments. I will certainly file follow-up jira for further discussion of related issues. Thanks.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-09-09T21:08:17.761+0000","updated":"2014-09-09T21:08:17.761+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14127891","id":"14127891","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wheat9","name":"wheat9","key":"wheat9","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Haohui Mai","active":true,"timeZone":"America/Los_Angeles"},"body":"{code}\n+  @VisibleForTesting\n+  public static final String CANT_FALLBACK_TO_INSECURE_MSG =\n+      \"The client is configured to only allow connecting to secure cluster\";\n+\n+ catch (AccessControlException ace) {\n+      Assert.assertTrue(ace.getMessage().startsWith(\n+          WebHdfsFileSystem.CANT_FALLBACK_TO_INSECURE_MSG));\n{code}\n\nPlease inline the string. It is sufficient to do it through {{@Test(expected=AccessControlException.class)}}.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wheat9","name":"wheat9","key":"wheat9","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Haohui Mai","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-09-10T01:31:57.683+0000","updated":"2014-09-10T01:31:57.683+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14127950","id":"14127950","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi [~wheat9],\n\nIn the following three statements, if any of the first two failed with IOException, the test would succeed instead of fail. If the third one failed for a different reason and throw exception, the test would still succeed. That's wrong behavior. My way of doing it made it succeed only when when we get the expected exception, don't you agree it's more accurate? Please explain why you think it's not more accurate otherwise.\n{code}\n      1. cluster = new MiniDFSCluster.Builder(conf).numDataNodes(0).build();\n      2. final FileSystem webHdfs = WebHdfsTestUtil.getWebHdfsFileSystem(conf,\n          WebHdfsFileSystem.SCHEME);\n      3. webHdfs.getDelegationToken(null);\n{code}\n\nThanks.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-09-10T02:16:49.485+0000","updated":"2014-09-10T02:16:49.485+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14127960","id":"14127960","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"BTW Haohui, I recalled that we debated on a very similar thing in a different jira a while back, and you seemed to be convinced there:\n\nhttps://issues.apache.org/jira/browse/HDFS-5939\nHaohui Mai added a comment - 21/Feb/14 13:50\n\nThanks.\n\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-09-10T02:32:20.509+0000","updated":"2014-09-10T02:32:20.509+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14128002","id":"14128002","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"One correction Haohui, you were talking about AccessControlException. When you read my prior comments, please replace IOException with AccessControlException,  which could be thrown with different message too. The point is, the test only succeeds with the expected exception, and fails otherwise. Thus it's more accurate. Please refer to HDFS-5939 for a similar discussion there.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-09-10T03:40:02.914+0000","updated":"2014-09-10T03:40:02.914+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14128003","id":"14128003","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tucu00","name":"tucu00","key":"tucu00","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Alejandro Abdelnur","active":true,"timeZone":"Europe/Madrid"},"body":"I'll commit this momentarily, if there are further discussions on how to make the testcase more accurate we can follow up in a new JIRA.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tucu00","name":"tucu00","key":"tucu00","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Alejandro Abdelnur","active":true,"timeZone":"Europe/Madrid"},"created":"2014-09-10T03:40:33.042+0000","updated":"2014-09-10T03:40:33.042+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14128053","id":"14128053","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wheat9","name":"wheat9","key":"wheat9","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Haohui Mai","active":true,"timeZone":"America/Los_Angeles"},"body":"{code}\nThe point is, the test only succeeds with the expected exception, and fails otherwise.\n{code}\n\nIn general it is a bad idea to make your test case depend on the exact message that the server is throwing out, since the message itself is not part of the contract but the class of the exception usually does.\n\nIt should be fine if you don't want to change it, but just for the record, the test is fragile.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wheat9","name":"wheat9","key":"wheat9","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Haohui Mai","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-09-10T05:02:56.863+0000","updated":"2014-09-10T05:02:56.863+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14128074","id":"14128074","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks Haohui. I think it's very common to see same type of exceptions thrown with different message (if this happens, the test would succeed, which is wrong), on the other hand,  it would be less common to have another exception of same type to have the exact same message. See I had used string constant to make it a contract. between the production code and test code. So I think having the message parsing is less fragile than without. Thanks.\n\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-09-10T05:22:31.584+0000","updated":"2014-09-10T05:22:31.584+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14128077","id":"14128077","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tucu00","name":"tucu00","key":"tucu00","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Alejandro Abdelnur","active":true,"timeZone":"Europe/Madrid"},"body":"Thanks YongJun and thanks Haohui for reviewing it.\n\nCommitted to trunk and branch-2.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tucu00","name":"tucu00","key":"tucu00","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Alejandro Abdelnur","active":true,"timeZone":"Europe/Madrid"},"created":"2014-09-10T05:26:31.417+0000","updated":"2014-09-10T05:26:31.417+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14128115","id":"14128115","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks a lot [~tucu00]!\n\nMany thanks to [~aw], [~tthompso], [~daryn], [~atm], [~wheat9], and [~jingzhao] for the review and comments.\n\nI just created HDFS-7036 and HDFS-7037 as follow-up.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-09-10T06:03:38.098+0000","updated":"2014-09-10T06:03:38.098+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14128356","id":"14128356","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"FAILURE: Integrated in Hadoop-Yarn-trunk #676 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/676/])\nHDFS-6776. Using distcp to copy data between insecure and secure cluster via webdhfs doesn't work. (yzhangal via tucu) (tucu: rev bbff44cb03d0150f990acc3b77170893241cc282)\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestWebHDFS.java\n* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/security/token/delegation/DelegationTokenSecretManager.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/web/resources/NamenodeWebHdfsMethods.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2014-09-10T11:23:23.653+0000","updated":"2014-09-10T11:23:23.653+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14128493","id":"14128493","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"SUCCESS: Integrated in Hadoop-Hdfs-trunk #1867 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1867/])\nHDFS-6776. Using distcp to copy data between insecure and secure cluster via webdhfs doesn't work. (yzhangal via tucu) (tucu: rev bbff44cb03d0150f990acc3b77170893241cc282)\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestWebHDFS.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/web/resources/NamenodeWebHdfsMethods.java\n* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/security/token/delegation/DelegationTokenSecretManager.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2014-09-10T14:04:08.632+0000","updated":"2014-09-10T14:04:08.632+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14128914","id":"14128914","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"FAILURE: Integrated in Hadoop-Mapreduce-trunk #1892 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1892/])\nHDFS-6776. Using distcp to copy data between insecure and secure cluster via webdhfs doesn't work. (yzhangal via tucu) (tucu: rev bbff44cb03d0150f990acc3b77170893241cc282)\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/web/resources/NamenodeWebHdfsMethods.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestWebHDFS.java\n* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/security/token/delegation/DelegationTokenSecretManager.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2014-09-10T18:45:33.712+0000","updated":"2014-09-10T18:45:33.712+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12730649/comment/14131676","id":"14131676","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"HI Folks on the watch list, \n\nAs [~tucu00] and [~atm] pointed out earlier that it's going to be quite a pain on user without a solution for HDFS-7036, and I agree. So I'm trying to see if we can converge to a solution there. Your comment in HDFS-7036 is very much appreciated. \n\nThanks.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-09-12T15:51:00.654+0000","updated":"2014-09-12T15:51:00.654+0000"}],"maxResults":129,"total":129,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-6776/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i1ybqv:"}}