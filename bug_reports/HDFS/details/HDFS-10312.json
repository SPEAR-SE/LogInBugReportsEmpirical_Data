{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12960120","self":"https://issues.apache.org/jira/rest/api/2/issue/12960120","key":"HDFS-10312","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12329057","id":"12329057","description":"2.8.0 release","name":"2.8.0","archived":false,"released":true,"releaseDate":"2017-03-22"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12335732","id":"12335732","description":"3.0.0-alpha1 release","name":"3.0.0-alpha1","archived":false,"released":true,"releaseDate":"2016-09-03"}],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2016-04-19T21:30:20.806+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Wed Apr 20 21:54:47 UTC 2016","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_132617_*|*_5_*:*_1_*:*_0_*|*_10002_*:*_1_*:*_87886944","customfield_12312321":null,"resolutiondate":"2016-04-20T21:02:59.580+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-10312/watchers","watchCount":12,"isWatching":false},"created":"2016-04-19T20:36:00.109+0000","customfield_12310192":null,"customfield_12310191":[{"self":"https://issues.apache.org/jira/rest/api/2/customFieldOption/10343","value":"Reviewed","id":"10343"}],"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"4.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[],"issuelinks":[{"id":"12464129","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12464129","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"inwardIssue":{"id":"12960160","key":"HADOOP-13039","self":"https://issues.apache.org/jira/rest/api/2/issue/12960160","fields":{"summary":"Add documentation for configuration property ipc.maximum.data.length for controlling maximum RPC message size.","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/4","id":"4","description":"An improvement or enhancement to an existing feature or task.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype","name":"Improvement","subtask":false,"avatarId":21140}}}},{"id":"12465315","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12465315","type":{"id":"12310050","name":"Regression","inward":"is broken by","outward":"breaks","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/12310050"},"outwardIssue":{"id":"12963980","key":"HDFS-10349","self":"https://issues.apache.org/jira/rest/api/2/issue/12963980","fields":{"summary":"Ozone: StorageContainerManager fails to compile after merge of HDFS-10312 maxDataLength enforcement.","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/7","id":"7","description":"The sub-task of the issue","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype","name":"Sub-task","subtask":true,"avatarId":21146}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2016-08-30T01:16:45.868+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12312926","id":"12312926","name":"namenode"}],"timeoriginalestimate":null,"description":"Our RPC server caps the maximum size of incoming messages at 64 MB by default.  For exceptional circumstances, this can be uptuned using {{ipc.maximum.data.length}}.  However, for block reports, there is still an internal maximum length restriction of 64 MB enforced by protobuf.  (Sample stack trace to follow in comments.)  This issue proposes to apply the same override to our block list decoding, so that large block reports can proceed.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12329057","id":"12329057","description":"2.8.0 release","name":"2.8.0","archived":false,"released":true,"releaseDate":"2017-03-22"}],"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12799578","id":"12799578","filename":"HDFS-10312.001.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-04-19T20:37:57.571+0000","size":21832,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12799578/HDFS-10312.001.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12799603","id":"12799603","filename":"HDFS-10312.002.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-04-19T21:44:12.292+0000","size":21908,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12799603/HDFS-10312.002.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12799611","id":"12799611","filename":"HDFS-10312.003.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-04-19T22:19:18.841+0000","size":23647,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12799611/HDFS-10312.003.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12799621","id":"12799621","filename":"HDFS-10312.004.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-04-19T22:59:17.702+0000","size":23857,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12799621/HDFS-10312.004.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"Large block reports may fail to decode at NameNode due to 64 MB protobuf maximum length restriction.","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12960120/comment/15248577","id":"15248577","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"body":"I saw this happen with a block report from a DataNode containing ~6 million blocks.  All blocks were on a single data directory, so unfortunately, the block report splitting by storage didn't help.  Here is a sample stack trace:\n\n{code}\norg.apache.hadoop.ipc.RemoteException: java.lang.IllegalStateException: com.google.protobuf.InvalidProtocolBufferException: Protocol message was too large.  May be malicious.  Use CodedInputStream.setSizeLimit() to increase the size limit.\n\tat org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.runBlockOp(BlockManager.java:4404)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.blockReport(NameNodeRpcServer.java:1436)\n\tat org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolServerSideTranslatorPB.blockReport(DatanodeProtocolServerSideTranslatorPB.java:173)\n\tat org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$DatanodeProtocolService$2.callBlockingMethod(DatanodeProtocolProtos.java:30059)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:637)\n\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)\n\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2423)\n\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2419)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:415)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1742)\n\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2417)\nCaused by: java.lang.IllegalStateException: com.google.protobuf.InvalidProtocolBufferException: Protocol message was too large.  May be malicious.  Use CodedInputStream.setSizeLimit() to increase the size limit.\n\tat org.apache.hadoop.hdfs.protocol.BlockListAsLongs$BufferDecoder$1.next(BlockListAsLongs.java:369)\n\tat org.apache.hadoop.hdfs.protocol.BlockListAsLongs$BufferDecoder$1.next(BlockListAsLongs.java:347)\n\tat org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.reportDiffSorted(BlockManager.java:2478)\n\tat org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.processReport(BlockManager.java:2313)\n\tat org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.processReport(BlockManager.java:2121)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer$1.call(NameNodeRpcServer.java:1439)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer$1.call(NameNodeRpcServer.java:1436)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\n\tat org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$BlockReportProcessingThread.processQueue(BlockManager.java:4463)\n\tat org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$BlockReportProcessingThread.run(BlockManager.java:4442)\nCaused by: com.google.protobuf.InvalidProtocolBufferException: Protocol message was too large.  May be malicious.  Use CodedInputStream.setSizeLimit() to increase the size limit.\n\tat com.google.protobuf.InvalidProtocolBufferException.sizeLimitExceeded(InvalidProtocolBufferException.java:110)\n\tat com.google.protobuf.CodedInputStream.refillBuffer(CodedInputStream.java:755)\n\tat com.google.protobuf.CodedInputStream.readRawByte(CodedInputStream.java:769)\n\tat com.google.protobuf.CodedInputStream.readRawVarint64(CodedInputStream.java:462)\n\tat org.apache.hadoop.hdfs.protocol.BlockListAsLongs$BufferDecoder$1.next(BlockListAsLongs.java:365)\n\t... 9 more\n\n\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1443)\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1402)\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1352)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:230)\n\tat com.sun.proxy.$Proxy21.blockReport(Unknown Source)\n\tat org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.blockReport(DatanodeProtocolClientSideTranslatorPB.java:204)\n\tat org.apache.hadoop.hdfs.server.datanode.TestLargeBlockReport.testBlockReportSucceedsWithLargerLengthLimit(TestLargeBlockReport.java:86)\n{code}\n\nThis is an unusual situation, but we should provide a way for it to succeed.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-04-19T20:36:24.387+0000","updated":"2016-04-19T20:36:24.387+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12960120/comment/15248581","id":"15248581","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"body":"The attached patch passes the value of {{ipc.maximum.data.length}} through to the block list decoding layer, and then applies it as an override to the protobuf classes.  I considered introducing a new configuration property, but ultimately I decided against it, because the admin would just have to tune 2 things in sync if they encountered this problem.  I maintained a few of the old method signatures that don't include the max length and annotated them {{VisibleForTesting}} to avoid larger impact on existing tests.  The new test suite demonstrates the problem and the fix.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-04-19T20:37:57.585+0000","updated":"2016-04-19T20:37:57.585+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12960120/comment/15248696","id":"15248696","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xyao","name":"xyao","key":"xyao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xiaoyu Yao","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks [~cnauroth] for posting the fix along with your analysis. The patch looks good to me. +1 pending Jenkins.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xyao","name":"xyao","key":"xyao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xiaoyu Yao","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-04-19T21:30:20.806+0000","updated":"2016-04-19T21:30:20.806+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12960120/comment/15248712","id":"15248712","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xyao","name":"xyao","key":"xyao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xiaoyu Yao","active":true,"timeZone":"America/Los_Angeles"},"body":"As a follow up, I suggest we document this *ipc.maximum.data.length* key. Currently, I can't find information about it in the core-default.xml.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xyao","name":"xyao","key":"xyao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xiaoyu Yao","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-04-19T21:35:25.885+0000","updated":"2016-04-19T21:35:25.885+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12960120/comment/15248713","id":"15248713","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=liuml07","name":"liuml07","key":"liuml07","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=liuml07&avatarId=29203","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=liuml07&avatarId=29203","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=liuml07&avatarId=29203","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=liuml07&avatarId=29203"},"displayName":"Mingliang Liu","active":true,"timeZone":"America/Los_Angeles"},"body":"+1 (non-binding)\n\nOne nit is that, in the unit test {{testBlockReportExceedsLengthLimit()}}, we can add a {{fail(\"Should have failed because of the too long RPC data length\");}} as the last statement of the {{try}} block.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=liuml07","name":"liuml07","key":"liuml07","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=liuml07&avatarId=29203","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=liuml07&avatarId=29203","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=liuml07&avatarId=29203","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=liuml07&avatarId=29203"},"displayName":"Mingliang Liu","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-04-19T21:35:38.480+0000","updated":"2016-04-19T21:35:38.480+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12960120/comment/15248729","id":"15248729","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"body":"[~liuml07] and [~xyao], thank you for the code reviews.  That's a great catch on the lack of {{fail}} in the test.  I'm attaching patch v002 with the fix.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-04-19T21:44:12.295+0000","updated":"2016-04-19T21:44:12.295+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12960120/comment/15248802","id":"15248802","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"body":"Here is patch v003 with one more change in the test.  I found that all of the bogus block IDs were causing a lot of log spam and slowing down the test, particularly for the block state change messages and the {{FsDatasetImpl}} \"Failed to delete replica\" messages.  I've changed the test to set log level to WARN for these.  That skips the log spam and speeds up the test quite a bit.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-04-19T22:19:18.845+0000","updated":"2016-04-19T22:19:18.845+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12960120/comment/15248807","id":"15248807","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=liuml07","name":"liuml07","key":"liuml07","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=liuml07&avatarId=29203","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=liuml07&avatarId=29203","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=liuml07&avatarId=29203","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=liuml07&avatarId=29203"},"displayName":"Mingliang Liu","active":true,"timeZone":"America/Los_Angeles"},"body":"Shall we create a new jira for this?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=liuml07","name":"liuml07","key":"liuml07","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=liuml07&avatarId=29203","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=liuml07&avatarId=29203","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=liuml07&avatarId=29203","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=liuml07&avatarId=29203"},"displayName":"Mingliang Liu","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-04-19T22:24:45.082+0000","updated":"2016-04-19T22:24:45.082+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12960120/comment/15248813","id":"15248813","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"body":"Yes, that's going to be a small change, but technically it should be grouped as a HADOOP JIRA, not HDFS.  I created HADOOP-13039.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-04-19T22:34:04.897+0000","updated":"2016-04-19T22:34:04.897+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12960120/comment/15248830","id":"15248830","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 11s {color} | {color:blue} Docker mode activated. {color} |\n| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green} 0m 0s {color} | {color:green} The patch appears to include 1 new or modified test files. {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 6m 44s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 0m 40s {color} | {color:green} trunk passed with JDK v1.8.0_77 {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 0m 42s {color} | {color:green} trunk passed with JDK v1.7.0_95 {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 24s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 0m 52s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 13s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 1m 56s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 8s {color} | {color:green} trunk passed with JDK v1.8.0_77 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 46s {color} | {color:green} trunk passed with JDK v1.7.0_95 {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 0m 46s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 0m 36s {color} | {color:green} the patch passed with JDK v1.8.0_77 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 0m 36s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 0m 39s {color} | {color:green} the patch passed with JDK v1.7.0_95 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 0m 39s {color} | {color:green} the patch passed {color} |\n| {color:red}-1{color} | {color:red} checkstyle {color} | {color:red} 0m 21s {color} | {color:red} hadoop-hdfs-project/hadoop-hdfs: patch generated 3 new + 244 unchanged - 1 fixed = 247 total (was 245) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 0m 50s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 11s {color} | {color:green} the patch passed {color} |\n| {color:red}-1{color} | {color:red} whitespace {color} | {color:red} 0m 0s {color} | {color:red} The patch has 1 line(s) that end in whitespace. Use git apply --whitespace=fix. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 2m 9s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 4s {color} | {color:green} the patch passed with JDK v1.8.0_77 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 46s {color} | {color:green} the patch passed with JDK v1.7.0_95 {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 31m 25s {color} | {color:red} hadoop-hdfs in the patch failed with JDK v1.8.0_77. {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 0m 34s {color} | {color:red} hadoop-hdfs in the patch failed with JDK v1.7.0_95. {color} |\n| {color:red}-1{color} | {color:red} asflicense {color} | {color:red} 0m 22s {color} | {color:red} Patch generated 1 ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black} 57m 29s {color} | {color:black} {color} |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:fbe3e86 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12799603/HDFS-10312.002.patch |\n| JIRA Issue | HDFS-10312 |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux 677ff777c2a3 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / af9bdbe |\n| Default Java | 1.7.0_95 |\n| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_77 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_95 |\n| findbugs | v3.0.0 |\n| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/15200/artifact/patchprocess/diff-checkstyle-hadoop-hdfs-project_hadoop-hdfs.txt |\n| whitespace | https://builds.apache.org/job/PreCommit-HDFS-Build/15200/artifact/patchprocess/whitespace-eol.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/15200/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.8.0_77.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/15200/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.7.0_95.txt |\n| JDK v1.7.0_95  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/15200/testReport/ |\n| asflicense | https://builds.apache.org/job/PreCommit-HDFS-Build/15200/artifact/patchprocess/patch-asflicense-problems.txt |\n| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/15200/console |\n| Powered by | Apache Yetus 0.2.0   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2016-04-19T22:44:52.848+0000","updated":"2016-04-19T22:44:52.848+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12960120/comment/15248854","id":"15248854","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"body":"Patch v004 addresses the Checkstyle warnings.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-04-19T22:59:17.706+0000","updated":"2016-04-19T22:59:17.706+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12960120/comment/15248924","id":"15248924","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=arpitagarwal","name":"arpitagarwal","key":"arpitagarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arpit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi [~cnauroth], +1 for the v4 patch. Thanks for this improvement.\n\nThe attached test-delta.patch reduces the test runtime from ~30 seconds to ~3 seconds by using a lower message size limit. What do you think?\n\nAlso (and Chris etc. know this of course!), it is far from ideal to have ~6 million blocks on one storage directory. We should add a warning when we document this setting.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=arpitagarwal","name":"arpitagarwal","key":"arpitagarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arpit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-04-19T23:34:47.041+0000","updated":"2016-04-19T23:34:47.041+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12960120/comment/15248935","id":"15248935","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 0s {color} | {color:blue} Docker mode activated. {color} |\n| {color:red}-1{color} | {color:red} patch {color} | {color:red} 0m 15s {color} | {color:red} HDFS-10312 does not apply to trunk. Rebase required? Wrong Branch? See https://wiki.apache.org/hadoop/HowToContribute for help. {color} |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12799625/test-delta.patch |\n| JIRA Issue | HDFS-10312 |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/15207/console |\n| Powered by | Apache Yetus 0.2.0   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2016-04-19T23:39:23.630+0000","updated":"2016-04-19T23:39:23.630+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12960120/comment/15248947","id":"15248947","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=arpitagarwal","name":"arpitagarwal","key":"arpitagarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arpit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"body":"Pasting the delta inline to avoid confusing Jenkins. I'll kick off a build manually.\n{code}\ndiff --git a/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestLargeBlockReport.java b/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestLargeBlockReport.java\nindex bd9c0a2..0dff33f 100644\n--- a/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestLargeBlockReport.java\n+++ b/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestLargeBlockReport.java\n@@ -74,10 +74,10 @@ public void tearDown() {\n \n   @Test\n   public void testBlockReportExceedsLengthLimit() throws Exception {\n-    initCluster();\n+    initCluster(1024 * 1024);\n     // Create a large enough report that we expect it will go beyond the RPC\n     // server's length validation, and also protobuf length validation.\n-    StorageBlockReport[] reports = createReports(6000000);\n+    StorageBlockReport[] reports = createReports(200000);\n     try {\n       nnProxy.blockReport(bpRegistration, bpId, reports,\n           new BlockReportContext(1, 0, reportId, fullBrLeaseId, sorted));\n@@ -91,9 +91,8 @@ public void testBlockReportExceedsLengthLimit() throws Exception {\n \n   @Test\n   public void testBlockReportSucceedsWithLargerLengthLimit() throws Exception {\n-    conf.setInt(IPC_MAXIMUM_DATA_LENGTH, 128 * 1024 * 1024); // 128 MB\n-    initCluster();\n-    StorageBlockReport[] reports = createReports(6000000);\n+    initCluster(2 * 1024 * 1024);\n+    StorageBlockReport[] reports = createReports(200000);\n     nnProxy.blockReport(bpRegistration, bpId, reports,\n         new BlockReportContext(1, 0, reportId, fullBrLeaseId, sorted));\n   }\n@@ -129,7 +128,8 @@ public void testBlockReportSucceedsWithLargerLengthLimit() throws Exception {\n    *\n    * @throws Exception if initialization fails\n    */\n-  private void initCluster() throws Exception {\n+  private void initCluster(int ipcMaxDataLength) throws Exception {\n+    conf.setInt(IPC_MAXIMUM_DATA_LENGTH, ipcMaxDataLength);\n     cluster = new MiniDFSCluster.Builder(conf).numDataNodes(1).build();\n     cluster.waitActive();\n     dn = cluster.getDataNodes().get(0);\n{code}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=arpitagarwal","name":"arpitagarwal","key":"arpitagarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arpit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-04-19T23:46:07.719+0000","updated":"2016-04-19T23:46:07.719+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12960120/comment/15248984","id":"15248984","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"body":"[~arpitagarwal], I like your suggestion for speeding up the test.  Unfortunately, I think this doesn't quite give us the same test coverage.  To demonstrate this, apply patch v004, then revert the src/main changes, and then run the test.  It will fail on a protobuf decoding exception.  That's exactly the condition we want to test, and the src/main changes make the test pass.  After applying the delta, that's no longer true.  The test passes with or without the src/main changes.  That's because with the smaller block report sizes, we don't hit the internal protobuf default of 64 MB maximum.  Using a block report size of 6000000, we definitely push over 64 MB for the RPC message size, so we definitely trigger the right condition.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-04-20T00:05:36.775+0000","updated":"2016-04-20T00:05:36.775+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12960120/comment/15249007","id":"15249007","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 15s {color} | {color:blue} Docker mode activated. {color} |\n| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green} 0m 0s {color} | {color:green} The patch appears to include 1 new or modified test files. {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 6m 49s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 0m 40s {color} | {color:green} trunk passed with JDK v1.8.0_77 {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 0m 44s {color} | {color:green} trunk passed with JDK v1.7.0_95 {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 27s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 0m 55s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 15s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 2m 0s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 8s {color} | {color:green} trunk passed with JDK v1.8.0_77 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 48s {color} | {color:green} trunk passed with JDK v1.7.0_95 {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 0m 51s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 0m 40s {color} | {color:green} the patch passed with JDK v1.8.0_77 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 0m 40s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 0m 40s {color} | {color:green} the patch passed with JDK v1.7.0_95 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 0m 40s {color} | {color:green} the patch passed {color} |\n| {color:red}-1{color} | {color:red} checkstyle {color} | {color:red} 0m 20s {color} | {color:red} hadoop-hdfs-project/hadoop-hdfs: patch generated 3 new + 244 unchanged - 1 fixed = 247 total (was 245) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 0m 52s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 11s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green} 0m 0s {color} | {color:green} Patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 2m 15s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 7s {color} | {color:green} the patch passed with JDK v1.8.0_77 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 52s {color} | {color:green} the patch passed with JDK v1.7.0_95 {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 73m 40s {color} | {color:red} hadoop-hdfs in the patch failed with JDK v1.8.0_77. {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 69m 53s {color} | {color:red} hadoop-hdfs in the patch failed with JDK v1.7.0_95. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green} 0m 20s {color} | {color:green} Patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black} 169m 55s {color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| JDK v1.8.0_77 Failed junit tests | hadoop.hdfs.TestFileAppend |\n|   | hadoop.hdfs.server.namenode.TestNamenodeRetryCache |\n|   | hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA |\n| JDK v1.7.0_95 Failed junit tests | hadoop.hdfs.TestHFlush |\n|   | hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl |\n|   | hadoop.hdfs.server.namenode.TestNamenodeRetryCache |\n|   | hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA |\n|   | hadoop.hdfs.server.datanode.TestFsDatasetCache |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:fbe3e86 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12799578/HDFS-10312.001.patch |\n| JIRA Issue | HDFS-10312 |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux 55397ea62d2d 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / af9bdbe |\n| Default Java | 1.7.0_95 |\n| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_77 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_95 |\n| findbugs | v3.0.0 |\n| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/15199/artifact/patchprocess/diff-checkstyle-hadoop-hdfs-project_hadoop-hdfs.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/15199/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.8.0_77.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/15199/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.7.0_95.txt |\n| unit test logs |  https://builds.apache.org/job/PreCommit-HDFS-Build/15199/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.8.0_77.txt https://builds.apache.org/job/PreCommit-HDFS-Build/15199/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.7.0_95.txt |\n| JDK v1.7.0_95  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/15199/testReport/ |\n| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/15199/console |\n| Powered by | Apache Yetus 0.2.0   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2016-04-20T00:16:00.130+0000","updated":"2016-04-20T00:16:00.130+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12960120/comment/15249030","id":"15249030","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=arpitagarwal","name":"arpitagarwal","key":"arpitagarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arpit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"body":"Yeah I agree that is rather unfortunate since the change to the message length is not plumbed without your patch.\n\nI think the missing code paths can be tested with a targeted pre-condition that ensures any change to the config setting is propagated to the BufferDecoder (and the CodedInputStream) and that pre-condition will fail without your src/main changes. However it's okay to evaluate it in a follow up Jira and we don't need to hold up this one.\n\n+1 from me.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=arpitagarwal","name":"arpitagarwal","key":"arpitagarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arpit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-04-20T00:30:54.364+0000","updated":"2016-04-20T00:30:54.364+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12960120/comment/15249060","id":"15249060","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 10s {color} | {color:blue} Docker mode activated. {color} |\n| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green} 0m 0s {color} | {color:green} The patch appears to include 2 new or modified test files. {color} |\n| {color:red}-1{color} | {color:red} mvninstall {color} | {color:red} 5m 31s {color} | {color:red} root in trunk failed. {color} |\n| {color:red}-1{color} | {color:red} compile {color} | {color:red} 0m 9s {color} | {color:red} hadoop-hdfs in trunk failed with JDK v1.8.0_77. {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 0m 42s {color} | {color:green} trunk passed with JDK v1.7.0_95 {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 23s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 0m 48s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 13s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 1m 53s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 5s {color} | {color:green} trunk passed with JDK v1.8.0_77 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 44s {color} | {color:green} trunk passed with JDK v1.7.0_95 {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 0m 45s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 0m 39s {color} | {color:green} the patch passed with JDK v1.8.0_77 {color} |\n| {color:red}-1{color} | {color:red} javac {color} | {color:red} 6m 18s {color} | {color:red} hadoop-hdfs-project_hadoop-hdfs-jdk1.8.0_77 with JDK v1.8.0_77 generated 33 new + 0 unchanged - 0 fixed = 33 total (was 0) {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 0m 39s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 0m 38s {color} | {color:green} the patch passed with JDK v1.7.0_95 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 0m 38s {color} | {color:green} the patch passed {color} |\n| {color:red}-1{color} | {color:red} checkstyle {color} | {color:red} 0m 20s {color} | {color:red} hadoop-hdfs-project/hadoop-hdfs: patch generated 3 new + 244 unchanged - 1 fixed = 247 total (was 245) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 0m 48s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 11s {color} | {color:green} the patch passed {color} |\n| {color:red}-1{color} | {color:red} whitespace {color} | {color:red} 0m 0s {color} | {color:red} The patch has 476 line(s) that end in whitespace. Use git apply --whitespace=fix. {color} |\n| {color:red}-1{color} | {color:red} whitespace {color} | {color:red} 0m 9s {color} | {color:red} The patch has 384 line(s) with tabs. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 2m 6s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 3s {color} | {color:green} the patch passed with JDK v1.8.0_77 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 45s {color} | {color:green} the patch passed with JDK v1.7.0_95 {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 60m 4s {color} | {color:red} hadoop-hdfs in the patch failed with JDK v1.8.0_77. {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 59m 25s {color} | {color:red} hadoop-hdfs in the patch failed with JDK v1.7.0_95. {color} |\n| {color:red}-1{color} | {color:red} asflicense {color} | {color:red} 0m 23s {color} | {color:red} Patch generated 1 ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black} 143m 10s {color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| JDK v1.8.0_77 Failed junit tests | hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl |\n|   | hadoop.hdfs.server.namenode.TestNamenodeRetryCache |\n|   | hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA |\n| JDK v1.7.0_95 Failed junit tests | hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl |\n|   | hadoop.hdfs.TestHFlush |\n|   | hadoop.hdfs.shortcircuit.TestShortCircuitCache |\n|   | hadoop.hdfs.server.namenode.TestEditLog |\n|   | hadoop.hdfs.server.namenode.TestNamenodeRetryCache |\n|   | hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:fbe3e86 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12799611/HDFS-10312.003.patch |\n| JIRA Issue | HDFS-10312 |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux c931bce5be3e 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / af9bdbe |\n| Default Java | 1.7.0_95 |\n| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_77 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_95 |\n| mvninstall | https://builds.apache.org/job/PreCommit-HDFS-Build/15203/artifact/patchprocess/branch-mvninstall-root.txt |\n| compile | https://builds.apache.org/job/PreCommit-HDFS-Build/15203/artifact/patchprocess/branch-compile-hadoop-hdfs-project_hadoop-hdfs-jdk1.8.0_77.txt |\n| findbugs | v3.0.0 |\n| javac | hadoop-hdfs-project_hadoop-hdfs-jdk1.8.0_77: https://builds.apache.org/job/PreCommit-HDFS-Build/15203/artifact/patchprocess/diff-compile-javac-hadoop-hdfs-project_hadoop-hdfs-jdk1.8.0_77.txt |\n| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/15203/artifact/patchprocess/diff-checkstyle-hadoop-hdfs-project_hadoop-hdfs.txt |\n| whitespace | https://builds.apache.org/job/PreCommit-HDFS-Build/15203/artifact/patchprocess/whitespace-eol.txt |\n| whitespace | https://builds.apache.org/job/PreCommit-HDFS-Build/15203/artifact/patchprocess/whitespace-tabs.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/15203/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.8.0_77.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/15203/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.7.0_95.txt |\n| unit test logs |  https://builds.apache.org/job/PreCommit-HDFS-Build/15203/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.8.0_77.txt https://builds.apache.org/job/PreCommit-HDFS-Build/15203/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.7.0_95.txt |\n| JDK v1.7.0_95  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/15203/testReport/ |\n| asflicense | https://builds.apache.org/job/PreCommit-HDFS-Build/15203/artifact/patchprocess/patch-asflicense-problems.txt |\n| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/15203/console |\n| Powered by | Apache Yetus 0.2.0   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2016-04-20T01:01:37.328+0000","updated":"2016-04-20T01:01:37.328+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12960120/comment/15249106","id":"15249106","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 15s {color} | {color:blue} Docker mode activated. {color} |\n| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green} 0m 0s {color} | {color:green} The patch appears to include 2 new or modified test files. {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 7m 22s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 0m 55s {color} | {color:green} trunk passed with JDK v1.8.0_77 {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 0m 43s {color} | {color:green} trunk passed with JDK v1.7.0_95 {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 23s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 0m 56s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 14s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 2m 4s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 17s {color} | {color:green} trunk passed with JDK v1.8.0_77 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 56s {color} | {color:green} trunk passed with JDK v1.7.0_95 {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 0m 48s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 0m 49s {color} | {color:green} the patch passed with JDK v1.8.0_77 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 0m 49s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 0m 40s {color} | {color:green} the patch passed with JDK v1.7.0_95 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 0m 40s {color} | {color:green} the patch passed {color} |\n| {color:red}-1{color} | {color:red} checkstyle {color} | {color:red} 0m 22s {color} | {color:red} hadoop-hdfs-project/hadoop-hdfs: patch generated 3 new + 244 unchanged - 1 fixed = 247 total (was 245) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 0m 56s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 12s {color} | {color:green} the patch passed {color} |\n| {color:red}-1{color} | {color:red} whitespace {color} | {color:red} 0m 0s {color} | {color:red} The patch has 1 line(s) that end in whitespace. Use git apply --whitespace=fix. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 2m 15s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 16s {color} | {color:green} the patch passed with JDK v1.8.0_77 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 55s {color} | {color:green} the patch passed with JDK v1.7.0_95 {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 80m 35s {color} | {color:red} hadoop-hdfs in the patch failed with JDK v1.8.0_77. {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 95m 11s {color} | {color:red} hadoop-hdfs in the patch failed with JDK v1.7.0_95. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green} 0m 31s {color} | {color:green} Patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black} 204m 0s {color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| JDK v1.8.0_77 Failed junit tests | hadoop.hdfs.server.namenode.TestNamenodeRetryCache |\n|   | hadoop.hdfs.server.namenode.ha.TestEditLogTailer |\n|   | hadoop.hdfs.server.blockmanagement.TestBlockManager |\n|   | hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA |\n|   | hadoop.hdfs.TestFileAppend |\n|   | hadoop.hdfs.server.namenode.ha.TestDFSUpgradeWithHA |\n| JDK v1.7.0_95 Failed junit tests | hadoop.hdfs.server.namenode.TestNamenodeRetryCache |\n|   | hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA |\n|   | hadoop.hdfs.server.balancer.TestBalancerWithMultipleNameNodes |\n|   | hadoop.fs.TestSymlinkHdfsFileContext |\n|   | hadoop.hdfs.server.namenode.TestFileTruncate |\n| JDK v1.7.0_95 Timed out junit tests | org.apache.hadoop.hdfs.TestDatanodeRegistration |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:fbe3e86 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12799611/HDFS-10312.003.patch |\n| JIRA Issue | HDFS-10312 |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux c3401102ce70 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / af9bdbe |\n| Default Java | 1.7.0_95 |\n| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_77 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_95 |\n| findbugs | v3.0.0 |\n| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/15202/artifact/patchprocess/diff-checkstyle-hadoop-hdfs-project_hadoop-hdfs.txt |\n| whitespace | https://builds.apache.org/job/PreCommit-HDFS-Build/15202/artifact/patchprocess/whitespace-eol.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/15202/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.8.0_77.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/15202/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.7.0_95.txt |\n| unit test logs |  https://builds.apache.org/job/PreCommit-HDFS-Build/15202/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.8.0_77.txt https://builds.apache.org/job/PreCommit-HDFS-Build/15202/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.7.0_95.txt |\n| JDK v1.7.0_95  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/15202/testReport/ |\n| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/15202/console |\n| Powered by | Apache Yetus 0.2.0   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2016-04-20T01:44:14.627+0000","updated":"2016-04-20T01:44:14.627+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12960120/comment/15249123","id":"15249123","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 11s {color} | {color:blue} Docker mode activated. {color} |\n| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green} 0m 0s {color} | {color:green} The patch appears to include 2 new or modified test files. {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 7m 5s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 0m 40s {color} | {color:green} trunk passed with JDK v1.8.0_77 {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 0m 45s {color} | {color:green} trunk passed with JDK v1.7.0_95 {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 24s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 0m 55s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 14s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 2m 2s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 8s {color} | {color:green} trunk passed with JDK v1.8.0_77 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 57s {color} | {color:green} trunk passed with JDK v1.7.0_95 {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 0m 47s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 0m 39s {color} | {color:green} the patch passed with JDK v1.8.0_77 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 0m 39s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 0m 41s {color} | {color:green} the patch passed with JDK v1.7.0_95 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 0m 41s {color} | {color:green} the patch passed {color} |\n| {color:red}-1{color} | {color:red} checkstyle {color} | {color:red} 0m 24s {color} | {color:red} hadoop-hdfs-project/hadoop-hdfs: patch generated 1 new + 242 unchanged - 3 fixed = 243 total (was 245) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 0m 53s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 12s {color} | {color:green} the patch passed {color} |\n| {color:red}-1{color} | {color:red} whitespace {color} | {color:red} 0m 0s {color} | {color:red} The patch has 1 line(s) that end in whitespace. Use git apply --whitespace=fix. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 2m 16s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 9s {color} | {color:green} the patch passed with JDK v1.8.0_77 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 42s {color} | {color:green} the patch passed with JDK v1.7.0_95 {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 59m 16s {color} | {color:red} hadoop-hdfs in the patch failed with JDK v1.8.0_77. {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 55m 1s {color} | {color:red} hadoop-hdfs in the patch failed with JDK v1.7.0_95. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green} 0m 21s {color} | {color:green} Patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black} 140m 43s {color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| JDK v1.8.0_77 Failed junit tests | hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA |\n|   | hadoop.hdfs.server.namenode.TestNamenodeRetryCache |\n|   | hadoop.hdfs.TestDFSUpgradeFromImage |\n| JDK v1.7.0_95 Failed junit tests | hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA |\n|   | hadoop.hdfs.TestHFlush |\n|   | hadoop.hdfs.server.namenode.TestNamenodeRetryCache |\n|   | hadoop.hdfs.server.blockmanagement.TestReplicationPolicy |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:fbe3e86 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12799621/HDFS-10312.004.patch |\n| JIRA Issue | HDFS-10312 |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux c989188cbae7 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / af9bdbe |\n| Default Java | 1.7.0_95 |\n| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_77 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_95 |\n| findbugs | v3.0.0 |\n| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/15208/artifact/patchprocess/diff-checkstyle-hadoop-hdfs-project_hadoop-hdfs.txt |\n| whitespace | https://builds.apache.org/job/PreCommit-HDFS-Build/15208/artifact/patchprocess/whitespace-eol.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/15208/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.8.0_77.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/15208/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.7.0_95.txt |\n| unit test logs |  https://builds.apache.org/job/PreCommit-HDFS-Build/15208/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.8.0_77.txt https://builds.apache.org/job/PreCommit-HDFS-Build/15208/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.7.0_95.txt |\n| JDK v1.7.0_95  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/15208/testReport/ |\n| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/15208/console |\n| Powered by | Apache Yetus 0.2.0   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2016-04-20T02:07:47.422+0000","updated":"2016-04-20T02:07:47.422+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12960120/comment/15249247","id":"15249247","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brahmareddy","name":"brahmareddy","key":"brahmareddy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=brahmareddy&avatarId=24624","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=brahmareddy&avatarId=24624","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=brahmareddy&avatarId=24624","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=brahmareddy&avatarId=24624"},"displayName":"Brahma Reddy Battula","active":true,"timeZone":"Asia/Kolkata"},"body":"We've seen same issue and reported HDFS-8574 . As per discussion , it can be solved by HDFS-9011 but did not seen any progress there.\nAs colin suggested there, \"It would be simpler for the admin to create two (or more) storages on the same drive, and it wouldn't involve any code modification by us.\" \n\nEven now numofblocks per volume are exposed ( HDFS-9425) such that admin can monitor this.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brahmareddy","name":"brahmareddy","key":"brahmareddy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=brahmareddy&avatarId=24624","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=brahmareddy&avatarId=24624","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=brahmareddy&avatarId=24624","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=brahmareddy&avatarId=24624"},"displayName":"Brahma Reddy Battula","active":true,"timeZone":"Asia/Kolkata"},"created":"2016-04-20T05:03:05.734+0000","updated":"2016-04-20T05:03:05.734+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12960120/comment/15249299","id":"15249299","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"body":"It appears the discussions in those other JIRAs missed the point that {{ipc.maximum.data.length}} controls only the maximum payload accepted by the RPC server.  Without this patch, it is not sufficient to work around the size enforcement by protobuf, demonstrated in the stack trace that I included in prior comments.  Asking admins to repartition blocks across multiple storages on the same drive isn't a viable workaround for them.  HDFS-9011 is a much deeper change that will require further review.  This patch is a simple way to unblock clusters that have already gotten into this state accidentally.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-04-20T05:42:08.478+0000","updated":"2016-04-20T05:42:08.478+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12960120/comment/15249302","id":"15249302","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"body":"The remaining Checkstyle warning is for a long method.  It's best not to address it in scope of this patch.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-04-20T05:42:52.443+0000","updated":"2016-04-20T05:42:52.443+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12960120/comment/15249482","id":"15249482","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brahmareddy","name":"brahmareddy","key":"brahmareddy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=brahmareddy&avatarId=24624","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=brahmareddy&avatarId=24624","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=brahmareddy&avatarId=24624","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=brahmareddy&avatarId=24624"},"displayName":"Brahma Reddy Battula","active":true,"timeZone":"Asia/Kolkata"},"body":"You are right. It would be non-trivial for admin's to split the existing storage directory to multiple storage directories.\n\nWith your patch, to come out the current case, ipc.maximum.data.length should be changed in both NN and DN side. \nI am also fine with this approach.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brahmareddy","name":"brahmareddy","key":"brahmareddy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=brahmareddy&avatarId=24624","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=brahmareddy&avatarId=24624","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=brahmareddy&avatarId=24624","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=brahmareddy&avatarId=24624"},"displayName":"Brahma Reddy Battula","active":true,"timeZone":"Asia/Kolkata"},"created":"2016-04-20T08:25:58.062+0000","updated":"2016-04-20T08:25:58.062+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12960120/comment/15249906","id":"15249906","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"body":"bq. With your patch, to come out the current case, ipc.maximum.data.length should be changed in both NN and DN side.\n\nThe slightly strange thing is that it seems the 64 MB enforcement by protobuf only happens at time of decoding a message, not at time of creating the message.  In my testing, I only saw problems on the server side consuming the message (the NameNode).  I'm not sure that it would be strictly required to make the configuration change on DataNodes, but there is also no harm in doing it that way.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-04-20T13:41:25.384+0000","updated":"2016-04-20T13:41:25.384+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12960120/comment/15250712","id":"15250712","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"body":"Thank you for the reviews anyone.  The test failures were unrelated.  I corrected the whitespace warning.  I have committed this to trunk, branch-2 and branch-2.8.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-04-20T21:02:59.648+0000","updated":"2016-04-20T21:02:59.648+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12960120/comment/15250792","id":"15250792","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"FAILURE: Integrated in Hadoop-trunk-Commit #9637 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/9637/])\nHDFS-10312. Large block reports may fail to decode at NameNode due to 64 (cnauroth: rev 63ac2db59af2b50e74dc892cae1dbc4d2e061423)\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/BlockPoolSlice.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImplTestUtils.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNodeRpcServer.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/BlockListAsLongs.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestLargeBlockReport.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolServerSideTranslatorPB.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2016-04-20T21:54:47.043+0000","updated":"2016-04-20T21:54:47.043+0000"}],"maxResults":27,"total":27,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-10312/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i2wcbj:"}}