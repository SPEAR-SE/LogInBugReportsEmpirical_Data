{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12972299","self":"https://issues.apache.org/jira/rest/api/2/issue/12972299","key":"HDFS-10453","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12341434","id":"12341434","description":"3.1.0 release","name":"3.1.0","archived":false,"released":true,"releaseDate":"2018-04-06"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12341705","id":"12341705","description":"2.10.0 release","name":"2.10.0","archived":false,"released":false},{"self":"https://issues.apache.org/jira/rest/api/2/version/12341761","id":"12341761","description":"2.9.1 release","name":"2.9.1","archived":false,"released":true,"releaseDate":"2018-05-03"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12342177","id":"12342177","description":"2.8.4 release","name":"2.8.4","archived":false,"released":true,"releaseDate":"2018-05-15"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12342316","id":"12342316","description":"2.7.6 release","name":"2.7.6","archived":false,"released":true,"releaseDate":"2018-04-16"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12343020","id":"12343020","description":"3.0.3 release","name":"3.0.3","archived":false,"released":true,"releaseDate":"2018-06-08"}],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2016-05-24T07:28:57.313+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Fri Aug 17 17:25:29 UTC 2018","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":"1_*:*_5_*:*_1050042_*|*_5_*:*_1_*:*_0_*|*_10002_*:*_5_*:*_54373765634","customfield_12312321":null,"resolutiondate":"2018-02-12T15:20:46.627+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-10453/watchers","watchCount":25,"isWatching":false},"created":"2016-05-24T07:13:51.012+0000","customfield_12310192":null,"customfield_12310191":[{"self":"https://issues.apache.org/jira/rest/api/2/customFieldOption/10343","value":"Reviewed","id":"10343"}],"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"17.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12326696","id":"12326696","description":"2.4.1 bug-fix release","name":"2.4.1","archived":false,"released":true,"releaseDate":"2014-06-30"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12328970","id":"12328970","description":"2.5.2 release","name":"2.5.2","archived":false,"released":true,"releaseDate":"2014-11-19"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12331979","id":"12331979","description":"2.7.1 release","name":"2.7.1","archived":false,"released":true,"releaseDate":"2015-07-06"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12334241","id":"12334241","description":"2.6.4 release","name":"2.6.4","archived":false,"released":true,"releaseDate":"2016-02-11"}],"issuelinks":[{"id":"12540687","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12540687","type":{"id":"12310000","name":"Duplicate","inward":"is duplicated by","outward":"duplicates","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/12310000"},"inwardIssue":{"id":"12843138","key":"HDFS-8718","self":"https://issues.apache.org/jira/rest/api/2/issue/12843138","fields":{"summary":"Block replicating cannot work after upgrading to 2.7 ","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12540671","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12540671","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"13162757","key":"HDFS-13638","self":"https://issues.apache.org/jira/rest/api/2/issue/13162757","fields":{"summary":"DataNode Can't replicate block because NameNode thinks the length is 9223372036854775807","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hexiaoqiao","name":"hexiaoqiao","key":"hexiaoqiao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hexiaoqiao&avatarId=26980","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hexiaoqiao&avatarId=26980","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hexiaoqiao&avatarId=26980","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hexiaoqiao&avatarId=26980"},"displayName":"He Xiaoqiao","active":true,"timeZone":"Asia/Shanghai"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2018-08-17T17:26:29.960+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12312926","id":"12312926","name":"namenode"}],"timeoriginalestimate":null,"description":"ReplicationMonitor thread could stuck for long time and loss data with little probability. Consider the typical scenarioï¼š\n(1) create and close a file with the default replicas(3);\n(2) increase replication (to 10) of the file.\n(3) delete the file while ReplicationMonitor is scheduling blocks belong to that file for replications.\n\nif ReplicationMonitor stuck reappeared, NameNode will print log as:\n{code:xml}\n2016-04-19 10:20:48,083 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 7 to reach 10 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy\n......\n2016-04-19 10:21:17,184 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 7 to reach 10 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy\n2016-04-19 10:21:17,184 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 7 but only 0 storage types can be selected (replication=10, selected=[], unavailable=[DISK, ARCHIVE], removed=[DISK, DISK, DISK, DISK, DISK, DISK, DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})\n2016-04-19 10:21:17,184 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 7 to reach 10 (unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) All required storage types are unavailable:  unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}\n{code}\n\nThis is because 2 threads (#NameNodeRpcServer and #ReplicationMonitor) process same block at the same moment.\n(1) ReplicationMonitor#computeReplicationWorkForBlocks get blocks to replicate and leave the global lock.\n(2) FSNamesystem#delete invoked to delete blocks then clear the reference in blocksmap, needReplications, etc. the block's NumBytes will set NO_ACK(Long.MAX_VALUE) which is used to indicate that the block deletion does not need explicit ACK from the node. \n(3) ReplicationMonitor#computeReplicationWorkForBlocks continue to chooseTargets for the same blocks and no node will be selected after traverse whole cluster because  no node choice satisfy the goodness criteria (remaining spaces achieve required size Long.MAX_VALUE). \n\nDuring of stage#3 ReplicationMonitor stuck for long time, especial in a large cluster. invalidateBlocks & neededReplications continues to grow and no consumes. it will loss data at the worst.\n\nThis can mostly be avoided by skip chooseTarget for BlockCommand.NO_ACK block and remove it from neededReplications.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12806074","id":"12806074","filename":"HDFS-10453.001.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hexiaoqiao","name":"hexiaoqiao","key":"hexiaoqiao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hexiaoqiao&avatarId=26980","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hexiaoqiao&avatarId=26980","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hexiaoqiao&avatarId=26980","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hexiaoqiao&avatarId=26980"},"displayName":"He Xiaoqiao","active":true,"timeZone":"Asia/Shanghai"},"created":"2016-05-25T06:12:34.500+0000","size":5239,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12806074/HDFS-10453.001.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12805830","id":"12805830","filename":"HDFS-10453-branch-2.001.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hexiaoqiao","name":"hexiaoqiao","key":"hexiaoqiao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hexiaoqiao&avatarId=26980","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hexiaoqiao&avatarId=26980","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hexiaoqiao&avatarId=26980","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hexiaoqiao&avatarId=26980"},"displayName":"He Xiaoqiao","active":true,"timeZone":"Asia/Shanghai"},"created":"2016-05-24T07:38:00.316+0000","size":5038,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12805830/HDFS-10453-branch-2.001.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12806883","id":"12806883","filename":"HDFS-10453-branch-2.003.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hexiaoqiao","name":"hexiaoqiao","key":"hexiaoqiao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hexiaoqiao&avatarId=26980","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hexiaoqiao&avatarId=26980","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hexiaoqiao&avatarId=26980","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hexiaoqiao&avatarId=26980"},"displayName":"He Xiaoqiao","active":true,"timeZone":"Asia/Shanghai"},"created":"2016-05-29T11:30:03.765+0000","size":5248,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12806883/HDFS-10453-branch-2.003.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12901044","id":"12901044","filename":"HDFS-10453-branch-2.7.004.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hexiaoqiao","name":"hexiaoqiao","key":"hexiaoqiao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hexiaoqiao&avatarId=26980","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hexiaoqiao&avatarId=26980","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hexiaoqiao&avatarId=26980","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hexiaoqiao&avatarId=26980"},"displayName":"He Xiaoqiao","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-12-07T10:55:23.830+0000","size":5470,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12901044/HDFS-10453-branch-2.7.004.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12901616","id":"12901616","filename":"HDFS-10453-branch-2.7.005.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hexiaoqiao","name":"hexiaoqiao","key":"hexiaoqiao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hexiaoqiao&avatarId=26980","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hexiaoqiao&avatarId=26980","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hexiaoqiao&avatarId=26980","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hexiaoqiao&avatarId=26980"},"displayName":"He Xiaoqiao","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-12-12T06:21:49.768+0000","size":5544,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12901616/HDFS-10453-branch-2.7.005.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12908724","id":"12908724","filename":"HDFS-10453-branch-2.7.006.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hexiaoqiao","name":"hexiaoqiao","key":"hexiaoqiao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hexiaoqiao&avatarId=26980","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hexiaoqiao&avatarId=26980","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hexiaoqiao&avatarId=26980","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hexiaoqiao&avatarId=26980"},"displayName":"He Xiaoqiao","active":true,"timeZone":"Asia/Shanghai"},"created":"2018-02-01T05:50:48.426+0000","size":6053,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12908724/HDFS-10453-branch-2.7.006.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12909377","id":"12909377","filename":"HDFS-10453-branch-2.7.007.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hexiaoqiao","name":"hexiaoqiao","key":"hexiaoqiao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hexiaoqiao&avatarId=26980","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hexiaoqiao&avatarId=26980","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hexiaoqiao&avatarId=26980","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hexiaoqiao&avatarId=26980"},"displayName":"He Xiaoqiao","active":true,"timeZone":"Asia/Shanghai"},"created":"2018-02-06T06:24:32.470+0000","size":6765,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12909377/HDFS-10453-branch-2.7.007.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12909881","id":"12909881","filename":"HDFS-10453-branch-2.7.008.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hexiaoqiao","name":"hexiaoqiao","key":"hexiaoqiao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hexiaoqiao&avatarId=26980","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hexiaoqiao&avatarId=26980","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hexiaoqiao&avatarId=26980","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hexiaoqiao&avatarId=26980"},"displayName":"He Xiaoqiao","active":true,"timeZone":"Asia/Shanghai"},"created":"2018-02-09T03:57:48.128+0000","size":4722,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12909881/HDFS-10453-branch-2.7.008.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12910019","id":"12910019","filename":"HDFS-10453-branch-2.7.009.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hexiaoqiao","name":"hexiaoqiao","key":"hexiaoqiao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hexiaoqiao&avatarId=26980","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hexiaoqiao&avatarId=26980","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hexiaoqiao&avatarId=26980","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hexiaoqiao&avatarId=26980"},"displayName":"He Xiaoqiao","active":true,"timeZone":"Asia/Shanghai"},"created":"2018-02-10T03:48:37.280+0000","size":1645,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12910019/HDFS-10453-branch-2.7.009.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12909882","id":"12909882","filename":"HDFS-10453-branch-2.8.001.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hexiaoqiao","name":"hexiaoqiao","key":"hexiaoqiao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hexiaoqiao&avatarId=26980","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hexiaoqiao&avatarId=26980","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hexiaoqiao&avatarId=26980","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hexiaoqiao&avatarId=26980"},"displayName":"He Xiaoqiao","active":true,"timeZone":"Asia/Shanghai"},"created":"2018-02-09T03:57:48.127+0000","size":4725,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12909882/HDFS-10453-branch-2.8.001.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12910020","id":"12910020","filename":"HDFS-10453-branch-2.8.002.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hexiaoqiao","name":"hexiaoqiao","key":"hexiaoqiao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hexiaoqiao&avatarId=26980","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hexiaoqiao&avatarId=26980","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hexiaoqiao&avatarId=26980","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hexiaoqiao&avatarId=26980"},"displayName":"He Xiaoqiao","active":true,"timeZone":"Asia/Shanghai"},"created":"2018-02-10T03:48:37.392+0000","size":1584,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12910020/HDFS-10453-branch-2.8.002.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12909883","id":"12909883","filename":"HDFS-10453-branch-2.9.001.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hexiaoqiao","name":"hexiaoqiao","key":"hexiaoqiao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hexiaoqiao&avatarId=26980","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hexiaoqiao&avatarId=26980","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hexiaoqiao&avatarId=26980","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hexiaoqiao&avatarId=26980"},"displayName":"He Xiaoqiao","active":true,"timeZone":"Asia/Shanghai"},"created":"2018-02-09T03:57:48.127+0000","size":4202,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12909883/HDFS-10453-branch-2.9.001.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12910021","id":"12910021","filename":"HDFS-10453-branch-2.9.002.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hexiaoqiao","name":"hexiaoqiao","key":"hexiaoqiao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hexiaoqiao&avatarId=26980","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hexiaoqiao&avatarId=26980","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hexiaoqiao&avatarId=26980","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hexiaoqiao&avatarId=26980"},"displayName":"He Xiaoqiao","active":true,"timeZone":"Asia/Shanghai"},"created":"2018-02-10T03:48:37.750+0000","size":1584,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12910021/HDFS-10453-branch-2.9.002.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12909884","id":"12909884","filename":"HDFS-10453-branch-3.0.001.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hexiaoqiao","name":"hexiaoqiao","key":"hexiaoqiao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hexiaoqiao&avatarId=26980","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hexiaoqiao&avatarId=26980","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hexiaoqiao&avatarId=26980","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hexiaoqiao&avatarId=26980"},"displayName":"He Xiaoqiao","active":true,"timeZone":"Asia/Shanghai"},"created":"2018-02-09T03:57:48.127+0000","size":6135,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12909884/HDFS-10453-branch-3.0.001.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12910022","id":"12910022","filename":"HDFS-10453-branch-3.0.002.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hexiaoqiao","name":"hexiaoqiao","key":"hexiaoqiao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hexiaoqiao&avatarId=26980","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hexiaoqiao&avatarId=26980","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hexiaoqiao&avatarId=26980","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hexiaoqiao&avatarId=26980"},"displayName":"He Xiaoqiao","active":true,"timeZone":"Asia/Shanghai"},"created":"2018-02-10T03:48:37.787+0000","size":3498,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12910022/HDFS-10453-branch-3.0.002.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12909885","id":"12909885","filename":"HDFS-10453-trunk.001.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hexiaoqiao","name":"hexiaoqiao","key":"hexiaoqiao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hexiaoqiao&avatarId=26980","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hexiaoqiao&avatarId=26980","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hexiaoqiao&avatarId=26980","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hexiaoqiao&avatarId=26980"},"displayName":"He Xiaoqiao","active":true,"timeZone":"Asia/Shanghai"},"created":"2018-02-09T03:57:48.127+0000","size":6110,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12909885/HDFS-10453-trunk.001.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12910023","id":"12910023","filename":"HDFS-10453-trunk.002.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hexiaoqiao","name":"hexiaoqiao","key":"hexiaoqiao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hexiaoqiao&avatarId=26980","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hexiaoqiao&avatarId=26980","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hexiaoqiao&avatarId=26980","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hexiaoqiao&avatarId=26980"},"displayName":"He Xiaoqiao","active":true,"timeZone":"Asia/Shanghai"},"created":"2018-02-10T03:48:37.949+0000","size":3498,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12910023/HDFS-10453-trunk.002.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"ReplicationMonitor thread could stuck for long time due to the race between replication and delete of same file in a large cluster.","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hexiaoqiao","name":"hexiaoqiao","key":"hexiaoqiao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hexiaoqiao&avatarId=26980","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hexiaoqiao&avatarId=26980","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hexiaoqiao&avatarId=26980","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hexiaoqiao&avatarId=26980"},"displayName":"He Xiaoqiao","active":true,"timeZone":"Asia/Shanghai"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hexiaoqiao","name":"hexiaoqiao","key":"hexiaoqiao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hexiaoqiao&avatarId=26980","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hexiaoqiao&avatarId=26980","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hexiaoqiao&avatarId=26980","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hexiaoqiao&avatarId=26980"},"displayName":"He Xiaoqiao","active":true,"timeZone":"Asia/Shanghai"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12972299/comment/15297826","id":"15297826","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hexiaoqiao","name":"hexiaoqiao","key":"hexiaoqiao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hexiaoqiao&avatarId=26980","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hexiaoqiao&avatarId=26980","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hexiaoqiao&avatarId=26980","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hexiaoqiao&avatarId=26980"},"displayName":"He Xiaoqiao","active":true,"timeZone":"Asia/Shanghai"},"body":"committe to branch-2.7.1","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hexiaoqiao","name":"hexiaoqiao","key":"hexiaoqiao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hexiaoqiao&avatarId=26980","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hexiaoqiao&avatarId=26980","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hexiaoqiao&avatarId=26980","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hexiaoqiao&avatarId=26980"},"displayName":"He Xiaoqiao","active":true,"timeZone":"Asia/Shanghai"},"created":"2016-05-24T07:22:41.460+0000","updated":"2016-05-24T07:22:41.460+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12972299/comment/15297832","id":"15297832","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 0s {color} | {color:blue} Docker mode activated. {color} |\n| {color:red}-1{color} | {color:red} patch {color} | {color:red} 0m 4s {color} | {color:red} HDFS-10453 does not apply to trunk. Rebase required? Wrong Branch? See https://wiki.apache.org/hadoop/HowToContribute for help. {color} |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12805826/HDFS-10453.patch |\n| JIRA Issue | HDFS-10453 |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/15539/console |\n| Powered by | Apache Yetus 0.2.0   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2016-05-24T07:28:57.313+0000","updated":"2016-05-24T07:28:57.313+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12972299/comment/15299529","id":"15299529","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hexiaoqiao","name":"hexiaoqiao","key":"hexiaoqiao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hexiaoqiao&avatarId=26980","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hexiaoqiao&avatarId=26980","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hexiaoqiao&avatarId=26980","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hexiaoqiao&avatarId=26980"},"displayName":"He Xiaoqiao","active":true,"timeZone":"Asia/Shanghai"},"body":"submit patch for truck","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hexiaoqiao","name":"hexiaoqiao","key":"hexiaoqiao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hexiaoqiao&avatarId=26980","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hexiaoqiao&avatarId=26980","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hexiaoqiao&avatarId=26980","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hexiaoqiao&avatarId=26980"},"displayName":"He Xiaoqiao","active":true,"timeZone":"Asia/Shanghai"},"created":"2016-05-25T06:14:17.148+0000","updated":"2016-05-25T06:14:17.148+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12972299/comment/15299642","id":"15299642","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 16s {color} | {color:blue} Docker mode activated. {color} |\n| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green} 0m 0s {color} | {color:green} The patch appears to include 1 new or modified test files. {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 7m 30s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 0m 50s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 28s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 0m 59s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 11s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 1m 51s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 9s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 0m 53s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 0m 47s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 0m 47s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 27s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 0m 57s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 9s {color} | {color:green} the patch passed {color} |\n| {color:red}-1{color} | {color:red} whitespace {color} | {color:red} 0m 0s {color} | {color:red} The patch has 2 line(s) that end in whitespace. Use git apply --whitespace=fix. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 1m 58s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 6s {color} | {color:green} the patch passed {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 82m 34s {color} | {color:red} hadoop-hdfs in the patch failed. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green} 0m 19s {color} | {color:green} Patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black} 103m 42s {color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| Failed junit tests | hadoop.hdfs.server.namenode.snapshot.TestSnapshotFileLength |\n|   | hadoop.hdfs.TestAsyncDFSRename |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:2c91fd8 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12806074/HDFS-10453.001.patch |\n| JIRA Issue | HDFS-10453 |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux 17b64327d605 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / 28bd63e |\n| Default Java | 1.8.0_91 |\n| findbugs | v3.0.0 |\n| whitespace | https://builds.apache.org/job/PreCommit-HDFS-Build/15556/artifact/patchprocess/whitespace-eol.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/15556/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |\n| unit test logs |  https://builds.apache.org/job/PreCommit-HDFS-Build/15556/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |\n|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/15556/testReport/ |\n| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/15556/console |\n| Powered by | Apache Yetus 0.2.0   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2016-05-25T08:02:33.387+0000","updated":"2016-05-25T08:02:33.387+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12972299/comment/15305222","id":"15305222","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hexiaoqiao","name":"hexiaoqiao","key":"hexiaoqiao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hexiaoqiao&avatarId=26980","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hexiaoqiao&avatarId=26980","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hexiaoqiao&avatarId=26980","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hexiaoqiao&avatarId=26980"},"displayName":"He Xiaoqiao","active":true,"timeZone":"Asia/Shanghai"},"body":"hi [~shahrs87], thanks a lot for your watching this issue. It would be helpful with ur reviews and more suggestions.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hexiaoqiao","name":"hexiaoqiao","key":"hexiaoqiao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hexiaoqiao&avatarId=26980","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hexiaoqiao&avatarId=26980","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hexiaoqiao&avatarId=26980","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hexiaoqiao&avatarId=26980"},"displayName":"He Xiaoqiao","active":true,"timeZone":"Asia/Shanghai"},"created":"2016-05-28T07:32:55.427+0000","updated":"2016-05-28T07:32:55.427+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12972299/comment/15305863","id":"15305863","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hexiaoqiao","name":"hexiaoqiao","key":"hexiaoqiao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hexiaoqiao&avatarId=26980","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hexiaoqiao&avatarId=26980","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hexiaoqiao&avatarId=26980","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hexiaoqiao&avatarId=26980"},"displayName":"He Xiaoqiao","active":true,"timeZone":"Asia/Shanghai"},"body":"Kick jenkins for branch-2.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hexiaoqiao","name":"hexiaoqiao","key":"hexiaoqiao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hexiaoqiao&avatarId=26980","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hexiaoqiao&avatarId=26980","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hexiaoqiao&avatarId=26980","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hexiaoqiao&avatarId=26980"},"displayName":"He Xiaoqiao","active":true,"timeZone":"Asia/Shanghai"},"created":"2016-05-29T11:35:52.509+0000","updated":"2016-05-29T11:35:52.509+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12972299/comment/15305917","id":"15305917","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 13m 53s {color} | {color:blue} Docker mode activated. {color} |\n| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green} 0m 0s {color} | {color:green} The patch appears to include 1 new or modified test files. {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 6m 29s {color} | {color:green} branch-2 passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 0m 37s {color} | {color:green} branch-2 passed with JDK v1.8.0_91 {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 0m 41s {color} | {color:green} branch-2 passed with JDK v1.7.0_101 {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 29s {color} | {color:green} branch-2 passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 0m 50s {color} | {color:green} branch-2 passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 14s {color} | {color:green} branch-2 passed {color} |\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red} 1m 54s {color} | {color:red} hadoop-hdfs-project/hadoop-hdfs in branch-2 has 1 extant Findbugs warnings. {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 3s {color} | {color:green} branch-2 passed with JDK v1.8.0_91 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 45s {color} | {color:green} branch-2 passed with JDK v1.7.0_101 {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 0m 45s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 0m 35s {color} | {color:green} the patch passed with JDK v1.8.0_91 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 0m 35s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 0m 38s {color} | {color:green} the patch passed with JDK v1.7.0_101 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 0m 38s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 26s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 0m 47s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 11s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green} 0m 0s {color} | {color:green} The patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 2m 5s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 1s {color} | {color:green} the patch passed with JDK v1.8.0_91 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 41s {color} | {color:green} the patch passed with JDK v1.7.0_101 {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 60m 31s {color} | {color:red} hadoop-hdfs in the patch failed with JDK v1.8.0_91. {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 58m 17s {color} | {color:red} hadoop-hdfs in the patch failed with JDK v1.7.0_101. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green} 0m 20s {color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black} 157m 14s {color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| JDK v1.8.0_91 Failed junit tests | hadoop.hdfs.TestDistributedFileSystem |\n|   | hadoop.hdfs.server.blockmanagement.TestRBWBlockInvalidation |\n|   | hadoop.metrics2.sink.TestRollingFileSystemSinkWithHdfs |\n| JDK v1.7.0_101 Failed junit tests | hadoop.hdfs.TestDistributedFileSystem |\n|   | hadoop.metrics2.sink.TestRollingFileSystemSinkWithHdfs |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:babe025 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12806883/HDFS-10453-branch-2.003.patch |\n| JIRA Issue | HDFS-10453 |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux 015f3d668fe4 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | branch-2 / b3f5337 |\n| Default Java | 1.7.0_101 |\n| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_91 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_101 |\n| findbugs | v3.0.0 |\n| findbugs | https://builds.apache.org/job/PreCommit-HDFS-Build/15601/artifact/patchprocess/branch-findbugs-hadoop-hdfs-project_hadoop-hdfs-warnings.html |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/15601/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.8.0_91.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/15601/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.7.0_101.txt |\n| unit test logs |  https://builds.apache.org/job/PreCommit-HDFS-Build/15601/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.8.0_91.txt https://builds.apache.org/job/PreCommit-HDFS-Build/15601/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.7.0_101.txt |\n| JDK v1.7.0_101  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/15601/testReport/ |\n| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/15601/console |\n| Powered by | Apache Yetus 0.3.0   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2016-05-29T14:15:42.191+0000","updated":"2016-05-29T14:15:42.191+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12972299/comment/15306248","id":"15306248","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinayrpet","name":"vinayrpet","key":"vinayrpet","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinayakumar B","active":true,"timeZone":"Asia/Kolkata"},"body":"In Branch-2 code, {{BlockManager#computeReconstructionWorkForBlocks()}}, flow goes like below before reaching the part of the code where you have provided the patch,\n1. With global-lock held, {{work}} list will be created with the blocks which are exactly present at that time in {{scheduleReplication()}}, lock will be released after creating the list.\n{code}    if (block.isDeleted() || !block.isCompleteOrCommitted()) {\n      // remove from neededReplications\n      neededReplications.remove(block, priority);\n      return null;\n    }{code}\n2. For blocks in {{work}} list, targets will be chosen.\n3. Global lock will be acquired again, recheck happens for all {{ReplicationWork}} blocks which have got targets, whether block deleted or not during step #2. Now only blocks which are not deleted during this time will be proceeded for replication.\n{code}    if (block.isDeleted() || !block.isCompleteOrCommitted()) {\n      neededReplications.remove(block, priority);\n      rw.resetTargets();\n      return false;\n    }{code}\n\nTherefore the problem you mentioned in the description does not occur IMO.\n\nCorrect me, If I am wrong.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinayrpet","name":"vinayrpet","key":"vinayrpet","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinayakumar B","active":true,"timeZone":"Asia/Kolkata"},"created":"2016-05-30T05:31:01.756+0000","updated":"2016-05-30T05:31:01.756+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12972299/comment/15306312","id":"15306312","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hexiaoqiao","name":"hexiaoqiao","key":"hexiaoqiao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hexiaoqiao&avatarId=26980","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hexiaoqiao&avatarId=26980","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hexiaoqiao&avatarId=26980","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hexiaoqiao&avatarId=26980"},"displayName":"He Xiaoqiao","active":true,"timeZone":"Asia/Shanghai"},"body":"hi [~vinayrpet], thanks for your comments.\nActually this case occurs at Step 2 in {{BlockManager#computeReconstructionWorkForBlocks()}} which is not with global-lock held as you metioned.\nbq. 2. For blocks in work list, targets will be chosen.\n\n{{rw.chooseTargets}} will stuck for long time in the following scenarios:\n1. *Blocks* are chosen to be reconstructed at {{neededReconstruction#chooseLowRedundancyBlocks(blocksToProcess)}} with global-lock held;\n2. BlockReconstructionWork list {{reconWork}} will be created with the *blocks* which are exactly present at that time in {{scheduleReplication()}} also with global-lock. After creating list, lock is released.\n3. Deletion happens at {{BlockManager#removeBlock(BlockInfo block)}} with global lock held. it is a critical parts of this case,\n{code}\n  public void removeBlock(BlockInfo block) {\n    assert namesystem.hasWriteLock();\n    // No need to ACK blocks that are being removed entirely\n    // from the namespace, since the removal of the associated\n    // file already removes them from the block map below.\n    block.setNumBytes(BlockCommand.NO_ACK);\n    addToInvalidates(block);\n    removeBlockFromMap(block);\n    // Remove the block from pendingReconstruction and neededReconstruction\n    pendingReconstruction.remove(block);\n    neededReconstruction.remove(block, LowRedundancyBlocks.LEVEL);\n    if (postponedMisreplicatedBlocks.remove(block)) {\n      postponedMisreplicatedBlocksCount.decrementAndGet();\n    }\n  }\n{code}\nAfter {{removeBlock(BlockInfo block)}} *numbytes* of the block is set to BlockCommand.NO_ACK (=Long.MAX_VALUE), block is delete from {{neededReconstruction}},{{pendingReconstruction}} and {{blocksMap}}, but it is still referenced by {{reconWork}} which is local variable of {{BlockManager #computeReconstructionWorkForBlocks}}.\n4. Choose target for each block in {{reconWork}}, but no Node could be selected after *traverse whole cluster* at this moment since numbytes of this block is Long.MAX_VALUE. if there are multiple blocks as depict above in a large cluster, Step 2 as flow below of {{BlockManager#computeReconstructionWorkForBlocks()}} will cost long time. it could be above *10 min* in our online cluster.\n{code}\n    // Step 2: choose target nodes for each reconstruction task\n    final Set<Node> excludedNodes = new HashSet<>();\n    for(BlockReconstructionWork rw : reconWork){\n      // Exclude all of the containing nodes from being targets.\n      // This list includes decommissioning or corrupt nodes.\n      excludedNodes.clear();\n      for (DatanodeDescriptor dn : rw.getContainingNodes()) {\n        excludedNodes.add(dn);\n      }\n\n      // choose replication targets: NOT HOLDING THE GLOBAL LOCK\n      // It is costly to extract the filename for which chooseTargets is called,\n      // so for now we pass in the block collection itself.\n      final BlockPlacementPolicy placementPolicy =\n          placementPolicies.getPolicy(rw.getBlock().isStriped());\n      rw.chooseTargets(placementPolicy, storagePolicySuite, excludedNodes);\n    }\n{code}\n5. The rest processing as usually.\n\nFYI.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hexiaoqiao","name":"hexiaoqiao","key":"hexiaoqiao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hexiaoqiao&avatarId=26980","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hexiaoqiao&avatarId=26980","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hexiaoqiao&avatarId=26980","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hexiaoqiao&avatarId=26980"},"displayName":"He Xiaoqiao","active":true,"timeZone":"Asia/Shanghai"},"created":"2016-05-30T06:59:27.369+0000","updated":"2016-05-30T06:59:27.369+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12972299/comment/15709564","id":"15709564","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wutaklon%40amazon.com","name":"wutaklon@amazon.com","key":"wutaklon@amazon.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10443","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10443","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10443","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10443"},"displayName":"Taklon Stephen Wu","active":true,"timeZone":"Etc/UTC"},"body":"is this issue still ongoing?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wutaklon%40amazon.com","name":"wutaklon@amazon.com","key":"wutaklon@amazon.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10443","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10443","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10443","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10443"},"displayName":"Taklon Stephen Wu","active":true,"timeZone":"Etc/UTC"},"created":"2016-11-30T19:45:44.380+0000","updated":"2016-11-30T19:45:44.380+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12972299/comment/15709995","id":"15709995","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 14m 25s{color} | {color:blue} Docker mode activated. {color} |\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  7m 38s{color} | {color:green} branch-2 passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 46s{color} | {color:green} branch-2 passed with JDK v1.8.0_111 {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 48s{color} | {color:green} branch-2 passed with JDK v1.7.0_121 {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 32s{color} | {color:green} branch-2 passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 56s{color} | {color:green} branch-2 passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 17s{color} | {color:green} branch-2 passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 13s{color} | {color:green} branch-2 passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m  9s{color} | {color:green} branch-2 passed with JDK v1.8.0_111 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 52s{color} | {color:green} branch-2 passed with JDK v1.7.0_121 {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 52s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 54s{color} | {color:green} the patch passed with JDK v1.8.0_111 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 54s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 45s{color} | {color:green} the patch passed with JDK v1.7.0_121 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 45s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 28s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 54s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 14s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 18s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 57s{color} | {color:green} the patch passed with JDK v1.8.0_111 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 44s{color} | {color:green} the patch passed with JDK v1.7.0_121 {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 53m 38s{color} | {color:red} hadoop-hdfs in the patch failed with JDK v1.7.0_121. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 31s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black}154m 55s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| JDK v1.8.0_111 Failed junit tests | hadoop.hdfs.server.namenode.TestNameNodeMetricsLogger |\n|   | hadoop.hdfs.server.blockmanagement.TestRBWBlockInvalidation |\n|   | hadoop.hdfs.TestBlockStoragePolicy |\n| JDK v1.7.0_121 Failed junit tests | hadoop.hdfs.server.datanode.TestFsDatasetCache |\n|   | hadoop.metrics2.sink.TestRollingFileSystemSinkWithSecureHdfs |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:b59b8b7 |\n| JIRA Issue | HDFS-10453 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12806883/HDFS-10453-branch-2.003.patch |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux 6d0e25f9ff3c 3.13.0-92-generic #139-Ubuntu SMP Tue Jun 28 20:42:26 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | branch-2 / 3013b02 |\n| Default Java | 1.7.0_121 |\n| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_111 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_121 |\n| findbugs | v3.0.0 |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/17714/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.7.0_121.txt |\n| JDK v1.7.0_121  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/17714/testReport/ |\n| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/17714/console |\n| Powered by | Apache Yetus 0.4.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2016-11-30T22:23:46.818+0000","updated":"2016-11-30T22:23:46.818+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12972299/comment/15710641","id":"15710641","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hexiaoqiao","name":"hexiaoqiao","key":"hexiaoqiao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hexiaoqiao&avatarId=26980","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hexiaoqiao&avatarId=26980","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hexiaoqiao&avatarId=26980","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hexiaoqiao&avatarId=26980"},"displayName":"He Xiaoqiao","active":true,"timeZone":"Asia/Shanghai"},"body":"[~wutaklon@amazon.com]\nThanks for your comments, The patch is ready, and i think the failure tests are not related to this patch.\n Actually, This bugfix has run on our production environment over half a year and the exception does not appear.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hexiaoqiao","name":"hexiaoqiao","key":"hexiaoqiao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hexiaoqiao&avatarId=26980","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hexiaoqiao&avatarId=26980","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hexiaoqiao&avatarId=26980","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hexiaoqiao&avatarId=26980"},"displayName":"He Xiaoqiao","active":true,"timeZone":"Asia/Shanghai"},"created":"2016-12-01T02:43:37.662+0000","updated":"2016-12-01T02:43:37.662+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12972299/comment/15710653","id":"15710653","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wutaklon%40amazon.com","name":"wutaklon@amazon.com","key":"wutaklon@amazon.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10443","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10443","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10443","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10443"},"displayName":"Taklon Stephen Wu","active":true,"timeZone":"Etc/UTC"},"body":"+1, could someone please review this patch again?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wutaklon%40amazon.com","name":"wutaklon@amazon.com","key":"wutaklon@amazon.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10443","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10443","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10443","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10443"},"displayName":"Taklon Stephen Wu","active":true,"timeZone":"Etc/UTC"},"created":"2016-12-01T02:47:50.850+0000","updated":"2016-12-01T02:47:50.850+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12972299/comment/15755580","id":"15755580","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yangyishan0901m","name":"yangyishan0901m","key":"yangyishan0901m","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yishan Yang","active":true,"timeZone":"Etc/UTC"},"body":"Any update? Whether community wanna accept this fix? Thanks!","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yangyishan0901m","name":"yangyishan0901m","key":"yangyishan0901m","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yishan Yang","active":true,"timeZone":"Etc/UTC"},"created":"2016-12-16T21:39:51.903+0000","updated":"2016-12-16T21:39:51.903+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12972299/comment/15756632","id":"15756632","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hexiaoqiao","name":"hexiaoqiao","key":"hexiaoqiao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hexiaoqiao&avatarId=26980","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hexiaoqiao&avatarId=26980","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hexiaoqiao&avatarId=26980","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hexiaoqiao&avatarId=26980"},"displayName":"He Xiaoqiao","active":true,"timeZone":"Asia/Shanghai"},"body":"[~yangyishan0901m]\npatch is ready and it works well for long times in our production env as expected. you can patch and test it for yourself.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hexiaoqiao","name":"hexiaoqiao","key":"hexiaoqiao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hexiaoqiao&avatarId=26980","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hexiaoqiao&avatarId=26980","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hexiaoqiao&avatarId=26980","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hexiaoqiao&avatarId=26980"},"displayName":"He Xiaoqiao","active":true,"timeZone":"Asia/Shanghai"},"created":"2016-12-17T08:29:19.222+0000","updated":"2016-12-17T08:29:19.222+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12972299/comment/16281396","id":"16281396","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=water","name":"water","key":"water","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=water&avatarId=32871","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=water&avatarId=32871","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=water&avatarId=32871","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=water&avatarId=32871"},"displayName":"Xiang Li","active":true,"timeZone":"Asia/Shanghai"},"body":"Hi [~hexiaoqiao], we met the same issue and thanks for the patch!\r\nI read your patch and it seems no lock is added when trying to remove rw from neededReplications.\r\nCould it be something like?\r\n{code}\r\nsynchronized (neededReplications) {\r\n  if (rw.getBlock().getNumBytes() == BlockCommand.NO_ACK) {\r\n    //remove from neededReconstruction while block has deleted.\r\n    neededReplications.remove(rw.getBlock(), rw.getPriority());\r\n  }\r\n}\r\n{code}\r\nCould you help to explain a little more why you do not place a lock of neededReplications here?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=water","name":"water","key":"water","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=water&avatarId=32871","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=water&avatarId=32871","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=water&avatarId=32871","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=water&avatarId=32871"},"displayName":"Xiang Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-12-07T06:45:17.571+0000","updated":"2017-12-07T06:45:17.571+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12972299/comment/16281548","id":"16281548","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=genericqa","name":"genericqa","key":"genericqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=genericqa&avatarId=33630","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=genericqa&avatarId=33630","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=genericqa&avatarId=33630","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=genericqa&avatarId=33630"},"displayName":"genericqa","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 19m  0s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |\r\n|| || || || {color:brown} branch-2 Compile Tests {color} ||\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  9m 51s{color} | {color:green} branch-2 passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 49s{color} | {color:green} branch-2 passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 31s{color} | {color:green} branch-2 passed {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 59s{color} | {color:green} branch-2 passed {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m  9s{color} | {color:green} branch-2 passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 10s{color} | {color:green} branch-2 passed {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 55s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 45s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 45s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 28s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 55s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 23s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m  7s{color} | {color:green} the patch passed {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}107m 16s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |\r\n| {color:red}-1{color} | {color:red} asflicense {color} | {color:red}  1m 16s{color} | {color:red} The patch generated 207 ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black}151m 56s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Reason || Tests ||\r\n| Unreaped Processes | hadoop-hdfs:24 |\r\n| Failed junit tests | hadoop.hdfs.server.datanode.TestDataNodeUUID |\r\n|   | hadoop.hdfs.server.datanode.checker.TestThrottledAsyncChecker |\r\n|   | hadoop.hdfs.TestEncryptedTransfer |\r\n|   | hadoop.hdfs.server.namenode.snapshot.TestSnapshotMetrics |\r\n|   | hadoop.hdfs.server.namenode.snapshot.TestSnapshottableDirListing |\r\n|   | hadoop.hdfs.TestDFSPermission |\r\n|   | hadoop.hdfs.server.datanode.TestBatchIbr |\r\n|   | hadoop.hdfs.server.namenode.TestNestedEncryptionZones |\r\n|   | hadoop.hdfs.server.datanode.fsdataset.impl.TestLazyPersistPolicy |\r\n|   | hadoop.hdfs.server.datanode.TestBpServiceActorScheduler |\r\n|   | hadoop.hdfs.server.federation.router.TestRouter |\r\n|   | hadoop.hdfs.server.datanode.metrics.TestDataNodeOutlierDetectionViaMetrics |\r\n|   | hadoop.hdfs.server.federation.metrics.TestFederationMetrics |\r\n|   | hadoop.hdfs.server.datanode.fsdataset.impl.TestInterDatanodeProtocol |\r\n|   | hadoop.hdfs.server.namenode.snapshot.TestNestedSnapshots |\r\n|   | hadoop.hdfs.server.blockmanagement.TestNameNodePrunesMissingStorages |\r\n|   | hadoop.hdfs.TestSetTimes |\r\n|   | hadoop.hdfs.server.blockmanagement.TestHeartbeatHandling |\r\n|   | hadoop.hdfs.server.blockmanagement.TestPendingInvalidateBlock |\r\n|   | hadoop.hdfs.server.blockmanagement.TestBlockTokenWithDFS |\r\n|   | hadoop.hdfs.server.datanode.fsdataset.impl.TestLazyPersistLockedMemory |\r\n|   | hadoop.hdfs.TestDatanodeDeath |\r\n|   | hadoop.hdfs.server.blockmanagement.TestReplicationPolicyConsiderLoad |\r\n|   | hadoop.hdfs.server.datanode.TestDataNodeTransferSocketSize |\r\n|   | hadoop.hdfs.server.datanode.TestBlockCountersInPendingIBR |\r\n|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeMetrics |\r\n|   | hadoop.fs.TestFcHdfsCreateMkdir |\r\n|   | hadoop.hdfs.server.federation.resolver.TestNamenodeResolver |\r\n|   | hadoop.hdfs.TestDFSRollback |\r\n|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration |\r\n|   | hadoop.hdfs.server.datanode.checker.TestDatasetVolumeCheckerTimeout |\r\n|   | hadoop.hdfs.server.namenode.TestNamenodeRetryCache |\r\n|   | hadoop.hdfs.server.datanode.TestFsDatasetCache |\r\n|   | hadoop.hdfs.server.datanode.TestDataNodePeerMetrics |\r\n|   | hadoop.hdfs.server.federation.store.driver.TestStateStoreFileSystem |\r\n|   | hadoop.hdfs.server.datanode.checker.TestStorageLocationChecker |\r\n|   | hadoop.hdfs.server.datanode.TestLargeBlockReport |\r\n|   | hadoop.hdfs.server.namenode.TestStorageRestore |\r\n|   | hadoop.hdfs.server.namenode.TestParallelImageWrite |\r\n|   | hadoop.hdfs.server.datanode.TestDiskError |\r\n|   | hadoop.hdfs.server.blockmanagement.TestDatanodeManager |\r\n|   | hadoop.hdfs.server.federation.store.driver.TestStateStoreZK |\r\n|   | hadoop.hdfs.server.namenode.snapshot.TestRenameWithSnapshots |\r\n|   | hadoop.hdfs.server.datanode.web.TestDatanodeHttpXFrame |\r\n|   | hadoop.hdfs.shortcircuit.TestShortCircuitCache |\r\n|   | hadoop.hdfs.server.balancer.TestBalancerWithNodeGroup |\r\n|   | hadoop.hdfs.server.datanode.TestDnRespectsBlockReportSplitThreshold |\r\n|   | hadoop.hdfs.server.namenode.snapshot.TestSnapshotNameWithInvalidCharacters |\r\n|   | hadoop.hdfs.server.blockmanagement.TestBlockManager |\r\n|   | hadoop.hdfs.server.datanode.TestDataNodeMultipleRegistrations |\r\n|   | hadoop.hdfs.TestSetrepIncreasing |\r\n|   | hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl |\r\n|   | hadoop.hdfs.shortcircuit.TestShortCircuitLocalRead |\r\n|   | hadoop.hdfs.server.datanode.TestDataNodeMetrics |\r\n|   | hadoop.hdfs.server.balancer.TestBalancerWithHANameNodes |\r\n|   | hadoop.hdfs.TestSetrepDecreasing |\r\n|   | hadoop.hdfs.server.datanode.TestDataNodeECN |\r\n|   | hadoop.hdfs.server.namenode.TestProcessCorruptBlocks |\r\n|   | hadoop.hdfs.server.datanode.TestDataNodeLifeline |\r\n|   | hadoop.hdfs.TestDatanodeStartupFixesLegacyStorageIDs |\r\n|   | hadoop.hdfs.server.datanode.checker.TestDatasetVolumeChecker |\r\n|   | hadoop.hdfs.server.namenode.TestSecondaryNameNodeUpgrade |\r\n|   | hadoop.hdfs.TestListFilesInFileContext |\r\n|   | hadoop.hdfs.server.datanode.TestDataNodeRollingUpgrade |\r\n|   | hadoop.hdfs.server.datanode.fsdataset.impl.TestLazyPersistReplicaPlacement |\r\n|   | hadoop.hdfs.server.datanode.TestIncrementalBrVariations |\r\n|   | hadoop.hdfs.TestDecommission |\r\n|   | hadoop.hdfs.server.namenode.TestValidateConfigurationSettings |\r\n|   | hadoop.hdfs.TestSeekBug |\r\n|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure |\r\n|   | hadoop.hdfs.TestDFSFinalize |\r\n|   | hadoop.hdfs.server.federation.store.driver.TestStateStoreFile |\r\n|   | hadoop.hdfs.server.datanode.TestTransferRbw |\r\n|   | hadoop.hdfs.server.balancer.TestBalancer |\r\n|   | hadoop.hdfs.server.federation.store.TestStateStoreMembershipState |\r\n|   | hadoop.hdfs.server.datanode.TestNNHandlesBlockReportPerStorage |\r\n|   | hadoop.hdfs.server.datanode.TestDataNodeInitStorage |\r\n|   | hadoop.hdfs.server.namenode.snapshot.TestXAttrWithSnapshot |\r\n|   | hadoop.hdfs.server.datanode.TestDataNodeHotSwapVolumes |\r\n|   | hadoop.hdfs.server.datanode.fsdataset.TestAvailableSpaceVolumeChoosingPolicy |\r\n|   | hadoop.hdfs.server.namenode.snapshot.TestSnapshot |\r\n|   | hadoop.hdfs.server.datanode.TestDataNodeMXBean |\r\n|   | hadoop.hdfs.server.datanode.TestBlockReplacement |\r\n|   | hadoop.hdfs.TestDatanodeConfig |\r\n|   | hadoop.hdfs.server.namenode.TestNNStorageRetentionFunctional |\r\n|   | hadoop.hdfs.TestTrashWithEncryptionZones |\r\n|   | hadoop.hdfs.server.blockmanagement.TestRBWBlockInvalidation |\r\n|   | hadoop.hdfs.TestFSInputChecker |\r\n|   | hadoop.hdfs.server.namenode.snapshot.TestSnapshotListing |\r\n|   | hadoop.hdfs.server.balancer.TestBalancerWithMultipleNameNodes |\r\n|   | hadoop.hdfs.TestDFSShellGenericOptions |\r\n|   | hadoop.hdfs.server.datanode.TestCachingStrategy |\r\n|   | hadoop.hdfs.server.balancer.TestKeyManager |\r\n|   | hadoop.hdfs.server.blockmanagement.TestBlockManagerSafeMode |\r\n|   | hadoop.hdfs.TestIsMethodSupported |\r\n|   | hadoop.hdfs.server.namenode.snapshot.TestINodeFileUnderConstructionWithSnapshot |\r\n|   | hadoop.hdfs.server.namenode.TestEditLogRace |\r\n|   | hadoop.hdfs.server.namenode.TestFileContextXAttr |\r\n|   | hadoop.hdfs.server.datanode.TestDataStorage |\r\n|   | hadoop.hdfs.server.blockmanagement.TestBlockStatsMXBean |\r\n|   | hadoop.hdfs.server.namenode.snapshot.TestDisallowModifyROSnapshot |\r\n|   | hadoop.hdfs.server.namenode.TestNamenodeCapacityReport |\r\n|   | hadoop.hdfs.server.namenode.snapshot.TestSnapshotReplication |\r\n|   | hadoop.hdfs.TestRollingUpgradeRollback |\r\n|   | hadoop.hdfs.server.blockmanagement.TestCachedBlocksList |\r\n|   | hadoop.hdfs.TestFsShellPermission |\r\n|   | hadoop.hdfs.server.datanode.fsdataset.impl.TestLazyWriter |\r\n|   | hadoop.hdfs.server.namenode.snapshot.TestCheckpointsWithSnapshots |\r\n|   | hadoop.hdfs.server.datanode.web.webhdfs.TestDataNodeUGIProvider |\r\n|   | hadoop.hdfs.server.federation.router.TestRouterRpcMultiDestination |\r\n|   | hadoop.hdfs.server.blockmanagement.TestNodeCount |\r\n|   | hadoop.hdfs.server.federation.store.TestStateStoreMountTable |\r\n|   | hadoop.hdfs.TestEncryptionZonesWithHA |\r\n|   | hadoop.hdfs.server.namenode.TestCacheDirectives |\r\n|   | hadoop.hdfs.server.datanode.TestHSync |\r\n|   | hadoop.hdfs.server.datanode.TestStorageReport |\r\n|   | hadoop.hdfs.TestTrashWithSecureEncryptionZones |\r\n|   | hadoop.hdfs.server.datanode.fsdataset.impl.TestLazyPersistReplicaRecovery |\r\n|   | hadoop.hdfs.TestBalancerBandwidth |\r\n|   | hadoop.hdfs.server.datanode.TestDataXceiverLazyPersistHint |\r\n|   | hadoop.hdfs.server.datanode.TestNNHandlesCombinedBlockReport |\r\n|   | hadoop.hdfs.server.datanode.TestDeleteBlockPool |\r\n|   | hadoop.hdfs.TestListFilesInDFS |\r\n|   | hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot |\r\n|   | hadoop.hdfs.TestDFSRename |\r\n|   | hadoop.hdfs.server.federation.router.TestRouterAdmin |\r\n|   | hadoop.hdfs.server.datanode.TestDataDirs |\r\n|   | hadoop.hdfs.server.datanode.TestBPOfferService |\r\n|   | hadoop.hdfs.server.namenode.snapshot.TestSnapshotStatsMXBean |\r\n|   | hadoop.hdfs.server.datanode.TestDirectoryScanner |\r\n|   | hadoop.hdfs.server.datanode.TestDatanodeProtocolRetryPolicy |\r\n|   | hadoop.hdfs.server.datanode.checker.TestThrottledAsyncCheckerTimeout |\r\n|   | hadoop.hdfs.server.namenode.startupprogress.TestStartupProgress |\r\n|   | hadoop.hdfs.server.datanode.fsdataset.impl.TestDatanodeRestart |\r\n| Timed out junit tests | org.apache.hadoop.hdfs.TestLeaseRecovery2 |\r\n|   | org.apache.hadoop.hdfs.TestDatanodeRegistration |\r\n|   | org.apache.hadoop.hdfs.TestDFSClientFailover |\r\n|   | org.apache.hadoop.hdfs.web.TestWebHdfsTokens |\r\n|   | org.apache.hadoop.hdfs.TestDFSInotifyEventInputStream |\r\n|   | org.apache.hadoop.hdfs.TestDatanodeLayoutUpgrade |\r\n|   | org.apache.hadoop.hdfs.TestFileAppendRestart |\r\n|   | org.apache.hadoop.hdfs.web.TestWebHdfsWithRestCsrfPreventionFilter |\r\n|   | org.apache.hadoop.hdfs.TestDatanodeReport |\r\n|   | org.apache.hadoop.hdfs.web.TestWebHDFS |\r\n|   | org.apache.hadoop.hdfs.web.TestWebHDFSXAttr |\r\n|   | org.apache.hadoop.hdfs.web.TestWebHdfsWithMultipleNameNodes |\r\n|   | org.apache.hadoop.metrics2.sink.TestRollingFileSystemSinkWithHdfs |\r\n|   | org.apache.hadoop.hdfs.TestMiniDFSCluster |\r\n|   | org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs |\r\n|   | org.apache.hadoop.hdfs.TestDistributedFileSystem |\r\n|   | org.apache.hadoop.hdfs.web.TestWebHDFSForHA |\r\n|   | org.apache.hadoop.hdfs.TestReplaceDatanodeFailureReplication |\r\n|   | org.apache.hadoop.hdfs.TestDFSShell |\r\n|   | org.apache.hadoop.hdfs.web.TestWebHDFSAcl |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:17213a0 |\r\n| JIRA Issue | HDFS-10453 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12806883/HDFS-10453-branch-2.003.patch |\r\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |\r\n| uname | Linux 7920063eca16 3.13.0-135-generic #184-Ubuntu SMP Wed Oct 18 11:55:51 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | /testptch/patchprocess/precommit/personality/provided.sh |\r\n| git revision | branch-2 / 046424c |\r\n| maven | version: Apache Maven 3.3.9 (bb52d8502b132ec0a5a3f4c09453c07478323dc5; 2015-11-10T16:41:47+00:00) |\r\n| Default Java | 1.7.0_151 |\r\n| findbugs | v3.0.0 |\r\n| Unreaped Processes Log | https://builds.apache.org/job/PreCommit-HDFS-Build/22311/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs-reaper.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/22311/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |\r\n|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/22311/testReport/ |\r\n| asflicense | https://builds.apache.org/job/PreCommit-HDFS-Build/22311/artifact/out/patch-asflicense-problems.txt |\r\n| Max. process+thread count | 4898 (vs. ulimit of 5000) |\r\n| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |\r\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/22311/console |\r\n| Powered by | Apache Yetus 0.7.0-SNAPSHOT   http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=genericqa","name":"genericqa","key":"genericqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=genericqa&avatarId=33630","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=genericqa&avatarId=33630","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=genericqa&avatarId=33630","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=genericqa&avatarId=33630"},"displayName":"genericqa","active":true,"timeZone":"Etc/UTC"},"created":"2017-12-07T09:22:49.967+0000","updated":"2017-12-07T09:22:49.967+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12972299/comment/16281571","id":"16281571","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hexiaoqiao","name":"hexiaoqiao","key":"hexiaoqiao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hexiaoqiao&avatarId=26980","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hexiaoqiao&avatarId=26980","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hexiaoqiao&avatarId=26980","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hexiaoqiao&avatarId=26980"},"displayName":"He Xiaoqiao","active":true,"timeZone":"Asia/Shanghai"},"body":"[~Octivian] [~genericqa]\r\nThanks for your comments and tests. Actually you are right, it needs add lock to {{neededReplications}} exactly. In our production env, this patch has update with synchronized of {{neededReplications}}.\r\nI will update this patch for a moment.\r\nThanks again.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hexiaoqiao","name":"hexiaoqiao","key":"hexiaoqiao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hexiaoqiao&avatarId=26980","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hexiaoqiao&avatarId=26980","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hexiaoqiao&avatarId=26980","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hexiaoqiao&avatarId=26980"},"displayName":"He Xiaoqiao","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-12-07T09:44:03.210+0000","updated":"2017-12-07T09:44:03.210+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12972299/comment/16281686","id":"16281686","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hexiaoqiao","name":"hexiaoqiao","key":"hexiaoqiao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hexiaoqiao&avatarId=26980","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hexiaoqiao&avatarId=26980","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hexiaoqiao&avatarId=26980","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hexiaoqiao&avatarId=26980"},"displayName":"He Xiaoqiao","active":true,"timeZone":"Asia/Shanghai"},"body":"attach new patch for branch-2.7","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hexiaoqiao","name":"hexiaoqiao","key":"hexiaoqiao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hexiaoqiao&avatarId=26980","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hexiaoqiao&avatarId=26980","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hexiaoqiao&avatarId=26980","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hexiaoqiao&avatarId=26980"},"displayName":"He Xiaoqiao","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-12-07T10:55:48.636+0000","updated":"2017-12-07T10:55:48.636+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12972299/comment/16281696","id":"16281696","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hexiaoqiao","name":"hexiaoqiao","key":"hexiaoqiao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hexiaoqiao&avatarId=26980","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hexiaoqiao&avatarId=26980","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hexiaoqiao&avatarId=26980","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hexiaoqiao&avatarId=26980"},"displayName":"He Xiaoqiao","active":true,"timeZone":"Asia/Shanghai"},"body":"[~Octivian] The new patch is ready and update based on you mentioned above, FYI.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hexiaoqiao","name":"hexiaoqiao","key":"hexiaoqiao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hexiaoqiao&avatarId=26980","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hexiaoqiao&avatarId=26980","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hexiaoqiao&avatarId=26980","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hexiaoqiao&avatarId=26980"},"displayName":"He Xiaoqiao","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-12-07T11:02:50.822+0000","updated":"2017-12-07T11:02:50.822+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12972299/comment/16287059","id":"16287059","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=water","name":"water","key":"water","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=water&avatarId=32871","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=water&avatarId=32871","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=water&avatarId=32871","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=water&avatarId=32871"},"displayName":"Xiang Li","active":true,"timeZone":"Asia/Shanghai"},"body":"[~hexiaoqiao], thanks for the patch and quick update!\r\nShall we need to call {{neededReplications.decrementReplicationIndex(priority)}} after {{neededReplications.remove(rw.block, rw.priority)}}\r\nto make it like\r\n{code}\r\nif (rw.block.getNumBytes() == BlockCommand.NO_ACK) {\r\n  // remove from neededReplications while block has deleted.\r\n  neededReplications.remove(rw.block, rw.priority);\r\n  neededReplications.remove(rw.priority) // <-- here\r\n}\r\n{code}\r\nI am not quite familiar with those code, please advise\r\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=water","name":"water","key":"water","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=water&avatarId=32871","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=water&avatarId=32871","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=water&avatarId=32871","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=water&avatarId=32871"},"displayName":"Xiang Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-12-12T03:51:49.816+0000","updated":"2017-12-12T03:51:49.816+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12972299/comment/16287183","id":"16287183","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hexiaoqiao","name":"hexiaoqiao","key":"hexiaoqiao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hexiaoqiao&avatarId=26980","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hexiaoqiao&avatarId=26980","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hexiaoqiao&avatarId=26980","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hexiaoqiao&avatarId=26980"},"displayName":"He Xiaoqiao","active":true,"timeZone":"Asia/Shanghai"},"body":"[~Octivian] thanks for your suggestions, we do need to update {{priorityToReplIdx}} when remove block/blocks from {{neededReplications}}. I just upload new patch for branch-2.7, please let me know if i am wrong.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hexiaoqiao","name":"hexiaoqiao","key":"hexiaoqiao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hexiaoqiao&avatarId=26980","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hexiaoqiao&avatarId=26980","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hexiaoqiao&avatarId=26980","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hexiaoqiao&avatarId=26980"},"displayName":"He Xiaoqiao","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-12-12T06:23:16.012+0000","updated":"2017-12-12T06:23:16.012+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12972299/comment/16287441","id":"16287441","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=genericqa","name":"genericqa","key":"genericqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=genericqa&avatarId=33630","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=genericqa&avatarId=33630","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=genericqa&avatarId=33630","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=genericqa&avatarId=33630"},"displayName":"genericqa","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 18m 20s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |\r\n|| || || || {color:brown} branch-2.7 Compile Tests {color} ||\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  5m 54s{color} | {color:green} branch-2.7 passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m  1s{color} | {color:green} branch-2.7 passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 24s{color} | {color:green} branch-2.7 passed {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  0s{color} | {color:green} branch-2.7 passed {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 54s{color} | {color:green} branch-2.7 passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 47s{color} | {color:green} branch-2.7 passed {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 54s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 59s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 59s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 22s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 57s{color} | {color:green} the patch passed {color} |\r\n| {color:red}-1{color} | {color:red} whitespace {color} | {color:red}  0m  0s{color} | {color:red} The patch has 60 line(s) that end in whitespace. Use git apply --whitespace=fix <<patch_file>>. Refer https://git-scm.com/docs/git-apply {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  3m  4s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 44s{color} | {color:green} the patch passed {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}106m  9s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |\r\n| {color:red}-1{color} | {color:red} asflicense {color} | {color:red}  1m 15s{color} | {color:red} The patch generated 1 ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black}148m 22s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Reason || Tests ||\r\n| Unreaped Processes | hadoop-hdfs:25 |\r\n| Failed junit tests | hadoop.hdfs.TestBlocksScheduledCounter |\r\n|   | hadoop.hdfs.TestListFilesInDFS |\r\n| Timed out junit tests | org.apache.hadoop.hdfs.TestLeaseRecovery2 |\r\n|   | org.apache.hadoop.hdfs.TestDatanodeRegistration |\r\n|   | org.apache.hadoop.hdfs.TestDFSClientFailover |\r\n|   | org.apache.hadoop.hdfs.TestRead |\r\n|   | org.apache.hadoop.security.TestPermission |\r\n|   | org.apache.hadoop.hdfs.web.TestWebHdfsTokens |\r\n|   | org.apache.hadoop.hdfs.TestDFSInotifyEventInputStream |\r\n|   | org.apache.hadoop.hdfs.TestFileAppendRestart |\r\n|   | org.apache.hadoop.hdfs.TestReadWhileWriting |\r\n|   | org.apache.hadoop.hdfs.security.TestDelegationToken |\r\n|   | org.apache.hadoop.hdfs.TestDFSOutputStream |\r\n|   | org.apache.hadoop.hdfs.TestDFSMkdirs |\r\n|   | org.apache.hadoop.security.TestRefreshUserMappings |\r\n|   | org.apache.hadoop.hdfs.TestDatanodeReport |\r\n|   | org.apache.hadoop.hdfs.web.TestWebHDFS |\r\n|   | org.apache.hadoop.hdfs.web.TestWebHDFSXAttr |\r\n|   | org.apache.hadoop.hdfs.web.TestWebHdfsWithMultipleNameNodes |\r\n|   | org.apache.hadoop.hdfs.TestMiniDFSCluster |\r\n|   | org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs |\r\n|   | org.apache.hadoop.hdfs.TestDistributedFileSystem |\r\n|   | org.apache.hadoop.hdfs.web.TestWebHDFSForHA |\r\n|   | org.apache.hadoop.hdfs.TestDFSShell |\r\n|   | org.apache.hadoop.hdfs.web.TestWebHDFSAcl |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:67e87c9 |\r\n| JIRA Issue | HDFS-10453 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12901616/HDFS-10453-branch-2.7.005.patch |\r\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |\r\n| uname | Linux 40f6f64acae3 3.13.0-135-generic #184-Ubuntu SMP Wed Oct 18 11:55:51 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | /testptch/patchprocess/precommit/personality/provided.sh |\r\n| git revision | branch-2.7 / a4dd069 |\r\n| maven | version: Apache Maven 3.0.5 |\r\n| Default Java | 1.7.0_151 |\r\n| findbugs | v3.0.0 |\r\n| whitespace | https://builds.apache.org/job/PreCommit-HDFS-Build/22362/artifact/out/whitespace-eol.txt |\r\n| Unreaped Processes Log | https://builds.apache.org/job/PreCommit-HDFS-Build/22362/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs-reaper.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/22362/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |\r\n|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/22362/testReport/ |\r\n| asflicense | https://builds.apache.org/job/PreCommit-HDFS-Build/22362/artifact/out/patch-asflicense-problems.txt |\r\n| Max. process+thread count | 4898 (vs. ulimit of 5000) |\r\n| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |\r\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/22362/console |\r\n| Powered by | Apache Yetus 0.7.0-SNAPSHOT   http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=genericqa","name":"genericqa","key":"genericqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=genericqa&avatarId=33630","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=genericqa&avatarId=33630","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=genericqa&avatarId=33630","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=genericqa&avatarId=33630"},"displayName":"genericqa","active":true,"timeZone":"Etc/UTC"},"created":"2017-12-12T11:01:48.064+0000","updated":"2017-12-12T11:01:48.064+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12972299/comment/16288578","id":"16288578","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=water","name":"water","key":"water","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=water&avatarId=32871","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=water&avatarId=32871","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=water&avatarId=32871","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=water&avatarId=32871"},"displayName":"Xiang Li","active":true,"timeZone":"Asia/Shanghai"},"body":"Agree. Thanks xiaoqiao!","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=water","name":"water","key":"water","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=water&avatarId=32871","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=water&avatarId=32871","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=water&avatarId=32871","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=water&avatarId=32871"},"displayName":"Xiang Li","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-12-13T01:26:05.458+0000","updated":"2017-12-13T01:26:05.458+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12972299/comment/16347753","id":"16347753","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ajayydv","name":"ajayydv","key":"ajayydv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ajay Kumar","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi [~hexiaoqiao], Thanks for working on this. Patch looks good to me. One minor suggestion, I think we can simplify the patch a bit myÂ merging the new check {{if (rw.block.getNumBytes() == BlockCommand.NO_ACK)}}Â with {{if(bc == null || (bc.isUnderConstruction() && block.equals(bc.getLastBlock())))}} inside {{BlockManager#computeReplicationWorkForBlocks}}Â L1501.\r\n\r\nÂ ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ajayydv","name":"ajayydv","key":"ajayydv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ajay Kumar","active":true,"timeZone":"America/Los_Angeles"},"created":"2018-01-31T23:10:51.691+0000","updated":"2018-01-31T23:12:24.992+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12972299/comment/16348056","id":"16348056","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hexiaoqiao","name":"hexiaoqiao","key":"hexiaoqiao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hexiaoqiao&avatarId=26980","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hexiaoqiao&avatarId=26980","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hexiaoqiao&avatarId=26980","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hexiaoqiao&avatarId=26980"},"displayName":"He Xiaoqiao","active":true,"timeZone":"Asia/Shanghai"},"body":"[~ajayydv]Â Thank you for your suggestion,Â  I just attach new patch [#HDFS-10453-branch-2.7.006.patch]Â for branch-2.7 and first check if {{block}} is abandoned or reopen for append, thus it can avoid choose target fail for deleted blocks endless loop. FYI.\r\nplease correct me if i am wrong, Thanks again.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hexiaoqiao","name":"hexiaoqiao","key":"hexiaoqiao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hexiaoqiao&avatarId=26980","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hexiaoqiao&avatarId=26980","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hexiaoqiao&avatarId=26980","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hexiaoqiao&avatarId=26980"},"displayName":"He Xiaoqiao","active":true,"timeZone":"Asia/Shanghai"},"created":"2018-02-01T06:03:05.394+0000","updated":"2018-02-01T06:03:05.394+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12972299/comment/16348172","id":"16348172","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=genericqa","name":"genericqa","key":"genericqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=genericqa&avatarId=33630","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=genericqa&avatarId=33630","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=genericqa&avatarId=33630","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=genericqa&avatarId=33630"},"displayName":"genericqa","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 15m 11s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |\r\n|| || || || {color:brown} branch-2.7 Compile Tests {color} ||\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  7m 57s{color} | {color:green} branch-2.7 passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m  8s{color} | {color:green} branch-2.7 passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 27s{color} | {color:green} branch-2.7 passed {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  5s{color} | {color:green} branch-2.7 passed {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  3m  5s{color} | {color:green} branch-2.7 passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 44s{color} | {color:green} branch-2.7 passed {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 55s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m  6s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  1m  6s{color} | {color:green} the patch passed {color} |\r\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 25s{color} | {color:orange} hadoop-hdfs-project/hadoop-hdfs: The patch generated 1 new + 237 unchanged - 1 fixed = 238 total (was 238) {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 59s{color} | {color:green} the patch passed {color} |\r\n| {color:red}-1{color} | {color:red} whitespace {color} | {color:red}  0m  0s{color} | {color:red} The patch has 60 line(s) that end in whitespace. Use git apply --whitespace=fix <<patch_file>>. Refer https://git-scm.com/docs/git-apply {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  3m 18s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 47s{color} | {color:green} the patch passed {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 93m  1s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |\r\n| {color:red}-1{color} | {color:red} asflicense {color} | {color:red}  1m 20s{color} | {color:red} The patch generated 204 ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black}135m  9s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Reason || Tests ||\r\n| Unreaped Processes | hadoop-hdfs:22 |\r\n| Failed junit tests | hadoop.hdfs.TestBlockReaderLocal |\r\n|   | hadoop.hdfs.TestDatanodeDeath |\r\n|   | hadoop.hdfs.TestSetrepIncreasing |\r\n|   | hadoop.hdfs.TestDataTransferProtocol |\r\n|   | hadoop.hdfs.TestDFSFinalize |\r\n| Timed out junit tests | org.apache.hadoop.hdfs.TestLeaseRecovery2 |\r\n|   | org.apache.hadoop.hdfs.TestDatanodeRegistration |\r\n|   | org.apache.hadoop.hdfs.TestDFSClientFailover |\r\n|   | org.apache.hadoop.hdfs.TestDFSClientRetries |\r\n|   | org.apache.hadoop.hdfs.web.TestWebHdfsTokens |\r\n|   | org.apache.hadoop.hdfs.TestDFSInotifyEventInputStream |\r\n|   | org.apache.hadoop.hdfs.TestFileAppendRestart |\r\n|   | org.apache.hadoop.hdfs.TestSeekBug |\r\n|   | org.apache.hadoop.hdfs.TestDFSMkdirs |\r\n|   | org.apache.hadoop.hdfs.TestDatanodeReport |\r\n|   | org.apache.hadoop.hdfs.web.TestWebHDFS |\r\n|   | org.apache.hadoop.hdfs.web.TestWebHDFSXAttr |\r\n|   | org.apache.hadoop.hdfs.web.TestWebHdfsWithMultipleNameNodes |\r\n|   | org.apache.hadoop.hdfs.TestDFSRollback |\r\n|   | org.apache.hadoop.hdfs.TestMiniDFSCluster |\r\n|   | org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs |\r\n|   | org.apache.hadoop.hdfs.TestDistributedFileSystem |\r\n|   | org.apache.hadoop.hdfs.web.TestWebHDFSForHA |\r\n|   | org.apache.hadoop.hdfs.TestSetTimes |\r\n|   | org.apache.hadoop.hdfs.TestDFSShell |\r\n|   | org.apache.hadoop.hdfs.web.TestWebHDFSAcl |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:ea57d10 |\r\n| JIRA Issue | HDFS-10453 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12908724/HDFS-10453-branch-2.7.006.patch |\r\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |\r\n| uname | Linux 631a51fc69f4 3.13.0-135-generic #184-Ubuntu SMP Wed Oct 18 11:55:51 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | /testptch/patchprocess/precommit/personality/provided.sh |\r\n| git revision | branch-2.7 / 1ef88c9 |\r\n| maven | version: Apache Maven 3.0.5 |\r\n| Default Java | 1.7.0_151 |\r\n| findbugs | v3.0.0 |\r\n| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/22915/artifact/out/diff-checkstyle-hadoop-hdfs-project_hadoop-hdfs.txt |\r\n| whitespace | https://builds.apache.org/job/PreCommit-HDFS-Build/22915/artifact/out/whitespace-eol.txt |\r\n| Unreaped Processes Log | https://builds.apache.org/job/PreCommit-HDFS-Build/22915/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs-reaper.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/22915/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |\r\n|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/22915/testReport/ |\r\n| asflicense | https://builds.apache.org/job/PreCommit-HDFS-Build/22915/artifact/out/patch-asflicense-problems.txt |\r\n| Max. process+thread count | 4890 (vs. ulimit of 5000) |\r\n| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |\r\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/22915/console |\r\n| Powered by | Apache Yetus 0.8.0-SNAPSHOT   http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=genericqa","name":"genericqa","key":"genericqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=genericqa&avatarId=33630","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=genericqa&avatarId=33630","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=genericqa&avatarId=33630","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=genericqa&avatarId=33630"},"displayName":"genericqa","active":true,"timeZone":"Etc/UTC"},"created":"2018-02-01T08:15:55.046+0000","updated":"2018-02-01T08:15:55.046+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12972299/comment/16348942","id":"16348942","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ajayydv","name":"ajayydv","key":"ajayydv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ajay Kumar","active":true,"timeZone":"America/Los_Angeles"},"body":"[~hexiaoqiao], thanks for updating the patch. New patch doesn't contains your initial check:\r\n\r\n{code}\r\nif (rw.block.getNumBytes() == BlockCommand.NO_ACK) {\r\n\t              // remove from neededReplications while block has deleted.\r\n\t              neededReplications.remove(rw.block, rw.priority);\r\n\t              neededReplications.decrementReplicationIndex(rw.priority);\r\n}\r\n{code}\r\n\r\nI was suggesting something like this:\r\n{code}\r\n // abandoned block or block reopened for append or deleted block\r\n          if(bc == null || (bc.isUnderConstruction() && block.equals(bc\r\n              .getLastBlock())) || (block.getNumBytes() == BlockCommand.NO_ACK)) {\r\n            neededReplications.remove(block, priority); // remove from neededReplications\r\n            rw.targets = null;\r\n            neededReplications.decrementReplicationIndex(priority);\r\n            continue;\r\n          }\r\n{code}\r\n[~stevel@apache.org],[~xyao],[~andrew.wang] mind to have a look and share you feedback? ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ajayydv","name":"ajayydv","key":"ajayydv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ajay Kumar","active":true,"timeZone":"America/Los_Angeles"},"created":"2018-02-01T17:18:31.915+0000","updated":"2018-02-01T17:18:31.915+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12972299/comment/16349077","id":"16349077","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"Not my area of expertise at all; I'm not safe to have opinions on it. Sorry","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2018-02-01T18:38:08.247+0000","updated":"2018-02-01T18:38:08.247+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12972299/comment/16349730","id":"16349730","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hexiaoqiao","name":"hexiaoqiao","key":"hexiaoqiao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hexiaoqiao&avatarId=26980","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hexiaoqiao&avatarId=26980","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hexiaoqiao&avatarId=26980","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hexiaoqiao&avatarId=26980"},"displayName":"He Xiaoqiao","active":true,"timeZone":"Asia/Shanghai"},"body":"[~ajayydv] Thanks for your reviews. In the lastest patch, I check if {{BlockCollection}} of {{block}} is null firstly, I think it can cover {{block.getNumBytes() == BlockCommand.NO_ACK}} since {{bc}} which take out from {{blocksmap}} is NULL now when it has been deleted. Thus it is not necessary to check if block's size is BlockCommand.NO_ACK. FYI.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hexiaoqiao","name":"hexiaoqiao","key":"hexiaoqiao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hexiaoqiao&avatarId=26980","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hexiaoqiao&avatarId=26980","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hexiaoqiao&avatarId=26980","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hexiaoqiao&avatarId=26980"},"displayName":"He Xiaoqiao","active":true,"timeZone":"Asia/Shanghai"},"created":"2018-02-02T03:36:42.501+0000","updated":"2018-02-02T03:36:42.501+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12972299/comment/16350705","id":"16350705","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hexiaoqiao","name":"hexiaoqiao","key":"hexiaoqiao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hexiaoqiao&avatarId=26980","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hexiaoqiao&avatarId=26980","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hexiaoqiao&avatarId=26980","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hexiaoqiao&avatarId=26980"},"displayName":"He Xiaoqiao","active":true,"timeZone":"Asia/Shanghai"},"body":"ping [~ajayydv], please share your feedback and give some suggestions at your convenience. thanks again.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hexiaoqiao","name":"hexiaoqiao","key":"hexiaoqiao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hexiaoqiao&avatarId=26980","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hexiaoqiao&avatarId=26980","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hexiaoqiao&avatarId=26980","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hexiaoqiao&avatarId=26980"},"displayName":"He Xiaoqiao","active":true,"timeZone":"Asia/Shanghai"},"created":"2018-02-02T17:35:48.347+0000","updated":"2018-02-02T17:35:48.347+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12972299/comment/16350826","id":"16350826","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ajayydv","name":"ajayydv","key":"ajayydv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ajay Kumar","active":true,"timeZone":"America/Los_Angeles"},"body":" [~hexiaoqiao], \r\n{quote} I think it can cover block.getNumBytes() == BlockCommand.NO_ACK since bc which take out from blocksmap is NULL now when it has been deleted. Thus it is not necessary to check if block's size is BlockCommand.NO_ACK.{quote}\r\nThis check {{if(bc == null || (bc.isUnderConstruction() && block.equals(bc.getLastBlock())))}} in {{BlockManager#computeReplicationWorkForBlocks}} exists already. So, if it was handling this case we will not face it. I think this additional check for {{block.getNumBytes() == BlockCommand.NO_ACK}} is required. Lets confirm with few experts in community.\r\n\r\n[~arpitagarwal],[~ajisakaa] Mind having a look?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ajayydv","name":"ajayydv","key":"ajayydv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ajay Kumar","active":true,"timeZone":"America/Los_Angeles"},"created":"2018-02-02T19:15:31.280+0000","updated":"2018-02-02T19:15:31.280+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12972299/comment/16351434","id":"16351434","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hexiaoqiao","name":"hexiaoqiao","key":"hexiaoqiao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hexiaoqiao&avatarId=26980","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hexiaoqiao&avatarId=26980","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hexiaoqiao&avatarId=26980","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hexiaoqiao&avatarId=26980"},"displayName":"He Xiaoqiao","active":true,"timeZone":"Asia/Shanghai"},"body":"hi [~ajayydv]\r\n{quote}This checkÂ {{if(bc == null || (bc.isUnderConstruction() && block.equals(bc.getLastBlock())))}}Â inÂ {{BlockManager#computeReplicationWorkForBlocks}}Â exists already. So, if it was handling this case we will not face it. I think this additional check forÂ {{block.getNumBytes() == BlockCommand.NO_ACK}}Â is required.\r\n{quote}\r\nSince BlockManager#computeReplicationWorkForBlocks checks if \\{{(bc == null || (bc.isUnderConstruction() && block.equals(bc.getLastBlock()))}} after check if \\{{target == null}} which is always true, then the block will not be removed from {{neededReplications}},Â ReplicationMonitor#run willÂ continue to chooseTargets for the same block and no node will be selected even if traverse all nodes of cluster in next loop and so on. This case will avoid if check \\{{block == null}} before \\{{target == null}}.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hexiaoqiao","name":"hexiaoqiao","key":"hexiaoqiao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hexiaoqiao&avatarId=26980","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hexiaoqiao&avatarId=26980","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hexiaoqiao&avatarId=26980","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hexiaoqiao&avatarId=26980"},"displayName":"He Xiaoqiao","active":true,"timeZone":"Asia/Shanghai"},"created":"2018-02-03T16:11:53.145+0000","updated":"2018-02-03T16:11:53.145+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12972299/comment/16352702","id":"16352702","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xkrogen","name":"xkrogen","key":"xkrogen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=xkrogen&avatarId=34526","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=xkrogen&avatarId=34526","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=xkrogen&avatarId=34526","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=xkrogen&avatarId=34526"},"displayName":"Erik Krogen","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi [~hexiaoqiao], goodÂ catch on discovering and diagnosing this issue. We have seen it as well. I agree with your last comment that we can use the check for the null block collection; when the size is set to {{NO_ACK}} in {{BlockManager#removeBlock()}}, the block collection is also set to null. A deleted block should always be removed from the {{needingReplications}} list regardless of whether or not any targets were found for it, so it makes sense to perform this check before the check for an empty targets list. This change does mean that, if no targets are returned, we have to acquire the lock on {{neededReplications}} whereas as we did not previously, but I think this situation is infrequent enough that it is not an issue.\r\n\r\nMy one comment on the v006 patch main code: why do you choose to add the {{blocksize == BlockCommand.NO_ACK}} check within {{BlockPlacementPolicyDefault#chooseTarget(String, int, Node, List<DatanodeStorageInfo>, boolean, Set<Node>, long, BlockStoragePolicy)}}, currently just a delegation method, rather than {{BlockPlacementPolicyDefault#chooseTarget(int, Node, List<DatanodeStorageInfo>, boolean, Set<Node>, long, BlockStoragePolicy)}}, where the implementation lives? It seems it would be better to keep this logic centralized in the implementation method.\r\n\r\nFew comments on the test as well:\r\n* We should set {{DFSConfigKeys.DFS_NAMENODE_REPLICATION_INTERVAL_KEY}} to be a lower value (i.e. 1) to avoid the test taking longer than necessary.\r\n* The line creating the MiniDFSCluster is too long. Not sure why checkstyle is not complaining.\r\n* Can we use {{GenericTestUtils#waitFor()}} instead of a {{sleep()}} to be more robust about waiting for the ReplicationMonitor to remove the deleted block from its list?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xkrogen","name":"xkrogen","key":"xkrogen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=xkrogen&avatarId=34526","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=xkrogen&avatarId=34526","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=xkrogen&avatarId=34526","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=xkrogen&avatarId=34526"},"displayName":"Erik Krogen","active":true,"timeZone":"America/Los_Angeles"},"created":"2018-02-05T18:00:52.396+0000","updated":"2018-02-05T18:00:52.396+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12972299/comment/16353143","id":"16353143","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vagarychen","name":"vagarychen","key":"vagarychen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chen Liang","active":true,"timeZone":"America/Los_Angeles"},"body":"This is a very tricky case, thanks [~hexiaoqiao] for working on this, really appreciate! I've only looked through v6 patch on branch-2.7, and I've got a question.\r\n\r\nGiven the change in {{BlockPlacementPolicyDefault#chooseTarget}} that, if the size is {{NO_ACK}}, it immediately returns an empty array, do we still really need the change in {{BlockManager#computeReplicationWorkForBlocks}}? Because with the change in {{chooseTarget}}, I think {{rw.chooseTargets(...);}} would set {{rw.targets}} to empty array, then in {{computeReplicationWorkForBlocks}}, {{if(targets == null || targets.length == 0)}} will be true and the {{rw}} gets skipped.\r\n\r\nIn addition, the check {{blocksize == BlockCommand.NO_ACK}} in {{BlockPlacementPolicyDefault}} seems a bit hacky. Because I think this flag {{NO_ACK}} only specifically means \"an indicator of no need for DN to ack\", but we are using it here as \"an indicator that the block does not need placement\". Can't think of a better easy alternative though, ideally, we may need another flag to indicate blocks being removed. But for now at least we can do something to make this easier to track in the future, such as:\r\n 1. add some explanation comments on what this check is about, i.e. why NO_ACK is against blockSize.\r\n 2. maybe move this check to merge in the check in L196 {{if (numOfReplicas == 0 || clusterMap.getNumOfLeaves()==0)}}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vagarychen","name":"vagarychen","key":"vagarychen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chen Liang","active":true,"timeZone":"America/Los_Angeles"},"created":"2018-02-06T00:26:33.243+0000","updated":"2018-02-06T00:50:24.058+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12972299/comment/16353480","id":"16353480","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hexiaoqiao","name":"hexiaoqiao","key":"hexiaoqiao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hexiaoqiao&avatarId=26980","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hexiaoqiao&avatarId=26980","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hexiaoqiao&avatarId=26980","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hexiaoqiao&avatarId=26980"},"displayName":"He Xiaoqiao","active":true,"timeZone":"Asia/Shanghai"},"body":"[~xkrogen] [~vagarychen],\r\n\r\nThanks for you comments, I attach #HDFS-10453-branch-2.7.007.patch following your suggestions.\r\n{quote}Given the change inÂ {{BlockPlacementPolicyDefault#chooseTarget}}Â that, if the size isÂ {{NO_ACK}}, it immediately returns an empty array, do we still really need the change inÂ {{BlockManager#computeReplicationWorkForBlocks}}? Because with the change inÂ {{chooseTarget}}, I thinkÂ {{rw.chooseTargets(...);}}Â would setÂ {{rw.targets}}Â to empty array, then inÂ {{computeReplicationWorkForBlocks}},Â {{if(targets == null || targets.length == 0)}}Â will be true and theÂ \\{{rw}}gets skipped.\r\n{quote}\r\nI think it is necessary to check if Block is null inÂ BlockManager#computeReplicationWorkForBlocks, even if return empty in rw#chooseTargets when block has been deleted, because there are many cases lead to return of rw#chooseTarget is empty/null, if checkÂ {{if(targets == null || targets.length == 0)}} and continue loop, it will waste some CPU resource,Â especiallyÂ anyÂ case as this Jira describe. on another hand, I am not sure if there are some other case cause block to beÂ  null, if check \\{{bc == null}} firstly, it won't make the situation worse at least.\r\n{quote}I think this flagÂ {{NO_ACK}}Â only specifically means \"an indicator of no need for DN to ack\", but we are using it here as \"an indicator that the block does not need placement\".Â \r\n{quote}\r\nas you mentioned, this flag used here is not original intention indeed, but I think it canÂ describe `deleted block` as the annotation in branch-2.7:\r\n{quote}/**\r\n * This constant is used to indicate that the block deletion does not need\r\n * explicit ACK from the datanode. When a block is put into the list of blocks\r\n * to be deleted, it's size is set to this constant. We assume that no block\r\n * would actually have this size. Otherwise, we would miss ACKs for blocks\r\n * with such size. Positive number is used for compatibility reasons.\r\n */\r\npublic static final long NO_ACK = Long.MAX_VALUE;\r\n{quote}\r\n[~xkrogen] [~vagarychen]Â thanks again and please let me know if there are something wrong.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hexiaoqiao","name":"hexiaoqiao","key":"hexiaoqiao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hexiaoqiao&avatarId=26980","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hexiaoqiao&avatarId=26980","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hexiaoqiao&avatarId=26980","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hexiaoqiao&avatarId=26980"},"displayName":"He Xiaoqiao","active":true,"timeZone":"Asia/Shanghai"},"created":"2018-02-06T07:01:24.310+0000","updated":"2018-02-06T07:01:24.310+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12972299/comment/16353567","id":"16353567","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=genericqa","name":"genericqa","key":"genericqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=genericqa&avatarId=33630","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=genericqa&avatarId=33630","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=genericqa&avatarId=33630","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=genericqa&avatarId=33630"},"displayName":"genericqa","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 16m 26s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |\r\n|| || || || {color:brown} branch-2.7 Compile Tests {color} ||\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  6m 21s{color} | {color:green} branch-2.7 passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m  6s{color} | {color:green} branch-2.7 passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 26s{color} | {color:green} branch-2.7 passed {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 59s{color} | {color:green} branch-2.7 passed {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  3m  2s{color} | {color:green} branch-2.7 passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 47s{color} | {color:green} branch-2.7 passed {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m  0s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m  4s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  1m  4s{color} | {color:green} the patch passed {color} |\r\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 25s{color} | {color:orange} hadoop-hdfs-project/hadoop-hdfs: The patch generated 1 new + 237 unchanged - 1 fixed = 238 total (was 238) {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  3s{color} | {color:green} the patch passed {color} |\r\n| {color:red}-1{color} | {color:red} whitespace {color} | {color:red}  0m  0s{color} | {color:red} The patch has 60 line(s) that end in whitespace. Use git apply --whitespace=fix <<patch_file>>. Refer https://git-scm.com/docs/git-apply {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  3m 23s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 45s{color} | {color:green} the patch passed {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 79m 12s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |\r\n| {color:red}-1{color} | {color:red} asflicense {color} | {color:red}  1m 29s{color} | {color:red} The patch generated 321 ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black}121m 13s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Reason || Tests ||\r\n| Unreaped Processes | hadoop-hdfs:20 |\r\n| Failed junit tests | hadoop.hdfs.TestClientBlockVerification |\r\n|   | hadoop.hdfs.web.TestWebHdfsFileSystemContract |\r\n| Timed out junit tests | org.apache.hadoop.hdfs.TestLeaseRecovery2 |\r\n|   | org.apache.hadoop.hdfs.TestDatanodeRegistration |\r\n|   | org.apache.hadoop.hdfs.TestDFSClientFailover |\r\n|   | org.apache.hadoop.hdfs.TestDFSClientRetries |\r\n|   | org.apache.hadoop.security.TestPermission |\r\n|   | org.apache.hadoop.hdfs.web.TestWebHdfsTokens |\r\n|   | org.apache.hadoop.hdfs.TestDFSInotifyEventInputStream |\r\n|   | org.apache.hadoop.hdfs.TestFileAppendRestart |\r\n|   | org.apache.hadoop.hdfs.TestSeekBug |\r\n|   | org.apache.hadoop.hdfs.TestDatanodeReport |\r\n|   | org.apache.hadoop.hdfs.web.TestWebHDFS |\r\n|   | org.apache.hadoop.hdfs.web.TestWebHDFSXAttr |\r\n|   | org.apache.hadoop.hdfs.web.TestWebHdfsWithMultipleNameNodes |\r\n|   | org.apache.hadoop.hdfs.TestMiniDFSCluster |\r\n|   | org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs |\r\n|   | org.apache.hadoop.hdfs.TestDistributedFileSystem |\r\n|   | org.apache.hadoop.hdfs.web.TestWebHDFSForHA |\r\n|   | org.apache.hadoop.hdfs.TestSetTimes |\r\n|   | org.apache.hadoop.hdfs.TestDFSShell |\r\n|   | org.apache.hadoop.hdfs.web.TestWebHDFSAcl |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:ea57d10 |\r\n| JIRA Issue | HDFS-10453 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12909377/HDFS-10453-branch-2.7.007.patch |\r\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |\r\n| uname | Linux ca86f6c77f6e 3.13.0-135-generic #184-Ubuntu SMP Wed Oct 18 11:55:51 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | /testptch/patchprocess/precommit/personality/provided.sh |\r\n| git revision | branch-2.7 / 1ef88c9 |\r\n| maven | version: Apache Maven 3.0.5 |\r\n| Default Java | 1.7.0_151 |\r\n| findbugs | v3.0.0 |\r\n| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/22943/artifact/out/diff-checkstyle-hadoop-hdfs-project_hadoop-hdfs.txt |\r\n| whitespace | https://builds.apache.org/job/PreCommit-HDFS-Build/22943/artifact/out/whitespace-eol.txt |\r\n| Unreaped Processes Log | https://builds.apache.org/job/PreCommit-HDFS-Build/22943/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs-reaper.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/22943/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |\r\n|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/22943/testReport/ |\r\n| asflicense | https://builds.apache.org/job/PreCommit-HDFS-Build/22943/artifact/out/patch-asflicense-problems.txt |\r\n| Max. process+thread count | 4268 (vs. ulimit of 5500) |\r\n| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |\r\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/22943/console |\r\n| Powered by | Apache Yetus 0.8.0-SNAPSHOT   http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=genericqa","name":"genericqa","key":"genericqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=genericqa&avatarId=33630","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=genericqa&avatarId=33630","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=genericqa&avatarId=33630","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=genericqa&avatarId=33630"},"displayName":"genericqa","active":true,"timeZone":"Etc/UTC"},"created":"2018-02-06T08:31:59.711+0000","updated":"2018-02-06T08:31:59.711+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12972299/comment/16354286","id":"16354286","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vagarychen","name":"vagarychen","key":"vagarychen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chen Liang","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks for the follow up [~hexiaoqiao]!\r\n{quote}if check if(targets == null || targets.length == 0) and continue loop, it will waste some CPU resource\r\n{quote}\r\nMoving this check into synchronized block also has the potential CPU waste issue of grabbing the lock on neededReplications, but then do nothing but just immediately releasing the lock and continue (when targets is empty or null). I'm not sure whether this matters though, I'm okay with either way. v007 patch looking good to me.\r\n\r\nPing [~arpitagarwal], do you mind having a look?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vagarychen","name":"vagarychen","key":"vagarychen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chen Liang","active":true,"timeZone":"America/Los_Angeles"},"created":"2018-02-06T18:19:16.255+0000","updated":"2018-02-06T18:22:42.529+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12972299/comment/16354571","id":"16354571","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ajayydv","name":"ajayydv","key":"ajayydv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ajay Kumar","active":true,"timeZone":"America/Los_Angeles"},"body":" LGTM.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ajayydv","name":"ajayydv","key":"ajayydv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ajay Kumar","active":true,"timeZone":"America/Los_Angeles"},"created":"2018-02-06T21:32:33.224+0000","updated":"2018-02-06T21:32:33.224+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12972299/comment/16354677","id":"16354677","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=arpitagarwal","name":"arpitagarwal","key":"arpitagarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arpit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi [~hexiaoqiao], I assume this is the key part of the fix in the v7 patch:\r\n{code}\r\n    // Skip choose targets for block where one of the following conditions:\r\n    //  a. additional number of replicas wanted is zero\r\n    //  b. the datanode number of cluster is zero\r\n    //  c. block has been deleted which is indicated by BlockCommand.NO_ACK.\r\n    if (numOfReplicas == 0 || clusterMap.getNumOfLeaves()==0\r\n            || blocksize == BlockCommand.NO_ACK) {\r\n      return DatanodeStorageInfo.EMPTY_ARRAY;\r\n    }\r\n{code}\r\ni.e. chooseTargets avoids looking for replication targets if the blockSize was changed to NO_ACK.\r\n\r\nThis won't work. The block.length field was read by the caller ReplicationWork#chooseTargets after releasing the lock, so there's no guarantee it sees the most recent value. I don't think we should attempt to fix chooseTarget at all since it runs outside the lock.\r\n\r\nYour v4 patch was on the right track. I will review it more closely.\r\n\r\nAlso we'll need a trunk patch (and patches for branch-2.9 and branch-2.8, if we want to commit this to branch-2.7).","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=arpitagarwal","name":"arpitagarwal","key":"arpitagarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arpit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"created":"2018-02-06T22:52:56.832+0000","updated":"2018-02-06T22:52:56.832+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12972299/comment/16354711","id":"16354711","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xkrogen","name":"xkrogen","key":"xkrogen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=xkrogen&avatarId=34526","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=xkrogen&avatarId=34526","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=xkrogen&avatarId=34526","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=xkrogen&avatarId=34526"},"displayName":"Erik Krogen","active":true,"timeZone":"America/Los_Angeles"},"body":"Hey [~arpitagarwal], IIUC it doesn't need to see the most recent value to fix this issue. The problem comes when:\r\n1. Block is added to ReplicationWork under lock\r\n2. Block is deleted\r\n3. Block length is read by ReplicationWork as NO_ACK\r\n4. chooseTargets attempts to place a block of size Long.MAX_VALUE; this causes issue because there is no valid placement, so it takes a long time for the chooseTargets loop to terminate\r\n\r\nIf the original block length is read rather than the most recent value, the issue discussed here does not occur:\r\n1. Block is added to ReplicationWork under lock\r\n2. Block is deleted\r\n3. Block length is read by ReplicationWork as a normal length\r\n4. chooseTargets successfully finds some new locations; then the {{bc == null}} check properly removes the block from {{neededReplications}}\r\n\r\nHowever, going through this makes me realize, a more simple fix may be to just fetch and save {{blocksize}} within the constructor for ReplicationWork rather than calling {{block.getNumBytes()}} within {{chooseTargets()}}. This ensures consistency, so there should no longer be any ReplicationWorks which consider a block size of NO_ACK. It avoids the \"hacky\" nature of checking size equality with NO_ACK as discussed by Chen. Similar to what was done for the race condition in HDFS-12832","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xkrogen","name":"xkrogen","key":"xkrogen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=xkrogen&avatarId=34526","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=xkrogen&avatarId=34526","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=xkrogen&avatarId=34526","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=xkrogen&avatarId=34526"},"displayName":"Erik Krogen","active":true,"timeZone":"America/Los_Angeles"},"created":"2018-02-06T23:20:29.275+0000","updated":"2018-02-06T23:33:05.534+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12972299/comment/16354717","id":"16354717","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=arpitagarwal","name":"arpitagarwal","key":"arpitagarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arpit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"body":"bq. However, going through this makes me realize, a more simple fix may be to just fetch and save blocksize within the constructor for ReplicationWork rather than calling block.getNumBytes() within chooseTargets().\r\n+1 for this suggestion. That is a more deterministic solution than depending on a value sampled outside of the lock.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=arpitagarwal","name":"arpitagarwal","key":"arpitagarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arpit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"created":"2018-02-06T23:29:04.272+0000","updated":"2018-02-06T23:29:04.272+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12972299/comment/16354927","id":"16354927","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hexiaoqiao","name":"hexiaoqiao","key":"hexiaoqiao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hexiaoqiao&avatarId=26980","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hexiaoqiao&avatarId=26980","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hexiaoqiao&avatarId=26980","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hexiaoqiao&avatarId=26980"},"displayName":"He Xiaoqiao","active":true,"timeZone":"Asia/Shanghai"},"body":"{quote}However, going through this makes me realize, a more simple fix may be to just fetch and save blocksize within the constructor for ReplicationWork rather than calling block.getNumBytes() within chooseTargets(). {quote}\r\n+1. It makes sense for me. Thanks [~arpitagarwal] [~xkrogen] for your suggestions. [#HDFS-10453-branch-2.7.008.patch]","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hexiaoqiao","name":"hexiaoqiao","key":"hexiaoqiao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hexiaoqiao&avatarId=26980","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hexiaoqiao&avatarId=26980","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hexiaoqiao&avatarId=26980","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hexiaoqiao&avatarId=26980"},"displayName":"He Xiaoqiao","active":true,"timeZone":"Asia/Shanghai"},"created":"2018-02-07T04:01:12.404+0000","updated":"2018-02-07T04:11:59.122+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12972299/comment/16355019","id":"16355019","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=genericqa","name":"genericqa","key":"genericqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=genericqa&avatarId=33630","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=genericqa&avatarId=33630","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=genericqa&avatarId=33630","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=genericqa&avatarId=33630"},"displayName":"genericqa","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 18s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |\r\n|| || || || {color:brown} branch-2.7 Compile Tests {color} ||\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  6m  3s{color} | {color:green} branch-2.7 passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m  8s{color} | {color:green} branch-2.7 passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 26s{color} | {color:green} branch-2.7 passed {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  0s{color} | {color:green} branch-2.7 passed {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  3m  6s{color} | {color:green} branch-2.7 passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m  3s{color} | {color:green} branch-2.7 passed {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m 13s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m 15s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  1m 15s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 29s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 12s{color} | {color:green} the patch passed {color} |\r\n| {color:red}-1{color} | {color:red} whitespace {color} | {color:red}  0m  0s{color} | {color:red} The patch has 60 line(s) that end in whitespace. Use git apply --whitespace=fix <<patch_file>>. Refer https://git-scm.com/docs/git-apply {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  3m 37s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 57s{color} | {color:green} the patch passed {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}109m  7s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |\r\n| {color:red}-1{color} | {color:red} asflicense {color} | {color:red}  1m 36s{color} | {color:red} The patch generated 304 ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black}136m 41s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Reason || Tests ||\r\n| Unreaped Processes | hadoop-hdfs:26 |\r\n| Failed junit tests | hadoop.hdfs.crypto.TestHdfsCryptoStreams |\r\n|   | hadoop.hdfs.TestParallelShortCircuitLegacyRead |\r\n|   | hadoop.hdfs.TestFetchImage |\r\n|   | hadoop.hdfs.TestDFSRollback |\r\n|   | hadoop.hdfs.TestSetrepIncreasing |\r\n|   | hadoop.hdfs.TestDataTransferProtocol |\r\n|   | hadoop.hdfs.TestRollingUpgrade |\r\n|   | hadoop.hdfs.TestAbandonBlock |\r\n|   | hadoop.hdfs.TestHDFSTrash |\r\n|   | hadoop.hdfs.TestParallelUnixDomainRead |\r\n|   | hadoop.hdfs.TestFileCreationClient |\r\n| Timed out junit tests | org.apache.hadoop.hdfs.TestLeaseRecovery2 |\r\n|   | org.apache.hadoop.hdfs.TestDatanodeRegistration |\r\n|   | org.apache.hadoop.hdfs.TestDFSClientFailover |\r\n|   | org.apache.hadoop.hdfs.TestDatanodeDeath |\r\n|   | org.apache.hadoop.hdfs.TestDFSClientRetries |\r\n|   | org.apache.hadoop.hdfs.web.TestWebHdfsTokens |\r\n|   | org.apache.hadoop.hdfs.TestDFSInotifyEventInputStream |\r\n|   | org.apache.hadoop.hdfs.TestFileAppendRestart |\r\n|   | org.apache.hadoop.hdfs.security.TestDelegationToken |\r\n|   | org.apache.hadoop.hdfs.TestSeekBug |\r\n|   | org.apache.hadoop.hdfs.TestDFSMkdirs |\r\n|   | org.apache.hadoop.hdfs.TestDatanodeReport |\r\n|   | org.apache.hadoop.hdfs.web.TestWebHDFS |\r\n|   | org.apache.hadoop.hdfs.web.TestWebHDFSXAttr |\r\n|   | org.apache.hadoop.hdfs.web.TestWebHdfsWithMultipleNameNodes |\r\n|   | org.apache.hadoop.hdfs.TestMiniDFSCluster |\r\n|   | org.apache.hadoop.hdfs.TestDistributedFileSystem |\r\n|   | org.apache.hadoop.hdfs.web.TestWebHDFSForHA |\r\n|   | org.apache.hadoop.hdfs.TestBalancerBandwidth |\r\n|   | org.apache.hadoop.hdfs.TestSetTimes |\r\n|   | org.apache.hadoop.hdfs.TestDFSShell |\r\n|   | org.apache.hadoop.hdfs.web.TestWebHDFSAcl |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:ea57d10 |\r\n| JIRA Issue | HDFS-10453 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12909555/HDFS-10453-branch-2.7.008.patch |\r\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |\r\n| uname | Linux 8daf8fb6417b 3.13.0-135-generic #184-Ubuntu SMP Wed Oct 18 11:55:51 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | /testptch/patchprocess/precommit/personality/provided.sh |\r\n| git revision | branch-2.7 / 6ea2a93 |\r\n| maven | version: Apache Maven 3.0.5 |\r\n| Default Java | 1.7.0_151 |\r\n| findbugs | v3.0.0 |\r\n| whitespace | https://builds.apache.org/job/PreCommit-HDFS-Build/22967/artifact/out/whitespace-eol.txt |\r\n| Unreaped Processes Log | https://builds.apache.org/job/PreCommit-HDFS-Build/22967/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs-reaper.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/22967/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |\r\n|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/22967/testReport/ |\r\n| asflicense | https://builds.apache.org/job/PreCommit-HDFS-Build/22967/artifact/out/patch-asflicense-problems.txt |\r\n| Max. process+thread count | 4778 (vs. ulimit of 5500) |\r\n| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |\r\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/22967/console |\r\n| Powered by | Apache Yetus 0.8.0-SNAPSHOT   http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=genericqa","name":"genericqa","key":"genericqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=genericqa&avatarId=33630","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=genericqa&avatarId=33630","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=genericqa&avatarId=33630","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=genericqa&avatarId=33630"},"displayName":"genericqa","active":true,"timeZone":"Etc/UTC"},"created":"2018-02-07T06:27:20.705+0000","updated":"2018-02-07T06:27:20.705+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12972299/comment/16355650","id":"16355650","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xkrogen","name":"xkrogen","key":"xkrogen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=xkrogen&avatarId=34526","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=xkrogen&avatarId=34526","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=xkrogen&avatarId=34526","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=xkrogen&avatarId=34526"},"displayName":"Erik Krogen","active":true,"timeZone":"America/Los_Angeles"},"body":"Re: v008 patch, looks like you are using {{getPreferredBlockSize()}} instead of {{getNumBytes()}} , that does not seem right, was it an unintentional change?\r\n\r\nOther than that I am pleased with the simplicity of the new change. This looks valid to go trunk~2.8 as well.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xkrogen","name":"xkrogen","key":"xkrogen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=xkrogen&avatarId=34526","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=xkrogen&avatarId=34526","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=xkrogen&avatarId=34526","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=xkrogen&avatarId=34526"},"displayName":"Erik Krogen","active":true,"timeZone":"America/Los_Angeles"},"created":"2018-02-07T16:14:49.097+0000","updated":"2018-02-07T16:16:56.732+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12972299/comment/16357343","id":"16357343","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ajayydv","name":"ajayydv","key":"ajayydv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ajay Kumar","active":true,"timeZone":"America/Los_Angeles"},"body":"[~hexiaoqiao], Patch v8 doesn't have changes from patch v7 in {{BlockManager#computeReplicationWorkForBlocks}}. Is that intentional?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ajayydv","name":"ajayydv","key":"ajayydv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ajay Kumar","active":true,"timeZone":"America/Los_Angeles"},"created":"2018-02-08T18:12:20.572+0000","updated":"2018-02-08T18:12:20.572+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12972299/comment/16357897","id":"16357897","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hexiaoqiao","name":"hexiaoqiao","key":"hexiaoqiao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hexiaoqiao&avatarId=26980","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hexiaoqiao&avatarId=26980","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hexiaoqiao&avatarId=26980","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hexiaoqiao&avatarId=26980"},"displayName":"He Xiaoqiao","active":true,"timeZone":"Asia/Shanghai"},"body":"[~xkrogen],[~ajayydv]\r\nSorry for so late comments. I just update v008 [#HDFS-10453-branch-2.7.008.patch] patch for branch-2.7, and patchs for other branchs also be ready, which correct the properly invoke to get number bytes of block. {{getNumBytes()}}.\r\n\r\n{quote}He Xiaoqiao, Patch v8 doesn't have changes from patch v7 in BlockManager#computeReplicationWorkForBlocks. Is that intentional?{quote}\r\n[~ajayydv] Thanks for your comments firstly. since we have saved blocksize within the constructor for ReplicationWork rather than calling block.getNumBytes() within chooseTargets() in new patch [#HDFS-10453-branch-2.7.008.patch], so it is impossible to choose target for a block whose length is {{Long.MAX_VALUE}}. FYI.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hexiaoqiao","name":"hexiaoqiao","key":"hexiaoqiao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hexiaoqiao&avatarId=26980","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hexiaoqiao&avatarId=26980","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hexiaoqiao&avatarId=26980","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hexiaoqiao&avatarId=26980"},"displayName":"He Xiaoqiao","active":true,"timeZone":"Asia/Shanghai"},"created":"2018-02-09T04:10:56.592+0000","updated":"2018-02-09T04:10:56.592+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12972299/comment/16357925","id":"16357925","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ajayydv","name":"ajayydv","key":"ajayydv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ajay Kumar","active":true,"timeZone":"America/Los_Angeles"},"body":"[~hexiaoqiao], I was referring to moving the check {{if (bc == null || (bc.isUnderConstruction() && block.equals(bc.getLastBlock())))}} before {{if(targets == null || targets.length == 0)}}.\r\n\r\nAs [~xkrogen] mentioned earlier \"A deleted block should always be removed from the needingReplications list regardless of whether or not any targets were found for it, so it makes sense to perform this check before the check for an empty targets list. \".  In current scenario it will be removed in next iteration of {{computeReplicationWorkForBlocks}}.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ajayydv","name":"ajayydv","key":"ajayydv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ajay Kumar","active":true,"timeZone":"America/Los_Angeles"},"created":"2018-02-09T05:10:10.978+0000","updated":"2018-02-09T05:10:10.978+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12972299/comment/16358033","id":"16358033","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=genericqa","name":"genericqa","key":"genericqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=genericqa&avatarId=33630","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=genericqa&avatarId=33630","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=genericqa&avatarId=33630","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=genericqa&avatarId=33630"},"displayName":"genericqa","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 23s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |\r\n|| || || || {color:brown} trunk Compile Tests {color} ||\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 15m 26s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 53s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 35s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 57s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 10m 45s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 44s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 53s{color} | {color:green} trunk passed {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 54s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 47s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 47s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 32s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 52s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 10m 20s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 51s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 48s{color} | {color:green} the patch passed {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}143m 18s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 20s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black}191m  8s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Reason || Tests ||\r\n| Failed junit tests | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure |\r\n|   | hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA |\r\n|   | hadoop.hdfs.qjournal.server.TestJournalNodeSync |\r\n|   | hadoop.hdfs.web.TestWebHdfsTimeouts |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure |\r\n|   | hadoop.hdfs.TestBlocksScheduledCounter |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:5b98639 |\r\n| JIRA Issue | HDFS-10453 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12909885/HDFS-10453-trunk.001.patch |\r\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |\r\n| uname | Linux 351fb731547f 4.4.0-64-generic #85-Ubuntu SMP Mon Feb 20 11:50:30 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | /testptch/patchprocess/precommit/personality/provided.sh |\r\n| git revision | trunk / 1bc03dd |\r\n| maven | version: Apache Maven 3.3.9 |\r\n| Default Java | 1.8.0_151 |\r\n| findbugs | v3.1.0-RC1 |\r\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/23000/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |\r\n|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/23000/testReport/ |\r\n| Max. process+thread count | 4146 (vs. ulimit of 5500) |\r\n| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |\r\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/23000/console |\r\n| Powered by | Apache Yetus 0.8.0-SNAPSHOT   http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=genericqa","name":"genericqa","key":"genericqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=genericqa&avatarId=33630","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=genericqa&avatarId=33630","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=genericqa&avatarId=33630","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=genericqa&avatarId=33630"},"displayName":"genericqa","active":true,"timeZone":"Etc/UTC"},"created":"2018-02-09T07:15:38.177+0000","updated":"2018-02-09T07:15:38.177+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12972299/comment/16358323","id":"16358323","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hexiaoqiao","name":"hexiaoqiao","key":"hexiaoqiao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hexiaoqiao&avatarId=26980","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hexiaoqiao&avatarId=26980","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hexiaoqiao&avatarId=26980","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hexiaoqiao&avatarId=26980"},"displayName":"He Xiaoqiao","active":true,"timeZone":"Asia/Shanghai"},"body":"[~ajayydv]\r\n{quote}\r\nAs Erik Krogen mentioned earlier \"A deleted block should always be removed from the needingReplications list regardless of whether or not any targets were found for it, so it makes sense to perform this check before the check for an empty targets list. \". In current scenario it will be removed in next iteration of computeReplicationWorkForBlocks.\r\n{quote}\r\nI think we need discuss about if moving check {{if (bc == null || (bc.isUnderConstruction() && block.equals(bc.getLastBlock())))}} before {{if(targets == null || targets.length == 0)}}. Since there is cost that grabbing the lock on neededReplications to get {{block}} for all scenario.\r\n[~xkrogen],[~arpitagarwal], do you mind having a look?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hexiaoqiao","name":"hexiaoqiao","key":"hexiaoqiao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hexiaoqiao&avatarId=26980","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hexiaoqiao&avatarId=26980","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hexiaoqiao&avatarId=26980","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hexiaoqiao&avatarId=26980"},"displayName":"He Xiaoqiao","active":true,"timeZone":"Asia/Shanghai"},"created":"2018-02-09T12:20:23.940+0000","updated":"2018-02-09T12:20:23.940+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12972299/comment/16358657","id":"16358657","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xkrogen","name":"xkrogen","key":"xkrogen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=xkrogen&avatarId=34526","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=xkrogen&avatarId=34526","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=xkrogen&avatarId=34526","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=xkrogen&avatarId=34526"},"displayName":"Erik Krogen","active":true,"timeZone":"America/Los_Angeles"},"body":"I don't think that move is necessary anymore. Given that we use the block's old, non-deleted size, the expectation is that targets will _not_ be empty. Thus the {{bc == null}} check will end up being triggered regardless. branch-2.7 v008 & trunk v001 patches LGTM.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xkrogen","name":"xkrogen","key":"xkrogen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=xkrogen&avatarId=34526","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=xkrogen&avatarId=34526","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=xkrogen&avatarId=34526","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=xkrogen&avatarId=34526"},"displayName":"Erik Krogen","active":true,"timeZone":"America/Los_Angeles"},"created":"2018-02-09T16:53:36.482+0000","updated":"2018-02-09T16:53:36.482+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12972299/comment/16358739","id":"16358739","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ajayydv","name":"ajayydv","key":"ajayydv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ajay Kumar","active":true,"timeZone":"America/Los_Angeles"},"body":"[~xkrogen] i am also good with change. Question was about some edge cases where we don't find any target. Even in those cases we will remove it in next iteration so that should be fine as well.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ajayydv","name":"ajayydv","key":"ajayydv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ajay Kumar","active":true,"timeZone":"America/Los_Angeles"},"created":"2018-02-09T17:31:08.980+0000","updated":"2018-02-09T17:31:08.980+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12972299/comment/16358772","id":"16358772","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=arpitagarwal","name":"arpitagarwal","key":"arpitagarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arpit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"body":"[~hexiaoqiao], +1 from me also. However the new test doesn't verify this fix. I don't see a way to unit test the race condition without refactoring, so let's just remove the new unit test. +1 with that removed.\r\n\r\nAlso you can delay attaching patches for the branches other than trunk until there is a +1, to save yourself work. :)","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=arpitagarwal","name":"arpitagarwal","key":"arpitagarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arpit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"created":"2018-02-09T18:03:07.355+0000","updated":"2018-02-09T18:03:07.355+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12972299/comment/16359229","id":"16359229","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=arpitagarwal","name":"arpitagarwal","key":"arpitagarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arpit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"body":"+1 for HDFS-10453-trunk.002.patch, pending Jenkins.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=arpitagarwal","name":"arpitagarwal","key":"arpitagarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arpit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"created":"2018-02-10T03:51:25.611+0000","updated":"2018-02-10T03:51:25.611+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12972299/comment/16359237","id":"16359237","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hexiaoqiao","name":"hexiaoqiao","key":"hexiaoqiao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hexiaoqiao&avatarId=26980","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hexiaoqiao&avatarId=26980","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hexiaoqiao&avatarId=26980","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hexiaoqiao&avatarId=26980"},"displayName":"He Xiaoqiao","active":true,"timeZone":"Asia/Shanghai"},"body":"[~arpitagarwal]\r\nupload new patches without unit test.\r\n{quote}However the new test doesn't verify this fix. I don't see a way to unit test the race condition without refactoring, so let's just remove the new unit test.{quote}\r\nThanks for your careful review.The added unit test doesn't work well as your mentioned using this simple fix type as well. And I do not find an elegant way to verify this fix since we could not manipulate thread {{ReplicationMonitor}} and {{PendingReplicationMonitor}} progress in MiniDFSCluster without refactoring. Please share your idea if there are good suggestions.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hexiaoqiao","name":"hexiaoqiao","key":"hexiaoqiao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hexiaoqiao&avatarId=26980","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hexiaoqiao&avatarId=26980","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hexiaoqiao&avatarId=26980","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hexiaoqiao&avatarId=26980"},"displayName":"He Xiaoqiao","active":true,"timeZone":"Asia/Shanghai"},"created":"2018-02-10T04:03:38.364+0000","updated":"2018-02-10T04:03:38.364+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12972299/comment/16359285","id":"16359285","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=genericqa","name":"genericqa","key":"genericqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=genericqa&avatarId=33630","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=genericqa&avatarId=33630","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=genericqa&avatarId=33630","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=genericqa&avatarId=33630"},"displayName":"genericqa","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 25s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |\r\n|| || || || {color:brown} trunk Compile Tests {color} ||\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 15m 26s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 53s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 37s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 57s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 10m 56s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 45s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 53s{color} | {color:green} trunk passed {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 55s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 47s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 47s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 34s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 52s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  1s{color} | {color:green} The patch has no whitespace issues. {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 10m 26s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 51s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 54s{color} | {color:green} the patch passed {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}128m  7s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 23s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black}176m 34s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Reason || Tests ||\r\n| Failed junit tests | hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA |\r\n|   | hadoop.hdfs.web.TestWebHdfsTimeouts |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:5b98639 |\r\n| JIRA Issue | HDFS-10453 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12910023/HDFS-10453-trunk.002.patch |\r\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |\r\n| uname | Linux f10611600a15 4.4.0-64-generic #85-Ubuntu SMP Mon Feb 20 11:50:30 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | /testptch/patchprocess/precommit/personality/provided.sh |\r\n| git revision | trunk / c97d5bc |\r\n| maven | version: Apache Maven 3.3.9 |\r\n| Default Java | 1.8.0_151 |\r\n| findbugs | v3.1.0-RC1 |\r\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/23019/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |\r\n|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/23019/testReport/ |\r\n| Max. process+thread count | 3577 (vs. ulimit of 5500) |\r\n| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |\r\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/23019/console |\r\n| Powered by | Apache Yetus 0.8.0-SNAPSHOT   http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=genericqa","name":"genericqa","key":"genericqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=genericqa&avatarId=33630","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=genericqa&avatarId=33630","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=genericqa&avatarId=33630","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=genericqa&avatarId=33630"},"displayName":"genericqa","active":true,"timeZone":"Etc/UTC"},"created":"2018-02-10T06:47:24.243+0000","updated":"2018-02-10T06:47:24.243+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12972299/comment/16360400","id":"16360400","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hexiaoqiao","name":"hexiaoqiao","key":"hexiaoqiao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hexiaoqiao&avatarId=26980","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hexiaoqiao&avatarId=26980","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hexiaoqiao&avatarId=26980","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hexiaoqiao&avatarId=26980"},"displayName":"He Xiaoqiao","active":true,"timeZone":"Asia/Shanghai"},"body":"I checked the failed UTs and tested locally, it seems to work fine and might not relate to this patch, please double check at your convenience. [~arpitagarwal]","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hexiaoqiao","name":"hexiaoqiao","key":"hexiaoqiao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hexiaoqiao&avatarId=26980","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hexiaoqiao&avatarId=26980","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hexiaoqiao&avatarId=26980","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hexiaoqiao&avatarId=26980"},"displayName":"He Xiaoqiao","active":true,"timeZone":"Asia/Shanghai"},"created":"2018-02-12T07:54:24.837+0000","updated":"2018-02-12T07:54:24.837+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12972299/comment/16360866","id":"16360866","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=arpitagarwal","name":"arpitagarwal","key":"arpitagarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arpit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"body":"Committed to trunk, branch-3.0, branch-3.1, branch-2, branch-2.9, branch-2.8 and branch-2.7.\r\n\r\nThanks [~hexiaoqiao] for reporting and fixing this for all the active release branches! And thanks to all the reviewers (too numerous to mention).","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=arpitagarwal","name":"arpitagarwal","key":"arpitagarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arpit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"created":"2018-02-12T15:20:46.657+0000","updated":"2018-02-12T15:20:46.657+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12972299/comment/16360934","id":"16360934","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"SUCCESS: Integrated in Jenkins build Hadoop-trunk-Commit #13645 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/13645/])\nHDFS-10453. ReplicationMonitor thread could stuck for long time due to (arp: rev 96bb6a51ec4a470e9b287c94e377444a9f97c410)\n* (edit) hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/ErasureCodingWork.java\n* (edit) hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/ReplicationWork.java\n* (edit) hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockReconstructionWork.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2018-02-12T15:52:22.774+0000","updated":"2018-02-12T15:52:22.774+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12972299/comment/16584189","id":"16584189","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rikeppb100","name":"rikeppb100","key":"rikeppb100","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=rikeppb100&avatarId=36577","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=rikeppb100&avatarId=36577","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=rikeppb100&avatarId=36577","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=rikeppb100&avatarId=36577"},"displayName":"Henrique Barros","active":true,"timeZone":"Etc/UTC"},"body":"I have the same problem with Hadoop 2.6.0-cdh5.15.0\r\n With Cloudera CDH-5.15.0-1.cdh5.15.0.p0.21\r\n\r\nÂ \r\n\r\nIn my case we areÂ getting this error very randomly and with only one Datanode (for now).\r\n Here is the Log.\r\n{code:java}\r\nChoosing random from 1 available nodes on node /default, scope=/default, excludedScope=null, excludeNodes=[]\r\n2:38:20.527 PM\tDEBUG\tNetworkTopology\t\r\nChoosing random from 0 available nodes on node /default, scope=/default, excludedScope=null, excludeNodes=[192.168.220.53:50010]\r\n2:38:20.527 PM\tDEBUG\tNetworkTopology\t\r\nchooseRandom returning null\r\n2:38:20.527 PM\tDEBUG\tBlockPlacementPolicy\t\r\n[\r\nNode /default/192.168.220.53:50010 [\r\n  Datanode 192.168.220.53:50010 is not chosen since the node is too busy (load: 8 > 0.0).\r\n2:38:20.527 PM\tDEBUG\tNetworkTopology\t\r\nchooseRandom returning 192.168.220.53:50010\r\n2:38:20.527 PM\tINFO\tBlockPlacementPolicy\t\r\nNot enough replicas was chosen. Reason:{NODE_TOO_BUSY=1}\r\n2:38:20.527 PM\tDEBUG\tStateChange\t\r\ncloseFile: /mobi.me/development/apps/flink/checkpoints/a5a6806866c1640660924ea1453cbe34/chk-2118/eef8bff6-75a9-43c1-ae93-4b1a9ca31ad9 with 1 blocks is persisted to the file system\r\n2:38:20.527 PM\tDEBUG\tStateChange\t\r\n*BLOCK* NameNode.addBlock: file /mobi.me/development/apps/flink/checkpoints/a5a6806866c1640660924ea1453cbe34/chk-2118/1cfe900d-6f45-4b55-baaa-73c02ace2660 fileId=129628869 for DFSClient_NONMAPREDUCE_467616914_65\r\n2:38:20.527 PM\tDEBUG\tBlockPlacementPolicy\t\r\nFailed to choose from local rack (location = /default); the second replica is not found, retry choosing ramdomly\r\norg.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy$NotEnoughReplicasException: \r\n\tat org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRandom(BlockPlacementPolicyDefault.java:784)\r\n\tat org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRandom(BlockPlacementPolicyDefault.java:694)\r\n\tat org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseLocalRack(BlockPlacementPolicyDefault.java:601)\r\n\tat org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseLocalStorage(BlockPlacementPolicyDefault.java:561)\r\n\tat org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTargetInOrder(BlockPlacementPolicyDefault.java:464)\r\n\tat org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:395)\r\n\tat org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:270)\r\n\tat org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:142)\r\n\tat org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:158)\r\n\tat org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:1715)\r\n\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:3505)\r\n\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:694)\r\n\tat org.apache.hadoop.hdfs.server.namenode.AuthorizationProviderProxyClientProtocol.addBlock(AuthorizationProviderProxyClientProtocol.java:219)\r\n\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:507)\r\n\tat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\r\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:617)\r\n\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1073)\r\n\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2281)\r\n\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2277)\r\n\tat java.security.AccessController.doPrivileged(Native Method)\r\n\tat javax.security.auth.Subject.doAs(Subject.java:422)\r\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1920)\r\n\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2275)\r\n\r\n{code}\r\nThis part makes no sense at all:\r\n{code:java}\r\nload: 8 > 0.0{code}\r\nÂ I created a dedicated Bug for this case since it could not have anything to do with this one:\r\nhttps://issues.apache.org/jira/browse/HDFS-13833\r\n\r\nÂ ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rikeppb100","name":"rikeppb100","key":"rikeppb100","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=rikeppb100&avatarId=36577","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=rikeppb100&avatarId=36577","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=rikeppb100&avatarId=36577","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=rikeppb100&avatarId=36577"},"displayName":"Henrique Barros","active":true,"timeZone":"Etc/UTC"},"created":"2018-08-17T17:25:29.979+0000","updated":"2018-08-17T17:26:29.953+0000"}],"maxResults":60,"total":60,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-10453/votes","votes":2,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i2yeqv:"}}