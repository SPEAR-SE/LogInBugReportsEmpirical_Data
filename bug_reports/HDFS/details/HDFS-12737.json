{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"13112709","self":"https://issues.apache.org/jira/rest/api/2/issue/13112709","key":"HDFS-12737","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":"2017-10-27T22:42:04.937+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Tue Nov 14 01:21:22 UTC 2017","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-12737/watchers","watchCount":13,"isWatching":false},"created":"2017-10-27T22:12:58.506+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[],"issuelinks":[{"id":"12518744","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12518744","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"12507820","key":"HDFS-1965","self":"https://issues.apache.org/jira/rest/api/2/issue/12507820","fields":{"summary":"IPCs done using block token-based tickets can't reuse connections","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/2","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/critical.svg","name":"Critical","id":"2"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2017-11-14T01:21:22.462+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12330102","id":"12330102","name":"ipc"}],"timeoriginalestimate":null,"description":"On a HBase cluster we found HBase RegionServers have thousands of sockets in TIME_WAIT state. It depleted system resources and caused other services to fail.\r\n\r\nAfter months of troubleshooting, we found the issue is the cluster has hundreds of replication peers, and has multi-WAL = 2. That creates hundreds of replication threads in HBase RS, and each thread opens WAL file *every second*.\r\n\r\nWe found that the IPC client closes socket right away, and does not reuse socket connection. Since each closed socket stays in TIME_WAIT state for 60 seconds in Linux by default, that generates thousands of TIME_WAIT sockets.\r\n\r\n{code:title=ClientDatanodeProtocolTranslatorPB:createClientDatanodeProtocolProxy}\r\n    // Since we're creating a new UserGroupInformation here, we know that no\r\n    // future RPC proxies will be able to re-use the same connection. And\r\n    // usages of this proxy tend to be one-off calls.\r\n    //\r\n    // This is a temporary fix: callers should really achieve this by using\r\n    // RPC.stopProxy() on the resulting object, but this is currently not\r\n    // working in trunk. See the discussion on HDFS-1965.\r\n    Configuration confWithNoIpcIdle = new Configuration(conf);\r\n    confWithNoIpcIdle.setInt(CommonConfigurationKeysPublic\r\n        .IPC_CLIENT_CONNECTION_MAXIDLETIME_KEY, 0);\r\n{code}\r\nThis piece of code is used in DistributedFileSystem#open()\r\n{noformat}\r\n2017-10-27 14:01:44,152 DEBUG org.apache.hadoop.ipc.Client: New connection Thread[IPC Client (1838187805) connection to /172.131.21.48:20001 from blk_1013754707_14032,5,main] for remoteId /172.131.21.48:20001\r\njava.lang.Throwable: For logging stack trace, not a real exception\r\n        at org.apache.hadoop.ipc.Client.getConnection(Client.java:1556)\r\n        at org.apache.hadoop.ipc.Client.call(Client.java:1482)\r\n        at org.apache.hadoop.ipc.Client.call(Client.java:1443)\r\n        at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:230)\r\n        at com.sun.proxy.$Proxy28.getReplicaVisibleLength(Unknown Source)\r\n        at org.apache.hadoop.hdfs.protocolPB.ClientDatanodeProtocolTranslatorPB.getReplicaVisibleLength(ClientDatanodeProtocolTranslatorPB.java:198)\r\n        at org.apache.hadoop.hdfs.DFSInputStream.readBlockLength(DFSInputStream.java:365)\r\n        at org.apache.hadoop.hdfs.DFSInputStream.fetchLocatedBlocksAndGetLastBlockLength(DFSInputStream.java:335)\r\n        at org.apache.hadoop.hdfs.DFSInputStream.openInfo(DFSInputStream.java:271)\r\n        at org.apache.hadoop.hdfs.DFSInputStream.<init>(DFSInputStream.java:263)\r\n        at org.apache.hadoop.hdfs.DFSClient.open(DFSClient.java:1585)\r\n        at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:326)\r\n        at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:322)\r\n        at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)\r\n        at org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:322)\r\n        at org.apache.hadoop.fs.FilterFileSystem.open(FilterFileSystem.java:162)\r\n        at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:783)\r\n        at org.apache.hadoop.hbase.wal.WALFactory.createReader(WALFactory.java:293)\r\n        at org.apache.hadoop.hbase.wal.WALFactory.createReader(WALFactory.java:267)\r\n        at org.apache.hadoop.hbase.wal.WALFactory.createReader(WALFactory.java:255)\r\n        at org.apache.hadoop.hbase.wal.WALFactory.createReader(WALFactory.java:414)\r\n        at org.apache.hadoop.hbase.replication.regionserver.ReplicationWALReaderManager.openReader(ReplicationWALReaderManager.java:70)\r\n        at org.apache.hadoop.hbase.replication.regionserver.ReplicationSource$ReplicationSourceWorkerThread.openReader(ReplicationSource.java:747)\r\n        at org.apache.hadoop.hbase.replication.regionserver.ReplicationSource$ReplicationSourceWorkerThread.run(ReplicationSource.java:543)\r\n{noformat}\r\nUnfortunately, given the HBase's usage pattern, this hack creates the problem.\r\n\r\nIgnoring the fact that having hundreds of HBase replication peers is a bad practice (I'll probably file a HBASE jira to help remedy that), the fact that Hadoop IPC client does not reuse socket seems not right. The relevant code is historical and deep in the stack, so I'd like to invite comments. I have a patch but it's pretty hacky.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"Thousands of sockets lingering in TIME_WAIT state due to frequent file open operations","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":"CDH5.10.2, HBase Multi-WAL=2, 250 replication peers","customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/13112709/comment/16222981","id":"16222981","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"body":"If the same user (i.e. the same UGI instance) talks to the same namenode via RPC, a connection will be shared.  If the files system cache is disabled, the sharing cannot happen. Are those requests being made by separate processes?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"created":"2017-10-27T22:42:04.937+0000","updated":"2017-10-27T22:42:04.937+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13112709/comment/16222989","id":"16222989","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"body":"You quoted {{ClientDatanodeProtocol}}, so I guess they are the connections made to datanodes. That's different.\r\n\r\nPlease explain what your patch does, if you don't want to post it. The design probably assumed a typical client consuming small number of files.  We need to re-evaluate the design. I do think it is worth fixing.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"created":"2017-10-27T22:44:17.645+0000","updated":"2017-10-27T22:49:07.354+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13112709/comment/16222994","id":"16222994","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"body":"Correct. This issue (new connection for every call) only happens to Hbase RS --> local DataNode connections. RS --> NameNode connections are always reused.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-10-27T22:47:22.253+0000","updated":"2017-10-27T22:47:22.253+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13112709/comment/16223009","id":"16223009","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"body":"I don't understand why the client needs to make a dummy UGI to access datanode, so I made it to use the current UGI and do not reset maxIdleTime. My hack is probably not correct but there you go:\r\n\r\n{code}\r\ndiff --git a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/ClientDatanodeProtocolTranslatorPB.java b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/ClientDatanodeProtocolTranslatorPB.java\r\nindex 19ef9ec0155..660b4e902ce 100644\r\n--- a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/ClientDatanodeProtocolTranslatorPB.java\r\n+++ b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/ClientDatanodeProtocolTranslatorPB.java\r\n@@ -164,14 +164,15 @@ static ClientDatanodeProtocolPB createClientDatanodeProtocolProxy(\r\n     // This is a temporary fix: callers should really achieve this by using\r\n     // RPC.stopProxy() on the resulting object, but this is currently not\r\n     // working in trunk. See the discussion on HDFS-1965.\r\n-    Configuration confWithNoIpcIdle = new Configuration(conf);\r\n+    /*Configuration confWithNoIpcIdle = new Configuration(conf);\r\n     confWithNoIpcIdle.setInt(CommonConfigurationKeysPublic\r\n         .IPC_CLIENT_CONNECTION_MAXIDLETIME_KEY, 0);\r\n-\r\n-    UserGroupInformation ticket = UserGroupInformation\r\n-        .createRemoteUser(locatedBlock.getBlock().getLocalBlock().toString());\r\n+    */\r\n+    UserGroupInformation ticket = UserGroupInformation.getCurrentUser();\r\n+        /*UserGroupInformation\r\n+        .createRemoteUser(locatedBlock.getBlock().getLocalBlock().toString());*/\r\n     ticket.addToken(locatedBlock.getBlockToken());\r\n-    return createClientDatanodeProtocolProxy(addr, ticket, confWithNoIpcIdle,\r\n+    return createClientDatanodeProtocolProxy(addr, ticket, conf,\r\n         NetUtils.getDefaultSocketFactory(conf), socketTimeout);\r\n   }\r\n{code}\r\nI applied the patch on a cluster and ran ycsb, which seems to run just fine.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-10-27T23:05:11.363+0000","updated":"2017-10-27T23:05:11.363+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13112709/comment/16226008","id":"16226008","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks [~jojochuang] for working on this issue.\r\n\r\nHi [~jnp] and [~kzhang],\r\n\r\nYou guys worked on HDFS-992 which introduced the code to create a UGI each time the code Wai-Chiu modified above. Would you please share the reason why we have to create a new UGI here?\r\n\r\nIf we create a new UGI each time (like how the current code looks like), and a new Subject instance is created within the UGI construction, it made the connection sharing impossible, even for the same user when accessing the same DataNode.   Notice that another jira HDFS-1965 [~tlipcon] did is based on the observation that the connections can not be shared here.\r\n\r\nOn the other hand, Wei-Chiu's change to use {{UserGroupInformation.getCurrentUser()}} seems to make sense to me, this way, the connection for the same user can be shared. \r\n\r\nWould you please help to comment here?\r\n\r\nVery much appreciated.\r\n\r\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-10-30T23:54:58.838+0000","updated":"2017-10-30T23:54:58.838+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13112709/comment/16227678","id":"16227678","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jnp","name":"jnp","key":"jnp","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jitendra Nath Pandey","active":true,"timeZone":"Etc/UTC"},"body":"   BlockTokenSelector uses only Token-Kind to match the token, therefore you would need to either change the selector, or make sure the UGI has only one token. The current-user could be trying to read/write multiple files in parallel, and therefore, dealing with multiple tokens at an instant. \r\n   \r\n   ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jnp","name":"jnp","key":"jnp","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jitendra Nath Pandey","active":true,"timeZone":"Etc/UTC"},"created":"2017-10-31T22:01:23.227+0000","updated":"2017-10-31T22:01:23.227+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13112709/comment/16234752","id":"16234752","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Many thanks [~jnp], that make sense!\r\n\r\nIf we could make the BlockTokenSelector also check block id, when finding it's a block token, it would help, but it looks not an easy thing to do at all.\r\n\r\n\r\n\r\n\r\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-11-01T21:05:40.988+0000","updated":"2017-11-01T21:05:40.988+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13112709/comment/16235182","id":"16235182","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jnp","name":"jnp","key":"jnp","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jitendra Nath Pandey","active":true,"timeZone":"Etc/UTC"},"body":"[~yzhangal], The block token is also being used to authorize the access to a block. Therefore, a connection context must be established using that particular block token. \r\n   In method {{DataNode#checkReadAccess}}. The block-id from the token-identifier in the UGI is used to authorize the access. Therefore, sharing of connections for different block tokens will likely expose a security risk. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jnp","name":"jnp","key":"jnp","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jitendra Nath Pandey","active":true,"timeZone":"Etc/UTC"},"created":"2017-11-02T05:03:25.539+0000","updated":"2017-11-02T05:03:25.539+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13112709/comment/16235221","id":"16235221","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"In the data transfer protocol we just pass tokens with each operation. Could the relevant RPCs just be modified to take tokens as parameters rather than using them as part of the connection context?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2017-11-02T05:50:25.528+0000","updated":"2017-11-02T05:50:25.528+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13112709/comment/16243215","id":"16243215","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks a lot [~jnp] and [~tlipcon]!\r\n\r\nI did some study and figure out this: Connection is associated with a Socket, which allows only one input stream and one output stream, if we really want to share the same Connection to a DN for multiple blocks, we need to handle multiplexing, which we don't do.\r\n\r\nSo I think we can conclude that the current design is, one Connection can only be used for one block at the same time. \r\n\r\nIf we are to implement multiplexing in the future, can either take Todd's suggestion of passing tokens as parameter, or modify Token Selector to select not only token type, but also block id for BlockToken.\r\n\r\nThanks.\r\n\r\n\r\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-11-08T01:14:43.159+0000","updated":"2017-11-08T01:14:43.159+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13112709/comment/16250627","id":"16250627","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"Not following what you mean by \"implement multiplexing in the future\" -- it's already the case that we share a single connection from multiple proxies so long as the UGI matches, isn't it? The ipc.Client class has a Map<ConnectionId, Connection> and the UGI makes up part of the ConnectionId. So simply using a non-block-token-based UGI and then passing the token as a call parameter ought to be sufficient to share a single connection.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2017-11-14T01:21:22.462+0000","updated":"2017-11-14T01:21:22.462+0000"}],"maxResults":11,"total":11,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-12737/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i3lt9r:"}}