{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"13013009","self":"https://issues.apache.org/jira/rest/api/2/issue/13013009","key":"HDFS-11022","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":"2016-10-17T22:51:12.692+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Sun Nov 20 07:20:55 UTC 2016","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-11022/watchers","watchCount":11,"isWatching":false},"created":"2016-10-17T22:18:07.404+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"1.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12327181","id":"12327181","description":"2.6.0 release","name":"2.6.0","archived":false,"released":true,"releaseDate":"2014-11-18"}],"issuelinks":[{"id":"12486994","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12486994","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"inwardIssue":{"id":"13021981","key":"HDFS-11160","self":"https://issues.apache.org/jira/rest/api/2/issue/13021981","fields":{"summary":"VolumeScanner reports write-in-progress replicas as corrupt incorrectly","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2016-11-20T07:20:55.484+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12312927","id":"12312927","name":"datanode"},{"self":"https://issues.apache.org/jira/rest/api/2/component/12312926","id":"12312926","name":"namenode"}],"timeoriginalestimate":null,"description":"Scenario:\n# A client reads a replica blk_A_x from a data node and detected corruption.\n# In the meantime, the replica is appended, updating its generation stamp from x to y.\n# The client tells NN to mark the replica blk_A_x corrupt.\n# NN tells the data node to (1) delete replica blk_A_x and (2) replicate the newer replica blk_A_y from another datanode. Due to block placement policy, blk_A_y is replicated to the same node. (It's a small cluster)\n# DN is unable to receive the newer replica blk_A_y, because the replica already exists.\n# DN is also unable to delete replica blk_A_y because blk_A_y does not exist.\n# The replica on the DN is not part of data pipeline, so it becomes stale.\n\nIf another replica becomes corrupt and NameNode wants to replicate a healthy replica to this DataNode, it can't, because a stale replica exists. Because this is a small cluster, soon enough (in a matter of a hour) no DataNode is able to receive a healthy replica.\n\nThis cluster also suffers from HDFS-11019, so even though DataNode later detected data corruption, it was unable to report to NameNode.\n\nNote that we are still investigating the root cause of the corruption.\n\nThe access pattern of client is through Httpfs, and it appended to finalized blocks and then finalize the block quickly. It's not long running pipeline.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12833824","id":"12833824","filename":"HDFS-11022.png","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-10-17T22:20:21.694+0000","size":51852,"mimeType":"image/png","content":"https://issues.apache.org/jira/secure/attachment/12833824/HDFS-11022.png"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"DataNode unable to remove corrupt block replica due to race condition","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":"CDH5.7.0","customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/13013009/comment/15583678","id":"15583678","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"body":"Attach a diagram if it is easier for people to understand.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-10-17T22:19:49.809+0000","updated":"2016-10-17T22:19:49.809+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13013009/comment/15583753","id":"15583753","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=manojg","name":"manojg","key":"manojg","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Manoj Govindassamy","active":true,"timeZone":"America/Los_Angeles"},"body":"Sounds similar to the case as in HDFS-10819, except for the step in (5). In HDFS-10819, DN accepted the newer block and when it tried to contact NN for {{addStoredBlock}}, the NN rejected it saying it already had the block (the older one) and tried to invalidate it. The invalidation never went through as the DN did not have the block (because of storage volume removal).\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=manojg","name":"manojg","key":"manojg","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Manoj Govindassamy","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-10-17T22:51:12.692+0000","updated":"2016-10-17T22:51:12.692+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13013009/comment/15585313","id":"15585313","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"body":"FWIW, I am posting the relevent logs below:\n\nbq. In the meantime, the replica is appended, updating its generation stamp from x to y.\n\n2016-10-12 09:43:12,988 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1092022411-10.0.0.55-1474407949037:blk_1073803461_73556 src: /10.0.0.64:45516 dest: /10.0.0.58:50010\n\n2016-10-12 09:43:12,988 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Appending to FinalizedReplica, blk_1073803461_73556, FINALIZED\n  getNumBytes()     = 46585252\n  getBytesOnDisk()  = 46585252\n  getVisibleLength()= 46585252\n  getVolume()       = /data/3/dfs/dn/current\n  getBlockFile()    = /data/3/dfs/dn/current/BP-1092022411-10.0.0.55-1474407949037/current/finalized/subdir0/subdir240/blk_1073803461\n\n2016-10-12 09:43:13,018 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.0.0.64:45516, dest: /10.0.0.58:50010, bytes: 47014152, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-957820327_243, offset: 0, srvID: bad3566e-51d0-4002-8504-a0a14df73450, blockid: BP-1092022411-10.0.0.55-1474407949037:blk_1073803461_73598, duration: 13117326\n\nbq. The client tells NN to mark the replica blk_A_x corrupt.\n2016-10-12 09:43:13,885 INFO BlockStateChange: BLOCK NameSystem.addToCorruptReplicasMap: blk_1073803461 added as corrupt on 10.0.0.58:50010 by /10.0.0.58  because client machine reported it\n\nbq. NN tells the data node to (1) delete replica blk_A_x and (2) replicate the newer replica blk_A_y from another datanode. Due to block placement policy, blk_A_y is replicated to the same node. (It's a small cluster)\n\n2016-10-12 09:43:13,886 INFO BlockStateChange: BLOCK* invalidateBlock: blk_1073803461_73556(stored=blk_1073803461_73598) on 10.0.0.58:50010\n 2016-10-12 09:43:13,886 INFO BlockStateChange: BLOCK* InvalidateBlocks: add blk_1073803461_73556 to 10.0.0.58:50010\n 2016-10-12 09:43:16,789 INFO BlockStateChange: BLOCK* ask 10.0.0.64:50010 to replicate blk_1073803461_73598 to datanode(s) 10.0.0.58:50010\n2016-10-12 09:43:16,789 INFO BlockStateChange: BLOCK* BlockManager: ask 10.0.0.58:50010 to delete [blk_1073803461_73556]\n\nbq. DN is unable to receive the newer replica blk_A_y, because the replica already exists.\n\n(The source of transfer)\n2016-10-12 09:43:13,022 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.0.0.54:45890, dest: /10.0.0.64:50010, bytes: 47014152, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-957820327_243, offset: 0, srvID: 998d2a6f-048e-4829-9bc4-38d383631304, blockid: BP-1092022411-10.0.0.55-1474407949037:blk_1073803461_73598, duration: 13844523\n\n2016-10-12 09:43:13,022 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1092022411-10.0.0.55-1474407949037:blk_1073803461_73598, type=HAS_DOWNSTREAM_IN_PIPELINE terminating\n\n2016-10-12 09:43:17,078 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(10.0.0.64, datanodeUuid=998d2a6f-048e-4829-9bc4-38d383631304, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=cluster16;nsid=2009955746;c=0) Starting thread to transfer BP-1092022411-10.0.0.55-1474407949037:blk_1073803461_73598 to 10.0.0.58:5001010.0.0.\n\n2016-10-12 09:43:17,082 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(10.0.0.64, datanodeUuid=998d2a6f-048e-4829-9bc4-38d383631304, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=cluster16;nsid=2009955746;c=0):Failed to transfer BP-1092022411-10.0.0.55-1474407949037:blk_1073803461_73598 to 10.0.0.58:50010 got\n\njava.net.SocketException: Original Exception : java.io.IOException: Connection reset by peer\n\n       at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)\n\n       at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:433)\n\n       at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:565)\n\n       at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:223)\n\n       at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:578)\n\n       at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:758)\n\n       at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:705)\n\n       at org.apache.hadoop.hdfs.server.datanode.DataNode$DataTransfer.run(DataNode.java:2170)\n\n       at java.lang.Thread.run(Thread.java:745)\n\nCaused by: java.io.IOException: Connection reset by peer\n\n       ... 9 more\n(The destination of transfer)\n2016-10-12 09:43:12,988 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1092022411-10.0.0.55-1474407949037:blk_1073803461_73556 src: /10.0.0.64:45516 dest: /10.0.0.58:50010\n\n2016-10-12 09:43:12,988 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Appending to FinalizedReplica, blk_1073803461_73556, FINALIZED\n\n getNumBytes()     = 46585252\n\n getBytesOnDisk()  = 46585252\n\n getVisibleLength()= 46585252\n\n getVolume()       = /data/3/dfs/dn/current\n\n getBlockFile()    = /data/3/dfs/dn/current/BP-1092022411-10.0.0.55-1474407949037/current/finalized/subdir0/subdir240/blk_1073803461\n\n2016-10-12 09:43:13,018 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.0.0.64:45516, dest: /10.0.0.58:50010, bytes: 47014152, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-957820327_243, offset: 0, srvID: bad3566e-51d0-4002-8504-a0a14df73450, blockid: BP-1092022411-10.0.0.55-1474407949037:blk_1073803461_73598, duration: 1311732610.0.0.10.0.0.\n\n2016-10-12 09:43:13,018 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1092022411-10.0.0.55-1474407949037:blk_1073803461_73598, type=HAS_DOWNSTREAM_IN_PIPELINE terminating\n\n2016-10-12 09:43:17,078 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1092022411-10.0.0.55-1474407949037:blk_1073803461_73598 src: /10.0.0.64:45526 dest: /10.0.0.58:5001010.0.0.10.0.0.\n\n2016-10-12 09:43:17,078 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: opWriteBlock BP-1092022411-10.0.0.55-1474407949037:blk_1073803461_73598 received exception org.apache.hadoop.hdfs.server.datanode.ReplicaAlreadyExistsException: Block BP-1092022411-10.0.0.55-1474407949037:blk_1073803461_73598 already exists in state FINALIZED and thus cannot be created.\n\n\n2016-10-12 09:43:17,078 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: d03nappp0090.corp.chartercom.com:50010:DataXceiver error processing WRITE_BLOCK operation  src: /10.0.0.64:45526 dst: /10.0.0.58:50010; org.apache.hadoop.hdfs.server.datanode.ReplicaAlreadyExistsException: Block BP-1092022411-10.0.0.55-1474407949037:blk_1073803461_73598 already exists in state FINALIZED and thus cannot be created.10.0.0.10.0.0.10.0.0.\n\n\nbq. DN is also unable to delete replica blk_A_y because blk_A_y does not exist.\n\n2016-10-12 09:43:17,319 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Failed to delete replica blk_1073803461_73556: ReplicaInfo not found.\n\nbq. The replica on the DN is not part of data pipeline, so it becomes stale.\n2016-10-12 09:44:17,906 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: updatePipeline(block=BP-1092022411-10.0.0.55-1474407949037:blk_1073803461_73598, newGenerationStamp=73638, newLength=47014152, newNodes=[10.0.0.64:50010, 10.0.0.63:50010, 10.0.0.56:50010], clientName=DFSClient_NONMAPREDUCE_1477780923_243)","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-10-18T12:15:36.484+0000","updated":"2016-10-18T12:15:36.484+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13013009/comment/15585708","id":"15585708","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"body":"[~kihwal] [~shahrs87] appreciate if you could comment on this issue. I am not sure what is the best way to make DataNode do what it is expected.\nSpecifically the question I have is: \n* should an invalidation command removes all replicas (different genstamp) of the same block on a datanode?\n* should there be a flag to forcefully replace a replica for data transfer if there is already an existing replica (same genstamp)?\n\nThanks a lot!!","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-10-18T15:10:46.629+0000","updated":"2016-10-18T15:10:46.629+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13013009/comment/15603060","id":"15603060","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"body":"\n{quote}\n    NN tells the data node to (1) delete replica blk_A_x and (2) replicate the newer replica blk_A_y from another datanode. Due to block placement policy, blk_A_y is replicated to the same node. (It's a small cluster)\n\n2016-10-12 09:43:13,886 INFO BlockStateChange: BLOCK* invalidateBlock: blk_1073803461_73556(stored=blk_1073803461_73598) on 10.0.0.58:50010\n{quote}\nI guess the easiest fix is this: Given that BlockManager knows the up to date block replica genstamp, issue two invalidation commands so that even if the block replica is updated on the datanode, it is still invalidated. \n\n{code}\ndiff --git a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java\nindex 03bdb7a..e16b296 100644\n--- a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java\n+++ b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java\n@@ -1595,6 +1595,7 @@ private boolean invalidateBlock(BlockToMarkCorrupt b, DatanodeInfo dn,\n       // we already checked the number of replicas in the caller of this\n       // function and know there are enough live replicas, so we can delete it.\n       addToInvalidates(b.getCorrupted(), dn);\n+      addToInvalidates(b.getStored(), dn);\n       removeStoredBlock(b.getStored(), node);\n       blockLog.debug(\"BLOCK* invalidateBlocks: {} on {} listed for deletion.\",\n           b, dn);\n\n{code}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-10-24T20:11:41.617+0000","updated":"2016-10-24T20:11:41.617+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13013009/comment/15680601","id":"15680601","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"body":"Reduce the severity to major from critical. HDFS-11160 is what caused corruption in the first place, so that appears to be a more critical issue than this one.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-11-20T07:20:55.484+0000","updated":"2016-11-20T07:20:55.484+0000"}],"maxResults":6,"total":6,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-11022/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i35093:"}}