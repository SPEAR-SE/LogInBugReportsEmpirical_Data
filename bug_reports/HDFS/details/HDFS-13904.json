{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"13183701","self":"https://issues.apache.org/jira/rest/api/2/issue/13183701","key":"HDFS-13904","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":"2018-09-07T20:32:38.558+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Fri Sep 07 21:55:13 UTC 2018","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-13904/watchers","watchCount":5,"isWatching":false},"created":"2018-09-07T18:11:27.115+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[],"issuelinks":[],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xkrogen","name":"xkrogen","key":"xkrogen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=xkrogen&avatarId=34526","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=xkrogen&avatarId=34526","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=xkrogen&avatarId=34526","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=xkrogen&avatarId=34526"},"displayName":"Erik Krogen","active":true,"timeZone":"America/Los_Angeles"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2018-09-07T21:57:35.161+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12329603","id":"12329603","name":"hdfs"},{"self":"https://issues.apache.org/jira/rest/api/2/component/12312926","id":"12312926","name":"namenode"}],"timeoriginalestimate":null,"description":"HDFS-4995 added a config {{dfs.content-summary.limit}} which allows for an administrator to set a limit on the number of entries processed during a single acquisition of the {{FSNamesystemLock}} during the creation of a content summary. This is useful to prevent very long (multiple seconds) pauses on the NameNode when {{getContentSummary}} is called on large directories.\r\n\r\nHowever, even on versions with HDFS-4995, we have seen warnings like:\r\n{code}\r\nINFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: FSNamesystem read lock held for 9398 ms via\r\njava.lang.Thread.getStackTrace(Thread.java:1552)\r\norg.apache.hadoop.util.StringUtils.getStackTrace(StringUtils.java:950)\r\norg.apache.hadoop.hdfs.server.namenode.FSNamesystemLock.readUnlock(FSNamesystemLock.java:188)\r\norg.apache.hadoop.hdfs.server.namenode.FSNamesystem.readUnlock(FSNamesystem.java:1486)\r\norg.apache.hadoop.hdfs.server.namenode.ContentSummaryComputationContext.yield(ContentSummaryComputationContext.java:109)\r\norg.apache.hadoop.hdfs.server.namenode.INodeDirectory.computeDirectoryContentSummary(INodeDirectory.java:679)\r\norg.apache.hadoop.hdfs.server.namenode.INodeDirectory.computeContentSummary(INodeDirectory.java:642)\r\norg.apache.hadoop.hdfs.server.namenode.INodeDirectory.computeDirectoryContentSummary(INodeDirectory.java:656)\r\n{code}\r\nhappen quite consistently when {{getContentSummary}} was called on a large directory on a heavily-loaded NameNode. Such long pauses completely destroy the performance of the NameNode. We have the limit set to its default of 5000; if it was respected, clearly there would not be a 10-second pause.\r\n\r\nThe current {{yield()}} code within {{ContentSummaryComputationContext}} looks like:\r\n{code}\r\n  public boolean yield() {\r\n    // Are we set up to do this?\r\n    if (limitPerRun <= 0 || dir == null || fsn == null) {\r\n      return false;\r\n    }\r\n\r\n    // Have we reached the limit?\r\n    long currentCount = counts.getFileCount() +\r\n        counts.getSymlinkCount() +\r\n        counts.getDirectoryCount() +\r\n        counts.getSnapshotableDirectoryCount();\r\n    if (currentCount <= nextCountLimit) {\r\n      return false;\r\n    }\r\n\r\n    // Update the next limit\r\n    nextCountLimit = currentCount + limitPerRun;\r\n\r\n    boolean hadDirReadLock = dir.hasReadLock();\r\n    boolean hadDirWriteLock = dir.hasWriteLock();\r\n    boolean hadFsnReadLock = fsn.hasReadLock();\r\n    boolean hadFsnWriteLock = fsn.hasWriteLock();\r\n\r\n    // sanity check.\r\n    if (!hadDirReadLock || !hadFsnReadLock || hadDirWriteLock ||\r\n        hadFsnWriteLock || dir.getReadHoldCount() != 1 ||\r\n        fsn.getReadHoldCount() != 1) {\r\n      // cannot relinquish\r\n      return false;\r\n    }\r\n\r\n    // unlock\r\n    dir.readUnlock();\r\n    fsn.readUnlock(\"contentSummary\");\r\n\r\n    try {\r\n      Thread.sleep(sleepMilliSec, sleepNanoSec);\r\n    } catch (InterruptedException ie) {\r\n    } finally {\r\n      // reacquire\r\n      fsn.readLock();\r\n      dir.readLock();\r\n    }\r\n    yieldCount++;\r\n    return true;\r\n  }\r\n{code}\r\nWe believe that this check in particular is the culprit:\r\n{code}\r\n    if (!hadDirReadLock || !hadFsnReadLock || hadDirWriteLock ||\r\n        hadFsnWriteLock || dir.getReadHoldCount() != 1 ||\r\n        fsn.getReadHoldCount() != 1) {\r\n      // cannot relinquish\r\n      return false;\r\n    }\r\n{code}\r\nThe content summary computation will only relinquish the lock if it is currently the _only_ holder of the lock. Given the high volume of read requests on a heavily loaded NameNode, especially when unfair locking is enabled, it is likely there may be another holder of the read lock performing some short-lived operation. By refusing to give up the lock in this case, the content summary computation ends up never relinquishing the lock.\r\n\r\nWe propose to simply remove the readHoldCount checks from this {{yield()}}. This should alleviate the case described above by giving up the read lock and allowing other short-lived operations to complete (while the content summary thread sleeps) so that the lock can finally be given up completely. This has the drawback that sometimes, the content summary may give up the lock unnecessarily, if the read lock is never actually released by the time the thread continues again. The only negative impact from this is to make some large content summary operations slightly slower, with the tradeoff of reducing NameNode-wide performance impact.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12343021","id":"12343021","description":"","name":"3.0.4","archived":false,"released":false}],"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"ContentSummary does not always respect processing limit, resulting in long lock acquisitions","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xkrogen","name":"xkrogen","key":"xkrogen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=xkrogen&avatarId=34526","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=xkrogen&avatarId=34526","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=xkrogen&avatarId=34526","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=xkrogen&avatarId=34526"},"displayName":"Erik Krogen","active":true,"timeZone":"America/Los_Angeles"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xkrogen","name":"xkrogen","key":"xkrogen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=xkrogen&avatarId=34526","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=xkrogen&avatarId=34526","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=xkrogen&avatarId=34526","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=xkrogen&avatarId=34526"},"displayName":"Erik Krogen","active":true,"timeZone":"America/Los_Angeles"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/13183701/comment/16607627","id":"16607627","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=arpitagarwal","name":"arpitagarwal","key":"arpitagarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arpit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"body":"Nice find [~xkrogen]. Yes I think we can remove those non-deterministic checks.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=arpitagarwal","name":"arpitagarwal","key":"arpitagarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arpit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"created":"2018-09-07T20:32:38.558+0000","updated":"2018-09-07T20:32:38.558+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13183701/comment/16607629","id":"16607629","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"body":"Your proposal sounds reasonable, although I wonder what is actually causing the long lock in your case.  Do you have snapshots? We don't. We have long getContentSummary calls made periodically and they can take close to a minute. But we do not hit this kind of long locking problems.  Even with unfair locking, read locking is blocked after a while. I.e. the lock is not indefinitely unfair even in the unfair mode. I believe as soon as a writer arrives, no more readers are allowed. So it is either lock is not relinquished for another reason or there are concurrent long read operations.  If the former is the case, the proposed change may not make any difference. The change may help if the concurrent long reads are all getContentSummary calls.  In any case, I think it is worth a try. It will be great if you can try it on one of your clusters and prove it helps.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"created":"2018-09-07T20:34:04.095+0000","updated":"2018-09-07T20:35:37.399+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13183701/comment/16607707","id":"16607707","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xkrogen","name":"xkrogen","key":"xkrogen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=xkrogen&avatarId=34526","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=xkrogen&avatarId=34526","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=xkrogen&avatarId=34526","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=xkrogen&avatarId=34526"},"displayName":"Erik Krogen","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks [~arpitagarwal] and [~kihwal] for taking a look!\r\n{quote}\r\nDo you have snapshots? We don't.\r\n{quote}\r\nNo snapshots!\r\n\r\n{quote}\r\nI wonder what is actually causing the long lock in your case.\r\n...\r\nWe have long getContentSummary calls made periodically and they can take close to a minute. But we do not hit this kind of long locking problems.\r\n{quote}\r\nThe directory in question had around 100M entries. But, you make good points. To describe more fully the situation under which we observed this behavior:\r\n* There was a job periodically calling {{getContentSummary}} on this huge directory. No long lock warnings were seen.\r\n* The NameNode was restarted.\r\n* Now, consistently, every {{contentSummary}} call on that directory caused the lock hold warning.\r\n* The NameNode was restarted again.\r\n* The long lock holds were no longer seen.\r\n\r\nSo I agree that it is an odd case, and probably only triggered under certain circumstances...\r\n\r\n{quote}The change may help if the concurrent long reads are all getContentSummary calls.{quote}\r\nAre there other long read operations besides {{getContentSummary}}? {{listStatus}} is already bounded by an even smaller limit.\r\n\r\n\r\nI'll see if I can replicate this more deterministically to test the efficacy of the patch, perhaps with Dynamometer...","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xkrogen","name":"xkrogen","key":"xkrogen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=xkrogen&avatarId=34526","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=xkrogen&avatarId=34526","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=xkrogen&avatarId=34526","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=xkrogen&avatarId=34526"},"displayName":"Erik Krogen","active":true,"timeZone":"America/Los_Angeles"},"created":"2018-09-07T21:55:13.322+0000","updated":"2018-09-07T21:57:35.150+0000"}],"maxResults":3,"total":3,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-13904/votes","votes":1,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i3xus7:"}}