{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"13156390","self":"https://issues.apache.org/jira/rest/api/2/issue/13156390","key":"HDFS-13518","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":null,"customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Tue May 01 22:15:22 UTC 2018","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-13518/watchers","watchCount":1,"isWatching":false},"created":"2018-05-01T17:40:33.766+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"1.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12333995","id":"12333995","description":"2.7.3 release","name":"2.7.3","archived":false,"released":true,"releaseDate":"2016-08-25"}],"issuelinks":[],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2018-05-01T22:15:22.397+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12331105","id":"12331105","name":"fs/adl"},{"self":"https://issues.apache.org/jira/rest/api/2/component/12313126","id":"12313126","name":"libhdfs","description":"The C++ interface to HDFS."}],"timeoriginalestimate":null,"description":"If hdfsFileClose() is called on a file opened for write/append directly after hdfsHSync(), without further data being written to the file, the file doesn't close and the lease isn't released. In the ADL\r\n output trace, with hdfsHSync() immediately before hdfsFileClose() I see:\r\n  \r\n 18/04/26 23:31:11 DEBUG store.HttpTransport: HTTPRequest,Succeeded,cReqId:607c6051-2ef3-4e57-9b20-caea70f22a31.0,lat:43,err:,Reqlen:14,Resplen:0,token_ns:3700,sReqId:40b2a8df-c9b5-4eff-b84e-c1346f4fdb88,path:/tmp/testfile.txt,qp:op=APPEND&append=true&syncFlag=METADATA&filesessionid=76b19d5b-f3ad-4400-a742-2f7996450859&leaseid=76b19d5b-f3ad-4400-a742-2f7996450859&offset=28&api-version=2016-11-01\r\n  \r\n but nothing else. I also get an error if I try to re-open the file:\r\n  \r\n 18/04/26 23:37:28 DEBUG store.HttpTransport: HTTPRequest,Failed,cReqId:f216b9d6-3e35-4166-92cf-a7c4e2389dcd.0,lat:9,err:HTTP400(IllegalArgumentException),Reqlen:0,Resplen:357,token_ns:13001,sReqId:4b9e1e11-3f61-46a6-b461-3e5b180266c5,path:/tmp/testfile.txt,qp:op=APPEND&append=true&syncFlag=DATA&filesessionid=3197c37c-356d-491a-a902-aa19b6d8a374&leaseid=3197c37c-356d-491a-a902-aa19b6d8a374&api-version=2016-11-01\r\n hdfsOpenFile(/tmp/testfile.txt): FileSystem#append((Lorg/apache/hadoop/fs/Path;)Lorg/apache/hadoop/fs/FSDataOutputStream;) error:\r\n java.io.IOException: APPEND failed with error 0x83090a16 (Failed to perform the requested operation because the file is currently open in write mode by another user or process.). [4b9e1e11-3f61-46a6-b461-3e5b180266c5][2018-04-26T16:37:28.6549201-07:00]\r\n at com.microsoft.azure.datalake.store.ADLStoreClient.getRemoteException(ADLStoreClient.java:1142)\r\n at com.microsoft.azure.datalake.store.ADLStoreClient.getExceptionFromResponse(ADLStoreClient.java:1106)\r\n at com.microsoft.azure.datalake.store.ADLStoreClient.getAppendStream(ADLStoreClient.java:294)\r\n at org.apache.hadoop.fs.adl.AdlFileSystem.append(AdlFileSystem.java:398)\r\n at org.apache.hadoop.fs.FileSystem.append(FileSystem.java:1187)\r\n  \r\n Appending to the file is then prevented for the next 8 or so minutes until the lease expires. If hdfsWrite()/Flush() is called after hdfsHSync() and before hdfsFileClose() I see the APPEND() with syncFlag=CLOSE as expected.\r\n  \r\n 18/04/26 23:37:53 DEBUG store.HttpTransport: HTTPRequest,Succeeded,cReqId:ecd19d36-b535-4dd5-8c49-1588a2a60947.0,lat:124,err:,Reqlen:14,Resplen:0,token_ns:4700,sReqId:4a6a2c94-ab31-47b2-aae8-1e4250974d27,path:/tmp/testfile.txt,qp:op=APPEND&append=true&syncFlag=METADATA&filesessionid=21adf26e-3208-40fc-803a-1c18e1914090&leaseid=21adf26e-3208-40fc-803a-1c18e1914090&offset=0&api-version=2016-11-01\r\n 18/04/26 23:37:53 DEBUG store.HttpTransport: HTTPRequest,Succeeded,cReqId:08708059-6396-4af9-a4da-d7d60c44041b.0,lat:43,err:,Reqlen:14,Resplen:0,token_ns:3900,sReqId:a4b5f419-f87f-4bed-99ed-8ad1d24c9ab7,path:/tmp/testfile.txt,qp:op=APPEND&append=true&syncFlag=CLOSE&filesessionid=21adf26e-3208-40fc-803a-1c18e1914090&leaseid=21adf26e-3208-40fc-803a-1c18e1914090&offset=14&api-version=2016-11-01\r\n  \r\n  libhdfs repro case attached.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12921428","id":"12921428","filename":"hdfssimple.c","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ukjay75","name":"ukjay75","key":"ukjay75","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=34043","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34043","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34043","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34043"},"displayName":"Jay Hankinson","active":true,"timeZone":"America/Los_Angeles"},"created":"2018-05-01T17:43:59.212+0000","size":1417,"mimeType":"text/x-c","content":"https://issues.apache.org/jira/secure/attachment/12921428/hdfssimple.c"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"hdfsHSync()/hdfsFileClose() doesn't release lease with libhdfs on Azure ADL","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ukjay75","name":"ukjay75","key":"ukjay75","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=34043","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34043","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34043","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34043"},"displayName":"Jay Hankinson","active":true,"timeZone":"America/Los_Angeles"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ukjay75","name":"ukjay75","key":"ukjay75","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=34043","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34043","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34043","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34043"},"displayName":"Jay Hankinson","active":true,"timeZone":"America/Los_Angeles"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":"HDInsight in Azure:\r\n\r\nactian@hn0-vector:~$ hadoop version\r\n\r\nHadoop 2.7.3.2.6.2.25-1\r\n\r\nSubversion git@github.com:hortonworks/hadoop.git -r 1ceeb58bb3bb5904df0cbb7983389bcaf2ffd0b6\r\n\r\nCompiled by jenkins on 2017-11-29T15:28Z\r\n\r\nCompiled with protoc 2.5.0\r\n\r\nFrom source with checksum 90b73c4c185645c1f47b61f942230\r\n\r\nThis command was run using /usr/hdp/2.6.2.25-1/hadoop/hadoop-common-2.7.3.2.6.2.25-1.jar\r\n\r\nactian@hn0-vector:~$ cat /etc/lsb-release \r\n\r\nDISTRIB_ID=Ubuntu\r\n\r\nDISTRIB_RELEASE=16.04\r\n\r\nDISTRIB_CODENAME=xenial\r\n\r\nDISTRIB_DESCRIPTION=\"Ubuntu 16.04.4 LTS\"","customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/13156390/comment/16460221","id":"16460221","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ukjay75","name":"ukjay75","key":"ukjay75","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=34043","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34043","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34043","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34043"},"displayName":"Jay Hankinson","active":true,"timeZone":"America/Los_Angeles"},"body":"Using hdfsHFlush() instead of hdfsFlush() has the same effect as calling hdfsHsync(), i.e. file doesn't close/release lease","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ukjay75","name":"ukjay75","key":"ukjay75","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=34043","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34043","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34043","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34043"},"displayName":"Jay Hankinson","active":true,"timeZone":"America/Los_Angeles"},"created":"2018-05-01T22:15:22.397+0000","updated":"2018-05-01T22:15:22.397+0000"}],"maxResults":1,"total":1,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-13518/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i3t81j:"}}