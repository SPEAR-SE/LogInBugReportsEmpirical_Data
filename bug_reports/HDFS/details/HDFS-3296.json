{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12551448","self":"https://issues.apache.org/jira/rest/api/2/issue/12551448","key":"HDFS-3296","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":"2015-01-08T00:46:56.351+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Tue Oct 24 22:29:17 UTC 2017","customfield_12310420":"236256","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-3296/watchers","watchCount":8,"isWatching":false},"created":"2012-04-18T11:24:10.716+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"4.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[],"issuelinks":[{"id":"12449982","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12449982","type":{"id":"10032","name":"Blocker","inward":"is blocked by","outward":"blocks","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10032"},"inwardIssue":{"id":"12828913","key":"HADOOP-11957","self":"https://issues.apache.org/jira/rest/api/2/issue/12828913","fields":{"summary":"if an IOException error is thrown in DomainSocket.close we go into infinite loop.","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/10002","description":"A patch for this issue has been uploaded to JIRA by a contributor.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/document.png","name":"Patch Available","id":"10002","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/4","id":4,"key":"indeterminate","colorName":"yellow","name":"In Progress"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12466889","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12466889","type":{"id":"12310040","name":"Required","inward":"is required by","outward":"requires","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/12310040"},"outwardIssue":{"id":"12970916","key":"HADOOP-13177","self":"https://issues.apache.org/jira/rest/api/2/issue/12970916","fields":{"summary":"Native tests fail on OS X, because DYLD_LIBRARY_PATH is not defined to include libhadoop.dylib.","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/4","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/minor.svg","name":"Minor","id":"4"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2017-10-24T22:29:17.380+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12313126","id":"12313126","name":"libhdfs","description":"The C++ interface to HDFS."}],"timeoriginalestimate":null,"description":"Running \"ant -Dcompile.c++=true -Dlibhdfs=true test-c++-libhdfs\" on Mac fails with following error:\n\n{noformat}\n     [exec] dyld: lazy symbol binding failed: Symbol not found: _JNI_GetCreatedJavaVMs\n     [exec]   Referenced from: /Users/amareshwari.sr/workspace/hadoop/build/c++/Mac_OS_X-x86_64-64/lib/libhdfs.0.dylib\n     [exec]   Expected in: flat namespace\n     [exec] \n     [exec] dyld: Symbol not found: _JNI_GetCreatedJavaVMs\n     [exec]   Referenced from: /Users/amareshwari.sr/workspace/hadoop/build/c++/Mac_OS_X-x86_64-64/lib/libhdfs.0.dylib\n     [exec]   Expected in: flat namespace\n     [exec] \n     [exec] /Users/amareshwari.sr/workspace/hadoop/src/c++/libhdfs/tests/test-libhdfs.sh: line 122: 39485 Trace/BPT trap: 5       CLASSPATH=$HADOOP_CONF_DIR:$CLASSPATH LD_PRELOAD=\"$LIB_JVM_DIR/libjvm.so:$LIBHDFS_INSTALL_DIR/libhdfs.so:\" $LIBHDFS_BUILD_DIR/$HDFS_TEST\n{noformat}","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12690681","id":"12690681","filename":"HDFS-3296.001.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-01-08T00:46:56.345+0000","size":1801,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12690681/HDFS-3296.001.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12773907","id":"12773907","filename":"HDFS-3296.002.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-11-23T21:33:21.522+0000","size":1789,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12773907/HDFS-3296.002.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12804783","id":"12804783","filename":"HDFS-3296.003.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-05-18T20:47:18.303+0000","size":985,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12804783/HDFS-3296.003.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12893814","id":"12893814","filename":"HDFS-3296.004.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jzhuge","name":"jzhuge","key":"jzhuge","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jzhuge&avatarId=31264","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jzhuge&avatarId=31264","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jzhuge&avatarId=31264","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jzhuge&avatarId=31264"},"displayName":"John Zhuge","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-10-24T18:56:32.216+0000","size":22532,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12893814/HDFS-3296.004.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"114163","customfield_12312823":null,"summary":"Running libhdfs tests in mac fails","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=amareshwari","name":"amareshwari","key":"amareshwari","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Amareshwari Sriramadasu","active":true,"timeZone":"Asia/Kolkata"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=amareshwari","name":"amareshwari","key":"amareshwari","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Amareshwari Sriramadasu","active":true,"timeZone":"Asia/Kolkata"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12551448/comment/14268622","id":"14268622","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"body":"This is almost working in current trunk, as long as we set {{DYLD_LIBRARY_PATH}}.  (Patch attached.)  However, this then runs into a problem with test_libhdfs_zerocopy hanging.  There appears to be some difference in domain socket handling on Mac (or BSDs in general) that our code isn't handling well.  I'm still investigating.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-01-08T00:46:56.351+0000","updated":"2015-01-08T00:46:56.351+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12551448/comment/14268792","id":"14268792","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12690681/HDFS-3296.001.patch\n  against trunk revision ef237bd.\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.\n                        Please justify why no new tests are needed for this patch.\n                        Also please list what manual steps were performed to verify this patch.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:\n\n                  org.apache.hadoop.hdfs.server.balancer.TestBalancer\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/9151//testReport/\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/9151//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2015-01-08T04:01:45.310+0000","updated":"2015-01-08T04:01:45.310+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12551448/comment/14488766","id":"14488766","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12690681/HDFS-3296.001.patch\n  against trunk revision af9d4fe.\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.\n                        Please justify why no new tests are needed for this patch.\n                        Also please list what manual steps were performed to verify this patch.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/10248//testReport/\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/10248//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2015-04-10T02:18:16.713+0000","updated":"2015-04-10T02:18:16.713+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12551448/comment/14635673","id":"14635673","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=aw","name":"aw","key":"aw","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=aw&avatarId=23681","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=aw&avatarId=23681","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=aw&avatarId=23681","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=aw&avatarId=23681"},"displayName":"Allen Wittenauer","active":true,"timeZone":"America/Tijuana"},"body":"Is there any reason to not just set DYLD_LIBRARY_PATH the same as LD_LIBRARY_PATH? i.e., do we need a separate property?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=aw","name":"aw","key":"aw","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=aw&avatarId=23681","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=aw&avatarId=23681","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=aw&avatarId=23681","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=aw&avatarId=23681"},"displayName":"Allen Wittenauer","active":true,"timeZone":"America/Tijuana"},"created":"2015-07-21T19:26:25.298+0000","updated":"2015-07-21T19:26:25.298+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12551448/comment/14635691","id":"14635691","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"body":"We define {{<LD_LIBRARY_PATH>}} by appending to the existing {{LD_LIBRARY_PATH}} of the environment.  Similarly, {{<DYLD_LIBRARY_PATH>}} would need to append to the existing {{DYLD_LIBRARY_PATH}}.  Because of that difference, I don't think we can consolidate to a single property.  However, we probably could define a shared property in the {{<properties>}} section to reduce some of the duplication.  I'll do that in the next rev.\n\nThis is still blocked on figuring out failures in things like {{test_libhdfs_zerocopy}} on Mac.  There was some investigation related to this in HADOOP-11957, but it's not done yet.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-07-21T19:39:10.162+0000","updated":"2015-07-21T19:39:10.162+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12551448/comment/14635962","id":"14635962","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"\\\\\n\\\\\n| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | pre-patch |  14m 54s | Pre-patch trunk compilation is healthy. |\n| {color:green}+1{color} | @author |   0m  0s | The patch does not contain any @author tags. |\n| {color:red}-1{color} | tests included |   0m  0s | The patch doesn't appear to include any new or modified tests.  Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. |\n| {color:green}+1{color} | javac |   7m 38s | There were no new javac warning messages. |\n| {color:green}+1{color} | javadoc |   9m 44s | There were no new javadoc warning messages. |\n| {color:green}+1{color} | release audit |   0m 23s | The applied patch does not increase the total number of release audit warnings. |\n| {color:green}+1{color} | whitespace |   0m  0s | The patch has no lines that end in whitespace. |\n| {color:green}+1{color} | install |   1m 19s | mvn install still works. |\n| {color:green}+1{color} | eclipse:eclipse |   0m 32s | The patch built with eclipse:eclipse. |\n| {color:green}+1{color} | native |   3m  5s | Pre-build of native portion |\n| {color:red}-1{color} | hdfs tests | 158m 42s | Tests failed in hadoop-hdfs. |\n| | | 196m 20s | |\n\\\\\n\\\\\n|| Reason || Tests ||\n| Failed unit tests | hadoop.hdfs.TestDistributedFileSystem |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Patch URL | http://issues.apache.org/jira/secure/attachment/12690681/HDFS-3296.001.patch |\n| Optional Tests | javadoc javac unit |\n| git revision | trunk / 5137b38 |\n| hadoop-hdfs test log | https://builds.apache.org/job/PreCommit-HDFS-Build/11775/artifact/patchprocess/testrun_hadoop-hdfs.txt |\n| Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/11775/testReport/ |\n| Java | 1.7.0_55 |\n| uname | Linux asf901.gq1.ygridcore.net 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/11775/console |\n\n\nThis message was automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2015-07-21T22:41:17.351+0000","updated":"2015-07-21T22:41:17.351+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12551448/comment/15021289","id":"15021289","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wheat9","name":"wheat9","key":"wheat9","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Haohui Mai","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi [~cnauroth], can you please rebase the latest patch? Thanks.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wheat9","name":"wheat9","key":"wheat9","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Haohui Mai","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-11-23T00:53:08.274+0000","updated":"2015-11-23T00:53:08.274+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12551448/comment/15023122","id":"15023122","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"body":"Patch v002 is a rebased patch for the required build changes.  I still consider this effectively blocked on HADOOP-11957, where we need to address domain socket test failures on Mac.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-11-23T21:33:21.539+0000","updated":"2015-11-23T21:33:21.539+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12551448/comment/15023239","id":"15023239","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 0s {color} | {color:blue} Docker mode activated. {color} |\n| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:red}-1{color} | {color:red} test4tests {color} | {color:red} 0m 0s {color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 7m 41s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 7m 45s {color} | {color:green} trunk passed with JDK v1.8.0_66 {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 8m 38s {color} | {color:green} trunk passed with JDK v1.7.0_85 {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 0m 26s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 22s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 0m 19s {color} | {color:green} trunk passed with JDK v1.8.0_66 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 0m 20s {color} | {color:green} trunk passed with JDK v1.7.0_85 {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 0m 22s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 7m 58s {color} | {color:green} the patch passed with JDK v1.8.0_66 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 7m 58s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 8m 43s {color} | {color:green} the patch passed with JDK v1.7.0_85 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 8m 43s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 0m 27s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 22s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green} 0m 0s {color} | {color:green} Patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} xml {color} | {color:green} 0m 1s {color} | {color:green} The patch has no ill-formed XML file. {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 0m 18s {color} | {color:green} the patch passed with JDK v1.8.0_66 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 0m 20s {color} | {color:green} the patch passed with JDK v1.7.0_85 {color} |\n| {color:green}+1{color} | {color:green} unit {color} | {color:green} 0m 8s {color} | {color:green} hadoop-project in the patch passed with JDK v1.8.0_66. {color} |\n| {color:green}+1{color} | {color:green} unit {color} | {color:green} 0m 40s {color} | {color:green} hadoop-hdfs-native-client in the patch passed with JDK v1.8.0_66. {color} |\n| {color:green}+1{color} | {color:green} unit {color} | {color:green} 0m 9s {color} | {color:green} hadoop-project in the patch passed with JDK v1.7.0_85. {color} |\n| {color:green}+1{color} | {color:green} unit {color} | {color:green} 0m 41s {color} | {color:green} hadoop-hdfs-native-client in the patch passed with JDK v1.7.0_85. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green} 0m 24s {color} | {color:green} Patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black} 48m 14s {color} | {color:black} {color} |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:0ca8df7 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12773907/HDFS-3296.002.patch |\n| JIRA Issue | HDFS-3296 |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  xml  |\n| uname | Linux 0a8ddaa259b4 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / 5f269a0 |\n| JDK v1.7.0_85  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/13622/testReport/ |\n| modules | C: hadoop-hdfs-project/hadoop-hdfs-native-client hadoop-project U: . |\n| Max memory used | 75MB |\n| Powered by | Apache Yetus   http://yetus.apache.org |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/13622/console |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2015-11-23T22:31:54.342+0000","updated":"2015-11-23T22:31:54.342+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12551448/comment/15289561","id":"15289561","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=aw","name":"aw","key":"aw","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=aw&avatarId=23681","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=aw&avatarId=23681","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=aw&avatarId=23681","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=aw&avatarId=23681"},"displayName":"Allen Wittenauer","active":true,"timeZone":"America/Tijuana"},"body":"I'm in the process of setting up a nightly build for OS X on the ASF build infrastructure.  We definitely need this patch just for hadoop-common to build.  So let's get this rebased and committed.  [~cnauroth], if you want, you or I can open another JIRA to do that with if you want.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=aw","name":"aw","key":"aw","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=aw&avatarId=23681","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=aw&avatarId=23681","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=aw&avatarId=23681","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=aw&avatarId=23681"},"displayName":"Allen Wittenauer","active":true,"timeZone":"America/Tijuana"},"created":"2016-05-18T18:44:26.415+0000","updated":"2016-05-18T18:44:26.415+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12551448/comment/15289618","id":"15289618","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi [~aw].  Thanks for setting up a nightly on OS X!  Even just a basic build to catch compilation errors is a huge help.\n\nThe patch here won't help with any compilation problems.  This patch was just a small step towards fixing the libhdfs tests on Mac by setting up {{DYLD_LIBRARY_PATH}} with the right shared library dependencies.  It isn't sufficient though, because we still have a compatibility problem around domain socket usage.  This manifests as test failures in {{TestDomainSocketWatcher}} and unfortunately some of the libhdfs tests just hang.\n\nIf the immediate goal is a basic build on OS X, then what I'm currently seeing on trunk is a compilation error in the container executor.  This was introduced by patch YARN-4594, and I commented on the situation here:\n\nhttps://issues.apache.org/jira/browse/YARN-4594?focusedCommentId=15139679&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-15139679\n\nTo summarize that discussion, if I can get the build environment to target the Mac OS X 10.10 SDK, then I suspect it would work.  I wasn't able to follow up on it though.  I'm curious if you have any thoughts on this.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-05-18T19:13:42.969+0000","updated":"2016-05-18T19:13:42.969+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12551448/comment/15289662","id":"15289662","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=aw","name":"aw","key":"aw","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=aw&avatarId=23681","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=aw&avatarId=23681","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=aw&avatarId=23681","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=aw&avatarId=23681"},"displayName":"Allen Wittenauer","active":true,"timeZone":"America/Tijuana"},"body":"bq. The patch here won't help with any compilation problems. \n\nCorrect.  I'm well past that point and now trying to get unit tests to work.  native unit tests are failing in hadoop-common because they can't find libhadoop.so.  I ended up writing pretty much the exact same change to hadoop-project/pom.xml (since replaced with what you have here) and am manually patching the pom prior to launching maven on the build host.  We're now left with a bunch of other problems, including this likely related one:\n\n(from https://builds.apache.org/view/H-L/view/Hadoop/job/hadoop-trunk-osx-java8/14/console )\n\n{code}\ntestInvalidOperations(org.apache.hadoop.net.unix.TestDomainSocket)  Time elapsed: 0.012 sec  <<< FAILURE!\njava.lang.AssertionError: Expected to find 'connect(2) error: ' but got unexpected exception:java.net.SocketException: error computing UNIX domain socket path: path too long.  The longest UNIX domain socket path possible on this host is 103 bytes.\n\tat org.apache.hadoop.net.unix.DomainSocket.connect0(Native Method)\n\tat org.apache.hadoop.net.unix.DomainSocket.connect(DomainSocket.java:256)\n\tat org.apache.hadoop.net.unix.TestDomainSocket.testInvalidOperations(TestDomainSocket.java:266)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)\n\tat org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)\n\tat org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)\n\tat org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)\n\tat org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)\n\n\tat org.apache.hadoop.net.unix.DomainSocket.connect0(Native Method)\n\tat org.apache.hadoop.net.unix.DomainSocket.connect(DomainSocket.java:256)\n\tat org.apache.hadoop.net.unix.TestDomainSocket.testInvalidOperations(TestDomainSocket.java:266)\n{code}\n\nI think I'm going to set up a precommit job for Mac so that folks can manually trigger it to test Mac-specific patches.\n\nbq. target the Mac OS X 10.10 SDK\n\nThe Mac mini in the build infrastructure is a 10.9 box.\n\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=aw","name":"aw","key":"aw","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=aw&avatarId=23681","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=aw&avatarId=23681","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=aw&avatarId=23681","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=aw&avatarId=23681"},"displayName":"Allen Wittenauer","active":true,"timeZone":"America/Tijuana"},"created":"2016-05-18T19:39:49.385+0000","updated":"2016-05-18T19:39:49.385+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12551448/comment/15289784","id":"15289784","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"body":"[~aw], I have filed HADOOP-13177 with a one-line patch for the Surefire configuration change to set {{DYLD_LIBRARY_PATH}}.  We can commit that one to move ahead with Jenkins runs on OS X.\n\nI'm also attaching a rebased v003 patch here for just the change in hadoop-hdfs-native-client.  We won't want to commit this one, because this will just make {{test_libhdfs_zerocopy_hdfs_static}} hang indefinitely.  We need to get to the bottom of the domain socket issues on OS X before we can commit this one.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-05-18T20:47:18.307+0000","updated":"2016-05-18T20:47:18.307+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12551448/comment/15289800","id":"15289800","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=aw","name":"aw","key":"aw","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=aw&avatarId=23681","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=aw&avatarId=23681","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=aw&avatarId=23681","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=aw&avatarId=23681"},"displayName":"Allen Wittenauer","active":true,"timeZone":"America/Tijuana"},"body":"Awesome thanks.\n\nyeah, totally understand about the libhdfs issue. :)","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=aw","name":"aw","key":"aw","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=aw&avatarId=23681","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=aw&avatarId=23681","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=aw&avatarId=23681","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=aw&avatarId=23681"},"displayName":"Allen Wittenauer","active":true,"timeZone":"America/Tijuana"},"created":"2016-05-18T20:55:39.646+0000","updated":"2016-05-18T20:55:39.646+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12551448/comment/16217711","id":"16217711","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jzhuge","name":"jzhuge","key":"jzhuge","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jzhuge&avatarId=31264","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jzhuge&avatarId=31264","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jzhuge&avatarId=31264","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jzhuge&avatarId=31264"},"displayName":"John Zhuge","active":true,"timeZone":"America/Los_Angeles"},"body":"I'd like to share a patch I have been using. Not totally polished or thoroughly tested yet.\r\n\r\nPatch 004\r\n* Work around domain socket path limitation by using \"/tmp\" instead of $java.io.tmpdir\r\n* On Mac, {{shutdown0}} can not unblock {{accept0}} which still holds on to a refcount, thus {{DomainSocket#close}} stuck in the loop. Fix the issue by using the \"self-pipe\" method. See {{accept1}} implementation for details.\r\n* Add syslog calls to DomainSocket.c for easier debugging\r\n* Set DYLD_LIBRARY_PATH to hadoop-hdfs-native-client pom. All libhdfs tests pass including the zerocopy test.\r\n\r\nTODO:\r\n* {{TestDomainSocket#testAsyncCloseDuringWrite}} failed\r\n* Pass all ShortCircuitRead tests","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jzhuge","name":"jzhuge","key":"jzhuge","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jzhuge&avatarId=31264","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jzhuge&avatarId=31264","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jzhuge&avatarId=31264","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jzhuge&avatarId=31264"},"displayName":"John Zhuge","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-10-24T21:12:40.183+0000","updated":"2017-10-24T21:12:40.183+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12551448/comment/16217817","id":"16217817","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jzhuge","name":"jzhuge","key":"jzhuge","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jzhuge&avatarId=31264","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jzhuge&avatarId=31264","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jzhuge&avatarId=31264","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jzhuge&avatarId=31264"},"displayName":"John Zhuge","active":true,"timeZone":"America/Los_Angeles"},"body":"TestDomainSocket#testAsyncCloseDuringWrite failure:\r\n{noformat}\r\njava.util.concurrent.ExecutionException: java.lang.NoSuchMethodError: <init>\r\n\r\n\tat java.util.concurrent.FutureTask.report(FutureTask.java:122)\r\n\tat java.util.concurrent.FutureTask.get(FutureTask.java:206)\r\n\tat org.apache.hadoop.net.unix.TestDomainSocket.testAsyncCloseDuringIO(TestDomainSocket.java:245)\r\n\tat org.apache.hadoop.net.unix.TestDomainSocket.testAsyncCloseDuringWrite(TestDomainSocket.java:250)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:497)\r\n\tat org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)\r\n\tat org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)\r\n\tat org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)\r\n\tat org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)\r\n\tat org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)\r\nCaused by: java.lang.NoSuchMethodError: <init>\r\n\tat org.apache.hadoop.net.unix.DomainSocket.writeArray0(Native Method)\r\n\tat org.apache.hadoop.net.unix.DomainSocket.access$300(DomainSocket.java:45)\r\n\tat org.apache.hadoop.net.unix.DomainSocket$DomainOutputStream.write(DomainSocket.java:598)\r\n\tat java.io.OutputStream.write(OutputStream.java:75)\r\n\tat org.apache.hadoop.net.unix.TestDomainSocket$3.call(TestDomainSocket.java:195)\r\n\tat org.apache.hadoop.net.unix.TestDomainSocket$3.call(TestDomainSocket.java:180)\r\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n\tat java.lang.Thread.run(Thread.java:745)\r\n{noformat}\r\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jzhuge","name":"jzhuge","key":"jzhuge","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jzhuge&avatarId=31264","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jzhuge&avatarId=31264","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jzhuge&avatarId=31264","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jzhuge&avatarId=31264"},"displayName":"John Zhuge","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-10-24T22:29:17.380+0000","updated":"2017-10-24T22:29:17.380+0000"}],"maxResults":16,"total":16,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-3296/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i0jwav:"}}