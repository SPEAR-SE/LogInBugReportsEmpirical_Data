{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12822796","self":"https://issues.apache.org/jira/rest/api/2/issue/12822796","key":"HDFS-8213","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12329057","id":"12329057","description":"2.8.0 release","name":"2.8.0","archived":false,"released":true,"releaseDate":"2017-03-22"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12331979","id":"12331979","description":"2.7.1 release","name":"2.7.1","archived":false,"released":true,"releaseDate":"2015-07-06"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12335732","id":"12335732","description":"3.0.0-alpha1 release","name":"3.0.0-alpha1","archived":false,"released":true,"releaseDate":"2016-09-03"}],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2015-04-21T21:27:21.148+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Sat May 02 15:34:48 UTC 2015","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":"10002_*:*_1_*:*_684343756_*|*_1_*:*_1_*:*_174584001_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2015-05-01T19:38:47.345+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-8213/watchers","watchCount":8,"isWatching":false},"created":"2015-04-21T21:03:19.686+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/2","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/critical.svg","name":"Critical","id":"2"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"2.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12327584","id":"12327584","description":"2.7.0 release","name":"2.7.0","archived":false,"released":true,"releaseDate":"2015-04-20"}],"issuelinks":[{"id":"12423041","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12423041","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"12825769","key":"HDFS-8284","self":"https://issues.apache.org/jira/rest/api/2/issue/12825769","fields":{"summary":"Update documentation about how to use HTrace with HDFS","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/4","id":"4","description":"An improvement or enhancement to an existing feature or task.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype","name":"Improvement","subtask":false,"avatarId":21140}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2017-01-06T00:45:37.662+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[],"timeoriginalestimate":null,"description":"DFSClient initializing SpanReceivers is a problem for Accumulo, which manages SpanReceivers through its own configuration.  This results in the same receivers being registered multiple times and spans being delivered more than once.  The documentation says SpanReceiverHost.getInstance should be issued once per process, so there is no expectation that DFSClient should do this.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12331979","id":"12331979","description":"2.7.1 release","name":"2.7.1","archived":false,"released":true,"releaseDate":"2015-07-06"}],"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12727720","id":"12727720","filename":"HDFS-8213.001.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-04-23T21:32:51.286+0000","size":10262,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12727720/HDFS-8213.001.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12728982","id":"12728982","filename":"HDFS-8213.002.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-04-29T00:02:02.345+0000","size":17248,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12728982/HDFS-8213.002.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"DFSClient should use hdfs.client.htrace HTrace configuration prefix rather than hadoop.htrace","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=billie.rinaldi","name":"billie.rinaldi","key":"billie.rinaldi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=billie.rinaldi&avatarId=30233","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=billie.rinaldi&avatarId=30233","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=billie.rinaldi&avatarId=30233","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=billie.rinaldi&avatarId=30233"},"displayName":"Billie Rinaldi","active":true,"timeZone":"America/New_York"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=billie.rinaldi","name":"billie.rinaldi","key":"billie.rinaldi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=billie.rinaldi&avatarId=30233","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=billie.rinaldi&avatarId=30233","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=billie.rinaldi&avatarId=30233","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=billie.rinaldi&avatarId=30233"},"displayName":"Billie Rinaldi","active":true,"timeZone":"America/New_York"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12822796/comment/14505797","id":"14505797","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi Billie,\n\n{{DFSClient}} needs to instantiate {{SpanReceiverHost}} in order to implement tracing, in the case where the process using the {{DFSClient}} doesn't configure its own span receivers.\n\nIf you are concerned about multiple span receivers being instantiated, simply set {{hadoop.htrace.span.receiver.classes}} to the empty string, and Hadoop won't instantiate any span receivers.  That should be its default anyway.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-04-21T21:27:21.148+0000","updated":"2015-04-21T21:27:21.148+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12822796/comment/14505847","id":"14505847","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=billie.rinaldi","name":"billie.rinaldi","key":"billie.rinaldi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=billie.rinaldi&avatarId=30233","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=billie.rinaldi&avatarId=30233","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=billie.rinaldi&avatarId=30233","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=billie.rinaldi&avatarId=30233"},"displayName":"Billie Rinaldi","active":true,"timeZone":"America/New_York"},"body":"As documented, each process must configure its own span receivers if it wants to use tracing.  If I set hadoop.htrace.span.receiver.classes to the empty string, then the NameNode and DataNode will not do any tracing.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=billie.rinaldi","name":"billie.rinaldi","key":"billie.rinaldi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=billie.rinaldi&avatarId=30233","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=billie.rinaldi&avatarId=30233","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=billie.rinaldi&avatarId=30233","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=billie.rinaldi&avatarId=30233"},"displayName":"Billie Rinaldi","active":true,"timeZone":"America/New_York"},"created":"2015-04-21T21:48:18.244+0000","updated":"2015-04-21T21:48:18.244+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12822796/comment/14505854","id":"14505854","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=billie.rinaldi","name":"billie.rinaldi","key":"billie.rinaldi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=billie.rinaldi&avatarId=30233","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=billie.rinaldi&avatarId=30233","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=billie.rinaldi&avatarId=30233","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=billie.rinaldi&avatarId=30233"},"displayName":"Billie Rinaldi","active":true,"timeZone":"America/New_York"},"body":"If span receiver initialization in DFSClient is important to the use of the hadoop.htrace.sampler configuration property, perhaps a compromise would be to perform SpanReceiverHost.getInstance only when the sampler is set to something other than NeverSampler.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=billie.rinaldi","name":"billie.rinaldi","key":"billie.rinaldi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=billie.rinaldi&avatarId=30233","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=billie.rinaldi&avatarId=30233","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=billie.rinaldi&avatarId=30233","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=billie.rinaldi&avatarId=30233"},"displayName":"Billie Rinaldi","active":true,"timeZone":"America/New_York"},"created":"2015-04-21T21:50:45.489+0000","updated":"2015-04-21T21:50:45.489+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12822796/comment/14505860","id":"14505860","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ndimiduk","name":"ndimiduk","key":"ndimiduk","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=ndimiduk&avatarId=17533","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=ndimiduk&avatarId=17533","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=ndimiduk&avatarId=17533","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=ndimiduk&avatarId=17533"},"displayName":"Nick Dimiduk","active":true,"timeZone":"America/Los_Angeles"},"body":"I think [~billie.rinaldi] is correct here; the client should not instantiate it's own SpanReceiverHost, but instead depend on the process in which it resides to provide. This is how HBase client works as well.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ndimiduk","name":"ndimiduk","key":"ndimiduk","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=ndimiduk&avatarId=17533","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=ndimiduk&avatarId=17533","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=ndimiduk&avatarId=17533","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=ndimiduk&avatarId=17533"},"displayName":"Nick Dimiduk","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-04-21T21:53:06.563+0000","updated":"2015-04-21T21:53:06.563+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12822796/comment/14507643","id":"14507643","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks again for kicking the tires on htrace, [~billie.rinaldi].  Let me see if I can get to the bottom of this.\n\nbq. As documented, each process must configure its own span receivers if it wants to use tracing. If I set hadoop.htrace.span.receiver.classes to the empty string, then the NameNode and DataNode will not do any tracing.\n\nYou are right that you need to set {{hadoop.htrace.span.receiver.classes}} in the NameNode and DataNode configuration.  However, you need to avoid setting it in the Accumulo configuration... instead, use whatever configuration Accumulo uses to set this value.  This means that you can't use the same config file for the NN and DN as for the DFSClient, currently.\n\nbq. If span receiver initialization in DFSClient is important to the use of the hadoop.htrace.sampler configuration property, perhaps a compromise would be to perform SpanReceiverHost.getInstance only when the sampler is set to something other than NeverSampler.\n\nKeep in mind that {{hadoop.htrace.sampler}} is a completely different configuration key than {{hadoop.htrace.span.receiver.classes}}.  If you are sampling at the level of Accumulo operations, I would not recommend setting {{hadoop.htrace.sampler}}, in any config file on the cluster.  You want all of the sampling to happen inside accumulo.\n\nbq. I think Billie Rinaldi is correct here; the client should not instantiate it's own SpanReceiverHost, but instead depend on the process in which it resides to provide. This is how HBase client works as well.\n\nHBase is exactly the same.  In the case of HBase, you do not want to set {{hadoop.htrace.span.receiver.classes}} in the HBase config files.  Instead, you would set {{hbase.htrace.span.receiver.classes}}.  Then HBase would create a span receiver, and DFSClient would not.\n\nIt seems like there is a hidden assumption here that you want to use the same config file for everything.  But we really don't support that right now.\n\nGetting rid of the SpanReceiverHost in DFSClient is not an option since some people want to just trace HDFS without tracing any other system.  Plus, it just kicks the problem up to a higher level.  If my FooProcess wants to use both HTrace and Accumulo, FooProcess could easily make the same argument that \"Accumulo should not instantiate SpanReceiverHost\" since FooProcess is already doing that.  And since FooProcess uses the accumulo client, it would conflict with whatever accumulo was configuring, if the same config file was used for everything.\n\nOne thing we could do to make this a little less painful is to deduplicate span receivers inside the library.  So if both DFSClient and Accumlo requested an HTracedSpanReceiver, we could simply create one instance of that.  This would allow us to use the same config file for everything.\n\nAs a side note, [~billie.rinaldi], can you explain how you configure which sampler and span receiver accumulo uses?  In HBase we set it to {{hbase.htrace.span.receiver.classes}}, etc.  I would recommend something like {{accumulo.htrace.span.receiver.classes}} for consistency.  This also allows you to sue the same config file for everything since it doesn't conflict with the keys which Hadoop uses to set these values.  That is the reason why we set up the \"hbase.htrace\" \"namespace\" as separate from the \"hadoop.htrace\" \"namespace\" if you see what I'm saying.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-04-22T18:45:59.395+0000","updated":"2015-04-22T18:45:59.395+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12822796/comment/14507771","id":"14507771","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=billie.rinaldi","name":"billie.rinaldi","key":"billie.rinaldi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=billie.rinaldi&avatarId=30233","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=billie.rinaldi&avatarId=30233","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=billie.rinaldi&avatarId=30233","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=billie.rinaldi&avatarId=30233"},"displayName":"Billie Rinaldi","active":true,"timeZone":"America/New_York"},"body":"The hadoop.htrace.span.receiver.classes is not set in Accumulo configuration files, but it is set in Hadoop configuration files.  Accumulo uses Hadoop configuration files to connect to HDFS, thus its uses of DFSClient will have Hadoop's hadoop.htrace.span.receiver.classes.  HBase does something similar, I believe.\n\nbq. Plus, it just kicks the problem up to a higher level. If my FooProcess wants to use both HTrace and Accumulo, FooProcess could easily make the same argument that \"Accumulo should not instantiate SpanReceiverHost\" since FooProcess is already doing that. And since FooProcess uses the accumulo client, it would conflict with whatever accumulo was configuring, if the same config file was used for everything.\n\nNo.  The way it works (did work, until this change was introduced in DFSClient) is that server processes instantiate SpanReceiverHost.  If an app wants tracing, it also has to instantiate SpanReceiverHost.  The Accumulo client does not instantiate SPH itself, as DFSClient should not.\n\nbq. One thing we could do to make this a little less painful is to deduplicate span receivers inside the library. So if both DFSClient and Accumlo requested an HTracedSpanReceiver, we could simply create one instance of that. This would allow us to use the same config file for everything.\n\nThe change in DFSClient changes how apps are supposed to use tracing.  It seems like this would be mitigated by deduping SpanReceivers in htrace, but if we go that route I would like the DFSClient change to be reverted until HDFS moves to a version of htrace with deduping.  Otherwise, Accumulo and HBase will have to leave HDFS tracing disabled, or change how they're configuring HDFS, if they wish to avoid double delivery of spans.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=billie.rinaldi","name":"billie.rinaldi","key":"billie.rinaldi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=billie.rinaldi&avatarId=30233","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=billie.rinaldi&avatarId=30233","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=billie.rinaldi&avatarId=30233","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=billie.rinaldi&avatarId=30233"},"displayName":"Billie Rinaldi","active":true,"timeZone":"America/New_York"},"created":"2015-04-22T19:57:31.404+0000","updated":"2015-04-22T19:57:31.404+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12822796/comment/14507819","id":"14507819","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"body":"bq. The hadoop.htrace.span.receiver.classes is not set in Accumulo configuration files, but it is set in Hadoop configuration files. Accumulo uses Hadoop configuration files to connect to HDFS, thus its uses of DFSClient will have Hadoop's hadoop.htrace.span.receiver.classes. HBase does something similar, I believe.\n\nThe way Cloudera Manager manages configuration files is that it creates separate config files for each daemon.  So the NameNode reads its own set of config files, the DataNode reads a separate set, Hive reads another set, Flume reads still another set, etc. etc.  So {{hadoop.htrace.span.receiver.classes}} would be set in the NN and DN configuration files, but not in the ones targetted towards the DFSClients.  Does Ambari do something similar?  It seems like using the same set of configuration files for everything would be very limiting, if you wanted to do something like turn on short circuit for some clients but not for others, etc.\n\nI know from a developer perspective it's frustrating to not be able to use the same config files for every daemon (I like to do that myself) but it's not broken, just inconvenient.\n\nbq. No. The way it works (did work, until this change was introduced in DFSClient) is that server processes instantiate SpanReceiverHost. If an app wants tracing, it also has to instantiate SpanReceiverHost. The Accumulo client does not instantiate SPH itself, as DFSClient should not.\n\nIt's not true that only server processes need tracing.  Clients also need tracing.  For example, one test I do a lot is to run FsShell with tracing turned on.  This would not be possible if only servers had tracing.  The point that I was making with my example is that the Accumulo client itself probably should have tracing too, and this would potentially conflict with another server using the Accumulo client.\n\nbq. The change in DFSClient changes how apps are supposed to use tracing. It seems like this would be mitigated by deduping SpanReceivers in htrace, but if we go that route I would like the DFSClient change to be reverted until HDFS moves to a version of htrace with deduping. Otherwise, Accumulo and HBase will have to leave HDFS tracing disabled, or change how they're configuring HDFS, if they wish to avoid double delivery of spans.\n\nWe're doing a new release of HTrace soon... like this week or the next.  If we can get the deduping into the 3.2 release, we can bump the version in Hadoop 2.7.1.  We can't change what's in Hadoop 2.7.0, that release is done.\n\nThanks again for trying this stuff out.  I'm going to work on a deduping patch for HTrace, would appreciate a review.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-04-22T20:23:45.177+0000","updated":"2015-04-22T20:23:45.177+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12822796/comment/14507847","id":"14507847","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=billie.rinaldi","name":"billie.rinaldi","key":"billie.rinaldi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=billie.rinaldi&avatarId=30233","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=billie.rinaldi&avatarId=30233","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=billie.rinaldi&avatarId=30233","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=billie.rinaldi&avatarId=30233"},"displayName":"Billie Rinaldi","active":true,"timeZone":"America/New_York"},"body":"Yes, clients need tracing, and when they do they should enable it themselves.  FsShell should enable tracing when it wants to use it, instead of doing that in DFSClient.\n\nA solution in 2.7.1 would be sufficient.  I have concerns about bumping the htrace dependency version as htrace 3.2 has many API incompatibilities with 3.1.  I've begun to compile them on ACCUMULO-3741.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=billie.rinaldi","name":"billie.rinaldi","key":"billie.rinaldi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=billie.rinaldi&avatarId=30233","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=billie.rinaldi&avatarId=30233","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=billie.rinaldi&avatarId=30233","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=billie.rinaldi&avatarId=30233"},"displayName":"Billie Rinaldi","active":true,"timeZone":"America/New_York"},"created":"2015-04-22T20:40:39.206+0000","updated":"2015-04-22T20:40:39.206+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12822796/comment/14507888","id":"14507888","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"body":"bq. I think Billie Rinaldi is correct here; the client should not instantiate it's own SpanReceiverHost, but instead depend on the process in which it resides to provide. This is how HBase client works as well.\n\n[~ndimiduk], what if I want to trace an HBase PUT all the way through the system?  You're saying that the HBase client can't activate tracing on its own, so I have to make code changes to the process doing the PUT (i.e. the user of the HBase client) in order to get that info?  Seems like a limitation.\n\nIt's also worth pointing out that adding a {{SpanReceiverHost}} to the {{DFSClient}} is not really a new change... it goes back to HDFS-7055, last October.  So it's been in there at least 6 months.  Of course we can revisit it if that makes sense, but it's not really \"new\" except in the sense that it took a very long time to do another Hadoop release with that in it.  (We really should start being better with releases...)\n\nThinking about this a little more, another possible resolution here is to change the configuration keys which the DFSClient looks for so that it's different than the ones which the NameNode and DataNode look for.  Right now {{hadoop.htrace.spanreceiver.classes}} will activate span receivers in both the NN and the DFSClient.  But the DFSClient could instead look for {{hdfs.client.htrace.spanreceiver.classes}}.  Then [~billie.rinaldi] could use the same configuration file for everything, and the dfsclient would never create its own span receivers or samplers.  And I could continue to trace the dfsclient without modifying daemon code.  Seems like a good resolution.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-04-22T21:01:22.170+0000","updated":"2015-04-22T21:01:22.170+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12822796/comment/14508049","id":"14508049","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"body":"bq. Yes, clients need tracing, and when they do they should enable it themselves. FsShell should enable tracing when it wants to use it, instead of doing that in DFSClient.\n\nThere are hundreds or maybe even thousands of programs that use the HDFS client.  It's not practical to modify them all to run {{Trace#addSpanReceiver}}.  In some cases the programs that use HDFS are even proprietary or customer programs where we don't have access to the source code.\n\nI have some ideas for how to make this all work better with a better interface in {{Tracer}}.  We might need an incompatible interface change to do it, though.  For now, let's just change the config key for DFSClient... that should fix the problem for Accumulo.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-04-22T22:39:30.940+0000","updated":"2015-04-22T22:39:30.940+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12822796/comment/14508190","id":"14508190","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=billie.rinaldi","name":"billie.rinaldi","key":"billie.rinaldi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=billie.rinaldi&avatarId=30233","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=billie.rinaldi&avatarId=30233","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=billie.rinaldi&avatarId=30233","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=billie.rinaldi&avatarId=30233"},"displayName":"Billie Rinaldi","active":true,"timeZone":"America/New_York"},"body":"I agree, having DFSClient use a separate configuration key seems like it would satisfy all the issues we've discussed.  Thanks for coming up with a solution that works for both of us, [~cmccabe].","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=billie.rinaldi","name":"billie.rinaldi","key":"billie.rinaldi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=billie.rinaldi&avatarId=30233","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=billie.rinaldi&avatarId=30233","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=billie.rinaldi&avatarId=30233","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=billie.rinaldi&avatarId=30233"},"displayName":"Billie Rinaldi","active":true,"timeZone":"America/New_York"},"created":"2015-04-23T00:10:00.676+0000","updated":"2015-04-23T00:10:00.676+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12822796/comment/14508544","id":"14508544","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brahmareddy","name":"brahmareddy","key":"brahmareddy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=brahmareddy&avatarId=24624","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=brahmareddy&avatarId=24624","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=brahmareddy&avatarId=24624","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=brahmareddy&avatarId=24624"},"displayName":"Brahma Reddy Battula","active":true,"timeZone":"Asia/Kolkata"},"body":"Thanks [~billie.rinaldi] for raising issue and [~cmccabe] for your inputs ..\n\ncan you people suggest configuration for DFSClient..? ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brahmareddy","name":"brahmareddy","key":"brahmareddy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=brahmareddy&avatarId=24624","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=brahmareddy&avatarId=24624","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=brahmareddy&avatarId=24624","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=brahmareddy&avatarId=24624"},"displayName":"Brahma Reddy Battula","active":true,"timeZone":"Asia/Kolkata"},"created":"2015-04-23T06:44:26.233+0000","updated":"2015-04-23T06:44:26.233+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12822796/comment/14509472","id":"14509472","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"body":"bq. can you people suggest configuration for DFSClient..?\n\nI'm thinking {{hdfs.client.htrace.spanreceiver.classes}}.  It's not completely trivial because I have to change our SpanReceiverHost thing, but shouldn't be too bad... let me see if I can post the patch","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-04-23T18:03:48.346+0000","updated":"2015-04-23T18:03:48.346+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12822796/comment/14510323","id":"14510323","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"\\\\\n\\\\\n| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | pre-patch |  14m 30s | Pre-patch trunk compilation is healthy. |\n| {color:green}+1{color} | @author |   0m  0s | The patch does not contain any @author tags. |\n| {color:green}+1{color} | tests included |   0m  0s | The patch appears to include 3 new or modified test files. |\n| {color:green}+1{color} | whitespace |   0m  0s | The patch has no lines that end in whitespace. |\n| {color:green}+1{color} | javac |   7m 25s | There were no new javac warning messages. |\n| {color:green}+1{color} | javadoc |   9m 36s | There were no new javadoc warning messages. |\n| {color:green}+1{color} | release audit |   0m 22s | The applied patch does not increase the total number of release audit warnings. |\n| {color:red}-1{color} | checkstyle |   7m 41s | The applied patch generated  1  additional checkstyle issues. |\n| {color:green}+1{color} | install |   1m 33s | mvn install still works. |\n| {color:green}+1{color} | eclipse:eclipse |   0m 32s | The patch built with eclipse:eclipse. |\n| {color:green}+1{color} | findbugs |   4m 44s | The patch does not introduce any new Findbugs (version 2.0.3) warnings. |\n| {color:green}+1{color} | common tests |  22m 50s | Tests passed in hadoop-common. |\n| {color:green}+1{color} | hdfs tests | 167m 16s | Tests passed in hadoop-hdfs. |\n| | | 236m 34s | |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Patch URL | http://issues.apache.org/jira/secure/attachment/12727720/HDFS-8213.001.patch |\n| Optional Tests | javadoc javac unit findbugs checkstyle |\n| git revision | trunk / ef4e996 |\n| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/10361/artifact/patchprocess/checkstyle-result-diff.txt |\n| hadoop-common test log | https://builds.apache.org/job/PreCommit-HDFS-Build/10361/artifact/patchprocess/testrun_hadoop-common.txt |\n| hadoop-hdfs test log | https://builds.apache.org/job/PreCommit-HDFS-Build/10361/artifact/patchprocess/testrun_hadoop-hdfs.txt |\n| Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/10361/testReport/ |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/10361/console |\n\n\nThis message was automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2015-04-24T01:36:51.264+0000","updated":"2015-04-24T01:36:51.264+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12822796/comment/14510497","id":"14510497","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ndimiduk","name":"ndimiduk","key":"ndimiduk","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=ndimiduk&avatarId=17533","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=ndimiduk&avatarId=17533","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=ndimiduk&avatarId=17533","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=ndimiduk&avatarId=17533"},"displayName":"Nick Dimiduk","active":true,"timeZone":"America/Los_Angeles"},"body":"bq. Nick Dimiduk, what if I want to trace an HBase PUT all the way through the system? You're saying that the HBase client can't activate tracing on its own, so I have to make code changes to the process doing the PUT (i.e. the user of the HBase client) in order to get that info? Seems like a limitation.\n\nI think your characterization is accurate. HBase client is a library embedded in applications. The client doesn't enable tracing, the application does. HBase client faithfully extends the calling context through the system by enabling tracing on requests for which the application has initialized a trace request. It delegates responsibility for receiver registration to that calling context as well. For applications that exist before tracing, yes, this implies code changes to add support for the new feature.\n\nFor instance, I have a main program and provide an option for enabling tracing on some percentage of requests. This context is set above the hbase client, which simply honors the context in which it is run. I imaging FsShell would work this way, enabling a trace for a specific invocation of a command. Phoenix's integration works this way too, with a session flag for enabling or disabling tracing managed from the connection or user session. From screen shots I've seen, I believe Cassandra's tracing feature works this way as well, though I don't know if it's using HTrace.\n\nIn a way, the application that embeds the hbase client must also participate in the cluster tracing configuration. It must configure its span receiver to send spends to the same store as the rest of the cluster for the full context to be available.\n\nbq. {{hadoop.htrace.span.receiver.classes}} would be set in the NN and DN configuration files, but not in the ones targetted towards the DFSClients. Does Ambari do something similar?\n\nLast I looked, Ambari appeared to drop an hdfs-site.xml file into /etc/hbase/conf, which is identical to the one in /etc/hadoop/conf. I don't know if this is different from the configs used by the daemon processes.\n\nbq. There are hundreds or maybe even thousands of programs that use the HDFS client. It's not practical to modify them all to run Trace#addSpanReceiver. In some cases the programs that use HDFS are even proprietary or customer programs where we don't have access to the source code.\n\nI'm not sure where the \"final responsibility\" for instantiating the snap receiver is supposed to lie; I always thought it was with process. HDFSClient seems like an arbitrary place. Should HBase and Accumulo clients be providing the same? Phoenix? My perspective is that there's a singleton list of instances for the process, so it's the responsibility of the main(), not one of the libraries it's imported. So yes, I am suggesting that it is the responsibility of those hundreds or thousands of programs who have all written a main method to setup span receivers for their process in order to take advantage of tracing. The approach you describe hadn't occurred to me until just now.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ndimiduk","name":"ndimiduk","key":"ndimiduk","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=ndimiduk&avatarId=17533","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=ndimiduk&avatarId=17533","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=ndimiduk&avatarId=17533","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=ndimiduk&avatarId=17533"},"displayName":"Nick Dimiduk","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-04-24T05:52:32.829+0000","updated":"2015-04-24T05:52:32.829+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12822796/comment/14511727","id":"14511727","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks for that perspective, [~ndimiduk].  \n\nI actually don't see any conflict between allowing the client to trace itself, and allowing the application to trace itself.  We should be able to support both use-cases.  The people who don't want to have the client initiate tracing can simply not set {{hdfs.client.htrace.spanreceiver.classes}} and {{hdfs.client.trace.sampler}}.\n\nOne very important use-case for HTrace is \"how can HBase figure out what HDFS is doing.\"  For this use-case, of course, we don't need the client to initiate tracing... HBase can simply change its code to have the relevant calls to HTrace, and then that will get picked up by DFSClient, DataNode, NN, etc.  I think this is the use-case you guys have been focusing on, and understandably so.  But this is only one use-case of many.  Another very important use case of tracing is \"I have proprietary app X that talks to HDFS, and it's slow.  How come?\"  For that use-case, we need to be able to have the DFSClient initiate the tracing, since we don't have the source code for the proprietary app (or if we do, modifying it and redeploying it may require a lengthy admin process.)\n\nbq. Should HBase and Accumulo clients be providing the same?\n\nI believe they should.  It would be nice to be able to figure out why HBase is slow for some arbitrary workload, without hacking the client.  I would like to be able to give a talk about profiling HBase that doesn't start with \"first, modify your source code in ways X, Y, and Z\"... it's much nicer to tell people to set a config option.  Otherwise I feel like I'm telling people to write a mapreduce job in erlang... and you know what that really means I'm telling them :)  This is especially true for non-devs.\n\nI think we could also improve our API to make it less likely (or maybe even impossible) for client and server tracing configs to conflict so much.  I have some ideas for how to do that which I'll take a look at in a follow-on jira","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-04-24T21:00:21.133+0000","updated":"2015-04-24T21:00:21.133+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12822796/comment/14511954","id":"14511954","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ndimiduk","name":"ndimiduk","key":"ndimiduk","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=ndimiduk&avatarId=17533","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=ndimiduk&avatarId=17533","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=ndimiduk&avatarId=17533","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=ndimiduk&avatarId=17533"},"displayName":"Nick Dimiduk","active":true,"timeZone":"America/Los_Angeles"},"body":"bq. Another very important use case of tracing is \"I have proprietary app X that talks to HDFS, and it's slow. How come?\"\n\nBingo! That's the perspective I was missing. I hadn't considered a proprietary app market around these tools; being a consumer of some app running on my cluster and wanting visibility into it w/o the app supporting tracing explicitly. Thanks [~cmccabe]! Please socialize this idea more widely ;)","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ndimiduk","name":"ndimiduk","key":"ndimiduk","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=ndimiduk&avatarId=17533","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=ndimiduk&avatarId=17533","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=ndimiduk&avatarId=17533","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=ndimiduk&avatarId=17533"},"displayName":"Nick Dimiduk","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-04-24T22:55:31.864+0000","updated":"2015-04-24T22:55:31.864+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12822796/comment/14511958","id":"14511958","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ndimiduk","name":"ndimiduk","key":"ndimiduk","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=ndimiduk&avatarId=17533","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=ndimiduk&avatarId=17533","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=ndimiduk&avatarId=17533","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=ndimiduk&avatarId=17533"},"displayName":"Nick Dimiduk","active":true,"timeZone":"America/Los_Angeles"},"body":"Hit post too soon...\n\nWhat that doesn't clarify to me is how I would connect the dots of spans initiated within the HDFSClient back to actions takes by said app.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ndimiduk","name":"ndimiduk","key":"ndimiduk","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=ndimiduk&avatarId=17533","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=ndimiduk&avatarId=17533","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=ndimiduk&avatarId=17533","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=ndimiduk&avatarId=17533"},"displayName":"Nick Dimiduk","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-04-24T22:57:01.367+0000","updated":"2015-04-24T22:57:01.367+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12822796/comment/14514721","id":"14514721","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"body":"bq. What that doesn't clarify to me is how I would connect the dots of spans initiated within the HDFSClient back to actions takes by said app.\n\nIt depends on what we're trying to do.  For example, we may be getting reports that the cluster is slow.  In this case, seeing that HDFS / HBase requests complete quickly allows us to focus on other systems in the stack.\n\nUltimately, the best thing will always be to have tracing in every app.  But it will take a while to get there and having the ability to get useful results out of incremental steps is really useful.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-04-27T19:02:51.609+0000","updated":"2015-04-27T19:02:51.609+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12822796/comment/14516311","id":"14516311","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=iwasakims","name":"iwasakims","key":"iwasakims","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=iwasakims&avatarId=18289","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=iwasakims&avatarId=18289","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=iwasakims&avatarId=18289","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=iwasakims&avatarId=18289"},"displayName":"Masatake Iwasaki","active":true,"timeZone":"Asia/Tokyo"},"body":"I agree to use independent config keys for DFSClient in order to make end-to-end tracing from HBase/Accumulo to HDFS work.\n\nFew comments for 001.\n---\nIn {{SpanReceiverHost#getInstance}}, {{loadSpanReceivers}} is called even if there is already initialized SRH instance. Is it intentional?\n{code}\n    synchronized (SingletonHolder.INSTANCE.lock) {\n      if (SingletonHolder.INSTANCE.host == null) {\n        SingletonHolder.INSTANCE.host = new SpanReceiverHost();\n      }\n      SingletonHolder.INSTANCE.host.loadSpanReceivers(conf, configPrefix);\n      ShutdownHookManager.get().addShutdownHook(new Runnable() {\n          public void run() {\n            SingletonHolder.INSTANCE.host.closeReceivers();\n          }\n        }, 0);\n      return SingletonHolder.INSTANCE.host;\n{code}\n---\nWe need to fix {{TraceUtils#wrapHadoopConf}} which always assumes that prefix is \"hadoop.htrace.\".\n{code}\npublic class TraceUtils {\n  public static final String HTRACE_CONF_PREFIX = \"hadoop.htrace.\";\n{code}\n---\nShould we add entry for {{hdfs.client.htrace.spanreceiver.classes}} to hdfs-default.xml?\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=iwasakims","name":"iwasakims","key":"iwasakims","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=iwasakims&avatarId=18289","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=iwasakims&avatarId=18289","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=iwasakims&avatarId=18289","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=iwasakims&avatarId=18289"},"displayName":"Masatake Iwasaki","active":true,"timeZone":"Asia/Tokyo"},"created":"2015-04-28T04:18:20.934+0000","updated":"2015-04-28T04:18:20.934+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12822796/comment/14518196","id":"14518196","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"body":"bq. In SpanReceiverHost#getInstance, loadSpanReceivers is called even if there is already initialized SRH instance. Is it intentional?\n\nHmm.  Good point... we don't want to be calling this more than once.  Let's have a {{SpanReceiverHost}} for each config prefix.  That's the easiest thing to do.  Long-term, I think we should have a new API that avoids the need for all this boilerplate code in the client...\n\nbq. We need to fix TraceUtils#wrapHadoopConf which always assumes that prefix is \"hadoop.htrace.\".\n\nfixed\n\nbq. Should we add entry for hdfs.client.htrace.spanreceiver.classes to hdfs-default.xml?\n\nyeah","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-04-28T22:09:15.719+0000","updated":"2015-04-28T22:09:15.719+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12822796/comment/14518389","id":"14518389","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks for the review, [~iwasakims].  I attached a patch.  Let's do the hdfs-default.xml and other docs stuff later since it's not directly related to this","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-04-29T00:02:37.519+0000","updated":"2015-04-29T00:02:37.519+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12822796/comment/14518570","id":"14518570","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"(!) The patch artifact directory on has been removed! \nThis is a fatal error for test-patch.sh.  Aborting. \nJenkins (node H4) information at https://builds.apache.org/job/PreCommit-HDFS-Build/10444/ may provide some hints.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2015-04-29T02:07:03.251+0000","updated":"2015-04-29T02:07:03.251+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12822796/comment/14518598","id":"14518598","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=iwasakims","name":"iwasakims","key":"iwasakims","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=iwasakims&avatarId=18289","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=iwasakims&avatarId=18289","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=iwasakims&avatarId=18289","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=iwasakims&avatarId=18289"},"displayName":"Masatake Iwasaki","active":true,"timeZone":"Asia/Tokyo"},"body":"Thanks for the update, [~cmccabe]. I'm +1(non-binding) for 002.\n\nbq. Let's do the hdfs-default.xml and other docs stuff later since it's not directly related to this\n\nYeah. I filed HDFS-8284.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=iwasakims","name":"iwasakims","key":"iwasakims","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=iwasakims&avatarId=18289","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=iwasakims&avatarId=18289","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=iwasakims&avatarId=18289","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=iwasakims&avatarId=18289"},"displayName":"Masatake Iwasaki","active":true,"timeZone":"Asia/Tokyo"},"created":"2015-04-29T02:19:07.583+0000","updated":"2015-04-29T02:19:07.583+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12822796/comment/14522264","id":"14522264","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stack","name":"stack","key":"stack","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"stack","active":true,"timeZone":"America/Los_Angeles"},"body":"+1 from me.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stack","name":"stack","key":"stack","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"stack","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-04-30T21:02:25.235+0000","updated":"2015-04-30T21:02:25.235+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12822796/comment/14522645","id":"14522645","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"\\\\\n\\\\\n| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | pre-patch |  14m 33s | Pre-patch trunk compilation is healthy. |\n| {color:green}+1{color} | @author |   0m  0s | The patch does not contain any @author tags. |\n| {color:green}+1{color} | tests included |   0m  0s | The patch appears to include 4 new or modified test files. |\n| {color:green}+1{color} | whitespace |   0m  0s | The patch has no lines that end in whitespace. |\n| {color:green}+1{color} | javac |   7m 29s | There were no new javac warning messages. |\n| {color:green}+1{color} | javadoc |   9m 37s | There were no new javadoc warning messages. |\n| {color:green}+1{color} | release audit |   0m 22s | The applied patch does not increase the total number of release audit warnings. |\n| {color:red}-1{color} | checkstyle |   5m 21s | The applied patch generated  1  additional checkstyle issues. |\n| {color:green}+1{color} | install |   1m 34s | mvn install still works. |\n| {color:green}+1{color} | eclipse:eclipse |   0m 32s | The patch built with eclipse:eclipse. |\n| {color:red}-1{color} | findbugs |   4m 47s | The patch appears to introduce 1 new Findbugs (version 2.0.3) warnings. |\n| {color:green}+1{color} | common tests |  23m  3s | Tests passed in hadoop-common. |\n| {color:red}-1{color} | hdfs tests | 227m 12s | Tests failed in hadoop-hdfs. |\n| | | 294m 35s | |\n\\\\\n\\\\\n|| Reason || Tests ||\n| FindBugs | module:hadoop-hdfs |\n|  |  Class org.apache.hadoop.hdfs.DataStreamer$LastException is not derived from an Exception, even though it is named as such  At DataStreamer.java:from an Exception, even though it is named as such  At DataStreamer.java:[lines 177-201] |\n| Failed unit tests | hadoop.hdfs.server.datanode.TestBlockRecovery |\n|   | hadoop.hdfs.TestDFSClientRetries |\n|   | hadoop.hdfs.TestQuota |\n|   | hadoop.cli.TestHDFSCLI |\n|   | hadoop.hdfs.TestClose |\n|   | hadoop.hdfs.TestCrcCorruption |\n|   | hadoop.hdfs.TestMultiThreadedHflush |\n|   | hadoop.hdfs.TestFileLengthOnClusterRestart |\n|   | hadoop.hdfs.TestDFSOutputStream |\n|   | hadoop.hdfs.qjournal.TestNNWithQJM |\n|   | hadoop.hdfs.server.namenode.TestDeleteRace |\n|   | hadoop.hdfs.server.datanode.fsdataset.impl.TestRbwSpaceReservation |\n| Timed out tests | org.apache.hadoop.hdfs.server.namenode.TestNamenodeRetryCache |\n|   | org.apache.hadoop.hdfs.tools.offlineEditsViewer.TestOfflineEditsViewer |\n|   | org.apache.hadoop.hdfs.TestClientProtocolForPipelineRecovery |\n|   | org.apache.hadoop.hdfs.TestDataTransferProtocol |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Patch URL | http://issues.apache.org/jira/secure/attachment/12728982/HDFS-8213.002.patch |\n| Optional Tests | javadoc javac unit findbugs checkstyle |\n| git revision | trunk / c55d609 |\n| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/10489/artifact/patchprocess/checkstyle-result-diff.txt |\n| Findbugs warnings | https://builds.apache.org/job/PreCommit-HDFS-Build/10489/artifact/patchprocess/newPatchFindbugsWarningshadoop-hdfs.html |\n| hadoop-common test log | https://builds.apache.org/job/PreCommit-HDFS-Build/10489/artifact/patchprocess/testrun_hadoop-common.txt |\n| hadoop-hdfs test log | https://builds.apache.org/job/PreCommit-HDFS-Build/10489/artifact/patchprocess/testrun_hadoop-hdfs.txt |\n| Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/10489/testReport/ |\n| Java | 1.7.0_55 |\n| uname | Linux asf905.gq1.ygridcore.net 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/10489/console |\n\n\nThis message was automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2015-05-01T01:52:05.078+0000","updated":"2015-05-01T01:52:05.078+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12822796/comment/14522663","id":"14522663","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"body":"findbugs warning is bogus.  patch doesn't modify org.apache.hadoop.hdfs.DataStreamer$LastException.  the rest of the stuff looks bogus as well (a lot of test timeouts on random things that aren't enabling / touching tracing), guess it's time to re-run again","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-05-01T02:12:00.234+0000","updated":"2015-05-01T02:12:36.872+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12822796/comment/14522870","id":"14522870","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"\\\\\n\\\\\n| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | pre-patch |  14m 39s | Pre-patch trunk compilation is healthy. |\n| {color:green}+1{color} | @author |   0m  0s | The patch does not contain any @author tags. |\n| {color:green}+1{color} | tests included |   0m  0s | The patch appears to include 4 new or modified test files. |\n| {color:green}+1{color} | javac |   7m 26s | There were no new javac warning messages. |\n| {color:green}+1{color} | javadoc |   9m 38s | There were no new javadoc warning messages. |\n| {color:green}+1{color} | release audit |   0m 21s | The applied patch does not increase the total number of release audit warnings. |\n| {color:red}-1{color} | checkstyle |   1m 47s | The applied patch generated  2 new checkstyle issues (total was 17, now 16). |\n| {color:green}+1{color} | whitespace |   0m  1s | The patch has no lines that end in whitespace. |\n| {color:green}+1{color} | install |   1m 37s | mvn install still works. |\n| {color:green}+1{color} | eclipse:eclipse |   0m 32s | The patch built with eclipse:eclipse. |\n| {color:green}+1{color} | findbugs |   4m 42s | The patch does not introduce any new Findbugs (version 2.0.3) warnings. |\n| {color:green}+1{color} | common tests |  23m 32s | Tests passed in hadoop-common. |\n| {color:red}-1{color} | hdfs tests | 163m 48s | Tests failed in hadoop-hdfs. |\n| | | 228m 31s | |\n\\\\\n\\\\\n|| Reason || Tests ||\n| Failed unit tests | hadoop.hdfs.server.namenode.TestFileTruncate |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Patch URL | http://issues.apache.org/jira/secure/attachment/12728982/HDFS-8213.002.patch |\n| Optional Tests | javadoc javac unit findbugs checkstyle |\n| git revision | trunk / 98a6176 |\n| checkstyle |  https://builds.apache.org/job/PreCommit-HDFS-Build/10499/artifact/patchprocess/diffcheckstylehadoop-common.txt |\n| hadoop-common test log | https://builds.apache.org/job/PreCommit-HDFS-Build/10499/artifact/patchprocess/testrun_hadoop-common.txt |\n| hadoop-hdfs test log | https://builds.apache.org/job/PreCommit-HDFS-Build/10499/artifact/patchprocess/testrun_hadoop-hdfs.txt |\n| Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/10499/testReport/ |\n| Java | 1.7.0_55 |\n| uname | Linux asf900.gq1.ygridcore.net 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/10499/console |\n\n\nThis message was automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2015-05-01T07:19:43.169+0000","updated":"2015-05-01T07:19:43.169+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12822796/comment/14523571","id":"14523571","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"body":"TestFileTruncate warning is unrelated.  checkstyle continues to be busted.  committing...","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-05-01T18:18:28.367+0000","updated":"2015-05-01T18:18:28.367+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12822796/comment/14523702","id":"14523702","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"FAILURE: Integrated in Hadoop-trunk-Commit #7714 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/7714/])\nHDFS-8213. DFSClient should use hdfs.client.htrace HTrace configuration prefix rather than hadoop.htrace (cmccabe) (cmccabe: rev b82567d45507c50d2f28eff4bbdf3b1a69d4bf1b)\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSClient.java\n* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/tracing/TraceUtils.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/tracing/TestTracingShortCircuitLocalRead.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSConfigKeys.java\n* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/tracing/SpanReceiverHost.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java\n* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt\n* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/tracing/TestTraceUtils.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/tracing/TestTracing.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/tracing/TestTraceAdmin.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2015-05-01T19:01:40.640+0000","updated":"2015-05-01T19:01:40.640+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12822796/comment/14523775","id":"14523775","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"body":"committed to 2.7.1.  thanks, guys.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-05-01T19:38:47.413+0000","updated":"2015-05-01T19:38:47.413+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12822796/comment/14525208","id":"14525208","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"FAILURE: Integrated in Hadoop-Yarn-trunk-Java8 #181 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk-Java8/181/])\nHDFS-8213. DFSClient should use hdfs.client.htrace HTrace configuration prefix rather than hadoop.htrace (cmccabe) (cmccabe: rev b82567d45507c50d2f28eff4bbdf3b1a69d4bf1b)\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/tracing/TestTraceAdmin.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/tracing/TestTracingShortCircuitLocalRead.java\n* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/tracing/SpanReceiverHost.java\n* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/tracing/TraceUtils.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java\n* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSClient.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/tracing/TestTracing.java\n* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/tracing/TestTraceUtils.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSConfigKeys.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2015-05-02T11:48:17.308+0000","updated":"2015-05-02T11:48:17.308+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12822796/comment/14525225","id":"14525225","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"FAILURE: Integrated in Hadoop-Yarn-trunk #915 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/915/])\nHDFS-8213. DFSClient should use hdfs.client.htrace HTrace configuration prefix rather than hadoop.htrace (cmccabe) (cmccabe: rev b82567d45507c50d2f28eff4bbdf3b1a69d4bf1b)\n* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/tracing/TraceUtils.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/tracing/TestTracingShortCircuitLocalRead.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSConfigKeys.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/tracing/TestTraceAdmin.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java\n* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/tracing/TestTraceUtils.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSClient.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java\n* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt\n* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/tracing/SpanReceiverHost.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/tracing/TestTracing.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2015-05-02T12:00:05.475+0000","updated":"2015-05-02T12:00:05.475+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12822796/comment/14525280","id":"14525280","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"FAILURE: Integrated in Hadoop-Hdfs-trunk-Java8 #172 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk-Java8/172/])\nHDFS-8213. DFSClient should use hdfs.client.htrace HTrace configuration prefix rather than hadoop.htrace (cmccabe) (cmccabe: rev b82567d45507c50d2f28eff4bbdf3b1a69d4bf1b)\n* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/tracing/TraceUtils.java\n* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/tracing/TestTraceAdmin.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/tracing/TestTracing.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSConfigKeys.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java\n* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/tracing/TestTraceUtils.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/tracing/TestTracingShortCircuitLocalRead.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSClient.java\n* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/tracing/SpanReceiverHost.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2015-05-02T15:02:56.114+0000","updated":"2015-05-02T15:02:56.114+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12822796/comment/14525293","id":"14525293","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"SUCCESS: Integrated in Hadoop-Hdfs-trunk #2113 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/2113/])\nHDFS-8213. DFSClient should use hdfs.client.htrace HTrace configuration prefix rather than hadoop.htrace (cmccabe) (cmccabe: rev b82567d45507c50d2f28eff4bbdf3b1a69d4bf1b)\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSConfigKeys.java\n* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/tracing/TestTracing.java\n* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/tracing/SpanReceiverHost.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/tracing/TestTracingShortCircuitLocalRead.java\n* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/tracing/TraceUtils.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSClient.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java\n* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/tracing/TestTraceUtils.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/tracing/TestTraceAdmin.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2015-05-02T15:05:48.083+0000","updated":"2015-05-02T15:05:48.083+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12822796/comment/14525306","id":"14525306","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"FAILURE: Integrated in Hadoop-Mapreduce-trunk-Java8 #182 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk-Java8/182/])\nHDFS-8213. DFSClient should use hdfs.client.htrace HTrace configuration prefix rather than hadoop.htrace (cmccabe) (cmccabe: rev b82567d45507c50d2f28eff4bbdf3b1a69d4bf1b)\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/tracing/TestTracing.java\n* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/tracing/TraceUtils.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSClient.java\n* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/tracing/SpanReceiverHost.java\n* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/tracing/TestTraceUtils.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java\n* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSConfigKeys.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/tracing/TestTraceAdmin.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/tracing/TestTracingShortCircuitLocalRead.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2015-05-02T15:07:23.026+0000","updated":"2015-05-02T15:07:23.026+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12822796/comment/14525325","id":"14525325","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"SUCCESS: Integrated in Hadoop-Mapreduce-trunk #2131 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/2131/])\nHDFS-8213. DFSClient should use hdfs.client.htrace HTrace configuration prefix rather than hadoop.htrace (cmccabe) (cmccabe: rev b82567d45507c50d2f28eff4bbdf3b1a69d4bf1b)\n* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/tracing/TraceUtils.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSConfigKeys.java\n* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/tracing/TestTraceUtils.java\n* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/tracing/SpanReceiverHost.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/tracing/TestTracing.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/tracing/TestTracingShortCircuitLocalRead.java\n* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/tracing/TestTraceAdmin.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSClient.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2015-05-02T15:34:48.491+0000","updated":"2015-05-02T15:34:48.491+0000"}],"maxResults":37,"total":37,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-8213/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i2dk9r:"}}