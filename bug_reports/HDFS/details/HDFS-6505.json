{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12720264","self":"https://issues.apache.org/jira/rest/api/2/issue/12720264","key":"HDFS-6505","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":null,"customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Tue Jun 10 03:14:34 UTC 2014","customfield_12310420":"398463","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-6505/watchers","watchCount":9,"isWatching":false},"created":"2014-06-10T03:04:43.402+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12325049","id":"12325049","description":"2.2.0 release","name":"2.2.0","archived":false,"released":true,"releaseDate":"2013-10-15"}],"issuelinks":[],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2014-06-17T10:09:15.970+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"components":[],"timeoriginalestimate":null,"description":"After appending a file, client could not close it. Because namenode could not complete the last block in file. The UC status of last block remained as COMMIT and never change.\nThe namenode log was like this.\n{code}\nINFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* checkFileProgress: blk_1073741920_13948{blockUCState=COMMITTED, primaryNodeIndex=-1,\nreplicas=[ReplicaUnderConstruction[172.28.1.2:50010|RBW]]} has not reached minimal replication 1\n{code}\n\nAfter going through the log of namenode, I found a log like this\n{code}\nINFO BlockStateChange: BLOCK NameSystem.addToCorruptReplicasMap: blk_1073741920 added as corrupt on 172.28.1.2:50010 by sdw3/172.28.1.3 because client machine reported it\n{code}\nBut actually, the last block was finished successfully in the data node. Because I could find the log in datanode\n{code}\nINFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer: Transmitted BP-649434182-172.28.1.251-1401432753616:blk_1073741920_13808 (numBytes=50120352) to /172.28.1.3:50010\nINFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.28.1.2:36860, dest: /172.28.1.2:50010, bytes: 51686616, op: HDFS_WRITE, cliID: libhdfs3_client_random_741511239_count_1_pid_215802_tid_140085714196576, offset: 0, srvID: DS-2074102060-172.28.1.2-50010-1401432768690, blockid: BP-649434182-172.28.1.251-1401432753616:blk_1073741920_13948, duration: 189226453336\nINFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-649434182-172.28.1.251-1401432753616:blk_1073741920_13948, type=LAST_IN_PIPELINE, downstreams=0:[] terminating\n{code}","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"398588","customfield_12312823":null,"summary":"file is corrupt due to last block is marked as corrupt by mistake","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wangg23","name":"wangg23","key":"wangg23","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=wangg23&avatarId=18994","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wangg23&avatarId=18994","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wangg23&avatarId=18994","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wangg23&avatarId=18994"},"displayName":"Gordon Wang","active":true,"timeZone":"Asia/Shanghai"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wangg23","name":"wangg23","key":"wangg23","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=wangg23&avatarId=18994","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wangg23&avatarId=18994","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wangg23&avatarId=18994","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wangg23&avatarId=18994"},"displayName":"Gordon Wang","active":true,"timeZone":"Asia/Shanghai"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12720264/comment/14026085","id":"14026085","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wangg23","name":"wangg23","key":"wangg23","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=wangg23&avatarId=18994","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wangg23&avatarId=18994","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wangg23&avatarId=18994","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wangg23&avatarId=18994"},"displayName":"Gordon Wang","active":true,"timeZone":"Asia/Shanghai"},"body":"This issue causes the last block is missing and the file is corrupted. But actually, the data on DataNode is correct.\n\nI went through the code, and I think some safe check is missing when namenode receives a bad block report from datanodes.\nSee the following code snippet in namenode BlockManager\n{code}\n  public void findAndMarkBlockAsCorrupt(final ExtendedBlock blk,\n      final DatanodeInfo dn, String storageID, String reason) throws IOException {\n    assert namesystem.hasWriteLock();\n    final BlockInfo storedBlock = getStoredBlock(blk.getLocalBlock());\n    if (storedBlock == null) {\n      // Check if the replica is in the blockMap, if not\n      // ignore the request for now. This could happen when BlockScanner\n      // thread of Datanode reports bad block before Block reports are sent\n      // by the Datanode on startup\n      blockLog.info(\"BLOCK* findAndMarkBlockAsCorrupt: \"\n          + blk + \" not found\");\n      return;\n    }\n    markBlockAsCorrupt(new BlockToMarkCorrupt(storedBlock, reason,\n        Reason.CORRUPTION_REPORTED), dn, storageID);\n  }\n{code} \nWe should check the timestamp in reported block and stored block. If the reported block has a smaller timestamp, this block should not be marked as corrupt. It is possible that the reported block has a smaller timestamp when client has done some work on recovering pipeline.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wangg23","name":"wangg23","key":"wangg23","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=wangg23&avatarId=18994","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wangg23&avatarId=18994","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wangg23&avatarId=18994","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wangg23&avatarId=18994"},"displayName":"Gordon Wang","active":true,"timeZone":"Asia/Shanghai"},"created":"2014-06-10T03:14:34.843+0000","updated":"2014-06-10T03:14:34.843+0000"}],"maxResults":1,"total":1,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-6505/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i1wlmf:"}}