{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12965068","self":"https://issues.apache.org/jira/rest/api/2/issue/12965068","key":"HDFS-10365","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/10004","id":"10004","description":"Not A Bug","name":"Not A Bug"},"customfield_12312322":null,"customfield_12310220":"2016-05-04T18:53:13.343+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Thu Sep 22 06:18:17 UTC 2016","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_12137882026_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2016-09-22T06:18:16.857+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-10365/watchers","watchCount":10,"isWatching":false},"created":"2016-05-04T18:40:15.187+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/2","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/critical.svg","name":"Critical","id":"2"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12327181","id":"12327181","description":"2.6.0 release","name":"2.6.0","archived":false,"released":true,"releaseDate":"2014-11-18"}],"issuelinks":[],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2016-09-22T06:18:17.210+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12329603","id":"12329603","name":"hdfs"}],"timeoriginalestimate":null,"description":"Whenever NN is restarted, it takes huge time for NN to come back to stable state. i.e. Last contact time remains more than 1 or 2 mins continuously for around 3 to 4 hours. This is mainly because most of the DN's getting timeout (60s) in blockReport (FBR) rpc call and then it keep sending FBR again.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"FullBlockReports retransmission delays NN startup time in large cluster.","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chackra","name":"chackra","key":"chackra","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chackaravarthy","active":true,"timeZone":"Asia/Kolkata"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chackra","name":"chackra","key":"chackra","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chackaravarthy","active":true,"timeZone":"Asia/Kolkata"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":"version - hadoop-2.6.0 (hdp-2.2)\nDN - 1200 nodes","customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12965068/comment/15271194","id":"15271194","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"body":"Hello [~chackra].  You mentioned that you saw this in Hadoop 2.6.0.  You might be interested in several enhancements in block reporting in later versions.  I think the most relevant ones for the symptoms you describe are HDFS-7097 and HDFS-7435.  Some other good ones are HDFS-7923 and HDFS-9710.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-05-04T18:53:13.343+0000","updated":"2016-05-04T18:53:13.343+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12965068/comment/15271208","id":"15271208","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chackra","name":"chackra","key":"chackra","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chackaravarthy","active":true,"timeZone":"Asia/Kolkata"},"body":"Cluster details :\n\nVersion - Hadoop-2.6.0\nNo of datanodes - 1200\nNN hardware - 74G heap allocated to NN process, 40 core machine\nTotal blocks - 80M+\nTotal Files/Directories - 60M+\nTotal FSObjects - 150M+\nipc.ping.interval=60s (default)\ndfs.blockreport.initialDelay=120\ndfs.namenode.service.handler.count=600\n\nNN takes more than 1 minute to process FBR because of write lock getting released while processing report for each storage. Since block report initial delay set to 120s, NN is flooded with FBR from all DN's. After processing report for each storage, lock contention is more and by the time it completes processing for all storages (10 data dirs configured), DN gets timeout. \n\nWhat if we acquire lock at the start and release it only after processing reports for all storages? Since FBR call frequency is very less (only during startup of NN or DN, once every 6 hours, or when a disk failure happens in DN) will this change impact the normal heartbeat/IBR flow? Or acquiring lock at each storage report processing is done intentionally? I could not find any comment related to this in HDFS-4987 Please correct me If I am wrong.\n\nI could see possible config options to overcome this to increase block report initial delay or increasing ipc.ping.interval. Also may be 600 is not correct value for service handler count. Is there any guideline to set service handler count depending upon cluster size?\n\nThanks.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chackra","name":"chackra","key":"chackra","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chackaravarthy","active":true,"timeZone":"Asia/Kolkata"},"created":"2016-05-04T18:59:13.137+0000","updated":"2016-05-04T18:59:13.137+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12965068/comment/15271252","id":"15271252","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chackra","name":"chackra","key":"chackra","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chackaravarthy","active":true,"timeZone":"Asia/Kolkata"},"body":"Thanks [~cnauroth] for the response. These fixes seems relevant to resolve the issue which we are facing currently. We will see if we can backport these fixes.\n\nAs a quick fix to handle in 2.6.0, do you think this can be solved by tuning any config? And is there any guideline to set service handler count depending upon cluster size?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chackra","name":"chackra","key":"chackra","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chackaravarthy","active":true,"timeZone":"Asia/Kolkata"},"created":"2016-05-04T19:19:33.842+0000","updated":"2016-05-04T19:19:33.842+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12965068/comment/15271291","id":"15271291","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=arpitagarwal","name":"arpitagarwal","key":"arpitagarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arpit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi [~chackra], Chris mentioned a good list of Jiras to help with this problem.\n\nMeanwhile you can try increasing {{dfs.blockreport.initialDelay}}. A rule of thumb I often use is 2*numDataNodes seconds. So for a 500 node cluster, I'd set it to 1000. It is a very conservative value and it increases the total NN startup time but I find it effective to improve the startup stability of the NameNode on older releases like 2.6.x that don't have some of the performance fixes listed by Chris.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=arpitagarwal","name":"arpitagarwal","key":"arpitagarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arpit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-05-04T19:34:33.408+0000","updated":"2016-05-04T19:37:07.911+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12965068/comment/15271330","id":"15271330","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chackra","name":"chackra","key":"chackra","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chackaravarthy","active":true,"timeZone":"Asia/Kolkata"},"body":"Thanks [~arpitagarwal] for the suggestion. Sure, will increase the {{dfs.blockreport.initialDelay}} and try it. Do you suggest to decrease {{dfs.namenode.service.handler.count}} from 600 (1200 node cluster)? Because other than heartbeat, the most frequent service RPC call will be IBR as there could be multiple IBR's between 2 successive heart beat (interval set to 10s). IBR also needs write lock and hence not sure whether 600 handler count really helps here or not.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chackra","name":"chackra","key":"chackra","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chackaravarthy","active":true,"timeZone":"Asia/Kolkata"},"created":"2016-05-04T19:55:38.192+0000","updated":"2016-05-04T19:55:38.192+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12965068/comment/15271335","id":"15271335","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=arpitagarwal","name":"arpitagarwal","key":"arpitagarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arpit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"body":"600 is rather high. 200 handlers should be plenty for a 1200 node cluster.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=arpitagarwal","name":"arpitagarwal","key":"arpitagarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arpit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-05-04T20:00:38.053+0000","updated":"2016-05-04T20:00:38.053+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12965068/comment/15271337","id":"15271337","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=arpitagarwal","name":"arpitagarwal","key":"arpitagarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arpit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"body":"A good rule of thumb for handler count is _20 * log2(num nodes)_. This one is from the excellent _Hadoop Operations_ book.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=arpitagarwal","name":"arpitagarwal","key":"arpitagarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arpit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-05-04T20:03:29.897+0000","updated":"2016-05-04T20:03:29.897+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12965068/comment/15271340","id":"15271340","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"body":"I checked one of our mid-size clusters with 2,400 nodes and 120M blocks. During the last start-up, the start-up safe mode was about 14 minutes long. But it runs 2.7.2 +  patches, so it might behave a bit differently from yours. There are few things that affect the safe mode time greatly:\n- A bigger initial delay so that reports are more widely spaced\n- Sufficiently big CMS \"young gen\" size to absorb influx of large requests. So far CMS seems to work better than G1 for big namenodes.\n- Have datanodes break up full block reports by storage. This  makes each FBR RPC smaller, so the impact of timeout-retransmit can be lower.\n\nI think the number of handlers is too high. It makes the call queue bigger, so more things will queue up and timeout.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"created":"2016-05-04T20:04:50.651+0000","updated":"2016-05-04T20:04:50.651+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12965068/comment/15271353","id":"15271353","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chackra","name":"chackra","key":"chackra","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chackaravarthy","active":true,"timeZone":"Asia/Kolkata"},"body":"Thanks [~arpitagarwal]","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chackra","name":"chackra","key":"chackra","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chackaravarthy","active":true,"timeZone":"Asia/Kolkata"},"created":"2016-05-04T20:12:11.849+0000","updated":"2016-05-04T20:12:11.849+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12965068/comment/15271381","id":"15271381","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chackra","name":"chackra","key":"chackra","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chackaravarthy","active":true,"timeZone":"Asia/Kolkata"},"body":"Hi [~kihwal], Thanks for the pointers. In our cluster, NN is configured with G1. \nIn our case also, NN comes out of safe mode in 15 or 20 mins. But still it is flooded with FBR from DN's as all FirstFBR gets timed out and NN gets error only while sending output (but updates its state and comes out of safe mode).\n{quote}\nHave datanodes break up full block reports by storage. This makes each FBR RPC smaller, so the impact of timeout-retransmit can be lower.\n{quote}\nAre you suggesting to tune {{dfs.blockreport.split.threashold}} to make DN to send FBR per storage? currently average total blocks per DN is 200k around. So if I reduce {{dfs.blockreport.split.threashold}} from 1Million (default) to 100k or 150k, then this would make FBR RPC smaller. Is this what you meant?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chackra","name":"chackra","key":"chackra","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chackaravarthy","active":true,"timeZone":"Asia/Kolkata"},"created":"2016-05-04T20:26:09.630+0000","updated":"2016-05-04T20:26:09.630+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12965068/comment/15271433","id":"15271433","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"body":"bq. Are you suggesting to tune dfs.blockreport.split.threashold ...\nYes. Each FBR rpc will be smaller, so the impact of timeout-retransmit will be lower. Also NN will process individual report quicker.\n\nNN creates lots of temporary objects and their life time can be longer than expected, especially when requests need to sit in the call queue for a long time. A larger CMS young gen has been shown to absorb them well and the young gen collection time does not become excessive as most objects get freed rather than copied. Of course it is a bit different during start-up when the data structures are being built up.  We thought a high rate of allocation and freeing will go well with what G1 is designed for, but so far we haven't found a magic recipe that works better than CMS for large namenodes.   I hear it does a better job for HBase region servers though.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"created":"2016-05-04T21:02:51.412+0000","updated":"2016-05-04T21:02:51.412+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12965068/comment/15272001","id":"15272001","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chackra","name":"chackra","key":"chackra","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chackaravarthy","active":true,"timeZone":"Asia/Kolkata"},"body":"[~kihwal] These are valuable inputs for us. Thanks.\n{noformat}\nYes. Each FBR rpc will be smaller, so the impact of timeout-retransmit will be lower. Also NN will process individual report quicker.\n{noformat}\nBy doing so, are we not delaying the next heartbeat sent from DN too long as each RPC call might consume upto 60s. Or this is affordable to do since FBR will happen only once in 6 hours? ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chackra","name":"chackra","key":"chackra","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chackaravarthy","active":true,"timeZone":"Asia/Kolkata"},"created":"2016-05-05T07:15:57.387+0000","updated":"2016-05-05T07:15:57.387+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12965068/comment/15512325","id":"15512325","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chackra","name":"chackra","key":"chackra","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chackaravarthy","active":true,"timeZone":"Asia/Kolkata"},"body":"Closing this jira as the issue was resolved after increasing {{dfs.blockreport.initialDelay}} value. Thanks for all the inputs.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chackra","name":"chackra","key":"chackra","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chackaravarthy","active":true,"timeZone":"Asia/Kolkata"},"created":"2016-09-22T06:18:17.002+0000","updated":"2016-09-22T06:18:17.002+0000"}],"maxResults":13,"total":13,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-10365/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i2x693:"}}