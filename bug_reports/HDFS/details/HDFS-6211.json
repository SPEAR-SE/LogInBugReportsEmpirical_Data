{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12707352","self":"https://issues.apache.org/jira/rest/api/2/issue/12707352","key":"HDFS-6211","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":null,"customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"2014-04-09 05:10:00.901","customfield_12310420":"385675","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-6211/watchers","watchCount":1,"isWatching":false},"created":"2014-04-09T05:10:00.901+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12323593","id":"12323593","description":"maintenance release on branch-1.1","name":"1.1.2","archived":false,"released":true,"releaseDate":"2013-02-15"}],"issuelinks":[],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2014-04-09T05:10:00.901+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12312928","id":"12312928","name":"hdfs-client"}],"timeoriginalestimate":null,"description":"Scene:  When use OOZIE to run pig script, if the fs.default.name is hostname, like FQDN, but OOZIE spec an IP address in its configuration , the JobTracker will thread leak after many jobs submitted.\n\nI investigated the issue: In JobTracker, it will use a CACHE to cache DFSClient in FileSystem, the CACHE is a Map<Key, FileSystem>, the Key of the Cache has three members: scheme, server-host, and (UserGroupInfomation)ugi,  and when client request an instances, it will get from cache first.\n\nThe issue is jobtracker is crashed by thread leak after many jobs submitted through OOZIE and the leaked thread is LeaseChecker. it was created by DFSClient and thread will run till the DFSClient was closed, FileSystem is an abstract class, and his Implementation DistributedFileSystem has a member DFSClient, so if a cached DFSClient isn't close, it will cause thread leak.\n\nJobClient will generated and upload the related files likes the properties file \"Job_XXX.xml\" to HDFS, in normal cluster, JobClient will read the properties of core-site.xml, the \"fs.default.name\" is same usually, but OOZIE is special, it’s a workflow engine, it use the same class of Hadoop configuration, but OOZIE didn’t read Hadoop configuration. So every jobs must specify HDFS URI and Job Tracker (Resource Manager)’s address. It will put a property named ”fs.default.name” to job.xml\n\nWhen Jobtracker initialize a job to run, it will read the JobConfiguration from Job_XXX.xml, the property \"fs.default.name\" in core-site.xml was overrided by JobConf, if the code, which is related to JobConf, get DFSClient from the CACHE, the properties will be changed, likes hostname changed to IP address. it will use an different key to get from the Cache, most of the cached DFSClient would be closed by CleanupQueue or close directly, the changed key can't be closed, so it cause the thread leak.\n\n\nSolutions:\n1.Make the property is final, after add an attribute ”final” to \"fs.default.name\", it would not be override at any time\nAfter make the property is final, no subsequent load could change it, it will affect all the cluster, no sure if other components had no requirement to change it.\n2.Transform hostname to IP-address of the Key in JobTracker.\nIt need a patch to HDFS, We should transform it before create the key.\n\n\nHere is the example scripts to reproduce the issue:\nFile:a.pig\nA = load '/user/root/oozietest/input.data' USING PigStorage(',') AS (c1:int, c2:chararray);\nB= group A by c2;\nC= FOREACH B GENERATE group , SUM(A.c1);\nSTORE C into '/user/root/oozietest/output' using PigStorage (';');\n\nFile:input.data\n1,aaa\n2,bbb\n3,ccc\n4,aaa\n\nFile:workflow.xml\n<?xml version=\"1.0\"?>\n<workflow-app xmlns=\"uri:oozie:workflow:0.1\" name=\"OoziepigTest\">\n  <start to=\"Step1\"/>\n  <action name=\"Step1\">\n    <pig>\n      <job-tracker>#ip-address#:54311</job-tracker>\n      <name-node>hdfs://#ip-address#:8020</name-node>\n      <script>a.pig</script>\n    </pig>\n    <ok to=\"end\"/>\n    <error to=\"end\"/>\n  </action>\n  <end name=\"end\"/>\n</workflow-app>\n\nFile:job.properties\noozie.use.system.libpath=true\noozie.libpath=/user/oozie/share/lib\noozie.wf.application.path=hdfs://#ip-address#:8020/user/${user.name}/oozietest\n","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"385939","customfield_12312823":null,"summary":"Thread leak of JobTracker when using OOZIE to submit a job","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dapengsun","name":"dapengsun","key":"dapengsun","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Dapeng Sun","active":true,"timeZone":"Asia/Shanghai"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dapengsun","name":"dapengsun","key":"dapengsun","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Dapeng Sun","active":true,"timeZone":"Asia/Shanghai"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[],"maxResults":0,"total":0,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-6211/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i1ufvr:"}}