{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12605611","self":"https://issues.apache.org/jira/rest/api/2/issue/12605611","key":"HDFS-3875","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12324031","id":"12324031","description":"2.1.0-beta release","name":"2.1.0-beta","archived":false,"released":true,"releaseDate":"2013-08-22"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12324141","id":"12324141","description":"0.23.8 release","name":"0.23.8","archived":false,"released":true,"releaseDate":"2013-06-05"}],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2012-11-26T16:36:02.053+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Mon Aug 25 06:19:28 UTC 2014","customfield_12310420":"257253","customfield_12312320":null,"customfield_12310222":"10002_*:*_1_*:*_14768780429_*|*_1_*:*_1_*:*_8008476609_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2013-05-21T13:49:53.049+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-3875/watchers","watchCount":20,"isWatching":false},"created":"2012-08-30T22:48:56.107+0000","customfield_12310192":null,"customfield_12310191":[{"self":"https://issues.apache.org/jira/rest/api/2/customFieldOption/10343","value":"Reviewed","id":"10343"}],"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/2","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/critical.svg","name":"Critical","id":"2"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"15.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12322472","id":"12322472","description":"2.0.2-alpha release","name":"2.0.2-alpha","archived":false,"released":true,"releaseDate":"2012-10-09"}],"issuelinks":[{"id":"12363608","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12363608","type":{"id":"12310000","name":"Duplicate","inward":"is duplicated by","outward":"duplicates","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/12310000"},"outwardIssue":{"id":"12605609","key":"HDFS-3874","self":"https://issues.apache.org/jira/rest/api/2/issue/12605609","fields":{"summary":"Exception when client reports bad checksum to NN","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/2","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/critical.svg","name":"Critical","id":"2"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12360816","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12360816","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"inwardIssue":{"id":"12496584","key":"HDFS-1595","self":"https://issues.apache.org/jira/rest/api/2/issue/12496584","fields":{"summary":"DFSClient may incorrectly detect datanode failure","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/2","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/critical.svg","name":"Critical","id":"2"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2014-09-03T23:00:32.682+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12312927","id":"12312927","name":"datanode"},{"self":"https://issues.apache.org/jira/rest/api/2/component/12312928","id":"12312928","name":"hdfs-client"}],"timeoriginalestimate":null,"description":"We saw this issue with one block in a large test cluster. The client is storing the data with replication level 2, and we saw the following:\n- the second node in the pipeline detects a checksum error on the data it received from the first node. We don't know if the client sent a bad checksum, or if it got corrupted between node 1 and node 2 in the pipeline.\n- this caused the second node to get kicked out of the pipeline, since it threw an exception. The pipeline started up again with only one replica (the first node in the pipeline)\n- this replica was later determined to be corrupt by the block scanner, and unrecoverable since it is the only replica","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12323274","id":"12323274","description":"2.0.3-alpha release","name":"2.0.3-alpha","archived":false,"released":true,"releaseDate":"2013-02-14"}],"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12555623","id":"12555623","filename":"hdfs-3875.branch-0.23.no.test.patch.txt","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"created":"2012-12-01T09:02:59.902+0000","size":7762,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12555623/hdfs-3875.branch-0.23.no.test.patch.txt"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12583834","id":"12583834","filename":"hdfs-3875.branch-0.23.patch.txt","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"created":"2013-05-20T14:06:17.570+0000","size":18012,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12583834/hdfs-3875.branch-0.23.patch.txt"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12572397","id":"12572397","filename":"hdfs-3875.branch-0.23.patch.txt","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"created":"2013-03-06T21:08:09.102+0000","size":17759,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12572397/hdfs-3875.branch-0.23.patch.txt"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12555624","id":"12555624","filename":"hdfs-3875.branch-0.23.with.test.patch.txt","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"created":"2012-12-01T09:02:59.904+0000","size":12282,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12555624/hdfs-3875.branch-0.23.with.test.patch.txt"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12583879","id":"12583879","filename":"hdfs-3875.branch-2.patch.txt","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"created":"2013-05-20T19:11:34.776+0000","size":18277,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12583879/hdfs-3875.branch-2.patch.txt"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12583880","id":"12583880","filename":"hdfs-3875.patch.txt","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"created":"2013-05-20T19:11:34.779+0000","size":18491,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12583880/hdfs-3875.patch.txt"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12583835","id":"12583835","filename":"hdfs-3875.patch.txt","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"created":"2013-05-20T14:06:36.691+0000","size":18491,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12583835/hdfs-3875.patch.txt"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12572398","id":"12572398","filename":"hdfs-3875.patch.txt","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"created":"2013-03-06T21:08:21.364+0000","size":18238,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12572398/hdfs-3875.patch.txt"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12555643","id":"12555643","filename":"hdfs-3875.trunk.no.test.patch.txt","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"created":"2012-12-01T18:20:51.388+0000","size":8612,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12555643/hdfs-3875.trunk.no.test.patch.txt"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12555625","id":"12555625","filename":"hdfs-3875.trunk.no.test.patch.txt","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"created":"2012-12-01T09:04:25.897+0000","size":8563,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12555625/hdfs-3875.trunk.no.test.patch.txt"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12560280","id":"12560280","filename":"hdfs-3875.trunk.patch.txt","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"created":"2012-12-10T21:20:06.023+0000","size":14317,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12560280/hdfs-3875.trunk.patch.txt"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12559661","id":"12559661","filename":"hdfs-3875.trunk.patch.txt","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"created":"2012-12-06T22:33:42.917+0000","size":15683,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12559661/hdfs-3875.trunk.patch.txt"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12555642","id":"12555642","filename":"hdfs-3875.trunk.with.test.patch.txt","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"created":"2012-12-01T18:20:51.386+0000","size":14098,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12555642/hdfs-3875.trunk.with.test.patch.txt"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12555626","id":"12555626","filename":"hdfs-3875.trunk.with.test.patch.txt","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"created":"2012-12-01T09:04:25.899+0000","size":14049,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12555626/hdfs-3875.trunk.with.test.patch.txt"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12555261","id":"12555261","filename":"hdfs-3875-wip.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"created":"2012-11-28T22:47:32.758+0000","size":14760,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12555261/hdfs-3875-wip.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"114317","customfield_12312823":null,"summary":"Issue handling checksum errors in write pipeline","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12605611/comment/13445385","id":"13445385","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"Here's the recovery from the perspective of the NN:\n\n{code}\n2012-08-28 19:16:33,532 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: updatePipeline(block=BP-1507505631-172.29.97.196-1337120439433:blk_2632740624757457378_140581786, newGenerationStamp=140581806, newLength=44281856, newNodes=[172.29.97.219:50010], clientNam\n2012-08-28 19:16:33,597 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: updatePipeline(BP-1507505631-172.29.97.196-1337120439433:blk_2632740624757457378_140581786) successfully to BP-1507505631-172.29.97.196-1337120439433:blk_2632740624757457378_140581806\n{code}\n\nHere's the recovery from the perspective of the middle node:\n\n{code}\n2012-08-28 19:16:33,531 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Recovering replica ReplicaBeingWritten, blk_2632740624757457378_140581786, RBW\n  getNumBytes()     = 44867072\n  getBytesOnDisk()  = 44867072\n  getVisibleLength()= 44281856\n  getVolume()       = /data/2/dfs/dn/current\n  getBlockFile()    = /data/2/dfs/dn/current/BP-1507505631-172.29.97.196-1337120439433/current/rbw/blk_2632740624757457378\n  bytesAcked=44281856\n  bytesOnDisk=44867072\n{code}\n\nand then the later checksum exception from the block scanner:\n\n{code}\n2012-08-28 19:23:59,275 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Second Verification failed for BP-1507505631-172.29.97.196-1337120439433:blk_2632740624757457378_140581806\norg.apache.hadoop.fs.ChecksumException: Checksum failed at 44217344\n{code}\n\nInterestingly, the checksum exception noticed by the block scanner is less than the \"acked length\" seen at recovery time.\n\nOn the node in question, I see a fair number of weird errors (page allocation failures etc) in the kernel log. So my guess is that the machine is borked and was silently corrupting memory in the middle of the pipeline. Hence, because the recovery kicked out the wrong node, it ended up persisting a corrupt version of the block instead of a good one.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2012-08-30T22:53:06.180+0000","updated":"2012-08-30T22:53:06.180+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12605611/comment/13445411","id":"13445411","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"Just to brainstorm, here's one potential solution:\n- if the tail node in the pipeline detects a checksum error, then it returns a special error code back up the pipeline indicating this (rather than just disconnecting)\n- if a non-tail node receives this error code, then it immediately scans its own block on disk (from the beginning up through the last acked length). If it detects a corruption on its local copy, then it should assume that _it_ is the faulty one, rather than the downstream neighbor. If it detects no corruption, then the faulty node is either the downstream mirror or the network link between the two, and the current behavior is reasonable.\n\nDepending on the above, it would report back the errorIndex appropriately to the client, so that the correct faulty node is removed from the pipeline.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2012-08-30T23:14:03.349+0000","updated":"2012-08-30T23:14:03.349+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12605611/comment/13503875","id":"13503875","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"body":"This sounds like the symptom I mentioned in HDFS-3874. The tail node in the pipeline containing three detected a corruption, but it's report failed due to HDFS-3874 and it just went away. Since the last of the three in the pipeline just disappeared, the corrupt packet was acked with {SUCCESS, SUCCESS, FAIL}. So recreation of pipeline using the remaining two ended up containing the corrupt portion of data.\n\nbq. Depending on the above, it would report back the errorIndex appropriately to the client, so that the correct faulty node is removed from the pipeline.\n\n* This should cover the cases where a particular datanode corrupting data IF the client checksum and storage checksum method is identical.\n\n* If the two checksum methods are different, datanodes would have recalculated and wrote out data along with their own checksum. Even if incoming data was corrupt, it would appear okay on disk of these nodes. The tail node can detect corruption, but if it somehow terminates or get ignored, there is no retrospective scan that will tell us the integrity of the stored block, since the checksum may have been recreated to match the corrupted data.  Maybe we should force datanodes to verify checksum if the two checksums types are different.\n\n* Even if we don't have the above issue, a special handling is needed for the case where client is corrupting data. After recreating a pipeline, the same thing will repeat since client moves un-acked packets to its data queue and resend. Fail after trying twice? Or may be the client should do self integrity check of the packets in the ack queue if a corruption is present in the first datanode.\n\n* How will it work with reportBadBlocks() being called by the last node in the pipeline? The semantics of this method does not seem compatible with the blocks being actively written and could be recovered by calling recoverRbw().\n\n* Given all these issues, simply failing/abandoning block may be the easiest way out without missing any other possible corner cases.  This will be even more convincing if we have any evidence showing that client-side corruption is the most common cause. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"created":"2012-11-26T16:36:02.053+0000","updated":"2012-11-26T16:36:02.053+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12605611/comment/13503889","id":"13503889","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"body":"bq. If the two checksum methods are different, datanodes would have recalculated and wrote out data along with their own checksum. Even if incoming data was corrupt, it would appear okay on disk of these nodes.\n\nIt appears the checksum verification is already done if {{needsChecksumTranslation}} is true. There is one less thing to worry about. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"created":"2012-11-26T16:48:46.422+0000","updated":"2012-11-26T16:48:46.422+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12605611/comment/13504038","id":"13504038","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=acmurthy","name":"acmurthy","key":"acmurthy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun C Murthy","active":true,"timeZone":"America/Los_Angeles"},"body":"Potential blocker for 2.0.3-alpha.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=acmurthy","name":"acmurthy","key":"acmurthy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun C Murthy","active":true,"timeZone":"America/Los_Angeles"},"created":"2012-11-26T19:51:29.603+0000","updated":"2012-11-26T19:51:29.603+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12605611/comment/13504260","id":"13504260","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"body":"I don't think calling reportBadBlocks() alone does any good. Without client knowing details of a corruption, it won't be able to recover the block properly. reportBadBlocks() during create is only useful when a corruption is confined to one replica. If we get the in-line corruption detection and recovery right, this call will not be needed during write operations.\n\nIf the meaning of response in the data packet transfer is to be extended to cover packet corruption,\n\n* A tail node should not ACK until the checksum of a packet is verified. Currently, an ack is enqueued before verifying checksum, which in case of tail node causes immediate transmission of ACK/SUCCESS.\n\n* When the tail node is dropped from a pipeline, other nodes should not simply ack with success since that would mean checksum was okay on those nodes. \n\n* The portions that were ACK'ed with SUCCESS are guaranteed to be not corrupt. To be precise, there can be corruption on disk due to local issues, but not in the data each datanode received. I.e. any on-disk corruption must be an isolated corruption, not caused by propagated corruption.\n\nFor the second point, we could have datanodes to verify checksums when they lose the mirror node or explicitly get ACK/CORRUPTION. But this can be simplified if we can guarantee that no ACK/SUCCESS is sent back when a corruption is detected in the packet or the mirror node is lost. We can just drop the portion of data by not ACKing the corrupt packet or sending ACK/CORRUPTION back for it. I think client will redo the un-ACK'ed packet in this case. \n\nThe worst case is rewriting some packets. But advantage is simplicity and avoiding checksum verification of written data.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"created":"2012-11-27T00:24:26.298+0000","updated":"2012-11-27T00:24:26.298+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12605611/comment/13504625","id":"13504625","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"body":"The key is to prevent ACKing the corrupt packet. Data corruption can be avoided with this alone. For a better error-recovery, datanodes should return a specific error code to let client know. {{Status}} already has ERROR_CHECKSUM defined. I will have a patch ready soon.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"created":"2012-11-27T14:10:16.139+0000","updated":"2012-11-27T14:10:16.139+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12605611/comment/13504816","id":"13504816","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"Thanks for looking into this, Kihwal. Your analysis makes sense to me.\n\nArun - not sure this should be a blocker - while it's a nasty corruption issue, I don't think it's anything new. AFAIK the write pipeline has always had this issue since the ancient days, right? Or did the HDFS-265 rewrite end up changing the order of the ack send and the CRC verification?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2012-11-27T18:27:37.237+0000","updated":"2012-11-27T18:27:37.237+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12605611/comment/13505119","id":"13505119","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sureshms","name":"sureshms","key":"sureshms","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10450","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10450","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10450","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10450"},"displayName":"Suresh Srinivas","active":true,"timeZone":"America/Los_Angeles"},"body":"bq. while it's a nasty corruption issue, I don't think it's anything new...\nI think its a good idea to keep this as blocker even if this issue is not a new one, given it is a corruption issue. Nicholas, any comments on if this applies to old pipeline vs new pipeline?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sureshms","name":"sureshms","key":"sureshms","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10450","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10450","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10450","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10450"},"displayName":"Suresh Srinivas","active":true,"timeZone":"America/Los_Angeles"},"created":"2012-11-28T00:53:32.567+0000","updated":"2012-11-28T00:53:32.567+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12605611/comment/13505142","id":"13505142","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"body":"This looks like similar to HDFS-1595.\n\nDoes the writer able to close the file successfully?  If yes, then it is a real data loss case caused by only one faulty datanode.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2012-11-28T01:27:36.993+0000","updated":"2012-11-28T01:27:36.993+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12605611/comment/13505151","id":"13505151","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"body":"> ... Nicholas, any comments on if this applies to old pipeline vs new pipeline?\n\nBoth the old and the new pipelines should have the similar problem since, when machine A sends some data to machine B and it fails, it is generally impossible to detect whether A, B or the network is faulty.  Of course, we can detect it for some special cases such as one of the machine dead.\n\n> Potential blocker for 2.0.3-alpha.\n\nI would say that this is not a blocker for 2.0.3-alpha since this is not a regression.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2012-11-28T01:36:10.779+0000","updated":"2012-11-28T01:36:10.779+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12605611/comment/13506005","id":"13506005","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"body":"> Does the writer able to close the file successfully?\nYes. In one case the corrupt block ended up in the middle of a file. Of course all replicas were corrupt, so when Nn tried to up the repl factor, all replicas got marked corrupt.\n\nI will post my patch for review, not for precomit build, although I ran all tests and only testBlockCorruptionRecoveryPolicy2 failed probably due to change in how corruption recovery works.  I haven't debugged it yet.  Please take a look and see if the approach seems reasonable.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"created":"2012-11-28T22:45:05.018+0000","updated":"2012-11-28T22:45:05.018+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12605611/comment/13506008","id":"13506008","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"body":"The attached patch is not a commit candidate. At minimum, there is a test breakage to be fixed.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"created":"2012-11-28T22:47:32.760+0000","updated":"2012-11-28T22:47:32.760+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12605611/comment/13507843","id":"13507843","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"body":"Two new patches for trunk are attached. The two has the identical implementation of the bug fix. One includes a test case and necessary changes to make the test work.  Since the test is a bit invasive, the no test version is also attached.\n\nThe test simulates corruption during data transmission. It demonstrates the effectiveness of patch. Without the patch, corruption is detected much later after the data is written and acked, which makes recovery impossible.\n\nThe patch for branch-0.23 requires a slightly different patch.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"created":"2012-12-01T02:35:23.055+0000","updated":"2012-12-01T02:35:23.055+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12605611/comment/13507845","id":"13507845","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"body":"I originally changed PipelineACK to return errors instead of making writer terminate. It generally worked, but some corner cases required a significant change in DFSOutputStream. So I decided to simplify and make it not send ACK-back on checksum errors and terminate as it would in case of any other error.  Local AckStatus is saved in each status tracking packet(not actual data packet), so that successful acks enqueued before checksum error still can be sent.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"created":"2012-12-01T02:42:49.646+0000","updated":"2012-12-01T02:42:49.646+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12605611/comment/13507905","id":"13507905","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"body":"Attaching patches for branch-0.23.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"created":"2012-12-01T09:02:59.906+0000","updated":"2012-12-01T09:02:59.906+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12605611/comment/13507906","id":"13507906","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"body":"Attaching slightly optimized trunk patches. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"created":"2012-12-01T09:04:25.900+0000","updated":"2012-12-01T09:04:25.900+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12605611/comment/13507907","id":"13507907","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"body":"Again, the test is a bit invasive as it requires modification of DFSOutputStream. Nevertheless, it can effectively emulate data corruption during transmission and verify the patch works.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"created":"2012-12-01T09:08:11.607+0000","updated":"2012-12-01T09:08:11.607+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12605611/comment/13508006","id":"13508006","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12555626/hdfs-3875.trunk.with.test.patch.txt\n  against trunk revision .\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:red}-1 findbugs{color}.  The patch appears to introduce 3 new Findbugs (version 1.3.9) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:\n\n                  org.apache.hadoop.hdfs.TestReplaceDatanodeOnFailure\n\n    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/3585//testReport/\nFindbugs warnings: https://builds.apache.org/job/PreCommit-HDFS-Build/3585//artifact/trunk/patchprocess/newPatchFindbugsWarningshadoop-hdfs.html\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/3585//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2012-12-01T17:20:09.415+0000","updated":"2012-12-01T17:20:09.415+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12605611/comment/13508014","id":"13508014","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"body":"There is something missing in the latest patch that was in the original. The test failure is caused by it. I will post updated the patch in a moment\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"created":"2012-12-01T18:16:38.869+0000","updated":"2012-12-01T18:16:38.869+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12605611/comment/13508015","id":"13508015","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"body":"Attaching updated patch. The missing part applies only to the trunk path, thus only updating the trunk version.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"created":"2012-12-01T18:20:51.390+0000","updated":"2012-12-01T18:20:51.390+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12605611/comment/13508041","id":"13508041","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12555643/hdfs-3875.trunk.no.test.patch.txt\n  against trunk revision .\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.\n                        Please justify why no new tests are needed for this patch.\n                        Also please list what manual steps were performed to verify this patch.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.\n\n    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/3587//testReport/\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/3587//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2012-12-01T20:11:05.799+0000","updated":"2012-12-01T20:11:05.799+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12605611/comment/13508057","id":"13508057","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sureshms","name":"sureshms","key":"sureshms","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10450","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10450","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10450","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10450"},"displayName":"Suresh Srinivas","active":true,"timeZone":"America/Los_Angeles"},"body":"kihwal, I will review the patch shortly and post comments by the evening.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sureshms","name":"sureshms","key":"sureshms","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10450","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10450","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10450","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10450"},"displayName":"Suresh Srinivas","active":true,"timeZone":"America/Los_Angeles"},"created":"2012-12-01T21:26:07.312+0000","updated":"2012-12-01T21:26:07.312+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12605611/comment/13508134","id":"13508134","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi Kihwal,\n\nIn a client write pipeline, only the last datanode verifies checksum.  If there is a checksum error, we don't know what goes wrong.  It could be the cases that one of the datanodes is faulty or a network path is faulty.  So, the client must stop but cannot simply take out a datanode and continue.  Do you agree?\n\nIn the patch, only the last datanode possibly reports checksum error.  If it does, all statuses in the ack become ERROR_CHECKSUM.  The approach seems reasonable.\n\nSome questions on the patch:\n- receivePacket() returns -1 for checksum error.  Why not throw an exception?  Returning -1 should mean exit normally.\n- The exception caught is not used below.  Should it re-throw the exception?\n{code}\n+      if (shouldVerifyChecksum()) {\n+        try {\n+          verifyChunks(dataBuf, checksumBuf);\n+        } catch (IOException e) {\n+          // checksum error detected locally. there is no reason to continue.\n+          if (responder != null) {\n+            ((PacketResponder) responder.getRunnable()).enqueue(seqno,\n+                lastPacketInBlock, offsetInBlock,\n+                Status.ERROR_CHECKSUM);\n+          }\n+          // return without writing data.\n+          checksumError = true;\n+          return -1;\n+        }\n{code}\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2012-12-02T02:48:49.534+0000","updated":"2012-12-02T02:48:49.534+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12605611/comment/13508136","id":"13508136","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"body":"Whether it returns or throws an exception the result is not very different. The packet responder will log the checksum error and initiate the shutdown. If an exception is thrown, datanode ends up logging much more with multiple stack traces. I thought clean termination of the writer (DataXceiver) thread is acceptable, since it is a controlled shutdown with a purpose and expected outcome, rather than a panic shutdown. If you think throwing exception makes more sense, I will update the patch.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"created":"2012-12-02T03:39:49.182+0000","updated":"2012-12-02T03:39:49.182+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12605611/comment/13508138","id":"13508138","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"body":"Also, checksumError is set true before returning, so receiveBlock() will actually end up throwing an exception. I experimented with receiveBlock() throwing an exception and also simply returning and they all worked fine. I thought you were refering to this. \n\nTo answer your question better, the occurance checksum error is already logged and the exception thrown in receiveBlock() will clearly show what happened. We could catch IOexception in receiveBlock(), check checksumError and rethrow. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"created":"2012-12-02T03:56:45.570+0000","updated":"2012-12-02T03:56:45.570+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12605611/comment/13508186","id":"13508186","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"body":"If you have already well tested the patch.  I am okay with it.\n\nSuresh, any comment?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2012-12-02T07:56:12.960+0000","updated":"2012-12-02T07:56:12.960+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12605611/comment/13508337","id":"13508337","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sureshms","name":"sureshms","key":"sureshms","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10450","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10450","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10450","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10450"},"displayName":"Suresh Srinivas","active":true,"timeZone":"America/Los_Angeles"},"body":"It took me a lot of time to review this code. BlockReceiver code is a poorly documented code. One of these days I will add some javadoc to make understanding the code and reviewing easier :-).\n\nWhy do you have two variants of the patch - with and without tests?\n\nComments for patch with no tests:\n# Comment against #checkSumError could have - \"Indicates checksumError. When set block receiving and writing is stopped.\" It is better to initialize it to false than in the constructor.\n# #shouldVerifyChecksum() - could we describe the condition when checksum needs to be verified in javadoc? Along the lines - \"Checksum verified in the following cases - 1. if the datanode is the last one in the pipeline with no mirrorOut. 2. If the block is being written by another datanode for replication. 3. If checksum translation is needed.\" There is some equivalent comment where shouldVerifyChecksum() is presently called. That comment can be removed.\n# receivePacket() returned -1 earlier when a block was completely written or length of packet received. Now it also returns -1 on checksum error. It would be good to add a javadoc to this method indicating returns -1.\n# receivePacket() - do you see it is a good idea to print warn/info level logs when returning -1 on checksum error or when checksumError is set to -1? This will help debugging these issues on each datanode in the pipeline using the logs. Given that these are rare errors it should not take up too much of log space.\n# Comment \"If there is a checksum error, responder will shut it down\". Can you please clairfy this comment saying \"responder will shut itself and interrupt the receiver.\"\n# In #enqueue() - why is checksumError check in synchronized block. It can be outside right?\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sureshms","name":"sureshms","key":"sureshms","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10450","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10450","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10450","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10450"},"displayName":"Suresh Srinivas","active":true,"timeZone":"America/Los_Angeles"},"created":"2012-12-02T19:44:15.337+0000","updated":"2012-12-02T19:44:15.337+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12605611/comment/13508980","id":"13508980","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"body":"> The exception caught is not used below. ...\n\nLet's also change \"boolean checksumError\" to \"IOException checksumException\" so that it can record the actual exception.  We should also log it.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2012-12-03T19:51:48.804+0000","updated":"2012-12-03T19:51:48.804+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12605611/comment/13525885","id":"13525885","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"body":"The new patch addresses the review comments. {{checksumError}} is no more! Instead, exceptions are thrown and logged. So {{receivePacket()}} does not return -1 anymore on checksum error. The change in enqueue() has been removed since more ACKs won't be sent anyways when the threads are shutting down.\n\nRan all HDFS tests with one failure in TestEditLog#testFuzzSequences, which is being fixed in HDFS-4282.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"created":"2012-12-06T22:33:42.921+0000","updated":"2012-12-06T22:33:42.921+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12605611/comment/13526068","id":"13526068","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12559661/hdfs-3875.trunk.patch.txt\n  against trunk revision .\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:\n\n                  org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyCheckpoints\n                  org.apache.hadoop.hdfs.server.namenode.TestEditLog\n\n    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/3616//testReport/\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/3616//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2012-12-07T01:13:59.283+0000","updated":"2012-12-07T01:13:59.283+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12605611/comment/13526101","id":"13526101","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"body":"Test failures are not caused by this patch. HDFS-4282, HDFS-3806","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"created":"2012-12-07T02:58:47.355+0000","updated":"2012-12-07T02:58:47.355+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12605611/comment/13528301","id":"13528301","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"body":"Attaching a slightly improved/simplified patch. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"created":"2012-12-10T21:20:06.026+0000","updated":"2012-12-10T21:20:06.026+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12605611/comment/13528417","id":"13528417","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12560280/hdfs-3875.trunk.patch.txt\n  against trunk revision .\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:\n\n                  org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyCheckpoints\n                  org.apache.hadoop.hdfs.server.balancer.TestBalancerWithNodeGroup\n\n    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/3630//testReport/\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/3630//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2012-12-10T23:20:31.534+0000","updated":"2012-12-10T23:20:31.534+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12605611/comment/13543140","id":"13543140","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=acmurthy","name":"acmurthy","key":"acmurthy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun C Murthy","active":true,"timeZone":"America/Los_Angeles"},"body":"Any update on this? Thanks.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=acmurthy","name":"acmurthy","key":"acmurthy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun C Murthy","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-01-03T18:08:29.976+0000","updated":"2013-01-03T18:08:29.976+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12605611/comment/13547616","id":"13547616","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=acmurthy","name":"acmurthy","key":"acmurthy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun C Murthy","active":true,"timeZone":"America/Los_Angeles"},"body":"Kihwal? Todd?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=acmurthy","name":"acmurthy","key":"acmurthy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun C Murthy","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-01-09T04:18:59.723+0000","updated":"2013-01-09T04:18:59.723+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12605611/comment/13547627","id":"13547627","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sureshms","name":"sureshms","key":"sureshms","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10450","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10450","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10450","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10450"},"displayName":"Suresh Srinivas","active":true,"timeZone":"America/Los_Angeles"},"body":"Arun, I will review this in next two days.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sureshms","name":"sureshms","key":"sureshms","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10450","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10450","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10450","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10450"},"displayName":"Suresh Srinivas","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-01-09T04:33:00.542+0000","updated":"2013-01-09T04:33:00.542+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12605611/comment/13547634","id":"13547634","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=acmurthy","name":"acmurthy","key":"acmurthy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun C Murthy","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks [~sureshms]! I'm looking to wrap up 2.0.3-alpha asap.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=acmurthy","name":"acmurthy","key":"acmurthy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun C Murthy","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-01-09T04:52:25.470+0000","updated":"2013-01-09T04:52:25.470+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12605611/comment/13553148","id":"13553148","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sureshms","name":"sureshms","key":"sureshms","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10450","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10450","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10450","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10450"},"displayName":"Suresh Srinivas","active":true,"timeZone":"America/Los_Angeles"},"body":"Arun, I am removing the Blocker based on the input from Todd and Nicholas in the above comments. However, I have started reviewing this - so lets try to get this in 2.0.3-alpha.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sureshms","name":"sureshms","key":"sureshms","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10450","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10450","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10450","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10450"},"displayName":"Suresh Srinivas","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-01-14T21:37:17.010+0000","updated":"2013-01-14T21:37:17.010+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12605611/comment/13553193","id":"13553193","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sureshms","name":"sureshms","key":"sureshms","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10450","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10450","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10450","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10450"},"displayName":"Suresh Srinivas","active":true,"timeZone":"America/Los_Angeles"},"body":"Kihwal, here is how I understand the new behavior. Correct me if I am wrong. In the following scenarios, client is writing in a pipeline to datanodes d1, d2 and d3. At each point in the pipeline the data is marked as corrupt or not.\n\nclient(not corrupt) d1(not corrupt) d2(not corrupt) d3(corrupt)\n* d3 detects corrupt and reports CHECKSUM_ERROR ACK to d2\n* d2 does not verify checksum and hence status is SUCCESS, but receives CHECKSUM_ERROR and shutsdown\n* d1 does not verify checksum. Its status is SUCCESS + MIRROR_ERROR.\n\nOnly d1 is considered to be valid copy even though d2 may not be corrupt.\n\nclient(not corrupt) d1(not corrupt) d2(corrupt) d3(corrupt)\n* d3 detects corrupt and reports CHECKSUM_ERROR ACK to d2\n* d2 does not verify checksum and hence status is SUCCESS, but receives CHECKSUM_ERROR and shutsdown\n* d1 does not verify checksum. Its status is SUCCESS + MIRROR_ERROR.\n\nOnly d1 is considered to be valid copy.\n\nclient(not corrupt) d1(corrupt) d2(corrupt) d3(corrupt)\n* d3 detects corrupt and reports CHECKSUM_ERROR ACK to d2\n* d2 does not verify checksum and hence status is SUCCESS, but receives CHECKSUM_ERROR and shutsdown\n* _d1 does not verify checksum. Its status is SUCCESS + MIRROR_ERROR._\n\nd1 is still considered a valid coyp. Is this correct?\n\nclient(corrupt) d1(corrupt) d2(corrupt) d3(corrupt)\n* d3 detects corrupt and reports CHECKSUM_ERROR ACK to d2\n* d2 does not verify checksum and hence status is SUCCESS, but receives CHECKSUM_ERROR and shutsdown\n* d1 does not verify checksum. Its status is SUCCESS + MIRROR_ERROR.\n\nd1 is still considered a valid copy.\n\nIn all the above cases whether a node detects checksum error or the downstream detects checksum error the results appears the same to the upstream nodes (as mirror error). Is that what you intended?\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sureshms","name":"sureshms","key":"sureshms","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10450","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10450","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10450","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10450"},"displayName":"Suresh Srinivas","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-01-14T22:15:39.816+0000","updated":"2013-01-14T22:17:48.266+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12605611/comment/13553370","id":"13553370","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sureshms","name":"sureshms","key":"sureshms","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10450","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10450","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10450","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10450"},"displayName":"Suresh Srinivas","active":true,"timeZone":"America/Los_Angeles"},"body":"Had an offline conversation with Kihwal. Here is one of the above scenarios in more detail (thanks Kihwal for explaining the current behavior).\n\nClient(not corrupt) d1(not corrupt) d2(not corrupt) d3(corrupt), where d3 for some reason sees only corrupt data.\n* d3 detects corruption and reports CHECKSUM_ERROR ACK to d2. Packet is not written to the disk on d3.\n* d2 does not verify checksum and hence status is SUCCESS, but receives CHECKSUM_ERROR and shutsdown\n* d1 does not verify checksum. Its status is {SUCCESS, MIRROR_ERROR}\n* client establishes the pipeline with d1 and d3 and sends the packet again.\n* d3 detects corruption again and reports CHECKSUM_ERROR ACK to d1. Packet is not written to the disk on d3.\n* d1 does not verify checksum and hence status is SUCCESS, but receives CHECKSUM_ERROR and shutsdown\n* client establishes the pipeline with d3 and sends the packet again.\n* d3 detects corruption again and reports CHECKSUM_ERROR ACK to d1. Packet is not written to the disk on d3.\n* Client fails to write the packet and abandons writing the file? \n\nThe current behavior picks the node that sees corruption (or is corrupting the data) repeatedly in pipeline recovery (d3 above). Also the node that did not see corruption gets dropped from the pipeline. If a datanode performs checksum verification when it gets a down stream datanode reporting checksum error should avoid this. With this, new recovered pipleline will recover the pipeline up to the point of corruption in the pipeline.\n\nKihwal, add comments if I missed some thing.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sureshms","name":"sureshms","key":"sureshms","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10450","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10450","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10450","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10450"},"displayName":"Suresh Srinivas","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-01-15T01:13:56.039+0000","updated":"2013-01-15T01:13:56.039+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12605611/comment/13593583","id":"13593583","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"body":"Sorry for getting back to this so late and thank you Suresh for the feedback.\n\nIt made me think more about the non-leaf nodes in a pipeline. If the leaf node disappears from the pipeline before reporting checksum error and recoverRbw() is done, we can end up with latent checksum error in the block. This is because datanodes won't discard already written data on pipeline recovery.  It looks like we have to make recoverRbw() to truncate blocks to the acked size to be really safe.\n\nAlso, client should give up after certain number of pipeline reconstructions for the same block.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"created":"2013-03-05T17:00:10.680+0000","updated":"2013-03-05T17:00:10.680+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12605611/comment/13595134","id":"13595134","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"body":"The new patch forces datanodes to truncate the block being recovered to the acked length.  Since the nodes in the middle of write pipeline does not perform checksum verification and writes data to disk before getting ack back from downstream, the unacked portion can contain corrupt data. If the last node simply disappears before reporting a checksum error up, the current pipeline recovery mechanism can overlook the corruption in written data.\n\nSince this truncation discards potentially corrupt portion of block, we do not need any explicit checksum re-verification on checksum error.\n\nAnother new feature added to the latest patch is to terminate hdfs client when pipeline recovery is attempted for more than 5 times while writing the same data packet. This likely indicates the source data is corrupt.  In a very small cluster, clients may run out of datanodes and fail before retrying 5 times.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"created":"2013-03-06T21:23:29.287+0000","updated":"2013-03-06T21:23:29.287+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12605611/comment/13595228","id":"13595228","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:green}+1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12572398/hdfs-3875.patch.txt\n  against trunk revision .\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.\n\n    {color:green}+1 tests included appear to have a timeout.{color}\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.\n\n    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/4044//testReport/\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/4044//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2013-03-06T22:46:37.420+0000","updated":"2013-03-06T22:46:37.420+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12605611/comment/13659229","id":"13659229","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lohit","name":"lohit","key":"lohit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Lohit Vijayarenu","active":true,"timeZone":"America/Los_Angeles"},"body":"Could this be targeted for 2.0.5 release? We are seeing this exact same issue on one of our clusters. We are running hadoop-2.0.3-alpha release. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lohit","name":"lohit","key":"lohit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Lohit Vijayarenu","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-05-16T05:06:13.491+0000","updated":"2013-05-16T05:06:13.491+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12605611/comment/13661044","id":"13661044","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tgraves","name":"tgraves","key":"tgraves","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Thomas Graves","active":true,"timeZone":"America/Chicago"},"body":"Suresh, Todd,  Any comments on the latest patch?  I am hoping to get this committed soon for 23.8","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tgraves","name":"tgraves","key":"tgraves","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Thomas Graves","active":true,"timeZone":"America/Chicago"},"created":"2013-05-17T21:00:29.942+0000","updated":"2013-05-17T21:00:29.942+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12605611/comment/13661050","id":"13661050","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sureshms","name":"sureshms","key":"sureshms","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10450","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10450","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10450","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10450"},"displayName":"Suresh Srinivas","active":true,"timeZone":"America/Los_Angeles"},"body":"Sorry, I have been meaning to look at this. But have not been able to spend time. Will review before the end of the day. \n\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sureshms","name":"sureshms","key":"sureshms","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10450","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10450","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10450","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10450"},"displayName":"Suresh Srinivas","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-05-17T21:05:15.626+0000","updated":"2013-05-17T21:05:15.626+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12605611/comment/13661161","id":"13661161","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sureshms","name":"sureshms","key":"sureshms","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10450","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10450","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10450","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10450"},"displayName":"Suresh Srinivas","active":true,"timeZone":"America/Los_Angeles"},"body":"[~kihwal] the new solutions looks much better. Nice work!\n\nSome minor comments. +1 with those addressed:\n# DFSOutputStream.java\n#* Initialize lastAckedSeqnoBeforeFailure to appropriate value. lastAckedSeqNo is initialized to -1.\n#* Change info log, print warn? Instead of \"Already tried 5 times\" -> \"Already retried 5 times\", given total attempts are 6 and retries are 5.\n# DFSClientFaultInjecto#uncorruptPacket() - does it need to throw IOException?\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sureshms","name":"sureshms","key":"sureshms","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10450","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10450","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10450","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10450"},"displayName":"Suresh Srinivas","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-05-17T23:49:22.156+0000","updated":"2013-05-17T23:49:22.156+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12605611/comment/13662016","id":"13662016","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"body":"Thanks for the review, Suresh. The latest patch addresses all review comments.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"created":"2013-05-20T14:07:19.309+0000","updated":"2013-05-20T14:07:19.309+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12605611/comment/13662098","id":"13662098","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:green}+1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12583835/hdfs-3875.patch.txt\n  against trunk revision .\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.\n\n    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/4416//testReport/\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/4416//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2013-05-20T15:59:07.359+0000","updated":"2013-05-20T15:59:07.359+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12605611/comment/13662120","id":"13662120","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sureshms","name":"sureshms","key":"sureshms","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10450","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10450","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10450","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10450"},"displayName":"Suresh Srinivas","active":true,"timeZone":"America/Los_Angeles"},"body":"+1 for the patch\n\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sureshms","name":"sureshms","key":"sureshms","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10450","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10450","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10450","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10450"},"displayName":"Suresh Srinivas","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-05-20T16:35:14.715+0000","updated":"2013-05-20T16:35:14.715+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12605611/comment/13662144","id":"13662144","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"Sorry it took me some time to get to this. A couple small questions below:\n\n{code}\n+              // Wait until the responder sends back the response\n+              // and interrupt this thread.\n+              Thread.sleep(3000);\n{code}\nCan you explain this sleep here a little further? The assumption is that the responder will come back and interrupt the streamer? Why do we need to wait instead of just bailing out immediately with the IOE? Will this cause a 3-second delay in re-establishing the pipeline again?\n\n----\n{code}\n+        // If the mirror has reported that it received a corrupt packet,\n+        // do self-destruct to mark myself bad, instead of making the \n+        // mirror node bad. The mirror is guaranteed to be good without\n+        // corrupt data on disk.\n{code}\n\nWhat if the issue is on the receiving NIC of the downstream node? In this case, it would be kept around in the next pipeline and likely cause an exception again, right?\n\n----\n{code}\n+      // corrupt the date for testing.\n{code}\ntypo: date","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2013-05-20T16:54:39.677+0000","updated":"2013-05-20T16:54:39.677+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12605611/comment/13662214","id":"13662214","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"body":"bq. Can you explain this sleep here a little further? The assumption is that the responder will come back and interrupt the streamer? Why do we need to wait instead of just bailing out immediately with the IOE? Will this cause a 3-second delay in re-establishing the pipeline again?\n\nThis gives the responder time to send the checksum error back upstream, so that the upstream node can blow up and exclude itself from the pipeline. This may not be always ideal since there can be many different failure modes, but if anything needs to be eliminated without knowing the cause, the source seems to be a better candidate than the sink who actually verifies checksum.\n\nUnless there is network issue in sending ACKs, responder will immediately terminate and interrupt the main writer thread, so the thread won't stay up. Even if the thread stays up for some reason, recoverRbw() during pipeline recovery will interrupt the thread, so there won't be 3 second delay.\n\nIf the last node in a pipeline has a faulty NIC, two upstream nodes will be eliminated (in 3 replica case) and after adding a new dn to the end of pipeline, the faulty node will be removed. Issues on intermediate nodes will be handled in less number of iterations and the worst case will be when data is corrupt in DFSOutputStream, which will be detected after hitting the maximum number of retries. There will be no recovery in this case.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"created":"2013-05-20T17:57:34.363+0000","updated":"2013-05-20T17:57:34.363+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12605611/comment/13662294","id":"13662294","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"body":"The BlockReceiver in branch-2 seems to be in between 0.23 and trunk. Adding patch for branch-2 as well.  The new trunk patch corrects the typo in the comment.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"created":"2013-05-20T19:11:34.782+0000","updated":"2013-05-20T19:11:34.782+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12605611/comment/13662358","id":"13662358","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:green}+1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12583880/hdfs-3875.patch.txt\n  against trunk revision .\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.\n\n    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/4417//testReport/\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/4417//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2013-05-20T21:06:25.895+0000","updated":"2013-05-20T21:06:25.895+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12605611/comment/13662436","id":"13662436","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"OK, thanks for the explanations. +1 from me.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2013-05-20T23:02:58.573+0000","updated":"2013-05-20T23:02:58.573+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12605611/comment/13662979","id":"13662979","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"body":"I've committed this to trunk, branch-2 and branch-0.23.\nThanks everybody for the reviews.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"created":"2013-05-21T13:49:53.096+0000","updated":"2013-05-21T13:49:53.096+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12605611/comment/13662982","id":"13662982","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"Integrated in Hadoop-trunk-Commit #3771 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/3771/])\n    HDFS-3875. Issue handling checksum errors in write pipeline. Contributed by Kihwal Lee. (Revision 1484808)\n\n     Result = SUCCESS\nkihwal : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1484808\nFiles : \n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSClientFaultInjector.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestCrcCorruption.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2013-05-21T13:55:14.606+0000","updated":"2013-05-21T13:55:14.606+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12605611/comment/13663996","id":"13663996","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"Integrated in Hadoop-Yarn-trunk #217 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/217/])\n    HDFS-3875. Issue handling checksum errors in write pipeline. Contributed by Kihwal Lee. (Revision 1484808)\n\n     Result = FAILURE\nkihwal : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1484808\nFiles : \n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSClientFaultInjector.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestCrcCorruption.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2013-05-22T10:46:04.004+0000","updated":"2013-05-22T10:46:04.004+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12605611/comment/13664056","id":"13664056","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"Integrated in Hadoop-Hdfs-0.23-Build #615 (See [https://builds.apache.org/job/Hadoop-Hdfs-0.23-Build/615/])\n    HDFS-3875. Issue handling checksum errors in write pipeline. Contributed by Kihwal Lee. (Revision 1484811)\n\n     Result = SUCCESS\nkihwal : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1484811\nFiles : \n* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt\n* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSClientFaultInjector.java\n* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java\n* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java\n* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/FSDataset.java\n* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestCrcCorruption.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2013-05-22T12:40:10.813+0000","updated":"2013-05-22T12:40:10.813+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12605611/comment/13664074","id":"13664074","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"Integrated in Hadoop-Hdfs-trunk #1406 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1406/])\n    HDFS-3875. Issue handling checksum errors in write pipeline. Contributed by Kihwal Lee. (Revision 1484808)\n\n     Result = FAILURE\nkihwal : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1484808\nFiles : \n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSClientFaultInjector.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestCrcCorruption.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2013-05-22T13:02:40.198+0000","updated":"2013-05-22T13:02:40.198+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12605611/comment/13664125","id":"13664125","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"Integrated in Hadoop-Mapreduce-trunk #1433 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1433/])\n    HDFS-3875. Issue handling checksum errors in write pipeline. Contributed by Kihwal Lee. (Revision 1484808)\n\n     Result = SUCCESS\nkihwal : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1484808\nFiles : \n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSClientFaultInjector.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestCrcCorruption.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2013-05-22T14:07:25.938+0000","updated":"2013-05-22T14:07:25.938+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12605611/comment/14107107","id":"14107107","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"HI [~kihwal],\n\nThanks for your earlier work for this issue. We are seeing a similar problem like this though we have this patch. One question about this patch:\n\nAssuming we have a pipeline of three DNs, DN1, DN2, and DN3. DN3 detects a checksum error, and reports back to  DN2. DN2 decided to truncate its replica to the acknowledged size by calling {{static private void truncateBlock(File blockFile, File metaFile,}} which reads the data from the local replica file, calculate the checksum for the length to be truncated to, and write the checksum back to the meta file. \n\nMy question is, when writing back the checksum to the meta file, this method doesn't check against an already computed checksum to see if it matches. However, DN3 does check its computed checksum against the checksum sent from upstream of the pipeline when reporting the checksum mismatch. If DN2 got something wrong in the truncateBlock method (say, for some reason the existing data is corrupted), then DN2 has incorrect cheksum and it's not aware of it. Then later when we try to recover the pipeline, and use DN2 replica as the source, the new DN that receives data from the DN2 will always find checksum error.\n\nThis is my speculation so far. Do you think this is a possibility? \n\nThanks a lot.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-22T17:11:50.757+0000","updated":"2014-08-22T17:11:50.757+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12605611/comment/14108798","id":"14108798","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi [~kihwal], I filed HDFS-6937 to track the similar issue I'm seeing, so we can continue the discussion there. Thanks.\n\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-08-25T06:19:28.705+0000","updated":"2014-08-25T06:19:28.705+0000"}],"maxResults":64,"total":64,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-3875/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i0jx93:"}}