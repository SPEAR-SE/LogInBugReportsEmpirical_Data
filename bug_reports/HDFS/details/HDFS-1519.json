{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12491572","self":"https://issues.apache.org/jira/rest/api/2/issue/12491572","key":"HDFS-1519","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/2","id":"2","description":"The problem described is an issue which will never be fixed.","name":"Won't Fix"},"customfield_12312322":null,"customfield_12310220":"2010-11-30T06:14:15.375+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Thu Mar 17 16:22:38 UTC 2016","customfield_12310420":"15329","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_36568640_*|*_4_*:*_1_*:*_167099023011_*|*_5_*:*_2_*:*_35080294","customfield_12312321":null,"resolutiondate":"2016-03-17T16:22:38.695+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-1519/watchers","watchCount":2,"isWatching":false},"created":"2010-11-29T20:04:46.828+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12314046","id":"12314046","description":"","name":"0.21.0","archived":false,"released":true,"releaseDate":"2010-08-23"}],"issuelinks":[{"id":"12336186","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12336186","type":{"id":"12310010","name":"Incorporates","inward":"is part of","outward":"incorporates","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/12310010"},"inwardIssue":{"id":"12468403","key":"HADOOP-6846","self":"https://issues.apache.org/jira/rest/api/2/issue/12468403","fields":{"summary":"Scripts for building Hadoop 0.22.0 release","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/3","id":"3","description":"A task that needs to be done.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype","name":"Task","subtask":false,"avatarId":21148}}}}],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2016-03-17T16:22:38.771+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12312925","id":"12312925","name":"build"}],"timeoriginalestimate":null,"description":"HADOOP_DIR/hdfs$ ant ivy-resolve-common\nBuildfile: build.xml\n\nivy-download:\n      [get] Getting: http://repo2.maven.org/maven2/org/apache/ivy/ivy/2.1.0/ivy-2.1.0.jar\n      [get] To: /usr/products/hadoop/v0_21_0/ANY/hdfs/ivy/ivy-2.1.0.jar\n      [get] Not modified - so not downloaded\n\nivy-init-dirs:\n\nivy-probe-antlib:\n\nivy-init-antlib:\n\nivy-init:\n[ivy:configure] :: Ivy 2.1.0 - 20090925235825 :: http://ant.apache.org/ivy/ ::\n[ivy:configure] :: loading settings :: file = /usr/products/hadoop/v0_21_0/ANY/hdfs/ivy/ivysettings.xml\n\nivy-resolve-common:\n[ivy:resolve] \n[ivy:resolve] :: problems summary ::\n[ivy:resolve] :::: WARNINGS\n[ivy:resolve] \t\tmodule not found: org.apache.hadoop#hadoop-common;0.21.0\n[ivy:resolve] \t==== apache-snapshot: tried\n[ivy:resolve] \t  https://repository.apache.org/content/repositories/snapshots/org/apache/hadoop/hadoop-common/0.21.0/hadoop-common-0.21.0.pom\n[ivy:resolve] \t  -- artifact org.apache.hadoop#hadoop-common;0.21.0!hadoop-common.jar:\n[ivy:resolve] \t  https://repository.apache.org/content/repositories/snapshots/org/apache/hadoop/hadoop-common/0.21.0/hadoop-common-0.21.0.jar\n[ivy:resolve] \t==== maven2: tried\n[ivy:resolve] \t  http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-common/0.21.0/hadoop-common-0.21.0.pom\n[ivy:resolve] \t  -- artifact org.apache.hadoop#hadoop-common;0.21.0!hadoop-common.jar:\n[ivy:resolve] \t  http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-common/0.21.0/hadoop-common-0.21.0.jar\n[ivy:resolve] \t\t::::::::::::::::::::::::::::::::::::::::::::::\n[ivy:resolve] \t\t::          UNRESOLVED DEPENDENCIES         ::\n[ivy:resolve] \t\t::::::::::::::::::::::::::::::::::::::::::::::\n[ivy:resolve] \t\t:: org.apache.hadoop#hadoop-common;0.21.0: not found\n[ivy:resolve] \t\t::::::::::::::::::::::::::::::::::::::::::::::\n[ivy:resolve] \n[ivy:resolve] :: USE VERBOSE OR DEBUG MESSAGE LEVEL FOR MORE DETAILS\n\nBUILD FAILED\n/usr/products/hadoop/v0_21_0/ANY/hdfs/build.xml:1549: impossible to resolve dependencies:\n\tresolve failed - see output for details\n\nTotal time: 3 seconds\n","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"113604","customfield_12312823":null,"summary":"HDFS build is broken, ivy-resolve-common does not find hadoop-common","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jsw-osu","name":"jsw-osu","key":"jsw-osu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jon Wilson","active":true,"timeZone":"Etc/UTC"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jsw-osu","name":"jsw-osu","key":"jsw-osu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jon Wilson","active":true,"timeZone":"Etc/UTC"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":"openSUSE 11.1, Linux roisin 2.6.27.48-0.2-default #1 SMP 2010-07-29 20:06:52 +0200 x86_64 x86_64 x86_64 GNU/Linux","customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12491572/comment/12965110","id":"12965110","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cos","name":"cos","key":"cos","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cos&avatarId=16741","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cos&avatarId=16741","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cos&avatarId=16741","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cos&avatarId=16741"},"displayName":"Konstantin Boudnik","active":true,"timeZone":"America/Los_Angeles"},"body":"Usually it is an indication of:\na) temp. service interruption of snapshop repo's server\nb) issues with local Ivy cache.\n\nI have cleaned local cache and ran 'ant clean compile' - build was successful:\n\n{noformat}\n[ivy:resolve] downloading https://repository.apache.org/content/repositories/snapshots/org/apache/hadoop/hadoop-common/0.21.0-SNAPSHOT/hadoop-common-0.21.0-20101120.093342-38.jar ...\n[ivy:resolve] ......................................................................................................................................................................................... (1259kB)\n[ivy:resolve] .. (0kB)\n[ivy:resolve]   [SUCCESSFUL ] org.apache.hadoop#hadoop-common;0.21.0-SNAPSHOT!hadoop-common.jar (3761ms)\n{noformat}\n\nPlease make sure that the issue you see isn't caused by some local reasons and re-open this bug if you still see the issue.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cos","name":"cos","key":"cos","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cos&avatarId=16741","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cos&avatarId=16741","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cos&avatarId=16741","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cos&avatarId=16741"},"displayName":"Konstantin Boudnik","active":true,"timeZone":"America/Los_Angeles"},"created":"2010-11-30T06:14:15.375+0000","updated":"2010-11-30T06:14:15.375+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12491572/comment/12965262","id":"12965262","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jsw-osu","name":"jsw-osu","key":"jsw-osu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jon Wilson","active":true,"timeZone":"Etc/UTC"},"body":"$ rm -r ~/.ivy2\nHADOOP_DIR/hdfs$ ant clean compile\n-- snip --\n[ivy:resolve] :: problems summary ::\n[ivy:resolve] :::: WARNINGS\n[ivy:resolve] \t\tmodule not found: org.apache.hadoop#hadoop-common;0.21.0\n[ivy:resolve] \t==== apache-snapshot: tried\n[ivy:resolve] \t  https://repository.apache.org/content/repositories/snapshots/org/apache/hadoop/hadoop-common/0.21.0/hadoop-common-0.21.0.pom\n[ivy:resolve] \t  -- artifact org.apache.hadoop#hadoop-common;0.21.0!hadoop-common.jar:\n[ivy:resolve] \t  https://repository.apache.org/content/repositories/snapshots/org/apache/hadoop/hadoop-common/0.21.0/hadoop-common-0.21.0.jar\n[ivy:resolve] \t==== maven2: tried\n[ivy:resolve] \t  http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-common/0.21.0/hadoop-common-0.21.0.pom\n[ivy:resolve] \t  -- artifact org.apache.hadoop#hadoop-common;0.21.0!hadoop-common.jar:\n[ivy:resolve] \t  http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-common/0.21.0/hadoop-common-0.21.0.jar\n[ivy:resolve] \t\t::::::::::::::::::::::::::::::::::::::::::::::\n[ivy:resolve] \t\t::          UNRESOLVED DEPENDENCIES         ::\n[ivy:resolve] \t\t::::::::::::::::::::::::::::::::::::::::::::::\n[ivy:resolve] \t\t:: org.apache.hadoop#hadoop-common;0.21.0: not found\n[ivy:resolve] \t\t::::::::::::::::::::::::::::::::::::::::::::::\n[ivy:resolve] \n[ivy:resolve] :: USE VERBOSE OR DEBUG MESSAGE LEVEL FOR MORE DETAILS\n\nBUILD FAILED\n/usr/products/hadoop/v0_21_0/ANY/hdfs/build.xml:1549: impossible to resolve dependencies:\n\tresolve failed - see output for details\n\nTotal time: 1 minute 45 seconds\n\n\nI still see the same problem.  It looks like somehow the URL template is not correct, as the attempted URL is\nhttps://repository.apache.org/content/repositories/snapshots/org/apache/hadoop/hadoop-common/0.21.0/hadoop-common-0.21.0.jar\nrather than\nhttps://repository.apache.org/content/repositories/snapshots/org/apache/hadoop/hadoop-common/0.21.0-SNAPSHOT/hadoop-common-0.21.0-20101120.093342-38.jar\n\nI've attempted to look around in the ivy xml files, but with no ivy experience, I couldn't figure out just what was constructing this URL.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jsw-osu","name":"jsw-osu","key":"jsw-osu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jon Wilson","active":true,"timeZone":"Etc/UTC"},"created":"2010-11-30T15:58:55.713+0000","updated":"2010-11-30T15:58:55.713+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12491572/comment/12965285","id":"12965285","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cos","name":"cos","key":"cos","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cos&avatarId=16741","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cos&avatarId=16741","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cos&avatarId=16741","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cos&avatarId=16741"},"displayName":"Konstantin Boudnik","active":true,"timeZone":"America/Los_Angeles"},"body":"What workspace do you use (e.g. what .svn/entries says at the top) and what is the revision in your workspace?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cos","name":"cos","key":"cos","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cos&avatarId=16741","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cos&avatarId=16741","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cos&avatarId=16741","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cos&avatarId=16741"},"displayName":"Konstantin Boudnik","active":true,"timeZone":"America/Los_Angeles"},"created":"2010-11-30T16:49:15.376+0000","updated":"2010-11-30T16:49:15.376+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12491572/comment/12965322","id":"12965322","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jsw-osu","name":"jsw-osu","key":"jsw-osu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jon Wilson","active":true,"timeZone":"Etc/UTC"},"body":"I downloaded the tarball from http://mirror.nyi.net/apache//hadoop/core/hadoop-0.21.0/hadoop-0.21.0.tar.gz (or possibly some other mirror...), so I don't have a .svn directory.\nI unpacked the tarball into /usr/products/hadoop/v0_21_0/ANY/ (a sort of /opt type space), as user horton, and set the environment variable HADOOP_DIR to /usr/products/hadoop/v0_21_0/ANY/.  I am running ant from $HADOOP_DIR/hdfs as user horton.\nWhen I run ant from $HADOOP_DIR/mapred, I see the same sort of problems.  When I run ant from $HADOOP_DIR/common, I do not encounter any problems.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jsw-osu","name":"jsw-osu","key":"jsw-osu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jon Wilson","active":true,"timeZone":"Etc/UTC"},"created":"2010-11-30T18:15:17.640+0000","updated":"2010-11-30T18:15:17.640+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12491572/comment/12965346","id":"12965346","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cos","name":"cos","key":"cos","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cos&avatarId=16741","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cos&avatarId=16741","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cos&avatarId=16741","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cos&avatarId=16741"},"displayName":"Konstantin Boudnik","active":true,"timeZone":"America/Los_Angeles"},"body":"The tarball you have downloaded is the release tarball. Once again, why do you need to run ant on a released version? You might have a perfectly legit reason for this, I just don't know your intentions. I am not sure if release tarballs were even suitable for running builds on them.\n\nIf you want to build Hadoop for yourself you can take a look [this link|http://wiki.apache.org/hadoop/HowToContribute]","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cos","name":"cos","key":"cos","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cos&avatarId=16741","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cos&avatarId=16741","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cos&avatarId=16741","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cos&avatarId=16741"},"displayName":"Konstantin Boudnik","active":true,"timeZone":"America/Los_Angeles"},"created":"2010-11-30T19:05:14.976+0000","updated":"2010-11-30T19:05:14.976+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12491572/comment/12965387","id":"12965387","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jsw-osu","name":"jsw-osu","key":"jsw-osu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jon Wilson","active":true,"timeZone":"Etc/UTC"},"body":"I want to build fuse-dfs, which requires libhdfs.  Do I need to get an subversion checkout to run ant instead of using a release tarball?  Perhaps libhdfs and fuse-dfs are already built in the release tarball?  Thanks for the help so far.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jsw-osu","name":"jsw-osu","key":"jsw-osu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jon Wilson","active":true,"timeZone":"Etc/UTC"},"created":"2010-11-30T19:52:03.354+0000","updated":"2010-11-30T19:52:03.354+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12491572/comment/12965407","id":"12965407","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cos","name":"cos","key":"cos","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cos&avatarId=16741","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cos&avatarId=16741","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cos&avatarId=16741","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cos&avatarId=16741"},"displayName":"Konstantin Boudnik","active":true,"timeZone":"America/Los_Angeles"},"body":"I am not certain if the release tar ball has fuse-dfs included in it (check for yourself), but I am sure you should be able to build from the source code according to the a couple of simple steps in {{src/contrib/fuse-dfs/README}}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cos","name":"cos","key":"cos","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cos&avatarId=16741","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cos&avatarId=16741","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cos&avatarId=16741","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cos&avatarId=16741"},"displayName":"Konstantin Boudnik","active":true,"timeZone":"America/Los_Angeles"},"created":"2010-11-30T20:24:20.973+0000","updated":"2010-11-30T20:24:20.973+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12491572/comment/12965415","id":"12965415","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jsw-osu","name":"jsw-osu","key":"jsw-osu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jon Wilson","active":true,"timeZone":"Etc/UTC"},"body":"I've been following the instructions at http://wiki.apache.org/hadoop/MountableHDFS, which worked (with minor modifications) with the release tarball for 0.20.2.  However, my application (ROOT: http://root.cern.ch) opens files with mode O_RDWR (it doesn't do anything that hdfs doesn't support with them, though), so I needed the later version with HDFS-861 fixed.\n\nI did a bit of poking, and it looks like all the code for fuse-dfs and for libhdfs is present, but that libhdfs is not built in the release tarball.  So I do need to build libhdfs.  Is ant the recommended way to do this?  Looking at http://wiki.apache.org/hadoop/LibHDFS, perhaps I should just use make instead.  I'll try that, and report back.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jsw-osu","name":"jsw-osu","key":"jsw-osu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jon Wilson","active":true,"timeZone":"Etc/UTC"},"created":"2010-11-30T20:37:11.250+0000","updated":"2010-11-30T20:37:11.250+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12491572/comment/12965433","id":"12965433","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cos","name":"cos","key":"cos","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cos&avatarId=16741","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cos&avatarId=16741","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cos&avatarId=16741","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cos&avatarId=16741"},"displayName":"Konstantin Boudnik","active":true,"timeZone":"America/Los_Angeles"},"body":"It isn't like ant is the recommended way to build libhdfs. It might be simpler to do though. Basically all you need (if you have source tree handy) is to run {{ant compile-contrib -Dcompile.c++=yes -Dlibhdfs=yes}} and after a short while you'll find the library binaries under {{build/c++}}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cos","name":"cos","key":"cos","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cos&avatarId=16741","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cos&avatarId=16741","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cos&avatarId=16741","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cos&avatarId=16741"},"displayName":"Konstantin Boudnik","active":true,"timeZone":"America/Los_Angeles"},"created":"2010-11-30T20:56:22.113+0000","updated":"2010-11-30T20:56:22.113+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12491572/comment/12965724","id":"12965724","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jsw-osu","name":"jsw-osu","key":"jsw-osu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jon Wilson","active":true,"timeZone":"Etc/UTC"},"body":"I did find that both libhdfs and fuse-dfs are built in the release tarball.  Luckily, they do appear to be built for the correct architecture for me, so things are well for me.  My issues are resolved by this, but perhaps the JIRA issue should remain open, since ant still cannot be run on a release tarball.\n\nThe instructions on the wiki at MountableHDFS and libHDFS should be updated to note that these are built in the release tarball, or ant in the release should be fixed (or more likely both).","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jsw-osu","name":"jsw-osu","key":"jsw-osu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jon Wilson","active":true,"timeZone":"Etc/UTC"},"created":"2010-12-01T16:06:26.922+0000","updated":"2010-12-01T16:06:26.922+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12491572/comment/12965811","id":"12965811","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cos","name":"cos","key":"cos","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cos&avatarId=16741","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cos&avatarId=16741","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cos&avatarId=16741","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cos&avatarId=16741"},"displayName":"Konstantin Boudnik","active":true,"timeZone":"America/Los_Angeles"},"body":"Tom White (the release manager for 0.21) has pointed out that post-split releases aren't easy to build together (exactly because they are split in three different parts). \n\nHowever, this dependency issue seems like something else however related to the overall problem.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cos","name":"cos","key":"cos","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cos&avatarId=16741","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cos&avatarId=16741","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cos&avatarId=16741","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cos&avatarId=16741"},"displayName":"Konstantin Boudnik","active":true,"timeZone":"America/Los_Angeles"},"created":"2010-12-01T19:33:32.800+0000","updated":"2010-12-01T19:33:32.800+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12491572/comment/12995421","id":"12995421","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tvald","name":"tvald","key":"tvald","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Tony Valderrama","active":true,"timeZone":"Etc/UTC"},"body":"I was building thriftfs, and got all of hdfs to rebuild with the following modifications.  This was mostly just bumping around in config files until it worked, so somebody who knows the build system should make an actual patch.  I also had to manually run 'mkdir hdfs/lib' because ant was complaining that it didn't exist.\n\n{noformat}\nhdfs/ivy.xml\n---     <dependency org=\"org.apache.hadoop\" name=\"hadoop-common\" rev=\"${hadoop-common.version}\" conf=\"common->default\"/>\n+++     <dependency org=\"org.apache.hadoop\" name=\"hadoop-common\" rev=\"${hadoop-common.version}-SNAPSHOT\" conf=\"common->default\"/>\n{noformat}\n\n{noformat}\nhdfs/src/contrib/hdfsproxy/ivy.xml\n       <dependency org=\"org.apache.hadoop\"\n         name=\"hadoop-common\"\n---      rev=\"${hadoop-common.version}\"\n+++      rev=\"${hadoop-common.version}-SNAPSHOT\"\n         conf=\"common->default\"/>\n       <dependency org=\"org.apache.hadoop\"\n         name=\"hadoop-common-test\"\n---      rev=\"${hadoop-common.version}\"\n+++      rev=\"${hadoop-common.version}-SNAPSHOT\"\n         conf=\"common->default\"/>\n{noformat}\n\n\n{noformat}\nhdfs/src/contrib/thriftfs/ivy.xml\n       <dependency org=\"org.apache.hadoop\"\n         name=\"hadoop-common\"\n---      rev=\"${hadoop-common.version}\"\n+++      rev=\"${hadoop-common.version}-SNAPSHOT\"\n         conf=\"common->default\"/>\n{noformat}\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tvald","name":"tvald","key":"tvald","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Tony Valderrama","active":true,"timeZone":"Etc/UTC"},"created":"2011-02-16T18:06:29.688+0000","updated":"2011-02-16T18:06:29.688+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12491572/comment/12998196","id":"12998196","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yanbo","name":"yanbo","key":"yanbo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"YBL","active":true,"timeZone":"Etc/UTC"},"body":"I was building hdfs checked out from svn and met the same problem.\nIs it the repository has not been updated?\nHow to resolve this problem?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yanbo","name":"yanbo","key":"yanbo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"YBL","active":true,"timeZone":"Etc/UTC"},"created":"2011-02-23T07:16:39.246+0000","updated":"2011-02-23T07:16:39.246+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12491572/comment/13041068","id":"13041068","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=weilu","name":"weilu","key":"weilu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wei Lu","active":true,"timeZone":"Etc/UTC"},"body":"@Tony Valderrama \n+1 I agree. I had to do the same. And your config changes worked for me.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=weilu","name":"weilu","key":"weilu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wei Lu","active":true,"timeZone":"Etc/UTC"},"created":"2011-05-30T09:51:14.893+0000","updated":"2011-05-30T09:51:14.893+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12491572/comment/15199827","id":"15199827","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=aw","name":"aw","key":"aw","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=aw&avatarId=23681","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=aw&avatarId=23681","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=aw&avatarId=23681","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=aw&avatarId=23681"},"displayName":"Allen Wittenauer","active":true,"timeZone":"America/Tijuana"},"body":"Stale.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=aw","name":"aw","key":"aw","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=aw&avatarId=23681","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=aw&avatarId=23681","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=aw&avatarId=23681","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=aw&avatarId=23681"},"displayName":"Allen Wittenauer","active":true,"timeZone":"America/Tijuana"},"created":"2016-03-17T16:22:38.740+0000","updated":"2016-03-17T16:22:38.740+0000"}],"maxResults":15,"total":15,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-1519/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i0jsun:"}}