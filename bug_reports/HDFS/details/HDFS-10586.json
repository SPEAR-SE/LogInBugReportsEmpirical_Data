{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12980736","self":"https://issues.apache.org/jira/rest/api/2/issue/12980736","key":"HDFS-10586","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":"2016-07-25T11:46:02.392+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Wed Aug 03 11:29:01 UTC 2016","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-10586/watchers","watchCount":7,"isWatching":false},"created":"2016-06-20T07:55:04.134+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12335732","id":"12335732","description":"3.0.0-alpha1 release","name":"3.0.0-alpha1","archived":false,"released":true,"releaseDate":"2016-09-03"}],"issuelinks":[{"id":"12476167","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12476167","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"inwardIssue":{"id":"12992917","key":"HDFS-10697","self":"https://issues.apache.org/jira/rest/api/2/issue/12992917","fields":{"summary":"Erasure Code(6:3) can not work, using get fs shell when 2 datanode down","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}}],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2016-08-03T11:29:01.414+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12327961","id":"12327961","name":"erasure-coding"}],"timeoriginalestimate":null,"description":"The following is the steps to reproduce:\n\n1) hadoop fs -mkdir /ec\n2) set erasured code policy as \"6-3\"\n3) \"write\" data by : \n\ntime hadoop jar /opt/hadoop/hadoop-3.0.0-SNAPSHOT/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.0.0-SNAPSHOT.jar  TestDFSIO -D test.build.data=/ec -write -nrFiles 30 -fileSize 12288 -bufferSize 1073741824\n\n4) Manually down 3 nodes.  Kill the threads of  \"datanode\" and \"nodemanager\" in 3 DataNode.\n\n5) By using erasured code to \"read\" data by:\n\ntime hadoop jar /opt/hadoop/hadoop-3.0.0-SNAPSHOT/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.0.0-SNAPSHOT.jar  TestDFSIO -D test.build.data=/ec -read -nrFiles 30 -fileSize 12288 -bufferSize 1073741824\n\n\nthen the failure occurs and the exception is thrown as:\n\nINFO mapreduce.Job: Task Id : attempt_1465445965249_0008_m_000034_2, Status : FAILED\nError: java.io.IOException: 4 missing blocks, the stripe is: Offset=0, length=8388608, fetchedChunksNum=0, missingChunksNum=4\n\tat org.apache.hadoop.hdfs.DFSStripedInputStream$StripeReader.checkMissingBlocks(DFSStripedInputStream.java:614)\n\tat org.apache.hadoop.hdfs.DFSStripedInputStream$StripeReader.readParityChunks(DFSStripedInputStream.java:647)\n\tat org.apache.hadoop.hdfs.DFSStripedInputStream$StripeReader.readStripe(DFSStripedInputStream.java:762)\n\tat org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:316)\n\tat org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:450)\n\tat org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:941)\n\tat java.io.DataInputStream.read(DataInputStream.java:149)\n\tat org.apache.hadoop.fs.TestDFSIO$ReadMapper.doIO(TestDFSIO.java:531)\n\tat org.apache.hadoop.fs.TestDFSIO$ReadMapper.doIO(TestDFSIO.java:508)\n\tat org.apache.hadoop.fs.IOMapperBase.map(IOMapperBase.java:134)\n\tat org.apache.hadoop.fs.IOMapperBase.map(IOMapperBase.java:37)\n\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)\n\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:453)\n\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)\n\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:422)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1669)\n\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"Erasure Code misfunctions when 3 DataNode down","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gaoshbj","name":"gaoshbj","key":"gaoshbj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"gao shan","active":true,"timeZone":"Etc/UTC"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gaoshbj","name":"gaoshbj","key":"gaoshbj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"gao shan","active":true,"timeZone":"Etc/UTC"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":"9 DataNode and 1 NameNode,    Erasured code policy is set as \"6--3\",   When 3 DataNode down,  erasured code fails and an exception is thrown","customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":[{"self":"https://issues.apache.org/jira/rest/api/2/customFieldOption/10431","value":"Important","id":"10431"}],"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12980736/comment/15358715","id":"15358715","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gaoshbj","name":"gaoshbj","key":"gaoshbj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"gao shan","active":true,"timeZone":"Etc/UTC"},"body":"I check the log, find the following errors.  All the datanodes are alive, but what's the meaning of the WARN  \"Failed to find datanode \" ?   172.16.1.85 is the namenode,  The other IPs are for datanodes.\n\n2016-06-28 10:44:57,995 WARN org.apache.hadoop.net.NetworkTopology: Failed to find datanode (scope=\"\" excludedScope=\"/default-rack\").\n2016-06-28 10:44:57,996 WARN org.apache.hadoop.net.NetworkTopology: Failed to find datanode (scope=\"\" excludedScope=\"/default-rack\").\n2016-06-28 10:44:57,996 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073744759_7794, replicas=172.16.1.143:9866, 172.16.1.92:9866, 172.16.1.87:9866 for /tmp/hadoop-yarn/staging/root/.staging/job_1467124628054_0001/job.jar\n2016-06-28 10:44:58,233 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1467124628054_0001/job.jar is closed by DFSClient_NONMAPREDUCE_1881763906_1\n2016-06-28 10:44:58,239 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 3 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1467124628054_0001/job.jar\n2016-06-28 10:44:58,365 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 3 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1467124628054_0001/job.split\n2016-06-28 10:44:58,368 WARN org.apache.hadoop.net.NetworkTopology: Failed to find datanode (scope=\"\" excludedScope=\"/default-rack\").\n2016-06-28 10:44:58,368 WARN org.apache.hadoop.net.NetworkTopology: Failed to find datanode (scope=\"\" excludedScope=\"/default-rack\").\n2016-06-28 10:44:58,369 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073744760_7795, replicas=172.16.1.87:9866, 172.16.1.90:9866, 172.16.1.91:9866, 172.16.1.88:9866, 172.16.1.89:9866, 172.16.1.86:9866, 172.16.1.93:9866, 172.16.1.92:9866, 172.16.1.143:9866 for /tmp/hadoop-yarn/staging/root/.staging/job_1467124628054_0001/job.split\n2016-06-28 10:44:58,541 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1467124628054_0001/job.split is closed by DFSClient_NONMAPREDUCE_1881763906_1\n2016-06-28 10:44:58,548 WARN org.apache.hadoop.net.NetworkTopology: Failed to find datanode (scope=\"\" excludedScope=\"/default-rack\").\n2016-06-28 10:44:58,549 WARN org.apache.hadoop.net.NetworkTopology: Failed to find datanode (scope=\"\" excludedScope=\"/default-rack\").\n2016-06-28 10:44:58,549 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073744761_7796, replicas=172.16.1.93:9866, 172.16.1.88:9866, 172.16.1.143:9866 for /tmp/hadoop-yarn/staging/root/.staging/job_1467124628054_0001/job.splitmetainfo\n2016-06-28 10:44:58,632 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1467124628054_0001/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_1881763906_1\n2016-06-28 10:44:58,773 WARN org.apache.hadoop.net.NetworkTopology: Failed to find datanode (scope=\"\" excludedScope=\"/default-rack\").\n2016-06-28 10:44:58,773 WARN org.apache.hadoop.net.NetworkTopology: Failed to find datanode (scope=\"\" excludedScope=\"/default-rack\").\n2016-06-28 10:44:58,774 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073744762_7797, replicas=172.16.1.91:9866, 172.16.1.143:9866, 172.16.1.86:9866 for /tmp/hadoop-yarn/staging/root/.staging/job_1467124628054_0001/job.xml\n2016-06-28 10:44:58,857 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1467124628054_0001/job.xml is closed by DFSClient_NONMAPREDUCE_1881763906_1\n2016-06-28 10:45:06,285 WARN org.apache.hadoop.net.NetworkTopology: Failed to find datanode (scope=\"\" excludedScope=\"/default-rack\").\n2016-06-28 10:45:06,285 WARN org.apache.hadoop.net.NetworkTopology: Failed to find datanode (scope=\"\" excludedScope=\"/default-rack\").\n2016-06-28 10:45:06,285 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073744763_7798, replicas=172.16.1.90:9866, 172.16.1.86:9866, 172.16.1.91:9866 for /tmp/hadoop-yarn/staging/root/.staging/job_1467124628054_0001/job_1467124628054_0001_1_conf.xml\n2016-06-28 10:45:06,353 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1467124628054_0001/job_1467124628054_0001_1_conf.xml is closed by DFSClient_NONMAPREDUCE_2078921355_1\n2016-06-28 10:45:12,227 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 9 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy\n2016-06-28 10:45:12,228 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=9, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})\n2016-06-28 10:45:12,228 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 9 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}\n2016-06-28 10:45:12,228 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_-9223372036854736880_7799, replicas=172.16.1.90:9866, 172.16.1.87:9866, 172.16.1.93:9866, 172.16.1.86:9866, 172.16.1.88:9866, 172.16.1.143:9866, 172.16.1.92:9866, 172.16.1.89:9866 for /gaos/io_data/test_io_12\n2016-06-28 10:45:12,541 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: updatePipeline(blk_-9223372036854736880_7799, newGS=7800, newLength=393216, newNodes=[172.16.1.90:9866, 172.16.1.87:9866, 172.16.1.93:9866, 172.16.1.86:9866, 172.16.1.88:9866, 172.16.1.143:9866, 172.16.1.92:9866, 172.16.1.89:9866, null:0], client=DFSClient_attempt_1467124628054_0001_m_000002_0_1932721620_1)\n2016-06-28 10:45:12,542 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: updatePipeline(blk_-9223372036854736880_7799 => blk_-9223372036854736880_7800) success\n2016-06-28 10:45:14,660 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_-9223372036854736864_7801, replicas=172.16.1.92:9866, 172.16.1.93:9866, 172.16.1.86:9866, 172.16.1.143:9866, 172.16.1.91:9866, 172.16.1.87:9866, 172.16.1.89:9866, 172.16.1.90:9866, 172.16.1.88:9866 for /gaos/io_data/test_io_4\n2016-06-28 10:45:14,722 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_-9223372036854736848_7802, replicas=172.16.1.91:9866, 172.16.1.87:9866, 172.16.1.90:9866, 172.16.1.86:9866, 172.16.1.88:9866, 172.16.1.93:9866, 172.16.1.92:9866, 172.16.1.143:9866, 172.16.1.89:9866 for /gaos/io_data/test_io_8\n2016-06-28 10:45:14,749 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_-9223372036854736832_7803, replicas=172.16.1.86:9866, 172.16.1.93:9866, 172.16.1.89:9866, 172.16.1.92:9866, 172.16.1.143:9866, 172.16.1.90:9866, 172.16.1.87:9866, 172.16.1.91:9866, 172.16.1.88:9866 for /gaos/io_data/test_io_18\n............................\n\n\nAlso on the datanodes, ( e.g. 172.16.1.143),   there are some errors:,\n\njava.io.IOException: Premature EOF from inputStream\n\tat org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:204)\n\tat org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)\n\tat org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)\n\tat org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)\n\tat org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:522)\n\tat org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:923)\n\tat org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:846)\n\tat org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:171)\n\tat org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:105)\n\tat org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:289)\n\tat java.lang.Thread.run(Thread.java:745)\n2016-06-28 10:56:44,830 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-257845079-172.16.1.85-1466418599731:blk_-9223372036854736496_7847, type=LAST_IN_PIPELINE: Thread is interrupted.\n2016-06-28 10:56:44,830 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-257845079-172.16.1.85-1466418599731:blk_-9223372036854736496_7847, type=LAST_IN_PIPELINE terminating\n2016-06-28 10:56:44,830 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: opWriteBlock BP-257845079-172.16.1.85-1466418599731:blk_-9223372036854736496_7847 received exception java.io.IOException: Premature EOF from inputStream\n2016-06-28 10:56:44,830 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: host-172-16-1-143:9866:DataXceiver error processing WRITE_BLOCK operation  src: /172.16.1.85:8185 dst: /172.16.1.143:9866\njava.io.IOException: Premature EOF from inputStream\n\tat org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:204)\n\tat org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)\n\tat org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)\n\tat org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)\n\tat org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:522)\n.................................","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gaoshbj","name":"gaoshbj","key":"gaoshbj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"gao shan","active":true,"timeZone":"Etc/UTC"},"created":"2016-07-01T09:45:21.668+0000","updated":"2016-07-01T09:45:21.668+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12980736/comment/15358732","id":"15358732","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gaoshbj","name":"gaoshbj","key":"gaoshbj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"gao shan","active":true,"timeZone":"Etc/UTC"},"body":"Other data nodes show a lot of Premature EOF errors too,  although I have set dfs.datanode.max.transfer.threads to 8192 and added  \" *   -  nofile  655360,  \"  in the /etc/security/limits.conf,.  \n\n2016-06-28 10:45:16,366 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Exception for BP-257845079-172.16.1.85-1466418599731:blk_-9223372036854736697_7811\njava.io.IOException: Premature EOF from inputStream\n\tat org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:204)\n\tat org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)\n\tat org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)\n\tat org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)\n\tat org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:522)\n\tat org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:923)\n\tat org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:846)\n\tat org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:171)\n\tat org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:105)\n\tat org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:289)\n\tat java.lang.Thread.run(Thread.java:745)\n2016-06-28 10:45:16,366 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-257845079-172.16.1.85-1466418599731:blk_-9223372036854736697_7811, type=LAST_IN_PIPELINE: Thread is interrupted.\n2016-06-28 10:45:16,366 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-257845079-172.16.1.85-1466418599731:blk_-9223372036854736697_7811, type=LAST_IN_PIPELINE terminating\n2016-06-28 10:45:16,367 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: opWriteBlock BP-257845079-172.16.1.85-1466418599731:blk_-9223372036854736697_7811 received exception java.io.IOException: Premature EOF from inputStream\n2016-06-28 10:45:16,367 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: host-172-16-1-89:9866:DataXceiver error processing WRITE_BLOCK operation  src: /172.16.1.88:22616 dst: /172.16.1.89:9866\njava.io.IOException: Premature EOF from inputStream\n\tat org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:204)","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gaoshbj","name":"gaoshbj","key":"gaoshbj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"gao shan","active":true,"timeZone":"Etc/UTC"},"created":"2016-07-01T09:58:28.716+0000","updated":"2016-07-01T09:58:28.716+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12980736/comment/15391755","id":"15391755","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=AlbericLiu","name":"AlbericLiu","key":"albericliu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Alberic Liu","active":true,"timeZone":"Etc/UTC"},"body":"does the map reduce job is successfully or not. Or just the some child task is failed.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=AlbericLiu","name":"AlbericLiu","key":"albericliu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Alberic Liu","active":true,"timeZone":"Etc/UTC"},"created":"2016-07-25T11:46:02.392+0000","updated":"2016-07-25T11:46:02.392+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12980736/comment/15393010","id":"15393010","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gaoshbj","name":"gaoshbj","key":"gaoshbj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"gao shan","active":true,"timeZone":"Etc/UTC"},"body":"The MR job failed and exited.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gaoshbj","name":"gaoshbj","key":"gaoshbj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"gao shan","active":true,"timeZone":"Etc/UTC"},"created":"2016-07-26T01:40:44.853+0000","updated":"2016-07-26T01:40:44.853+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12980736/comment/15393729","id":"15393729","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=AlbericLiu","name":"AlbericLiu","key":"albericliu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Alberic Liu","active":true,"timeZone":"Etc/UTC"},"body":"我也一样，写和读可以，但挂掉3个节点就读不出来，明天看看代码，哪有问题。\n你那边put, get 一个文件，get的时候要挂掉3个节点，也会出这个错吧？\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=AlbericLiu","name":"AlbericLiu","key":"albericliu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Alberic Liu","active":true,"timeZone":"Etc/UTC"},"created":"2016-07-26T12:35:57.136+0000","updated":"2016-07-26T12:39:18.723+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12980736/comment/15394913","id":"15394913","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gaoshbj","name":"gaoshbj","key":"gaoshbj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"gao shan","active":true,"timeZone":"Etc/UTC"},"body":"put/get 在挂掉3个节点时候, 没有出错.   另外, TestDFSIO 虽然出错,但也不是每次都出错, 只是出错的几率很高","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gaoshbj","name":"gaoshbj","key":"gaoshbj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"gao shan","active":true,"timeZone":"Etc/UTC"},"created":"2016-07-27T01:37:53.047+0000","updated":"2016-07-27T01:37:53.047+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12980736/comment/15394960","id":"15394960","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=drankye","name":"drankye","key":"drankye","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Kai Zheng","active":true,"timeZone":"Asia/Chongqing"},"body":"Hi guys,\n\nThanks for reporting this. Could you discuss in English so that others can understand.\n\nIt looks like, at least 4 blocks were lost from 9 ones in a coding group, but since only 3 datanodes were killed, it should be an issue. It could happen if the 4 blocks reside in the 3 datanodes, which means the 4 blocks were misplaced, or they should be in 4 datanodes instead. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=drankye","name":"drankye","key":"drankye","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Kai Zheng","active":true,"timeZone":"Asia/Chongqing"},"created":"2016-07-27T02:29:38.470+0000","updated":"2016-07-27T02:29:38.470+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12980736/comment/15399467","id":"15399467","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rakeshr","name":"rakeshr","key":"rakeshr","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=rakeshr&avatarId=29267","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=rakeshr&avatarId=29267","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=rakeshr&avatarId=29267","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=rakeshr&avatarId=29267"},"displayName":"Rakesh R","active":true,"timeZone":"Asia/Kolkata"},"body":"[~gaoshbj], could you please analyse the client and datanode logs to check the possibility of poor network or datanode unreachable cases which can result in more than parity number of datanode read failures. FYI, recently HDFS-10697 issue discussed one such case.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rakeshr","name":"rakeshr","key":"rakeshr","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=rakeshr&avatarId=29267","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=rakeshr&avatarId=29267","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=rakeshr&avatarId=29267","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=rakeshr&avatarId=29267"},"displayName":"Rakesh R","active":true,"timeZone":"Asia/Kolkata"},"created":"2016-07-29T15:08:08.481+0000","updated":"2016-07-29T15:08:08.481+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12980736/comment/15403291","id":"15403291","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gaoshbj","name":"gaoshbj","key":"gaoshbj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"gao shan","active":true,"timeZone":"Etc/UTC"},"body":"Thanks. but I feel that is not caused by network.  The cluster consists of  10 nodes ( 1 namenode and 9 datanodes ) , which are all virtual machines (15G memory for per vm) created in a same physical server machine. And IPs of these 10 nodes are assigned in a same internal network segment ( 192.168.X .X ).","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gaoshbj","name":"gaoshbj","key":"gaoshbj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"gao shan","active":true,"timeZone":"Etc/UTC"},"created":"2016-08-02T03:17:49.648+0000","updated":"2016-08-02T03:17:49.648+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12980736/comment/15405759","id":"15405759","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gaoshbj","name":"gaoshbj","key":"gaoshbj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"gao shan","active":true,"timeZone":"Etc/UTC"},"body":"By running \"hadoop fsck\" , I find the following info.  It shows  the file /gaotest9/io_data/test_io_7  does not have 9 replicated blocks,   The machine  \"192.168.122.57\" is lost for this file. \n\n////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n/gaotest9/io_data/test_io_5 536870912 bytes, 1 block(s):  OK\n0. BP-1490713436-192.168.122.69-1469603790713:blk_-9223372036854726320_8994 len=536870912 Live_repl=9  [/default-rack/192.168.122.200:50010, /default-rack/192.168.122.214:50010, /default-rack/192.168.122.43:50010, /default-rack/192.168.122.57:50010, /default-rack/192.168.122.23:50010, /default-rack/192.168.122.198:50010, /default-rack/192.168.122.92:50010, /default-rack/192.168.122.111:50010, /default-rack/192.168.122.178:50010]\n\n/gaotest9/io_data/test_io_6 536870912 bytes, 1 block(s):  OK\n0. BP-1490713436-192.168.122.69-1469603790713:blk_-9223372036854726256_8998 len=536870912 Live_repl=9  [/default-rack/192.168.122.214:50010, /default-rack/192.168.122.43:50010, /default-rack/192.168.122.57:50010, /default-rack/192.168.122.111:50010, /default-rack/192.168.122.23:50010, /default-rack/192.168.122.200:50010, /default-rack/192.168.122.178:50010, /default-rack/192.168.122.198:50010, /default-rack/192.168.122.92:50010]\n\n/gaotest9/io_data/test_io_7 536870912 bytes, 1 block(s):  Under replicated BP-1490713436-192.168.122.69-1469603790713:blk_-9223372036854726064_9013. Target Replicas is 9 but found 8 live replica(s), 0 decommissioned replica(s) and 0 decommissioning replica(s).\n0. BP-1490713436-192.168.122.69-1469603790713:blk_-9223372036854726064_9013 len=536870912 Live_repl=8  [/default-rack/192.168.122.178:50010, /default-rack/192.168.122.198:50010, /default-rack/192.168.122.92:50010, /default-rack/192.168.122.214:50010, /default-rack/192.168.122.23:50010, /default-rack/192.168.122.200:50010, /default-rack/192.168.122.111:50010, /default-rack/192.168.122.43:50010]\n\n/gaotest9/io_data/test_io_8 536870912 bytes, 1 block(s):  OK\n0. BP-1490713436-192.168.122.69-1469603790713:blk_-9223372036854726048_9012 len=536870912 Live_repl=9  [/default-rack/192.168.122.92:50010, /default-rack/192.168.122.198:50010, /default-rack/192.168.122.178:50010, /default-rack/192.168.122.200:50010, /default-rack/192.168.122.214:50010, /default-rack/192.168.122.23:50010, /default-rack/192.168.122.57:50010, /default-rack/192.168.122.43:50010, /default-rack/192.168.122.111:50010]\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gaoshbj","name":"gaoshbj","key":"gaoshbj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"gao shan","active":true,"timeZone":"Etc/UTC"},"created":"2016-08-03T11:29:01.414+0000","updated":"2016-08-03T11:29:01.414+0000"}],"maxResults":10,"total":10,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-10586/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i2zq07:"}}