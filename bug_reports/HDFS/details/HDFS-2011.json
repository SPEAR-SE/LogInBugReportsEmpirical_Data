{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12508729","self":"https://issues.apache.org/jira/rest/api/2/issue/12508729","key":"HDFS-2011","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12315571","id":"12315571","description":"","name":"0.23.0","archived":false,"released":true,"releaseDate":"2011-11-11"}],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2011-05-30T16:42:27.172+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Mon Jul 18 16:21:10 UTC 2011","customfield_12310420":"15238","customfield_12312320":null,"customfield_12310222":"10002_*:*_1_*:*_2703009406_*|*_1_*:*_1_*:*_242668_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2011-06-30T23:25:06.128+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-2011/watchers","watchCount":7,"isWatching":false},"created":"2011-05-30T16:30:54.195+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"12.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12315571","id":"12315571","description":"","name":"0.23.0","archived":false,"released":true,"releaseDate":"2011-11-11"}],"issuelinks":[{"id":"12339372","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12339372","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"12497010","key":"HDFS-1602","self":"https://issues.apache.org/jira/rest/api/2/issue/12497010","fields":{"summary":"NameNode storage failed replica restoration is broken","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2011-11-15T00:52:51.922+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12312926","id":"12312926","name":"namenode"}],"timeoriginalestimate":null,"description":"Removal and restoration of storage directories on checkpointing failure doesn't work properly. Sometimes it throws a NullPointerException and sometimes it doesn't take off a failed storage directory","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12485516","id":"12485516","filename":"elfos-close-patch-on-1073.txt","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2011-07-07T00:34:13.206+0000","size":4421,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12485516/elfos-close-patch-on-1073.txt"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12486369","id":"12486369","filename":"elfos-close-patch-on-1073-2.txt","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=eli","name":"eli","key":"eli","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eli Collins","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-07-13T21:07:31.833+0000","size":4812,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12486369/elfos-close-patch-on-1073-2.txt"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12486381","id":"12486381","filename":"elfos-close-patch-on-1073-3.txt","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=eli","name":"eli","key":"eli","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eli Collins","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-07-13T22:18:47.748+0000","size":4981,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12486381/elfos-close-patch-on-1073-3.txt"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12481129","id":"12481129","filename":"HDFS-2011.3.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-06-01T19:09:45.983+0000","size":5790,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12481129/HDFS-2011.3.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12481349","id":"12481349","filename":"HDFS-2011.4.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-06-03T14:29:56.625+0000","size":5779,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12481349/HDFS-2011.4.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12481396","id":"12481396","filename":"HDFS-2011.5.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-06-03T19:29:38.093+0000","size":5599,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12481396/HDFS-2011.5.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12483975","id":"12483975","filename":"HDFS-2011.6.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-06-27T16:51:24.928+0000","size":6279,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12483975/HDFS-2011.6.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12484007","id":"12484007","filename":"HDFS-2011.7.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-06-27T20:50:44.203+0000","size":6253,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12484007/HDFS-2011.7.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12484433","id":"12484433","filename":"HDFS-2011.8.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-06-28T13:28:09.545+0000","size":6294,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12484433/HDFS-2011.8.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12481119","id":"12481119","filename":"HDFS-2011.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-06-01T17:56:05.097+0000","size":5807,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12481119/HDFS-2011.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12481110","id":"12481110","filename":"HDFS-2011.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-06-01T16:56:54.400+0000","size":5807,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12481110/HDFS-2011.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12480858","id":"12480858","filename":"HDFS-2011.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-05-30T16:37:04.773+0000","size":1960,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12480858/HDFS-2011.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"13653","customfield_12312823":null,"summary":"Removal and restoration of storage directories on checkpointing failure doesn't work properly","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12508729/comment/13041193","id":"13041193","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"body":"This applies to commit a8cacc60847be89b5769741f0eb5f560cdb64691 \n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-05-30T16:37:04.811+0000","updated":"2011-05-30T16:37:04.811+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12508729/comment/13041195","id":"13041195","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"-1 overall.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12480858/HDFS-2011.patch\n  against trunk revision 1128987.\n\n    +1 @author.  The patch does not contain any @author tags.\n\n    -1 tests included.  The patch doesn't appear to include any new or modified tests.\n                        Please justify why no new tests are needed for this patch.\n                        Also please list what manual steps were performed to verify this patch.\n\n    -1 patch.  The patch command could not apply the patch.\n\nConsole output: https://builds.apache.org/hudson/job/PreCommit-HDFS-Build/659//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2011-05-30T16:42:27.172+0000","updated":"2011-05-30T16:42:27.172+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12508729/comment/13041200","id":"13041200","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"Any chance of unit tests for these?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2011-05-30T17:10:08.707+0000","updated":"2011-05-30T17:10:08.707+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12508729/comment/13041707","id":"13041707","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mattf","name":"mattf","key":"mattf","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Matt Foley","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi Ravi, for future reference please write a short Description field, then add the long details in a first Comment.  The problem is the Description gets re-sent in every Jira email about the ticket.  Thanks.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mattf","name":"mattf","key":"mattf","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Matt Foley","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-05-31T17:50:13.258+0000","updated":"2011-05-31T17:50:13.258+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12508729/comment/13041858","id":"13041858","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"body":"I had been automating tests to verify the removal and restoration of storage directories. I was testing by setting up a loopback file system, using that as one of the storage directories, and filling it up to make the writes from Hadoop namenode to the checkpoint fail.\nMostly I would see the functionality work. However, very often I would see this exception in the logs:\n\n2011-05-29 23:34:30,241 WARN org.mortbay.log: /getimage: java.io.IOException: GetImage failed. java.io.IOException: No space left on device\nat java.io.FileOutputStream.writeBytes(Native Method)\nat java.io.FileOutputStream.write(FileOutputStream.java:297)\nat org.apache.hadoop.hdfs.server.namenode.TransferFsImage.getFileClient(TransferFsImage.java:224)\nat org.apache.hadoop.hdfs.server.namenode.GetImageServlet$1$1.run(GetImageServlet.java:101)\nat org.apache.hadoop.hdfs.server.namenode.GetImageServlet$1$1.run(GetImageServlet.java:98)\nat java.security.AccessController.doPrivileged(Native Method)\nat javax.security.auth.Subject.doAs(Subject.java:416)\nat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1131)\nat org.apache.hadoop.hdfs.server.namenode.GetImageServlet$1.run(GetImageServlet.java:97)\nat org.apache.hadoop.hdfs.server.namenode.GetImageServlet$1.run(GetImageServlet.java:74)\nat java.security.AccessController.doPrivileged(Native Method)\nat javax.security.auth.Subject.doAs(Subject.java:416)\nat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1131)\nat org.apache.hadoop.hdfs.server.namenode.GetImageServlet.doGet(GetImageServlet.java:74)\nat javax.servlet.http.HttpServlet.service(HttpServlet.java:707)\nat javax.servlet.http.HttpServlet.service(HttpServlet.java:820)\nat org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:502)\nat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1124)\nat org.apache.hadoop.http.HttpServer$QuotingInputFilter.doFilter(HttpServer.java:871)\nat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1115)\nat org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:361)\nat org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216)\nat org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:181)\nat org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:766)\nat org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:417)\nat org.mortbay.jetty.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:230)\nat org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)\nat org.mortbay.jetty.Server.handle(Server.java:324)\nat org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:534)\nat org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:864)\nat org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:533)\nat org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:207)\nat org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:403)\nat org.mortbay.io.nio.SelectChannelEndPoint.run(SelectChannelEndPoint.java:409)\nat org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:522)\n\nIn this case the storage directory wasn't taken offline. It would not be removed from the list. John George figured out this was because the IOException was happening in a code path fromm where the function to remove the corresponding wasn't being called.\n\nAlso, very rarely, I would see this exception\n\n2011-04-05 17:36:56,187 INFO org.apache.hadoop.ipc.Server: IPC Server handler 87 on 8020, call getEditLogSize() from\n98.137.97.99:35862: error: java.io.IOException: java.lang.NullPointerException\njava.io.IOException: java.lang.NullPointerException\nat org.apache.hadoop.hdfs.server.namenode.EditLogFileOutputStream.close(EditLogFileOutputStream.java:109)\nat org.apache.hadoop.hdfs.server.namenode.FSEditLog.processIOError(FSEditLog.java:299)\nat org.apache.hadoop.hdfs.server.namenode.FSEditLog.getEditLogSize(FSEditLog.java:849)\nat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getEditLogSize(FSNamesystem.java:4270)\nat org.apache.hadoop.hdfs.server.namenode.NameNode.getEditLogSize(NameNode.java:1095)\nat sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)\nat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\nat java.lang.reflect.Method.invoke(Method.java:597)\nat org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:346)\nat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1399)\nat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1395)\nat java.security.AccessController.doPrivileged(Native Method)\nat javax.security.auth.Subject.doAs(Subject.java:396)\nat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1094)\nat org.apache.hadoop.ipc.Server$Handler.run(Server.java:1393)\n\nAfter this, the Secondary Namenode and the Namenode would go into infinite loops of this NullPointerExceptions. John George figured out this was because close was being called on the editStream twice (so it was trying to close an editstream which was already closed).\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-05-31T22:06:33.320+0000","updated":"2011-05-31T22:06:33.320+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12508729/comment/13041859","id":"13041859","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks for your comments Todd and Matt! :)\n\nI'm working on a unit test. I'm almost done. \n\nSorry for the junking the emails. I've edited the JIRA and shortened the description. I promise it won't happen again. Thanks for the advice. :)","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-05-31T22:08:10.617+0000","updated":"2011-05-31T22:08:10.617+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12508729/comment/13042284","id":"13042284","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"body":"HDFS-2011.patch","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-06-01T16:56:54.445+0000","updated":"2011-06-01T16:56:54.445+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12508729/comment/13042285","id":"13042285","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"body":"I ran test-patch. Also ran ant-test and no new test failures have been introduced. Can someone please review / commit the patch?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-06-01T16:57:46.329+0000","updated":"2011-06-01T16:57:46.329+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12508729/comment/13042322","id":"13042322","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"body":"Granting license to ASF.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-06-01T17:56:05.116+0000","updated":"2011-06-01T17:56:05.116+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12508729/comment/13042356","id":"13042356","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"-1 overall.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12481110/HDFS-2011.patch\n  against trunk revision 1129942.\n\n    +1 @author.  The patch does not contain any @author tags.\n\n    +1 tests included.  The patch appears to include 8 new or modified tests.\n\n    +1 javadoc.  The javadoc tool did not generate any warning messages.\n\n    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.\n\n    +1 findbugs.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.\n\n    +1 release audit.  The applied patch does not increase the total number of release audit warnings.\n\n    -1 core tests.  The patch failed these core unit tests:\n                  org.apache.hadoop.hdfs.TestDFSUpgradeFromImage\n                  org.apache.hadoop.hdfs.TestHFlush\n\n    +1 contrib tests.  The patch passed contrib unit tests.\n\n    +1 system test framework.  The patch passed system test framework compile.\n\nTest results: https://builds.apache.org/hudson/job/PreCommit-HDFS-Build/672//testReport/\nFindbugs warnings: https://builds.apache.org/hudson/job/PreCommit-HDFS-Build/672//artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html\nConsole output: https://builds.apache.org/hudson/job/PreCommit-HDFS-Build/672//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2011-06-01T18:41:53.832+0000","updated":"2011-06-01T18:41:53.832+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12508729/comment/13042365","id":"13042365","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"-1 overall.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12481119/HDFS-2011.patch\n  against trunk revision 1129942.\n\n    +1 @author.  The patch does not contain any @author tags.\n\n    +1 tests included.  The patch appears to include 8 new or modified tests.\n\n    +1 javadoc.  The javadoc tool did not generate any warning messages.\n\n    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.\n\n    +1 findbugs.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.\n\n    +1 release audit.  The applied patch does not increase the total number of release audit warnings.\n\n    -1 core tests.  The patch failed these core unit tests:\n                  org.apache.hadoop.cli.TestHDFSCLI\n\n    +1 contrib tests.  The patch passed contrib unit tests.\n\n    +1 system test framework.  The patch passed system test framework compile.\n\nTest results: https://builds.apache.org/hudson/job/PreCommit-HDFS-Build/674//testReport/\nFindbugs warnings: https://builds.apache.org/hudson/job/PreCommit-HDFS-Build/674//artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html\nConsole output: https://builds.apache.org/hudson/job/PreCommit-HDFS-Build/674//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2011-06-01T19:03:07.085+0000","updated":"2011-06-01T19:03:07.085+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12508729/comment/13042369","id":"13042369","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"body":"Updated patch. Fixed some things I looked over.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-06-01T19:09:46.022+0000","updated":"2011-06-01T19:09:46.022+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12508729/comment/13042402","id":"13042402","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"+1 overall.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12481129/HDFS-2011.3.patch\n  against trunk revision 1130262.\n\n    +1 @author.  The patch does not contain any @author tags.\n\n    +1 tests included.  The patch appears to include 8 new or modified tests.\n\n    +1 javadoc.  The javadoc tool did not generate any warning messages.\n\n    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.\n\n    +1 findbugs.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.\n\n    +1 release audit.  The applied patch does not increase the total number of release audit warnings.\n\n    +1 core tests.  The patch passed core unit tests.\n\n    +1 contrib tests.  The patch passed contrib unit tests.\n\n    +1 system test framework.  The patch passed system test framework compile.\n\nTest results: https://builds.apache.org/hudson/job/PreCommit-HDFS-Build/676//testReport/\nFindbugs warnings: https://builds.apache.org/hudson/job/PreCommit-HDFS-Build/676//artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html\nConsole output: https://builds.apache.org/hudson/job/PreCommit-HDFS-Build/676//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2011-06-01T20:24:49.556+0000","updated":"2011-06-01T20:24:49.556+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12508729/comment/13043144","id":"13043144","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mattf","name":"mattf","key":"mattf","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Matt Foley","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi Ravi, the logic of your changes is fine.  The following comments are almost all regarding common usages in Hadoop code base and unit tests.\n\nTestCheckpoint.checkEditLogFileOutputStreamCloses():\n* To obtain the build/test/data directory correctly, use System.getProperty(\"test.build.data\",\"/tmp\") rather than hardcoding it; then create your desired file relative to that directory.\n* I find \"elfosFile\" to be a very opaque name.  Would it be reasonable to use something like \"editLogStream\" instead?\n* Instead of Assert.assertTrue(\"msg\",false), use Assert.fail(\"msg\").\n* But, there is no need to catch and message exceptions that shouldn't happen.  Both \"catch{}\" clauses add no significant value compared to the stack trace that will be printed on exception, by junit.  In fact, the stack trace from the catch-and-Assert is LESS informative than the original exception stack trace would have been, because it points into the catch clause instead of into where the exception actually occurred.\n* It's good that you bracket both the beginning and end with printlns that clearly state what is being tested; if an exception occurs the developer will immediately see what went wrong (with the help of the stack trace).\n* Within the \"finally{}\" clause, it might be a good idea to put the delete() call in its own try/catch context.  If another exception happened, you wouldn't want to interfere with the original exception message, which carries the info you created the testcase to expose.\n\ncheckSetCheckpointTimeInStorageHandlesIOException():\n* alFS and alES are also very opaque names.  Hadoop doesn't subscribe to Hungarian naming, so the \"al\" prefix isn't needed.  \"FS\" usually means FileSystem, which isn't the same as a StorageDirectory.  So consider renaming these, perhaps to fsImageDirs and editsDirs.\n* First try/catch context:  Again, there's no need to catch-and-Assert unexpected failures.  If they occur, they will be duly reported by junit.\n* As before, the place to put the directories you create should be relative to System.getProperty(\"test.build.data\",\"/tmp\").\n* And to create the URIs, it is probably best to do something equivalent to \"new Path(System.getProperty(\"test.build.data\",\"/tmp\"), \"storageDirToCheck\").toUri()\".  This will work around any filesystem path naming oddities.\n* In the assert, use listRsd.get(listRsd.size()-1) instead of listRsd.get(0), because the new element would be added to the end of the list -- I think :-)\n* It might be good to use nnStorage.getEditsDirectories() and/or nnStorage.getImageDirectories() before deleting the dir, to assure that the setStorageDirectories() had the expected result, and call nnStorage.getRemovedStorageDirs() before to assure that the list initially does not contain \"storageDirToCheck\".\n\nNNStorage.setCheckpointTimeInStorage():\n* In the comment \"//Since writeCheckpointTime may also encounter an IOException in case underlying storage fails\" substitute \"reportErrorsOnDirectories()\" for \"writeCheckpointTime\".\n* There is a singular reportErrorsOnDirectory() method.  Could you use it instead of reportErrorsOnDirectories()?  Then you wouldn't need to construct the ArrayList.\n* In the LOG.error if the second IOE happens, suggest \nLOG.error(\"Failed to report and remove NN storage directory \" + sd.getRoot().getPath(), ioe);\nBesides clarifying the msg, note that \"+ ioe\" uses ioe.toString(), which only prints a single line about the exception, while using \", ioe\" in a LOG argument list causes the entire stack trace to be printed.\n\nEditLogFileOutputStream.close():\n* Suggest you separate the bufCurrent and bufReady cases.  Do:\n{code}\nif (bufCurrent != null) {\n    int bufSize = bufCurrent.size();\n    if (bufSize != 0) {\n      throw new IOException(\"FSEditStream has \" + bufSize\n          + \" bytes still to be flushed and cannot \" + \"be closed.\");\n    }\n    bufCurrent.close();\n}\nif (bufReady != null) {\n    bufReady.close();\n}\n{code}\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mattf","name":"mattf","key":"mattf","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Matt Foley","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-06-02T23:55:01.885+0000","updated":"2011-06-02T23:55:01.885+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12508729/comment/13043220","id":"13043220","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cos","name":"cos","key":"cos","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cos&avatarId=16741","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cos&avatarId=16741","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cos&avatarId=16741","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cos&avatarId=16741"},"displayName":"Konstantin Boudnik","active":true,"timeZone":"America/Los_Angeles"},"body":"There's also this error message\n{{+            LOG.error(\"Problem erroring streams \" + ioe);}}\nwhich is somewhat moot.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cos","name":"cos","key":"cos","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cos&avatarId=16741","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cos&avatarId=16741","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cos&avatarId=16741","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cos&avatarId=16741"},"displayName":"Konstantin Boudnik","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-06-03T05:48:01.818+0000","updated":"2011-06-03T05:48:01.818+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12508729/comment/13043368","id":"13043368","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"body":"Incorporated Matt's and Konstantin's comments","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-06-03T14:29:56.669+0000","updated":"2011-06-03T14:29:56.669+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12508729/comment/13043370","id":"13043370","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi Matt,\n\nThanks a ton for your review! I learned a lot from your detailed explanations. :) I followed all of your suggestions. Couple of things to note\n\n1. To be able to throw exceptions like you suggested, I had to make my two functions individual jUnit tests. I hope that is fine. (Earlier they were being called from testCheckpoint() throws IOException)\n2. Thanks for the tip to use toURI. :) However, when I used new Path(System.getProperty(\"test.build.data\",\"/tmp\"), \"storageDirToCheck\").toUri(), the test failed saying \n{noformat} \nTestcase: testSetCheckpointTimeInStorageHandlesIOException took 0.077 sec\n        Caused an ERROR\nUndefined scheme for /home/raviprak/Code/hadoop/hadoop-hdfs/build/test/data/storageDirToCheck\njava.io.IOException: Undefined scheme for /home/raviprak/Code/hadoop/hadoop-hdfs/build/test/data/storageDirToCheck\n        at org.apache.hadoop.hdfs.server.namenode.NNStorage.checkSchemeConsistency(NNStorage.java:348)\n        at org.apache.hadoop.hdfs.server.namenode.NNStorage.setStorageDirectories(NNStorage.java:306)\n        at org.apache.hadoop.hdfs.server.namenode.TestCheckpoint.testSetCheckpointTimeInStorageHandlesIOException(TestCheckpoint.java:179)\n{noformat} \nSo I changed it to use new File(...).toURI(). I hope that is fine too. \n3. In the comment, I meant to convey that the block of code was for when writeCheckpointTime incurred an IOException. I've removed the comment seeing that it had been already mentioned by the comment above it. Sorry for the ambiguity.\n4. When I separated the bufCurrent and bufReady cases, the test failed saying \n{noformat} \nTestcase: testEditLogFileOutputStreamCloses took 0.042 sec\n        Caused an ERROR\nBad file descriptor\njava.io.IOException: Bad file descriptor\n        at sun.nio.ch.FileChannelImpl.position0(Native Method)\n        at sun.nio.ch.FileChannelImpl.position(FileChannelImpl.java:284)\n        at org.apache.hadoop.hdfs.server.namenode.EditLogFileOutputStream.close(EditLogFileOutputStream.java:141)\n        at org.apache.hadoop.hdfs.server.namenode.TestCheckpoint.testEditLogFileOutputStreamCloses(TestCheckpoint.java:154)\n{noformat} \nThis was because these lines (more specifically the 1st) were still being called.  \n{noformat} \n    // remove the last INVALID marker from transaction log.\n    fc.truncate(fc.position());\n    fp.close();\n{noformat} \nI've let it remain the same. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-06-03T14:30:04.840+0000","updated":"2011-06-03T14:30:04.840+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12508729/comment/13043414","id":"13043414","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"+1 overall.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12481349/HDFS-2011.4.patch\n  against trunk revision 1130870.\n\n    +1 @author.  The patch does not contain any @author tags.\n\n    +1 tests included.  The patch appears to include 4 new or modified tests.\n\n    +1 javadoc.  The javadoc tool did not generate any warning messages.\n\n    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.\n\n    +1 findbugs.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.\n\n    +1 release audit.  The applied patch does not increase the total number of release audit warnings.\n\n    +1 core tests.  The patch passed core unit tests.\n\n    +1 contrib tests.  The patch passed contrib unit tests.\n\n    +1 system test framework.  The patch passed system test framework compile.\n\nTest results: https://builds.apache.org/hudson/job/PreCommit-HDFS-Build/696//testReport/\nFindbugs warnings: https://builds.apache.org/hudson/job/PreCommit-HDFS-Build/696//artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html\nConsole output: https://builds.apache.org/hudson/job/PreCommit-HDFS-Build/696//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2011-06-03T15:45:15.252+0000","updated":"2011-06-03T15:45:15.252+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12508729/comment/13043892","id":"13043892","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"A few style nits on HDFS-2011.4.patch:\n- please try to keep lines under 80 columns wide where possible. If it spills over to 85 or 90 here and there, not a huge deal, but 100+ columns should be avoided\n- why catch SecurityException? that looks very much out of place, and given it's an unchecked exception, you don't need to catch it at all\n- the assertTrue around mkdir() in testSetCheckpoingTimeInStorageHandlesIOException should probably check \"exists() || mkdir()\". Or call deleteFully on it at the top of the test\n- you construct that same file path several times in the same test. Please just make it once as a constant\n- in the error messages, better to do something like: \"Couldn't remove directory \" + TEST_STORAGE_DIR.getAbsoluteFile(). That way the developer can easily track down the full path\n- alignment is off in NNStorage.java change\n- the comment referring to \"edit and edits.new\" in ELFOS is out of place - that class shouldn't know about details of how it's used. Instead it should read something like \"// if already closed, just return\"\n- TestCheckpoint inherits from TestCase, so you don't need to import org.junit.Assert","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2011-06-03T17:30:40.305+0000","updated":"2011-06-03T17:30:40.305+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12508729/comment/13043990","id":"13043990","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi Todd,\n\nThanks a lot for reviewing the patch. :) I continue to learn :) I have followed all of your suggestions. The only note is that I am checking for SecurityException so that in the finally block it doesn't mask an IOException / NullPointerException that was possibly thrown in the try block. I hope that is fine.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-06-03T19:29:23.857+0000","updated":"2011-06-03T19:29:23.857+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12508729/comment/13044011","id":"13044011","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"re SecurityException: I still don't see any reason that delete() would throw such an exception. AFAIK that only happens if a security manager is installed, which we never expect in unit tests.\n\nWill try to look over the new patch revision later today or early next week. Thanks!","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2011-06-03T20:12:26.438+0000","updated":"2011-06-03T20:12:26.438+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12508729/comment/13044025","id":"13044025","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"+1 overall.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12481396/HDFS-2011.5.patch\n  against trunk revision 1131124.\n\n    +1 @author.  The patch does not contain any @author tags.\n\n    +1 tests included.  The patch appears to include 3 new or modified tests.\n\n    +1 javadoc.  The javadoc tool did not generate any warning messages.\n\n    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.\n\n    +1 findbugs.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.\n\n    +1 release audit.  The applied patch does not increase the total number of release audit warnings.\n\n    +1 core tests.  The patch passed core unit tests.\n\n    +1 contrib tests.  The patch passed contrib unit tests.\n\n    +1 system test framework.  The patch passed system test framework compile.\n\nTest results: https://builds.apache.org/hudson/job/PreCommit-HDFS-Build/701//testReport/\nFindbugs warnings: https://builds.apache.org/hudson/job/PreCommit-HDFS-Build/701//artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html\nConsole output: https://builds.apache.org/hudson/job/PreCommit-HDFS-Build/701//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2011-06-03T20:37:15.353+0000","updated":"2011-06-03T20:37:15.353+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12508729/comment/13045163","id":"13045163","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mattf","name":"mattf","key":"mattf","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Matt Foley","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi Ravi, looking a lot better.  Here's a few more.\n\nTestCheckpoint.testEditLogFileOutputStreamCloses():\n1. Use the two-argument form of File ctor:\nFile(System.getProperty(\"test.build.data\",\"/tmp\"), \"editLogStream.dat\")\nnot\nFile(System.getProperty(\"test.build.data\",\"/tmp\") + \"editLogStream.dat\")\nThis will insure the path delimiter is inserted correctly.\n2. in the \"finally\" clause:\nAgain, there's no point in catch-then-assert, unless you need to do something in between.  You can just let it fail.  The point of the try/catch I recommended was so that it WOULDN'T fail, because failing could prevent any prior exception info from propagating.  So the \"catch\" clause should use println to log the problem, but not fail or otherwise cause an assert.\n3. if you want to fine-tune that a little, you could have a variable \"success\" which is set to false at the beginning, and set to true at the end of the main body (before the \"finally\" clause).  Then in this \"catch\" clause you could throw if success==true, but just println if !success.\n4. If you need to use println or Assert to message an exception, you can use StringUtils.stringifyException(e), which prints the whole stack trace, vs e.toString(), which only prints one line of info. But \"LOG\" and \"throw\" messages allow using Exception objects as additional arguments, giving the same result as StringUtils.stringifyException() but with cleaner syntax.\n\ntestSetCheckpointTimeInStorageHandlesIOException():\n5. Use File(System.getProperty(\"test.build.data\",\"/tmp\"), \"storageDirToCheck\")\ninstead of File (System.getProperty(\"test.build.data\",\"/tmp\") + \"/storageDirToCheck/\")\n6. and don't put a space between \"File\" and the following parenthesis.  A ctor is a method call.\n7. You probably want to use mkdirs() rather than mkdir().\n8. Extra blanks before and after argument lists are against the coding style standard.\n9. In \"assertTrue(\"List of storage directories didn't have storageDirToCheck.\"...), did you intend to iterate over all elements in the list?  You go to the trouble of creating an iterator, and then only use the first element.\n10. Doesn't this routine also need a try/catch context that cleans up the created directory if an error occurs?\n\nEditLogFileOutputStream.close():\n11. Interesting problem.  It looks like fc and fp are not directly dependent on bufCurrent and bufReady, but simply are likely to be null if bufCurrent and bufReady end up null, therefore I think we should still treat bufCurrent and bufReady as possibly valid/invalid separately.  Can you tell if the problem value of fc is null or simply a file descriptor that is already closed?  What if you use the previously suggested statements for bufCurrent and bufReady, followed by:\n{code}\n    // remove the last INVALID marker from transaction log.\n    if (fc != null && fc.isOpen()) {\n      fc.truncate(fc.position());\n    }\n    if (fp != null) {\n      fp.close();\n    }\n{code}\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mattf","name":"mattf","key":"mattf","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Matt Foley","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-06-06T22:11:31.931+0000","updated":"2011-06-06T22:11:31.931+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12508729/comment/13045168","id":"13045168","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mattf","name":"mattf","key":"mattf","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Matt Foley","active":true,"timeZone":"America/Los_Angeles"},"body":"Oh, and in that last bit of code, if fc is still open I would think it should be closed after the truncate.  But it isn't in the current code.  Can you see a reason why?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mattf","name":"mattf","key":"mattf","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Matt Foley","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-06-06T22:15:24.517+0000","updated":"2011-06-06T22:15:24.517+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12508729/comment/13049387","id":"13049387","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mattf","name":"mattf","key":"mattf","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Matt Foley","active":true,"timeZone":"America/Los_Angeles"},"body":"Ravi, I don't think this collides with HDFS-988, but please check.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mattf","name":"mattf","key":"mattf","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Matt Foley","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-06-14T20:30:06.312+0000","updated":"2011-06-14T20:30:06.312+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12508729/comment/13055647","id":"13055647","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"body":"Incorporated Matt's latest comments","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-06-27T16:51:24.947+0000","updated":"2011-06-27T16:51:24.947+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12508729/comment/13055660","id":"13055660","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks Matt,\n\nIncorporated all your comments :)\n\n{quote}\n9. In \"assertTrue(\"List of storage directories didn't have storageDirToCheck.\"...), did you intend to iterate over all elements in the list? You go to the trouble of creating an iterator, and then only use the first element.\n{quote}\nI meant to get the first element of the Collection (since that's what nnStorage.getEditsDirectories() returns me). \n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-06-27T16:56:50.966+0000","updated":"2011-06-27T16:56:50.966+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12508729/comment/13055663","id":"13055663","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"body":"{quote}\nOh, and in that last bit of code, if fc is still open I would think it should be closed after the truncate. But it isn't in the current code. Can you see a reason why?\n{quote}\n\nI don't know how File Channels work, but in the constructor you can see that fc and fp are both derived from the same RandomAccessFile (rp). Could calling fp.close() automatically close fc too?\n\n\n{quote}\nRavi, I don't think this collides with HDFS-988, but please check.\n{quote}\ndiffstat's didn't have any common files. \n{noformat}\n$ diffstat hdfs-988-7.patch \n java/org/apache/hadoop/hdfs/DFSOutputStream.java                                |    5 \n java/org/apache/hadoop/hdfs/server/namenode/BlockManager.java                   |    5 \n java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java                    |  804 ++--\n java/org/apache/hadoop/hdfs/server/namenode/FSEditLogLoader.java                |   10 \n java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java                   | 1891 +++++-----\n java/org/apache/hadoop/hdfs/server/namenode/LeaseManager.java                   |    1 \n test/hdfs/org/apache/hadoop/cli/TestHDFSCLI.java                                |    2 \n test/hdfs/org/apache/hadoop/hdfs/DFSTestUtil.java                               |    9 \n test/hdfs/org/apache/hadoop/hdfs/TestDecommission.java                          |    6 \n test/hdfs/org/apache/hadoop/hdfs/TestSafeMode.java                              |  208 -\n test/hdfs/org/apache/hadoop/hdfs/server/namenode/NameNodeAdapter.java           |   15 \n test/hdfs/org/apache/hadoop/hdfs/server/namenode/TestDeadDatanode.java          |    9 \n test/hdfs/org/apache/hadoop/hdfs/server/namenode/TestHeartbeatHandling.java     |    8 \n test/hdfs/org/apache/hadoop/hdfs/server/namenode/TestNNThroughputBenchmark.java |    1 \n test/hdfs/org/apache/hadoop/hdfs/server/namenode/TestSafeMode.java              |   90 \n test/unit/org/apache/hadoop/hdfs/server/namenode/TestNNLeaseRecovery.java       |   39 \n 16 files changed, 1676 insertions(+), 1427 deletions(-)\n$ diffstat HDFS-2011.6.patch \n java/org/apache/hadoop/hdfs/server/namenode/EditLogFileOutputStream.java |   31 +++-\n java/org/apache/hadoop/hdfs/server/namenode/NNStorage.java               |    6 \n test/hdfs/org/apache/hadoop/hdfs/server/namenode/TestCheckpoint.java     |   67 ++++++++++\n 3 files changed, 94 insertions(+), 10 deletions(-)\n{noformat}\ntest-patch passed and I also ran my automated test twice just to be sure. Functionality doesn't seem to have collided.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-06-27T17:11:16.625+0000","updated":"2011-06-27T17:11:16.625+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12508729/comment/13055689","id":"13055689","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"-1 overall.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12483975/HDFS-2011.6.patch\n  against trunk revision 1140030.\n\n    +1 @author.  The patch does not contain any @author tags.\n\n    +1 tests included.  The patch appears to include 3 new or modified tests.\n\n    +1 javadoc.  The javadoc tool did not generate any warning messages.\n\n    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.\n\n    +1 findbugs.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.\n\n    +1 release audit.  The applied patch does not increase the total number of release audit warnings.\n\n    -1 core tests.  The patch failed these core unit tests:\n                  org.apache.hadoop.hdfs.server.namenode.TestCheckpoint\n                  org.apache.hadoop.hdfs.TestFileAppend2\n\n    +1 contrib tests.  The patch passed contrib unit tests.\n\n    +1 system test framework.  The patch passed system test framework compile.\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/848//testReport/\nFindbugs warnings: https://builds.apache.org/job/PreCommit-HDFS-Build/848//artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/848//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2011-06-27T18:17:44.545+0000","updated":"2011-06-27T18:17:44.545+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12508729/comment/13055745","id":"13055745","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"body":"The test failed because fc.close() wasn't being called. Thanks Matt! :) Including that in the latest patch. The two failed tests passed and test-patch too. Also my automated unit tests.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-06-27T20:50:02.171+0000","updated":"2011-06-27T20:50:02.171+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12508729/comment/13055746","id":"13055746","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"body":"Included fc.close() in EditLogFileOutputStream.close()","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-06-27T20:50:44.238+0000","updated":"2011-06-27T20:50:44.238+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12508729/comment/13055799","id":"13055799","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"+1 overall.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12484007/HDFS-2011.7.patch\n  against trunk revision 1140030.\n\n    +1 @author.  The patch does not contain any @author tags.\n\n    +1 tests included.  The patch appears to include 3 new or modified tests.\n\n    +1 javadoc.  The javadoc tool did not generate any warning messages.\n\n    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.\n\n    +1 findbugs.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.\n\n    +1 release audit.  The applied patch does not increase the total number of release audit warnings.\n\n    +1 core tests.  The patch passed core unit tests.\n\n    +1 contrib tests.  The patch passed contrib unit tests.\n\n    +1 system test framework.  The patch passed system test framework compile.\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/849//testReport/\nFindbugs warnings: https://builds.apache.org/job/PreCommit-HDFS-Build/849//artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/849//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2011-06-27T22:06:22.680+0000","updated":"2011-06-27T22:06:22.680+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12508729/comment/13056216","id":"13056216","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mattf","name":"mattf","key":"mattf","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Matt Foley","active":true,"timeZone":"America/Los_Angeles"},"body":"Looking great!  And you're right about needing the iterator to access nnStorage.getEditsDirectories(), since it's just a Collection.\n\nThere's just one small thing I'd like to fix:\n* in testSetCheckpointTimeInStorageHandlesIOException, new File ctor, you shouldn't need slashes around \"/storageDirToCheck/\", \"storageDirToCheck\" should work.\n* and one trivial edit: The comment in EditLogFileOutputStream.close(), \"// if already closed, just return\" isn't correct any more.  \"// if already closed, just skip\" would be correct.\n\nIf that's okay, I'll commit it on the next round.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mattf","name":"mattf","key":"mattf","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Matt Foley","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-06-27T23:59:31.711+0000","updated":"2011-06-27T23:59:31.711+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12508729/comment/13056505","id":"13056505","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi Matt,\n\nI've incorporated both changes. Thanks for your insightful reviews :)\n\nCheers\nRavi","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-06-28T13:28:09.563+0000","updated":"2011-06-28T13:28:09.563+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12508729/comment/13056538","id":"13056538","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"+1 overall.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12484433/HDFS-2011.8.patch\n  against trunk revision 1140030.\n\n    +1 @author.  The patch does not contain any @author tags.\n\n    +1 tests included.  The patch appears to include 3 new or modified tests.\n\n    +1 javadoc.  The javadoc tool did not generate any warning messages.\n\n    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.\n\n    +1 findbugs.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.\n\n    +1 release audit.  The applied patch does not increase the total number of release audit warnings.\n\n    +1 core tests.  The patch passed core unit tests.\n\n    +1 contrib tests.  The patch passed contrib unit tests.\n\n    +1 system test framework.  The patch passed system test framework compile.\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/859//testReport/\nFindbugs warnings: https://builds.apache.org/job/PreCommit-HDFS-Build/859//artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/859//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2011-06-28T14:37:01.625+0000","updated":"2011-06-28T14:37:01.625+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12508729/comment/13058131","id":"13058131","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mattf","name":"mattf","key":"mattf","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Matt Foley","active":true,"timeZone":"America/Los_Angeles"},"body":"Committed to trunk.  Thanks Ravi!  And thanks to Todd and Cos for reviews.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mattf","name":"mattf","key":"mattf","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Matt Foley","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-06-30T23:25:06.153+0000","updated":"2011-06-30T23:25:06.153+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12508729/comment/13058136","id":"13058136","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"Integrated in Hadoop-Hdfs-trunk-Commit #771 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk-Commit/771/])\n    HDFS-2011. Removal and restoration of storage directories on checkpointing failure doesn't work properly. Contributed by Ravi Prakash.\n\nmattf : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1141748\nFiles : \n* /hadoop/common/trunk/hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/EditLogFileOutputStream.java\n* /hadoop/common/trunk/hdfs/CHANGES.txt\n* /hadoop/common/trunk/hdfs/src/test/hdfs/org/apache/hadoop/hdfs/server/namenode/TestCheckpoint.java\n* /hadoop/common/trunk/hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/NNStorage.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2011-06-30T23:44:14.820+0000","updated":"2011-06-30T23:44:14.820+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12508729/comment/13058532","id":"13058532","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"Integrated in Hadoop-Hdfs-trunk #712 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/712/])\n    HDFS-2011. Removal and restoration of storage directories on checkpointing failure doesn't work properly. Contributed by Ravi Prakash.\n\nmattf : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1141748\nFiles : \n* /hadoop/common/trunk/hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/EditLogFileOutputStream.java\n* /hadoop/common/trunk/hdfs/CHANGES.txt\n* /hadoop/common/trunk/hdfs/src/test/hdfs/org/apache/hadoop/hdfs/server/namenode/TestCheckpoint.java\n* /hadoop/common/trunk/hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/NNStorage.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2011-07-01T12:43:54.713+0000","updated":"2011-07-01T12:43:54.713+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12508729/comment/13058605","id":"13058605","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks Matt, Todd and Cos! My first patch into Hadoop. Yaayyyyy!!!","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-07-01T15:39:48.152+0000","updated":"2011-07-01T15:39:48.152+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12508729/comment/13060745","id":"13060745","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"I'm working on merging this with HDFS-1073, and had one question: when do we expect that an editlog stream would be closed twice? In 1073 there are some extra asserts, so instead of ignoring the second close, it now throws \"java.io.IOException: Trying to use aborted output stream\". I'm debating whether to remove this exception like you've done in this patch, vs remove the patch, since it seems like it might be indicative of a bug to close a stream twice.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2011-07-06T18:30:48.949+0000","updated":"2011-07-06T18:30:48.949+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12508729/comment/13060775","id":"13060775","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"body":"I had noticed close being called twice while testing this functionality . This was causing a NullPointerException the second time. The stack trace is given in comment https://issues.apache.org/jira/browse/HDFS-2011?focusedCommentId=13041858&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13041858\n\n{quote}\n2011-04-05 17:36:56,187 INFO org.apache.hadoop.ipc.Server: IPC Server handler 87 on 8020, call getEditLogSize() from\n98.137.97.99:35862: error: java.io.IOException: java.lang.NullPointerException\njava.io.IOException: java.lang.NullPointerException\nat org.apache.hadoop.hdfs.server.namenode.EditLogFileOutputStream.close(EditLogFileOutputStream.java:109)\nat org.apache.hadoop.hdfs.server.namenode.FSEditLog.processIOError(FSEditLog.java:299)\nat org.apache.hadoop.hdfs.server.namenode.FSEditLog.getEditLogSize(FSEditLog.java:849)\nat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getEditLogSize(FSNamesystem.java:4270)\nat org.apache.hadoop.hdfs.server.namenode.NameNode.getEditLogSize(NameNode.java:1095)\nat sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)\nat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\nat java.lang.reflect.Method.invoke(Method.java:597)\nat org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:346)\nat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1399)\nat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1395)\nat java.security.AccessController.doPrivileged(Native Method)\nat javax.security.auth.Subject.doAs(Subject.java:396)\nat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1094)\nat org.apache.hadoop.ipc.Server$Handler.run(Server.java:1393)\n{quote}\n\nThe bug itself is quite hard to reproduce. I had to run my tests in an infinite loop and the NullPointerException happened after 3-4 hours (each run of the test would take 2 mins maybe). After the NullPointerException, the namenode would essentially be useless. Even hdfs dfs -ls would throw a NullPointerException.\n\nI am not sure myself which philosophy would be better. FileOutputStream itself ignores a second close. I checked this with the following program\n\n{noformat}\nimport java.io.*;\n\npublic class TestJAVA \n{\n\n\tpublic static void main(String args[]) \n\t{\n\t\tSystem.out.println(\"Hello World\");\n\t\ttry {\n\t\t\n\t\t\tFileOutputStream fos = new FileOutputStream(\"/tmp/ravi.txt\");\n\t\t\tfos.write(50);\n\t\t\tfos.write(50);\n\t\t\tfos.write(50);\n\t\t\tfos.write(50);\n\t\t\tfos.write(50);\n\t\t\tfos.write(50);\n\t\t\tfos.close();\n\t\t\tfos.close();\n\t\t} catch (IOException ioe) {\n\t\t\tSystem.out.println(\"Hello California\");\n\t\t\tSystem.out.println (ioe);\n\t\t}\n\t\tSystem.out.println(\"Hello Champaign\");\n\t\t\n\t}\n\t\n}\n{noformat}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-07-06T19:14:50.346+0000","updated":"2011-07-06T19:14:50.346+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12508729/comment/13060777","id":"13060777","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"body":"The program above output\n{noformat}\nHello World\nHello Champaign\n{noformat}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-07-06T19:15:47.132+0000","updated":"2011-07-06T19:15:47.132+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12508729/comment/13060780","id":"13060780","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=johnvijoe","name":"johnvijoe","key":"johnvijoe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"John George","active":true,"timeZone":"America/Los_Angeles"},"body":"If I remember right, it was a case of an \"incomplete create\" as opposed to close being called twice. So, the close() was being called on a stream that was not really created...","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=johnvijoe","name":"johnvijoe","key":"johnvijoe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"John George","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-07-06T19:22:49.865+0000","updated":"2011-07-06T19:22:49.865+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12508729/comment/13060812","id":"13060812","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"In the HDFS-1073 branch, EditLogOutputStream now has separate close() and abort() methods. abort() is used when there has been some error on the stream and we expect to do an \"unclean\" close (ie without flushing). close() is used for clean closes. If close() itself fails, it will then proceed to abort() when the IO error is handled.\n\nSo, I think the correct test case on the branch is to call abort() twice and make sure that's ignored, or call close() and then abort() to make sure that's ignored. Does that sound reasonable?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2011-07-06T20:30:36.594+0000","updated":"2011-07-06T20:30:36.594+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12508729/comment/13060853","id":"13060853","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=johnvijoe","name":"johnvijoe","key":"johnvijoe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"John George","active":true,"timeZone":"America/Los_Angeles"},"body":"I think calling\n1. abort() twice\n2. close() twice\n3. close() followed by an abort()\n\nwould test most cases.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=johnvijoe","name":"johnvijoe","key":"johnvijoe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"John George","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-07-06T21:26:38.000+0000","updated":"2011-07-06T21:26:38.000+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12508729/comment/13060959","id":"13060959","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"Here's the patch I'm planning to commit to 1073 branch. Look good?\n\nI will also do some stress testing similar to what Ravi described on the branch to see if I can reproduce the issue he saw.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2011-07-07T00:34:13.250+0000","updated":"2011-07-07T00:34:13.250+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12508729/comment/13061273","id":"13061273","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=johnvijoe","name":"johnvijoe","key":"johnvijoe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"John George","active":true,"timeZone":"America/Los_Angeles"},"body":"The patch looks good. Shouldn't the sequence \"close() close()\" be tested as well, since that could be a case that could possibly happen?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=johnvijoe","name":"johnvijoe","key":"johnvijoe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"John George","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-07-07T13:04:52.182+0000","updated":"2011-07-07T13:04:52.182+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12508729/comment/13064846","id":"13064846","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=eli","name":"eli","key":"eli","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eli Collins","active":true,"timeZone":"America/Los_Angeles"},"body":"@John. I agree. Here's an updated (1073) patch that tests the double close and asserts that we get an IOE for using an aborted stream. \n\n@Ravi - want to incorporate this new test into the patch for trunk? ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=eli","name":"eli","key":"eli","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eli Collins","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-07-13T21:07:31.910+0000","updated":"2011-07-13T21:07:31.910+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12508729/comment/13064880","id":"13064880","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=johnvijoe","name":"johnvijoe","key":"johnvijoe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"John George","active":true,"timeZone":"America/Los_Angeles"},"body":"+1 Looks good to me. Thanks Eli.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=johnvijoe","name":"johnvijoe","key":"johnvijoe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"John George","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-07-13T21:39:25.049+0000","updated":"2011-07-13T21:39:25.049+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12508729/comment/13064914","id":"13064914","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=eli","name":"eli","key":"eli","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eli Collins","active":true,"timeZone":"America/Los_Angeles"},"body":"Attaching patch with minor fix to comment in the double close test.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=eli","name":"eli","key":"eli","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eli Collins","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-07-13T22:18:47.781+0000","updated":"2011-07-13T22:18:47.781+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12508729/comment/13065464","id":"13065464","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"Committed elfos-close-patch-on-1073-3.txt to the HDFS-1073 branch to fix the test case. Thanks Eli.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2011-07-14T18:59:50.816+0000","updated":"2011-07-14T18:59:50.816+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12508729/comment/13065667","id":"13065667","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"Integrated in Hadoop-Hdfs-1073-branch #9 (See [https://builds.apache.org/job/Hadoop-Hdfs-1073-branch/9/])\n    Amend HDFS-2011 for HDFS-1073 branch. Update test cases for new behavior of EditLogFileOutputStream. Contributed by Todd Lipcon and Eli Collins.\n\ntodd : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1146848\nFiles : \n* /hadoop/common/branches/HDFS-1073/hdfs/src/test/hdfs/org/apache/hadoop/hdfs/server/namenode/TestCheckpoint.java\n* /hadoop/common/branches/HDFS-1073/hdfs/src/test/hdfs/org/apache/hadoop/hdfs/server/namenode/TestEditLogFileOutputStream.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2011-07-15T01:42:48.624+0000","updated":"2011-07-15T01:42:48.624+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12508729/comment/13066603","id":"13066603","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"body":"@Eli - The new patch tests abort() but I couldn't find the method in EditLogFileOutputStream.java in trunk. Its available in HDFS-1073. Could you please point me to what exactly I should incorporate into trunk?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-07-17T08:11:25.834+0000","updated":"2011-07-17T08:11:25.834+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12508729/comment/13067108","id":"13067108","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=eli","name":"eli","key":"eli","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eli Collins","active":true,"timeZone":"America/Los_Angeles"},"body":"Ah, right, abort is new in 1073, I think the tests you have for trunk are fine for now. The new test with abort will come in when 1073 is merged.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=eli","name":"eli","key":"eli","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eli Collins","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-07-18T16:21:10.167+0000","updated":"2011-07-18T16:21:10.167+0000"}],"maxResults":54,"total":54,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-2011/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i02p0f:"}}