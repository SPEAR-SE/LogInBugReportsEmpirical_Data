{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12618845","self":"https://issues.apache.org/jira/rest/api/2/issue/12618845","key":"HDFS-4270","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12323274","id":"12323274","description":"2.0.3-alpha release","name":"2.0.3-alpha","archived":false,"released":true,"releaseDate":"2013-02-14"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12323503","id":"12323503","description":"0.23.6 release","name":"0.23.6","archived":false,"released":true,"releaseDate":"2013-02-06"}],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2012-12-05T19:21:39.390+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Sat Jan 05 12:36:21 UTC 2013","customfield_12310420":"296104","customfield_12312320":null,"customfield_12310222":"10002_*:*_2_*:*_2186968185_*|*_1_*:*_2_*:*_402274535_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2013-01-04T08:14:30.246+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-4270/watchers","watchCount":12,"isWatching":false},"created":"2012-12-05T09:00:27.572+0000","customfield_12310192":null,"customfield_12310191":[{"self":"https://issues.apache.org/jira/rest/api/2/customFieldOption/10343","value":"Reviewed","id":"10343"}],"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/4","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/minor.svg","name":"Minor","id":"4"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"6.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12323313","id":"12323313","description":"0.23.5 release","name":"0.23.5","archived":false,"released":true,"releaseDate":"2012-11-29"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12335732","id":"12335732","description":"3.0.0-alpha1 release","name":"3.0.0-alpha1","archived":false,"released":true,"releaseDate":"2016-09-03"}],"issuelinks":[],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dagit","name":"dagit","key":"dagit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dagit&avatarId=25742","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dagit&avatarId=25742","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dagit&avatarId=25742","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dagit&avatarId=25742"},"displayName":"Derek Dagit","active":true,"timeZone":"America/Chicago"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2016-05-12T18:16:00.948+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12312926","id":"12312926","name":"namenode"}],"timeoriginalestimate":null,"description":"Blocks that have been identified as under-replicated are placed on one of several priority queues.  The highest priority queue is essentially reserved for situations in which only one replica of the block exists, meaning it should be replicated ASAP.\n\nThe ReplicationMonitor periodically computes replication work, and a call to BlockManager#chooseUnderReplicatedBlocks selects a given number of under-replicated blocks, choosing blocks from the highest-priority queue first and working down to the lowest priority queue.\n\nIn the subsequent call to BlockManager#computeReplicationWorkForBlocks, a source for the replication is chosen from among datanodes that have an available copy of the block needed.  This is done in BlockManager#chooseSourceDatanode.\n\n\nchooseSourceDatanode's job is to choose the datanode for replication.  It chooses a random datanode from the available datanodes that has not reached its replication limit (preferring datanodes that are currently decommissioning).\n\nHowever, the priority queue of the block does not inform the logic.  If a datanode holds the last remaining replica of a block and has already reached its replication limit, the node is dismissed outright and the replication is not scheduled.\n\nIn some situations, this could lead to data loss, as the last remaining replica could disappear if an opportunity is not taken to schedule a replication.  It would be better to waive the max replication limit in cases of highest-priority block replication.\n","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12323274","id":"12323274","description":"2.0.3-alpha release","name":"2.0.3-alpha","archived":false,"released":true,"releaseDate":"2013-02-14"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12323503","id":"12323503","description":"0.23.6 release","name":"0.23.6","archived":false,"released":true,"releaseDate":"2013-02-06"}],"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12561923","id":"12561923","filename":"HDFS-4270.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dagit","name":"dagit","key":"dagit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dagit&avatarId=25742","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dagit&avatarId=25742","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dagit&avatarId=25742","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dagit&avatarId=25742"},"displayName":"Derek Dagit","active":true,"timeZone":"America/Chicago"},"created":"2012-12-20T16:34:01.071+0000","size":11076,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12561923/HDFS-4270.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12560368","id":"12560368","filename":"HDFS-4270.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dagit","name":"dagit","key":"dagit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dagit&avatarId=25742","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dagit&avatarId=25742","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dagit&avatarId=25742","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dagit&avatarId=25742"},"displayName":"Derek Dagit","active":true,"timeZone":"America/Chicago"},"created":"2012-12-11T07:51:16.263+0000","size":7125,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12560368/HDFS-4270.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12560296","id":"12560296","filename":"HDFS-4270.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dagit","name":"dagit","key":"dagit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dagit&avatarId=25742","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dagit&avatarId=25742","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dagit&avatarId=25742","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dagit&avatarId=25742"},"displayName":"Derek Dagit","active":true,"timeZone":"America/Chicago"},"created":"2012-12-10T22:50:47.335+0000","size":7125,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12560296/HDFS-4270.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12556116","id":"12556116","filename":"HDFS-4270.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dagit","name":"dagit","key":"dagit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dagit&avatarId=25742","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dagit&avatarId=25742","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dagit&avatarId=25742","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dagit&avatarId=25742"},"displayName":"Derek Dagit","active":true,"timeZone":"America/Chicago"},"created":"2012-12-05T17:23:47.179+0000","size":7125,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12556116/HDFS-4270.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12561918","id":"12561918","filename":"HDFS-4270-branch-0.23.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dagit","name":"dagit","key":"dagit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dagit&avatarId=25742","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dagit&avatarId=25742","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dagit&avatarId=25742","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dagit&avatarId=25742"},"displayName":"Derek Dagit","active":true,"timeZone":"America/Chicago"},"created":"2012-12-20T16:33:50.188+0000","size":10629,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12561918/HDFS-4270-branch-0.23.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12556115","id":"12556115","filename":"HDFS-4270-branch-0.23.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dagit","name":"dagit","key":"dagit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dagit&avatarId=25742","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dagit&avatarId=25742","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dagit&avatarId=25742","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dagit&avatarId=25742"},"displayName":"Derek Dagit","active":true,"timeZone":"America/Chicago"},"created":"2012-12-05T17:23:32.703+0000","size":6639,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12556115/HDFS-4270-branch-0.23.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"232444","customfield_12312823":null,"summary":"Replications of the highest priority should be allowed to choose a source datanode that has reached its max replication limit","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dagit","name":"dagit","key":"dagit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dagit&avatarId=25742","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dagit&avatarId=25742","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dagit&avatarId=25742","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dagit&avatarId=25742"},"displayName":"Derek Dagit","active":true,"timeZone":"America/Chicago"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dagit","name":"dagit","key":"dagit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dagit&avatarId=25742","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dagit&avatarId=25742","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dagit&avatarId=25742","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dagit&avatarId=25742"},"displayName":"Derek Dagit","active":true,"timeZone":"America/Chicago"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12618845/comment/13510608","id":"13510608","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dagit","name":"dagit","key":"dagit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dagit&avatarId=25742","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dagit&avatarId=25742","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dagit&avatarId=25742","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dagit&avatarId=25742"},"displayName":"Derek Dagit","active":true,"timeZone":"America/Chicago"},"body":"New patches add a second assert to the test, and fix some formatting/readability issues.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dagit","name":"dagit","key":"dagit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dagit&avatarId=25742","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dagit&avatarId=25742","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dagit&avatarId=25742","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dagit&avatarId=25742"},"displayName":"Derek Dagit","active":true,"timeZone":"America/Chicago"},"created":"2012-12-05T17:24:36.792+0000","updated":"2012-12-05T17:24:36.792+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12618845/comment/13510699","id":"13510699","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=atm","name":"atm","key":"atm","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=atm&avatarId=14136","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=atm&avatarId=14136","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=atm&avatarId=14136","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=atm&avatarId=14136"},"displayName":"Aaron T. Myers","active":true,"timeZone":"America/Los_Angeles"},"body":"Marking patch available for Derek so that test-patch runs.\n\nDerek - minor thing, but please don't set the \"fix versions\" field until the patch is actually committed. Before then, setting the affects/targets versions fields is sufficient.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=atm","name":"atm","key":"atm","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=atm&avatarId=14136","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=atm&avatarId=14136","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=atm&avatarId=14136","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=atm&avatarId=14136"},"displayName":"Aaron T. Myers","active":true,"timeZone":"America/Los_Angeles"},"created":"2012-12-05T19:21:39.390+0000","updated":"2012-12-05T19:21:39.390+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12618845/comment/13510708","id":"13510708","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"body":"I think we still need a limit for highest priority replications. Otherwise, there could be a large number of replications schedule to a datanode and then nothing can be done.  How about adding a (hard) limit for highest priority replication?  The current conf is a soft limit.  Only highest priority replications can pass the it.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2012-12-05T19:28:49.701+0000","updated":"2012-12-05T19:28:49.701+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12618845/comment/13510997","id":"13510997","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12556116/HDFS-4270.patch\n  against trunk revision .\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:red}-1 javadoc{color}.  The javadoc tool appears to have generated -6 warning messages.\n\n    {color:red}-1 eclipse:eclipse{color}.  The patch failed to build with eclipse:eclipse.\n\n    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:\n\n                  org.apache.hadoop.hdfs.server.namenode.TestEditLog\n\n    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/3600//testReport/\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/3600//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2012-12-06T01:07:39.386+0000","updated":"2012-12-06T01:07:39.386+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12618845/comment/13511433","id":"13511433","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=daryn","name":"daryn","key":"daryn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Daryn Sharp","active":true,"timeZone":"America/Chicago"},"body":"I don't fully understand this subsystem, but I'm a bit torn over limiting the \"only 1 block left\" replications.  This _should_ be a rare event, but it's a critical situation when it does.  I'm unclear if the max repls is compared against inflight or queued repls.  If the latter, perhaps higher prio blocks should displace already queued blocks for that DN?  If the \"only 1 block left\" repls are subjected to a new hard limit, is there an issue with how quickly the monitor will cycle back to schedule the critical blocks?\n\nBased on an actual incident: we lost most of a rack, then just so happened to lose the third DN before replication occurred.  A lot of nodes were being decommissioned, which appears to have delayed replication after the first DN was lost and again after the second DN on the rack was lost.  The third DN's disk with the remaining replica died hours later, and was decommissioned with no notification that the block was lost.  There may be more bugs involved, but this seemed like an obvious fix to mitigate the risk.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=daryn","name":"daryn","key":"daryn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Daryn Sharp","active":true,"timeZone":"America/Chicago"},"created":"2012-12-06T14:53:25.166+0000","updated":"2012-12-06T14:53:25.166+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12618845/comment/13511534","id":"13511534","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dagit","name":"dagit","key":"dagit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dagit&avatarId=25742","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dagit&avatarId=25742","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dagit&avatarId=25742","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dagit&avatarId=25742"},"displayName":"Derek Dagit","active":true,"timeZone":"America/Chicago"},"body":"Hi Aaron,\n\nNoted.  I meant to remove the entries in fixed, but I must have forgot.  I'll try not to do that in the future.\n\n\n\nHi Nicholas,\n\nI do see the concern over making this case unbounded, for the sake of the NN.\n\nI am interested, historically why was the default limit set to 2?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dagit","name":"dagit","key":"dagit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dagit&avatarId=25742","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dagit&avatarId=25742","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dagit&avatarId=25742","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dagit&avatarId=25742"},"displayName":"Derek Dagit","active":true,"timeZone":"America/Chicago"},"created":"2012-12-06T17:27:00.976+0000","updated":"2012-12-06T17:27:00.976+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12618845/comment/13511535","id":"13511535","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dagit","name":"dagit","key":"dagit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dagit&avatarId=25742","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dagit&avatarId=25742","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dagit&avatarId=25742","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dagit&avatarId=25742"},"displayName":"Derek Dagit","active":true,"timeZone":"America/Chicago"},"body":"Canceling patch for now.\n\nLater after discussion, I'll fix the errors and upload new patches.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dagit","name":"dagit","key":"dagit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dagit&avatarId=25742","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dagit&avatarId=25742","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dagit&avatarId=25742","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dagit&avatarId=25742"},"displayName":"Derek Dagit","active":true,"timeZone":"America/Chicago"},"created":"2012-12-06T17:27:46.887+0000","updated":"2012-12-06T17:27:46.887+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12618845/comment/13527370","id":"13527370","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"body":"> ..., historically why was the default limit set to 2?\n\nI actually don't know why the default is 2.  Let me check.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2012-12-09T08:22:05.935+0000","updated":"2012-12-09T08:22:05.935+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12618845/comment/13528392","id":"13528392","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dagit","name":"dagit","key":"dagit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dagit&avatarId=25742","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dagit&avatarId=25742","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dagit&avatarId=25742","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dagit&avatarId=25742"},"displayName":"Derek Dagit","active":true,"timeZone":"America/Chicago"},"body":"Manually ran eclipse:eclipse -> works for me\n\nManually ran TestEditLog.testFuzzSequences -> passes for me\n\nJavadoc error was a build error: connection timed out while fetching a dependency.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dagit","name":"dagit","key":"dagit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dagit&avatarId=25742","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dagit&avatarId=25742","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dagit&avatarId=25742","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dagit&avatarId=25742"},"displayName":"Derek Dagit","active":true,"timeZone":"America/Chicago"},"created":"2012-12-10T22:47:55.388+0000","updated":"2012-12-10T22:47:55.388+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12618845/comment/13528395","id":"13528395","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dagit","name":"dagit","key":"dagit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dagit&avatarId=25742","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dagit&avatarId=25742","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dagit&avatarId=25742","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dagit&avatarId=25742"},"displayName":"Derek Dagit","active":true,"timeZone":"America/Chicago"},"body":"Re-attaching patch, as the errors reported by the bot appear to be transient.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dagit","name":"dagit","key":"dagit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dagit&avatarId=25742","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dagit&avatarId=25742","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dagit&avatarId=25742","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dagit&avatarId=25742"},"displayName":"Derek Dagit","active":true,"timeZone":"America/Chicago"},"created":"2012-12-10T22:50:47.338+0000","updated":"2012-12-10T22:50:47.338+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12618845/comment/13528552","id":"13528552","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12560296/HDFS-4270.patch\n  against trunk revision .\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:\n\n                  org.apache.hadoop.hdfs.server.balancer.TestBalancerWithNodeGroup\n\n    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/3632//testReport/\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/3632//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2012-12-11T01:09:49.586+0000","updated":"2012-12-11T01:09:49.586+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12618845/comment/13528773","id":"13528773","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dagit","name":"dagit","key":"dagit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dagit&avatarId=25742","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dagit&avatarId=25742","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dagit&avatarId=25742","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dagit&avatarId=25742"},"displayName":"Derek Dagit","active":true,"timeZone":"America/Chicago"},"body":"Reattaching patch again.  The balancer test failure looks like another spurious result.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dagit","name":"dagit","key":"dagit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dagit&avatarId=25742","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dagit&avatarId=25742","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dagit&avatarId=25742","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dagit&avatarId=25742"},"displayName":"Derek Dagit","active":true,"timeZone":"America/Chicago"},"created":"2012-12-11T07:51:16.266+0000","updated":"2012-12-11T07:51:16.266+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12618845/comment/13528843","id":"13528843","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:green}+1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12560368/HDFS-4270.patch\n  against trunk revision .\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.\n\n    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/3634//testReport/\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/3634//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2012-12-11T09:43:25.424+0000","updated":"2012-12-11T09:43:25.424+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12618845/comment/13531452","id":"13531452","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dagit","name":"dagit","key":"dagit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dagit&avatarId=25742","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dagit&avatarId=25742","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dagit&avatarId=25742","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dagit&avatarId=25742"},"displayName":"Derek Dagit","active":true,"timeZone":"America/Chicago"},"body":"If we consider a hard limit, what should the limit be?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dagit","name":"dagit","key":"dagit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dagit&avatarId=25742","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dagit&avatarId=25742","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dagit&avatarId=25742","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dagit&avatarId=25742"},"displayName":"Derek Dagit","active":true,"timeZone":"America/Chicago"},"created":"2012-12-13T20:40:15.178+0000","updated":"2012-12-13T20:40:15.178+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12618845/comment/13531652","id":"13531652","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"body":"How about making it configurable and setting the default to 4?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2012-12-13T23:47:26.303+0000","updated":"2012-12-13T23:47:26.303+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12618845/comment/13537135","id":"13537135","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dagit","name":"dagit","key":"dagit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dagit&avatarId=25742","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dagit&avatarId=25742","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dagit&avatarId=25742","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dagit&avatarId=25742"},"displayName":"Derek Dagit","active":true,"timeZone":"America/Chicago"},"body":"New hard-limit config, defaults to 4.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dagit","name":"dagit","key":"dagit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dagit&avatarId=25742","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dagit&avatarId=25742","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dagit&avatarId=25742","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dagit&avatarId=25742"},"displayName":"Derek Dagit","active":true,"timeZone":"America/Chicago"},"created":"2012-12-20T16:33:50.191+0000","updated":"2012-12-20T16:33:50.191+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12618845/comment/13537138","id":"13537138","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dagit","name":"dagit","key":"dagit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dagit&avatarId=25742","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dagit&avatarId=25742","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dagit&avatarId=25742","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dagit&avatarId=25742"},"displayName":"Derek Dagit","active":true,"timeZone":"America/Chicago"},"body":"New hard-limit config, defaults to 4.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dagit","name":"dagit","key":"dagit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dagit&avatarId=25742","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dagit&avatarId=25742","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dagit&avatarId=25742","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dagit&avatarId=25742"},"displayName":"Derek Dagit","active":true,"timeZone":"America/Chicago"},"created":"2012-12-20T16:34:01.074+0000","updated":"2012-12-20T16:34:01.074+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12618845/comment/13537244","id":"13537244","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:green}+1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12561923/HDFS-4270.patch\n  against trunk revision .\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.\n\n    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/3684//testReport/\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/3684//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2012-12-20T18:40:12.054+0000","updated":"2012-12-20T18:40:12.054+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12618845/comment/13543590","id":"13543590","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"body":"+1 patch looks good.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-01-04T04:26:33.278+0000","updated":"2013-01-04T04:26:33.278+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12618845/comment/13543692","id":"13543692","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"body":"I have committed this.  Thanks, Derek!","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-01-04T08:14:30.274+0000","updated":"2013-01-04T08:14:30.274+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12618845/comment/13543695","id":"13543695","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"Integrated in Hadoop-trunk-Commit #3174 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/3174/])\n    HDFS-4270. Introduce soft and hard limits for max replication so that replications of the highest priority are allowed to choose a source datanode that has reached its soft limit but not the hard limit.  Contributed by Derek Dagit (Revision 1428739)\n\n     Result = FAILURE\nszetszwo : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1428739\nFiles : \n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSConfigKeys.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestBlockManager.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2013-01-04T08:17:23.196+0000","updated":"2013-01-04T08:17:23.196+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12618845/comment/13543771","id":"13543771","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"Integrated in Hadoop-Yarn-trunk #86 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/86/])\n    HDFS-4270. Introduce soft and hard limits for max replication so that replications of the highest priority are allowed to choose a source datanode that has reached its soft limit but not the hard limit.  Contributed by Derek Dagit (Revision 1428739)\n\n     Result = FAILURE\nszetszwo : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1428739\nFiles : \n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSConfigKeys.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestBlockManager.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2013-01-04T10:32:40.395+0000","updated":"2013-01-04T10:32:40.395+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12618845/comment/13543862","id":"13543862","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"Integrated in Hadoop-Hdfs-trunk #1275 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1275/])\n    HDFS-4270. Introduce soft and hard limits for max replication so that replications of the highest priority are allowed to choose a source datanode that has reached its soft limit but not the hard limit.  Contributed by Derek Dagit (Revision 1428739)\n\n     Result = FAILURE\nszetszwo : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1428739\nFiles : \n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSConfigKeys.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestBlockManager.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2013-01-04T12:52:41.878+0000","updated":"2013-01-04T12:52:41.878+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12618845/comment/13543905","id":"13543905","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"Integrated in Hadoop-Mapreduce-trunk #1305 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1305/])\n    HDFS-4270. Introduce soft and hard limits for max replication so that replications of the highest priority are allowed to choose a source datanode that has reached its soft limit but not the hard limit.  Contributed by Derek Dagit (Revision 1428739)\n\n     Result = SUCCESS\nszetszwo : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1428739\nFiles : \n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSConfigKeys.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestBlockManager.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2013-01-04T14:03:56.978+0000","updated":"2013-01-04T14:03:56.978+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12618845/comment/13543916","id":"13543916","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tgraves","name":"tgraves","key":"tgraves","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Thomas Graves","active":true,"timeZone":"America/Chicago"},"body":"I pulled this into branch-0.23","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tgraves","name":"tgraves","key":"tgraves","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Thomas Graves","active":true,"timeZone":"America/Chicago"},"created":"2013-01-04T14:29:26.220+0000","updated":"2013-01-04T14:29:26.220+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12618845/comment/13544687","id":"13544687","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"Integrated in Hadoop-Hdfs-0.23-Build #485 (See [https://builds.apache.org/job/Hadoop-Hdfs-0.23-Build/485/])\n    HDFS-4270. Replications of the highest priority should be allowed to choose a source datanode that has reached its max replication limit (Derek Dagit via tgraves) (Revision 1428883)\n\n     Result = FAILURE\ntgraves : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1428883\nFiles : \n* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt\n* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSConfigKeys.java\n* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java\n* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestBlockManager.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2013-01-05T12:36:21.539+0000","updated":"2013-01-05T12:36:21.539+0000"}],"maxResults":26,"total":26,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-4270/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i1461z:"}}