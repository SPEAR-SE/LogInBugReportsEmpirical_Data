{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"13084489","self":"https://issues.apache.org/jira/rest/api/2/issue/13084489","key":"HDFS-12082","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12334218","id":"12334218","description":"2.9.0 release","name":"2.9.0","archived":false,"released":true,"releaseDate":"2017-11-17"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12335737","id":"12335737","description":"3.0.0-beta1 release","name":"3.0.0-beta1","archived":false,"released":true,"releaseDate":"2017-10-03"}],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2017-07-04T16:04:42.406+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Tue Aug 01 06:41:04 UTC 2017","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_13597467_*|*_5_*:*_1_*:*_0_*|*_10002_*:*_1_*:*_2349584583","customfield_12312321":null,"resolutiondate":"2017-07-31T18:36:44.658+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-12082/watchers","watchCount":4,"isWatching":false},"created":"2017-07-04T10:10:22.688+0000","customfield_12310192":null,"customfield_12310191":[{"self":"https://issues.apache.org/jira/rest/api/2/customFieldOption/10343","value":"Reviewed","id":"10343"}],"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"4.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[],"issuelinks":[{"id":"12508302","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12508302","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"inwardIssue":{"id":"12478281","key":"HDFS-1477","self":"https://issues.apache.org/jira/rest/api/2/issue/12478281","fields":{"summary":"Support reconfiguring dfs.heartbeat.interval and dfs.namenode.heartbeat.recheck-interval without NN restart","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/7","id":"7","description":"The sub-task of the issue","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype","name":"Sub-task","subtask":true,"avatarId":21146}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cheersyang","name":"cheersyang","key":"cheersyang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cheersyang&avatarId=23772","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cheersyang&avatarId=23772","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cheersyang&avatarId=23772","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cheersyang&avatarId=23772"},"displayName":"Weiwei Yang","active":true,"timeZone":"Asia/Shanghai"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2017-08-01T06:41:04.191+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12329603","id":"12329603","name":"hdfs"},{"self":"https://issues.apache.org/jira/rest/api/2/component/12312926","id":"12312926","name":"namenode"}],"timeoriginalestimate":null,"description":"HDFS-1477 provides an option to reconfigured namenode heartbeat interval without restarting the namenode. When the heartbeat interval is reconfigured, {{blockInvalidateLimit}} gets recounted\n\n{code}\n this.blockInvalidateLimit = Math.max(20 * (int) (intervalSeconds),\n        DFSConfigKeys.DFS_BLOCK_INVALIDATE_LIMIT_DEFAULT);\n{code}\n\nthis doesn't honor the existing value set by {{dfs.block.invalidate.limit}}.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12875639","id":"12875639","filename":"HDFS-12082.001.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cheersyang","name":"cheersyang","key":"cheersyang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cheersyang&avatarId=23772","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cheersyang&avatarId=23772","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cheersyang&avatarId=23772","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cheersyang&avatarId=23772"},"displayName":"Weiwei Yang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-07-04T13:56:07.633+0000","size":4227,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12875639/HDFS-12082.001.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12875680","id":"12875680","filename":"HDFS-12082.002.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cheersyang","name":"cheersyang","key":"cheersyang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cheersyang&avatarId=23772","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cheersyang&avatarId=23772","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cheersyang&avatarId=23772","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cheersyang&avatarId=23772"},"displayName":"Weiwei Yang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-07-05T01:15:23.952+0000","size":4215,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12875680/HDFS-12082.002.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12876169","id":"12876169","filename":"HDFS-12082.003.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cheersyang","name":"cheersyang","key":"cheersyang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cheersyang&avatarId=23772","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cheersyang&avatarId=23772","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cheersyang&avatarId=23772","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cheersyang&avatarId=23772"},"displayName":"Weiwei Yang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-07-08T01:54:51.938+0000","size":5330,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12876169/HDFS-12082.003.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12879598","id":"12879598","filename":"HDFS-12082.004.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cheersyang","name":"cheersyang","key":"cheersyang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cheersyang&avatarId=23772","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cheersyang&avatarId=23772","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cheersyang&avatarId=23772","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cheersyang&avatarId=23772"},"displayName":"Weiwei Yang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-07-31T09:29:19.281+0000","size":5389,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12879598/HDFS-12082.004.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"BlockInvalidateLimit value is incorrectly set after namenode heartbeat interval reconfigured ","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cheersyang","name":"cheersyang","key":"cheersyang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cheersyang&avatarId=23772","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cheersyang&avatarId=23772","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cheersyang&avatarId=23772","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cheersyang&avatarId=23772"},"displayName":"Weiwei Yang","active":true,"timeZone":"Asia/Shanghai"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cheersyang","name":"cheersyang","key":"cheersyang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cheersyang&avatarId=23772","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cheersyang&avatarId=23772","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cheersyang&avatarId=23772","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cheersyang&avatarId=23772"},"displayName":"Weiwei Yang","active":true,"timeZone":"Asia/Shanghai"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/13084489/comment/16073760","id":"16073760","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cheersyang","name":"cheersyang","key":"cheersyang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cheersyang&avatarId=23772","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cheersyang&avatarId=23772","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cheersyang&avatarId=23772","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cheersyang&avatarId=23772"},"displayName":"Weiwei Yang","active":true,"timeZone":"Asia/Shanghai"},"body":"Proposed a patch to fix this issue. Otherwise if user reconfigures namenode interval, the value of property {{dfs.block.invalidate.limit}} will be always overwritten.\n\nThe fix simply honors the configuration of {{dfs.block.invalidate.limit}} and use it for block invalidate limit, and this will not change when heartbeat interval changes. Reason is, following formula doesn't really work\n\n{code}\n// Default heartbeat is 3s, unless heartbeat is set to bigger than 50s,\n// it is always 1000\n(1) final int blockInvalidateLimit = Math.max(20*(int)(heartbeatIntervalSeconds),\n          DFSConfigKeys.DFS_BLOCK_INVALIDATE_LIMIT_DEFAULT);\n\n// We will not reach the default value here, because we always load defaults\n// from hdfs-default.xml. If the property is not found in hdfs-site.xml,\n// it simply returns the default value from hdfs-default.xml, which is 1000.\n// Even blockInvalidateLimit is something else, it doesn't count.\n(2) this.blockInvalidateLimit = conf.getInt(\n          DFSConfigKeys.DFS_BLOCK_INVALIDATE_LIMIT_KEY, blockInvalidateLimit);\n{code}\n\nso right now there are two cases\n# {{dfs.block.invalidate.limit}} not set explicitly, blockInvalidateLimit=1000\n# {{dfs.block.invalidate.limit}} is explicitly set, blockInvalidateLimit=<value_of_the_property>\n\nin this case, why we still need (1) ? I think we can remove it.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cheersyang","name":"cheersyang","key":"cheersyang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cheersyang&avatarId=23772","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cheersyang&avatarId=23772","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cheersyang&avatarId=23772","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cheersyang&avatarId=23772"},"displayName":"Weiwei Yang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-07-04T14:39:25.056+0000","updated":"2017-07-04T14:39:25.056+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13084489/comment/16073866","id":"16073866","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 18s{color} | {color:blue} Docker mode activated. {color} |\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 15m 53s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 51s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 37s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 53s{color} | {color:green} trunk passed {color} |\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  1m 39s{color} | {color:red} hadoop-hdfs-project/hadoop-hdfs in trunk has 10 extant Findbugs warnings. {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 41s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 48s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 44s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 44s{color} | {color:green} the patch passed {color} |\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 33s{color} | {color:orange} hadoop-hdfs-project/hadoop-hdfs: The patch generated 1 new + 41 unchanged - 2 fixed = 42 total (was 43) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 49s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 42s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 36s{color} | {color:green} the patch passed {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 68m  1s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 23s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black} 95m 48s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| Failed junit tests | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure070 |\n|   | hadoop.hdfs.server.blockmanagement.TestRBWBlockInvalidation |\n|   | hadoop.hdfs.server.blockmanagement.TestUnderReplicatedBlocks |\n|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:14b5c93 |\n| JIRA Issue | HDFS-12082 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12875639/HDFS-12082.001.patch |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux f3b258454320 3.13.0-116-generic #163-Ubuntu SMP Fri Mar 31 14:13:22 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / b17e655 |\n| Default Java | 1.8.0_131 |\n| findbugs | v3.1.0-RC1 |\n| findbugs | https://builds.apache.org/job/PreCommit-HDFS-Build/20153/artifact/patchprocess/branch-findbugs-hadoop-hdfs-project_hadoop-hdfs-warnings.html |\n| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/20153/artifact/patchprocess/diff-checkstyle-hadoop-hdfs-project_hadoop-hdfs.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/20153/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |\n|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/20153/testReport/ |\n| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/20153/console |\n| Powered by | Apache Yetus 0.5.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2017-07-04T16:04:42.406+0000","updated":"2017-07-04T16:04:42.406+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13084489/comment/16074182","id":"16074182","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 12s{color} | {color:blue} Docker mode activated. {color} |\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 13m 52s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 47s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 36s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 53s{color} | {color:green} trunk passed {color} |\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  1m 39s{color} | {color:red} hadoop-hdfs-project/hadoop-hdfs in trunk has 10 extant Findbugs warnings. {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 39s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 48s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 45s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 45s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 33s{color} | {color:green} hadoop-hdfs-project/hadoop-hdfs: The patch generated 0 new + 41 unchanged - 2 fixed = 41 total (was 43) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 50s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 46s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 38s{color} | {color:green} the patch passed {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 66m 47s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 24s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black} 92m 25s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| Failed junit tests | hadoop.hdfs.server.blockmanagement.TestUnderReplicatedBlocks |\n|   | hadoop.hdfs.server.datanode.TestDataNodeErasureCodingMetrics |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure150 |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:14b5c93 |\n| JIRA Issue | HDFS-12082 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12875680/HDFS-12082.002.patch |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux 00247461dc88 3.13.0-119-generic #166-Ubuntu SMP Wed May 3 12:18:55 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / b17e655 |\n| Default Java | 1.8.0_131 |\n| findbugs | v3.1.0-RC1 |\n| findbugs | https://builds.apache.org/job/PreCommit-HDFS-Build/20155/artifact/patchprocess/branch-findbugs-hadoop-hdfs-project_hadoop-hdfs-warnings.html |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/20155/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |\n|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/20155/testReport/ |\n| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/20155/console |\n| Powered by | Apache Yetus 0.5.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2017-07-05T02:50:57.932+0000","updated":"2017-07-05T02:50:57.932+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13084489/comment/16078770","id":"16078770","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vagarychen","name":"vagarychen","key":"vagarychen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chen Liang","active":true,"timeZone":"America/Los_Angeles"},"body":"Thansk [~cheersyang] for reporting this!\n\nI'm a little confused about the patch though. When reading the description, I was thinking the change is probably that, when {{setHeartbeatInterval}} is called, instead of \n{{blockInvalidateLimit = Math.max(20 * (int) (intervalSeconds), DFSConfigKeys.DFS_BLOCK_INVALIDATE_LIMIT_DEFAULT);}}\nwe change it to something like\n{{blockInvalidateLimit = Math.max(20 * (int) (intervalSeconds), configuredLimit);}}\nwhere {{final int configuredLimit = conf.getInt(DFSConfigKeys.DFS_BLOCK_INVALIDATE_LIMIT_KEY, DFSConfigKeys.DFS_BLOCK_INVALIDATE_LIMIT_DEFAULT);}}\n\nBut seems the patch removed this part completely. It seems to me in this case {{blockInvalidateLimit}} will be set to configured value at the start once and will no longer change when {{setHeartbeatInterval}} gets called. Is this the desired behaviour? because the original code seems to have the syntax guarantee that no matter how {{setHeartbeatInterval}} gets called, {{blockInvalidateLimit}} will never be larger than 20x {{intervalSeconds}}, and it appears that this will not be guaranteed with the patch.\n\nAn addition minor comment, in the unit test, how about changing {{\"\" + 6}} to {{Integer.toString(6)}}?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vagarychen","name":"vagarychen","key":"vagarychen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chen Liang","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-07-07T22:07:47.184+0000","updated":"2017-07-07T22:07:47.184+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13084489/comment/16078904","id":"16078904","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cheersyang","name":"cheersyang","key":"cheersyang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cheersyang&avatarId=23772","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cheersyang&avatarId=23772","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cheersyang&avatarId=23772","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cheersyang&avatarId=23772"},"displayName":"Weiwei Yang","active":true,"timeZone":"Asia/Shanghai"},"body":"Hi [~vagarychen]\n\nThanks for helping to review this. You are making a good point. Second thought, I think it is better to ensure the effected invalidate block limit is the bigger one of configured value in hdfs-site.xml and 20*HB_interval.  This will ensure we don't throttle the block deletion too much on datanodes. I have revised the patch to do so. Please let me know if v3 patch makes sense to you. Thanks.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cheersyang","name":"cheersyang","key":"cheersyang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cheersyang&avatarId=23772","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cheersyang&avatarId=23772","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cheersyang&avatarId=23772","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cheersyang&avatarId=23772"},"displayName":"Weiwei Yang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-07-08T01:57:40.813+0000","updated":"2017-07-08T01:57:40.813+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13084489/comment/16078926","id":"16078926","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m  9s{color} | {color:blue} Docker mode activated. {color} |\n|| || || || {color:brown} Prechecks {color} ||\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |\n|| || || || {color:brown} trunk Compile Tests {color} ||\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 13m  7s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 48s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 35s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 54s{color} | {color:green} trunk passed {color} |\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  1m 37s{color} | {color:red} hadoop-hdfs-project/hadoop-hdfs in trunk has 10 extant Findbugs warnings. {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 40s{color} | {color:green} trunk passed {color} |\n|| || || || {color:brown} Patch Compile Tests {color} ||\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 47s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 45s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 45s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 33s{color} | {color:green} hadoop-hdfs-project/hadoop-hdfs: The patch generated 0 new + 41 unchanged - 2 fixed = 41 total (was 43) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 51s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 43s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 38s{color} | {color:green} the patch passed {color} |\n|| || || || {color:brown} Other Tests {color} ||\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 63m 37s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 19s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black} 88m 18s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| Failed junit tests | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure080 |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:14b5c93 |\n| JIRA Issue | HDFS-12082 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12876169/HDFS-12082.003.patch |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux e7abd3ea0994 3.13.0-119-generic #166-Ubuntu SMP Wed May 3 12:18:55 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / f484a6f |\n| Default Java | 1.8.0_131 |\n| findbugs | v3.1.0-RC1 |\n| findbugs | https://builds.apache.org/job/PreCommit-HDFS-Build/20197/artifact/patchprocess/branch-findbugs-hadoop-hdfs-project_hadoop-hdfs-warnings.html |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/20197/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |\n|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/20197/testReport/ |\n| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/20197/console |\n| Powered by | Apache Yetus 0.5.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2017-07-08T03:26:40.910+0000","updated":"2017-07-08T03:26:40.910+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13084489/comment/16080714","id":"16080714","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vagarychen","name":"vagarychen","key":"vagarychen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chen Liang","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks [~cheersyang] for the update! +1 on v003 patch ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vagarychen","name":"vagarychen","key":"vagarychen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chen Liang","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-07-10T17:36:49.856+0000","updated":"2017-07-10T17:36:49.856+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13084489/comment/16105827","id":"16105827","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=arpitagarwal","name":"arpitagarwal","key":"arpitagarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arpit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi [~cheersyang], thanks for reporting this and working on the fix.\n\nThere is a change in the default behavior on startup which looks unnecessary.\n\nThe previous formula for computing the limit on process startup was:\n# Use dfs.block.invalidate.limit if configured.\n# Else, use the max(20 * heartbeatInterval, DFS_BLOCK_INVALIDATE_LIMIT_DEFAULT).\n\nWith your patch this has effectively changed to:\n# Use the max(20 * heartbeatInterval, dfs.block.invalidate.limit) if dfs.block.invalidate.limit is configured.\n# Else, use 20*heartbeatInterval.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=arpitagarwal","name":"arpitagarwal","key":"arpitagarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arpit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-07-28T22:57:23.518+0000","updated":"2017-07-28T22:57:23.518+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13084489/comment/16107026","id":"16107026","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cheersyang","name":"cheersyang","key":"cheersyang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cheersyang&avatarId=23772","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cheersyang&avatarId=23772","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cheersyang&avatarId=23772","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cheersyang&avatarId=23772"},"displayName":"Weiwei Yang","active":true,"timeZone":"Asia/Shanghai"},"body":"Hi [~arpitagarwal]\n\nThanks for looking at this issue. This issue is a bit complex than it looks to be, please allow me to explain. \n\nBasically this is because following code isn't exactly working as expected,\n\n{code}\nthis.blockInvalidateLimit = conf.getInt(\n        DFSConfigKeys.DFS_BLOCK_INVALIDATE_LIMIT_KEY, blockInvalidateLimit);\n{code}\n\n*expected*:\n# Use the value of {{dfs.block.invalidate.limit}} from hdfs-site.xml if set\n# If {{dfs.block.invalidate.limit}} is not set in hdfs-site.xml, use max(20 * HBInterval, 1000)\n(like you mentioned)\n\nhowever in *actual*, it behaves like following\n# Use the value of {{dfs.block.invalidate.limit}} from hdfs-site.xml if set\n# Use the value of {{dfs.block.invalidate.limit}} in hdfs-default.xml if it is not set in hdfs-site.xml\n\nit will NEVER return the default value given by argument {{blockInvalidateLimit}} in cluster env, because we always ship {{hdfs-default.xml}} in hdfs jar file, that contains property {{dfs.block.invalidate.limit=1000}}.\n\nThe logic in my patch is (please check v4 patch, there was 1 line error in v3 patch)\n\nFind the bigger value from configuration files (first hdfs-site.xml then back off to hdfs-default.xml) and compare it with 20*HB_interval, use the bigger one as the effective value for the invalidate limit. This will ensure that user won't throttle the block deletion too much for datanodes (even after HB interval is reconfigured). For example, if HB is 60s, we don't want to let user to set the limit to less than 1200, otherwise the block deletion will be too slow.\n\nIt might be possible to fix this in another way round, by respecting to its \"original\" idea, but that will need to add a method in Configuration class to tell if a property is configured by user (use getPropertySources?). A bit over complex?\n\nPlease let me know your thought.\n\nThanks","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cheersyang","name":"cheersyang","key":"cheersyang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cheersyang&avatarId=23772","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cheersyang&avatarId=23772","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cheersyang&avatarId=23772","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cheersyang&avatarId=23772"},"displayName":"Weiwei Yang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-07-31T09:26:50.845+0000","updated":"2017-07-31T09:30:58.495+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13084489/comment/16107152","id":"16107152","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 17s{color} | {color:blue} Docker mode activated. {color} |\n|| || || || {color:brown} Prechecks {color} ||\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |\n|| || || || {color:brown} trunk Compile Tests {color} ||\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 15m  1s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 54s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 38s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  2s{color} | {color:green} trunk passed {color} |\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  1m 49s{color} | {color:red} hadoop-hdfs-project/hadoop-hdfs in trunk has 10 extant Findbugs warnings. {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 42s{color} | {color:green} trunk passed {color} |\n|| || || || {color:brown} Patch Compile Tests {color} ||\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 57s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 53s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 53s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 36s{color} | {color:green} hadoop-hdfs-project/hadoop-hdfs: The patch generated 0 new + 41 unchanged - 2 fixed = 41 total (was 43) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 57s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 55s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 42s{color} | {color:green} the patch passed {color} |\n|| || || || {color:brown} Other Tests {color} ||\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 67m 58s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 15s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black} 95m 57s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| Failed junit tests | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure150 |\n|   | hadoop.hdfs.server.blockmanagement.TestUnderReplicatedBlocks |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure010 |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailureWithRandomECPolicy |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure080 |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:14b5c93 |\n| JIRA Issue | HDFS-12082 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12879598/HDFS-12082.004.patch |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux 43238c93cee9 3.13.0-116-generic #163-Ubuntu SMP Fri Mar 31 14:13:22 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / 0fd6d0f |\n| Default Java | 1.8.0_131 |\n| findbugs | v3.1.0-RC1 |\n| findbugs | https://builds.apache.org/job/PreCommit-HDFS-Build/20496/artifact/patchprocess/branch-findbugs-hadoop-hdfs-project_hadoop-hdfs-warnings.html |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/20496/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |\n|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/20496/testReport/ |\n| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/20496/console |\n| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2017-07-31T11:14:41.856+0000","updated":"2017-07-31T11:14:41.856+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13084489/comment/16107738","id":"16107738","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=arpitagarwal","name":"arpitagarwal","key":"arpitagarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arpit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks [~cheersyang]. The v4 patch with the fix lgtm. Also thanks for adding a unit test.\n\nTestUnderReplicatedBlocks passed locally. I will commit your patch.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=arpitagarwal","name":"arpitagarwal","key":"arpitagarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arpit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-07-31T18:31:25.523+0000","updated":"2017-07-31T18:31:25.523+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13084489/comment/16107750","id":"16107750","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=arpitagarwal","name":"arpitagarwal","key":"arpitagarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arpit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"body":"I've committed this. Thanks for the contribution [~cheersyang] and thanks for the code review [~vagarychen].","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=arpitagarwal","name":"arpitagarwal","key":"arpitagarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arpit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-07-31T18:36:44.716+0000","updated":"2017-07-31T18:36:44.716+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13084489/comment/16107784","id":"16107784","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"SUCCESS: Integrated in Jenkins build Hadoop-trunk-Commit #12079 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/12079/])\nHDFS-12082. BlockInvalidateLimit value is incorrectly set after namenode (arp: rev 3e23415a92d43ce8818124f0b180227a52a33eaf)\n* (edit) hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestNameNodeReconfigure.java\n* (edit) hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2017-07-31T18:59:06.026+0000","updated":"2017-07-31T18:59:06.026+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13084489/comment/16108469","id":"16108469","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cheersyang","name":"cheersyang","key":"cheersyang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cheersyang&avatarId=23772","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cheersyang&avatarId=23772","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cheersyang&avatarId=23772","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cheersyang&avatarId=23772"},"displayName":"Weiwei Yang","active":true,"timeZone":"Asia/Shanghai"},"body":"Thanks [~arpiagariu] for the help :).","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cheersyang","name":"cheersyang","key":"cheersyang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cheersyang&avatarId=23772","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cheersyang&avatarId=23772","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cheersyang&avatarId=23772","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cheersyang&avatarId=23772"},"displayName":"Weiwei Yang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-08-01T06:41:04.191+0000","updated":"2017-08-01T06:41:04.191+0000"}],"maxResults":14,"total":14,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-12082/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i3h2k7:"}}