{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12627554","self":"https://issues.apache.org/jira/rest/api/2/issue/12627554","key":"HDFS-4403","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12323274","id":"12323274","description":"2.0.3-alpha release","name":"2.0.3-alpha","archived":false,"released":true,"releaseDate":"2013-02-14"}],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2013-01-15T04:48:14.104+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Tue Jan 22 14:04:57 UTC 2013","customfield_12310420":"304338","customfield_12312320":null,"customfield_12310222":"10002_*:*_1_*:*_604333465_*|*_1_*:*_1_*:*_6977749_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2013-01-22T02:59:50.621+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-4403/watchers","watchCount":11,"isWatching":false},"created":"2013-01-15T01:11:19.453+0000","customfield_12310192":"The HDFS implementation of getFileChecksum() can now operate correctly against earlier-version datanodes which do not include the checksum type information in their checksum response. The checksum type is automatically inferred by issuing a read of the first byte of each block.","customfield_12310191":[{"self":"https://issues.apache.org/jira/rest/api/2/customFieldOption/10343","value":"Reviewed","id":"10343"}],"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/4","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/minor.svg","name":"Minor","id":"4"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"2.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12322472","id":"12322472","description":"2.0.2-alpha release","name":"2.0.2-alpha","archived":false,"released":true,"releaseDate":"2012-10-09"}],"issuelinks":[],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2014-09-03T23:09:04.711+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12312928","id":"12312928","name":"hdfs-client"}],"timeoriginalestimate":null,"description":"HDFS-3177 added the checksum type to OpBlockChecksumResponseProto, but the new protobuf field is optional, with a default of CRC32. This means that this API, when used against an older cluster (like earlier 0.23 releases) will falsely return CRC32 even if that cluster has written files with CRC32C. This can cause issues for distcp, for example.\n\nInstead of defaulting the protobuf field to CRC32, we can leave it with no default, and if the OpBlockChecksumResponseProto has no checksum type set, the client can send OP_READ_BLOCK to read the first byte of the block, then grab the checksum type out of that response (which has always been present)","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12323274","id":"12323274","description":"2.0.3-alpha release","name":"2.0.3-alpha","archived":false,"released":true,"releaseDate":"2013-02-14"}],"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12565199","id":"12565199","filename":"hdfs-4403.txt","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2013-01-16T22:55:29.877+0000","size":13585,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12565199/hdfs-4403.txt"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12564863","id":"12564863","filename":"hdfs-4403.txt","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2013-01-15T03:07:18.004+0000","size":13088,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12564863/hdfs-4403.txt"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"252509","customfield_12312823":null,"summary":"DFSClient can infer checksum type when not provided by reading first byte","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12627554/comment/13553445","id":"13553445","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"Attached patch takes the following approach:\n\n- Remove the CRC32 default from the protobuf.\n- If the OP_BLOCK_CHECKSUM response doesn't include the checksum type, detect this:\n-- Re-connect to the same DN, and issue OP_READ_BLOCK for the first byte of the block.\n-- Extract the checksum type from the response\n\nGiven that this is a cross-version compatibility fix, it isn't really possible to make a reasonable functional test for it. However, the existing tests should keep this from regressing the non-cross-version case.\n\nI tested manually as follows:\n- Made a local branch off branch-2, and reverted HADOOP-9070, which was causing an IPC incompatibility (see discussion there for more details).\n- Cherry-picked HADOOP-9209 (shell command to see checksums)\n- Started a cluster from the Hadoop 2.0.0 release tarball\n\nWithout this patch:\n\n{code}\n$ ./bin/hadoop fs -checksum '/*'\n/issue  MD5-of-0MD5-of-512CRC32 000002000000000000000000b234aa05a75fed38536bda657b20bfcf\n/issue-crc32-old        MD5-of-0MD5-of-512CRC32 000002000000000000000000593b23e67a7477aab90e42e41478b321\n{code}\n\nIt shows both of these files as having CRC32 type checksums, which is not correct.\n\nWith the patch applied, I get the correct result:\n{code}\n$ ./bin/hadoop fs -checksum '/*'\n/issue  MD5-of-0MD5-of-512CRC32C        000002000000000000000000b234aa05a75fed38536bda657b20bfcf\n/issue-crc32-old        MD5-of-0MD5-of-512CRC32 000002000000000000000000593b23e67a7477aab90e42e41478b321\n{code}\n\n(note that it identifies CRC32C for the first of the two files, which is correct)\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2013-01-15T03:07:18.008+0000","updated":"2013-01-15T03:07:18.008+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12627554/comment/13553481","id":"13553481","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12564863/hdfs-4403.txt\n  against trunk revision .\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.\n                        Please justify why no new tests are needed for this patch.\n                        Also please list what manual steps were performed to verify this patch.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.\n\n        {color:red}-1 release audit{color}.  The applied patch generated 2 release audit warnings.\n\n    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.\n\n    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/3841//testReport/\nRelease audit warnings: https://builds.apache.org/job/PreCommit-HDFS-Build/3841//artifact/trunk/patchprocess/patchReleaseAuditProblems.txt\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/3841//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2013-01-15T04:48:14.104+0000","updated":"2013-01-15T04:48:14.104+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12627554/comment/13553500","id":"13553500","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"Release audit is due to HADOOP-9097. The lack of unit tests is justified above.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2013-01-15T05:24:09.299+0000","updated":"2013-01-15T05:24:09.299+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12627554/comment/13554083","id":"13554083","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sureshms","name":"sureshms","key":"sureshms","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10450","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10450","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10450","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10450"},"displayName":"Suresh Srinivas","active":true,"timeZone":"America/Los_Angeles"},"body":"Given the protobuf change where optional field no longer carries the previous default value, this should be marked incompatible?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sureshms","name":"sureshms","key":"sureshms","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10450","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10450","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10450","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10450"},"displayName":"Suresh Srinivas","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-01-15T18:22:26.670+0000","updated":"2013-01-15T18:22:26.670+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12627554/comment/13554175","id":"13554175","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"Hi Suresh. I don't see how that would be incompatible. You can add or remove defaults and maintain compatibility as far as I can imagine. What client/server combination would not work given this change?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2013-01-15T19:13:22.213+0000","updated":"2013-01-15T19:13:22.213+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12627554/comment/13554396","id":"13554396","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sureshms","name":"sureshms","key":"sureshms","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10450","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10450","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10450","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10450"},"displayName":"Suresh Srinivas","active":true,"timeZone":"America/Los_Angeles"},"body":"Prior to this change, the client always got default crcType in OpBlockChecksumResponseProto. The old client code just called getCrcType() without checking hasCrcType(). The old clients talking to new server with this change, get null pointer exception, if the new server does not set the crcType.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sureshms","name":"sureshms","key":"sureshms","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10450","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10450","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10450","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10450"},"displayName":"Suresh Srinivas","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-01-15T21:44:10.346+0000","updated":"2013-01-15T21:44:10.346+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12627554/comment/13554423","id":"13554423","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"bq. The old client code just called getCrcType() without checking hasCrcType(). The old clients talking to new server with this change, get null pointer exception, if the new server does not set the crcType\n\nThat's not how defaults work in protobuf -- the protobuf maintains a separate flag for \"hasFieldX\", which is set to false upon construction even if the field has a default. So, on the server side, if an optional field isn't explicitly set, it won't serialize the default of that field to the wire when it's serialized. That is to say, given that the field has always been optional, the case of a server not setting it will be handled the same regardless of whether or not it has a default.\n\nTo illustrate, I made the following test proto:\n{code}\nmessage MyTestProto {\n  optional string testField = 1 [ default = \"hello world\" ];\n}\n{code}\n\nAnd ran the following code:\n\n{code}\n    MyTestProto pb = MyTestProto.newBuilder().build();\n    System.err.println(\"has field? \" + pb.hasTestField());\n    System.err.println(\"field value: \" + pb.getTestField());\n    System.err.println(\"serialized: \" + StringUtils.byteToHexString(pb.toByteArray()));\n{code}\n\nOutput:\n\n{code}\nhas field? false\nfield value: hello world\nserialized: \n{code}\n\nNote how the default value isn't put on the \"wire\" when the protobuf is serialized to a byte array.\n\nSo, in your example, with the old clients talking to a new server which doesn't set crc type, the old clients would continue to use whatever default they'd defined locally.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2013-01-15T22:02:55.882+0000","updated":"2013-01-15T22:02:55.882+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12627554/comment/13554450","id":"13554450","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sureshms","name":"sureshms","key":"sureshms","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10450","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10450","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10450","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10450"},"displayName":"Suresh Srinivas","active":true,"timeZone":"America/Los_Angeles"},"body":"bq. So, in your example, with the old clients talking to a new server which doesn't set crc type, the old clients would continue to use whatever default they'd defined locally.\nMakes sense. So the old client when the field is not set uses CHECKSUM_CRC32.\n\nIs it possible that the server does not set the crcType and expects the client to infer the type. The checksum happens to be something other than CHECKSUM_CRC32. The old client treats it as CHECKSUM_CRC32 and runs into issues?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sureshms","name":"sureshms","key":"sureshms","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10450","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10450","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10450","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10450"},"displayName":"Suresh Srinivas","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-01-15T22:22:21.280+0000","updated":"2013-01-15T22:22:21.280+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12627554/comment/13554467","id":"13554467","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"bq. Is it possible that the server does not set the crcType and expects the client to infer the type. The checksum happens to be something other than CHECKSUM_CRC32. The old client treats it as CHECKSUM_CRC32 and runs into issues?\n\nThat's the bug this is trying to fix. If you currently run a newer 0.23-branch client against an earlier 0.23, or a 2.x branch (after making it IPC compatible) against 2.0.0, it will incorrectly report CHECKSUM_CRC32 back to the caller, even if the file is actually CHECKSUM_CRC32C. This results in distcp giving back errors about the copy failing due to checksum mismatch, etc.\n\nAny _new_ server always sets the checksum type explicitly, regardless of what type it is. It's only the old (pre-HDFS-3177) servers that wouldn't set one.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2013-01-15T22:38:09.073+0000","updated":"2013-01-15T22:38:09.073+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12627554/comment/13554477","id":"13554477","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sureshms","name":"sureshms","key":"sureshms","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10450","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10450","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10450","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10450"},"displayName":"Suresh Srinivas","active":true,"timeZone":"America/Los_Angeles"},"body":"bq. Any new server always sets the checksum type explicitly, regardless of what type it is. It's only the old (pre-HDFS-3177) servers that wouldn't set one.\nGiven that the field is optional, assuming that new server always sets the checksum type explicitly is an incorrect assumption. Only way to ensure that is by making the field required, right? One cannot prevent a future change where checksum type is not set (unless you or I review that change).","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sureshms","name":"sureshms","key":"sureshms","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10450","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10450","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10450","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10450"},"displayName":"Suresh Srinivas","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-01-15T22:47:13.155+0000","updated":"2013-01-15T22:47:13.155+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12627554/comment/13554484","id":"13554484","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"I don't really follow...\n\n'optional' is generally used in protobuf for adding new features compatibly. Old clients don't know about it, so they don't care. New clients already have to deal with old servers which don't set the field, so they have back-compat paths (like the one I'm adding here).\n\nIf there's an optional field, and a client assumes it's always set, then it's a bug, I agree. That's why the patch is calling hasChecksumType() here and going to a fallback (compatibility) path.\n\nIn this case, the options are:\n- old client, old server: there's a bug. We can't go back in time and change the code.\n- new client, new server: new server sets checksum type. new client reads it. Everything works great. (HDFS-3177)\n- new client, old server: old server doesn't set the type. HDFS-3177 set a default to CRC32, which wasn't correct. This patch instead fixes that to fallback to another (compatible) method to determine the type, rather than defaulting to some arbitrary choice.\n- old client, new server: new server sets type. old client ignores it. Again, can't go back in time to change the old client, but nothing breaks.\n\nIf in the future we change the server to not set a type, then it's our own fault that old clients wouldn't know what to do. That's just life. This is how you do versioning with protobuf: see the Language Guide at https://developers.google.com/protocol-buffers/docs/proto#updating :\n{quote}\nAny new fields that you add should be optional or repeated. This means that any messages serialized by code using your \"old\" message format can be parsed by your new generated code, as they won't be missing any required elements. You should set up sensible default values for these elements so that new code can properly interact with messages generated by old code. Similarly, messages created by your new code can be parsed by your old code: old binaries simply ignore the new field when parsing. However, the unknown fields are not discarded, and if the message is later serialized, the unknown fields are serialized along with it â€“ so if the message is passed on to new code, the new fields are still available. Note that preservation of unknown fields is currently not available for Python.\n{quote}\n\nHere there is no \"sensible default value\", so we use a \"sensible fallback code path\" instead.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2013-01-15T22:58:33.612+0000","updated":"2013-01-15T22:58:33.612+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12627554/comment/13554512","id":"13554512","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sureshms","name":"sureshms","key":"sureshms","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10450","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10450","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10450","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10450"},"displayName":"Suresh Srinivas","active":true,"timeZone":"America/Los_Angeles"},"body":"bq. old client, new server: new server sets type. old client ignores it. Again, can't go back in time to change the old client, but nothing breaks.\nIf the new server sets crcType, the old client does not ignore it. It does use the crcType sent by the server. If we can ensure new server always sets the crcType, there is no issue.\n\nLet me try to explain it better. May be I misunderstood the following comment: \nbq. Any new server always sets the checksum type explicitly, regardless of what type it is. It's only the old (pre-HDFS-3177) servers that wouldn't set one.\nHow do you ensure new server always sets the checksum type explicitly? What prevents a future (incorrect) change (say in 2.0.3) where server stops setting the crcType, because it is an optional field? In that case the old client (that had default value in proto definition) uses the default CRC type.\n\nI believe, the correct change is to make the crcType field required. That way:\n- old/new client talks to new server: new server always is forced to set the *required* field and old client/new clients use the crcType.\n- new client talks to old server: new clients infers the checksum type by reading first byte\n- old client and old server - cannot be solved as you described.\n\nMaking crcType required is not incompatible, given default value/explicitly set value was used by the old client.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sureshms","name":"sureshms","key":"sureshms","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10450","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10450","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10450","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10450"},"displayName":"Suresh Srinivas","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-01-15T23:25:29.709+0000","updated":"2013-01-15T23:25:29.709+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12627554/comment/13554527","id":"13554527","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"bq. new client talks to old server: new clients infers the checksum type by reading first byte\n\nIf you mark it 'required', then the new client will fail to deserialize a response from an old server, due to the missing field. To verify this, I changed my test protobuf above to make the field required, and tried to deserialize a byte array which didn't include the field using MyTestProto.parseFrom. It threw \"InvalidProtocolBufferException: Message missing required fields: testField\"\n\nBTW, the protobuf guide also talks about this specific case of changing the default:\n{quote}\nChanging a default value is generally OK, as long as you remember that default values are never sent over the wire. Thus, if a program receives a message in which a particular field isn't set, the program will see the default value as it was defined in that program's version of the protocol. It will NOT see the default value that was defined in the sender's code.\n{quote}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2013-01-15T23:42:31.375+0000","updated":"2013-01-15T23:42:31.375+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12627554/comment/13555542","id":"13555542","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"body":"{code}\n    * @param src The file path\n    * @return The checksum \n    */\n-  public static MD5MD5CRC32FileChecksum getFileChecksum(String src,\n+  static MD5MD5CRC32FileChecksum getFileChecksum(String src,\n+      String clientName,\n{code}\n\nNeed some JavaDoc about the new parameter, {{clientName}}.\n\n{code}\n-          final DataChecksum.Type ct = PBHelper.convert(checksumData\n-              .getCrcType());\n+          DataChecksum.Type ct;\n...\n{code}\n\nFor what it's worth, {{ct}} can still be {{final}} here (it only gets set once).\n\nI realize this isn't new with your change, but I find it kind of odd that the size of our *output* {{BufferedOutputStream}} is derived from the size of {{io.file.buffer.size}}.  Surely, these requests are small, and there's no reason to allocate a giant send buffer just because we wanted more file buffering?  Plus these are not \"file buffers\"-- we're not sending file data.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-01-16T22:30:12.235+0000","updated":"2013-01-16T22:30:12.235+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12627554/comment/13555566","id":"13555566","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"Attached patch fixes the javadoc and adds the 'final' keyword per Colin's review.\n\nI didn't change the buffer sizes, since that's an issue in lots and lots of places in the DFS source. We should change it throughout rather than try to change it in this unrelated JIRA.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2013-01-16T22:55:29.881+0000","updated":"2013-01-16T22:55:29.881+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12627554/comment/13555671","id":"13555671","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12565199/hdfs-4403.txt\n  against trunk revision .\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.\n                        Please justify why no new tests are needed for this patch.\n                        Also please list what manual steps were performed to verify this patch.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.\n\n    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/3849//testReport/\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/3849//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2013-01-17T00:35:35.039+0000","updated":"2013-01-17T00:35:35.039+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12627554/comment/13556944","id":"13556944","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=atm","name":"atm","key":"atm","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=atm&avatarId=14136","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=atm&avatarId=14136","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=atm&avatarId=14136","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=atm&avatarId=14136"},"displayName":"Aaron T. Myers","active":true,"timeZone":"America/Los_Angeles"},"body":"+1, the patch looks good to me.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=atm","name":"atm","key":"atm","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=atm&avatarId=14136","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=atm&avatarId=14136","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=atm&avatarId=14136","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=atm&avatarId=14136"},"displayName":"Aaron T. Myers","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-01-18T03:58:44.288+0000","updated":"2013-01-18T03:58:44.288+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12627554/comment/13559325","id":"13559325","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"Committed. Thanks for reviewing, Aaron.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2013-01-22T02:59:50.649+0000","updated":"2013-01-22T02:59:50.649+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12627554/comment/13559329","id":"13559329","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"Integrated in Hadoop-trunk-Commit #3265 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/3265/])\n    HDFS-4403. DFSClient can infer checksum type when not provided by reading first byte. Contributed by Todd Lipcon. (Revision 1436730)\n\n     Result = SUCCESS\ntodd : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1436730\nFiles : \n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSClient.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FileChecksumServlets.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/proto/datatransfer.proto\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2013-01-22T03:05:38.012+0000","updated":"2013-01-22T03:05:38.012+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12627554/comment/13559397","id":"13559397","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sureshms","name":"sureshms","key":"sureshms","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10450","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10450","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10450","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10450"},"displayName":"Suresh Srinivas","active":true,"timeZone":"America/Los_Angeles"},"body":"Todd, sorry got busy with other things. +1 for the change as well.\n\nConsider adding a brief release note on the issue with prior branch in the release notes to help users understand the issue.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sureshms","name":"sureshms","key":"sureshms","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10450","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10450","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10450","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10450"},"displayName":"Suresh Srinivas","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-01-22T04:51:41.987+0000","updated":"2013-01-22T04:51:41.987+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12627554/comment/13559541","id":"13559541","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"Integrated in Hadoop-Yarn-trunk #104 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/104/])\n    HDFS-4403. DFSClient can infer checksum type when not provided by reading first byte. Contributed by Todd Lipcon. (Revision 1436730)\n\n     Result = SUCCESS\ntodd : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1436730\nFiles : \n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSClient.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FileChecksumServlets.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/proto/datatransfer.proto\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2013-01-22T10:47:43.659+0000","updated":"2013-01-22T10:47:43.659+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12627554/comment/13559602","id":"13559602","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"Integrated in Hadoop-Hdfs-trunk #1293 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1293/])\n    HDFS-4403. DFSClient can infer checksum type when not provided by reading first byte. Contributed by Todd Lipcon. (Revision 1436730)\n\n     Result = FAILURE\ntodd : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1436730\nFiles : \n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSClient.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FileChecksumServlets.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/proto/datatransfer.proto\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2013-01-22T12:55:17.078+0000","updated":"2013-01-22T12:55:17.078+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12627554/comment/13559648","id":"13559648","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"Integrated in Hadoop-Mapreduce-trunk #1321 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1321/])\n    HDFS-4403. DFSClient can infer checksum type when not provided by reading first byte. Contributed by Todd Lipcon. (Revision 1436730)\n\n     Result = SUCCESS\ntodd : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1436730\nFiles : \n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSClient.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FileChecksumServlets.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/proto/datatransfer.proto\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2013-01-22T14:04:57.558+0000","updated":"2013-01-22T14:04:57.558+0000"}],"maxResults":23,"total":23,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-4403/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i17lun:"}}