{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12405233","self":"https://issues.apache.org/jira/rest/api/2/issue/12405233","key":"HDFS-183","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/2","id":"2","description":"The problem described is an issue which will never be fixed.","name":"Won't Fix"},"customfield_12312322":null,"customfield_12310220":"2010-06-22T06:24:10.322+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Wed Jan 25 21:36:48 UTC 2012","customfield_12310420":"16673","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_105092299840_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2012-01-25T21:36:48.054+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-183/watchers","watchCount":1,"isWatching":false},"created":"2008-09-26T13:18:28.386+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/2","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/critical.svg","name":"Critical","id":"2"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[],"issuelinks":[],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2012-01-25T21:36:48.152+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[],"timeoriginalestimate":null,"description":"On some special cases, all replications of a given file has truncated to zero  but the namenode still hold the original size (we don't know why),  the mapreduce streaming job will hang if we don't specified mapred.task.timeout when the input files contain this corrupted file, even the dfs shell \"cat\" will hang when fetch data from this corrupted file.\n\nWe found that job hang at DFSInputStream.blockSeekTo() when chosing a datanode.  The following test will show:\n1)\tCopy a small file to hdfs. \n2)\tGet the file blocks and login to these datanodes, and truncate these blocks to zero.\n3)\tCat this file through dfs shell \"cat\"\n4)\tCat command will enter dead loop.\n","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"108085","customfield_12312823":null,"summary":"MapReduce Streaming job hang when all replications of the input file has corrupted!","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=buptzhugy","name":"buptzhugy","key":"buptzhugy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ZhuGuanyin","active":true,"timeZone":"Etc/UTC"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=buptzhugy","name":"buptzhugy","key":"buptzhugy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ZhuGuanyin","active":true,"timeZone":"Etc/UTC"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12405233/comment/12634852","id":"12634852","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=buptzhugy","name":"buptzhugy","key":"buptzhugy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ZhuGuanyin","active":true,"timeZone":"Etc/UTC"},"body":"seems that after try all datanodes, it clears the deadnode list and retry, enter an infinite loop.\n\nWe add some debug code as follows:\n\n In DFSInputStream.blockSeekTo(): \n    \nprivate synchronized DatanodeInfo blockSeekTo(long target) throws IOException {\n      while (s == null) {\n\n        LOG.info(\"blockSeekTo step 1\"); \n        DNAddrPair retval = chooseDataNode(targetBlock);\n        LOG.info(\"blockSeekTo step 2\"); \n        try {\n          blockReader = BlockReader.newBlockReader();\n          return chosenNode;\n        } catch (IOException ex) {\n          LOG.info(\"blockSeekTo step 3\"); \n          addToDeadNodes(chosenNode);\n          if (s != null) {\n            try {\n              s.close();\n            } catch (IOException iex) {\n            LOG.info(\"blockSeekTo step 4\"); \n            }                        \n          }\n          s = null;\n        LOG.info(\"blockSeekTo step 5\"); \n        }\n        LOG.info(\"blockSeekTo step 6\"); \n      }\n      return chosenNode;\n}\n\n\n\nIn DFSInputStream. chooseDataNode ():\nprivate DNAddrPair chooseDataNode(LocatedBlock block)\n      throws IOException {\n      LOG.info(\"chooseDataNode() step 1\");\n      while (true) {\n        LOG.info(\"chooseDataNode() step 2\");\n        DatanodeInfo[] nodes = block.getLocations();\n        try {\n          LOG.info(\"chooseDataNode() step 3, failures = \" + failures);\n          DatanodeInfo chosenNode = bestNode(nodes, deadNodes);\n          LOG.info(\"chooseDataNode() step 4\");\n          InetSocketAddress targetAddr = DataNode.createSocketAddr(chosenNode.getName());\n          LOG.info(\"chooseDataNode() step 5\");\n          return new DNAddrPair(chosenNode, targetAddr);\n        } catch (IOException ie) {\n          String blockInfo = block.getBlock() + \" file=\" + src;\n          LOG.info(\"chooseDataNode() step 6, failures = \" + failures);\n          if (failures >= MAX_BLOCK_ACQUIRE_FAILURES) {\n            throw new IOException(\"Could not obtain block: \" + blockInfo);\n          }\n          \n          if (nodes == null || nodes.length == 0) {\n            LOG.info(\"No node available for block: \" + blockInfo);\n          }\n          LOG.info(\"Could not obtain block \" + block.getBlock() + \" from any node:  \" + ie);\n          try {\n            Thread.sleep(3000);\n          } catch (InterruptedException iex) {\n          }\n          LOG.info(\"chooseDataNode() step 7, failures = \" + failures);\n          deadNodes.clear(); //2nd option is to remove only nodes[blockId]\n          openInfo();\n          failures++;\n          LOG.info(\"chooseDataNode() step 8, failures = \" + failures);\n          continue;\n        }\n      }\n    } \n\nAfter we run ./hadoop dfs -cat /1.txt , we get the following stdout:\n\n[test@test. baidu.com ~]$ ./hadoop fs -cat /1.txt\n08/09/26 21:00:44 INFO fs.DFSClient: blockSeekTo step 1\n08/09/26 21:00:44 INFO fs.DFSClient: chooseDataNode() step 1\n08/09/26 21:00:44 INFO fs.DFSClient: chooseDataNode() step 2\n08/09/26 21:00:44 INFO fs.DFSClient: chooseDataNode() step 3, failures = 0\n08/09/26 21:00:44 INFO fs.DFSClient: chooseDataNode() step 4\n08/09/26 21:00:44 INFO fs.DFSClient: chooseDataNode() step 5\n08/09/26 21:00:44 INFO fs.DFSClient: blockSeekTo step 2\n08/09/26 21:00:44 INFO fs.DFSClient: blockSeekTo step 3\n08/09/26 21:00:44 INFO fs.DFSClient: blockSeekTo step 5\n08/09/26 21:00:44 INFO fs.DFSClient: blockSeekTo step 6\n08/09/26 21:00:44 INFO fs.DFSClient: blockSeekTo step 1\n08/09/26 21:00:44 INFO fs.DFSClient: chooseDataNode() step 1\n08/09/26 21:00:44 INFO fs.DFSClient: chooseDataNode() step 2\n08/09/26 21:00:44 INFO fs.DFSClient: chooseDataNode() step 3, failures = 0\n08/09/26 21:00:44 INFO fs.DFSClient: chooseDataNode() step 4\n08/09/26 21:00:44 INFO fs.DFSClient: chooseDataNode() step 5\n08/09/26 21:00:44 INFO fs.DFSClient: blockSeekTo step 2\n08/09/26 21:00:44 INFO fs.DFSClient: blockSeekTo step 3\n08/09/26 21:00:44 INFO fs.DFSClient: blockSeekTo step 5\n08/09/26 21:00:44 INFO fs.DFSClient: blockSeekTo step 6\n08/09/26 21:00:44 INFO fs.DFSClient: blockSeekTo step 1\n08/09/26 21:00:44 INFO fs.DFSClient: chooseDataNode() step 1\n08/09/26 21:00:44 INFO fs.DFSClient: chooseDataNode() step 2\n08/09/26 21:00:44 INFO fs.DFSClient: chooseDataNode() step 3, failures = 0\n08/09/26 21:00:44 INFO fs.DFSClient: chooseDataNode() step 4\n08/09/26 21:00:44 INFO fs.DFSClient: chooseDataNode() step 5\n08/09/26 21:00:44 INFO fs.DFSClient: blockSeekTo step 2\n08/09/26 21:00:44 INFO fs.DFSClient: blockSeekTo step 3\n08/09/26 21:00:44 INFO fs.DFSClient: blockSeekTo step 5\n08/09/26 21:00:44 INFO fs.DFSClient: blockSeekTo step 6\n08/09/26 21:00:44 INFO fs.DFSClient: blockSeekTo step 1\n08/09/26 21:00:44 INFO fs.DFSClient: chooseDataNode() step 1\n08/09/26 21:00:44 INFO fs.DFSClient: chooseDataNode() step 2\n08/09/26 21:00:44 INFO fs.DFSClient: chooseDataNode() step 3, failures = 0\n08/09/26 21:00:44 INFO fs.DFSClient: chooseDataNode() step 6, failures = 0\n08/09/26 21:00:44 INFO fs.DFSClient: Could not obtain block blk_1225 from any node:  java.io.IOException: No live nodes contain current block\n\n08/09/26 21:00:47 INFO fs.DFSClient: chooseDataNode() step 7, failures = 0\n08/09/26 21:00:47 INFO fs.DFSClient: chooseDataNode() step 8, failures = 1\n08/09/26 21:00:47 INFO fs.DFSClient: chooseDataNode() step 2\n08/09/26 21:00:47 INFO fs.DFSClient: chooseDataNode() step 3, failures = 1\n08/09/26 21:00:47 INFO fs.DFSClient: chooseDataNode() step 4\n08/09/26 21:00:47 INFO fs.DFSClient: chooseDataNode() step 5\n08/09/26 21:00:47 INFO fs.DFSClient: blockSeekTo step 2\n08/09/26 21:00:47 INFO fs.DFSClient: blockSeekTo step 3\n08/09/26 21:00:47 INFO fs.DFSClient: blockSeekTo step 5\n08/09/26 21:00:47 INFO fs.DFSClient: blockSeekTo step 6\n08/09/26 21:00:47 INFO fs.DFSClient: blockSeekTo step 1\n08/09/26 21:00:47 INFO fs.DFSClient: chooseDataNode() step 1\n08/09/26 21:00:47 INFO fs.DFSClient: chooseDataNode() step 2\n08/09/26 21:00:47 INFO fs.DFSClient: chooseDataNode() step 3, failures = 0\n08/09/26 21:00:47 INFO fs.DFSClient: chooseDataNode() step 4\n08/09/26 21:00:47 INFO fs.DFSClient: chooseDataNode() step 5\n08/09/26 21:00:47 INFO fs.DFSClient: blockSeekTo step 2\n08/09/26 21:00:47 INFO fs.DFSClient: blockSeekTo step 3\n08/09/26 21:00:47 INFO fs.DFSClient: blockSeekTo step 5\n08/09/26 21:00:47 INFO fs.DFSClient: blockSeekTo step 6\n08/09/26 21:00:47 INFO fs.DFSClient: blockSeekTo step 1\n08/09/26 21:00:47 INFO fs.DFSClient: chooseDataNode() step 1\n08/09/26 21:00:47 INFO fs.DFSClient: chooseDataNode() step 2\n08/09/26 21:00:47 INFO fs.DFSClient: chooseDataNode() step 3, failures = 0\n08/09/26 21:00:47 INFO fs.DFSClient: chooseDataNode() step 4\n08/09/26 21:00:47 INFO fs.DFSClient: chooseDataNode() step 5\n08/09/26 21:00:47 INFO fs.DFSClient: blockSeekTo step 2\n08/09/26 21:00:47 INFO fs.DFSClient: blockSeekTo step 3\n08/09/26 21:00:47 INFO fs.DFSClient: blockSeekTo step 5\n08/09/26 21:00:47 INFO fs.DFSClient: blockSeekTo step 6\n08/09/26 21:00:47 INFO fs.DFSClient: blockSeekTo step 1\n08/09/26 21:00:47 INFO fs.DFSClient: chooseDataNode() step 1\n08/09/26 21:00:47 INFO fs.DFSClient: chooseDataNode() step 2\n08/09/26 21:00:47 INFO fs.DFSClient: chooseDataNode() step 3, failures = 0\n08/09/26 21:00:47 INFO fs.DFSClient: chooseDataNode() step 6, failures = 0\n08/09/26 21:00:47 INFO fs.DFSClient: Could not obtain block blk_1225 from any node:  java.io.IOException: No live nodes contain current block\n.........................................................................................................\n\n\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=buptzhugy","name":"buptzhugy","key":"buptzhugy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ZhuGuanyin","active":true,"timeZone":"Etc/UTC"},"created":"2008-09-26T13:20:40.629+0000","updated":"2008-09-26T13:20:40.629+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12405233/comment/12881090","id":"12881090","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raj_velu","name":"raj_velu","key":"raj_velu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Soundararajan Velu","active":true,"timeZone":"Etc/UTC"},"body":"Zhu, I tried reproeducing this issue in our cluster with no luck... The dfs client retries for 5 times and then throws an IO exception and then terminates the operation. Please let me know if you are still facing this issue. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raj_velu","name":"raj_velu","key":"raj_velu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Soundararajan Velu","active":true,"timeZone":"Etc/UTC"},"created":"2010-06-22T06:24:10.322+0000","updated":"2010-06-22T06:24:10.322+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12405233/comment/13193351","id":"13193351","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sureshms","name":"sureshms","key":"sureshms","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10450","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10450","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10450","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10450"},"displayName":"Suresh Srinivas","active":true,"timeZone":"America/Los_Angeles"},"body":"This bug has been open for a while, with no reply to the last comment posted. Closing for now. Please re-open the bug or open a new bug, if the problem still persists.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sureshms","name":"sureshms","key":"sureshms","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10450","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10450","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10450","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10450"},"displayName":"Suresh Srinivas","active":true,"timeZone":"America/Los_Angeles"},"created":"2012-01-25T21:36:48.148+0000","updated":"2012-01-25T21:36:48.148+0000"}],"maxResults":3,"total":3,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-183/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i0iut3:"}}