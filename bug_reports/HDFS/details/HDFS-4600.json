{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12636848","self":"https://issues.apache.org/jira/rest/api/2/issue/12636848","key":"HDFS-4600","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/6","id":"6","description":"The problem isn't valid and it can't be fixed.","name":"Invalid"},"customfield_12312322":null,"customfield_12310220":"2013-03-14T02:15:21.083+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Thu Jan 16 18:40:36 UTC 2014","customfield_12310420":"317340","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_26692416554_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2014-01-16T18:40:36.933+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-4600/watchers","watchCount":11,"isWatching":false},"created":"2013-03-13T20:07:00.410+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"3.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12323274","id":"12323274","description":"2.0.3-alpha release","name":"2.0.3-alpha","archived":false,"released":true,"releaseDate":"2013-02-14"}],"issuelinks":[{"id":"12365710","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12365710","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"12546353","key":"HDFS-3091","self":"https://issues.apache.org/jira/rest/api/2/issue/12546353","fields":{"summary":"Update the usage limitations of ReplaceDatanodeOnFailure policy in the config description for the smaller clusters.","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/4","id":"4","description":"An improvement or enhancement to an existing feature or task.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype","name":"Improvement","subtask":false,"avatarId":21140}}}}],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2014-01-16T18:40:36.961+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[],"timeoriginalestimate":null,"description":"NOTE: the following only happens in a fully distributed setup (core-site.xml and hdfs-site.xml are attached)\n\nSteps to reproduce:\n\n{noformat}\n$ javac -cp /usr/lib/hadoop/client/\\* X.java\n$ echo aaaaa > a.txt\n$ hadoop fs -ls /tmp/a.txt\nls: `/tmp/a.txt': No such file or directory\n$ HADOOP_CLASSPATH=`pwd` hadoop X /tmp/a.txt\n13/03/13 16:05:14 WARN hdfs.DFSClient: DataStreamer Exception\njava.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[10.10.37.16:50010, 10.80.134.126:50010], original=[10.10.37.16:50010, 10.80.134.126:50010]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.\n\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.findNewDatanode(DFSOutputStream.java:793)\n\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.addDatanode2ExistingPipeline(DFSOutputStream.java:858)\n\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:964)\n\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:470)\nException in thread \"main\" java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[10.10.37.16:50010, 10.80.134.126:50010], original=[10.10.37.16:50010, 10.80.134.126:50010]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.\n\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.findNewDatanode(DFSOutputStream.java:793)\n\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.addDatanode2ExistingPipeline(DFSOutputStream.java:858)\n\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:964)\n\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:470)\n13/03/13 16:05:14 ERROR hdfs.DFSClient: Failed to close file /tmp/a.txt\njava.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[10.10.37.16:50010, 10.80.134.126:50010], original=[10.10.37.16:50010, 10.80.134.126:50010]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.\n\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.findNewDatanode(DFSOutputStream.java:793)\n\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.addDatanode2ExistingPipeline(DFSOutputStream.java:858)\n\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:964)\n\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:470)\n{noformat}\n\nGiven that the file actually does get created:\n{noformat}\n$ hadoop fs -ls /tmp/a.txt\nFound 1 items\n-rw-r--r--   3 root hadoop          6 2013-03-13 16:05 /tmp/a.txt\n{noformat}\n\nthis feels like a regression in APPEND's functionality.\n\n","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12573568","id":"12573568","filename":"core-site.xml","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rvs","name":"rvs","key":"rvs","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=rvs&avatarId=13930","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=rvs&avatarId=13930","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=rvs&avatarId=13930","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=rvs&avatarId=13930"},"displayName":"Roman Shaposhnik","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-03-13T20:07:20.477+0000","size":2437,"mimeType":"text/xml","content":"https://issues.apache.org/jira/secure/attachment/12573568/core-site.xml"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12573569","id":"12573569","filename":"hdfs-site.xml","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rvs","name":"rvs","key":"rvs","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=rvs&avatarId=13930","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=rvs&avatarId=13930","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=rvs&avatarId=13930","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=rvs&avatarId=13930"},"displayName":"Roman Shaposhnik","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-03-13T20:07:20.480+0000","size":2468,"mimeType":"text/xml","content":"https://issues.apache.org/jira/secure/attachment/12573569/hdfs-site.xml"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12573570","id":"12573570","filename":"X.java","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rvs","name":"rvs","key":"rvs","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=rvs&avatarId=13930","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=rvs&avatarId=13930","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=rvs&avatarId=13930","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=rvs&avatarId=13930"},"displayName":"Roman Shaposhnik","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-03-13T20:08:18.901+0000","size":1777,"mimeType":"text/x-java","content":"https://issues.apache.org/jira/secure/attachment/12573570/X.java"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"317681","customfield_12312823":null,"summary":"HDFS file append failing in multinode cluster","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rvs","name":"rvs","key":"rvs","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=rvs&avatarId=13930","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=rvs&avatarId=13930","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=rvs&avatarId=13930","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=rvs&avatarId=13930"},"displayName":"Roman Shaposhnik","active":true,"timeZone":"America/Los_Angeles"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rvs","name":"rvs","key":"rvs","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=rvs&avatarId=13930","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=rvs&avatarId=13930","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=rvs&avatarId=13930","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=rvs&avatarId=13930"},"displayName":"Roman Shaposhnik","active":true,"timeZone":"America/Los_Angeles"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12636848/comment/13601968","id":"13601968","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"body":"Just a guess, but do you have a 2-node cluster, and replication set to 3?  (I checked the XML conf files you attached and didn't see any evidence of replication set to something other than the default of 3).\n\nThe decision to throw an exception when we can't get up to the full replication factor was a design decision as I understand-- thought it has led to some (in my opinion) counter-intuitive behavior.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-03-14T02:15:21.083+0000","updated":"2013-03-14T02:15:21.083+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12636848/comment/13601986","id":"13601986","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rvs","name":"rvs","key":"rvs","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=rvs&avatarId=13930","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=rvs&avatarId=13930","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=rvs&avatarId=13930","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=rvs&avatarId=13930"},"displayName":"Roman Shaposhnik","active":true,"timeZone":"America/Los_Angeles"},"body":"It is indeed a 2 nodes cluster. That said, the first write to the file actually succeeds and it is only the append call that fails. The cluster is also fully functional wrt. the hadoop fs use. I can copy stuff in/out of it.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rvs","name":"rvs","key":"rvs","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=rvs&avatarId=13930","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=rvs&avatarId=13930","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=rvs&avatarId=13930","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=rvs&avatarId=13930"},"displayName":"Roman Shaposhnik","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-03-14T02:40:38.830+0000","updated":"2013-03-14T02:40:38.830+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12636848/comment/13602020","id":"13602020","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"body":"if the cluster size is 2 nodes, we recommend to disable this feature as we can not replace with new node in any case.\n\nLook at the comment for the configuration in hdfs-default.xml:\n{quote}\nIf there is a datanode/network failure in the write pipeline, DFSClient will try to remove the failed datanode from the pipeline and then continue writing with the remaining datanodes. As a result, the number of datanodes in the pipeline is decreased. The feature is to add new datanodes to the pipeline. This is a site-wide property to enable/disable the feature. When the cluster size is extremely small, e.g. 3 nodes or less, cluster administrators may want to set the policy to NEVER in the default configuration file or disable this feature. Otherwise, users may experience an unusually high rate of pipeline failures since it is impossible to find new datanodes for replacement. See also dfs.client.block.write.replace-datanode-on-failure.policy \n{quote}\n\nto disable this, we can set dfs.client.block.write.replace-datanode-on-failure.enable to false.\n\nHere existing/selected nodes will be only 2 and replication will be still set to 3? if So, policy might satisfied and trying to add another in pipeline I think. Alternatively you can set replication to 2 as your cluster max size is only 2. If replication is less than 3, this policy will not be used.  With smaller clusters It is always recommended to disable this fature.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-03-14T04:39:18.040+0000","updated":"2013-03-14T04:39:18.040+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12636848/comment/13602023","id":"13602023","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rvs","name":"rvs","key":"rvs","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=rvs&avatarId=13930","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=rvs&avatarId=13930","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=rvs&avatarId=13930","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=rvs&avatarId=13930"},"displayName":"Roman Shaposhnik","active":true,"timeZone":"America/Los_Angeles"},"body":"I would appreciate if somebody could explain the difference in behavior between a simple write and an append. Whatever the policy is it should affect both equally. Yet one is successful and the other is not. At this point I'm really suspicious that of this one is different between the two -- what else could there be? Do I have, from now on, explicitly test append on my clusters because the code path and applicable policies are different between the two? I would certainly hope not. Please comment.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rvs","name":"rvs","key":"rvs","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=rvs&avatarId=13930","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=rvs&avatarId=13930","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=rvs&avatarId=13930","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=rvs&avatarId=13930"},"displayName":"Roman Shaposhnik","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-03-14T04:47:10.447+0000","updated":"2013-03-14T04:47:10.447+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12636848/comment/13602035","id":"13602035","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"body":"Yeah, here behaviour is different for normal write and append flow with respective to this policy I think.\nThis particular policy check happens only in setupPipelineForAppendOrRecovery.\n\nIf initially pipeline establishes with less number of nodes also it is allowing to continue in normal write flow. This policy is coming into picture only if there is a pipeline failure or append call.\n\nI think the intention behind this feature might be here is:\nIn normal flow if it is trying to get only less nodes than requested means, it will not get even if it tried to add new nodes again with this policy. But append call can be even later after some time, so, there may be a chance in adding the new node in pipeline. But the strict condition here is to satisfy the replication 100% for ensuring strong tolerance.\n@Nicholas, can add more on this?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-03-14T05:03:41.156+0000","updated":"2013-03-14T05:03:41.156+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12636848/comment/13603036","id":"13603036","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi Roman, append and create are different in the sense that there is existing data in before append.  The existing data were already persisted in HDFS earlier.  The replace-datanode-on-failure feature is to prevent data lost.  For append, it makes sure there are enough datanodes to protect the existing data.  It is very useful for slow appender.  The feature can be disabled by setting dfs.client.block.write.replace-datanode-on-failure.enable if it is undesirable.\n\nThis JIRA is similar to HDFS-3091.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-03-15T02:40:25.233+0000","updated":"2013-03-15T02:40:25.233+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12636848/comment/13603472","id":"13603472","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tucu00","name":"tucu00","key":"tucu00","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Alejandro Abdelnur","active":true,"timeZone":"Europe/Madrid"},"body":"Uma, Nicholas, thanks for the details. I was looking at this issue with Roman, why does it work OK in a pseudo cluster setup then? I think we can lower the priority since there is a workaround.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tucu00","name":"tucu00","key":"tucu00","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Alejandro Abdelnur","active":true,"timeZone":"Europe/Madrid"},"created":"2013-03-15T16:01:28.356+0000","updated":"2013-03-15T16:01:28.356+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12636848/comment/13603484","id":"13603484","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rvs","name":"rvs","key":"rvs","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=rvs&avatarId=13930","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=rvs&avatarId=13930","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=rvs&avatarId=13930","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=rvs&avatarId=13930"},"displayName":"Roman Shaposhnik","active":true,"timeZone":"America/Los_Angeles"},"body":"Definitely not a blocker -- feel free to close it as a dup of HDFS-3091. As for why it worked in pseudo-distributed case -- the replication factor there is always set to 1.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rvs","name":"rvs","key":"rvs","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=rvs&avatarId=13930","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=rvs&avatarId=13930","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=rvs&avatarId=13930","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=rvs&avatarId=13930"},"displayName":"Roman Shaposhnik","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-03-15T16:23:25.868+0000","updated":"2013-03-15T16:23:25.868+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12636848/comment/13603486","id":"13603486","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cos","name":"cos","key":"cos","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cos&avatarId=16741","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cos&avatarId=16741","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cos&avatarId=16741","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cos&avatarId=16741"},"displayName":"Konstantin Boudnik","active":true,"timeZone":"America/Los_Angeles"},"body":"dudes, it isn't a bug at all, actually. It shouldn't be closed as a dup: it should be closed as invalid.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cos","name":"cos","key":"cos","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cos&avatarId=16741","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cos&avatarId=16741","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cos&avatarId=16741","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cos&avatarId=16741"},"displayName":"Konstantin Boudnik","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-03-15T16:25:30.550+0000","updated":"2013-03-15T16:25:30.550+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12636848/comment/13603592","id":"13603592","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rvs","name":"rvs","key":"rvs","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=rvs&avatarId=13930","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=rvs&avatarId=13930","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=rvs&avatarId=13930","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=rvs&avatarId=13930"},"displayName":"Roman Shaposhnik","active":true,"timeZone":"America/Los_Angeles"},"body":"As Colin pointed out -- there are different ways of looking at it. I still consider the difference between READ and APPEND code path to be artificial and surprising to the user. Imagine a POSIX open(2) giving you different behavior based on whether you specified O_APPEND or not.\n\nWhat I'm worried about here is not a pathological use case of a 2 node cluster but cases where files are over-replicated (for the purposes of availability) and can NOT be appended to by default. Of course, given that this can be controlled on a client side -- this makes it less of a problem.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rvs","name":"rvs","key":"rvs","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=rvs&avatarId=13930","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=rvs&avatarId=13930","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=rvs&avatarId=13930","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=rvs&avatarId=13930"},"displayName":"Roman Shaposhnik","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-03-15T17:52:47.929+0000","updated":"2013-03-15T17:52:47.929+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12636848/comment/13603755","id":"13603755","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cos","name":"cos","key":"cos","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cos&avatarId=16741","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cos&avatarId=16741","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cos&avatarId=16741","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cos&avatarId=16741"},"displayName":"Konstantin Boudnik","active":true,"timeZone":"America/Los_Angeles"},"body":"bq. where files are over-replicated (for the purposes of availability) and can NOT be appended to by default\n\nI won't worry about it, because if a block being over-replicated - e.g. because of a couple of datanodes went offline, and it causes overcompensation on the part of NN - the over-replication will eventually go away as NN will balance the number of replicas once and if the original DNs are back.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cos","name":"cos","key":"cos","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cos&avatarId=16741","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cos&avatarId=16741","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cos&avatarId=16741","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cos&avatarId=16741"},"displayName":"Konstantin Boudnik","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-03-15T19:46:33.860+0000","updated":"2013-03-15T19:46:33.860+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12636848/comment/13603760","id":"13603760","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rvs","name":"rvs","key":"rvs","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=rvs&avatarId=13930","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=rvs&avatarId=13930","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=rvs&avatarId=13930","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=rvs&avatarId=13930"},"displayName":"Roman Shaposhnik","active":true,"timeZone":"America/Los_Angeles"},"body":"bq. the over-replication will eventually go away as NN will balance the number of replicas once and if the original DNs are back.\n\nRight. But in the meantime APPEND would be unavailable to *unsuspecting* applications.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rvs","name":"rvs","key":"rvs","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=rvs&avatarId=13930","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=rvs&avatarId=13930","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=rvs&avatarId=13930","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=rvs&avatarId=13930"},"displayName":"Roman Shaposhnik","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-03-15T19:49:31.507+0000","updated":"2013-03-15T19:49:31.507+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12636848/comment/13603771","id":"13603771","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cos","name":"cos","key":"cos","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cos&avatarId=16741","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cos&avatarId=16741","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cos&avatarId=16741","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cos&avatarId=16741"},"displayName":"Konstantin Boudnik","active":true,"timeZone":"America/Los_Angeles"},"body":"well, yeah... but if the cluster doesn't have enough resources for the append then append shouldn't be happening. This is essentially the safe-bet behind this design decision (see [~szetszwo] comment above)","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cos","name":"cos","key":"cos","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cos&avatarId=16741","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cos&avatarId=16741","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cos&avatarId=16741","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cos&avatarId=16741"},"displayName":"Konstantin Boudnik","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-03-15T19:57:21.030+0000","updated":"2013-03-15T19:57:21.030+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12636848/comment/13603781","id":"13603781","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rvs","name":"rvs","key":"rvs","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=rvs&avatarId=13930","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=rvs&avatarId=13930","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=rvs&avatarId=13930","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=rvs&avatarId=13930"},"displayName":"Roman Shaposhnik","active":true,"timeZone":"America/Los_Angeles"},"body":"bq. well, yeah... but if the cluster doesn't have enough resources\n\nand yet in the very same scenario the plain write would be successful. All I am saying is that there's a surprising inconsistency here. Thanks to Nicholas I now understand the design ramifications and yet I find it slightly unfortunate that such inconsistency is there.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rvs","name":"rvs","key":"rvs","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=rvs&avatarId=13930","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=rvs&avatarId=13930","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=rvs&avatarId=13930","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=rvs&avatarId=13930"},"displayName":"Roman Shaposhnik","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-03-15T20:01:46.968+0000","updated":"2013-03-15T20:01:46.968+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12636848/comment/13604329","id":"13604329","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"body":"[~tucu00]\n{quote}, why does it work OK in a pseudo cluster setup then?{quote}\nIn pseudo mode replication would set to 1 right with single DN. So, in Append call it will not try adding any new node as it is meeting replication. In fully distributed mode replication would be default to 3. But here we have only 2 nodes in cluster.\n\n{code}\nand yet in the very same scenario the plain write would be successful. All I am saying is that there's a surprising inconsistency here. \n{code}\nThis feature is to check only if there are pipeline failures. see the property name dfs.client.block.write.replace-datanode-on-failure.enable . Here additionally we are checking even in append as we can have chance here to add node to pipeline if there are less. Ideally NN is not giving enough nodes means, 1) cluster it would not have good nodes 2) cluster is not having many nodes as many expected. So, here both the cases we can not replace with new nodes. For the #2, we are not recommending to enable this feature. For #1, I don't think this will happen in any normal clusters with more nodes. Because pipeline setup will happen normally if there are available nodes. It may fail later if there are NW issues or any crashes etc, that time anyway recovery will trigger and this feature will come into picture to not reducing the nodes in pipeline.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-03-16T17:43:24.880+0000","updated":"2013-03-16T17:43:24.880+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12636848/comment/13831029","id":"13831029","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi Roman, Do you still think something needs to be addressed here? or we can close this bug?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-11-24T19:35:59.869+0000","updated":"2013-11-24T19:35:59.869+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12636848/comment/13873691","id":"13873691","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sureshms","name":"sureshms","key":"sureshms","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10450","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10450","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10450","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10450"},"displayName":"Suresh Srinivas","active":true,"timeZone":"America/Los_Angeles"},"body":"[~cos], looks like you changed the priority. Is this still an issue? If not, I plan on closing this as not a problem in a day or so.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sureshms","name":"sureshms","key":"sureshms","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10450","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10450","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10450","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10450"},"displayName":"Suresh Srinivas","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-01-16T18:16:14.586+0000","updated":"2014-01-16T18:16:14.586+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12636848/comment/13873695","id":"13873695","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cos","name":"cos","key":"cos","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cos&avatarId=16741","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cos&avatarId=16741","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cos&avatarId=16741","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cos&avatarId=16741"},"displayName":"Konstantin Boudnik","active":true,"timeZone":"America/Los_Angeles"},"body":"Suresh, I didn't see its fixed, so yes - this is still seems to be an issue.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cos","name":"cos","key":"cos","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cos&avatarId=16741","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cos&avatarId=16741","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cos&avatarId=16741","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cos&avatarId=16741"},"displayName":"Konstantin Boudnik","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-01-16T18:19:23.867+0000","updated":"2014-01-16T18:19:23.867+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12636848/comment/13873712","id":"13873712","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sureshms","name":"sureshms","key":"sureshms","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10450","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10450","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10450","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10450"},"displayName":"Suresh Srinivas","active":true,"timeZone":"America/Los_Angeles"},"body":"I am actually surprised. Many people have expressed that this is not a bug. You also have expressed the same opinion in the comments above. What changed?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sureshms","name":"sureshms","key":"sureshms","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10450","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10450","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10450","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10450"},"displayName":"Suresh Srinivas","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-01-16T18:31:31.729+0000","updated":"2014-01-16T18:31:31.729+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12636848/comment/13873728","id":"13873728","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cos","name":"cos","key":"cos","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cos&avatarId=16741","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cos&avatarId=16741","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cos&avatarId=16741","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cos&avatarId=16741"},"displayName":"Konstantin Boudnik","active":true,"timeZone":"America/Los_Angeles"},"body":"Actually you're right. I've re-read the history of the ticket and will close it right away. Please disregard my last comment ;)","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cos","name":"cos","key":"cos","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cos&avatarId=16741","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cos&avatarId=16741","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cos&avatarId=16741","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cos&avatarId=16741"},"displayName":"Konstantin Boudnik","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-01-16T18:40:01.197+0000","updated":"2014-01-16T18:40:01.197+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12636848/comment/13873729","id":"13873729","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cos","name":"cos","key":"cos","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cos&avatarId=16741","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cos&avatarId=16741","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cos&avatarId=16741","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cos&avatarId=16741"},"displayName":"Konstantin Boudnik","active":true,"timeZone":"America/Los_Angeles"},"body":"The issues seems to be caused by specific cluster configuration rather than a software problem. Closing.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cos","name":"cos","key":"cos","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cos&avatarId=16741","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cos&avatarId=16741","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cos&avatarId=16741","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cos&avatarId=16741"},"displayName":"Konstantin Boudnik","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-01-16T18:40:36.957+0000","updated":"2014-01-16T18:40:36.957+0000"}],"maxResults":21,"total":21,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-4600/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i1ira7:"}}