{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"13079178","self":"https://issues.apache.org/jira/rest/api/2/issue/13079178","key":"HDFS-11968","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12341434","id":"12341434","description":"3.1.0 release","name":"3.1.0","archived":false,"released":true,"releaseDate":"2018-04-06"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12343020","id":"12343020","description":"3.0.3 release","name":"3.0.3","archived":false,"released":true,"releaseDate":"2018-06-08"}],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2017-06-12T11:08:15.311+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Fri Apr 06 22:18:46 UTC 2018","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_6130422938_*|*_5_*:*_1_*:*_0_*|*_10002_*:*_1_*:*_3661021597","customfield_12312321":null,"resolutiondate":"2017-10-03T18:25:19.530+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-11968/watchers","watchCount":9,"isWatching":false},"created":"2017-06-12T10:34:35.068+0000","customfield_12310192":null,"customfield_12310191":[{"self":"https://issues.apache.org/jira/rest/api/2/customFieldOption/10343","value":"Reviewed","id":"10343"}],"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"11.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12331979","id":"12331979","description":"2.7.1 release","name":"2.7.1","archived":false,"released":true,"releaseDate":"2015-07-06"}],"issuelinks":[],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=msingh","name":"msingh","key":"msingh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Mukul Kumar Singh","active":true,"timeZone":"Asia/Kolkata"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2018-04-06T22:18:46.357+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12329603","id":"12329603","name":"hdfs"}],"timeoriginalestimate":null,"description":"hdfs storagepolicies command fails with HDFS federation.\n\nFor storage policies commands, a given user path should be resolved to a HDFS path and\nstorage policy command should be applied onto the resolved HDFS path.\n\n{code}\n  static DistributedFileSystem getDFS(Configuration conf)\n      throws IOException {\n    FileSystem fs = FileSystem.get(conf);\n    if (!(fs instanceof DistributedFileSystem)) {\n      throw new IllegalArgumentException(\"FileSystem \" + fs.getUri() +\n          \" is not an HDFS file system\");\n    }\n    return (DistributedFileSystem)fs;\n  }\n{code}","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12883086","id":"12883086","filename":"HDFS-11968.001.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=msingh","name":"msingh","key":"msingh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Mukul Kumar Singh","active":true,"timeZone":"Asia/Kolkata"},"created":"2017-08-22T09:28:09.657+0000","size":11552,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12883086/HDFS-11968.001.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12883299","id":"12883299","filename":"HDFS-11968.002.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=msingh","name":"msingh","key":"msingh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Mukul Kumar Singh","active":true,"timeZone":"Asia/Kolkata"},"created":"2017-08-23T09:29:19.776+0000","size":11579,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12883299/HDFS-11968.002.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12883320","id":"12883320","filename":"HDFS-11968.003.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=msingh","name":"msingh","key":"msingh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Mukul Kumar Singh","active":true,"timeZone":"Asia/Kolkata"},"created":"2017-08-23T11:30:05.976+0000","size":11582,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12883320/HDFS-11968.003.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12884015","id":"12884015","filename":"HDFS-11968.004.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=msingh","name":"msingh","key":"msingh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Mukul Kumar Singh","active":true,"timeZone":"Asia/Kolkata"},"created":"2017-08-28T08:37:53.660+0000","size":12404,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12884015/HDFS-11968.004.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12885547","id":"12885547","filename":"HDFS-11968.005.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=msingh","name":"msingh","key":"msingh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Mukul Kumar Singh","active":true,"timeZone":"Asia/Kolkata"},"created":"2017-09-06T08:25:02.493+0000","size":16564,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12885547/HDFS-11968.005.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12887552","id":"12887552","filename":"HDFS-11968.006.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=msingh","name":"msingh","key":"msingh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Mukul Kumar Singh","active":true,"timeZone":"Asia/Kolkata"},"created":"2017-09-17T16:02:44.079+0000","size":32910,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12887552/HDFS-11968.006.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12887848","id":"12887848","filename":"HDFS-11968.007.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=msingh","name":"msingh","key":"msingh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Mukul Kumar Singh","active":true,"timeZone":"Asia/Kolkata"},"created":"2017-09-19T08:14:22.038+0000","size":31912,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12887848/HDFS-11968.007.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12888240","id":"12888240","filename":"HDFS-11968.008.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=msingh","name":"msingh","key":"msingh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Mukul Kumar Singh","active":true,"timeZone":"Asia/Kolkata"},"created":"2017-09-21T09:04:17.880+0000","size":13007,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12888240/HDFS-11968.008.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12888258","id":"12888258","filename":"HDFS-11968.009.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=msingh","name":"msingh","key":"msingh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Mukul Kumar Singh","active":true,"timeZone":"Asia/Kolkata"},"created":"2017-09-21T11:27:27.327+0000","size":12896,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12888258/HDFS-11968.009.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12888457","id":"12888457","filename":"HDFS-11968.010.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=msingh","name":"msingh","key":"msingh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Mukul Kumar Singh","active":true,"timeZone":"Asia/Kolkata"},"created":"2017-09-22T08:00:07.935+0000","size":13372,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12888457/HDFS-11968.010.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12890087","id":"12890087","filename":"HDFS-11968.011.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=msingh","name":"msingh","key":"msingh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Mukul Kumar Singh","active":true,"timeZone":"Asia/Kolkata"},"created":"2017-10-03T02:09:03.912+0000","size":13284,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12890087/HDFS-11968.011.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"ViewFS: StoragePolicies commands fail with HDFS federation","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=msingh","name":"msingh","key":"msingh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Mukul Kumar Singh","active":true,"timeZone":"Asia/Kolkata"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=msingh","name":"msingh","key":"msingh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Mukul Kumar Singh","active":true,"timeZone":"Asia/Kolkata"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/13079178/comment/16046441","id":"16046441","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brahmareddy","name":"brahmareddy","key":"brahmareddy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=brahmareddy&avatarId=24624","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=brahmareddy&avatarId=24624","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=brahmareddy&avatarId=24624","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=brahmareddy&avatarId=24624"},"displayName":"Brahma Reddy Battula","active":true,"timeZone":"Asia/Kolkata"},"body":"[~msingh] thanks for reporting. HDFS-11177 supports fqp. \nNow we need to support for viewfs based path also..So it's different right?,I just confused..\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brahmareddy","name":"brahmareddy","key":"brahmareddy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=brahmareddy&avatarId=24624","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=brahmareddy&avatarId=24624","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=brahmareddy&avatarId=24624","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=brahmareddy&avatarId=24624"},"displayName":"Brahma Reddy Battula","active":true,"timeZone":"Asia/Kolkata"},"created":"2017-06-12T11:08:15.311+0000","updated":"2017-06-12T11:21:26.309+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13079178/comment/16046472","id":"16046472","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=msingh","name":"msingh","key":"msingh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Mukul Kumar Singh","active":true,"timeZone":"Asia/Kolkata"},"body":"Hi [~brahmareddy],\n\nThanks for pointing me to HDFS-11177.\n\nAs you have pointed out, this bug is support storage policies command with HDFS federation.\nThis bug will add support to resolve Viewfs based paths to HDFS ones and then apply storage policy commands on them.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=msingh","name":"msingh","key":"msingh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Mukul Kumar Singh","active":true,"timeZone":"Asia/Kolkata"},"created":"2017-06-12T11:44:21.084+0000","updated":"2017-06-12T11:44:21.084+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13079178/comment/16047113","id":"16047113","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=manojg","name":"manojg","key":"manojg","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Manoj Govindassamy","active":true,"timeZone":"America/Los_Angeles"},"body":"[~msingh],\nAs you pointed out, the storage policy command {{StoragePolicyAdmin}} assumes the path is always DFS and bails out immediately on seeing non-dfs paths. Also, ViewFs only has partial support for storage policy commands. It supports get and set of storage policies by invoking the command on the target filesystem based on the path. But, I don't see it supporting the listing of all storage policies.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=manojg","name":"manojg","key":"manojg","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Manoj Govindassamy","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-06-12T21:44:18.117+0000","updated":"2017-06-12T21:44:18.117+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13079178/comment/16136647","id":"16136647","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 21s{color} | {color:blue} Docker mode activated. {color} |\n|| || || || {color:brown} Prechecks {color} ||\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 2 new or modified test files. {color} |\n|| || || || {color:brown} trunk Compile Tests {color} ||\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 16m 21s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 56s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 43s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  8s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 59s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 46s{color} | {color:green} trunk passed {color} |\n|| || || || {color:brown} Patch Compile Tests {color} ||\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 59s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 57s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 57s{color} | {color:green} the patch passed {color} |\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 40s{color} | {color:orange} hadoop-hdfs-project/hadoop-hdfs: The patch generated 12 new + 14 unchanged - 0 fixed = 26 total (was 14) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 58s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m  3s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 44s{color} | {color:green} the patch passed {color} |\n|| || || || {color:brown} Other Tests {color} ||\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 73m 26s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 16s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black}103m 45s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| Failed junit tests | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure080 |\n|   | hadoop.hdfs.server.blockmanagement.TestRBWBlockInvalidation |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:14b5c93 |\n| JIRA Issue | HDFS-11968 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12883086/HDFS-11968.001.patch |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux e53bd04faafe 3.13.0-117-generic #164-Ubuntu SMP Fri Apr 7 11:05:26 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / d5ff57a |\n| Default Java | 1.8.0_144 |\n| findbugs | v3.1.0-RC1 |\n| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/20801/artifact/patchprocess/diff-checkstyle-hadoop-hdfs-project_hadoop-hdfs.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/20801/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |\n|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/20801/testReport/ |\n| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/20801/console |\n| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2017-08-22T11:14:59.872+0000","updated":"2017-08-22T11:14:59.872+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13079178/comment/16138140","id":"16138140","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=msingh","name":"msingh","key":"msingh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Mukul Kumar Singh","active":true,"timeZone":"Asia/Kolkata"},"body":"Attached v2 patch fixes checkstyle issues.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=msingh","name":"msingh","key":"msingh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Mukul Kumar Singh","active":true,"timeZone":"Asia/Kolkata"},"created":"2017-08-23T09:29:43.793+0000","updated":"2017-08-23T09:29:43.793+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13079178/comment/16138239","id":"16138239","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 18s{color} | {color:blue} Docker mode activated. {color} |\n|| || || || {color:brown} Prechecks {color} ||\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 2 new or modified test files. {color} |\n|| || || || {color:brown} trunk Compile Tests {color} ||\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 17m 14s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m  1s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 43s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  8s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m  2s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 48s{color} | {color:green} trunk passed {color} |\n|| || || || {color:brown} Patch Compile Tests {color} ||\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m  3s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 58s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 58s{color} | {color:green} the patch passed {color} |\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 40s{color} | {color:orange} hadoop-hdfs-project/hadoop-hdfs: The patch generated 6 new + 14 unchanged - 0 fixed = 20 total (was 14) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  5s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 10s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 46s{color} | {color:green} the patch passed {color} |\n|| || || || {color:brown} Other Tests {color} ||\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 80m 30s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 19s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black}112m 19s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| Failed junit tests | hadoop.hdfs.server.datanode.TestDataNodeErasureCodingMetrics |\n|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure |\n|   | hadoop.hdfs.server.blockmanagement.TestUnderReplicatedBlocks |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure010 |\n|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure080 |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:14b5c93 |\n| JIRA Issue | HDFS-11968 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12883299/HDFS-11968.002.patch |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux 0831602413a0 3.13.0-116-generic #163-Ubuntu SMP Fri Mar 31 14:13:22 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / 4249172 |\n| Default Java | 1.8.0_144 |\n| findbugs | v3.1.0-RC1 |\n| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/20819/artifact/patchprocess/diff-checkstyle-hadoop-hdfs-project_hadoop-hdfs.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/20819/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |\n|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/20819/testReport/ |\n| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/20819/console |\n| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2017-08-23T11:23:35.462+0000","updated":"2017-08-23T11:23:35.462+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13079178/comment/16138312","id":"16138312","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 54s{color} | {color:blue} Docker mode activated. {color} |\n|| || || || {color:brown} Prechecks {color} ||\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 2 new or modified test files. {color} |\n|| || || || {color:brown} trunk Compile Tests {color} ||\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 13m 51s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 48s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 36s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 54s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 39s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 41s{color} | {color:green} trunk passed {color} |\n|| || || || {color:brown} Patch Compile Tests {color} ||\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 49s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 45s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 45s{color} | {color:green} the patch passed {color} |\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 33s{color} | {color:orange} hadoop-hdfs-project/hadoop-hdfs: The patch generated 3 new + 14 unchanged - 0 fixed = 17 total (was 14) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 51s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 44s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 38s{color} | {color:green} the patch passed {color} |\n|| || || || {color:brown} Other Tests {color} ||\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 64m 57s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 16s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black} 91m 11s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| Failed junit tests | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure080 |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure160 |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:14b5c93 |\n| JIRA Issue | HDFS-11968 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12883320/HDFS-11968.003.patch |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux 85ba2539c450 3.13.0-119-generic #166-Ubuntu SMP Wed May 3 12:18:55 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / 4249172 |\n| Default Java | 1.8.0_144 |\n| findbugs | v3.1.0-RC1 |\n| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/20822/artifact/patchprocess/diff-checkstyle-hadoop-hdfs-project_hadoop-hdfs.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/20822/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |\n|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/20822/testReport/ |\n| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/20822/console |\n| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2017-08-23T13:02:13.514+0000","updated":"2017-08-23T13:02:13.514+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13079178/comment/16142102","id":"16142102","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=arpitagarwal","name":"arpitagarwal","key":"arpitagarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arpit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks for reporting this issue [~msingh]. A few comments:\n# I don't think listing policies from all namespaces in getStoragePolicy is the right behavior. Policies with the same name may have different meanings in different clusters. It's okay to print an error message for viewfs and maybe list all available DistributedFileSystems so the administrator can query each.\n# Can you please add javadocs to getResolvedPath to summarize the behavior? Also perhaps it should be renamed to getResolvedDfsPath.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=arpitagarwal","name":"arpitagarwal","key":"arpitagarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arpit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-08-25T19:59:04.123+0000","updated":"2017-08-25T19:59:04.123+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13079178/comment/16143632","id":"16143632","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 15s{color} | {color:blue} Docker mode activated. {color} |\n|| || || || {color:brown} Prechecks {color} ||\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 2 new or modified test files. {color} |\n|| || || || {color:brown} trunk Compile Tests {color} ||\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 15m 57s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 48s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 37s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 54s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 45s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 42s{color} | {color:green} trunk passed {color} |\n|| || || || {color:brown} Patch Compile Tests {color} ||\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m  2s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 58s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 58s{color} | {color:green} the patch passed {color} |\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 37s{color} | {color:orange} hadoop-hdfs-project/hadoop-hdfs: The patch generated 5 new + 14 unchanged - 0 fixed = 19 total (was 14) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  4s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m  5s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 44s{color} | {color:green} the patch passed {color} |\n|| || || || {color:brown} Other Tests {color} ||\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}100m 17s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 16s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black}129m 27s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| Failed junit tests | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure100 |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure160 |\n|   | hadoop.hdfs.TestClientProtocolForPipelineRecovery |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure130 |\n|   | hadoop.hdfs.TestFileAppendRestart |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure180 |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure140 |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure190 |\n|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration |\n|   | hadoop.hdfs.TestDFSInputStream |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure020 |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure090 |\n|   | hadoop.hdfs.TestLeaseRecoveryStriped |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure080 |\n|   | hadoop.hdfs.TestFileCreationEmpty |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure200 |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure040 |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure120 |\n|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure010 |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure150 |\n|   | hadoop.hdfs.TestReconstructStripedFile |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure030 |\n| Timed out junit tests | org.apache.hadoop.hdfs.TestWriteReadStripedFile |\n|   | org.apache.hadoop.hdfs.TestReadStripedFileWithDecoding |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:14b5c93 |\n| JIRA Issue | HDFS-11968 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12884015/HDFS-11968.004.patch |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux e8eb1716e797 3.13.0-123-generic #172-Ubuntu SMP Mon Jun 26 18:04:35 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / 02599bd |\n| Default Java | 1.8.0_144 |\n| findbugs | v3.1.0-RC1 |\n| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/20895/artifact/patchprocess/diff-checkstyle-hadoop-hdfs-project_hadoop-hdfs.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/20895/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |\n|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/20895/testReport/ |\n| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/20895/console |\n| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2017-08-28T10:50:54.357+0000","updated":"2017-08-28T10:50:54.357+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13079178/comment/16144821","id":"16144821","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=surendrasingh","name":"surendrasingh","key":"surendrasingh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=surendrasingh&avatarId=30759","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=surendrasingh&avatarId=30759","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=surendrasingh&avatarId=30759","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=surendrasingh&avatarId=30759"},"displayName":"Surendra Singh Lilhore","active":true,"timeZone":"Etc/UTC"},"body":"Hi [~msingh],\n\nThanks for the patch. I have one suggestion. HADOOP-13272 implemented storage policy APIs in ViewFs. I think you can remove DFS check and directly send the call to given filesystem. If in given filesystem this APIs are not implemented then command will get UnsupportedOperationException.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=surendrasingh","name":"surendrasingh","key":"surendrasingh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=surendrasingh&avatarId=30759","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=surendrasingh&avatarId=30759","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=surendrasingh&avatarId=30759","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=surendrasingh&avatarId=30759"},"displayName":"Surendra Singh Lilhore","active":true,"timeZone":"Etc/UTC"},"created":"2017-08-29T06:39:43.623+0000","updated":"2017-09-19T06:18:04.058+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13079178/comment/16155227","id":"16155227","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 14s{color} | {color:blue} Docker mode activated. {color} |\n|| || || || {color:brown} Prechecks {color} ||\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 2 new or modified test files. {color} |\n|| || || || {color:brown} trunk Compile Tests {color} ||\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 23s{color} | {color:blue} Maven dependency ordering for branch {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 15m 55s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 17m 15s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m  9s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  3m 14s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  5m 20s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m 17s{color} | {color:green} trunk passed {color} |\n|| || || || {color:brown} Patch Compile Tests {color} ||\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 18s{color} | {color:blue} Maven dependency ordering for patch {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  2m 29s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 12m 41s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 12m 41s{color} | {color:green} the patch passed {color} |\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  2m 15s{color} | {color:orange} root: The patch generated 8 new + 187 unchanged - 2 fixed = 195 total (was 189) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  3m  7s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  5m 29s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m  7s{color} | {color:green} the patch passed {color} |\n|| || || || {color:brown} Other Tests {color} ||\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}  7m 10s{color} | {color:red} hadoop-common in the patch failed. {color} |\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  1m 21s{color} | {color:green} hadoop-hdfs-client in the patch passed. {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}101m 17s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 33s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black}187m  0s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| Failed junit tests | hadoop.fs.shell.TestCopyFromLocal |\n|   | hadoop.metrics2.sink.TestFileSink |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailureWithRandomECPolicy |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure160 |\n|   | hadoop.hdfs.TestClientProtocolForPipelineRecovery |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure130 |\n|   | hadoop.hdfs.TestEncryptedTransfer |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure000 |\n|   | hadoop.hdfs.TestHdfsAdmin |\n|   | hadoop.hdfs.TestApplyingStoragePolicy |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure020 |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure090 |\n|   | hadoop.hdfs.TestLeaseRecoveryStriped |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure040 |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure010 |\n| Timed out junit tests | org.apache.hadoop.hdfs.TestWriteReadStripedFile |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:71bbb86 |\n| JIRA Issue | HDFS-11968 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12885547/HDFS-11968.005.patch |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux 7f36b9d03f98 3.13.0-123-generic #172-Ubuntu SMP Mon Jun 26 18:04:35 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / 1f3bc63 |\n| Default Java | 1.8.0_144 |\n| findbugs | v3.1.0-RC1 |\n| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/21018/artifact/patchprocess/diff-checkstyle-root.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/21018/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/21018/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |\n|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/21018/testReport/ |\n| modules | C: hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs-client hadoop-hdfs-project/hadoop-hdfs U: . |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/21018/console |\n| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2017-09-06T11:38:06.203+0000","updated":"2017-09-06T11:38:06.203+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13079178/comment/16169393","id":"16169393","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 18s{color} | {color:blue} Docker mode activated. {color} |\n|| || || || {color:brown} Prechecks {color} ||\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 3 new or modified test files. {color} |\n|| || || || {color:brown} trunk Compile Tests {color} ||\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 52s{color} | {color:blue} Maven dependency ordering for branch {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 15m 47s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 17m 59s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m 23s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  4m 12s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  6m 35s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m 50s{color} | {color:green} trunk passed {color} |\n|| || || || {color:brown} Patch Compile Tests {color} ||\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 17s{color} | {color:blue} Maven dependency ordering for patch {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  2m 55s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 13m  8s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} cc {color} | {color:green} 13m  8s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 13m  8s{color} | {color:green} the patch passed {color} |\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  2m 16s{color} | {color:orange} root: The patch generated 5 new + 217 unchanged - 3 fixed = 222 total (was 220) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  3m 31s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  6m 55s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m 42s{color} | {color:green} the patch passed {color} |\n|| || || || {color:brown} Other Tests {color} ||\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  9m  3s{color} | {color:green} hadoop-common in the patch passed. {color} |\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  1m 33s{color} | {color:green} hadoop-hdfs-client in the patch passed. {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}100m 40s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  4m 39s{color} | {color:green} hadoop-hdfs-httpfs in the patch passed. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 31s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black}200m 48s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| Failed junit tests | hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA |\n|   | hadoop.hdfs.server.namenode.TestReencryptionWithKMS |\n|   | hadoop.hdfs.server.namenode.metrics.TestNameNodeMetrics |\n|   | hadoop.hdfs.server.namenode.TestNamenodeCapacityReport |\n|   | hadoop.hdfs.TestLeaseRecoveryStriped |\n|   | hadoop.hdfs.server.namenode.TestNamenodeRetryCache |\n| Timed out junit tests | org.apache.hadoop.hdfs.TestWriteReadStripedFile |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:71bbb86 |\n| JIRA Issue | HDFS-11968 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12887552/HDFS-11968.006.patch |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  cc  |\n| uname | Linux dd76e161b587 3.13.0-129-generic #178-Ubuntu SMP Fri Aug 11 12:48:20 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / 8d7cc22 |\n| Default Java | 1.8.0_144 |\n| findbugs | v3.1.0-RC1 |\n| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/21187/artifact/patchprocess/diff-checkstyle-root.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/21187/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |\n|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/21187/testReport/ |\n| modules | C: hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs-client hadoop-hdfs-project/hadoop-hdfs hadoop-hdfs-project/hadoop-hdfs-httpfs U: . |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/21187/console |\n| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2017-09-17T19:31:35.497+0000","updated":"2017-09-17T19:31:35.497+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13079178/comment/16169529","id":"16169529","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=msingh","name":"msingh","key":"msingh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Mukul Kumar Singh","active":true,"timeZone":"Asia/Kolkata"},"body":"Thanks for the awesome suggestion [~surendrasingh], I have address the review comment in the latest patch.\n\nI have also added 2 tests as well, one for Viewfs and another for WebHdfs. We already have one test for HDFS.\nThis will help in extending storage policy admin commands to all the supported filesystem.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=msingh","name":"msingh","key":"msingh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Mukul Kumar Singh","active":true,"timeZone":"Asia/Kolkata"},"created":"2017-09-18T02:50:09.212+0000","updated":"2017-09-18T02:50:09.212+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13079178/comment/16171202","id":"16171202","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=surendrasingh","name":"surendrasingh","key":"surendrasingh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=surendrasingh&avatarId=30759","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=surendrasingh&avatarId=30759","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=surendrasingh&avatarId=30759","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=surendrasingh&avatarId=30759"},"displayName":"Surendra Singh Lilhore","active":true,"timeZone":"Etc/UTC"},"body":"Thanks [~msingh] for patch.\nI have some question for your patch.\n\n1. {{ViewFileSystem#resolveStoragePolicyPath()}} why this method is required ?. {{fsState.resolve}} already throwing {{FileNotFoundException}}. Only thing is proper exception message is missing in {{fsState.resolve}}.\n\n2. What is realId in BlockStoragePolicySpi? \n{code}\n+  /**\n+   * Return the real id of the storage policy.\n+   *\n+   * @return the real id of the storage policy.\n+   */\n+  byte getRealId();\n{code}\nIf it is local policy id for a file/directory then no need to add here. {{BlockStoragePolicySpi}} define one policy and its information. I think you are trying to get the file/directory local policy ID for {{StoragePolicyAdmin#GetStoragePolicyCommand}} command, which is currently {{HdfsFileStatus#getStoragePolicy()}} giving. One way to get it is {{HDFS-11298}}, but need to think we can add policyid in FileStatus or not.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=surendrasingh","name":"surendrasingh","key":"surendrasingh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=surendrasingh&avatarId=30759","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=surendrasingh&avatarId=30759","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=surendrasingh&avatarId=30759","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=surendrasingh&avatarId=30759"},"displayName":"Surendra Singh Lilhore","active":true,"timeZone":"Etc/UTC"},"created":"2017-09-19T07:01:33.427+0000","updated":"2017-09-19T07:01:33.427+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13079178/comment/16171294","id":"16171294","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=msingh","name":"msingh","key":"msingh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Mukul Kumar Singh","active":true,"timeZone":"Asia/Kolkata"},"body":"Thanks for the review [~surendrasingh],\n\n1) ViewFileSystem#resolveStoragePolicyPath() why this method is required ?. fsState.resolve already throwing FileNotFoundException. Only thing is proper exception message is missing in fsState.resolve.\nbq. Fixed by modifying the message in fsState.resolve.\n\n2) What is realId in BlockStoragePolicySpi? \nbq. As you have already noted, this was added to get the local policy id. With ViewFilesystem we cannot use the HdfsFileStatus.\nHence I thought of adding another field to fetch the local policy id of the command. This also avoid two rpc calls one for\na) getting the filestatus and b) for getting the list of all the storage policies for a namenode.\n\nI have updated the patch for 1) Please have a look and let me know of your comments.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=msingh","name":"msingh","key":"msingh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Mukul Kumar Singh","active":true,"timeZone":"Asia/Kolkata"},"created":"2017-09-19T08:20:14.852+0000","updated":"2017-09-19T08:20:14.852+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13079178/comment/16171565","id":"16171565","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 16s{color} | {color:blue} Docker mode activated. {color} |\n|| || || || {color:brown} Prechecks {color} ||\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 3 new or modified test files. {color} |\n|| || || || {color:brown} trunk Compile Tests {color} ||\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 19s{color} | {color:blue} Maven dependency ordering for branch {color} |\n| {color:red}-1{color} | {color:red} mvninstall {color} | {color:red} 15m 28s{color} | {color:red} root in trunk failed. {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 17m  7s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m 14s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  3m 55s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  6m  9s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m 37s{color} | {color:green} trunk passed {color} |\n|| || || || {color:brown} Patch Compile Tests {color} ||\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 18s{color} | {color:blue} Maven dependency ordering for patch {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  2m 37s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 12m 40s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} cc {color} | {color:green} 12m 40s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 12m 40s{color} | {color:green} the patch passed {color} |\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  2m 18s{color} | {color:orange} root: The patch generated 3 new + 188 unchanged - 4 fixed = 191 total (was 192) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  3m 38s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  6m 30s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m 36s{color} | {color:green} the patch passed {color} |\n|| || || || {color:brown} Other Tests {color} ||\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  8m 33s{color} | {color:green} hadoop-common in the patch passed. {color} |\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  1m 21s{color} | {color:green} hadoop-hdfs-client in the patch passed. {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}105m 45s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  3m 35s{color} | {color:green} hadoop-hdfs-httpfs in the patch passed. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 31s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black}200m  4s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| Failed junit tests | hadoop.hdfs.TestPread |\n|   | hadoop.hdfs.server.namenode.metrics.TestNameNodeMetrics |\n|   | hadoop.hdfs.TestBalancerBandwidth |\n|   | hadoop.hdfs.server.namenode.TestDecommissioningStatus |\n|   | hadoop.hdfs.TestParallelShortCircuitReadNoChecksum |\n|   | hadoop.hdfs.server.balancer.TestBalancer |\n|   | hadoop.hdfs.TestLeaseRecoveryStriped |\n|   | hadoop.hdfs.TestParallelUnixDomainRead |\n|   | hadoop.hdfs.server.datanode.TestDirectoryScanner |\n|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting |\n|   | hadoop.hdfs.server.datanode.fsdataset.impl.TestLazyPersistReplicaRecovery |\n| Timed out junit tests | org.apache.hadoop.hdfs.TestWriteReadStripedFile |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:71bbb86 |\n| JIRA Issue | HDFS-11968 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12887848/HDFS-11968.007.patch |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  cc  |\n| uname | Linux c5adccfa66ab 3.13.0-123-generic #172-Ubuntu SMP Mon Jun 26 18:04:35 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / 2018538 |\n| Default Java | 1.8.0_144 |\n| mvninstall | https://builds.apache.org/job/PreCommit-HDFS-Build/21209/artifact/patchprocess/branch-mvninstall-root.txt |\n| findbugs | v3.1.0-RC1 |\n| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/21209/artifact/patchprocess/diff-checkstyle-root.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/21209/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |\n|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/21209/testReport/ |\n| modules | C: hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs-client hadoop-hdfs-project/hadoop-hdfs hadoop-hdfs-project/hadoop-hdfs-httpfs U: . |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/21209/console |\n| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2017-09-19T11:41:16.555+0000","updated":"2017-09-19T11:41:16.555+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13079178/comment/16173678","id":"16173678","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=surendrasingh","name":"surendrasingh","key":"surendrasingh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=surendrasingh&avatarId=30759","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=surendrasingh&avatarId=30759","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=surendrasingh&avatarId=30759","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=surendrasingh&avatarId=30759"},"displayName":"Surendra Singh Lilhore","active":true,"timeZone":"Etc/UTC"},"body":"Thanks [~msingh] patch. {{getStoragePolicy}} command is depend on {{HdfsFileStatus}} and {{BlockStoragePolicy}} to get the policy Id, which is specific to the HDFS. Lets not change any public interface({{BlockStoragePolicySpi}}) to get the policy ID. \nTry this code for {{getStoragePolicy}} command.\n{code}\n      try {\n        FileStatus status;\n        try {\n          status = fs.getFileStatus(new Path(path));\n        } catch (FileNotFoundException e) {\n          System.err.println(\"File/Directory does not exist: \" + path);\n          return 2;\n        }\n        if (status instanceof HdfsFileStatus) {\n          byte storagePolicyId = ((HdfsFileStatus) status).getStoragePolicy();\n          if (storagePolicyId == HdfsConstants.BLOCK_STORAGE_POLICY_ID_UNSPECIFIED) {\n            System.out.println(\"The storage policy of \" + path\n                + \" is unspecified\");\n            return 0;\n          }\n          Collection<? extends BlockStoragePolicySpi> policies = fs\n              .getAllStoragePolicies();\n          for (BlockStoragePolicySpi policy : policies) {\n            if (policy instanceof BlockStoragePolicy) {\n              if (((BlockStoragePolicy) policy).getId() == storagePolicyId) {\n                System.out.println(\"The storage policy of \" + path + \":\\n\"\n                    + policy);\n                return 0;\n              }\n            }\n          }\n        }\n        System.out.println(getName() + \" is not supported for filesystem \"\n            + fs.getScheme() + \" on path \" + path);\n        return 2;\n      } catch (Exception e) {\n        System.err.println(AdminHelper.prettifyException(e));\n        return 2;\n      }\n{code}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=surendrasingh","name":"surendrasingh","key":"surendrasingh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=surendrasingh&avatarId=30759","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=surendrasingh&avatarId=30759","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=surendrasingh&avatarId=30759","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=surendrasingh&avatarId=30759"},"displayName":"Surendra Singh Lilhore","active":true,"timeZone":"Etc/UTC"},"created":"2017-09-20T18:59:19.371+0000","updated":"2017-09-20T18:59:19.371+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13079178/comment/16173700","id":"16173700","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=surendrasingh","name":"surendrasingh","key":"surendrasingh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=surendrasingh&avatarId=30759","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=surendrasingh&avatarId=30759","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=surendrasingh&avatarId=30759","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=surendrasingh&avatarId=30759"},"displayName":"Surendra Singh Lilhore","active":true,"timeZone":"Etc/UTC"},"body":"Please handle some more comments\n1. No need of adding new methods in {{BlockStoragePolicySpi}}. Remove these methods.\n{code}\n   /**\n\n+  byte getId();\n+\n\n+  byte getRealId();\n{code}\n2. Please don't change any code which is not related to this patch, like \n{code}\n-      AdminHelper.printUsage(false, \"storagepolicies\", COMMANDS);\n+      AdminHelper\n+          .printUsage(false, \"storagepolicies\", COMMANDS);\n{code}\n3. {{InodeTree.java}} changes is not required.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=surendrasingh","name":"surendrasingh","key":"surendrasingh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=surendrasingh&avatarId=30759","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=surendrasingh&avatarId=30759","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=surendrasingh&avatarId=30759","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=surendrasingh&avatarId=30759"},"displayName":"Surendra Singh Lilhore","active":true,"timeZone":"Etc/UTC"},"created":"2017-09-20T19:11:09.750+0000","updated":"2017-09-20T19:11:09.750+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13079178/comment/16174470","id":"16174470","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=msingh","name":"msingh","key":"msingh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Mukul Kumar Singh","active":true,"timeZone":"Asia/Kolkata"},"body":"Hi [~surendrasingh], Thanks for the review. I have applied all of you review comments in the patch v8. Thanks for your the review. Please have a look again.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=msingh","name":"msingh","key":"msingh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Mukul Kumar Singh","active":true,"timeZone":"Asia/Kolkata"},"created":"2017-09-21T09:05:23.308+0000","updated":"2017-09-21T09:05:23.308+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13079178/comment/16174565","id":"16174565","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 12s{color} | {color:blue} Docker mode activated. {color} |\n|| || || || {color:brown} Prechecks {color} ||\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 3 new or modified test files. {color} |\n|| || || || {color:brown} trunk Compile Tests {color} ||\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 12m 53s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 43s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 35s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 49s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 34s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 37s{color} | {color:green} trunk passed {color} |\n|| || || || {color:brown} Patch Compile Tests {color} ||\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 42s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 43s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 43s{color} | {color:green} the patch passed {color} |\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 29s{color} | {color:orange} hadoop-hdfs-project/hadoop-hdfs: The patch generated 3 new + 5 unchanged - 3 fixed = 8 total (was 8) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 45s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  1m 43s{color} | {color:red} hadoop-hdfs-project/hadoop-hdfs generated 1 new + 0 unchanged - 0 fixed = 1 total (was 0) {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 37s{color} | {color:green} the patch passed {color} |\n|| || || || {color:brown} Other Tests {color} ||\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 83m  1s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 16s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black}106m 50s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| FindBugs | module:hadoop-hdfs-project/hadoop-hdfs |\n|  |  Redundant nullcheck of policy, which is known to be non-null in org.apache.hadoop.hdfs.tools.StoragePolicyAdmin$ListStoragePoliciesCommand.run(Configuration, List)  Redundant null check at StoragePolicyAdmin.java:is known to be non-null in org.apache.hadoop.hdfs.tools.StoragePolicyAdmin$ListStoragePoliciesCommand.run(Configuration, List)  Redundant null check at StoragePolicyAdmin.java:[line 113] |\n| Failed junit tests | hadoop.hdfs.web.TestWebHdfsTimeouts |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:71bbb86 |\n| JIRA Issue | HDFS-11968 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12888240/HDFS-11968.008.patch |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux 74968f765a03 4.4.0-43-generic #63-Ubuntu SMP Wed Oct 12 13:48:03 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / 8b33663 |\n| Default Java | 1.8.0_144 |\n| findbugs | v3.1.0-RC1 |\n| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/21276/artifact/patchprocess/diff-checkstyle-hadoop-hdfs-project_hadoop-hdfs.txt |\n| findbugs | https://builds.apache.org/job/PreCommit-HDFS-Build/21276/artifact/patchprocess/new-findbugs-hadoop-hdfs-project_hadoop-hdfs.html |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/21276/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |\n|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/21276/testReport/ |\n| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/21276/console |\n| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2017-09-21T10:58:13.514+0000","updated":"2017-09-21T10:58:13.514+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13079178/comment/16174596","id":"16174596","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=msingh","name":"msingh","key":"msingh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Mukul Kumar Singh","active":true,"timeZone":"Asia/Kolkata"},"body":"patch v9 fixes the findbugs issue.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=msingh","name":"msingh","key":"msingh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Mukul Kumar Singh","active":true,"timeZone":"Asia/Kolkata"},"created":"2017-09-21T11:27:36.777+0000","updated":"2017-09-21T11:27:36.777+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13079178/comment/16174760","id":"16174760","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (/) *{color:green}+1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 15m  7s{color} | {color:blue} Docker mode activated. {color} |\n|| || || || {color:brown} Prechecks {color} ||\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 3 new or modified test files. {color} |\n|| || || || {color:brown} trunk Compile Tests {color} ||\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 13m 44s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 51s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 36s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 55s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 43s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 42s{color} | {color:green} trunk passed {color} |\n|| || || || {color:brown} Patch Compile Tests {color} ||\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 49s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 46s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 46s{color} | {color:green} the patch passed {color} |\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 34s{color} | {color:orange} hadoop-hdfs-project/hadoop-hdfs: The patch generated 3 new + 5 unchanged - 3 fixed = 8 total (was 8) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 52s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 46s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 39s{color} | {color:green} the patch passed {color} |\n|| || || || {color:brown} Other Tests {color} ||\n| {color:green}+1{color} | {color:green} unit {color} | {color:green} 85m 48s{color} | {color:green} hadoop-hdfs in the patch passed. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 16s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black}126m 27s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:71bbb86 |\n| JIRA Issue | HDFS-11968 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12888258/HDFS-11968.009.patch |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux 6b06d72c8b58 3.13.0-119-generic #166-Ubuntu SMP Wed May 3 12:18:55 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / 50849ec |\n| Default Java | 1.8.0_144 |\n| findbugs | v3.1.0-RC1 |\n| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/21278/artifact/patchprocess/diff-checkstyle-hadoop-hdfs-project_hadoop-hdfs.txt |\n|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/21278/testReport/ |\n| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/21278/console |\n| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2017-09-21T13:38:41.040+0000","updated":"2017-09-21T13:38:41.040+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13079178/comment/16175936","id":"16175936","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=surendrasingh","name":"surendrasingh","key":"surendrasingh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=surendrasingh&avatarId=30759","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=surendrasingh&avatarId=30759","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=surendrasingh&avatarId=30759","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=surendrasingh&avatarId=30759"},"displayName":"Surendra Singh Lilhore","active":true,"timeZone":"Etc/UTC"},"body":"Thanks [~msingh] for patch..\n\nA few comments:\n# No need to catch {{FileNotFoundException}} explicitly in {{UnsetStoragePolicyCommand}} and {{SetStoragePolicyCommand}}. In {{GetStoragePolicyCommand}} handling {{FileNotFoundException}} because of compatibility issue. Message give by DistributedFileSystem in {{FileNotFoundException}} is different from the message in {{GetStoragePolicyCommand}}. I don't want to change it.\n{code}\n        HdfsFileStatus status = dfs.getClient().getFileInfo(\n            Path.getPathWithoutSchemeAndAuthority(p).toString());\n        if (status == null) {\n          System.err.println(\"File/Directory does not exist: \" + path);\n          return 2;\n        }\n{code}\n# Please handle the checkstyle warnings.\n\nOtherwise LGTM..\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=surendrasingh","name":"surendrasingh","key":"surendrasingh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=surendrasingh&avatarId=30759","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=surendrasingh&avatarId=30759","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=surendrasingh&avatarId=30759","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=surendrasingh&avatarId=30759"},"displayName":"Surendra Singh Lilhore","active":true,"timeZone":"Etc/UTC"},"created":"2017-09-22T05:28:38.766+0000","updated":"2017-09-22T05:28:38.766+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13079178/comment/16175968","id":"16175968","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=msingh","name":"msingh","key":"msingh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Mukul Kumar Singh","active":true,"timeZone":"Asia/Kolkata"},"body":"Thanks for the review [~surendrasingh]\n\n1) No need to catch FileNotFoundException explicitly in UnsetStoragePolicyCommand and SetStoragePolicyCommand. In GetStoragePolicyCommand handling FileNotFoundException because of compatibility issue. Message give by DistributedFileSystem in FileNotFoundException is different from the message in GetStoragePolicyCommand. I don't want to change it. \n\nbq. The exception handling in UnsetStoragePolicyCommand/SetStoragePolicyCommand is needed to make sure that the error message returned as part of ViewFileSystem is the same as the one returned by HDFS.\nIf FileNotFoundException is not handled then the error message will be {{FileNotFoundException: /fooz}} where as for HDFS a FileNotFoundException results in error mesage {{File/Directory does not exist: /fooz}}.\n\nWe can decide to either have different error messages for ViewFileSystem or this can be fixed by modifying the exception message in {{InodeTree.java:resolve}}\n{code}\n          failedAt.append('/').append(path[j]);\n        }\n        throw (new FileNotFoundException(failedAt.toString()));\n      }\n{code}\nor by handling the FileNotFoundException in the UnsetStoragePolicyCommand/SetStoragePolicyCommand handler.\n\nPlease let me know of you opinion :)\n\n2) Please handle the checkstyle warnings.\nbq. In order to write unit test with WebHDFSFileSystem and ViewFileSystem, fields conf, cluster and fs have been made protected which is resulting in the checkstyle warning.  ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=msingh","name":"msingh","key":"msingh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Mukul Kumar Singh","active":true,"timeZone":"Asia/Kolkata"},"created":"2017-09-22T06:07:05.608+0000","updated":"2017-09-22T06:07:33.473+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13079178/comment/16176022","id":"16176022","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=surendrasingh","name":"surendrasingh","key":"surendrasingh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=surendrasingh&avatarId=30759","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=surendrasingh&avatarId=30759","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=surendrasingh&avatarId=30759","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=surendrasingh&avatarId=30759"},"displayName":"Surendra Singh Lilhore","active":true,"timeZone":"Etc/UTC"},"body":"bq. We can decide to either have different error messages for ViewFileSystem or this can be fixed by modifying the exception message in InodeTree.java:resolve\n\nIts better to handle in {{InodeTree.java:resolve}}.\n\nbq. In order to write unit test with WebHDFSFileSystem and ViewFileSystem, fields conf, cluster and fs have been made protected which is resulting in the checkstyle warning.\n\nokay","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=surendrasingh","name":"surendrasingh","key":"surendrasingh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=surendrasingh&avatarId=30759","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=surendrasingh&avatarId=30759","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=surendrasingh&avatarId=30759","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=surendrasingh&avatarId=30759"},"displayName":"Surendra Singh Lilhore","active":true,"timeZone":"Etc/UTC"},"created":"2017-09-22T07:09:04.768+0000","updated":"2017-09-22T07:09:04.768+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13079178/comment/16176084","id":"16176084","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=msingh","name":"msingh","key":"msingh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Mukul Kumar Singh","active":true,"timeZone":"Asia/Kolkata"},"body":"Thanks for the review [~surendrasingh],   Patch v10 fixes the review comment. Please have a look again.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=msingh","name":"msingh","key":"msingh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Mukul Kumar Singh","active":true,"timeZone":"Asia/Kolkata"},"created":"2017-09-22T08:00:51.419+0000","updated":"2017-09-22T08:00:51.419+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13079178/comment/16176130","id":"16176130","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=surendrasingh","name":"surendrasingh","key":"surendrasingh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=surendrasingh&avatarId=30759","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=surendrasingh&avatarId=30759","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=surendrasingh&avatarId=30759","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=surendrasingh&avatarId=30759"},"displayName":"Surendra Singh Lilhore","active":true,"timeZone":"Etc/UTC"},"body":"+1 LGTM, pending jenkins.\n[~arpitagarwal], [~manojg] do you want to take a look at latest patch?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=surendrasingh","name":"surendrasingh","key":"surendrasingh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=surendrasingh&avatarId=30759","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=surendrasingh&avatarId=30759","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=surendrasingh&avatarId=30759","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=surendrasingh&avatarId=30759"},"displayName":"Surendra Singh Lilhore","active":true,"timeZone":"Etc/UTC"},"created":"2017-09-22T08:52:33.805+0000","updated":"2017-09-22T08:52:33.805+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13079178/comment/16176264","id":"16176264","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 14s{color} | {color:blue} Docker mode activated. {color} |\n|| || || || {color:brown} Prechecks {color} ||\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 3 new or modified test files. {color} |\n|| || || || {color:brown} trunk Compile Tests {color} ||\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 20s{color} | {color:blue} Maven dependency ordering for branch {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 15m 29s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 17m 39s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m 18s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  2m 18s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  3m 51s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 49s{color} | {color:green} trunk passed {color} |\n|| || || || {color:brown} Patch Compile Tests {color} ||\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 19s{color} | {color:blue} Maven dependency ordering for patch {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m 46s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 10m 58s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 10m 58s{color} | {color:green} the patch passed {color} |\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  2m  0s{color} | {color:orange} root: The patch generated 3 new + 27 unchanged - 3 fixed = 30 total (was 30) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 59s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  3m 27s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 38s{color} | {color:green} the patch passed {color} |\n|| || || || {color:brown} Other Tests {color} ||\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}  8m  4s{color} | {color:red} hadoop-common in the patch failed. {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 90m 16s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 31s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black}166m 17s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| Failed junit tests | hadoop.security.TestKDiag |\n|   | hadoop.hdfs.qjournal.server.TestJournalNodeSync |\n|   | hadoop.hdfs.server.namenode.TestReencryption |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:71bbb86 |\n| JIRA Issue | HDFS-11968 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12888457/HDFS-11968.010.patch |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux 9d19ab1c894d 3.13.0-117-generic #164-Ubuntu SMP Fri Apr 7 11:05:26 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / c71d137 |\n| Default Java | 1.8.0_144 |\n| findbugs | v3.1.0-RC1 |\n| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/21301/artifact/patchprocess/diff-checkstyle-root.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/21301/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/21301/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |\n|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/21301/testReport/ |\n| modules | C: hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs U: . |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/21301/console |\n| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2017-09-22T10:57:55.859+0000","updated":"2017-09-22T10:57:55.859+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13079178/comment/16177264","id":"16177264","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=arpitagarwal","name":"arpitagarwal","key":"arpitagarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arpit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi [~msingh], [~surendrasingh], \n\nWhat is the expected behavior now when running the getStoragePolicies command against a viewfs path?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=arpitagarwal","name":"arpitagarwal","key":"arpitagarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arpit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-09-22T22:24:21.247+0000","updated":"2017-09-22T22:24:21.247+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13079178/comment/16177588","id":"16177588","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=surendrasingh","name":"surendrasingh","key":"surendrasingh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=surendrasingh&avatarId=30759","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=surendrasingh&avatarId=30759","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=surendrasingh&avatarId=30759","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=surendrasingh&avatarId=30759"},"displayName":"Surendra Singh Lilhore","active":true,"timeZone":"Etc/UTC"},"body":"Thanks [~arpitagarwal].\nIf the given path is mounted with the *hdfs* filesystem then no change in behavior, otherwise command will fail and give message like {color:red}\"getStoragePolicies  is not supported for filesystem viewfs on path <path>\".{color}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=surendrasingh","name":"surendrasingh","key":"surendrasingh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=surendrasingh&avatarId=30759","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=surendrasingh&avatarId=30759","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=surendrasingh&avatarId=30759","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=surendrasingh&avatarId=30759"},"displayName":"Surendra Singh Lilhore","active":true,"timeZone":"Etc/UTC"},"created":"2017-09-23T06:09:21.590+0000","updated":"2017-09-23T06:09:21.590+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13079178/comment/16177689","id":"16177689","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=msingh","name":"msingh","key":"msingh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Mukul Kumar Singh","active":true,"timeZone":"Asia/Kolkata"},"body":"Hi [~arpitagarwal], I ran the following commands on a viewfs,hdfs and webhdfs based instances and following are the list of commands and their output.\n\nViewFS based uri\n{code}\n*core-site.xml*\n <property>\n    <name>fs.default.name</name>\n    <value>viewfs://cluster1</value>\n    </description>\n    <final>true</final>\n  </property>\n  <property>\n    <name>fs.viewfs.mounttable.cluster1.link./home</name>\n    <value>hdfs://127.0.0.1:8020/dir1</value>\n  </property>\n  <property>\n    <name>fs.viewfs.mounttable.cluster1.link./tmp</name>\n    <value>hdfs://127.0.0.1:8020/dir2</value>\n  </property>\n\n*list storage policies*\n[root@304a057b260f opt]# /opt/hadoop-3.1.0-SNAPSHOT/bin/hdfs storagepolicies -listPolicies\nBlock Storage Policies:\n\tBlockStoragePolicy{COLD:2, storageTypes=[ARCHIVE], creationFallbacks=[], replicationFallbacks=[]}\n\tBlockStoragePolicy{WARM:5, storageTypes=[DISK, ARCHIVE], creationFallbacks=[DISK, ARCHIVE], replicationFallbacks=[DISK, ARCHIVE]}\n\tBlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}\n\tBlockStoragePolicy{ONE_SSD:10, storageTypes=[SSD, DISK], creationFallbacks=[SSD, DISK], replicationFallbacks=[SSD, DISK]}\n\tBlockStoragePolicy{ALL_SSD:12, storageTypes=[SSD], creationFallbacks=[DISK], replicationFallbacks=[DISK]}\n\tBlockStoragePolicy{LAZY_PERSIST:15, storageTypes=[RAM_DISK, DISK], creationFallbacks=[DISK], replicationFallbacks=[DISK]}\n\n*set storage policy*\n[root@304a057b260f opt]# /opt/hadoop-3.1.0-SNAPSHOT/bin/hdfs storagepolicies -setStoragePolicy -path /home -policy ALL_SSD\nSet storage policy ALL_SSD on /home\n\n*get storage policies after setting a policy*\n[root@304a057b260f opt]# /opt/hadoop-3.1.0-SNAPSHOT/bin/hdfs storagepolicies -getStoragePolicy -path /home\nThe storage policy of /home:\nBlockStoragePolicy{ALL_SSD:12, storageTypes=[SSD], creationFallbacks=[DISK], replicationFallbacks=[DISK]\n\n*unset storage policy*\n[root@304a057b260f opt]# /opt/hadoop-3.1.0-SNAPSHOT/bin/hdfs storagepolicies -unsetStoragePolicy -path /home\nUnset storage policy from /home\n{code}\n\nWeb HDFS based uri\n{code}\n*core site*\n    <name>fs.default.name</name>\n    <value>webhdfs://127.0.0.1:9870/</value>\n\n*list storage policy*\n[root@304a057b260f opt]# /opt/hadoop-3.1.0-SNAPSHOT/bin/hdfs storagepolicies -listPolicies\nBlock Storage Policies:\n\tBlockStoragePolicy{COLD:2, storageTypes=[ARCHIVE], creationFallbacks=[], replicationFallbacks=[]}\n\tBlockStoragePolicy{WARM:5, storageTypes=[DISK, ARCHIVE], creationFallbacks=[DISK, ARCHIVE], replicationFallbacks=[DISK, ARCHIVE]}\n\tBlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}\n\tBlockStoragePolicy{ONE_SSD:10, storageTypes=[SSD, DISK], creationFallbacks=[SSD, DISK], replicationFallbacks=[SSD, DISK]}\n\tBlockStoragePolicy{ALL_SSD:12, storageTypes=[SSD], creationFallbacks=[DISK], replicationFallbacks=[DISK]}\n\tBlockStoragePolicy{LAZY_PERSIST:15, storageTypes=[RAM_DISK, DISK], creationFallbacks=[DISK], replicationFallbacks=[DISK]}\n\n*set storage policy*\n[root@304a057b260f opt]# /opt/hadoop-3.1.0-SNAPSHOT/bin/hdfs storagepolicies -setStoragePolicy -path /dir2 -policy WARM\nSet storage policy WARM on /dir2\n\n*get storage policy*\n[root@304a057b260f opt]# /opt/hadoop-3.1.0-SNAPSHOT/bin/hdfs storagepolicies -getStoragePolicy -path /dir2\nThe storage policy of /dir2:\nBlockStoragePolicy{WARM:5, storageTypes=[DISK, ARCHIVE], creationFallbacks=[DISK, ARCHIVE], replicationFallbacks=[DISK, ARCHIVE]}\n{code}\n\nHDFS based uri\n{code}\n*core site*\n    <name>fs.default.name</name>\n    <value>hdfs://127.0.0.1:8020/</value>\n\n*list storage policy*\n[root@304a057b260f opt]# /opt/hadoop-3.1.0-SNAPSHOT/bin/hdfs storagepolicies -listPolicies\nBlock Storage Policies:\n\tBlockStoragePolicy{COLD:2, storageTypes=[ARCHIVE], creationFallbacks=[], replicationFallbacks=[]}\n\tBlockStoragePolicy{WARM:5, storageTypes=[DISK, ARCHIVE], creationFallbacks=[DISK, ARCHIVE], replicationFallbacks=[DISK, ARCHIVE]}\n\tBlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}\n\tBlockStoragePolicy{ONE_SSD:10, storageTypes=[SSD, DISK], creationFallbacks=[SSD, DISK], replicationFallbacks=[SSD, DISK]}\n\tBlockStoragePolicy{ALL_SSD:12, storageTypes=[SSD], creationFallbacks=[DISK], replicationFallbacks=[DISK]}\n\tBlockStoragePolicy{LAZY_PERSIST:15, storageTypes=[RAM_DISK, DISK], creationFallbacks=[DISK], replicationFallbacks=[DISK]}\n\n*set storage policy*\n[root@304a057b260f opt]# /opt/hadoop-3.1.0-SNAPSHOT/bin/hdfs storagepolicies -setStoragePolicy -path /dir1 -policy COLD\nSet storage policy COLD on /dir1\n\n*get storage policy*\n[root@304a057b260f opt]# /opt/hadoop-3.1.0-SNAPSHOT/bin/hdfs storagepolicies -getStoragePolicy -path /dir1\nThe storage policy of /dir1:\nBlockStoragePolicy{COLD:2, storageTypes=[ARCHIVE], creationFallbacks=[], replicationFallbacks=[]}\n{code}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=msingh","name":"msingh","key":"msingh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Mukul Kumar Singh","active":true,"timeZone":"Asia/Kolkata"},"created":"2017-09-23T09:43:04.660+0000","updated":"2017-09-23T09:43:04.660+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13079178/comment/16187767","id":"16187767","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=msingh","name":"msingh","key":"msingh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Mukul Kumar Singh","active":true,"timeZone":"Asia/Kolkata"},"body":"The support for StoragePolicy was added to ViewFileSystem with HADOOP-13272.\n\nThe current patch makes use of this api to find out the underlying storage policies. Here is the output for 2 namenode setup\n{code}\n[hdfs@y126 ~]$ /opt/hadoop/hadoop-3.1.0-SNAPSHOT/bin/hdfs storagepolicies -listPolicies\n17/10/02 08:39:43 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\nBlock Storage Policies:\n\tBlockStoragePolicy{COLD:2, storageTypes=[ARCHIVE], creationFallbacks=[], replicationFallbacks=[]}\n\tBlockStoragePolicy{WARM:5, storageTypes=[DISK, ARCHIVE], creationFallbacks=[DISK, ARCHIVE], replicationFallbacks=[DISK, ARCHIVE]}\n\tBlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}\n\tBlockStoragePolicy{ONE_SSD:10, storageTypes=[SSD, DISK], creationFallbacks=[SSD, DISK], replicationFallbacks=[SSD, DISK]}\n\tBlockStoragePolicy{ALL_SSD:12, storageTypes=[SSD], creationFallbacks=[DISK], replicationFallbacks=[DISK]}\n\tBlockStoragePolicy{LAZY_PERSIST:15, storageTypes=[RAM_DISK, DISK], creationFallbacks=[DISK], replicationFallbacks=[DISK]}\n{code}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=msingh","name":"msingh","key":"msingh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Mukul Kumar Singh","active":true,"timeZone":"Asia/Kolkata"},"created":"2017-10-02T08:46:43.233+0000","updated":"2017-10-02T08:46:43.233+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13079178/comment/16188892","id":"16188892","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=arpitagarwal","name":"arpitagarwal","key":"arpitagarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arpit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks [~msingh]. Your patch looks good to me. We can fix the behavior introduced by HADOOP-13272 separately.\n\nTwo minor comments, but I am +1 basically.\n# The {{instanceof}} check is unnecessary. You can just print the policy object if it is non-null.\n{code}\n+          if ((policy != null) && (policy instanceof BlockStoragePolicy)) {\n             System.out.println(\"\\t\" + policy);\n{code}\n# The following error should go to stderr (via System.err.println)\n{code}\n        System.out.println(getName() + \" is not supported for filesystem \"\n            + fs.getScheme() + \" on path \" + path);\n{code}\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=arpitagarwal","name":"arpitagarwal","key":"arpitagarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arpit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-10-02T21:39:56.312+0000","updated":"2017-10-03T03:46:11.525+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13079178/comment/16189189","id":"16189189","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=msingh","name":"msingh","key":"msingh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Mukul Kumar Singh","active":true,"timeZone":"Asia/Kolkata"},"body":"Thanks for the review [~arpitagarwal], I have fixed the review comments in the latest patch.\n\nI have also raised HDFS-12581 to fix the issue with getAllStoragePolicies.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=msingh","name":"msingh","key":"msingh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Mukul Kumar Singh","active":true,"timeZone":"Asia/Kolkata"},"created":"2017-10-03T02:35:31.573+0000","updated":"2017-10-03T02:35:31.573+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13079178/comment/16189221","id":"16189221","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=arpitagarwal","name":"arpitagarwal","key":"arpitagarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arpit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"body":"+1 for the v11 patch. Thanks [~msingh].\n\n[~surendrasingh]/[~manojg], are you okay with the latest patch? I will hold off committing for now in case you have additional comments.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=arpitagarwal","name":"arpitagarwal","key":"arpitagarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arpit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-10-03T03:42:11.894+0000","updated":"2017-10-03T03:45:16.639+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13079178/comment/16189288","id":"16189288","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 52s{color} | {color:blue} Docker mode activated. {color} |\n|| || || || {color:brown} Prechecks {color} ||\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 3 new or modified test files. {color} |\n|| || || || {color:brown} trunk Compile Tests {color} ||\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 45s{color} | {color:blue} Maven dependency ordering for branch {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 13m 47s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 16m 35s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m 20s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  2m  4s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 13m 12s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  3m 12s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 36s{color} | {color:green} trunk passed {color} |\n|| || || || {color:brown} Patch Compile Tests {color} ||\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 14s{color} | {color:blue} Maven dependency ordering for patch {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m 28s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 11m 30s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 11m 30s{color} | {color:green} the patch passed {color} |\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  2m  3s{color} | {color:orange} root: The patch generated 3 new + 27 unchanged - 3 fixed = 30 total (was 30) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 59s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green}  9m 21s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  4m  8s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 49s{color} | {color:green} the patch passed {color} |\n|| || || || {color:brown} Other Tests {color} ||\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  9m 12s{color} | {color:green} hadoop-common in the patch passed. {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}108m 34s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 36s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black}202m 16s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| Failed junit tests | hadoop.hdfs.TestLeaseRecoveryStriped |\n|   | hadoop.hdfs.qjournal.server.TestJournalNodeSync |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:71bbb86 |\n| JIRA Issue | HDFS-11968 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12890087/HDFS-11968.011.patch |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |\n| uname | Linux f5a37e49cc99 3.13.0-116-generic #163-Ubuntu SMP Fri Mar 31 14:13:22 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / d4d2fd1 |\n| Default Java | 1.8.0_144 |\n| findbugs | v3.1.0-RC1 |\n| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/21493/artifact/patchprocess/diff-checkstyle-root.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/21493/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |\n|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/21493/testReport/ |\n| modules | C: hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs U: . |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/21493/console |\n| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2017-10-03T05:40:26.474+0000","updated":"2017-10-03T05:40:26.474+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13079178/comment/16189504","id":"16189504","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=surendrasingh","name":"surendrasingh","key":"surendrasingh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=surendrasingh&avatarId=30759","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=surendrasingh&avatarId=30759","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=surendrasingh&avatarId=30759","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=surendrasingh&avatarId=30759"},"displayName":"Surendra Singh Lilhore","active":true,"timeZone":"Etc/UTC"},"body":"+1 LGTM.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=surendrasingh","name":"surendrasingh","key":"surendrasingh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=surendrasingh&avatarId=30759","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=surendrasingh&avatarId=30759","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=surendrasingh&avatarId=30759","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=surendrasingh&avatarId=30759"},"displayName":"Surendra Singh Lilhore","active":true,"timeZone":"Etc/UTC"},"created":"2017-10-03T10:16:43.516+0000","updated":"2017-10-03T10:16:43.516+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13079178/comment/16190101","id":"16190101","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=arpitagarwal","name":"arpitagarwal","key":"arpitagarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arpit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"body":"I've committed this. Thanks for the contribution [~msingh]. Thanks for the reviews and ideas Surendra and Manoj.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=arpitagarwal","name":"arpitagarwal","key":"arpitagarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arpit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-10-03T18:25:19.586+0000","updated":"2017-10-03T18:25:19.586+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13079178/comment/16190135","id":"16190135","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"SUCCESS: Integrated in Jenkins build Hadoop-trunk-Commit #13014 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/13014/])\nHDFS-11968. ViewFS: StoragePolicies commands fail with HDFS federation. (arp: rev b91305119b434d23b99ae7e755aea6639f48b6ab)\n* (edit) hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestStoragePolicyCommands.java\n* (edit) hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/viewfs/InodeTree.java\n* (edit) hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/StoragePolicyAdmin.java\n* (add) hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestWebHDFSStoragePolicyCommands.java\n* (add) hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestViewFSStoragePolicyCommands.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2017-10-03T18:47:21.861+0000","updated":"2017-10-03T18:47:21.861+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13079178/comment/16429081","id":"16429081","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xiaochen","name":"xiaochen","key":"xiaochen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=xiaochen&avatarId=24893","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=xiaochen&avatarId=24893","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=xiaochen&avatarId=24893","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=xiaochen&avatarId=24893"},"displayName":"Xiao Chen","active":true,"timeZone":"America/Los_Angeles"},"body":"Pushed this to branch-3.0, thanks for the work here","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xiaochen","name":"xiaochen","key":"xiaochen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=xiaochen&avatarId=24893","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=xiaochen&avatarId=24893","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=xiaochen&avatarId=24893","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=xiaochen&avatarId=24893"},"displayName":"Xiao Chen","active":true,"timeZone":"America/Los_Angeles"},"created":"2018-04-06T22:18:46.357+0000","updated":"2018-04-06T22:18:46.357+0000"}],"maxResults":40,"total":40,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-11968/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i3g5un:"}}