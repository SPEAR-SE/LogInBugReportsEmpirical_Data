{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12436325","self":"https://issues.apache.org/jira/rest/api/2/issue/12436325","key":"HDFS-641","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12314046","id":"12314046","description":"","name":"0.21.0","archived":false,"released":true,"releaseDate":"2010-08-23"}],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2009-09-22T18:01:57.912+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Wed Nov 18 11:49:20 UTC 2009","customfield_12310420":"16727","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_4515610691_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2009-11-14T00:19:23.846+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-641/watchers","watchCount":9,"isWatching":false},"created":"2009-09-22T17:59:13.155+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/1","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/blocker.svg","name":"Blocker","id":"1"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12314204","id":"12314204","description":"","name":"0.20.2","archived":false,"released":true,"releaseDate":"2010-02-16"}],"issuelinks":[{"id":"12327236","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12327236","type":{"id":"10032","name":"Blocker","inward":"is blocked by","outward":"blocks","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10032"},"outwardIssue":{"id":"12434585","key":"HDFS-587","self":"https://issues.apache.org/jira/rest/api/2/issue/12434585","fields":{"summary":"Test programs support only default queue.","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12327235","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12327235","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"inwardIssue":{"id":"12387426","key":"MAPREDUCE-2593","self":"https://issues.apache.org/jira/rest/api/2/issue/12387426","fields":{"summary":"Random read benchmark for DFS","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/2","id":"2","description":"A new feature of the product, which has yet to be developed.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype","name":"New Feature","subtask":false,"avatarId":21141}}}},{"id":"12327234","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12327234","type":{"id":"10001","name":"dependent","inward":"is depended upon by","outward":"depends upon","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10001"},"inwardIssue":{"id":"12436884","key":"HDFS-663","self":"https://issues.apache.org/jira/rest/api/2/issue/12436884","fields":{"summary":"DFSIO for append","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/7","id":"7","description":"The sub-task of the issue","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype","name":"Sub-task","subtask":true,"avatarId":21146}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley","name":"owen.omalley","key":"owen.omalley","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=29697","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=29697","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=owen.omalley&avatarId=29697","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=owen.omalley&avatarId=29697"},"displayName":"Owen O'Malley","active":true,"timeZone":"America/Los_Angeles"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2013-05-02T02:29:19.977+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12312916","id":"12312916","name":"test"}],"timeoriginalestimate":null,"description":"Currently, we have a bad cycle where to build hdfs you need to test mapreduce and iterate once. This is broken.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"112991","customfield_12312823":null,"summary":"Move all of the benchmarks and tests that depend on mapreduce to mapreduce","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley","name":"owen.omalley","key":"owen.omalley","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=29697","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=29697","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=owen.omalley&avatarId=29697","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=owen.omalley&avatarId=29697"},"displayName":"Owen O'Malley","active":true,"timeZone":"America/Los_Angeles"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley","name":"owen.omalley","key":"owen.omalley","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=29697","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=29697","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=owen.omalley&avatarId=29697","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=owen.omalley&avatarId=29697"},"displayName":"Owen O'Malley","active":true,"timeZone":"America/Los_Angeles"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12436325/comment/12758323","id":"12758323","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley","name":"owen.omalley","key":"owen.omalley","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=29697","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=29697","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=owen.omalley&avatarId=29697","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=owen.omalley&avatarId=29697"},"displayName":"Owen O'Malley","active":true,"timeZone":"America/Los_Angeles"},"body":"I propose moving all of the the tests and benchmarks that depend on map/reduce into map/reduce. That will enable us to build in a linear order.\n\ncommon -> hdfs -> mapreduce\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley","name":"owen.omalley","key":"owen.omalley","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=29697","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=29697","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=owen.omalley&avatarId=29697","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=owen.omalley&avatarId=29697"},"displayName":"Owen O'Malley","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-09-22T18:01:22.991+0000","updated":"2009-09-22T18:01:22.991+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12436325/comment/12758324","id":"12758324","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"body":"+1","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-09-22T18:01:57.912+0000","updated":"2009-09-22T18:01:57.912+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12436325/comment/12758345","id":"12758345","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"body":"We will also need to move block_forensics stuff from hdfs/contrib into map-reduce if we want to straighten up project dependencies.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-09-22T18:32:58.239+0000","updated":"2009-09-22T18:32:58.239+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12436325/comment/12758580","id":"12758580","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinodkv","name":"vinodkv","key":"vinodkv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinod Kumar Vavilapalli","active":true,"timeZone":"America/Los_Angeles"},"body":"The current planned move is moving file-system specific tests which seem out of place in mapreduce to me. If something changes in FS/HDFS, it looks very odd to go and change the corresponding tests in mapred.\n\nWhy shouldn't HDFS tests and benchmarks just run with a specified version of mapreduce instead of the latest version. This will remove the dependency of building mapreduce every time a HDFS build is needed. If the tests/benchmarks need something cutting edge in mapreduce, then the corresponding mapreduce jar can be committed to HDFS at that point of time. Thoughts?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinodkv","name":"vinodkv","key":"vinodkv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinod Kumar Vavilapalli","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-09-23T04:16:29.004+0000","updated":"2009-09-23T04:16:29.004+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12436325/comment/12759036","id":"12759036","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley","name":"owen.omalley","key":"owen.omalley","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=29697","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=29697","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=owen.omalley&avatarId=29697","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=owen.omalley&avatarId=29697"},"displayName":"Owen O'Malley","active":true,"timeZone":"America/Los_Angeles"},"body":"That had been the plan, but in practice, it didn't work well. To build, you needed to compile common, and update the common jars in hdfs and mapred. Then you compile hdfs and push the jar to mapreduce. Then you compile mapreduce and push to hdfs. Then you compile hdfs-test and push to mapreduce. Then you compile mapreduce test and push it to hdfs. Then you run the hdfs tests. Then you run the mapreduce tests. \n\nBy comparison, if we break the cycle, we can compile common, test common, compile hdfs, test hdfs, compile mapreduce, and test mapreduce. Yes, we need to do more work to test hdfs without mapreduce. But this is a good change.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley","name":"owen.omalley","key":"owen.omalley","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=29697","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=29697","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=owen.omalley&avatarId=29697","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=owen.omalley&avatarId=29697"},"displayName":"Owen O'Malley","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-09-24T06:18:46.664+0000","updated":"2009-09-24T06:18:46.664+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12436325/comment/12759094","id":"12759094","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinodkv","name":"vinodkv","key":"vinodkv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinod Kumar Vavilapalli","active":true,"timeZone":"America/Los_Angeles"},"body":"With the approach that I've outlined, we will not have cycles. Building mapreduce doesn't need common/hdfs build again. This will be similar to what we will do once we have HADOOP-5107 and make mapreduce work with stable/intended versions of common/hdfs instead of always working on the latest versions.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinodkv","name":"vinodkv","key":"vinodkv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinod Kumar Vavilapalli","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-09-24T11:53:10.513+0000","updated":"2009-09-24T11:53:10.513+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12436325/comment/12759166","id":"12759166","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley","name":"owen.omalley","key":"owen.omalley","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=29697","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=29697","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=owen.omalley&avatarId=29697","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=owen.omalley&avatarId=29697"},"displayName":"Owen O'Malley","active":true,"timeZone":"America/Los_Angeles"},"body":"The problem is that we will have breakage that won't be detected until HDFS is updated. That would substantially increase the chance of missed problems.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley","name":"owen.omalley","key":"owen.omalley","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=29697","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=29697","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=owen.omalley&avatarId=29697","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=owen.omalley&avatarId=29697"},"displayName":"Owen O'Malley","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-09-24T16:38:12.083+0000","updated":"2009-09-24T16:38:12.083+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12436325/comment/12759433","id":"12759433","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinodkv","name":"vinodkv","key":"vinodkv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinod Kumar Vavilapalli","active":true,"timeZone":"America/Los_Angeles"},"body":"bq. The problem is that we will have breakage that won't be detected until HDFS is updated.\nA similar problem happens with your proposal too no? Let's say someone changes some functionality in common/hdfs and do not update the corresponding the test-case in mapreduce(for e.g., org.apache.hadoop.security.authorize.TestServiceLevelAuthorization.java). This will NOT be detected till mapreduce is built. If we talk of Hudson, then this won't happen till a mapreduce build is triggered by Hudson, which will be only when some other mapreduce patch is committed.\n\nWhat do others in the community think of this problem in general? Is it OK to move these hdfs/common related tests/benchmarks into mapreduce? If not, what are the alternative suggestions?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinodkv","name":"vinodkv","key":"vinodkv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinod Kumar Vavilapalli","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-09-25T08:06:35.959+0000","updated":"2009-09-25T08:06:35.959+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12436325/comment/12759435","id":"12759435","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"body":"> If something changes in FS/HDFS, it looks very odd to go and change the corresponding tests in mapred.\n\nI agree with Vinod. Moreover, the change cannot happen atomically because this will require two patches, one for HDFS and then one for the unit tests in mapred.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"created":"2009-09-25T08:17:16.095+0000","updated":"2009-09-25T08:17:16.095+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12436325/comment/12759490","id":"12759490","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yhemanth","name":"yhemanth","key":"yhemanth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hemanth Yamijala","active":true,"timeZone":"Asia/Kolkata"},"body":"I think the test cases in question are using map/reduce as a tool to submit jobs and are really not related to map/reduce. In that sense, it seems like HDFS is still the right place to keep these tests, no ?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yhemanth","name":"yhemanth","key":"yhemanth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hemanth Yamijala","active":true,"timeZone":"Asia/Kolkata"},"created":"2009-09-25T11:13:49.139+0000","updated":"2009-09-25T11:13:49.139+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12436325/comment/12759614","id":"12759614","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"body":"> If not, what are the alternative suggestions?\n\nPerhaps we just need a higher-level build file, so that the standard working pattern is something like:\n\n{noformat}\nsvn co https://svn.apache.org/repos/asf/hadoop/build/trunk .\nsvn co https://svn.apache.org/repos/asf/hadoop/common/trunk common\nsvn co https://svn.apache.org/repos/asf/hadoop/hdfs/trunk hdfs\nsvn co https://svn.apache.org/repos/asf/hadoop/mapreduce/trunk mapreduce\nant test-hdfs\nant test-mapreduce\n{noformat}\n\nIf you want to test against a different version, then checkout its branch or tag, or unpack its tarball.  The test-mapreduce and test-hdfs targets would first build both hdfs and mapreduce, then build and run tests.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-09-25T16:33:28.891+0000","updated":"2009-09-25T16:33:28.891+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12436325/comment/12759636","id":"12759636","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"body":"{quote}\nA similar problem happens with your proposal too no? Let's say someone changes some functionality in common/hdfs and do not update the corresponding the test-case in mapreduce(for e.g., org.apache.hadoop.security.authorize.TestServiceLevelAuthorization.java). This will NOT be detected till mapreduce is built. If we talk of Hudson, then this won't happen till a mapreduce build is triggered by Hudson, which will be only when some other mapreduce patch is committed.\n{quote}\n\nThat's correct but this is no cycle if we remove the dependence from hdfs to mapreduce.\n\nBTW, tests like TestServiceLevelAuthorization should be spitted into individual hdfs and mapreduce tests.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-09-25T17:26:45.273+0000","updated":"2009-09-25T17:26:45.273+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12436325/comment/12759855","id":"12759855","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sharadag","name":"sharadag","key":"sharadag","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sharad Agarwal","active":true,"timeZone":"Etc/UTC"},"body":"Since the tests in question use mapreduce as a *tool*, it can use a *specific* version of mapreduce not the SNAPSHOT version.\ncommon (SNAPSHOT) -> hdfs (SNAPSHOT) -> mapreduce\nmapreduce (specific version) -> hdfs (only for hdfs_with_mr tests)\nAbove dependencies don't lead to cycles. The version of mapreduce used by hdfs tests doesn't need to be latest. It can upgrade to newer version whenever required in the same fashion as it would upgrade any third party lib.\n\nOn a side note I think the issue of cycles only arise if we make the assumption that whenever common or hdfs is built, their jars should be updated in mapreduce, which is not correct IMO. That defeats the purpose of project split, no? Since these are different projects, they could have different release cycles in future. So building and validating the dependencies whenever the base version changes is not very correct. It should be looked at just like any other third party dependency. For example the change in third party library doesn't and can't validate that all projects using it are not broken. It is up to the project using it in case it wants to upgrade to newer version.\nSince at this stage each sub projects can't wait for the dependent project's changes to be released, they can work with SNAPSHOT versions. (HADOOP-5107).\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sharadag","name":"sharadag","key":"sharadag","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sharad Agarwal","active":true,"timeZone":"Etc/UTC"},"created":"2009-09-26T04:17:43.956+0000","updated":"2009-09-26T04:17:43.956+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12436325/comment/12759857","id":"12759857","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"body":"Yes, using a checked-in specific version of mapreduce should work well. Maybe this is true for all hdfs-tools that use Stable interfaces of mapreduce.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"created":"2009-09-26T04:43:23.013+0000","updated":"2009-09-26T04:43:23.013+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12436325/comment/12760587","id":"12760587","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"Integrated in Hadoop-Hdfs-trunk #98 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-Hdfs-trunk/98/])\n    ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2009-09-29T12:45:27.716+0000","updated":"2009-09-29T12:45:27.716+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12436325/comment/12762778","id":"12762778","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"body":"There is an addition to DFSIO benchmark related to append, see HDFS-663. I plan to commit it to branch 0.21. Do you want me also commit it to branch HDFS-641? I just don't want this changes to get lost in the transition process, wherever it goes.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-10-06T21:11:09.029+0000","updated":"2009-10-06T21:11:09.029+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12436325/comment/12762784","id":"12762784","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"body":"The same question will be with HDFS-236 if it needs to be committed before this is resolved.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-10-06T21:21:06.047+0000","updated":"2009-10-06T21:21:06.047+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12436325/comment/12763286","id":"12763286","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"body":"I am going to commit HDFS-641 to branch 0.21 and branch HDFS-641 if there are no objections...","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-10-07T21:53:17.455+0000","updated":"2009-10-07T21:53:17.455+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12436325/comment/12763308","id":"12763308","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"body":"Sorry, I meant to say:\nI am going to commit HDFS-663 (FDSIO for append) to branch 0.21 and branch HDFS-641 if there are no objections.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-10-07T23:46:59.023+0000","updated":"2009-10-07T23:46:59.023+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12436325/comment/12763871","id":"12763871","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"Integrated in Hdfs-Patch-h2.grid.sp2.yahoo.net #20 (See [http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h2.grid.sp2.yahoo.net/20/])\n    ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2009-10-09T06:42:48.108+0000","updated":"2009-10-09T06:42:48.108+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12436325/comment/12770746","id":"12770746","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=zasran","name":"zasran","key":"zasran","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Erik Steffl","active":true,"timeZone":"Etc/UTC"},"body":"Should the patch for HDFS-587 (0.21 version) also be part of this bug (committed to HDFS-641 branch)? It deals with the tests that were moved from Hdfs to Mapreduce.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=zasran","name":"zasran","key":"zasran","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Erik Steffl","active":true,"timeZone":"Etc/UTC"},"created":"2009-10-28T01:38:05.459+0000","updated":"2009-10-28T01:38:05.459+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12436325/comment/12777647","id":"12777647","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"Integrated in Hadoop-Mapreduce-trunk-Commit #118 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-Mapreduce-trunk-Commit/118/])\n    . Move all of the components that depend on map/reduce to \nmap/reduce. (omalley)\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2009-11-13T20:42:38.874+0000","updated":"2009-11-13T20:42:38.874+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12436325/comment/12777759","id":"12777759","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley","name":"owen.omalley","key":"owen.omalley","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=29697","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=29697","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=owen.omalley&avatarId=29697","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=owen.omalley&avatarId=29697"},"displayName":"Owen O'Malley","active":true,"timeZone":"America/Los_Angeles"},"body":"I just committed this.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley","name":"owen.omalley","key":"owen.omalley","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=29697","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=29697","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=owen.omalley&avatarId=29697","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=owen.omalley&avatarId=29697"},"displayName":"Owen O'Malley","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-11-14T00:19:23.816+0000","updated":"2009-11-14T00:19:23.816+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12436325/comment/12777770","id":"12777770","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"Integrated in Hadoop-Mapreduce-trunk-Commit #119 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-Mapreduce-trunk-Commit/119/])\n    . Missed a testcase in the move.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2009-11-14T00:35:51.575+0000","updated":"2009-11-14T00:35:51.575+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12436325/comment/12777955","id":"12777955","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"Integrated in Hadoop-Mapreduce-trunk #143 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-Mapreduce-trunk/143/])\n    . Missed a testcase in the move.\n. Move all of the components that depend on map/reduce to \nmap/reduce. (omalley)\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2009-11-14T16:16:36.876+0000","updated":"2009-11-14T16:16:36.876+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12436325/comment/12778773","id":"12778773","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinodkv","name":"vinodkv","key":"vinodkv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinod Kumar Vavilapalli","active":true,"timeZone":"America/Los_Angeles"},"body":"It is unfortunate that we couldn't make any progress on the complaints we have with this fix.\n\nIt is more unfortunate that the fix got committed clearly when no consensus was ever reached. Sharad/Hemant/Dhruba/Me all were either -1 or not +1 for the fix that got committed.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinodkv","name":"vinodkv","key":"vinodkv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinod Kumar Vavilapalli","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-11-17T08:43:07.582+0000","updated":"2009-11-17T08:43:07.582+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12436325/comment/12778997","id":"12778997","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley","name":"owen.omalley","key":"owen.omalley","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=29697","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=29697","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=owen.omalley&avatarId=29697","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=owen.omalley&avatarId=29697"},"displayName":"Owen O'Malley","active":true,"timeZone":"America/Los_Angeles"},"body":"*Sigh* I apologize for not closing the loop on the complaints before committing this. It had been so long since I started the process that I lost track that you still weren't happy with the solution.\n\nCycles in the dependency graph make everything harder. Until we get the interfaces locked down more and Common becomes more stable, there will be cross-project commits. While that is true, we need all 3 trunks (common, hdfs, and mapreduce) to depend on the current SNAPSHOT of each other. Otherwise, a change a common will break all of them. Using a fixed version of mapreduce for HDFS testing wouldn't work because that fixed version would become broken. In short, we would need to depend on a specific SNAPSHOT version of mapreduce. When would that be updated? Who would update it?\n\nThe majority of the move is about the tools and benchmarks using HDFS and MapReduce that are better served being in MapReduce. Some of the the tests should be recoded without MapReduce and pushed back into HDFS. However, most of the tests are the distributed equivalent of the tests still in HDFS and aren't that badly placed in MapReduce.\n\nHaving a strict build order without cycles is a huge win, especially for automated build systems like Hudson running CI builds for us. With HADOOP-5107, we no longer need to check in jar files. That makes life far easier for developers. Automated CI builds are big part of it.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley","name":"owen.omalley","key":"owen.omalley","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=29697","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=29697","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=owen.omalley&avatarId=29697","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=owen.omalley&avatarId=29697"},"displayName":"Owen O'Malley","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-11-17T17:24:23.499+0000","updated":"2009-11-17T17:24:23.499+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12436325/comment/12779005","id":"12779005","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"body":"> Sharad/Hemant/Dhruba/Me all were either -1 or not +1 for the fix that got committed.\n\nNo clear -1 votes were cast, but It's still not too late.  If a committer feels this is wrong, it can be reverted and discussed further.  We require one +1 review before commits, which I don't see above, and, even then, committers should still be able to veto and revert a change for the first few days after it's been committed in case they didn't have a chance to review it before it was committed.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-11-17T17:39:11.340+0000","updated":"2009-11-17T17:39:11.340+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12436325/comment/12779008","id":"12779008","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ltucker","name":"ltucker","key":"ltucker","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Lee Tucker","active":true,"timeZone":"Etc/UTC"},"body":"Circular dependencies are inherently evil, and fragile, and checked in jar files doubly so.  This cycle really needs to be broken for good build/test hygiene.    While it is a step backwards for HDFS users to have to build and maintain an MR layer to test their fixes, it's really not much different than before the project split, except that now the dependency is clearly exposed.\n\nPerhaps there's a solution that doesn't involve using MR to test HDFS?   That would resolve both the circular dependency, and the delayed testing of HDFS (because you're waiting for MR to build).","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ltucker","name":"ltucker","key":"ltucker","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Lee Tucker","active":true,"timeZone":"Etc/UTC"},"created":"2009-11-17T17:41:52.829+0000","updated":"2009-11-17T17:41:52.829+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12436325/comment/12779422","id":"12779422","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinodkv","name":"vinodkv","key":"vinodkv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinod Kumar Vavilapalli","active":true,"timeZone":"America/Los_Angeles"},"body":"bq. While that is true, we need all 3 trunks (common, hdfs, and mapreduce) to depend on the current SNAPSHOT of each other. Otherwise, a change a common will break all of them. Using a fixed version of mapreduce for HDFS testing wouldn't work because that fixed version would become broken. In short, we would need to depend on a specific SNAPSHOT version of mapreduce. When would that be updated? Who would update it?\nAh.. I didn't realize that. That definitely is a problem with letting HDFS using a particular version of mapred. Thanks, owen, for making this clear!\n\nbq. The majority of the move is about the tools and benchmarks using HDFS and MapReduce that are better served being in MapReduce. Some of the the tests should be recoded without MapReduce and pushed back into HDFS.\nI welcome this.\n\nIn general, I can share your concerns w.r.t cyclic dependencies. Just that I felt this might not be the right fix. Even that, I myself don't pretend to have any idea of the right solution for this.\n\nOne idea I can get from looking at the cyclic dependencies is that the sore points are the MiniMR and MiniDFS clusters. Leaving these behind, I guess mapred and hdfs are more or less completely independent. So one solution could be to create MR and DFS cluster interfaces and let mapred/hdfs code to these interfaces? Thoughts?\n\nBy the way, I am OK for not reverting this patch for now as it atleast addresses the cyclic dependency problem in one particular way. But we should definitely pursue other solutions, if any, perhaps on a different JIRA issue.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinodkv","name":"vinodkv","key":"vinodkv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinod Kumar Vavilapalli","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-11-18T11:49:20.015+0000","updated":"2009-11-18T11:49:20.015+0000"}],"maxResults":30,"total":30,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-641/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i0jp2f:"}}