{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12728835","self":"https://issues.apache.org/jira/rest/api/2/issue/12728835","key":"HDFS-6725","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/8","id":"8","description":"The described issue is not actually a problem - it is as designed.","name":"Not A Problem"},"customfield_12312322":null,"customfield_12310220":"2014-07-22T16:26:37.885+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Tue Jul 22 16:26:37 UTC 2014","customfield_12310420":"406909","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_17615848_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2014-07-22T16:26:37.860+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-6725/watchers","watchCount":2,"isWatching":false},"created":"2014-07-22T11:33:02.046+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/4","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/minor.svg","name":"Minor","id":"4"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[],"issuelinks":[],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2014-07-22T16:26:37.890+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12312927","id":"12312927","name":"datanode"}],"timeoriginalestimate":null,"description":"I am unable to start the datanode and tasktracker daemons on one of my slave nodes. I have got two slave nodes for my test env.\nThe error is familiar to Jira, however the solutions provided in JIRA is not working for me.\n\nBelow are the errors \nDatanode log file:\n\n2014-07-22 07:17:54,559 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: \n/************************************************************\nSTARTUP_MSG: Starting DataNode\nSTARTUP_MSG:   host = Hadslave1/127.0.1.1\nSTARTUP_MSG:   args = []\nSTARTUP_MSG:   version = 1.2.0\nSTARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-1.2 -r 1479473; compiled by 'hortonfo' on Mon May  6 \n06:59:37 UTC 2013\nSTARTUP_MSG:   java = 1.6.0_31\n************************************************************/\n2014-07-22 07:17:55,691 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties\n2014-07-22 07:17:55,703 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source MetricsSystem,sub=Stats registered.\n2014-07-22 07:17:55,732 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).\n2014-07-22 07:17:55,732 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started\n2014-07-22 07:17:56,265 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source ugi registered.\n2014-07-22 07:17:56,275 WARN org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Source name ugi already exists!\n2014-07-22 07:17:57,536 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: java.lang.IllegalArgumentException: Does not contain a valid\n host:port authority: file:///\n\tat org.apache.hadoop.net.NetUtils.createSocketAddr(NetUtils.java:164)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNode.getAddress(NameNode.java:212)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNode.getAddress(NameNode.java:244)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNode.getServiceAddress(NameNode.java:236)\n\tat org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:357)\n\tat org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:319)\n\tat org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:1698)\n\tat org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:1637)\n\tat org.apache.hadoop.hdfs.server.datanode.DataNode.createDataNode(DataNode.java:1655)\n\tat org.apache.hadoop.hdfs.server.datanode.DataNode.secureMain(DataNode.java:1781)\n\tat org.apache.hadoop.hdfs.server.datanode.DataNode.main(DataNode.java:1798)\n\n2014-07-22 07:17:57,566 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: \n/************************************************************\nSHUTDOWN_MSG: Shutting down DataNode at Hadslave1/127.0.1.1\n************************************************************/\n\n\nTask tracker's log files:\n\n2014-07-22 07:17:59,297 INFO org.apache.hadoop.mapred.TaskTracker: STARTUP_MSG: \n/************************************************************\nSTARTUP_MSG: Starting TaskTracker\nSTARTUP_MSG:   host = Hadslave1/127.0.1.1\nSTARTUP_MSG:   args = []\nSTARTUP_MSG:   version = 1.2.0\nSTARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-1.2 -r 1479473; compiled by 'hortonfo' on Mon May  6 \n06:59:37 UTC 2013\nSTARTUP_MSG:   java = 1.6.0_31\n************************************************************/\n2014-07-22 07:17:59,671 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties\n2014-07-22 07:17:59,814 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source MetricsSystem,sub=Stats registered.\n2014-07-22 07:17:59,815 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).\n2014-07-22 07:17:59,815 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: TaskTracker metrics system started\n2014-07-22 07:18:00,028 INFO org.apache.hadoop.util.NativeCodeLoader: Loaded the native-hadoop library\n2014-07-22 07:18:00,158 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source ugi registered.\n2014-07-22 07:18:00,160 WARN org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Source name ugi already exists!\n2014-07-22 07:18:00,265 ERROR org.apache.hadoop.mapred.TaskTracker: Can not start task tracker because java.lang.IllegalArgumentException: \nDoes not contain a valid host:port authority: local\n\tat org.apache.hadoop.net.NetUtils.createSocketAddr(NetUtils.java:164)\n\tat org.apache.hadoop.net.NetUtils.createSocketAddr(NetUtils.java:130)\n\tat org.apache.hadoop.mapred.JobTracker.getAddress(JobTracker.java:2121)\n\tat org.apache.hadoop.mapred.TaskTracker.<init>(TaskTracker.java:1540)\n\tat org.apache.hadoop.mapred.TaskTracker.main(TaskTracker.java:3937)\n\n2014-07-22 07:18:00,265 INFO org.apache.hadoop.mapred.TaskTracker: SHUTDOWN_MSG: \n/************************************************************\nSHUTDOWN_MSG: Shutting down TaskTracker at Hadslave1/127.0.1.1\n************************************************************/\n\nBelow are my configuration files:\nuser@Hadmast:/opt/hadoop-1.2.0/conf$ cat core-site.xml \n<?xml version=\"1.0\"?>\n<?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?>\n\n<!-- Put site-specific property overrides in this file. -->\n\n<configuration>\n\n<property>\n\n<name>fs.default.name</name>\n\n<value>hdfs://192.168.111.131:8020</value>\n\n</property>\n\n</configuration>\nuser@Hadmast:/opt/hadoop-1.2.0/conf$ cat hdfs-site.xml \n<?xml version=\"1.0\"?>\n<?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?>\n\n<!-- Put site-specific property overrides in this file. -->\n\n<configuration>\n\n<property>\n<name>dfs.replication</name>\n<value>2</value>\n</property>\n\n<property>\n<name>dfs.permissions</name>\n<value>false</value>\n</property>\n\n</configuration>\nuser@Hadmast:/opt/hadoop-1.2.0/conf$ cat mapred-site.xml \n<?xml version=\"1.0\"?>\n<?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?>\n\n<!-- Put site-specific property overrides in this file. -->\n\n<configuration>\n\n\t<property>\n\n\t\t<name>mapred.job.tracker</name>\n\n\t\t<value>localhost:8021</value>\n\n\t</property>\n\n</configuration>\nuser@Hadmast:/opt/hadoop-1.2.0/conf$ \n\nBoth the daemons start on Hadmast node but doesn't start on the other node.\n\nuser@Hadmast:~$ jps\n7947 Jps\n6421 NameNode\n7661 DataNode\n6941 JobTracker\n6866 SecondaryNameNode\n7172 TaskTracker\nuser@Hadmast:~$ \n\nuser@Hadslave1:~$ jps\n4826 Jps\nuser@Hadslave1:~$\n\nI have formated the namenode multiple times and have also rebuilt the Hadslave1 once but no change.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"406928","customfield_12312823":null,"summary":"Datanode and Task Tracker not starting","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shashang13","name":"shashang13","key":"shashang13","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Shashang Sheth","active":true,"timeZone":"Asia/Kolkata"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shashang13","name":"shashang13","key":"shashang13","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Shashang Sheth","active":true,"timeZone":"Asia/Kolkata"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":"user@Hadslave1:~$ uname -a\nLinux Hadslave1 3.2.0-23-generic-pae #36-Ubuntu SMP Tue Apr 10 22:19:09 UTC 2012 i686 i686 i386 GNU/Linux\nuser@Hadslave1:~$\n\nuser@Hadslave1:~$ /opt/hadoop-1.2.0/bin/hadoop -version\njava version \"1.6.0_31\"\nOpenJDK Runtime Environment (IcedTea6 1.13.3) (6b31-1.13.3-1ubuntu1~0.12.04.2)\nOpenJDK Client VM (build 23.25-b01, mixed mode, sharing)\n\nuser@Hadslave1:~$ java -version\njava version \"1.6.0_31\"\nOpenJDK Runtime Environment (IcedTea6 1.13.3) (6b31-1.13.3-1ubuntu1~0.12.04.2)\nOpenJDK Client VM (build 23.25-b01, mixed mode, sharing)\nuser@Hadslave1:~$","customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12728835/comment/14070150","id":"14070150","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shashang13","name":"shashang13","key":"shashang13","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Shashang Sheth","active":true,"timeZone":"Asia/Kolkata"},"body":"user@Hadmast:~$ jps\n7947 Jps\n6421 NameNode\n7661 DataNode\n6941 JobTracker\n6866 SecondaryNameNode\n7172 TaskTracker\nuser@Hadmast:~$ ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shashang13","name":"shashang13","key":"shashang13","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Shashang Sheth","active":true,"timeZone":"Asia/Kolkata"},"created":"2014-07-22T11:41:09.570+0000","updated":"2014-07-22T11:41:09.570+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12728835/comment/14070458","id":"14070458","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=aw","name":"aw","key":"aw","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=aw&avatarId=23681","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=aw&avatarId=23681","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=aw&avatarId=23681","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=aw&avatarId=23681"},"displayName":"Allen Wittenauer","active":true,"timeZone":"America/Tijuana"},"body":"JIRA is not for support issues such as these.  Besides, the error is clearly marked in the log:\n\n{code}\nERROR org.apache.hadoop.hdfs.server.datanode.DataNode: java.lang.IllegalArgumentException: Does not contain a valid\nhost:port authority: file:///\n{code}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=aw","name":"aw","key":"aw","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=aw&avatarId=23681","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=aw&avatarId=23681","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=aw&avatarId=23681","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=aw&avatarId=23681"},"displayName":"Allen Wittenauer","active":true,"timeZone":"America/Tijuana"},"created":"2014-07-22T16:26:37.885+0000","updated":"2014-07-22T16:26:37.885+0000"}],"maxResults":2,"total":2,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-6725/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i1y0s7:"}}