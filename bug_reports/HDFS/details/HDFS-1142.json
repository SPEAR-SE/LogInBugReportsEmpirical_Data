{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12464190","self":"https://issues.apache.org/jira/rest/api/2/issue/12464190","key":"HDFS-1142","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/8","id":"8","description":"The described issue is not actually a problem - it is as designed.","name":"Not A Problem"},"customfield_12312322":null,"customfield_12310220":"2010-05-11T03:52:58.439+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Thu Jun 03 21:48:33 UTC 2010","customfield_12310420":"16108","customfield_12312320":null,"customfield_12310222":"10002_*:*_3_*:*_929351086_*|*_1_*:*_3_*:*_3901247_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2010-05-21T18:25:31.927+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-1142/watchers","watchCount":8,"isWatching":false},"created":"2010-05-10T23:11:19.594+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"2.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12314046","id":"12314046","description":"","name":"0.21.0","archived":false,"released":true,"releaseDate":"2010-08-23"}],"issuelinks":[{"id":"12331860","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12331860","type":{"id":"12310010","name":"Incorporates","inward":"is part of","outward":"incorporates","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/12310010"},"inwardIssue":{"id":"12464180","key":"HDFS-1139","self":"https://issues.apache.org/jira/rest/api/2/issue/12464180","fields":{"summary":"Forward-port TestFileAppend4 tests from 20-append branch","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/6","id":"6","description":"A new unit, integration or system test.","iconUrl":"https://issues.apache.org/jira/images/icons/issuetypes/requirement.png","name":"Test","subtask":false}}}},{"id":"12331941","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12331941","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"12464382","key":"HDFS-1149","self":"https://issues.apache.org/jira/rest/api/2/issue/12464382","fields":{"summary":"Lease reassignment is not persisted to edit log","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12332076","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12332076","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"inwardIssue":{"id":"12465160","key":"HBASE-2593","self":"https://issues.apache.org/jira/rest/api/2/issue/12465160","fields":{"summary":"Race Between Log Splitting and Log Writing","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/2","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/critical.svg","name":"Critical","id":"2"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2010-06-03T21:48:33.104+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12312926","id":"12312926","name":"namenode"}],"timeoriginalestimate":null,"description":"If a soft lease has expired and another writer calls append(), it triggers lease recovery but doesn't reassign the lease to a new owner. Therefore, the old writer can continue to allocate new blocks, try to steal back the lease, etc. This is for the testRecoveryOnBlockBoundary case of HDFS-1139","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12444247","id":"12444247","filename":"hdfs-1142.txt","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2010-05-11T21:26:24.066+0000","size":12436,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12444247/hdfs-1142.txt"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12444164","id":"12444164","filename":"hdfs-1142.txt","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2010-05-11T00:12:11.515+0000","size":17028,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12444164/hdfs-1142.txt"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"113343","customfield_12312823":null,"summary":"Lease recovery doesn't reassign lease when triggered by append()","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12464190/comment/12865992","id":"12865992","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"Here's a patch that makes lease recovery reassign to the NN lease holder.\n\nOne thing I am somewhat worried about (not new with this patch, but related) is that lease reassignment is not logged to the edit log. Thus, if the NN restarts, the lease will revert to the old holder. Thoughts?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2010-05-11T00:12:11.596+0000","updated":"2010-05-11T00:12:11.596+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12464190/comment/12866043","id":"12866043","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"-1 overall.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12444164/hdfs-1142.txt\n  against trunk revision 942863.\n\n    +1 @author.  The patch does not contain any @author tags.\n\n    +1 tests included.  The patch appears to include 6 new or modified tests.\n\n    +1 javadoc.  The javadoc tool did not generate any warning messages.\n\n    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.\n\n    +1 findbugs.  The patch does not introduce any new Findbugs warnings.\n\n    +1 release audit.  The applied patch does not increase the total number of release audit warnings.\n\n    -1 core tests.  The patch failed core unit tests.\n\n    -1 contrib tests.  The patch failed contrib unit tests.\n\nTest results: http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h2.grid.sp2.yahoo.net/174/testReport/\nFindbugs warnings: http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h2.grid.sp2.yahoo.net/174/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html\nCheckstyle results: http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h2.grid.sp2.yahoo.net/174/artifact/trunk/build/test/checkstyle-errors.html\nConsole output: http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h2.grid.sp2.yahoo.net/174/console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2010-05-11T03:52:58.439+0000","updated":"2010-05-11T03:52:58.439+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12464190/comment/12866047","id":"12866047","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"Failed test is the one that's been failing all the recent builds.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2010-05-11T03:59:53.318+0000","updated":"2010-05-11T03:59:53.318+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12464190/comment/12866345","id":"12866345","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"New patch on top of trunk (since HDFS-1141 got committed)","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2010-05-11T21:26:24.131+0000","updated":"2010-05-11T21:26:24.131+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12464190/comment/12866361","id":"12866361","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"body":"can we re-run hadoopQA tests on the new patch?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"created":"2010-05-11T21:50:45.030+0000","updated":"2010-05-11T21:50:45.030+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12464190/comment/12866362","id":"12866362","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"Yea, I toggled patch available when I uploaded, should be on the queue.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2010-05-11T21:52:57.721+0000","updated":"2010-05-11T21:52:57.721+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12464190/comment/12866382","id":"12866382","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"-1 overall.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12444247/hdfs-1142.txt\n  against trunk revision 943306.\n\n    +1 @author.  The patch does not contain any @author tags.\n\n    +1 tests included.  The patch appears to include 7 new or modified tests.\n\n    +1 javadoc.  The javadoc tool did not generate any warning messages.\n\n    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.\n\n    +1 findbugs.  The patch does not introduce any new Findbugs warnings.\n\n    +1 release audit.  The applied patch does not increase the total number of release audit warnings.\n\n    -1 core tests.  The patch failed core unit tests.\n\n    -1 contrib tests.  The patch failed contrib unit tests.\n\nTest results: http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h5.grid.sp2.yahoo.net/356/testReport/\nFindbugs warnings: http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h5.grid.sp2.yahoo.net/356/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html\nCheckstyle results: http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h5.grid.sp2.yahoo.net/356/artifact/trunk/build/test/checkstyle-errors.html\nConsole output: http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h5.grid.sp2.yahoo.net/356/console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2010-05-11T23:02:41.926+0000","updated":"2010-05-11T23:02:41.926+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12464190/comment/12866383","id":"12866383","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"Toggling cuz Hudson build screwed up (silly NoClassDefFound thing, not this patch)","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2010-05-11T23:07:05.413+0000","updated":"2010-05-11T23:07:05.413+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12464190/comment/12866424","id":"12866424","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"-1 overall.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12444247/hdfs-1142.txt\n  against trunk revision 943306.\n\n    +1 @author.  The patch does not contain any @author tags.\n\n    +1 tests included.  The patch appears to include 7 new or modified tests.\n\n    +1 javadoc.  The javadoc tool did not generate any warning messages.\n\n    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.\n\n    +1 findbugs.  The patch does not introduce any new Findbugs warnings.\n\n    +1 release audit.  The applied patch does not increase the total number of release audit warnings.\n\n    +1 core tests.  The patch passed core unit tests.\n\n    -1 contrib tests.  The patch failed contrib unit tests.\n\nTest results: http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h5.grid.sp2.yahoo.net/357/testReport/\nFindbugs warnings: http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h5.grid.sp2.yahoo.net/357/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html\nCheckstyle results: http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h5.grid.sp2.yahoo.net/357/artifact/trunk/build/test/checkstyle-errors.html\nConsole output: http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h5.grid.sp2.yahoo.net/357/console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2010-05-12T01:43:17.399+0000","updated":"2010-05-12T01:43:17.399+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12464190/comment/12866436","id":"12866436","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"body":"+1 code looks good to me. can somebody else review this patch too?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"created":"2010-05-12T03:10:43.771+0000","updated":"2010-05-12T03:10:43.771+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12464190/comment/12866691","id":"12866691","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rash37","name":"rash37","key":"rash37","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"sam rash","active":true,"timeZone":"America/Los_Angeles"},"body":"Hey Todd, one question:  why does FSNameSystem.internalReleaseLease() now take the recovery holder as a parameter?  It's only called in 2 places (startFileInternal and checkLeases) and both cases use the same constant.  The patches you had for hdfs-142 had the constant within the function when you called reassignLease().  Is there a reason to move it up?  just wondering if you anticipate the recovery lease holder being something other than a constant that needs to flow from further up?  (otherwise it's just a parameter that's always a constant)","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rash37","name":"rash37","key":"rash37","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"sam rash","active":true,"timeZone":"America/Los_Angeles"},"created":"2010-05-12T18:59:51.175+0000","updated":"2010-05-12T18:59:51.175+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12464190/comment/12866692","id":"12866692","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rash37","name":"rash37","key":"rash37","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"sam rash","active":true,"timeZone":"America/Los_Angeles"},"body":"oh, I should add, looks good though :)\n(just curious on that one)\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rash37","name":"rash37","key":"rash37","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"sam rash","active":true,"timeZone":"America/Los_Angeles"},"created":"2010-05-12T19:00:36.729+0000","updated":"2010-05-12T19:00:36.729+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12464190/comment/12866697","id":"12866697","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"sam: actually, that change was done in a prior HDFS patch by Konstantin. I asked him to take a look at this one as well before we commit it. I agree that we can probably drop the argument now, but let's wait to hear from Konst.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2010-05-12T19:11:25.880+0000","updated":"2010-05-12T19:11:25.880+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12464190/comment/12866701","id":"12866701","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rash37","name":"rash37","key":"rash37","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"sam rash","active":true,"timeZone":"America/Los_Angeles"},"body":"oh right, I see that didn't change.\n\n+1 on this diff then.  lgtm","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rash37","name":"rash37","key":"rash37","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"sam rash","active":true,"timeZone":"America/Los_Angeles"},"created":"2010-05-12T19:23:49.429+0000","updated":"2010-05-12T19:23:49.429+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12464190/comment/12866711","id":"12866711","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"body":"I guess it would be good to save the lease in the edits log when the owner of the lease changes to \"NN-leaseholder\". This will ensure that when the NN restarts, the lease does not revert back to the original client.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"created":"2010-05-12T19:51:11.091+0000","updated":"2010-05-12T19:51:11.091+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12464190/comment/12866713","id":"12866713","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"I opened HDFS-1149 to persist lease reassignment to the edit log.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2010-05-12T19:56:25.249+0000","updated":"2010-05-12T19:56:25.249+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12464190/comment/12867747","id":"12867747","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"body":"Sorry, took me a while.\nThe idea with lease recovery after soft limit expiration was that it is done under the same lease holder. Here is why.\nExpiration of the soft limit means that somebody else can claim the lease, and if he succeeds, then he is the new owner, if not, then not.\nSo here several clients may compete for the same lease. They will call {{create()}} and get {{RecoveryInProgressException}} in response, which indicates that they should retry. The old client if still there can also compete for the lease. It has an advantage over other clients, because it does not need to go through the recovery process, but that seems fair.\nIf you reassign the lease to {{HDFS_NameNode}}, then its timeouts will reset, see {{reassignLease()}}. And this will change the behavior. The clients trying to claim the file will be getting {{AlreadyBeingCreatedException}}, which means they cannot compete for the file anymore, and should fail.\nSuppose there is only one new client, and the old owner had died already. The client tries {{create()}}. This triggers lease recovery on NN, which starts the recovery under {{HDFS_NameNode}}, and throws {{RecoveryInProgressException}} back to the client. The client retries as expected, and the next time gets {{AlreadyBeingCreatedException}}. Thinking that somebody else got lucky before him the client bails out, which is not right as there is nobody esle competing for the file. \nDoes that makes sense? I don't see a problem here. Do you have failing tests because of that?\nThat by the way explains the parameter {{internalReleaseLease()}}\n\n- Introduction of {{NN_LEASE_RECOVERY_HOLDER}} constant definitely makes sense.\n- Persisting leases is not an issue if we do not reassign.\n- For future reference it is very undesirable to declare public methods in {{FSNamesystem}} to provide access to them from tests. The tests should either be in the right package or alternatively the {{FSNamesystem}} methods should be access via {{NameNodeAdapter}}, that's why it was introduced in the first place, see HDFS-563.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"created":"2010-05-15T00:00:35.853+0000","updated":"2010-05-15T00:00:35.853+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12464190/comment/12867750","id":"12867750","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"Hi Konstantin. Thanks for the detailed response.\n\nbq. Suppose there is only one new client, and the old owner had died already. The client tries create(). This triggers lease recovery on NN, which starts the recovery under HDFS_NameNode, and throws RecoveryInProgressException back to the client. The client retries as expected, and the next time gets AlreadyBeingCreatedException. Thinking that somebody else got lucky before him the client bails out, which is not right as there is nobody esle competing for the file. \n\nWhat if we specifically compare the holder to the HDFS_Namenode special value, and in this case throw RecoveryInProgressException instead of AlreadyBeingCreatedException?\n\nbq. Does that makes sense? I don't see a problem here. Do you have failing tests because of that?\n\nYes - please see the new test case included in the patch above. The issue is that the client can continue to do things like completeFile or allocate new blocks while recovery is underway.\n\nbq. For future reference it is very undesirable to declare public methods in FSNamesystem to provide access to them from tests\n\nI agree. However, in order to do mockito spying on commitBlockSynchronization, using a trampoline class like NameNodeAdapter would not work. If you agree with my above points, I can see if I can move the spy call into NameNodeAdapter itself.\nBTW, isn't this the point of the \"Private\" InterfaceAudience annotation?\n\n\nLet me know if you agree with the above idea (throwing RecoveryInProgressException when the lease is held by HDFS_NameNode).","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2010-05-15T00:09:04.384+0000","updated":"2010-05-15T00:09:04.384+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12464190/comment/12867772","id":"12867772","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"body":"Comparing the holder with HDFS_Namenode will work, but current logic should work too, so why change it.\nI suspect this is more like a problem of completeFile() and the new block allocation, than the lease recovery's. But let me look deeper into the test cases.\n\n\"Private\" InterfaceAudience annotation will not prevent people from using the methods.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"created":"2010-05-15T01:06:25.074+0000","updated":"2010-05-15T01:06:25.074+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12464190/comment/12868487","id":"12868487","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"body":"One of the tests {{testRecoveryOnBlockBoundary()}} fails because you explicitly call\n{code}\nstm.hflush();\nfail(\"Sync was allowed after recovery started\");\n{code}\nThe test +assumes+ that {{hflush()}} should not succeed after the recovery started, but this assumption is incorrect.\nBtw, the test falls into infinite loop after that, because you infinitely trying to append to a file when the file system is already closed.\nThe other two tests run fine with current code.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"created":"2010-05-18T01:56:00.429+0000","updated":"2010-05-18T01:56:00.429+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12464190/comment/12868541","id":"12868541","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"bq. The test assumes that hflush() should not succeed after the recovery started, but this assumption is incorrect.\n\nHBase is using contracts like this to do IO fencing during regionserver recovery operations (eg see discussion on HBASE-2231 and HBASE-2238). The ability to use lease recovery to lock out a writer whose soft lease has expired provides lock-like functionality tied to the storage. Without HDFS itself providing a file locking primitive, it becomes essentially impossible to do correct recovery in systems like HBase where an old writer needs to be forcibly disallowed from continued progress. Using an external system like ZK since it is asynchronous in nature.\n\nLet me think if we have an alternate route to the same kind of behavior using the semantics you're describing.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2010-05-18T05:46:15.481+0000","updated":"2010-05-18T05:46:15.481+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12464190/comment/12868773","id":"12868773","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"body":"Lease recovery works as designed, imo.\nThe lock service is provided by ZooKeeper.\nI don't think we should overload the semantics and complicate things that are already complex enough.\n\nMay be setting harld_limit = soft_limit will help with fencing. It seems this is the behavior you are looking for.\n\nI'll remove the blocker flag for now.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"created":"2010-05-18T18:20:55.978+0000","updated":"2010-05-18T18:20:55.978+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12464190/comment/12868782","id":"12868782","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"Hey Konstantin,\n\nI agree that this shouldn't be marked blocker while discussion is going on.\n\nLet me better explain the context with regards to HBase. HBase uses ZK already to determine regionserver liveness. If a region server dies, it loses its ZK session, and thus an ephemeral znode disappears. The master notices this, initiates commitlog recovery for that server, and eventually reassigns the regions elsewhere. To provide proper database-like semantics, we need to ensure that once log recovery commences, the regionserver cannot write any more to that log (otherwise writes might be lost forever).\n\nOf course this all works fine if the regionserver has truly died. A big issue we face, though, is one of long garbage collection pauses (sound familiar?). In some cases, the pauses can last longer than the zk session timeout. Thus, the hbase master decides that the server has died and does log splitting, region reassignment, etc. Unfortunately, in this scenario, the region server then comes back to life and flushes a few more writes to the log file, which summarily get lost forever even though the client thinks they're committed. The regionserver eventually \"notices\" that it lost its ZK session and shuts itself down, but in practice it often has time to get off some last edits before doing so.\n\nClearly, using locks in ZK is subject to the same issue above - the issue is that our ZK coordination is not synchronous with our storage access.\n\nThere are two solutions I can think of here: (a) the \"STONITH\" technique ( http://en.wikipedia.org/wiki/STONITH ) - we could run the regionservers in a container service which allows us to kill -9 the regionserver when we think it should be dead. But this is obviously more complicated with regard to deployment, additional RPCs, etc. (b) file access revocation - this is what we're trying to do with lease recovery and what you're suggesting should not be possible.\n\nHere's a question - as you described it, the original lease holder and the recovering lease holder race to recover the lease. If the original holder wins the recovery, are we guaranteed that no interceding appends have occurred? eg what happens if the recovering process wins, opens the file for append, and immediately closes it. Are we guaranteed then that another flush() call from the client at that point would definitely fail, or can it transparently regain the lease from the now-closed file?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2010-05-18T18:39:59.522+0000","updated":"2010-05-18T18:39:59.522+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12464190/comment/12868783","id":"12868783","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"bq. May be setting harld_limit = soft_limit will help with fencing. It seems this is the behavior you are looking for.\n\nSince this is a cluster-wide setting I don't think it's a good idea. We only want this kind of lease-stealing behavior for hlog recovery - for other normal HDFS access, we definitely want the original lease holder to be able to renew its lease after soft limit has elapsed (assuming that no one else has tried to steal it)","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2010-05-18T18:41:19.117+0000","updated":"2010-05-18T18:41:19.117+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12464190/comment/12869424","id":"12869424","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"body":"Todd,\n\nThanks for elaborating on the HBase / ZK interaction. Sounds like you are trying to build HA there.\n\n> Since this is a cluster-wide setting I don't think it's a good idea. \n\nIn my previous comment I explained what the soft limit means - the original client is able to reclaim its lease by simply renewing it. Expiration of the hard limit means that the original client does not own the file anymore, and can claim the ownership only via reopening the file, same as everybody else. \nAfter soft limit expires hdfs can either reassign it to a new client or keep under the old ownership. Reassigning it to NN during lease recovery contradicts the definition of the soft limit. The revoking ownership behavior you are describing corresponds to expiration of the hard limit.\n\nI do not understand how (b) file access revocation can be solved with lease recovery, even with your modified semantics. The region server may wake up before soft limit expiration but after the region reassignment.\nWhat really needed is to first revoke file access, then start reassigning regions. Revoking file access is achieved by just opening it with another client. AFAU, regions reassignment should wait until the access is revoked.\n\n> Since this is a cluster-wide setting I don't think it's a good idea. We only want this kind of lease-stealing behavior for hlog recovery\n\nBut you are talking about clusterS-wide change of semantics only for those hlog recoveries.\n\nI will be glad to continue discussing HBase problems. But \"Lease recovery doesn't reassign lease when triggered by append()\" is not a bug and is not a problem from HDFS point of view. \nI propose to close this issue as \"Not a Problem\" (The described issue is not actually a problem - it is as designed.)","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"created":"2010-05-20T00:26:26.906+0000","updated":"2010-05-20T00:26:26.906+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12464190/comment/12869878","id":"12869878","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"body":"Let me understand this one. Suppose a client A has a write-lease on a file. It is doing some write/sync to this file. Then another client B decides to invoke append() to the same file. If we have exceeded the soft-timeout limit, then the B's append call will trigger lease recovery. However, at this point (when the lease recovery is starting), the lease is technically still owned by A. A can continue to sync/write data to the file. If client B now successfully acquires the lease, then from that moment onwards, any new sync/writes from A will start to fail. isn't that behaviour enough to support HBase region recovery?\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"created":"2010-05-21T05:35:36.321+0000","updated":"2010-05-21T05:35:36.321+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12464190/comment/12869880","id":"12869880","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"The question I asked above still stands:\n\n{quote}\nHere's a question - as you described it, the original lease holder and the recovering lease holder race to recover the lease. If the original holder wins the recovery, are we guaranteed that no interceding appends have occurred? eg what happens if the recovering process wins, opens the file for append, and immediately closes it. Are we guaranteed then that another flush() call from the client at that point would definitely fail, or can it transparently regain the lease from the now-closed file?\n{quote}\n\nIf the above situation is prevented, I think we can rejigger the \"recoverFile\" operation that HBase does, and make this work. If the above is not prevented, we have to think harder. Maybe we can still do it by renaming the files after recovering the lease (since iirc in 21 the lease holder can rename a file that it holds open for write)","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2010-05-21T05:40:04.125+0000","updated":"2010-05-21T05:40:04.125+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12464190/comment/12869882","id":"12869882","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"body":"{quote}\nwhat happens if the recovering process wins, opens the file for append, and immediately closes it. Are we guaranteed then that another flush() call from the client at that point would definitely fail, or can it transparently regain the lease from the now-closed file?\n\n{quote}\n\nthe original writer can transparently regain the lease.\n\nIf you want the original writer to not regain the lease, then the recovering process should keep the file opened for write and not close it.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"created":"2010-05-21T05:48:54.204+0000","updated":"2010-05-21T05:48:54.204+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12464190/comment/12870090","id":"12870090","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"body":"If the file is closed nobody can transparently regain the lease, because closed files don't have leases. I understand transparently as by calling write or flush, but without reopening it. So the answer to the question\n\n> if the recovering process wins, opens the file for append, and immediately closes it. Are we guaranteed then that another flush() call from the client at that point would definitely fail\n\nis Yes. \n\nI think Dhruba meant that if the recovering process closes the file, then the old client can access it by reopening it. But this is not transparent if my understanding of transparency is the same as yours.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"created":"2010-05-21T18:21:58.066+0000","updated":"2010-05-21T18:21:58.066+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12464190/comment/12870091","id":"12870091","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"body":"And if you keep the file open as Dhruba suggests then the old client will not be able to access it even by reopening.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"created":"2010-05-21T18:23:11.292+0000","updated":"2010-05-21T18:23:11.292+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12464190/comment/12870095","id":"12870095","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"I think you've convinced me that this is indeed reasonable semantics and we can work with them by rejiggering things on the HBase side for 0.21. Thanks for the enlightening discussion.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2010-05-21T18:25:31.904+0000","updated":"2010-05-21T18:25:31.904+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12464190/comment/12870862","id":"12870862","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rash37","name":"rash37","key":"rash37","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"sam rash","active":true,"timeZone":"America/Los_Angeles"},"body":"There's actually still one problem condition that can occur w/o the Namenode taking ownership of lease when it starts lease recovery:\n\n1. Client A loses lease due to soft/hard limit at a block boundary\n2. NN begins lease recovery and finalizes blocks\n3. Client A gets new block, starts writing\n4. NN closes the file and frees the lease\n5. Client A can continue to write to blocks acquired w/o the lease\n6. Client A has an error and the block is left as a blockBeingWritten in the datanode\n\nresults:\n-clients cannot open the file in append since the last block has no locations\n-last block shows up as a missing block\n-lease recovery will never cleanup the last block since no lease exists\n\nassigning the lease to the NN for recovery prevents step 3 above and can stop this\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rash37","name":"rash37","key":"rash37","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"sam rash","active":true,"timeZone":"America/Los_Angeles"},"created":"2010-05-24T21:47:31.256+0000","updated":"2010-05-24T21:47:31.256+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12464190/comment/12870870","id":"12870870","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rash37","name":"rash37","key":"rash37","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"sam rash","active":true,"timeZone":"America/Los_Angeles"},"body":"note: I think this case also violates() sync semantics if during 5 the client called sync. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rash37","name":"rash37","key":"rash37","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"sam rash","active":true,"timeZone":"America/Los_Angeles"},"created":"2010-05-24T22:05:12.708+0000","updated":"2010-05-24T22:05:12.708+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12464190/comment/12871407","id":"12871407","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"body":"Sam. Sounds like you are looking at 0.20 version, because in 0.22 sync has been replaced with hflush(). Please clarify.\nCould you also please indicate whether you can actually reproduce it or have a test case. If you do please open a new jira.\nLooking at the code (0.22) I think there might be a problem there. \nIn getAdditionalBlock() we do not reset recoveryId of the last block before allocating a new one.\nThe reset should be done in {{BlockInfoUnderConstruction.commitBlock()}}.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"created":"2010-05-25T23:02:14.280+0000","updated":"2010-05-25T23:02:14.280+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12464190/comment/12871416","id":"12871416","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rash37","name":"rash37","key":"rash37","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"sam rash","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi Konstantin,\n\nSorry, I am basing this mostly on the 0.20 code base.  I do not have a test case--this is purely analytical at this point and meant to be an argument for keeping this fix in 0.20 w/append + sync (hadoop 0.20 + hdfs-142 + hdfs-200).  From reading the design doc on hdfs-165, hflush would also be violated by this since the client would have received an ack for bytes in the real last block that will never be available for read.\n\nCan you comment on this scenario with respect to 0.20?  if I get some time, I can try to create a test case for this--it seems doable.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rash37","name":"rash37","key":"rash37","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"sam rash","active":true,"timeZone":"America/Los_Angeles"},"created":"2010-05-25T23:13:05.356+0000","updated":"2010-05-25T23:13:05.356+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12464190/comment/12871432","id":"12871432","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks. Yes with 0.20 that would be a completely different issue. I did not closely follow the latest developments with sync(). Dhruba would know this better. \nThere should be no violation for hflush(): if the old client renews the lease it will reset the blockRecoveryId, and the lease recovery that started before that will fail - no big deal.\nI'll create a jira to investigate my findings in 0.22 (21).","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"created":"2010-05-25T23:31:09.815+0000","updated":"2010-05-25T23:31:09.815+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12464190/comment/12871475","id":"12871475","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rash37","name":"rash37","key":"rash37","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"sam rash","active":true,"timeZone":"America/Los_Angeles"},"body":"hmm, the client never reacquires the lease in my example--it loses it, still is able to acquire blocks and write to the DNs, but those blocks do not complete (client dies) and report to the NN.  They are \"lost\" in that the lease recovery that completes by the NN will only know the block was allocated, but not any locations.  The lease will be removed and the blocks won't be recovered ever.\n\nduring this time, the client may have called sync/hflush and hence received acks for that data. This is the violation I think that might occur. I've looked at trunk and I'm not seeing how this is avoided there even...?\n\nThanks for your patience in discussing this--maybe there isn't a problem and I don't yet see how even trunk handles this?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rash37","name":"rash37","key":"rash37","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"sam rash","active":true,"timeZone":"America/Los_Angeles"},"created":"2010-05-26T02:03:45.548+0000","updated":"2010-05-26T02:03:45.548+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12464190/comment/12873212","id":"12873212","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rash37","name":"rash37","key":"rash37","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"sam rash","active":true,"timeZone":"America/Los_Angeles"},"body":"konstantin : nvm last comment, i misread your comment (and forgot 22 == trunk)\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rash37","name":"rash37","key":"rash37","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"sam rash","active":true,"timeZone":"America/Los_Angeles"},"created":"2010-05-29T01:24:04.207+0000","updated":"2010-05-29T01:24:04.207+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12464190/comment/12875298","id":"12875298","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hairong","name":"hairong","key":"hairong","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hairong Kuang","active":true,"timeZone":"Etc/UTC"},"body":"Interesting discussion...\nAs long as I understand, once lease recovery starts, the first thing that each replica datanode does is kill the block receiver. So the old client will fail since the pipleline is completely torn down.The idea is that no writer is allowed, i.e., no modification to the file is allowed from any client, while the file's lease recovery is in progress. So in this sense, it would be nice to reassign the lease to NN but still maintain the soft lease semantics that Konstantin described.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hairong","name":"hairong","key":"hairong","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hairong Kuang","active":true,"timeZone":"Etc/UTC"},"created":"2010-06-03T21:16:20.973+0000","updated":"2010-06-03T21:16:20.973+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12464190/comment/12875303","id":"12875303","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rash37","name":"rash37","key":"rash37","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"sam rash","active":true,"timeZone":"America/Los_Angeles"},"body":"a small sidenote:\n\nre: killing writers, it does so *after* getting metadata, so there is still a window under which the client could start another lease recovery, it would complete, and it could start writing and call sync.  the 1st lease recovery kills threads, then truncate the block (based on the first set of lengths).  This violates sync/hflush semantics.  I don't know if there's a jira for this, but I had planned to make the change so the writers *are* killed first thing before getting meta-data.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rash37","name":"rash37","key":"rash37","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"sam rash","active":true,"timeZone":"America/Los_Angeles"},"created":"2010-06-03T21:31:44.237+0000","updated":"2010-06-03T21:31:44.237+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12464190/comment/12875305","id":"12875305","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"Sam: I believe the way it works in trunk is that writers are killed when recovery is started, and then the replicas enter the RUR state, so no more writes are allowed until a recovery happens.\n\nIn 0.20 that's not the case, see HDFS-1186","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2010-06-03T21:35:44.877+0000","updated":"2010-06-03T21:35:44.877+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12464190/comment/12875313","id":"12875313","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rash37","name":"rash37","key":"rash37","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"sam rash","active":true,"timeZone":"America/Los_Angeles"},"body":"todd: ah yea, i had trunk open and just checked--it's exactly that way.  nice.  we do need 1186, though","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rash37","name":"rash37","key":"rash37","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"sam rash","active":true,"timeZone":"America/Los_Angeles"},"created":"2010-06-03T21:48:33.070+0000","updated":"2010-06-03T21:48:33.070+0000"}],"maxResults":42,"total":42,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-1142/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i0jr8n:"}}