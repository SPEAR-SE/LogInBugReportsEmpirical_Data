{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"13110491","self":"https://issues.apache.org/jira/rest/api/2/issue/13110491","key":"HDFS-12681","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12341434","id":"12341434","description":"3.1.0 release","name":"3.1.0","archived":false,"released":true,"releaseDate":"2018-04-06"}],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2017-10-21T04:15:16.019+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Thu Nov 30 04:51:28 UTC 2017","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":"1_*:*_4_*:*_194651447_*|*_4_*:*_1_*:*_3497850_*|*_5_*:*_2_*:*_1051982774_*|*_10002_*:*_5_*:*_2403497169","customfield_12312321":null,"resolutiondate":"2017-11-30T04:32:08.212+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-12681/watchers","watchCount":16,"isWatching":false},"created":"2017-10-18T21:38:19.048+0000","customfield_12310192":null,"customfield_12310191":[{"self":"https://issues.apache.org/jira/rest/api/2/customFieldOption/10343","value":"Reviewed","id":"10343"}],"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"17.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[],"issuelinks":[{"id":"12517900","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12517900","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"12779186","key":"HDFS-7878","self":"https://issues.apache.org/jira/rest/api/2/issue/12779186","fields":{"summary":"API - expose a unique file identifier","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/4","id":"4","description":"An improvement or enhancement to an existing feature or task.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype","name":"Improvement","subtask":false,"avatarId":21140}}}},{"id":"12521058","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12521058","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"inwardIssue":{"id":"13102382","key":"HDFS-12455","self":"https://issues.apache.org/jira/rest/api/2/issue/13102382","fields":{"summary":"WebHDFS - Adding \"snapshot enabled\" status to ListStatus query result.","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/4","id":"4","description":"An improvement or enhancement to an existing feature or task.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype","name":"Improvement","subtask":false,"avatarId":21140}}}},{"id":"12523235","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12523235","type":{"id":"12310050","name":"Regression","inward":"is broken by","outward":"breaks","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/12310050"},"outwardIssue":{"id":"13127723","key":"HDFS-12970","self":"https://issues.apache.org/jira/rest/api/2/issue/13127723","fields":{"summary":"HdfsFileStatus#getPath returning null.","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/2","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/critical.svg","name":"Critical","id":"2"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12518723","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12518723","type":{"id":"10001","name":"dependent","inward":"is depended upon by","outward":"depends upon","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10001"},"outwardIssue":{"id":"13106161","key":"HDFS-12582","self":"https://issues.apache.org/jira/rest/api/2/issue/13106161","fields":{"summary":"Replace HdfsFileStatus constructor with a builder pattern.","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2017-12-29T21:56:24.928+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[],"timeoriginalestimate":null,"description":"{{HdfsLocatedFileStatus}} is a subtype of {{HdfsFileStatus}}, but not of {{LocatedFileStatus}}. Conversion requires copying common fields and shedding unknown data. It would be cleaner and sufficient for {{HdfsFileStatus}} to extend {{LocatedFileStatus}}.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12341434","id":"12341434","description":"3.1.0 release","name":"3.1.0","archived":false,"released":true,"releaseDate":"2018-04-06"}],"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12893352","id":"12893352","filename":"HDFS-12681.00.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-10-20T22:38:52.704+0000","size":54066,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12893352/HDFS-12681.00.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12893363","id":"12893363","filename":"HDFS-12681.01.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-10-20T23:39:35.660+0000","size":54178,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12893363/HDFS-12681.01.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12893407","id":"12893407","filename":"HDFS-12681.02.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-10-21T07:31:59.836+0000","size":56278,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12893407/HDFS-12681.02.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12893620","id":"12893620","filename":"HDFS-12681.03.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-10-23T22:53:39.355+0000","size":54587,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12893620/HDFS-12681.03.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12893877","id":"12893877","filename":"HDFS-12681.04.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-10-25T05:02:17.808+0000","size":59719,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12893877/HDFS-12681.04.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12893995","id":"12893995","filename":"HDFS-12681.05.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-10-25T18:13:46.135+0000","size":60758,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12893995/HDFS-12681.05.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12894006","id":"12894006","filename":"HDFS-12681.06.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-10-25T18:54:45.308+0000","size":65178,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12894006/HDFS-12681.06.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12894437","id":"12894437","filename":"HDFS-12681.07.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-10-27T20:54:27.429+0000","size":33555,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12894437/HDFS-12681.07.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12894457","id":"12894457","filename":"HDFS-12681.08.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-10-27T21:34:23.963+0000","size":37975,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12894457/HDFS-12681.08.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12894798","id":"12894798","filename":"HDFS-12681.09.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-10-30T17:28:21.254+0000","size":33555,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12894798/HDFS-12681.09.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12895064","id":"12895064","filename":"HDFS-12681.10.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-10-31T20:31:31.763+0000","size":33099,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12895064/HDFS-12681.10.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12897916","id":"12897916","filename":"HDFS-12681.11.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-11-16T04:02:01.220+0000","size":45869,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12897916/HDFS-12681.11.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12898054","id":"12898054","filename":"HDFS-12681.12.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-11-16T20:40:14.618+0000","size":58839,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12898054/HDFS-12681.12.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12898617","id":"12898617","filename":"HDFS-12681.13.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-11-21T06:38:37.635+0000","size":59368,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12898617/HDFS-12681.13.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12899669","id":"12899669","filename":"HDFS-12681.14.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-11-28T19:42:51.905+0000","size":59518,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12899669/HDFS-12681.14.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12899718","id":"12899718","filename":"HDFS-12681.15.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-11-29T00:10:40.513+0000","size":60783,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12899718/HDFS-12681.15.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12899897","id":"12899897","filename":"HDFS-12681.16.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-11-29T23:02:52.918+0000","size":60783,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12899897/HDFS-12681.16.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"Make HdfsLocatedFileStatus a subtype of LocatedFileStatus","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/13110491/comment/16210095","id":"16210095","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"body":"Applications using {{instanceof}} to determine if the {{FileStatus}} instance contains locations may be affected. Most should be distinguished by the caller.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-10-18T21:40:41.457+0000","updated":"2017-10-18T21:40:41.457+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13110491/comment/16213581","id":"16213581","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"body":"This adds a builder pattern for {{HdfsFileStatus}}.\r\n\r\n[~stevel@apache.org], [~andrew.wang] do you have cycles to take a look?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-10-21T00:33:14.964+0000","updated":"2017-10-21T00:33:14.964+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13110491/comment/16213721","id":"16213721","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 15s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 7 new or modified test files. {color} |\r\n|| || || || {color:brown} trunk Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  1m 40s{color} | {color:blue} Maven dependency ordering for branch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 21m 38s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 17m 36s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m 27s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  3m 39s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 15m 37s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  6m 12s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m 43s{color} | {color:green} trunk passed {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 19s{color} | {color:blue} Maven dependency ordering for patch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  2m 47s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 14m  1s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 14m  1s{color} | {color:green} the patch passed {color} |\r\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  2m 25s{color} | {color:orange} root: The patch generated 69 new + 630 unchanged - 10 fixed = 699 total (was 640) {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  3m 37s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\r\n| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  1s{color} | {color:green} The patch has no ill-formed XML file. {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green}  9m 25s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |\r\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  2m 19s{color} | {color:red} hadoop-hdfs-project/hadoop-hdfs-client generated 2 new + 0 unchanged - 0 fixed = 2 total (was 0) {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  3m  6s{color} | {color:green} the patch passed {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green} 13m  3s{color} | {color:green} hadoop-common in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  1m 49s{color} | {color:green} hadoop-hdfs-client in the patch passed. {color} |\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}122m 12s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 46s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black}248m 55s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Reason || Tests ||\r\n| FindBugs | module:hadoop-hdfs-project/hadoop-hdfs-client |\r\n|  |  org.apache.hadoop.hdfs.protocol.HdfsFileStatus$Builder.path(byte[]) may expose internal representation by storing an externally mutable object into HdfsFileStatus$Builder.path  At HdfsFileStatus.java:by storing an externally mutable object into HdfsFileStatus$Builder.path  At HdfsFileStatus.java:[line 459] |\r\n|  |  org.apache.hadoop.hdfs.protocol.HdfsFileStatus$Builder.symlink(byte[]) may expose internal representation by storing an externally mutable object into HdfsFileStatus$Builder.symlink  At HdfsFileStatus.java:by storing an externally mutable object into HdfsFileStatus$Builder.symlink  At HdfsFileStatus.java:[line 448] |\r\n| Failed junit tests | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting |\r\n|   | hadoop.hdfs.server.namenode.ha.TestPipelinesFailover |\r\n|   | hadoop.hdfs.server.namenode.ha.TestDFSUpgradeWithHA |\r\n|   | hadoop.hdfs.TestReadStripedFileWithMissingBlocks |\r\n|   | hadoop.hdfs.server.datanode.TestDirectoryScanner |\r\n|   | hadoop.hdfs.security.TestDelegationTokenForProxyUser |\r\n|   | hadoop.hdfs.server.blockmanagement.TestBlockStatsMXBean |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker |  Image:yetus/hadoop:ca8ddc6 |\r\n| JIRA Issue | HDFS-12681 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12893363/HDFS-12681.01.patch |\r\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  xml  |\r\n| uname | Linux 5808568ff434 3.13.0-119-generic #166-Ubuntu SMP Wed May 3 12:18:55 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\r\n| git revision | trunk / 248d9b6 |\r\n| Default Java | 1.8.0_131 |\r\n| findbugs | v3.1.0-RC1 |\r\n| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/21771/artifact/patchprocess/diff-checkstyle-root.txt |\r\n| findbugs | https://builds.apache.org/job/PreCommit-HDFS-Build/21771/artifact/patchprocess/new-findbugs-hadoop-hdfs-project_hadoop-hdfs-client.html |\r\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/21771/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |\r\n|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/21771/testReport/ |\r\n| modules | C: hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs-client hadoop-hdfs-project/hadoop-hdfs U: . |\r\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/21771/console |\r\n| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2017-10-21T04:15:16.019+0000","updated":"2017-10-21T04:15:16.019+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13110491/comment/16213785","id":"16213785","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"body":"Checkstyle, findbugs","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-10-21T07:31:14.078+0000","updated":"2017-10-21T07:31:14.078+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13110491/comment/16213840","id":"16213840","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 11s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 7 new or modified test files. {color} |\r\n|| || || || {color:brown} trunk Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  1m 24s{color} | {color:blue} Maven dependency ordering for branch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 13m 11s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 11m 31s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m  6s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  2m 50s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 13m 24s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  4m 56s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m 12s{color} | {color:green} trunk passed {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 16s{color} | {color:blue} Maven dependency ordering for patch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  2m  7s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 10m 57s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 10m 57s{color} | {color:green} root generated 0 new + 1251 unchanged - 5 fixed = 1251 total (was 1256) {color} |\r\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  2m  5s{color} | {color:orange} root: The patch generated 33 new + 629 unchanged - 12 fixed = 662 total (was 641) {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  2m 47s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\r\n| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  1s{color} | {color:green} The patch has no ill-formed XML file. {color} |\r\n| {color:red}-1{color} | {color:red} shadedclient {color} | {color:red}  8m 23s{color} | {color:red} patch has errors when building and testing our client artifacts. {color} |\r\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  1m 42s{color} | {color:red} hadoop-hdfs-project/hadoop-hdfs-client generated 1 new + 0 unchanged - 0 fixed = 1 total (was 0) {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  0m 50s{color} | {color:red} hadoop-common-project_hadoop-common generated 1 new + 0 unchanged - 0 fixed = 1 total (was 0) {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  7m 23s{color} | {color:green} hadoop-common in the patch passed. {color} |\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}  1m 19s{color} | {color:red} hadoop-hdfs-client in the patch failed. {color} |\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 48m 16s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 27s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black}139m 37s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Reason || Tests ||\r\n| FindBugs | module:hadoop-hdfs-project/hadoop-hdfs-client |\r\n|  |  Null passed for non-null parameter of org.apache.hadoop.hdfs.protocol.HdfsFileStatus$Builder.symlink(byte[]) in org.apache.hadoop.hdfs.protocolPB.PBHelperClient.convert(HdfsProtos$HdfsFileStatusProto)  Method invoked at PBHelperClient.java:of org.apache.hadoop.hdfs.protocol.HdfsFileStatus$Builder.symlink(byte[]) in org.apache.hadoop.hdfs.protocolPB.PBHelperClient.convert(HdfsProtos$HdfsFileStatusProto)  Method invoked at PBHelperClient.java:[line 1581] |\r\n| Failed junit tests | hadoop.hdfs.web.TestWebHDFSOAuth2 |\r\n|   | hadoop.hdfs.server.namenode.web.resources.TestWebHdfsDataLocality |\r\n|   | hadoop.hdfs.TestDFSRemove |\r\n|   | hadoop.fs.viewfs.TestViewFileSystemLinkMergeSlash |\r\n|   | hadoop.hdfs.server.diskbalancer.TestConnectors |\r\n|   | hadoop.hdfs.server.datanode.TestDataNodeMetrics |\r\n|   | hadoop.fs.viewfs.TestViewFsAtHdfsRoot |\r\n|   | hadoop.fs.contract.hdfs.TestHDFSContractMkdir |\r\n|   | hadoop.hdfs.web.TestWebHDFSForHA |\r\n|   | hadoop.fs.viewfs.TestViewFileSystemWithTruncate |\r\n|   | hadoop.fs.TestEnhancedByteBufferAccess |\r\n|   | hadoop.cli.TestCryptoAdminCLI |\r\n|   | hadoop.hdfs.server.datanode.TestDataNodeFaultInjector |\r\n|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeMetrics |\r\n|   | hadoop.fs.TestFcHdfsCreateMkdir |\r\n|   | hadoop.hdfs.TestDataStream |\r\n|   | hadoop.hdfs.server.datanode.fsdataset.impl.TestLazyPersistFiles |\r\n|   | hadoop.hdfs.TestReconstructStripedFile |\r\n|   | hadoop.hdfs.server.datanode.TestDataNodeHotSwapVolumes |\r\n|   | hadoop.hdfs.TestSetrepIncreasing |\r\n|   | hadoop.hdfs.client.impl.TestBlockReaderLocal |\r\n|   | hadoop.hdfs.TestFetchImage |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure060 |\r\n|   | hadoop.hdfs.server.federation.router.TestRouterRpc |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStream |\r\n|   | hadoop.hdfs.server.namenode.ha.TestHAStateTransitions |\r\n|   | hadoop.hdfs.server.datanode.TestReadOnlySharedStorage |\r\n|   | hadoop.hdfs.server.namenode.snapshot.TestUpdatePipelineWithSnapshots |\r\n|   | hadoop.hdfs.web.TestHttpsFileSystem |\r\n|   | hadoop.fs.viewfs.TestViewFsFileStatusHdfs |\r\n|   | hadoop.hdfs.TestMaintenanceState |\r\n|   | hadoop.hdfs.server.namenode.snapshot.TestSnapshotNameWithInvalidCharacters |\r\n|   | hadoop.hdfs.TestFileCreationEmpty |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure150 |\r\n|   | hadoop.hdfs.TestMiniDFSCluster |\r\n|   | hadoop.hdfs.TestLeaseRecoveryStriped |\r\n|   | hadoop.hdfs.TestDFSClientRetries |\r\n|   | hadoop.hdfs.TestEncryptionZonesWithKMS |\r\n|   | hadoop.fs.contract.hdfs.TestHDFSContractRename |\r\n|   | hadoop.hdfs.TestReplication |\r\n|   | hadoop.hdfs.server.namenode.TestCheckpoint |\r\n|   | hadoop.hdfs.TestDFSOutputStream |\r\n|   | hadoop.hdfs.server.namenode.TestQuotaWithStripedBlocks |\r\n|   | hadoop.fs.TestSWebHdfsFileContextMainOperations |\r\n|   | hadoop.hdfs.TestDFSRollback |\r\n|   | hadoop.hdfs.TestErasureCodeBenchmarkThroughput |\r\n|   | hadoop.hdfs.server.namenode.ha.TestPendingCorruptDnMessages |\r\n|   | hadoop.hdfs.server.namenode.snapshot.TestXAttrWithSnapshot |\r\n|   | hadoop.hdfs.TestTrashWithSecureEncryptionZones |\r\n|   | hadoop.cli.TestErasureCodingCLI |\r\n|   | hadoop.tools.TestJMXGet |\r\n|   | hadoop.hdfs.TestParallelRead |\r\n|   | hadoop.hdfs.server.namenode.TestAddStripedBlocks |\r\n|   | hadoop.hdfs.TestHDFSTrash |\r\n|   | hadoop.hdfs.TestAclsEndToEnd |\r\n|   | hadoop.hdfs.server.namenode.TestQuotaByStorageType |\r\n|   | hadoop.hdfs.server.namenode.TestBlockUnderConstruction |\r\n|   | hadoop.hdfs.TestWriteRead |\r\n|   | hadoop.hdfs.TestFileAppend4 |\r\n|   | hadoop.hdfs.web.TestFSMainOperationsWebHdfs |\r\n|   | hadoop.hdfs.TestSnapshotCommands |\r\n|   | hadoop.hdfs.TestBlocksScheduledCounter |\r\n|   | hadoop.hdfs.client.impl.TestBlockReaderFactory |\r\n|   | hadoop.hdfs.web.TestWebHdfsWithMultipleNameNodes |\r\n|   | hadoop.hdfs.TestSafeModeWithStripedFile |\r\n|   | hadoop.hdfs.TestDFSShellGenericOptions |\r\n|   | hadoop.hdfs.server.datanode.TestNNHandlesBlockReportPerStorage |\r\n|   | hadoop.hdfs.TestDataTransferKeepalive |\r\n|   | hadoop.hdfs.TestClientProtocolForPipelineRecovery |\r\n|   | hadoop.hdfs.crypto.TestHdfsCryptoStreams |\r\n|   | hadoop.hdfs.TestLeaseRecovery2 |\r\n|   | hadoop.fs.contract.hdfs.TestHDFSContractOpen |\r\n|   | hadoop.hdfs.TestFSOutputSummer |\r\n|   | hadoop.hdfs.TestDFSFinalize |\r\n|   | hadoop.hdfs.server.namenode.TestDeleteRace |\r\n|   | hadoop.hdfs.server.namenode.TestAddBlockRetry |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure050 |\r\n|   | hadoop.hdfs.TestLargeBlock |\r\n|   | hadoop.hdfs.server.namenode.snapshot.TestSnapshotFileLength |\r\n|   | hadoop.hdfs.TestErasureCodingPoliciesWithRandomECPolicy |\r\n|   | hadoop.hdfs.server.blockmanagement.TestBlockTokenWithDFSStriped |\r\n|   | hadoop.hdfs.TestEncryptionZonesWithHA |\r\n|   | hadoop.hdfs.server.namenode.TestListCorruptFileBlocks |\r\n|   | hadoop.hdfs.server.namenode.TestNamenodeStorageDirectives |\r\n|   | hadoop.hdfs.server.datanode.TestDnRespectsBlockReportSplitThreshold |\r\n|   | hadoop.hdfs.server.namenode.ha.TestStandbyIsHot |\r\n|   | hadoop.hdfs.TestFileChecksum |\r\n|   | hadoop.hdfs.server.namenode.snapshot.TestSnapshotBlocksMap |\r\n|   | hadoop.hdfs.TestReservedRawPaths |\r\n|   | hadoop.hdfs.server.balancer.TestBalancerWithSaslDataTransfer |\r\n|   | hadoop.hdfs.server.namenode.TestAddBlock |\r\n|   | hadoop.hdfs.server.namenode.ha.TestPipelinesFailover |\r\n|   | hadoop.hdfs.server.balancer.TestBalancerWithHANameNodes |\r\n|   | hadoop.hdfs.server.blockmanagement.TestUnderReplicatedBlocks |\r\n|   | hadoop.hdfs.TestDFSStorageStateRecovery |\r\n|   | hadoop.hdfs.web.TestWebHdfsWithAuthenticationFilter |\r\n|   | hadoop.hdfs.server.datanode.fsdataset.impl.TestSpaceReservation |\r\n|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure |\r\n|   | hadoop.hdfs.server.namenode.TestFSImageWithXAttr |\r\n|   | hadoop.hdfs.server.namenode.snapshot.TestDisallowModifyROSnapshot |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure130 |\r\n|   | hadoop.hdfs.server.namenode.TestUpgradeDomainBlockPlacementPolicy |\r\n|   | hadoop.hdfs.TestLocalDFS |\r\n|   | hadoop.hdfs.server.namenode.TestSnapshotPathINodes |\r\n|   | hadoop.hdfs.server.federation.router.TestRouterRpcMultiDestination |\r\n|   | hadoop.hdfs.server.namenode.TestFSImageWithAcl |\r\n|   | hadoop.hdfs.server.namenode.snapshot.TestSnapshottableDirListing |\r\n|   | hadoop.hdfs.server.datanode.TestDirectoryScanner |\r\n|   | hadoop.hdfs.tools.TestViewFSStoragePolicyCommands |\r\n|   | hadoop.hdfs.TestRestartDFS |\r\n|   | hadoop.hdfs.server.blockmanagement.TestBlockStatsMXBean |\r\n|   | hadoop.hdfs.TestDataTransferProtocol |\r\n|   | hadoop.hdfs.server.datanode.TestDeleteBlockPool |\r\n|   | hadoop.hdfs.server.datanode.fsdataset.impl.TestLazyPersistPolicy |\r\n|   | hadoop.hdfs.server.namenode.snapshot.TestNestedSnapshots |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure170 |\r\n|   | hadoop.hdfs.TestDFSPermission |\r\n|   | hadoop.hdfs.server.namenode.ha.TestBootstrapStandby |\r\n|   | hadoop.hdfs.qjournal.TestSecureNNWithQJM |\r\n|   | hadoop.hdfs.server.namenode.ha.TestDFSUpgradeWithHA |\r\n|   | hadoop.hdfs.server.diskbalancer.TestDiskBalancerRPC |\r\n|   | hadoop.hdfs.shortcircuit.TestShortCircuitCache |\r\n|   | hadoop.hdfs.server.namenode.TestAddOverReplicatedStripedBlocks |\r\n|   | hadoop.hdfs.server.datanode.TestDataNodeMXBean |\r\n|   | hadoop.hdfs.server.mover.TestStorageMover |\r\n|   | hadoop.hdfs.server.namenode.snapshot.TestRenameWithSnapshots |\r\n|   | hadoop.hdfs.web.TestWebHDFS |\r\n|   | hadoop.fs.contract.hdfs.TestHDFSContractRootDirectory |\r\n|   | hadoop.hdfs.server.namenode.TestFsckWithMultipleNameNodes |\r\n|   | hadoop.hdfs.server.mover.TestMover |\r\n|   | hadoop.hdfs.security.TestDelegationToken |\r\n|   | hadoop.hdfs.TestSafeMode |\r\n|   | hadoop.hdfs.TestFileCreation |\r\n|   | hadoop.hdfs.server.namenode.snapshot.TestSnapshotMetrics |\r\n|   | hadoop.hdfs.TestDistributedFileSystemWithECFile |\r\n|   | hadoop.hdfs.server.balancer.TestBalancerWithMultipleNameNodes |\r\n|   | hadoop.fs.TestHDFSFileContextMainOperations |\r\n|   | hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl |\r\n|   | hadoop.hdfs.server.namenode.ha.TestStandbyBlockManagement |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure210 |\r\n|   | hadoop.hdfs.TestDistributedFileSystem |\r\n|   | hadoop.hdfs.TestSmallBlock |\r\n|   | hadoop.hdfs.TestReplaceDatanodeFailureReplication |\r\n|   | hadoop.hdfs.TestEncryptionZones |\r\n|   | hadoop.hdfs.server.blockmanagement.TestOverReplicatedBlocks |\r\n|   | hadoop.hdfs.server.diskbalancer.command.TestDiskBalancerCommand |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure180 |\r\n|   | hadoop.hdfs.server.datanode.TestHSync |\r\n|   | hadoop.hdfs.server.balancer.TestBalancerRPCDelay |\r\n|   | hadoop.hdfs.qjournal.TestNNWithQJM |\r\n|   | hadoop.hdfs.server.namenode.TestNameNodeXAttr |\r\n|   | hadoop.hdfs.server.namenode.snapshot.TestSetQuotaWithSnapshot |\r\n|   | hadoop.hdfs.TestFileAppendRestart |\r\n|   | hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA |\r\n|   | hadoop.hdfs.server.namenode.TestNamenodeCapacityReport |\r\n|   | hadoop.hdfs.server.namenode.web.resources.TestWebHdfsCreatePermissions |\r\n|   | hadoop.hdfs.TestDFSStripedInputStreamWithRandomECPolicy |\r\n|   | hadoop.hdfs.web.TestWebHDFSAcl |\r\n|   | hadoop.hdfs.server.namenode.TestStorageRestore |\r\n|   | hadoop.hdfs.TestErasureCodingPolicyWithSnapshot |\r\n|   | hadoop.hdfs.TestClientReportBadBlock |\r\n|   | hadoop.hdfs.TestErasureCodingPolicyWithSnapshotWithRandomECPolicy |\r\n|   | hadoop.hdfs.server.namenode.TestFsck |\r\n|   | hadoop.cli.TestDeleteCLI |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure030 |\r\n|   | hadoop.hdfs.TestDecommissionWithStriped |\r\n|   | hadoop.hdfs.TestClose |\r\n|   | hadoop.hdfs.server.namenode.ha.TestHAFsck |\r\n|   | hadoop.hdfs.server.blockmanagement.TestNodeCount |\r\n|   | hadoop.hdfs.TestSeekBug |\r\n|   | hadoop.hdfs.TestFileAppend2 |\r\n|   | hadoop.hdfs.TestLeaseRecovery |\r\n|   | hadoop.hdfs.TestSetTimes |\r\n|   | hadoop.hdfs.server.namenode.TestDecommissioningStatus |\r\n|   | hadoop.hdfs.server.namenode.snapshot.TestSnapshotRename |\r\n|   | hadoop.hdfs.tools.TestDFSZKFailoverController |\r\n|   | hadoop.fs.contract.hdfs.TestHDFSContractAppend |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure160 |\r\n|   | hadoop.hdfs.TestDistributedFileSystemWithECFileWithRandomECPolicy |\r\n|   | hadoop.hdfs.server.namenode.TestNameNodeMetadataConsistency |\r\n|   | hadoop.hdfs.server.blockmanagement.TestReconstructStripedBlocksWithRackAwareness |\r\n|   | hadoop.hdfs.server.blockmanagement.TestPendingReconstruction |\r\n|   | hadoop.hdfs.server.datanode.TestTriggerBlockReport |\r\n|   | hadoop.hdfs.TestFSInputChecker |\r\n|   | hadoop.hdfs.TestSafeModeWithStripedFileWithRandomECPolicy |\r\n|   | hadoop.hdfs.client.impl.TestBlockReaderLocalLegacy |\r\n|   | hadoop.hdfs.web.TestWebHdfsFileSystemContract |\r\n|   | hadoop.hdfs.server.namenode.TestCacheDirectives |\r\n|   | hadoop.hdfs.TestGetBlocks |\r\n|   | hadoop.fs.TestFcHdfsPermission |\r\n|   | hadoop.fs.permission.TestStickyBit |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure080 |\r\n|   | hadoop.hdfs.TestPipelines |\r\n|   | hadoop.fs.TestFcHdfsSetUMask |\r\n|   | hadoop.hdfs.server.namenode.TestStripedINodeFile |\r\n|   | hadoop.hdfs.TestRollingUpgrade |\r\n|   | hadoop.fs.contract.hdfs.TestHDFSContractCreate |\r\n|   | hadoop.hdfs.server.namenode.TestProcessCorruptBlocks |\r\n|   | hadoop.hdfs.TestAppendDifferentChecksum |\r\n|   | hadoop.hdfs.server.blockmanagement.TestPendingInvalidateBlock |\r\n|   | hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData |\r\n|   | hadoop.hdfs.server.namenode.ha.TestEditLogTailer |\r\n|   | hadoop.hdfs.server.balancer.TestBalancer |\r\n|   | hadoop.cli.TestAclCLIWithPosixAclInheritance |\r\n|   | hadoop.hdfs.TestRenameWhileOpen |\r\n|   | hadoop.hdfs.TestLease |\r\n|   | hadoop.hdfs.server.namenode.snapshot.TestRandomOpsWithSnapshots |\r\n|   | hadoop.hdfs.server.namenode.TestFSDirectory |\r\n|   | hadoop.hdfs.server.datanode.fsdataset.impl.TestLazyPersistLockedMemory |\r\n|   | hadoop.hdfs.TestBlockStoragePolicy |\r\n|   | hadoop.hdfs.server.datanode.TestBlockRecovery |\r\n|   | hadoop.hdfs.TestDisableConnCache |\r\n|   | hadoop.hdfs.server.namenode.snapshot.TestSnapshotReplication |\r\n|   | hadoop.hdfs.server.namenode.TestLeaseManager |\r\n|   | hadoop.hdfs.tools.offlineEditsViewer.TestOfflineEditsViewer |\r\n|   | hadoop.hdfs.TestBlockMissingException |\r\n|   | hadoop.hdfs.TestFileCreationDelete |\r\n|   | hadoop.hdfs.TestParallelShortCircuitLegacyRead |\r\n|   | hadoop.hdfs.server.datanode.fsdataset.impl.TestInterDatanodeProtocol |\r\n|   | hadoop.hdfs.server.namenode.TestNestedEncryptionZones |\r\n|   | hadoop.hdfs.TestGetFileChecksum |\r\n|   | hadoop.hdfs.TestReadStripedFileWithMissingBlocks |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure140 |\r\n|   | hadoop.hdfs.TestConnCache |\r\n|   | hadoop.hdfs.server.namenode.ha.TestHAMetrics |\r\n|   | hadoop.hdfs.server.balancer.TestBalancerWithNodeGroup |\r\n|   | hadoop.tracing.TestTracingShortCircuitLocalRead |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithRandomECPolicy |\r\n|   | hadoop.hdfs.TestDecommission |\r\n|   | hadoop.hdfs.TestDFSUpgrade |\r\n|   | hadoop.hdfs.server.namenode.TestReconstructStripedBlocks |\r\n|   | hadoop.hdfs.TestExtendedAcls |\r\n|   | hadoop.fs.TestResolveHdfsSymlink |\r\n|   | hadoop.cli.TestXAttrCLI |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure090 |\r\n|   | hadoop.hdfs.server.namenode.ha.TestFailureToReadEdits |\r\n|   | hadoop.hdfs.server.datanode.TestDataNodeTcpNoDelay |\r\n|   | hadoop.hdfs.server.namenode.TestFSImage |\r\n|   | hadoop.hdfs.TestModTime |\r\n|   | hadoop.hdfs.server.namenode.TestBlockPlacementPolicyRackFaultTolerant |\r\n|   | hadoop.hdfs.TestDFSStripedInputStream |\r\n|   | hadoop.hdfs.server.namenode.ha.TestXAttrsWithHA |\r\n|   | hadoop.hdfs.server.namenode.TestNameNodeMXBean |\r\n|   | hadoop.fs.shell.TestHdfsTextCommand |\r\n|   | hadoop.hdfs.TestDFSMkdirs |\r\n|   | hadoop.hdfs.TestFileStatus |\r\n|   | hadoop.hdfs.server.datanode.TestDiskError |\r\n|   | hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewerForContentSummary |\r\n|   | hadoop.hdfs.tools.TestStoragePolicyCommands |\r\n|   | hadoop.hdfs.web.TestWebHdfsTokens |\r\n|   | hadoop.hdfs.server.datanode.TestIncrementalBrVariations |\r\n|   | hadoop.hdfs.TestDatanodeLayoutUpgrade |\r\n|   | hadoop.hdfs.server.namenode.snapshot.TestSnapshotDeletion |\r\n|   | hadoop.hdfs.server.namenode.ha.TestInitializeSharedEdits |\r\n|   | hadoop.hdfs.TestParallelUnixDomainRead |\r\n|   | hadoop.hdfs.web.TestWebHdfsWithRestCsrfPreventionFilter |\r\n|   | hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure040 |\r\n|   | hadoop.hdfs.TestReadStripedFileWithDecoding |\r\n|   | hadoop.fs.viewfs.TestViewFileSystemAtHdfsRoot |\r\n|   | hadoop.hdfs.server.namenode.snapshot.TestSnapshotDiffReport |\r\n|   | hadoop.hdfs.TestMissingBlocksAlert |\r\n|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting |\r\n|   | hadoop.hdfs.TestDatanodeDeath |\r\n|   | hadoop.hdfs.server.namenode.TestAuditLogs |\r\n|   | hadoop.hdfs.server.datanode.TestBlockHasMultipleReplicasOnSameDN |\r\n|   | hadoop.hdfs.TestListFilesInFileContext |\r\n|   | hadoop.hdfs.TestErasureCodingPolicies |\r\n|   | hadoop.hdfs.server.namenode.ha.TestFailoverWithBlockTokensEnabled |\r\n|   | hadoop.hdfs.TestFileAppend |\r\n|   | hadoop.metrics2.sink.TestRollingFileSystemSinkWithSecureHdfs |\r\n|   | hadoop.hdfs.TestAppendSnapshotTruncate |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure010 |\r\n|   | hadoop.fs.viewfs.TestViewFileSystemHdfs |\r\n|   | hadoop.hdfs.TestFsShellPermission |\r\n|   | hadoop.hdfs.server.namenode.TestEditLog |\r\n|   | hadoop.security.TestPermissionSymlinks |\r\n|   | hadoop.hdfs.server.namenode.TestFavoredNodesEndToEnd |\r\n|   | hadoop.fs.contract.hdfs.TestHDFSContractDelete |\r\n|   | hadoop.fs.contract.hdfs.TestHDFSContractConcat |\r\n|   | hadoop.hdfs.server.namenode.snapshot.TestFileContextSnapshot |\r\n|   | hadoop.hdfs.server.namenode.TestFileContextAcl |\r\n|   | hadoop.hdfs.server.datanode.TestBatchIbr |\r\n|   | hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication |\r\n|   | hadoop.hdfs.server.namenode.TestMetaSave |\r\n|   | hadoop.hdfs.server.namenode.TestListOpenFiles |\r\n|   | hadoop.fs.TestUrlStreamHandler |\r\n|   | hadoop.hdfs.TestRollingUpgradeRollback |\r\n|   | hadoop.hdfs.server.blockmanagement.TestBlockTokenWithDFS |\r\n|   | hadoop.hdfs.server.blockmanagement.TestComputeInvalidateWork |\r\n|   | hadoop.hdfs.TestDFSUpgradeFromImage |\r\n|   | hadoop.hdfs.server.namenode.ha.TestEditLogsDuringFailover |\r\n|   | hadoop.hdfs.TestHDFSFileSystemContract |\r\n|   | hadoop.fs.TestSymlinkHdfsDisable |\r\n|   | hadoop.hdfs.server.namenode.metrics.TestNNMetricFilesInGetListingOps |\r\n|   | hadoop.hdfs.server.namenode.TestFSImageWithSnapshot |\r\n|   | hadoop.hdfs.TestEncryptedTransfer |\r\n|   | hadoop.hdfs.server.blockmanagement.TestBlockManager |\r\n|   | hadoop.hdfs.tools.TestWebHDFSStoragePolicyCommands |\r\n|   | hadoop.hdfs.TestWriteConfigurationToDFS |\r\n|   | hadoop.hdfs.TestExternalBlockReader |\r\n|   | hadoop.hdfs.server.namenode.TestStartup |\r\n|   | hadoop.hdfs.server.namenode.TestINodeAttributeProvider |\r\n|   | hadoop.hdfs.server.blockmanagement.TestSequentialBlockGroupId |\r\n|   | hadoop.hdfs.server.namenode.TestParallelImageWrite |\r\n|   | hadoop.hdfs.server.namenode.TestFileLimit |\r\n|   | hadoop.fs.viewfs.TestViewFsHdfs |\r\n|   | hadoop.hdfs.TestHdfsAdmin |\r\n|   | hadoop.hdfs.TestParallelShortCircuitRead |\r\n|   | hadoop.hdfs.server.datanode.fsdataset.impl.TestDatanodeRestart |\r\n|   | hadoop.hdfs.TestReadWhileWriting |\r\n|   | hadoop.hdfs.server.namenode.ha.TestDNFencing |\r\n|   | hadoop.hdfs.TestFileStatusSerialization |\r\n|   | hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer |\r\n|   | hadoop.fs.contract.hdfs.TestHDFSContractGetFileStatus |\r\n|   | hadoop.hdfs.server.namenode.ha.TestSeveralNameNodes |\r\n|   | hadoop.hdfs.TestFileStatusWithECPolicy |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure120 |\r\n|   | hadoop.hdfs.shortcircuit.TestShortCircuitLocalRead |\r\n|   | hadoop.hdfs.server.namenode.TestFileContextXAttr |\r\n|   | hadoop.hdfs.security.token.block.TestBlockToken |\r\n|   | hadoop.hdfs.server.namenode.TestLargeDirectoryDelete |\r\n|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure020 |\r\n|   | hadoop.hdfs.server.namenode.TestHostsFiles |\r\n|   | hadoop.hdfs.server.namenode.snapshot.TestSnapshotListing |\r\n|   | hadoop.hdfs.server.blockmanagement.TestBlocksWithNotEnoughRacks |\r\n|   | hadoop.hdfs.security.TestDelegationTokenForProxyUser |\r\n|   | hadoop.tracing.TestTracing |\r\n|   | hadoop.cli.TestHDFSCLI |\r\n|   | hadoop.hdfs.TestFileAppend3 |\r\n|   | hadoop.hdfs.tools.TestDebugAdmin |\r\n|   | hadoop.hdfs.TestWriteBlockGetsBlockLengthHint |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailureWithRandomECPolicy |\r\n|   | hadoop.hdfs.web.TestWebHDFSXAttr |\r\n|   | hadoop.hdfs.client.impl.TestBlockReaderRemote |\r\n|   | hadoop.hdfs.TestListFilesInDFS |\r\n|   | hadoop.hdfs.server.namenode.TestNamenodeRetryCache |\r\n|   | hadoop.hdfs.server.blockmanagement.TestSequentialBlockId |\r\n|   | hadoop.security.TestPermission |\r\n|   | hadoop.hdfs.server.namenode.TestFSEditLogLoader |\r\n|   | hadoop.hdfs.server.namenode.TestNameNodeAcl |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure200 |\r\n|   | hadoop.hdfs.server.namenode.TestReencryption |\r\n|   | hadoop.hdfs.server.namenode.TestFileTruncate |\r\n|   | hadoop.fs.loadGenerator.TestLoadGenerator |\r\n|   | hadoop.hdfs.server.namenode.ha.TestHASafeMode |\r\n|   | hadoop.hdfs.server.namenode.TestAddStripedBlockInFBR |\r\n|   | hadoop.hdfs.TestSecureEncryptionZoneWithKMS |\r\n|   | hadoop.TestRefreshCallQueue |\r\n|   | hadoop.metrics2.sink.TestRollingFileSystemSinkWithHdfs |\r\n|   | hadoop.hdfs.server.namenode.TestDefaultBlockPlacementPolicy |\r\n|   | hadoop.hdfs.tools.TestDFSAdmin |\r\n|   | hadoop.hdfs.server.datanode.fsdataset.impl.TestLazyPersistReplicaPlacement |\r\n|   | hadoop.fs.TestUnbuffer |\r\n|   | hadoop.hdfs.TestApplyingStoragePolicy |\r\n|   | hadoop.cli.TestAclCLI |\r\n|   | hadoop.fs.TestGlobPaths |\r\n|   | hadoop.hdfs.server.namenode.TestReencryptionWithKMS |\r\n|   | hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewerWithStripedBlocks |\r\n|   | hadoop.hdfs.server.namenode.TestHDFSConcat |\r\n|   | hadoop.hdfs.TestFileConcurrentReader |\r\n|   | hadoop.hdfs.TestDatanodeStartupFixesLegacyStorageIDs |\r\n|   | hadoop.hdfs.TestFileCreationClient |\r\n|   | hadoop.hdfs.TestDatanodeReport |\r\n|   | hadoop.hdfs.server.datanode.TestDataNodeRollingUpgrade |\r\n|   | hadoop.hdfs.TestDFSStartupVersions |\r\n|   | hadoop.hdfs.server.datanode.TestFsDatasetCache |\r\n|   | hadoop.hdfs.server.namenode.TestINodeFile |\r\n|   | hadoop.hdfs.TestReplaceDatanodeOnFailure |\r\n|   | hadoop.hdfs.TestDFSClientExcludedNodes |\r\n|   | hadoop.hdfs.server.datanode.TestCachingStrategy |\r\n|   | hadoop.hdfs.server.blockmanagement.TestNameNodePrunesMissingStorages |\r\n|   | hadoop.hdfs.server.namenode.ha.TestHAAppend |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure110 |\r\n|   | hadoop.hdfs.server.namenode.TestDiskspaceQuotaUpdate |\r\n|   | hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData |\r\n|   | hadoop.hdfs.server.datanode.TestBlockReplacement |\r\n|   | hadoop.hdfs.TestErasureCodingMultipleRacks |\r\n|   | hadoop.hdfs.TestCrcCorruption |\r\n|   | hadoop.hdfs.server.datanode.TestNNHandlesCombinedBlockReport |\r\n|   | hadoop.hdfs.server.namenode.ha.TestQuotasWithHA |\r\n|   | hadoop.hdfs.server.blockmanagement.TestRBWBlockInvalidation |\r\n|   | hadoop.hdfs.server.namenode.snapshot.TestGetContentSummaryWithSnapshot |\r\n|   | hadoop.hdfs.TestDFSInputStream |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure100 |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure070 |\r\n|   | hadoop.hdfs.TestDFSClientFailover |\r\n|   | hadoop.hdfs.TestParallelShortCircuitReadUnCached |\r\n|   | hadoop.hdfs.server.namenode.TestNameEditsConfigs |\r\n|   | hadoop.hdfs.TestAbandonBlock |\r\n|   | hadoop.hdfs.client.impl.TestClientBlockVerification |\r\n|   | hadoop.hdfs.TestDFSShell |\r\n|   | hadoop.hdfs.server.datanode.fsdataset.impl.TestLazyPersistReplicaRecovery |\r\n|   | hadoop.hdfs.TestMultiThreadedHflush |\r\n|   | hadoop.hdfs.server.namenode.metrics.TestNameNodeMetrics |\r\n|   | hadoop.fs.TestWebHdfsFileContextMainOperations |\r\n|   | hadoop.fs.viewfs.TestViewFileSystemLinkFallback |\r\n|   | hadoop.hdfs.protocol.datatransfer.sasl.TestSaslDataTransfer |\r\n|   | hadoop.fs.viewfs.TestViewFsDefaultValue |\r\n|   | hadoop.hdfs.server.datanode.TestDataNodeErasureCodingMetrics |\r\n|   | hadoop.hdfs.TestDFSRename |\r\n|   | hadoop.fs.TestSymlinkHdfsFileSystem |\r\n|   | hadoop.hdfs.TestWriteReadStripedFile |\r\n|   | hadoop.hdfs.server.namenode.snapshot.TestAclWithSnapshot |\r\n|   | hadoop.hdfs.server.diskbalancer.TestDiskBalancer |\r\n|   | hadoop.hdfs.server.namenode.TestGetContentSummaryWithPermission |\r\n|   | hadoop.hdfs.TestParallelShortCircuitReadNoChecksum |\r\n|   | hadoop.hdfs.TestFileCorruption |\r\n|   | hadoop.hdfs.server.namenode.ha.TestStandbyInProgressTail |\r\n|   | hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewerForAcl |\r\n|   | hadoop.hdfs.TestUnsetAndChangeDirectoryEcPolicy |\r\n|   | hadoop.hdfs.server.datanode.TestBlockScanner |\r\n|   | hadoop.hdfs.server.namenode.TestAuditLogger |\r\n|   | hadoop.hdfs.server.datanode.TestTransferRbw |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure190 |\r\n|   | hadoop.hdfs.TestSetrepDecreasing |\r\n|   | hadoop.fs.contract.hdfs.TestHDFSContractSeek |\r\n|   | hadoop.hdfs.server.namenode.snapshot.TestSnapshot |\r\n|   | hadoop.hdfs.server.datanode.fsdataset.impl.TestLazyWriter |\r\n|   | hadoop.hdfs.TestHFlush |\r\n|   | hadoop.hdfs.server.namenode.TestQuotaWithStripedBlocksWithRandomECPolicy |\r\n|   | hadoop.hdfs.TestRead |\r\n|   | hadoop.hdfs.server.datanode.TestFsDatasetCacheRevocation |\r\n|   | hadoop.hdfs.server.namenode.TestCommitBlockWithInvalidGenStamp |\r\n|   | hadoop.hdfs.server.federation.store.driver.TestStateStoreFileSystem |\r\n|   | hadoop.hdfs.server.balancer.TestBalancerWithEncryptedTransfer |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure |\r\n|   | hadoop.hdfs.TestPread |\r\n|   | hadoop.hdfs.server.datanode.fsdataset.impl.TestScrLazyPersistFiles |\r\n|   | hadoop.hdfs.TestDFSInotifyEventInputStream |\r\n|   | hadoop.hdfs.server.namenode.TestAuditLoggerWithCommands |\r\n|   | hadoop.hdfs.server.namenode.snapshot.TestINodeFileUnderConstructionWithSnapshot |\r\n|   | hadoop.hdfs.TestPersistBlocks |\r\n|   | hadoop.hdfs.server.namenode.TestSaveNamespace |\r\n|   | hadoop.hdfs.TestQuota |\r\n|   | hadoop.hdfs.server.namenode.ha.TestHarFileSystemWithHA |\r\n|   | hadoop.hdfs.server.namenode.TestNameNodeRecovery |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure000 |\r\n|   | hadoop.hdfs.TestTrashWithEncryptionZones |\r\n|   | hadoop.fs.TestSymlinkHdfsFileContext |\r\n|   | hadoop.hdfs.TestInjectionForSimulatedStorage |\r\n|   | hadoop.hdfs.TestFileLengthOnClusterRestart |\r\n| Timed out junit tests | org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyCheckpoints |\r\n|   | org.apache.hadoop.hdfs.server.namenode.TestNNThroughputBenchmark |\r\n|   | org.apache.hadoop.hdfs.server.namenode.TestBackupNode |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker |  Image:yetus/hadoop:ca8ddc6 |\r\n| JIRA Issue | HDFS-12681 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12893407/HDFS-12681.02.patch |\r\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  xml  |\r\n| uname | Linux 139ee48570e2 3.13.0-119-generic #166-Ubuntu SMP Wed May 3 12:18:55 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\r\n| git revision | trunk / 248d9b6 |\r\n| Default Java | 1.8.0_131 |\r\n| findbugs | v3.1.0-RC1 |\r\n| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/21775/artifact/patchprocess/diff-checkstyle-root.txt |\r\n| findbugs | https://builds.apache.org/job/PreCommit-HDFS-Build/21775/artifact/patchprocess/new-findbugs-hadoop-hdfs-project_hadoop-hdfs-client.html |\r\n| javadoc | https://builds.apache.org/job/PreCommit-HDFS-Build/21775/artifact/patchprocess/diff-javadoc-javadoc-hadoop-common-project_hadoop-common.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/21775/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-client.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/21775/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |\r\n|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/21775/testReport/ |\r\n| modules | C: hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs-client hadoop-hdfs-project/hadoop-hdfs U: . |\r\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/21775/console |\r\n| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2017-10-21T10:04:36.313+0000","updated":"2017-10-21T10:04:36.313+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13110491/comment/16215095","id":"16215095","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"Core idea looks good; tests are NPEing on unmarshall of pb and json tho'","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2017-10-23T12:57:27.285+0000","updated":"2017-10-23T12:57:27.285+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13110491/comment/16215998","id":"16215998","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"body":"I haven't been able to reproduce these errors... trying again","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-10-23T22:54:22.547+0000","updated":"2017-10-23T22:54:22.547+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13110491/comment/16217844","id":"16217844","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 13s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 7 new or modified test files. {color} |\r\n|| || || || {color:brown} trunk Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 17s{color} | {color:blue} Maven dependency ordering for branch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 14m 59s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 13m 44s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m 24s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  3m  3s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 14m 21s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  5m 36s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m 27s{color} | {color:green} trunk passed {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 17s{color} | {color:blue} Maven dependency ordering for patch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  2m 30s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 11m 15s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 11m 15s{color} | {color:green} the patch passed {color} |\r\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  2m 10s{color} | {color:orange} root: The patch generated 69 new + 631 unchanged - 10 fixed = 700 total (was 641) {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  2m 56s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\r\n| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  1s{color} | {color:green} The patch has no ill-formed XML file. {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green}  8m 40s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |\r\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  1m 43s{color} | {color:red} hadoop-hdfs-project/hadoop-hdfs-client generated 2 new + 0 unchanged - 0 fixed = 2 total (was 0) {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m  9s{color} | {color:green} the patch passed {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  7m 41s{color} | {color:green} hadoop-common in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  1m 24s{color} | {color:green} hadoop-hdfs-client in the patch passed. {color} |\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 98m 43s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 31s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black}196m 42s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Reason || Tests ||\r\n| FindBugs | module:hadoop-hdfs-project/hadoop-hdfs-client |\r\n|  |  org.apache.hadoop.hdfs.protocol.HdfsFileStatus$Builder.path(byte[]) may expose internal representation by storing an externally mutable object into HdfsFileStatus$Builder.path  At HdfsFileStatus.java:by storing an externally mutable object into HdfsFileStatus$Builder.path  At HdfsFileStatus.java:[line 459] |\r\n|  |  org.apache.hadoop.hdfs.protocol.HdfsFileStatus$Builder.symlink(byte[]) may expose internal representation by storing an externally mutable object into HdfsFileStatus$Builder.symlink  At HdfsFileStatus.java:by storing an externally mutable object into HdfsFileStatus$Builder.symlink  At HdfsFileStatus.java:[line 448] |\r\n| Failed junit tests | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting |\r\n|   | hadoop.hdfs.server.blockmanagement.TestBlockStatsMXBean |\r\n|   | hadoop.hdfs.server.federation.router.TestRouterRpc |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker |  Image:yetus/hadoop:ca8ddc6 |\r\n| JIRA Issue | HDFS-12681 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12893620/HDFS-12681.03.patch |\r\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  xml  |\r\n| uname | Linux 22ef825d6f9f 3.13.0-129-generic #178-Ubuntu SMP Fri Aug 11 12:48:20 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\r\n| git revision | trunk / 1c5c2b5 |\r\n| maven | version: Apache Maven 3.3.9 |\r\n| Default Java | 1.8.0_131 |\r\n| findbugs | v3.1.0-RC1 |\r\n| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/21802/artifact/patchprocess/diff-checkstyle-root.txt |\r\n| findbugs | https://builds.apache.org/job/PreCommit-HDFS-Build/21802/artifact/patchprocess/new-findbugs-hadoop-hdfs-project_hadoop-hdfs-client.html |\r\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/21802/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |\r\n|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/21802/testReport/ |\r\n| modules | C: hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs-client hadoop-hdfs-project/hadoop-hdfs U: . |\r\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/21802/console |\r\n| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2017-10-24T22:55:43.882+0000","updated":"2017-10-24T22:55:43.882+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13110491/comment/16218359","id":"16218359","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 26s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 7 new or modified test files. {color} |\r\n|| || || || {color:brown} trunk Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  1m 57s{color} | {color:blue} Maven dependency ordering for branch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 15m 37s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 13m 43s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m 22s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  3m 10s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 14m 34s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  5m  6s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m 34s{color} | {color:green} trunk passed {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 16s{color} | {color:blue} Maven dependency ordering for patch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  2m 26s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 13m 49s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 13m 49s{color} | {color:green} the patch passed {color} |\r\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  2m 18s{color} | {color:orange} root: The patch generated 21 new + 628 unchanged - 12 fixed = 649 total (was 640) {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  3m  5s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\r\n| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  1s{color} | {color:green} The patch has no ill-formed XML file. {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green}  8m 53s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  5m 29s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m 21s{color} | {color:green} the patch passed {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  8m 41s{color} | {color:green} hadoop-common in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  1m 27s{color} | {color:green} hadoop-hdfs-client in the patch passed. {color} |\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}152m 35s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  1m 18s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black}258m 15s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Reason || Tests ||\r\n| Failed junit tests | hadoop.hdfs.TestReadStripedFileWithMissingBlocks |\r\n|   | hadoop.hdfs.server.namenode.ha.TestBootstrapStandby |\r\n|   | hadoop.hdfs.server.datanode.TestDataNodeMultipleRegistrations |\r\n|   | hadoop.hdfs.server.blockmanagement.TestBlockStatsMXBean |\r\n|   | hadoop.hdfs.TestDFSOutputStream |\r\n|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker |  Image:yetus/hadoop:ca8ddc6 |\r\n| JIRA Issue | HDFS-12681 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12893877/HDFS-12681.04.patch |\r\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  xml  |\r\n| uname | Linux 19cf93f5c9e2 3.13.0-129-generic #178-Ubuntu SMP Fri Aug 11 12:48:20 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\r\n| git revision | trunk / d7f3737 |\r\n| maven | version: Apache Maven 3.3.9 |\r\n| Default Java | 1.8.0_131 |\r\n| findbugs | v3.1.0-RC1 |\r\n| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/21812/artifact/patchprocess/diff-checkstyle-root.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/21812/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |\r\n|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/21812/testReport/ |\r\n| modules | C: hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs-client hadoop-hdfs-project/hadoop-hdfs U: . |\r\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/21812/console |\r\n| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2017-10-25T10:15:32.937+0000","updated":"2017-10-25T10:15:32.937+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13110491/comment/16219220","id":"16219220","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"body":"The head of my dev branch wasn't the latest version of the patch; that makes more sense.\r\n\r\nv05 fixes the relevant checkstyle and fixes a unit test that tried to mock {{HdfsFileStatus}} (made final). Should be ready for review.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-10-25T18:15:39.418+0000","updated":"2017-10-25T18:15:39.418+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13110491/comment/16219288","id":"16219288","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"body":"v06 proposes to move the check for {{instanceof LocatedFileStatus}} inside the {{FileSystem}} instance.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-10-25T18:56:48.831+0000","updated":"2017-10-25T18:56:48.831+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13110491/comment/16219657","id":"16219657","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"body":"[~andrew.wang] Would it be possible to run v05 and/or v06 through your internal validation? If an existing client- like MapReduce- distinguishes between the two types, then it's possible this could be an incompatible change. IIRC, at least in the MapReduce case, the client should have requested that the locations be populated, but this is not guaranteed.\r\n\r\nv06 makes a change to HDFS, but 1) it changes the semantics of {{getFileBlockLocations(FileStatus)}} and 2) {{FileSystem}} implementations running MapReduce jobs may make redundant RPC calls without a similar short-circuit.\r\n\r\nFor that reason, I'd rather apply v05. Unless the application applies a highly selective filter, it should be calling {{FileSystem#listLocatedStatus}} (as MapReduce does), anyway.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-10-25T22:20:05.093+0000","updated":"2017-10-25T22:20:05.093+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13110491/comment/16222155","id":"16222155","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"Mockito seems unhappy in {{TestDFSOutputStream}}. \r\n{code}\r\nCannot mock/spy class org.apache.hadoop.hdfs.protocol.HdfsFileStatus\r\nMockito cannot mock/spy following:\r\n  - final classes\r\n  - anonymous classes\r\n  - primitive types\r\n{code}\r\n\r\nAkira is busy with the move to mockito 2.0; maybe that will help. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2017-10-27T10:47:39.697+0000","updated":"2017-10-27T10:47:39.697+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13110491/comment/16222648","id":"16222648","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"body":"bq. Mockito seems unhappy in TestDFSOutputStream.\r\nThat should be fixed in v05/v06, but Jenkins hasn't picked up the patch, yet.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-10-27T16:35:40.441+0000","updated":"2017-10-27T16:35:40.441+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13110491/comment/16222810","id":"16222810","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"body":"Rebase on HDFS-12582","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-10-27T20:54:40.479+0000","updated":"2017-10-27T20:54:40.479+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13110491/comment/16222875","id":"16222875","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"body":"Rebase on HDFS-12582","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-10-27T21:34:34.859+0000","updated":"2017-10-27T21:34:34.859+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13110491/comment/16223212","id":"16223212","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 13s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 3 new or modified test files. {color} |\r\n|| || || || {color:brown} trunk Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  1m 33s{color} | {color:blue} Maven dependency ordering for branch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 12m 58s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 11m 36s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m 52s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  3m  6s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 13m 13s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  5m 34s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m 23s{color} | {color:green} trunk passed {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 15s{color} | {color:blue} Maven dependency ordering for patch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  2m 20s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 11m  5s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 11m  5s{color} | {color:green} the patch passed {color} |\r\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  2m  0s{color} | {color:orange} root: The patch generated 3 new + 542 unchanged - 8 fixed = 545 total (was 550) {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  3m  4s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\r\n| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  1s{color} | {color:green} The patch has no ill-formed XML file. {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green}  7m 58s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  5m 52s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m 33s{color} | {color:green} the patch passed {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}  6m 46s{color} | {color:red} hadoop-common in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  1m 21s{color} | {color:green} hadoop-hdfs-client in the patch passed. {color} |\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 77m 20s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  2m 55s{color} | {color:green} hadoop-mapreduce-client-core in the patch passed. {color} |\r\n| {color:red}-1{color} | {color:red} asflicense {color} | {color:red}  0m 26s{color} | {color:red} The patch generated 3 ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black}173m 41s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Reason || Tests ||\r\n| Failed junit tests | hadoop.fs.shell.TestCopyPreserveFlag |\r\n|   | hadoop.fs.shell.TestCopyFromLocal |\r\n|   | hadoop.hdfs.TestErasureCodingPolicies |\r\n|   | hadoop.hdfs.TestMaintenanceState |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure |\r\n|   | hadoop.hdfs.server.namenode.ha.TestPipelinesFailover |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithRandomECPolicy |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure030 |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailureWithRandomECPolicy |\r\n|   | hadoop.hdfs.TestReplication |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure140 |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStream |\r\n|   | hadoop.hdfs.TestReconstructStripedFile |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure110 |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure130 |\r\n|   | hadoop.hdfs.web.TestWebHdfsTimeouts |\r\n|   | hadoop.hdfs.server.balancer.TestBalancerRPCDelay |\r\n|   | hadoop.hdfs.TestFileChecksum |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:5b98639 |\r\n| JIRA Issue | HDFS-12681 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12894457/HDFS-12681.08.patch |\r\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  xml  |\r\n| uname | Linux c229389f9133 4.4.0-43-generic #63-Ubuntu SMP Wed Oct 12 13:48:03 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | /testptch/patchprocess/precommit/personality/provided.sh |\r\n| git revision | trunk / 8be5707 |\r\n| maven | version: Apache Maven 3.3.9 |\r\n| Default Java | 1.8.0_131 |\r\n| findbugs | v3.1.0-RC1 |\r\n| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/21859/artifact/out/diff-checkstyle-root.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/21859/artifact/out/patch-unit-hadoop-common-project_hadoop-common.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/21859/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |\r\n|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/21859/testReport/ |\r\n| asflicense | https://builds.apache.org/job/PreCommit-HDFS-Build/21859/artifact/out/patch-asflicense-problems.txt |\r\n| modules | C: hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs-client hadoop-hdfs-project/hadoop-hdfs hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core U: . |\r\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/21859/console |\r\n| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2017-10-28T03:58:33.411+0000","updated":"2017-10-28T03:58:33.411+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13110491/comment/16225377","id":"16225377","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"body":"Accidentally picked up a v06 change in v08. This is ready for review, if someone has cycles for it.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-10-30T17:30:11.003+0000","updated":"2017-10-30T17:30:11.003+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13110491/comment/16226084","id":"16226084","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 17s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 3 new or modified test files. {color} |\r\n|| || || || {color:brown} trunk Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 35s{color} | {color:blue} Maven dependency ordering for branch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 35m 44s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 29m 17s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  3m 55s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 10m 13s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 33m 59s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 13m  9s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  4m 30s{color} | {color:green} trunk passed {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 27s{color} | {color:blue} Maven dependency ordering for patch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  4m 57s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 23m 21s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 23m 21s{color} | {color:green} the patch passed {color} |\r\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  2m 52s{color} | {color:orange} root: The patch generated 3 new + 381 unchanged - 8 fixed = 384 total (was 389) {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  4m 19s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\r\n| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  2s{color} | {color:green} The patch has no ill-formed XML file. {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 11m  0s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  8m  4s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  3m  3s{color} | {color:green} the patch passed {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green} 12m 13s{color} | {color:green} hadoop-common in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  1m 47s{color} | {color:green} hadoop-hdfs-client in the patch passed. {color} |\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}154m 59s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |\r\n| {color:red}-1{color} | {color:red} asflicense {color} | {color:red}  0m 57s{color} | {color:red} The patch generated 3 ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black}349m  4s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Reason || Tests ||\r\n| Failed junit tests | hadoop.hdfs.server.datanode.TestDirectoryScanner |\r\n|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration |\r\n|   | hadoop.hdfs.web.TestWebHdfsFileSystemContract |\r\n|   | hadoop.hdfs.server.blockmanagement.TestUnderReplicatedBlocks |\r\n|   | hadoop.hdfs.TestReadStripedFileWithMissingBlocks |\r\n|   | hadoop.hdfs.server.namenode.TestDecommissioningStatus |\r\n|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting |\r\n|   | hadoop.fs.viewfs.TestViewFsHdfs |\r\n|   | hadoop.hdfs.shortcircuit.TestShortCircuitLocalRead |\r\n|   | hadoop.hdfs.server.blockmanagement.TestBlockStatsMXBean |\r\n|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure |\r\n| Timed out junit tests | org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:5b98639 |\r\n| JIRA Issue | HDFS-12681 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12894798/HDFS-12681.09.patch |\r\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  xml  |\r\n| uname | Linux a3c5b37203be 3.13.0-129-generic #178-Ubuntu SMP Fri Aug 11 12:48:20 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | /testptch/patchprocess/precommit/personality/provided.sh |\r\n| git revision | trunk / 9a7e810 |\r\n| maven | version: Apache Maven 3.3.9 |\r\n| Default Java | 1.8.0_131 |\r\n| findbugs | v3.1.0-RC1 |\r\n| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/21881/artifact/out/diff-checkstyle-root.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/21881/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |\r\n|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/21881/testReport/ |\r\n| asflicense | https://builds.apache.org/job/PreCommit-HDFS-Build/21881/artifact/out/patch-asflicense-problems.txt |\r\n| modules | C: hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs-client hadoop-hdfs-project/hadoop-hdfs U: . |\r\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/21881/console |\r\n| Powered by | Apache Yetus 0.7.0-SNAPSHOT   http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2017-10-31T01:13:49.128+0000","updated":"2017-10-31T01:13:49.128+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13110491/comment/16227458","id":"16227458","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"body":"[~andrew.wang] Since the RC for 3.0.0 is planned for this week, either this and HDFS-7878 should be part of the release or neither should be. I think this improves the existing logic, but there is a risk that applications may require changes if they use {{instanceof}} instead of consistently using the {{FileSystem}} methods.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-10-31T20:23:22.698+0000","updated":"2017-10-31T20:23:22.698+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13110491/comment/16227471","id":"16227471","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"body":"Rebase on HDFS-7878","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-10-31T20:31:44.513+0000","updated":"2017-10-31T20:32:13.059+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13110491/comment/16227517","id":"16227517","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=andrew.wang","name":"andrew.wang","key":"andrew.wang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=andrew.wang&avatarId=19230","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=andrew.wang&avatarId=19230","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=andrew.wang&avatarId=19230","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=andrew.wang&avatarId=19230"},"displayName":"Andrew Wang","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks for bringing this up Chris. In the interest of keeping the branch releasable, could we revert for now, possibly retargeting for 3.1.0?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=andrew.wang","name":"andrew.wang","key":"andrew.wang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=andrew.wang&avatarId=19230","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=andrew.wang&avatarId=19230","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=andrew.wang&avatarId=19230","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=andrew.wang&avatarId=19230"},"displayName":"Andrew Wang","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-10-31T20:47:08.694+0000","updated":"2017-10-31T20:47:08.694+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13110491/comment/16227540","id":"16227540","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"body":"bq. In the interest of keeping the branch releasable, could we revert for now, possibly retargeting for 3.1.0?\r\nOK, sure.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-10-31T20:55:57.869+0000","updated":"2017-10-31T20:55:57.869+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13110491/comment/16227805","id":"16227805","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 10m 20s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 3 new or modified test files. {color} |\r\n|| || || || {color:brown} trunk Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  1m 47s{color} | {color:blue} Maven dependency ordering for branch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 16m 25s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 12m 29s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m 57s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  2m 51s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 13m 59s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  5m 12s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m  8s{color} | {color:green} trunk passed {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 19s{color} | {color:blue} Maven dependency ordering for patch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  2m 25s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 10m 55s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 10m 55s{color} | {color:green} the patch passed {color} |\r\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  1m 55s{color} | {color:orange} root: The patch generated 3 new + 381 unchanged - 8 fixed = 384 total (was 389) {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  2m 41s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\r\n| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  1s{color} | {color:green} The patch has no ill-formed XML file. {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green}  9m 34s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  4m 57s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m 18s{color} | {color:green} the patch passed {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  7m 15s{color} | {color:green} hadoop-common in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  1m 23s{color} | {color:green} hadoop-hdfs-client in the patch passed. {color} |\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 80m 44s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 34s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black}189m 53s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Reason || Tests ||\r\n| Failed junit tests | hadoop.hdfs.TestErasureCodingPolicies |\r\n|   | hadoop.hdfs.TestDatanodeDeath |\r\n|   | hadoop.hdfs.TestMaintenanceState |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure |\r\n|   | hadoop.hdfs.TestDecommissionWithStriped |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure030 |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure040 |\r\n|   | hadoop.hdfs.TestDFSShell |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure140 |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure110 |\r\n|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure |\r\n|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting |\r\n|   | hadoop.hdfs.web.TestWebHdfsTimeouts |\r\n|   | hadoop.hdfs.server.balancer.TestBalancerRPCDelay |\r\n|   | hadoop.hdfs.TestFileChecksum |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:5b98639 |\r\n| JIRA Issue | HDFS-12681 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12895064/HDFS-12681.10.patch |\r\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  xml  |\r\n| uname | Linux 47845cd73958 4.4.0-43-generic #63-Ubuntu SMP Wed Oct 12 13:48:03 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | /testptch/patchprocess/precommit/personality/provided.sh |\r\n| git revision | trunk / ed24da3 |\r\n| maven | version: Apache Maven 3.3.9 |\r\n| Default Java | 1.8.0_131 |\r\n| findbugs | v3.1.0-RC1 |\r\n| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/21907/artifact/out/diff-checkstyle-root.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/21907/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |\r\n|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/21907/testReport/ |\r\n| modules | C: hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs-client hadoop-hdfs-project/hadoop-hdfs U: . |\r\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/21907/console |\r\n| Powered by | Apache Yetus 0.7.0-SNAPSHOT   http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2017-11-01T00:02:27.954+0000","updated":"2017-11-01T00:02:27.954+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13110491/comment/16234304","id":"16234304","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"body":"Test failures are unrelated to the patch; all are due to resource exhaustion. Checkstyle errors are from the builder pattern.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-11-01T16:12:48.008+0000","updated":"2017-11-01T16:12:48.008+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13110491/comment/16236591","id":"16236591","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=elgoiri","name":"elgoiri","key":"elgoiri","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Íñigo Goiri","active":true,"timeZone":"Etc/UTC"},"body":"The \"hides a field\" checkstyle can easily fixed calling the paramters {{locs}}.\r\nIn general, I think is a good idea to remove {{HdfsLocatedFileStatus}} and add the {{setBlockLocations()}} by default.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=elgoiri","name":"elgoiri","key":"elgoiri","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Íñigo Goiri","active":true,"timeZone":"Etc/UTC"},"created":"2017-11-02T20:57:55.235+0000","updated":"2017-11-02T20:57:55.235+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13110491/comment/16236824","id":"16236824","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"body":"bq. The \"hides a field\" checkstyle can easily fixed calling the paramters locs.\r\nYeah, though this would change the pattern from the rest of the builder. IMHO findbugs is wrong, but it's not a hill I'd choose to die on if you insist.\r\n\r\nbq. In general, I think is a good idea to remove HdfsLocatedFileStatus and add the setBlockLocations() by default\r\nIt's possible the change in type could confuse downstream applications, but most callers should already be distinguishing the types.\r\n\r\nI'd like to get this in early in 3.1, so it has time to bake.\r\n\r\n/cc [~bharatviswa]","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-11-02T23:35:59.536+0000","updated":"2017-11-02T23:35:59.536+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13110491/comment/16236909","id":"16236909","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=elgoiri","name":"elgoiri","key":"elgoiri","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Íñigo Goiri","active":true,"timeZone":"Etc/UTC"},"body":"+1\r\nMy CDO would be happier with the checkstyles showing a +1 checkstyle issues instead of a +3 though.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=elgoiri","name":"elgoiri","key":"elgoiri","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Íñigo Goiri","active":true,"timeZone":"Etc/UTC"},"created":"2017-11-03T01:00:10.167+0000","updated":"2017-11-03T01:00:10.167+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13110491/comment/16238545","id":"16238545","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"body":"I committed this. Thanks for the review [~elgoiri] and [~stevel@apache.org].","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-11-03T23:03:40.413+0000","updated":"2017-11-03T23:03:40.413+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13110491/comment/16238688","id":"16238688","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"SUCCESS: Integrated in Jenkins build Hadoop-trunk-Commit #13188 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/13188/])\nHDFS-12681. Fold HdfsLocatedFileStatus into HdfsFileStatus. (cdouglas: rev b85603e3f85e85da406241b991f3a9974384c3aa)\n* (edit) hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/LocatedFileStatus.java\n* (edit) hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/mover/TestStorageMover.java\n* (edit) hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java\n* (edit) hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java\n* (edit) hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestBlockStoragePolicy.java\n* (edit) hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSOutputStream.java\n* (edit) hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocol/HdfsFileStatus.java\n* (edit) hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/fs/Hdfs.java\n* (edit) hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirStatAndListingOp.java\n* (edit) hadoop-hdfs-project/hadoop-hdfs/dev-support/findbugsExcludeFile.xml\n* (edit) hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/mover/Mover.java\n* (delete) hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocol/HdfsLocatedFileStatus.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2017-11-04T01:34:34.041+0000","updated":"2017-11-04T01:34:34.041+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13110491/comment/16253018","id":"16253018","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bharatviswa","name":"bharatviswa","key":"bharatviswa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Bharat Viswanadham","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi [~chris.douglas]\r\nIn FileInputFormat.java we have\r\nif (file instanceof LocatedFileStatus) {\r\n          blkLocations = ((LocatedFileStatus) file).getBlockLocations();\r\n        } else {\r\n          blkLocations = fs.getFileBlockLocations(file, 0, length);\r\n        }\r\n\r\nSo now with this change the blockLocations can be null right?\r\nDo we need to avoid instance of LocatedFileStatus here and directly call fs.getFileBlockLocations(file, 0, length) ?\r\n\r\nI am trying to understand why this is returning null, could you explain why this change caused this blockLocations to be returned null, as I was not clear with that part?\r\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bharatviswa","name":"bharatviswa","key":"bharatviswa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Bharat Viswanadham","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-11-15T06:30:20.368+0000","updated":"2017-11-15T06:30:20.368+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13110491/comment/16253029","id":"16253029","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"body":"bq. I am trying to understand why this is returning null, could you explain why this change caused this blockLocations to be returned null, as I was not clear with that part?\r\nAre you observing this returning null? Or are you asking if it might?\r\n\r\nAfter this change, if an application requests a mix of {{FileStatus}} and {{LocatedFileStatus}} instances, then it can't distinguish whether it needs an RPC to fetch locations based on their type (as in the example you cite). v05 (IIRC) of the patch is an alternative [discussed|https://issues.apache.org/jira/browse/HDFS-12681?focusedCommentId=16219657&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-16219657] earlier.\r\n\r\nIn the cases we found (though this wasn't exhaustive), clients that used locations requested the locations in the first request (receiving {{LocatedFileStatus}}), not using 2 RPCs.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-11-15T06:43:50.974+0000","updated":"2017-11-15T06:43:50.974+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13110491/comment/16253920","id":"16253920","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bharatviswa","name":"bharatviswa","key":"bharatviswa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Bharat Viswanadham","active":true,"timeZone":"America/Los_Angeles"},"body":"[~chris.douglas]\r\nThank You for info.\r\nYes, we have observed it being returning null.\r\n\r\n\r\n{noformat}\r\nIn the cases we found (though this wasn't exhaustive), clients that used locations requested the locations in the first request (receiving LocatedFileStatus), not using 2 RPCs.\r\n\r\n{noformat}\r\n\r\nSo, I need to call this makeQualifiedLocated\r\n\r\n((LocatedFileStatus) file).makeQualifiedLocated(URI defaultUri,path) and then call\r\n ((LocatedFileStatus) file).getBlockLocations(); \r\n\r\nAnd now need to remove the code of using\r\n{noformat}\r\n (file instanceof LocatedFileStatus)\r\n{noformat}\r\nas now it can't distiniguish whether it needs an RPC call, so we need to directly call fs.getFileBlockLocations or the above 2 step one?\r\n\r\n{code:java}\r\nAs from code comments, it is mentioned \r\n/**\r\n   * This function is used to transform the underlying HDFS LocatedBlocks to\r\n   * BlockLocations. This method must be invoked before\r\n   * {@link #getBlockLocations()}.\r\n**/\r\n{code}\r\n\r\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bharatviswa","name":"bharatviswa","key":"bharatviswa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Bharat Viswanadham","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-11-15T18:33:12.963+0000","updated":"2017-11-15T18:53:14.646+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13110491/comment/16253955","id":"16253955","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"body":"bq. now it can't distiniguish whether it needs an RPC call, so we need to directly call fs.getFileBlockLocations?\r\nv06 of the patch (not v05, sorry mixed them up) would not make an RPC if the {{FileStatus}} included locations:\r\n{noformat}\r\ndiff --git hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java\r\nindex a8a5cfa..617cbf4 100644\r\n--- hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java\r\n+++ hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java\r\n@@ -237,6 +236,12 @@ String getPathName(Path file) {\r\n     if (file == null) {\r\n       return null;\r\n     }\r\n+    if (file instanceof LocatedFileStatus) {\r\n+      BlockLocation[] loc = ((LocatedFileStatus)file).getBlockLocations();\r\n+      if (loc != null) {\r\n+        return loc;\r\n+      }\r\n+    }\r\n     return getFileBlockLocations(file.getPath(), start, len);\r\n   }\r\n {noformat}\r\n\r\nThis changes the semantics for HDFS (i.e., it won't refresh locations) and the change to MapReduce:\r\n{noformat}\r\ndiff --git hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/FileInputFormat.java hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/FileInputFormat.java\r\nindex 3e0ea25..0f0a45b 100644\r\n--- hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/FileInputFormat.java\r\n+++ hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/FileInputFormat.java\r\n@@ -344,11 +344,7 @@ protected FileSplit makeSplit(Path file, long start, long length,\r\n       if (length != 0) {\r\n         FileSystem fs = path.getFileSystem(job);\r\n         BlockLocation[] blkLocations;\r\n-        if (file instanceof LocatedFileStatus) {\r\n-          blkLocations = ((LocatedFileStatus) file).getBlockLocations();\r\n-        } else {\r\n-          blkLocations = fs.getFileBlockLocations(file, 0, length);\r\n-        }\r\n+        blkLocations = fs.getFileBlockLocations(file, 0, length);\r\n{noformat}\r\n\r\nWould have added additional RPC traffic for non-HDFS {{FileSystem}} implementations that rely on the type to determine if they need locations.\r\n\r\n{{makeQualified\\[Located\\]}} are internal methods that allow HDFS to lazily bind {{FileStatus}} fields (improving space efficiency and avoiding some conversions). Clients shouldn't need to call them.\r\n\r\nWe _hope_ that clients would request locations in the first RPC call, rather than asking for a {{FileStatus}} and then requesting its block locations.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-11-15T19:00:56.819+0000","updated":"2017-11-15T19:00:56.819+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13110491/comment/16254316","id":"16254316","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=arpitagarwal","name":"arpitagarwal","key":"arpitagarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arpit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"body":"This change may have broken some MapReduce unit tests. e.g. TestDelegatingInputFormat#testSplitting\r\n{code}\r\nTests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 4.521 sec <<< FAILURE! - in org.apache.hadoop.mapreduce.lib.input.TestDelegatingInputFormat\r\ntestSplitting(org.apache.hadoop.mapreduce.lib.input.TestDelegatingInputFormat)  Time elapsed: 4.454 sec  <<< ERROR!\r\njava.lang.NullPointerException: null\r\n\tat org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getBlockIndex(FileInputFormat.java:458)\r\n\tat org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:412)\r\n\tat org.apache.hadoop.mapreduce.lib.input.DelegatingInputFormat.getSplits(DelegatingInputFormat.java:115)\r\n\tat org.apache.hadoop.mapreduce.lib.input.TestDelegatingInputFormat.testSplitting(TestDelegatingInputFormat.java:67)\r\n{code}\r\n\r\nI am not sure why the breakage occurs. FileInputFormat should not be getting hold of a LocatedFileStatus object with null locations.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=arpitagarwal","name":"arpitagarwal","key":"arpitagarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arpit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-11-15T22:14:56.636+0000","updated":"2017-11-15T22:14:56.636+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13110491/comment/16254332","id":"16254332","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=djp","name":"djp","key":"djp","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=djp&avatarId=16954","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=djp&avatarId=16954","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=djp&avatarId=16954","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=djp&avatarId=16954"},"displayName":"Junping Du","active":true,"timeZone":"Asia/Shanghai"},"body":"bq. We hope that clients would request locations in the first RPC call, rather than asking for a FileStatus and then requesting its block locations.\r\nI am not sure if this assumption works for other places, but at least our MR jobs get broken here with NPE. Do we have a quick solution to fix this problem? Otherwise, we may need to consider to revert this (and may be HDFS-7878).\r\n\r\nI also notice this belongs to incompatible change - any reason that not get in 3.0 but instead go to 3.1 besides the time window of 3.0 release?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=djp","name":"djp","key":"djp","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=djp&avatarId=16954","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=djp&avatarId=16954","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=djp&avatarId=16954","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=djp&avatarId=16954"},"displayName":"Junping Du","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-11-15T22:21:44.222+0000","updated":"2017-11-15T22:21:44.222+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13110491/comment/16254357","id":"16254357","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"body":"bq. I am not sure if this assumption works for other places, but at least our MR jobs get broken here with NPE.\r\nThis seemed preferable to returning empty locations, which will be harder to debug. One of the reasons I wanted to get this in early was to check for compatibility downstream.\r\n\r\nbq. Do we have a quick solution to fix this problem? Otherwise, we may need to consider to revert this (and may be HDFS-7878).\r\nPlease don't. I've had to chase reviewers for over a _year_ to get any changes into {{FileSystem}}. This compromise incorporates others' preferences and concerns after months of negotiation.\r\n\r\nbq. I also notice this belongs to incompatible change - any reason that not get in 3.0 but instead go to 3.1 besides the time window of 3.0 release?\r\nNo.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-11-15T22:33:49.906+0000","updated":"2017-11-15T22:33:49.906+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13110491/comment/16254685","id":"16254685","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"body":"Reopening to revert this, and try another approach","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-11-16T03:16:43.199+0000","updated":"2017-11-16T03:16:43.199+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13110491/comment/16254704","id":"16254704","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"SUCCESS: Integrated in Jenkins build Hadoop-trunk-Commit #13242 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/13242/])\nRevert \"HDFS-12681. Fold HdfsLocatedFileStatus into HdfsFileStatus.\" (cdouglas: rev 675e9a8f57570771a0219d95940681b067d36b94)\n* (edit) hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSOutputStream.java\n* (edit) hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/LocatedFileStatus.java\n* (edit) hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java\n* (edit) hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java\n* (edit) hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocol/HdfsFileStatus.java\n* (edit) hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirStatAndListingOp.java\n* (edit) hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/fs/Hdfs.java\n* (edit) hadoop-hdfs-project/hadoop-hdfs/dev-support/findbugsExcludeFile.xml\n* (edit) hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestBlockStoragePolicy.java\n* (add) hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocol/HdfsLocatedFileStatus.java\n* (edit) hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/mover/TestStorageMover.java\n* (edit) hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/mover/Mover.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2017-11-16T03:41:28.469+0000","updated":"2017-11-16T03:41:28.469+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13110491/comment/16254724","id":"16254724","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"body":"Attaching WIP patch.\r\n\r\nThis restores the types, but it also preserves a common {{HdfsFileStatus}} API (to avoid changing internal references excessively, and making the patch un-reviewable). It is now an interface that is a superset of {{FileStatus}} (will add a unit test for this).\r\n\r\nIn v11, {{HdfsNamedFileStatus}} is a subtype of {{FileStatus}} while {{HdfsLocatedFileStatus}} is a subtype of {{LocatedFileStatus}}. Anything user-facing already copied a subset of fields from these types, so their previous relationship to one another is irrelevant to compatibility (i.e., the fact that {{HdfsLocatedFileStatus}} is no longer a subtype of {{HdfsFileStatus}} doesn't matter to user code).\r\n\r\nWhile v10 imposed some changes since the types were not distinct, this only resolves a naming collision, creating {{getBlockLocations}} and {{getLocatedBlocks}}. It should not be an incompatible change.\r\n\r\nThere are two other ways this could be solved.\r\n\r\n# Lazily populate block locations by keeping a reference to the {{FileSystem}}. This could not only interfere with GC, but untangling how that would work with the {{FileSystem}} cache seems like an unnecessary exercise.\r\n# For HDFS-7878, if {{FileStatus}} (and not {{PathHandle}}) was the token, then the conversion to the user-facing type could preserve metadata in the opaque blob. This JIRA is required because {{LocatedFileStatus}} contains only the fields of the base class.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-11-16T04:14:48.664+0000","updated":"2017-11-16T04:14:48.664+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13110491/comment/16254882","id":"16254882","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 16s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 4 new or modified test files. {color} |\r\n|| || || || {color:brown} trunk Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 16s{color} | {color:blue} Maven dependency ordering for branch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 16m  4s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 12m 27s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m 57s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  2m 44s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 14m 28s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  4m 44s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m 10s{color} | {color:green} trunk passed {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 14s{color} | {color:blue} Maven dependency ordering for patch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  2m 15s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 11m 27s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 11m 27s{color} | {color:green} the patch passed {color} |\r\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  1m 56s{color} | {color:orange} root: The patch generated 7 new + 342 unchanged - 6 fixed = 349 total (was 348) {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  2m 42s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\r\n| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  1s{color} | {color:green} The patch has no ill-formed XML file. {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green}  9m 16s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |\r\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  1m 39s{color} | {color:red} hadoop-hdfs-project/hadoop-hdfs-client generated 4 new + 0 unchanged - 0 fixed = 4 total (was 0) {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m  7s{color} | {color:green} the patch passed {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  8m 27s{color} | {color:green} hadoop-common in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  1m 18s{color} | {color:green} hadoop-hdfs-client in the patch passed. {color} |\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}107m 12s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 30s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black}205m 10s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Reason || Tests ||\r\n| FindBugs | module:hadoop-hdfs-project/hadoop-hdfs-client |\r\n|  |  org.apache.hadoop.hdfs.protocol.HdfsLocatedFileStatus.getLocalNameInBytes() may expose internal representation by returning HdfsLocatedFileStatus.uPath  At HdfsLocatedFileStatus.java:by returning HdfsLocatedFileStatus.uPath  At HdfsLocatedFileStatus.java:[line 136] |\r\n|  |  org.apache.hadoop.hdfs.protocol.HdfsLocatedFileStatus.getSymlinkInBytes() may expose internal representation by returning HdfsLocatedFileStatus.uSymlink  At HdfsLocatedFileStatus.java:by returning HdfsLocatedFileStatus.uSymlink  At HdfsLocatedFileStatus.java:[line 148] |\r\n|  |  org.apache.hadoop.hdfs.protocol.HdfsNamedFileStatus.getLocalNameInBytes() may expose internal representation by returning HdfsNamedFileStatus.uPath  At HdfsNamedFileStatus.java:by returning HdfsNamedFileStatus.uPath  At HdfsNamedFileStatus.java:[line 126] |\r\n|  |  org.apache.hadoop.hdfs.protocol.HdfsNamedFileStatus.getSymlinkInBytes() may expose internal representation by returning HdfsNamedFileStatus.uSymlink  At HdfsNamedFileStatus.java:by returning HdfsNamedFileStatus.uSymlink  At HdfsNamedFileStatus.java:[line 138] |\r\n| Failed junit tests | hadoop.fs.contract.hdfs.TestHDFSContractRootDirectory |\r\n|   | hadoop.hdfs.server.namenode.TestCheckpoint |\r\n|   | hadoop.security.TestPermissionSymlinks |\r\n|   | hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA |\r\n|   | hadoop.hdfs.server.namenode.TestINodeFile |\r\n|   | hadoop.hdfs.server.namenode.TestFsck |\r\n|   | hadoop.hdfs.TestListFilesInFileContext |\r\n|   | hadoop.hdfs.server.namenode.TestFSImage |\r\n|   | hadoop.hdfs.server.namenode.TestReencryptionWithKMS |\r\n|   | hadoop.hdfs.TestDistributedFileSystem |\r\n|   | hadoop.fs.viewfs.TestViewFsHdfs |\r\n|   | hadoop.fs.viewfs.TestViewFileSystemAtHdfsRoot |\r\n|   | hadoop.fs.TestSymlinkHdfsFileContext |\r\n|   | hadoop.fs.TestSymlinkHdfsFileSystem |\r\n|   | hadoop.fs.TestUnbuffer |\r\n|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting |\r\n|   | hadoop.fs.contract.hdfs.TestHDFSContractGetFileStatus |\r\n|   | hadoop.fs.viewfs.TestViewFileSystemHdfs |\r\n|   | hadoop.fs.viewfs.TestViewFileSystemLinkMergeSlash |\r\n|   | hadoop.hdfs.server.datanode.fsdataset.impl.TestLazyPersistReplicaRecovery |\r\n|   | hadoop.fs.viewfs.TestViewFsAtHdfsRoot |\r\n|   | hadoop.hdfs.TestListFilesInDFS |\r\n|   | hadoop.fs.viewfs.TestViewFileSystemLinkFallback |\r\n|   | hadoop.hdfs.TestClientProtocolForPipelineRecovery |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:5b98639 |\r\n| JIRA Issue | HDFS-12681 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12897916/HDFS-12681.11.patch |\r\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  xml  |\r\n| uname | Linux 5e59a1777b97 3.13.0-135-generic #184-Ubuntu SMP Wed Oct 18 11:55:51 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | /testptch/patchprocess/precommit/personality/provided.sh |\r\n| git revision | trunk / 675e9a8 |\r\n| maven | version: Apache Maven 3.3.9 |\r\n| Default Java | 1.8.0_151 |\r\n| findbugs | v3.1.0-RC1 |\r\n| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/22108/artifact/out/diff-checkstyle-root.txt |\r\n| findbugs | https://builds.apache.org/job/PreCommit-HDFS-Build/22108/artifact/out/new-findbugs-hadoop-hdfs-project_hadoop-hdfs-client.html |\r\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/22108/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |\r\n|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/22108/testReport/ |\r\n| Max. process+thread count | 3260 (vs. ulimit of 5000) |\r\n| modules | C: hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs-client hadoop-hdfs-project/hadoop-hdfs U: . |\r\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/22108/console |\r\n| Powered by | Apache Yetus 0.7.0-SNAPSHOT   http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2017-11-16T07:46:04.647+0000","updated":"2017-11-16T07:46:04.647+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13110491/comment/16255944","id":"16255944","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"body":"Revised patch. This should fix the unit test failures. Also added a unit test to ensure {{HdfsFileStatus}} remains a superset of {{FileStatus}}.\r\n\r\nThis modifies the approach taken by HDFS-12455 by removing the {{setSnapShotEnabledFlag}} method and exposing {{AttrFlags}}. Frankly, I'm not convinced that exposing all these attribute flags in {{FileStatus}}, when most are only meaningful to HDFS, is valuable. The point is moot since we've already released it, but I hope we can eventually curtail the practice.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-11-16T20:47:45.755+0000","updated":"2017-11-16T20:47:45.755+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13110491/comment/16256271","id":"16256271","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 26s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 4 new or modified test files. {color} |\r\n|| || || || {color:brown} trunk Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 24s{color} | {color:blue} Maven dependency ordering for branch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 21m 55s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 18m 52s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m  5s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  3m 32s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 16m 11s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  5m 51s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m 46s{color} | {color:green} trunk passed {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 16s{color} | {color:blue} Maven dependency ordering for patch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  2m 54s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 13m 18s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 13m 18s{color} | {color:green} the patch passed {color} |\r\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  2m  8s{color} | {color:orange} root: The patch generated 19 new + 410 unchanged - 6 fixed = 429 total (was 416) {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  3m 56s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\r\n| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  1s{color} | {color:green} The patch has no ill-formed XML file. {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 14m  1s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |\r\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  3m 25s{color} | {color:red} hadoop-hdfs-project/hadoop-hdfs-client generated 4 new + 0 unchanged - 0 fixed = 4 total (was 0) {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  5m 25s{color} | {color:green} the patch passed {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 14m 24s{color} | {color:red} hadoop-common in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  2m 42s{color} | {color:green} hadoop-hdfs-client in the patch passed. {color} |\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}127m 21s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}  0m 51s{color} | {color:red} hadoop-hdfs-httpfs in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 43s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black}270m 41s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Reason || Tests ||\r\n| FindBugs | module:hadoop-hdfs-project/hadoop-hdfs-client |\r\n|  |  org.apache.hadoop.hdfs.protocol.HdfsLocatedFileStatus.getLocalNameInBytes() may expose internal representation by returning HdfsLocatedFileStatus.uPath  At HdfsLocatedFileStatus.java:by returning HdfsLocatedFileStatus.uPath  At HdfsLocatedFileStatus.java:[line 133] |\r\n|  |  org.apache.hadoop.hdfs.protocol.HdfsLocatedFileStatus.getSymlinkInBytes() may expose internal representation by returning HdfsLocatedFileStatus.uSymlink  At HdfsLocatedFileStatus.java:by returning HdfsLocatedFileStatus.uSymlink  At HdfsLocatedFileStatus.java:[line 146] |\r\n|  |  org.apache.hadoop.hdfs.protocol.HdfsNamedFileStatus.getLocalNameInBytes() may expose internal representation by returning HdfsNamedFileStatus.uPath  At HdfsNamedFileStatus.java:by returning HdfsNamedFileStatus.uPath  At HdfsNamedFileStatus.java:[line 121] |\r\n|  |  org.apache.hadoop.hdfs.protocol.HdfsNamedFileStatus.getSymlinkInBytes() may expose internal representation by returning HdfsNamedFileStatus.uSymlink  At HdfsNamedFileStatus.java:by returning HdfsNamedFileStatus.uSymlink  At HdfsNamedFileStatus.java:[line 134] |\r\n| Unreaped Processes | hadoop-hdfs:4 |\r\n| Failed junit tests | hadoop.security.TestShellBasedUnixGroupsMapping |\r\n|   | hadoop.ipc.TestCallQueueManager |\r\n|   | hadoop.hdfs.TestReadStripedFileWithMissingBlocks |\r\n|   | hadoop.security.TestPermissionSymlinks |\r\n|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure |\r\n|   | hadoop.metrics2.sink.TestRollingFileSystemSinkWithSecureHdfs |\r\n|   | hadoop.fs.TestUnbuffer |\r\n|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting |\r\n|   | hadoop.metrics2.sink.TestRollingFileSystemSinkWithHdfs |\r\n|   | hadoop.security.TestRefreshUserMappings |\r\n|   | hadoop.security.TestPermission |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:5b98639 |\r\n| JIRA Issue | HDFS-12681 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12898054/HDFS-12681.12.patch |\r\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  xml  |\r\n| uname | Linux d99730eb2cd4 3.13.0-135-generic #184-Ubuntu SMP Wed Oct 18 11:55:51 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | /testptch/patchprocess/precommit/personality/provided.sh |\r\n| git revision | trunk / 0987a7b |\r\n| maven | version: Apache Maven 3.3.9 |\r\n| Default Java | 1.8.0_151 |\r\n| findbugs | v3.1.0-RC1 |\r\n| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/22120/artifact/out/diff-checkstyle-root.txt |\r\n| findbugs | https://builds.apache.org/job/PreCommit-HDFS-Build/22120/artifact/out/new-findbugs-hadoop-hdfs-project_hadoop-hdfs-client.html |\r\n| Unreaped Processes Log | https://builds.apache.org/job/PreCommit-HDFS-Build/22120/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs-reaper.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/22120/artifact/out/patch-unit-hadoop-common-project_hadoop-common.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/22120/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/22120/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs-httpfs.txt |\r\n|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/22120/testReport/ |\r\n| Max. process+thread count | 3676 (vs. ulimit of 5000) |\r\n| modules | C: hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs-client hadoop-hdfs-project/hadoop-hdfs hadoop-hdfs-project/hadoop-hdfs-httpfs U: . |\r\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/22120/console |\r\n| Powered by | Apache Yetus 0.7.0-SNAPSHOT   http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2017-11-17T01:21:52.620+0000","updated":"2017-11-17T01:21:52.620+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13110491/comment/16260322","id":"16260322","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"body":"Failing tests are due to resource exhaustion.\r\n\r\nUpdated patch to fix some checkstyle, put the findbugs suppression in the correct file.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-11-21T06:39:19.841+0000","updated":"2017-11-21T06:39:19.841+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13110491/comment/16260492","id":"16260492","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 12s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 4 new or modified test files. {color} |\r\n|| || || || {color:brown} trunk Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  1m 29s{color} | {color:blue} Maven dependency ordering for branch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 15m 58s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 12m 31s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m  6s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  3m 27s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 15m 51s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  5m 30s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m 40s{color} | {color:green} trunk passed {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 14s{color} | {color:blue} Maven dependency ordering for patch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  2m 38s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 11m 17s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 11m 17s{color} | {color:green} the patch passed {color} |\r\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  2m  6s{color} | {color:orange} root: The patch generated 12 new + 409 unchanged - 6 fixed = 421 total (was 415) {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  3m 24s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\r\n| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  2s{color} | {color:green} The patch has no ill-formed XML file. {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green}  9m 51s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  5m 56s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m 43s{color} | {color:green} the patch passed {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  8m 42s{color} | {color:green} hadoop-common in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  1m 30s{color} | {color:green} hadoop-hdfs-client in the patch passed. {color} |\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 82m 49s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  3m 47s{color} | {color:green} hadoop-hdfs-httpfs in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 34s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black}192m 21s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Reason || Tests ||\r\n| Failed junit tests | hadoop.fs.TestUnbuffer |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:5b98639 |\r\n| JIRA Issue | HDFS-12681 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12898617/HDFS-12681.13.patch |\r\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  xml  |\r\n| uname | Linux d0942e294c14 3.13.0-135-generic #184-Ubuntu SMP Wed Oct 18 11:55:51 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | /testptch/patchprocess/precommit/personality/provided.sh |\r\n| git revision | trunk / 659e85e |\r\n| maven | version: Apache Maven 3.3.9 |\r\n| Default Java | 1.8.0_151 |\r\n| findbugs | v3.1.0-RC1 |\r\n| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/22150/artifact/out/diff-checkstyle-root.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/22150/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |\r\n|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/22150/testReport/ |\r\n| Max. process+thread count | 4363 (vs. ulimit of 5000) |\r\n| modules | C: hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs-client hadoop-hdfs-project/hadoop-hdfs hadoop-hdfs-project/hadoop-hdfs-httpfs U: . |\r\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/22150/console |\r\n| Powered by | Apache Yetus 0.7.0-SNAPSHOT   http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2017-11-21T09:53:15.409+0000","updated":"2017-11-21T09:53:15.409+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13110491/comment/16261178","id":"16261178","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"body":"{{TestUnbuffer}} fails on trunk (HADOOP-15056, HADOOP-12815). The checkstyle errors are also inherited from trunk.\r\n\r\nAll the {{hadoop-mapreduce-client-core}} tests pass.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-11-21T18:02:49.022+0000","updated":"2017-11-21T18:10:25.730+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13110491/comment/16261414","id":"16261414","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"body":"Ran most of the MapReduce tests. Looks good.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-11-21T20:03:14.324+0000","updated":"2017-11-21T20:03:14.324+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13110491/comment/16261724","id":"16261724","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"body":"This is ready for review. To page in some context, the purpose of this JIRA is to allow HDFS to return a user-visible type that does not discard its metadata payload. This is a necessary followup to HDFS-7878, which allows a {{FileSystem}} to create a serializable {{PathHandle}} to an entity. HDFS-7878 built on HDFS-6984, which changed {{FileStatus}} serialization to use protocol buffers instead of {{Writable}} APIs, anticipating a {{PathHandle}} payload returned from the NameNode.\r\n\r\nHDFS-6984 effected the following change:\r\n{noformat}\r\nBefore:                                            After:\r\n                                                         FileStatus\r\n      FileStatus    <(COPY)     HdfsFileStatus               |     \\\r\n          |                          |                       |      HdfsFileStatus\r\n  LocatedFileStatus <(COPY) HdfsLocatedFileStatus            |                    \\\r\n                                                     LocatedFileStatus <(COPY) HdfsLocatedFileStatus\r\n{noformat}\r\nBefore HDFS-6984, the client would obtain an {{HdfsFileStatus}}, then copy a subset of its fields to a vanilla {{FileStatus}} instance. A comparable operation was used for {{LocatedFileStatus}}.\r\n\r\nSince HDFS-7878 wanted to use the open-by-inode API and the inode was stored in a {{fileId}} field on {{HdfsFileStatus}}, the copy lost information necessary to create the handle. HDFS-6984 set up HDFS-7878 to receive and propagate any {{FileSystem}} metadata to support an {{open(FileStatus)}} call.\r\n\r\nInstead, consensus in HDFS-7878 settled on an {{open(PathHandle)}} API. As a consequence, {{FileStatus}} and its subclass {{LocatedFileStatus}} did not have a generic way to store a {{PathHandle}}. This was fine for {{HdfsFileStatus}}, since it is a subtype of {{FileStatus}}. However, to create a {{LocatedFileStatus}}, HDFS-6984 would copy (and lose) this metadata.\r\n\r\nThe first solution committed (v10) attempted to resolve this by collapsing {{HdfsFileStatus}} and {{LocatedFileStatus}} into a single class:\r\n{noformat}\r\n      FileStatus\r\n          |\r\n  LocatedFileStatus\r\n          |\r\n   HdfsFileStatus(+HdfsLocatedFileStatus)\r\n{noformat}\r\nIf clients did not rely on the type to distinguish whether they need to call {{FileSystem::getFileBlockLocations}}, and instead made the (more efficient) single-RPC call that returned {{LocatedFileStatus}}, this is fine. Unfortunately, as demonstrated, clients use the 2-RPC variant too often for this approach to be viable.\r\n\r\nConsequently, v13 proposes the following refactoring:\r\n{noformat}\r\n      FileStatus                 HdfsFileStatus\r\n          |     \\                   /   /\r\n          |      HdfsNamedFileStatus   /\r\n  LocatedFileStatus                   /\r\n               \\                     /\r\n                HdfsLocatedFileStatus\r\n{noformat}\r\n{{HdfsFileStatus}} is an interface and its functionality is split across two concrete types.\r\n\r\nClients can distinguish between the two instances by type, unlike in v10. This also supports the {{FileSystem}} carrying metadata in its own type, so it is sufficient to implement HDFS-7878. The fact that {{HdfsLocatedFileStatus}} is not a subtype of {{HdfsNamedFileStatus}} should be irrelevant to user code, since neither is user-facing and a client can still pass a mix of {{FileStatus}} objects as required. This should be backwards-compatible.\r\n\r\nPulling methods into an {{HdfsFileStatus}} interface minimizes changes to HDFS. It is necessary because {{FileStatus}} is a user-facing, concrete class. Extracting an interface from {{FileStatus}} would have limited applicability, so this adds a unit test that verifies that {{HdfsFileStatus}} remains a superset. Alternatively, one could add a new interface implemented by {{FileStatus}} and extended by HdfsFileStatus. This is slightly \"cleaner\", but the unit test is still necessary because user code only uses {{FileStatus}}.\r\n\r\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-11-22T00:10:47.928+0000","updated":"2017-11-22T00:10:47.928+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13110491/comment/16261891","id":"16261891","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=elgoiri","name":"elgoiri","key":"elgoiri","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Íñigo Goiri","active":true,"timeZone":"Etc/UTC"},"body":"Should we file JIRAs to remove the 2-RPC variant and use the efficient approach?\r\nI would still do this change.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=elgoiri","name":"elgoiri","key":"elgoiri","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Íñigo Goiri","active":true,"timeZone":"Etc/UTC"},"created":"2017-11-22T02:51:21.983+0000","updated":"2017-11-22T02:51:21.983+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13110491/comment/16261948","id":"16261948","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"body":"bq. Should we file JIRAs to remove the 2-RPC variant and use the efficient approach?\r\nWe could deprecate it and advise users to ask for locations upfront, but I doubt we could remove it. It's been part of the API for too long.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-11-22T04:04:03.969+0000","updated":"2017-11-22T04:04:03.969+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13110491/comment/16262341","id":"16262341","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"It's nice to see the builder pattern here. I've been doing some stuff with subclasses of FileStatus recently and it's not great for subclassing.\r\n\r\n\r\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2017-11-22T11:26:34.062+0000","updated":"2017-11-22T11:26:34.062+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13110491/comment/16262929","id":"16262929","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"body":"bq. I've been doing some stuff with subclasses of FileStatus recently and it's not great for subclassing.\r\nYes, \"not great\" is a succinct way to put it. I tend to use more profanity.\r\n\r\nWhile a little unusual, the above seemed like the least-convoluted way to support all the constraints on the design without bleeding changes throughout HDFS. Again, we could extract an interface from {{FileStatus}}, but the type system wouldn't be verifying anything relevant.\r\n\r\n[~stevel@apache.org]/[~bharatviswa]/[~arpiagariu]/[~djp]/[~elgoiri], do you have cycles to review the patch? This is necessary for HDFS-9806, which we'd like to merge in the next couple weeks.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-11-22T17:12:11.681+0000","updated":"2017-11-22T17:12:11.681+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13110491/comment/16267230","id":"16267230","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=elgoiri","name":"elgoiri","key":"elgoiri","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Íñigo Goiri","active":true,"timeZone":"Etc/UTC"},"body":"bq. We could deprecate it and advise users to ask for locations upfront, but I doubt we could remove it. It's been part of the API for too long.\r\n\r\nI would be OK marking that as deprecated. However, I was talking about the unit tests that failed with this change. I would file a JIRA to change those to use the 1-RPC call approach (even though, we need to keep some basic unit tests that makes sure that the 2-RPC approach works).","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=elgoiri","name":"elgoiri","key":"elgoiri","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Íñigo Goiri","active":true,"timeZone":"Etc/UTC"},"created":"2017-11-27T18:46:14.089+0000","updated":"2017-11-27T18:46:14.089+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13110491/comment/16269250","id":"16269250","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=elgoiri","name":"elgoiri","key":"elgoiri","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Íñigo Goiri","active":true,"timeZone":"Etc/UTC"},"body":"Most of [^HDFS-12681.13.patch] is cleaning up the {{HdfsFileStatus}}, style fixes, and tiding up the changes from HDFS-12455; so no large changes there.\r\n\r\nThe main change is the introduction of the {{HdfsNamedFileStatus}}. I think this is a less intrusive solution than what we had.\r\nDo all the MapReduce unit tests pass now?\r\n\r\nA couple nits:\r\n* Given the size of {{HdfsFileStatus#build()}} I would do a full if instead of a ternary.\r\n* Add javadoc to {{FileEncryptionInfo getFileEncryptionInfo()}} for consistency with the rest.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=elgoiri","name":"elgoiri","key":"elgoiri","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Íñigo Goiri","active":true,"timeZone":"Etc/UTC"},"created":"2017-11-28T18:47:47.981+0000","updated":"2017-11-28T18:47:47.981+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13110491/comment/16269283","id":"16269283","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"body":"bq. I would file a JIRA to change those to use the 1-RPC call approach (even though, we need to keep some basic unit tests that makes sure that the 2-RPC approach works).\r\nGot it. Yes, that makes sense. I'll file a MR JIRA to fix the examples, there. There are existing cases e.g., HADOOP-14600 that probably prevent us from deprecating the 2-RPC variant, but we can at least make MR more efficient.\r\n\r\nbq. Do all the MapReduce unit tests pass now?\r\nYes, they pass. I got one failure, which turned out to be spurious (MAPREDUCE-7011).\r\n\r\nI'll post a new patch presently.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-11-28T19:03:19.076+0000","updated":"2017-11-28T19:03:19.076+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13110491/comment/16269700","id":"16269700","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=genericqa","name":"genericqa","key":"genericqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=genericqa&avatarId=33630","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=genericqa&avatarId=33630","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=genericqa&avatarId=33630","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=genericqa&avatarId=33630"},"displayName":"genericqa","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  9m 42s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 4 new or modified test files. {color} |\r\n|| || || || {color:brown} trunk Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  1m 50s{color} | {color:blue} Maven dependency ordering for branch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 18m 24s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 15m  0s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m 23s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  3m 48s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 16m 35s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  5m 31s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m 42s{color} | {color:green} trunk passed {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 16s{color} | {color:blue} Maven dependency ordering for patch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  2m 37s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 11m 30s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 11m 30s{color} | {color:green} the patch passed {color} |\r\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  2m  5s{color} | {color:orange} root: The patch generated 13 new + 409 unchanged - 6 fixed = 422 total (was 415) {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  3m 26s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\r\n| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  3s{color} | {color:green} The patch has no ill-formed XML file. {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green}  9m 51s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  7m  0s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m 55s{color} | {color:green} the patch passed {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  9m  7s{color} | {color:green} hadoop-common in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  1m 30s{color} | {color:green} hadoop-hdfs-client in the patch passed. {color} |\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 88m 57s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  3m 49s{color} | {color:green} hadoop-hdfs-httpfs in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 35s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black}215m 58s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Reason || Tests ||\r\n| Failed junit tests | hadoop.fs.TestUnbuffer |\r\n|   | hadoop.hdfs.qjournal.server.TestJournalNodeSync |\r\n|   | hadoop.hdfs.TestReconstructStripedFile |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:5b98639 |\r\n| JIRA Issue | HDFS-12681 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12899669/HDFS-12681.14.patch |\r\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  xml  |\r\n| uname | Linux 0bc40bbf528d 3.13.0-135-generic #184-Ubuntu SMP Wed Oct 18 11:55:51 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | /testptch/patchprocess/precommit/personality/provided.sh |\r\n| git revision | trunk / 30941d9 |\r\n| maven | version: Apache Maven 3.3.9 |\r\n| Default Java | 1.8.0_151 |\r\n| findbugs | v3.1.0-RC1 |\r\n| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/22213/artifact/out/diff-checkstyle-root.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/22213/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |\r\n|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/22213/testReport/ |\r\n| Max. process+thread count | 4162 (vs. ulimit of 5000) |\r\n| modules | C: hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs-client hadoop-hdfs-project/hadoop-hdfs hadoop-hdfs-project/hadoop-hdfs-httpfs U: . |\r\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/22213/console |\r\n| Powered by | Apache Yetus 0.7.0-SNAPSHOT   http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=genericqa","name":"genericqa","key":"genericqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=genericqa&avatarId=33630","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=genericqa&avatarId=33630","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=genericqa&avatarId=33630","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=genericqa&avatarId=33630"},"displayName":"genericqa","active":true,"timeZone":"Etc/UTC"},"created":"2017-11-28T23:27:02.412+0000","updated":"2017-11-28T23:27:02.412+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13110491/comment/16269790","id":"16269790","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"body":"Fixed a checkstyle issue.\r\n\r\nFiled MAPREDUCE-7016 to track the 2-RPC case for {{FileInputFormat}}, which is where most of the failures from v10 originated. Fixing it is not straightforward, as globbing in {{FileSystem}} needs to work around a lot of legacy constraints. Many are documented, but some may require working with HDFS to retain the semantics of hidden directories, snapshots, etc.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-11-29T00:16:11.851+0000","updated":"2017-11-29T00:16:11.851+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13110491/comment/16270119","id":"16270119","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=genericqa","name":"genericqa","key":"genericqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=genericqa&avatarId=33630","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=genericqa&avatarId=33630","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=genericqa&avatarId=33630","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=genericqa&avatarId=33630"},"displayName":"genericqa","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 13s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 4 new or modified test files. {color} |\r\n|| || || || {color:brown} trunk Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  1m 40s{color} | {color:blue} Maven dependency ordering for branch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 15m 15s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 11m 57s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m 59s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  3m 32s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 15m 28s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  5m 15s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m 25s{color} | {color:green} trunk passed {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 15s{color} | {color:blue} Maven dependency ordering for patch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  2m 31s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 10m 58s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 10m 58s{color} | {color:green} the patch passed {color} |\r\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  1m 53s{color} | {color:orange} root: The patch generated 12 new + 409 unchanged - 6 fixed = 421 total (was 415) {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  3m 13s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\r\n| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  3s{color} | {color:green} The patch has no ill-formed XML file. {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green}  8m 54s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  5m 54s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m 36s{color} | {color:green} the patch passed {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}  8m  2s{color} | {color:red} hadoop-common in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  1m 29s{color} | {color:green} hadoop-hdfs-client in the patch passed. {color} |\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}117m 59s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  3m 59s{color} | {color:green} hadoop-hdfs-httpfs in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 36s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black}223m  4s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Reason || Tests ||\r\n| Failed junit tests | hadoop.security.TestRaceWhenRelogin |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure000 |\r\n|   | hadoop.hdfs.TestDistributedFileSystemWithECFile |\r\n|   | hadoop.hdfs.TestDatanodeStartupFixesLegacyStorageIDs |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure150 |\r\n|   | hadoop.hdfs.TestFileAppend |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure |\r\n|   | hadoop.hdfs.TestDFSRemove |\r\n|   | hadoop.hdfs.server.blockmanagement.TestBlockStatsMXBean |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure160 |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure120 |\r\n|   | hadoop.hdfs.TestWriteRead |\r\n|   | hadoop.hdfs.TestMaintenanceState |\r\n|   | hadoop.hdfs.TestErasureCodingPoliciesWithRandomECPolicy |\r\n|   | hadoop.hdfs.TestFileCreation |\r\n|   | hadoop.hdfs.TestHDFSFileSystemContract |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure020 |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure180 |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStream |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithRandomECPolicy |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure190 |\r\n|   | hadoop.hdfs.TestGetFileChecksum |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure140 |\r\n|   | hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData |\r\n|   | hadoop.hdfs.server.balancer.TestBalancerRPCDelay |\r\n|   | hadoop.hdfs.TestUnsetAndChangeDirectoryEcPolicy |\r\n|   | hadoop.hdfs.web.TestWebHdfsTimeouts |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure090 |\r\n|   | hadoop.hdfs.TestErasureCodingPolicies |\r\n|   | hadoop.hdfs.TestReconstructStripedFile |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure130 |\r\n|   | hadoop.hdfs.TestDFSStorageStateRecovery |\r\n|   | hadoop.fs.TestUnbuffer |\r\n|   | hadoop.hdfs.TestWriteReadStripedFile |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:5b98639 |\r\n| JIRA Issue | HDFS-12681 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12899718/HDFS-12681.15.patch |\r\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  xml  |\r\n| uname | Linux 1ceacc4efaa7 4.4.0-43-generic #63-Ubuntu SMP Wed Oct 12 13:48:03 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | /testptch/patchprocess/precommit/personality/provided.sh |\r\n| git revision | trunk / 30941d9 |\r\n| maven | version: Apache Maven 3.3.9 |\r\n| Default Java | 1.8.0_151 |\r\n| findbugs | v3.1.0-RC1 |\r\n| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/22215/artifact/out/diff-checkstyle-root.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/22215/artifact/out/patch-unit-hadoop-common-project_hadoop-common.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/22215/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |\r\n|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/22215/testReport/ |\r\n| Max. process+thread count | 4750 (vs. ulimit of 5000) |\r\n| modules | C: hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs-client hadoop-hdfs-project/hadoop-hdfs hadoop-hdfs-project/hadoop-hdfs-httpfs U: . |\r\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/22215/console |\r\n| Powered by | Apache Yetus 0.7.0-SNAPSHOT   http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=genericqa","name":"genericqa","key":"genericqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=genericqa&avatarId=33630","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=genericqa&avatarId=33630","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=genericqa&avatarId=33630","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=genericqa&avatarId=33630"},"displayName":"genericqa","active":true,"timeZone":"Etc/UTC"},"created":"2017-11-29T04:30:29.087+0000","updated":"2017-11-29T04:30:29.087+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13110491/comment/16271541","id":"16271541","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=elgoiri","name":"elgoiri","key":"elgoiri","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Íñigo Goiri","active":true,"timeZone":"Etc/UTC"},"body":"I would ignore the left check styles.\r\nThe unit test failures seem spurious.\r\nGiven that locally they pass (including the MapReduce ones): +1\r\nGood to rerun QA just to get a cleaner build though.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=elgoiri","name":"elgoiri","key":"elgoiri","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Íñigo Goiri","active":true,"timeZone":"Etc/UTC"},"created":"2017-11-29T21:07:14.345+0000","updated":"2017-11-29T21:07:14.345+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13110491/comment/16271730","id":"16271730","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"body":"Soright, will try the same patch, see if Jenkins is feeling more generous this time.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-11-29T23:03:11.570+0000","updated":"2017-11-29T23:03:11.570+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13110491/comment/16272124","id":"16272124","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=genericqa","name":"genericqa","key":"genericqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=genericqa&avatarId=33630","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=genericqa&avatarId=33630","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=genericqa&avatarId=33630","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=genericqa&avatarId=33630"},"displayName":"genericqa","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 19s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 4 new or modified test files. {color} |\r\n|| || || || {color:brown} trunk Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 24s{color} | {color:blue} Maven dependency ordering for branch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 20m 51s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 15m 14s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m 24s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  4m 30s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 18m  7s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  7m 14s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  3m 45s{color} | {color:green} trunk passed {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 50s{color} | {color:blue} Maven dependency ordering for patch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  4m 20s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 17m 31s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 17m 31s{color} | {color:green} the patch passed {color} |\r\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  2m 23s{color} | {color:orange} root: The patch generated 12 new + 410 unchanged - 6 fixed = 422 total (was 416) {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  4m 48s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\r\n| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  3s{color} | {color:green} The patch has no ill-formed XML file. {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 12m  1s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  9m 26s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  4m  4s{color} | {color:green} the patch passed {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 13m 14s{color} | {color:red} hadoop-common in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  2m 14s{color} | {color:green} hadoop-hdfs-client in the patch passed. {color} |\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}125m 53s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  3m 48s{color} | {color:green} hadoop-hdfs-httpfs in the patch passed. {color} |\r\n| {color:red}-1{color} | {color:red} asflicense {color} | {color:red}  0m 32s{color} | {color:red} The patch generated 3 ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black}275m 48s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Reason || Tests ||\r\n| Failed junit tests | hadoop.security.TestShellBasedUnixGroupsMapping |\r\n|   | hadoop.hdfs.TestEncryptedTransfer |\r\n|   | hadoop.hdfs.TestSnapshotCommands |\r\n|   | hadoop.hdfs.TestBlocksScheduledCounter |\r\n|   | hadoop.hdfs.TestDFSClientFailover |\r\n|   | hadoop.hdfs.TestDatanodeDeath |\r\n|   | hadoop.hdfs.TestDFSRollback |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure040 |\r\n|   | hadoop.hdfs.shortcircuit.TestShortCircuitLocalRead |\r\n|   | hadoop.hdfs.TestHDFSFileSystemContract |\r\n|   | hadoop.hdfs.server.balancer.TestBalancerWithSaslDataTransfer |\r\n|   | hadoop.hdfs.security.TestDelegationTokenForProxyUser |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure140 |\r\n|   | hadoop.hdfs.TestErasureCodingPolicyWithSnapshot |\r\n|   | hadoop.hdfs.TestDecommission |\r\n|   | hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData |\r\n|   | hadoop.hdfs.TestDatanodeRegistration |\r\n|   | hadoop.hdfs.TestDistributedFileSystem |\r\n|   | hadoop.hdfs.server.federation.router.TestRouterRpc |\r\n|   | hadoop.hdfs.TestDFSShell |\r\n|   | hadoop.hdfs.server.balancer.TestBalancerWithMultipleNameNodes |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure110 |\r\n|   | hadoop.hdfs.TestIsMethodSupported |\r\n|   | hadoop.hdfs.TestFileAppendRestart |\r\n|   | hadoop.hdfs.TestDatanodeReport |\r\n|   | hadoop.hdfs.TestMiniDFSCluster |\r\n|   | hadoop.fs.TestUnbuffer |\r\n|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure000 |\r\n|   | hadoop.metrics2.sink.TestRollingFileSystemSinkWithHdfs |\r\n|   | hadoop.hdfs.web.TestFSMainOperationsWebHdfs |\r\n|   | hadoop.hdfs.server.balancer.TestBalancerRPCDelay |\r\n|   | hadoop.hdfs.web.TestWebHDFS |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:5b98639 |\r\n| JIRA Issue | HDFS-12681 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12899897/HDFS-12681.16.patch |\r\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  xml  |\r\n| uname | Linux ba58f7db2078 3.13.0-135-generic #184-Ubuntu SMP Wed Oct 18 11:55:51 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | /testptch/patchprocess/precommit/personality/provided.sh |\r\n| git revision | trunk / 333ef30 |\r\n| maven | version: Apache Maven 3.3.9 |\r\n| Default Java | 1.8.0_151 |\r\n| findbugs | v3.1.0-RC1 |\r\n| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/22224/artifact/out/diff-checkstyle-root.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/22224/artifact/out/patch-unit-hadoop-common-project_hadoop-common.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/22224/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |\r\n|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/22224/testReport/ |\r\n| asflicense | https://builds.apache.org/job/PreCommit-HDFS-Build/22224/artifact/out/patch-asflicense-problems.txt |\r\n| Max. process+thread count | 2900 (vs. ulimit of 5000) |\r\n| modules | C: hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs-client hadoop-hdfs-project/hadoop-hdfs hadoop-hdfs-project/hadoop-hdfs-httpfs U: . |\r\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/22224/console |\r\n| Powered by | Apache Yetus 0.7.0-SNAPSHOT   http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=genericqa","name":"genericqa","key":"genericqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=genericqa&avatarId=33630","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=genericqa&avatarId=33630","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=genericqa&avatarId=33630","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=genericqa&avatarId=33630"},"displayName":"genericqa","active":true,"timeZone":"Etc/UTC"},"created":"2017-11-30T03:46:50.796+0000","updated":"2017-11-30T03:46:50.796+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13110491/comment/16272148","id":"16272148","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"body":"Failed tests are due to resource exhaustion. {{TestUnbuffer}} failed in my environment (HADOOP-15056), but the other tests passed last time I ran them.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-11-30T04:26:36.287+0000","updated":"2017-11-30T04:26:36.287+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13110491/comment/16272150","id":"16272150","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"body":"I committed this.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-11-30T04:32:08.264+0000","updated":"2017-11-30T04:32:08.264+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13110491/comment/16272165","id":"16272165","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"SUCCESS: Integrated in Jenkins build Hadoop-trunk-Commit #13295 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/13295/])\nHDFS-12681. Make HdfsLocatedFileStatus a subtype of LocatedFileStatus (cdouglas: rev 0e560f3b8d194c10dce06443979df4074e14b0db)\n* (edit) hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java\n* (edit) hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/protocolPB/PBHelper.java\n* (edit) hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileStatusSerialization.java\n* (edit) hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FileStatus.java\n* (edit) hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocol/HdfsFileStatus.java\n* (edit) hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocol/HdfsLocatedFileStatus.java\n* (edit) hadoop-hdfs-project/hadoop-hdfs/dev-support/findbugsExcludeFile.xml\n* (edit) hadoop-hdfs-project/hadoop-hdfs-httpfs/src/main/java/org/apache/hadoop/fs/http/client/HttpFSFileSystem.java\n* (add) hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocol/HdfsNamedFileStatus.java\n* (add) hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocol/package-info.java\n* (add) hadoop-hdfs-project/hadoop-hdfs-client/src/test/java/org/apache/hadoop/hdfs/protocol/TestHdfsFileStatusMethods.java\n* (edit) hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/mover/TestStorageMover.java\n* (edit) hadoop-hdfs-project/hadoop-hdfs-client/dev-support/findbugsExcludeFile.xml\n* (edit) hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/mover/Mover.java\n* (edit) hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirStatAndListingOp.java\n* (edit) hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/LocatedFileStatus.java\n* (edit) hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestBlockStoragePolicy.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2017-11-30T04:51:28.511+0000","updated":"2017-11-30T04:51:28.511+0000"}],"maxResults":64,"total":64,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-12681/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i3nbcv:"}}