{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12783422","self":"https://issues.apache.org/jira/rest/api/2/issue/12783422","key":"HDFS-7960","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12327584","id":"12327584","description":"2.7.0 release","name":"2.7.0","archived":false,"released":true,"releaseDate":"2015-04-20"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12329018","id":"12329018","description":"2.6.1 release","name":"2.6.1","archived":false,"released":true,"releaseDate":"2015-09-23"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12335732","id":"12335732","description":"3.0.0-alpha1 release","name":"3.0.0-alpha1","archived":false,"released":true,"releaseDate":"2016-09-03"}],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2015-03-19T23:27:09.098+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Wed Sep 02 02:03:44 UTC 2015","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":"10002_*:*_3_*:*_355734374_*|*_1_*:*_3_*:*_10439829_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2015-03-24T05:02:23.202+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-7960/watchers","watchCount":18,"isWatching":false},"created":"2015-03-19T23:19:29.054+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/2","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/critical.svg","name":"Critical","id":"2"},"labels":["2.6.1-candidate"],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"8.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12327181","id":"12327181","description":"2.6.0 release","name":"2.6.0","archived":false,"released":true,"releaseDate":"2014-11-18"}],"issuelinks":[{"id":"12412112","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12412112","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"12732458","key":"HDFS-6830","self":"https://issues.apache.org/jira/rest/api/2/issue/12732458","fields":{"summary":"BlockInfo.addStorage fails when DN changes the storage for a block replica","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12411649","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12411649","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"inwardIssue":{"id":"12785077","key":"HDFS-7979","self":"https://issues.apache.org/jira/rest/api/2/issue/12785077","fields":{"summary":"Initialize block report IDs with a random number","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/4","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/minor.svg","name":"Minor","id":"4"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/4","id":"4","description":"An improvement or enhancement to an existing feature or task.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype","name":"Improvement","subtask":false,"avatarId":21140}}}},{"id":"12463865","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12463865","type":{"id":"12310050","name":"Regression","inward":"is broken by","outward":"breaks","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/12310050"},"outwardIssue":{"id":"12959486","key":"HDFS-10301","self":"https://issues.apache.org/jira/rest/api/2/issue/12959486","fields":{"summary":"BlockReport retransmissions may lead to storages falsely being declared zombie if storage report processing happens out of order","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/2","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/critical.svg","name":"Critical","id":"2"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12411187","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12411187","type":{"id":"10001","name":"dependent","inward":"is depended upon by","outward":"depends upon","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10001"},"inwardIssue":{"id":"12783429","key":"HDFS-7961","self":"https://issues.apache.org/jira/rest/api/2/issue/12783429","fields":{"summary":"Trigger full block report after hot swapping disk","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2016-08-30T01:38:14.299+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[],"timeoriginalestimate":null,"description":"The full block report should prune zombie storages even if they're not empty.  We have seen cases in production where zombie storages have not been pruned subsequent to HDFS-7575.  This could arise any time the NameNode thinks there is a block in some old storage which is actually not there.  In this case, the block will not show up in the \"new\" storage (once old is renamed to new) and the old storage will linger forever as a zombie, even with the HDFS-7596 fix applied.  This also happens with datanode hotplug, when a drive is removed.  In this case, an entire storage (volume) goes away but the blocks do not show up in another storage on the same datanode.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12327584","id":"12327584","description":"2.7.0 release","name":"2.7.0","archived":false,"released":true,"releaseDate":"2015-04-20"}],"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12705807","id":"12705807","filename":"HDFS-7960.002.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-03-20T02:15:59.442+0000","size":33904,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12705807/HDFS-7960.002.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12706059","id":"12706059","filename":"HDFS-7960.003.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-03-20T21:52:33.353+0000","size":47437,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12706059/HDFS-7960.003.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12706075","id":"12706075","filename":"HDFS-7960.004.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=andrew.wang","name":"andrew.wang","key":"andrew.wang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=andrew.wang&avatarId=19230","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=andrew.wang&avatarId=19230","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=andrew.wang&avatarId=19230","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=andrew.wang&avatarId=19230"},"displayName":"Andrew Wang","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-03-20T22:42:25.910+0000","size":47464,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12706075/HDFS-7960.004.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12706118","id":"12706118","filename":"HDFS-7960.005.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-03-21T03:37:14.296+0000","size":57335,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12706118/HDFS-7960.005.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12706122","id":"12706122","filename":"HDFS-7960.006.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-03-21T04:09:13.226+0000","size":57362,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12706122/HDFS-7960.006.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12706749","id":"12706749","filename":"HDFS-7960.007.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=eddyxu","name":"eddyxu","key":"eddyxu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Lei (Eddy) Xu","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-03-23T22:58:18.717+0000","size":55486,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12706749/HDFS-7960.007.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12706763","id":"12706763","filename":"HDFS-7960.008.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=eddyxu","name":"eddyxu","key":"eddyxu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Lei (Eddy) Xu","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-03-23T23:44:45.434+0000","size":57642,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12706763/HDFS-7960.008.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12753653","id":"12753653","filename":"HDFS-7960-branch-2.6.1.txt","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinodkv","name":"vinodkv","key":"vinodkv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinod Kumar Vavilapalli","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-09-02T02:03:44.691+0000","size":55877,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12753653/HDFS-7960-branch-2.6.1.txt"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"The full block report should prune zombie storages even if they're not empty","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=eddyxu","name":"eddyxu","key":"eddyxu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Lei (Eddy) Xu","active":true,"timeZone":"America/Los_Angeles"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=eddyxu","name":"eddyxu","key":"eddyxu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Lei (Eddy) Xu","active":true,"timeZone":"America/Los_Angeles"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12783422/comment/14370336","id":"14370336","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"body":"Just a note here: the reason why HDFS-7596 works in the non-hotplug case is because we make an implicit assumption that a block will be on at most one storage of a DataNode.  So when block reports come in that say that blocks B1, B2, ... etc. are on some storage, we remove them from any other storages they might be on.  So in the case of HDFS-7575, where we change a storage ID of a storage, this will gradually allow the zombie storage to go away.  Of course, this doesn't work for datanode hotplug, for the reasons I outlined above.  And even in the case where HDFS-7596 works, it's still relatively slow and could open up a window when we think something is replicated and it really isn't.  It's better to be clear in the FBR that certain storages just don't exist any more.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-03-19T23:27:09.098+0000","updated":"2015-03-19T23:27:09.098+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12783422/comment/14370571","id":"14370571","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"body":"patch to get jenkins run.  will put up a unit test soon","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-03-20T02:12:40.684+0000","updated":"2015-03-20T02:12:40.684+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12783422/comment/14370729","id":"14370729","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12705807/HDFS-7960.002.patch\n  against trunk revision e37ca22.\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:green}+1 tests included{color}.  The patch appears to include 14 new or modified test files.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager:\n\n                  org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestAllocationFileLoaderService\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/9996//testReport/\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/9996//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2015-03-20T04:57:05.836+0000","updated":"2015-03-20T04:57:05.836+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12783422/comment/14370761","id":"14370761","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=andrew.wang","name":"andrew.wang","key":"andrew.wang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=andrew.wang&avatarId=19230","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=andrew.wang&avatarId=19230","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=andrew.wang&avatarId=19230","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=andrew.wang&avatarId=19230"},"displayName":"Andrew Wang","active":true,"timeZone":"America/Los_Angeles"},"body":"Nice find and fix Colin. This change looks good to me overall, looking forward to the unit test. Just a few comments:\n\n* EMPTY_STORAGE_INFO_LIST is a little dangerous since it can still be modified, maybe use ImmutableLists instead? Alternatively we can just allocate the empty LinkedList, it'll be young gen and cheap.\n* Could use some comments about the lifecycle of updatedByCurrentFbr on the NN in a comment (on the zombie reaper methods?), also on the DN side too about sentAllStorages. The comment in the proto file is reasonable, but that is not the first place people will look.\n* When we're doing a rolling upgrade, I think updatedByCurrentFbr will be off. The NN will never get a sentAllStorages signal from an old DN, so it'll keep marking all of its storages as updatedByCurrentFbr. The DN upgrades, and the first FBR with sentAllStorages set won't handle zombies correctly since everything is marked updatedByCurrentFbr. This probably deserves a comment at least. We could also provide a \"first\" flag to go along with the \"last\", so the NN resets updatedByCurrentFbr on seeing \"first\" and reaps upon seeing \"last\".\n\nA few nits:\n\n{code}\n        List<DatanodeStorageInfo> zombies =  node.removeZombieStorages();\n{code}\n\ndouble space after equals here\n\n{code}\n      BlockReportRequestProto request)\n\t        throws ServiceException {\n{code}\n\nunnecessary whitespace change?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=andrew.wang","name":"andrew.wang","key":"andrew.wang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=andrew.wang&avatarId=19230","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=andrew.wang&avatarId=19230","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=andrew.wang&avatarId=19230","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=andrew.wang&avatarId=19230"},"displayName":"Andrew Wang","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-03-20T05:22:58.936+0000","updated":"2015-03-20T05:22:58.936+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12783422/comment/14372191","id":"14372191","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"body":"bq. EMPTY_STORAGE_INFO_LIST is a little dangerous since it can still be modified, maybe use ImmutableLists instead? Alternatively we can just allocate the empty LinkedList, it'll be young gen and cheap.\n\nYeah, let's use ImmutableList\n\nbq. double space after equals here\n\nfixed\n\nbq. unnecessary whitespace change?\n\nfixed\n\nOther changes: I thought about this a little more and I think instead of just a boolean to tell when the last rpc is happening, we should have 3 things: the current unique (across same DN) 64-bit block report ID, the total number of RPCs in the block report, and the current rpc in the block report.\n\nCan get a unique ID on the datanode from the monotonic time in nanoseconds.  (If for some bizarre reason the clock doesn't advance between BRs, we can just add one to the previous time).  This should also ensure that if we restart the DN, we don't re-use IDs.  The ID should help match up DN and NN in the logs.\n\nHaving a total RPC count and a current RPC index is more flexible if we want to chunk block report RPCs differently in the future.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-03-20T21:52:11.788+0000","updated":"2015-03-20T21:52:11.788+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12783422/comment/14372219","id":"14372219","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12706059/HDFS-7960.003.patch\n  against trunk revision 586348e.\n\n    {color:red}-1 patch{color}.  The patch command could not apply the patch.\n\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/10011//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2015-03-20T22:09:35.055+0000","updated":"2015-03-20T22:09:35.055+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12783422/comment/14372257","id":"14372257","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=andrew.wang","name":"andrew.wang","key":"andrew.wang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=andrew.wang&avatarId=19230","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=andrew.wang&avatarId=19230","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=andrew.wang&avatarId=19230","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=andrew.wang&avatarId=19230"},"displayName":"Andrew Wang","active":true,"timeZone":"America/Los_Angeles"},"body":"The patch application worked when I specified \"--3way\" without conflicts, so here's the .003 after I did that. No other changes.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=andrew.wang","name":"andrew.wang","key":"andrew.wang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=andrew.wang&avatarId=19230","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=andrew.wang&avatarId=19230","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=andrew.wang&avatarId=19230","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=andrew.wang&avatarId=19230"},"displayName":"Andrew Wang","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-03-20T22:42:25.917+0000","updated":"2015-03-20T22:42:25.917+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12783422/comment/14372295","id":"14372295","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=andrew.wang","name":"andrew.wang","key":"andrew.wang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=andrew.wang&avatarId=19230","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=andrew.wang&avatarId=19230","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=andrew.wang&avatarId=19230","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=andrew.wang&avatarId=19230"},"displayName":"Andrew Wang","active":true,"timeZone":"America/Los_Angeles"},"body":"Reading through it again, few comments:\n\nNNRpcServer:\n* there's a TODO: FIXME, we aren't passing in the BlockReportContext. processReport doesn't need that last parameter anymore either I think, since the information is in the BR context.\n\nBPServiceActor:\n* Is there a need for BR ids to be monotonic increasing? Else using a random number seems better. I see you do a fixup by checking with the previous ID, but with random this shouldn't be necessary.\n\nDatanodeDescriptor:\n* it looks like we only get/set LastBlockReportId in removeZombieStorages. We need to be setting to the current BR id as BRs come in right? This is probably a holdover from processReport not being updated from the previous patch rev.\n\nIf you wanted to add comments about all this, BlockReportContext's class javadoc would be a good choice.\n\nNit:\n\n{code}\n    assert (namesystem.hasWriteLock());\n{code}\n\nspace after assert\n\nGoing to stop there for now, I think we need to see another rev (the processReport FIXME basically) to get a feel for BlockReportContext.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=andrew.wang","name":"andrew.wang","key":"andrew.wang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=andrew.wang&avatarId=19230","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=andrew.wang&avatarId=19230","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=andrew.wang&avatarId=19230","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=andrew.wang&avatarId=19230"},"displayName":"Andrew Wang","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-03-20T23:11:12.026+0000","updated":"2015-03-20T23:11:12.026+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12783422/comment/14372404","id":"14372404","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"body":"bq. there's a TODO: FIXME, we aren't passing in the BlockReportContext.\n\nYeah, mea culpa.\n\nbq. processReport doesn't need that last parameter anymore either I think, since the information is in the BR context.\n\nThe last parameter is needed because we want to eliminate zombie storages only after all storages have been processed, and a single call to {{NameNodeRpcServer#blockReport}} can handle multiple storages\n\nbq. Is there a need for BR ids to be monotonic increasing? Else using a random number seems better. I see you do a fixup by checking with the previous ID, but with random this shouldn't be necessary\n\nI like the idea of monotonic increasing BR ids for two reasons: it makes it easier to see in the logs what block report came after what block report, and it effectively removes the (admittedly very, very small) chance of a collision between two subsequent BR IDs.  The monotonic timer in Linux (or other OS) only gets reset when a node reboots, so even restarting the DN process will not normally reset the ID.\n\nbq. If you wanted to add comments about all this, BlockReportContext's class javadoc would be a good choice.\n\nGood idea, I added some comments there.\n\nbq. space after assert\n\nfixed","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-03-21T00:54:24.951+0000","updated":"2015-03-21T00:54:24.951+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12783422/comment/14372454","id":"14372454","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12706075/HDFS-7960.004.patch\n  against trunk revision 586348e.\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:green}+1 tests included{color}.  The patch appears to include 14 new or modified test files.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:\n\n                  org.apache.hadoop.hdfs.TestDFSClientRetries\n                  org.apache.hadoop.tracing.TestTracing\n                  org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot\n                  org.apache.hadoop.hdfs.server.balancer.TestBalancer\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/10013//testReport/\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/10013//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2015-03-21T02:26:38.882+0000","updated":"2015-03-21T02:26:38.882+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12783422/comment/14372485","id":"14372485","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"body":"ok, this version adds a good unit test and addresses the previous issues with not passing the context.  Fixed up some of the logs to include the block report id and added some more comments","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-03-21T03:40:08.711+0000","updated":"2015-03-21T03:40:08.711+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12783422/comment/14372487","id":"14372487","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12706118/HDFS-7960.005.patch\n  against trunk revision e1feb4e.\n\n    {color:red}-1 patch{color}.  The patch command could not apply the patch.\n\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/10018//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2015-03-21T03:40:36.243+0000","updated":"2015-03-21T03:40:36.243+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12783422/comment/14372500","id":"14372500","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"body":"rebase on trunk","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-03-21T04:09:13.232+0000","updated":"2015-03-21T04:09:13.232+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12783422/comment/14372581","id":"14372581","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12706122/HDFS-7960.006.patch\n  against trunk revision e1feb4e.\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:green}+1 tests included{color}.  The patch appears to include 15 new or modified test files.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:\n\n                  org.apache.hadoop.hdfs.server.mover.TestMover\n                  org.apache.hadoop.tracing.TestTracing\n                  org.apache.hadoop.hdfs.server.datanode.TestNNHandlesBlockReportPerStorage\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/10019//testReport/\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/10019//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2015-03-21T07:37:34.970+0000","updated":"2015-03-21T07:37:34.970+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12783422/comment/14375781","id":"14375781","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hitliuyi","name":"hitliuyi","key":"hitliuyi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yi Liu","active":true,"timeZone":"Asia/Shanghai"},"body":"This is a good fix and improvement. Some comments:\n\n*1.* In {{BlockManager}}, the logic of checking zombie datanode storages has issue.\n{code}\n      if (context != null) {\n        storageInfo.setLastBlockReportId(context.getReportId());\n        if (lastStorageInRpc) {\n          int rpcsSeen = node.updateBlockReportContext(context);\n          if (rpcsSeen >= context.getTotalRpcs()) {\n            List<DatanodeStorageInfo> zombies = node.removeZombieStorages();\n            if (zombies.isEmpty()) {\n              ...\n{code}\nIn the patch, *rpcsSeen* is calculated in NN by counting all rpcs of same block report, it's not safe in case of split reports.\n{{DatanodeProtocol#blockReport}} is {{@Idempotent}}, if retry happens, {{if (rpcsSeen >= context.getTotalRpcs())}} can be *true*, while some datanode storages may not send splits of reports, in this case, these datanode storages will be treated as zombie and wrongly removed from NN.\nI suggest to check all rpc ids of block report received before checking zombie storages.\n\n*2.* Another comment is in {{removeZombieReplicas}}:\n{code}\n removeStoredBlock(block, zombie.getDatanodeDescriptor());\n{code}\nWhile removing stored block, we'd better to remove it from {{InvalidateBlocks}} too. How about call {{removeBlocksAssociatedTo(final DatanodeDescriptor node)}}? Then it can also save your code lines.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hitliuyi","name":"hitliuyi","key":"hitliuyi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yi Liu","active":true,"timeZone":"Asia/Shanghai"},"created":"2015-03-23T12:11:47.491+0000","updated":"2015-03-23T12:11:47.491+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12783422/comment/14376712","id":"14376712","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hitliuyi","name":"hitliuyi","key":"hitliuyi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yi Liu","active":true,"timeZone":"Asia/Shanghai"},"body":"Some incorrect in my second comment: wo could not use {{removeBlocksAssociatedTo}},it will remove of all blocks of that DN, not only the storage, so just add removing blocks from {{InvalidateBlocks}} in removeZombieReplicas","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hitliuyi","name":"hitliuyi","key":"hitliuyi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yi Liu","active":true,"timeZone":"Asia/Shanghai"},"created":"2015-03-23T21:47:44.362+0000","updated":"2015-03-23T21:47:44.362+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12783422/comment/14376851","id":"14376851","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=eddyxu","name":"eddyxu","key":"eddyxu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Lei (Eddy) Xu","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi, [~hitliuyi] and [~andrew.wang].\n\nI attempted to update the patch to address [~hitliuyi]'s comments, also fixed the test failure {{TestNNHandlesBlockReportPerStorage}}.\n\nCould you give another review? Thanks!","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=eddyxu","name":"eddyxu","key":"eddyxu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Lei (Eddy) Xu","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-03-23T22:58:18.725+0000","updated":"2015-03-23T22:58:18.725+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12783422/comment/14376878","id":"14376878","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"body":"bq. Yi wrote: In the patch, rpcsSeen is calculated in NN by counting all rpcs of same block report, it's not safe in case of split reports. DatanodeProtocol#blockReport is @Idempotent, if retry happens, if (rpcsSeen >= context.getTotalRpcs()) can be true, while some datanode storages may not send splits of reports, in this case, these datanode storages will be treated as zombie and wrongly removed from NN.\n\nThanks, that's a good point.  We should make sure that these RPCs stay idempotent.  I like [~eddyxu]'s solution of using a bitset to track which parts were received.\n\nbq. Yi wrote: While removing stored block, we'd better to remove it from InvalidateBlocks too.\n\nVery good point.\n\nbq. I attempted to update the patch to address Yi Liu's comments, also fixed the test failure TestNNHandlesBlockReportPerStorage.\n\nThanks, Eddy.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-03-23T23:13:43.306+0000","updated":"2015-03-23T23:13:43.306+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12783422/comment/14376912","id":"14376912","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12706749/HDFS-7960.007.patch\n  against trunk revision 972f1f1.\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:green}+1 tests included{color}.  The patch appears to include 15 new or modified test files.\n\n    {color:red}-1 javac{color:red}.  The patch appears to cause the build to fail.\n\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/10040//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2015-03-23T23:36:23.991+0000","updated":"2015-03-23T23:36:23.991+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12783422/comment/14376928","id":"14376928","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=eddyxu","name":"eddyxu","key":"eddyxu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Lei (Eddy) Xu","active":true,"timeZone":"America/Los_Angeles"},"body":"Added missing file to fix compiling errors. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=eddyxu","name":"eddyxu","key":"eddyxu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Lei (Eddy) Xu","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-03-23T23:44:45.439+0000","updated":"2015-03-23T23:44:45.439+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12783422/comment/14377060","id":"14377060","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hitliuyi","name":"hitliuyi","key":"hitliuyi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yi Liu","active":true,"timeZone":"Asia/Shanghai"},"body":"Thanks Colin, Lei for updating the patch. It looks really good, a nit:\n*1.* please add _InterfaceAudience_/_InterfaceStability_ annotations for {{BlockReportContext}}\n\nLet's wait to see what Andrew says, also wait for a fresh Jenkins.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hitliuyi","name":"hitliuyi","key":"hitliuyi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yi Liu","active":true,"timeZone":"Asia/Shanghai"},"created":"2015-03-24T01:35:07.950+0000","updated":"2015-03-24T01:35:07.950+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12783422/comment/14377207","id":"14377207","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12706763/HDFS-7960.008.patch\n  against trunk revision 2c238ae.\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:green}+1 tests included{color}.  The patch appears to include 15 new or modified test files.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:red}-1 javadoc{color}.  The javadoc tool appears to have generated 50 warning messages.\n        See https://builds.apache.org/job/PreCommit-HDFS-Build/10042//artifact/patchprocess/diffJavadocWarnings.txt for details.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs hadoop-hdfs-project/hadoop-hdfs-nfs:\n\n                  org.apache.hadoop.tracing.TestTracing\n\n                                      The following test timeouts occurred in hadoop-hdfs-project/hadoop-hdfs hadoop-hdfs-project/hadoop-hdfs-nfs:\n\norg.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestLazyPersistFiles\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/10042//testReport/\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/10042//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2015-03-24T03:33:03.591+0000","updated":"2015-03-24T03:33:03.591+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12783422/comment/14377287","id":"14377287","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=andrew.wang","name":"andrew.wang","key":"andrew.wang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=andrew.wang&avatarId=19230","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=andrew.wang&avatarId=19230","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=andrew.wang&avatarId=19230","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=andrew.wang&avatarId=19230"},"displayName":"Andrew Wang","active":true,"timeZone":"America/Los_Angeles"},"body":"Looks good to me too. I'll add the InterfaceAudience line at commit, it's a super minor change.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=andrew.wang","name":"andrew.wang","key":"andrew.wang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=andrew.wang&avatarId=19230","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=andrew.wang&avatarId=19230","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=andrew.wang&avatarId=19230","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=andrew.wang&avatarId=19230"},"displayName":"Andrew Wang","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-03-24T04:57:58.336+0000","updated":"2015-03-24T04:57:58.336+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12783422/comment/14377291","id":"14377291","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=andrew.wang","name":"andrew.wang","key":"andrew.wang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=andrew.wang&avatarId=19230","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=andrew.wang&avatarId=19230","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=andrew.wang&avatarId=19230","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=andrew.wang&avatarId=19230"},"displayName":"Andrew Wang","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks for the patch Colin and Eddy, and Yi for reviewing. I've committed this down to branch-2.7 for 2.7.0.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=andrew.wang","name":"andrew.wang","key":"andrew.wang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=andrew.wang&avatarId=19230","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=andrew.wang&avatarId=19230","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=andrew.wang&avatarId=19230","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=andrew.wang&avatarId=19230"},"displayName":"Andrew Wang","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-03-24T05:02:23.244+0000","updated":"2015-03-24T05:02:23.244+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12783422/comment/14377296","id":"14377296","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=andrew.wang","name":"andrew.wang","key":"andrew.wang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=andrew.wang&avatarId=19230","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=andrew.wang&avatarId=19230","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=andrew.wang&avatarId=19230","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=andrew.wang&avatarId=19230"},"displayName":"Andrew Wang","active":true,"timeZone":"America/Los_Angeles"},"body":"I also thought about it a bit, and the monotonic clock is roughly the time since boot, which isn't that random. I'd feel better if we seeded with a random number, then added the monotime to that after.\n\nI'll file a follow-up for that, and fix the interface audience nit there too.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=andrew.wang","name":"andrew.wang","key":"andrew.wang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=andrew.wang&avatarId=19230","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=andrew.wang&avatarId=19230","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=andrew.wang&avatarId=19230","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=andrew.wang&avatarId=19230"},"displayName":"Andrew Wang","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-03-24T05:06:40.968+0000","updated":"2015-03-24T05:06:40.968+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12783422/comment/14377303","id":"14377303","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"FAILURE: Integrated in Hadoop-trunk-Commit #7411 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/7411/])\nHDFS-7960. The full block report should prune zombie storages even if they're not empty. Contributed by Colin McCabe and Eddy Xu. (wang: rev 50ee8f4e67a66aa77c5359182f61f3e951844db6)\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestDNFencing.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestNameNodePrunesMissingStorages.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/protocol/BlockReportContext.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestTriggerBlockReport.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolClientSideTranslatorPB.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestNNHandlesCombinedBlockReport.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/NNThroughputBenchmark.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/BlockReportTestBase.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/protocol/TestBlockListAsLongs.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestBPOfferService.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestNNHandlesBlockReportPerStorage.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestBlockManager.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDatanodeProtocolRetryPolicy.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolServerSideTranslatorPB.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestDeadDatanode.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDataNodeVolumeFailure.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDnRespectsBlockReportSplitThreshold.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BPServiceActor.java\n* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNodeRpcServer.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/proto/DatanodeProtocol.proto\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeStorageInfo.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestBlockHasMultipleReplicasOnSameDN.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2015-03-24T05:12:42.848+0000","updated":"2015-03-24T05:12:42.848+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12783422/comment/14377314","id":"14377314","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=andrew.wang","name":"andrew.wang","key":"andrew.wang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=andrew.wang&avatarId=19230","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=andrew.wang&avatarId=19230","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=andrew.wang&avatarId=19230","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=andrew.wang&avatarId=19230"},"displayName":"Andrew Wang","active":true,"timeZone":"America/Los_Angeles"},"body":"HDFS-7979 has the follow-up.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=andrew.wang","name":"andrew.wang","key":"andrew.wang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=andrew.wang&avatarId=19230","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=andrew.wang&avatarId=19230","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=andrew.wang&avatarId=19230","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=andrew.wang&avatarId=19230"},"displayName":"Andrew Wang","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-03-24T05:23:31.553+0000","updated":"2015-03-24T05:23:31.553+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12783422/comment/14377636","id":"14377636","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"FAILURE: Integrated in Hadoop-Yarn-trunk-Java8 #142 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk-Java8/142/])\nHDFS-7960. The full block report should prune zombie storages even if they're not empty. Contributed by Colin McCabe and Eddy Xu. (wang: rev 50ee8f4e67a66aa77c5359182f61f3e951844db6)\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeStorageInfo.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestNameNodePrunesMissingStorages.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDatanodeProtocolRetryPolicy.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolServerSideTranslatorPB.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestBPOfferService.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BPServiceActor.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/proto/DatanodeProtocol.proto\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDataNodeVolumeFailure.java\n* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestBlockManager.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestNNHandlesBlockReportPerStorage.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestBlockHasMultipleReplicasOnSameDN.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/BlockReportTestBase.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/protocol/TestBlockListAsLongs.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolClientSideTranslatorPB.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNodeRpcServer.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestTriggerBlockReport.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestNNHandlesCombinedBlockReport.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/protocol/BlockReportContext.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestDNFencing.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestDeadDatanode.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/NNThroughputBenchmark.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDnRespectsBlockReportSplitThreshold.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2015-03-24T10:41:33.696+0000","updated":"2015-03-24T10:41:33.696+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12783422/comment/14377652","id":"14377652","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"FAILURE: Integrated in Hadoop-Yarn-trunk #876 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/876/])\nHDFS-7960. The full block report should prune zombie storages even if they're not empty. Contributed by Colin McCabe and Eddy Xu. (wang: rev 50ee8f4e67a66aa77c5359182f61f3e951844db6)\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolServerSideTranslatorPB.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestBlockManager.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/protocol/BlockReportContext.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNodeRpcServer.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDatanodeProtocolRetryPolicy.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeStorageInfo.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/protocol/TestBlockListAsLongs.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestNameNodePrunesMissingStorages.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/NNThroughputBenchmark.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestNNHandlesCombinedBlockReport.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/proto/DatanodeProtocol.proto\n* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BPServiceActor.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestTriggerBlockReport.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestBlockHasMultipleReplicasOnSameDN.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestNNHandlesBlockReportPerStorage.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDnRespectsBlockReportSplitThreshold.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/BlockReportTestBase.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDataNodeVolumeFailure.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestDeadDatanode.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestBPOfferService.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestDNFencing.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolClientSideTranslatorPB.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2015-03-24T10:45:05.535+0000","updated":"2015-03-24T10:45:05.535+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12783422/comment/14377728","id":"14377728","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hitliuyi","name":"hitliuyi","key":"hitliuyi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yi Liu","active":true,"timeZone":"Asia/Shanghai"},"body":"Thanks Colin and Eddy for the patch, and Andrew for reviewing.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hitliuyi","name":"hitliuyi","key":"hitliuyi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yi Liu","active":true,"timeZone":"Asia/Shanghai"},"created":"2015-03-24T11:35:46.612+0000","updated":"2015-03-24T11:35:46.612+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12783422/comment/14377866","id":"14377866","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"FAILURE: Integrated in Hadoop-Mapreduce-trunk #2092 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/2092/])\nHDFS-7960. The full block report should prune zombie storages even if they're not empty. Contributed by Colin McCabe and Eddy Xu. (wang: rev 50ee8f4e67a66aa77c5359182f61f3e951844db6)\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/protocol/TestBlockListAsLongs.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestBlockManager.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestNNHandlesBlockReportPerStorage.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestNNHandlesCombinedBlockReport.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/protocol/BlockReportContext.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolServerSideTranslatorPB.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDatanodeProtocolRetryPolicy.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestDeadDatanode.java\n* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNodeRpcServer.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestTriggerBlockReport.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/NNThroughputBenchmark.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDataNodeVolumeFailure.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDnRespectsBlockReportSplitThreshold.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestNameNodePrunesMissingStorages.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/BlockReportTestBase.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolClientSideTranslatorPB.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/proto/DatanodeProtocol.proto\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeStorageInfo.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BPServiceActor.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestDNFencing.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestBlockHasMultipleReplicasOnSameDN.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestBPOfferService.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2015-03-24T13:45:17.793+0000","updated":"2015-03-24T13:45:17.793+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12783422/comment/14377927","id":"14377927","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"FAILURE: Integrated in Hadoop-Hdfs-trunk #2074 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/2074/])\nHDFS-7960. The full block report should prune zombie storages even if they're not empty. Contributed by Colin McCabe and Eddy Xu. (wang: rev 50ee8f4e67a66aa77c5359182f61f3e951844db6)\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestDeadDatanode.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/proto/DatanodeProtocol.proto\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/BlockReportTestBase.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestBPOfferService.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/protocol/BlockReportContext.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolServerSideTranslatorPB.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestBlockManager.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/NNThroughputBenchmark.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolClientSideTranslatorPB.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestDNFencing.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDataNodeVolumeFailure.java\n* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestTriggerBlockReport.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDnRespectsBlockReportSplitThreshold.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestNNHandlesBlockReportPerStorage.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BPServiceActor.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestBlockHasMultipleReplicasOnSameDN.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDatanodeProtocolRetryPolicy.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestNNHandlesCombinedBlockReport.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeStorageInfo.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestNameNodePrunesMissingStorages.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNodeRpcServer.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/protocol/TestBlockListAsLongs.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2015-03-24T14:24:23.905+0000","updated":"2015-03-24T14:24:23.905+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12783422/comment/14377947","id":"14377947","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"FAILURE: Integrated in Hadoop-Hdfs-trunk-Java8 #133 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk-Java8/133/])\nHDFS-7960. The full block report should prune zombie storages even if they're not empty. Contributed by Colin McCabe and Eddy Xu. (wang: rev 50ee8f4e67a66aa77c5359182f61f3e951844db6)\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestNameNodePrunesMissingStorages.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeStorageInfo.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolServerSideTranslatorPB.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDatanodeProtocolRetryPolicy.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/proto/DatanodeProtocol.proto\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDataNodeVolumeFailure.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestBPOfferService.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestDNFencing.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestNNHandlesCombinedBlockReport.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolClientSideTranslatorPB.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestDeadDatanode.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/NNThroughputBenchmark.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestTriggerBlockReport.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BPServiceActor.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/BlockReportTestBase.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDnRespectsBlockReportSplitThreshold.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNodeRpcServer.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java\n* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestBlockHasMultipleReplicasOnSameDN.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/protocol/BlockReportContext.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestNNHandlesBlockReportPerStorage.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestBlockManager.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/protocol/TestBlockListAsLongs.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2015-03-24T14:34:33.230+0000","updated":"2015-03-24T14:34:33.230+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12783422/comment/14377997","id":"14377997","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"FAILURE: Integrated in Hadoop-Mapreduce-trunk-Java8 #142 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk-Java8/142/])\nHDFS-7960. The full block report should prune zombie storages even if they're not empty. Contributed by Colin McCabe and Eddy Xu. (wang: rev 50ee8f4e67a66aa77c5359182f61f3e951844db6)\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/proto/DatanodeProtocol.proto\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolServerSideTranslatorPB.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestNameNodePrunesMissingStorages.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDatanodeProtocolRetryPolicy.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/protocol/TestBlockListAsLongs.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestTriggerBlockReport.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/protocol/BlockReportContext.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestBlockManager.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/NNThroughputBenchmark.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDnRespectsBlockReportSplitThreshold.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestNNHandlesCombinedBlockReport.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestBPOfferService.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestDNFencing.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BPServiceActor.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestNNHandlesBlockReportPerStorage.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/BlockReportTestBase.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeStorageInfo.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolClientSideTranslatorPB.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNodeRpcServer.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestBlockHasMultipleReplicasOnSameDN.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestDeadDatanode.java\n* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDataNodeVolumeFailure.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2015-03-24T15:11:49.475+0000","updated":"2015-03-24T15:11:49.475+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12783422/comment/14378418","id":"14378418","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks [~andrew.wang], [~eddyxu], and [~hitliuyi].  Great work.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-03-24T19:25:26.581+0000","updated":"2015-03-24T19:25:47.510+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12783422/comment/14726588","id":"14726588","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinodkv","name":"vinodkv","key":"vinodkv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinod Kumar Vavilapalli","active":true,"timeZone":"America/Los_Angeles"},"body":"[~sjlee0] backported this to 2.6.1, after fixing merge conflicts, java7 style log4j statements and dropping changes from  TestBlockListAsLongs.java and TestTriggerBlockReport.java which don't exist in 2.6.\n\nI just pushed the commit to 2.6.1 after running compilation and TestBlockManager, TestNameNodePrunesMissingStorages, TestBPOfferService, TestBlockHasMultipleReplicasOnSameDN, TestDataNodeVolumeFailure, TestDatanodeProtocolRetryPolicy, TestDnRespectsBlockReportSplitThreshold, TestNNHandlesBlockReportPerStorage, TestNNHandlesCombinedBlockReport, TestDeadDatanode and TestDNFencing which changed in the patch.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinodkv","name":"vinodkv","key":"vinodkv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinod Kumar Vavilapalli","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-09-02T02:02:57.032+0000","updated":"2015-09-02T02:02:57.032+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12783422/comment/14726590","id":"14726590","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinodkv","name":"vinodkv","key":"vinodkv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinod Kumar Vavilapalli","active":true,"timeZone":"America/Los_Angeles"},"body":"Attaching the 2.6.1 patch that I committed.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinodkv","name":"vinodkv","key":"vinodkv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinod Kumar Vavilapalli","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-09-02T02:03:44.694+0000","updated":"2015-09-02T02:03:44.694+0000"}],"maxResults":37,"total":37,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-7960/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i270dr:"}}