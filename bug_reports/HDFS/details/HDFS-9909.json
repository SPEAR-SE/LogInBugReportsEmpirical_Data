{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12947103","self":"https://issues.apache.org/jira/rest/api/2/issue/12947103","key":"HDFS-9909","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":"2016-04-05T00:31:14.806+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Tue Apr 05 15:47:43 UTC 2016","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-9909/watchers","watchCount":7,"isWatching":false},"created":"2016-03-04T21:52:10.345+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/2","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/critical.svg","name":"Critical","id":"2"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"1.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12331979","id":"12331979","description":"2.7.1 release","name":"2.7.1","archived":false,"released":true,"releaseDate":"2015-07-06"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12332790","id":"12332790","description":"2.7.2 release","name":"2.7.2","archived":false,"released":true,"releaseDate":"2016-01-25"}],"issuelinks":[{"id":"12459464","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12459464","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"inwardIssue":{"id":"12520148","key":"HDFS-2288","self":"https://issues.apache.org/jira/rest/api/2/issue/12520148","fields":{"summary":"Replicas awaiting recovery should return a full visible length","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/2","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/critical.svg","name":"Critical","id":"2"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12459465","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12459465","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"inwardIssue":{"id":"12549910","key":"HDFS-3219","self":"https://issues.apache.org/jira/rest/api/2/issue/12549910","fields":{"summary":"Disambiguate \"visible length\" in the code and docs","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/4","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/minor.svg","name":"Minor","id":"4"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/4","id":"4","description":"An improvement or enhancement to an existing feature or task.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype","name":"Improvement","subtask":false,"avatarId":21140}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xiaochen","name":"xiaochen","key":"xiaochen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=xiaochen&avatarId=24893","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=xiaochen&avatarId=24893","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=xiaochen&avatarId=24893","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=xiaochen&avatarId=24893"},"displayName":"Xiao Chen","active":true,"timeZone":"America/Los_Angeles"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2016-04-05T15:47:43.852+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12312928","id":"12312928","name":"hdfs-client"},{"self":"https://issues.apache.org/jira/rest/api/2/component/12312926","id":"12312926","name":"namenode"}],"timeoriginalestimate":null,"description":"If HDFS is restarted while a file is open for writing then new clients can't read that file until the hard lease limit expires and block recovery starts.\n\nScenario:\n1. write to file, call hflush\n2. without closing the file, restart hdfs \n3. after hdfs is back up, opening file for reading from a new client fails for 1 hour\n\nRepro attached.\n\nThoughts:\n* possibly this also happens in other cases not just when hdfs is restarted (e.g. only all datanodes in pipeline are restarted)\n* As far as I can tell this happens because the last block is RWR and getReplicaVisibleLength returns -1 for this. The recovery starts after hard lease limit expires (so file is readable only after 1 hour).\n* one can call recoverLease which will start the lease recovery sooner, BUT, how can one know when to call this? The exception thrown is IOException which can happen for other reasons.\n\nI think a reasonable solution would be to return a specialized exception (similar to AlreadyBeingCreatedException when trying to write to open file).","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12791542","id":"12791542","filename":"Main.java","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bograd","name":"bograd","key":"bograd","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Bogdan Raducanu","active":true,"timeZone":"Europe/Amsterdam"},"created":"2016-03-04T21:53:22.181+0000","size":1781,"mimeType":"text/x-java","content":"https://issues.apache.org/jira/secure/attachment/12791542/Main.java"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"Can't read file after hdfs restart","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bograd","name":"bograd","key":"bograd","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Bogdan Raducanu","active":true,"timeZone":"Europe/Amsterdam"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bograd","name":"bograd","key":"bograd","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Bogdan Raducanu","active":true,"timeZone":"Europe/Amsterdam"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12947103/comment/15225381","id":"15225381","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xiaochen","name":"xiaochen","key":"xiaochen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=xiaochen&avatarId=24893","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=xiaochen&avatarId=24893","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=xiaochen&avatarId=24893","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=xiaochen&avatarId=24893"},"displayName":"Xiao Chen","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks for reporting this Bogdan. I'd like to work on this.\n\nThe test program attached actually passes on trunk. I further tested on branch-2.7 and it fails. The reason for this is that we have HDFS-5356 which automatically closes DFS on trunk.\n\nTo double check this, if I change the {{FileSystem}} to {{DistributedFileSystem}}, and call {{close}} before shutdown, the test passes on branch-2.7 as well.\n{code:java}\n\t\t/* start cluster and write something */\n//\t\tFileSystem fs = cluster.getFileSystem();\n\t\tDistributedFileSystem fs = cluster.getFileSystem();    // <=========== change to DFS\n\t\tFSDataOutputStream out = fs.create(path, true);\n\t\tout.write(bytes);\n\t\tout.hflush();\n\t\t/* stop cluster while file is open for writing */\n\t\tcluster.shutdown();\n\t\tfs.close();    // <=========== move this line up by 1\n                ....\n{code}\n\nSo now comes the original question: what if the client didn't call {{DFS#close}}, and HDFS restarts? Currently the file lease is revoked after the hard limit (1hr). Before that READ fails (e.g. {{cp: Cannot obtain block length for ...}}). This is because {{fs.delete}} or {{fs.create}} will remove the lease, but {{fs.open}} will not.\n\nSince it's the read that fails, I don't think it's a good idea to recover the lease on the read operation. One possible solution is perhaps to detect this and revoke on restart. I need to further investigate and will update here. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xiaochen","name":"xiaochen","key":"xiaochen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=xiaochen&avatarId=24893","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=xiaochen&avatarId=24893","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=xiaochen&avatarId=24893","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=xiaochen&avatarId=24893"},"displayName":"Xiao Chen","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-04-05T00:31:14.806+0000","updated":"2016-04-05T00:31:14.806+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12947103/comment/15226494","id":"15226494","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bograd","name":"bograd","key":"bograd","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Bogdan Raducanu","active":true,"timeZone":"Europe/Amsterdam"},"body":"OK, thanks.\nMy first idea was to just signal this case through a special exception, e.g. ReplicaWaitingRecoveryException which is reported to the client app. Then, the client app can choose what to do. In my case, when I get this exception, I would call DFSClient.recoverLease to trigger the lease recovery and open again after this. That's what I do in the write case, before the soft limit expires.\nIn fact, as a workaround, I do this even for reading now, just now I get a generic exception. Just an idea. Maybe you find something better.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bograd","name":"bograd","key":"bograd","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Bogdan Raducanu","active":true,"timeZone":"Europe/Amsterdam"},"created":"2016-04-05T15:47:43.852+0000","updated":"2016-04-05T15:47:43.852+0000"}],"maxResults":2,"total":2,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-9909/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i2u6g7:"}}