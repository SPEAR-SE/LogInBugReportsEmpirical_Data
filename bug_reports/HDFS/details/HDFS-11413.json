{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"13042855","self":"https://issues.apache.org/jira/rest/api/2/issue/13042855","key":"HDFS-11413","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/10004","id":"10004","description":"Not A Bug","name":"Not A Bug"},"customfield_12312322":null,"customfield_12310220":"2017-02-14T08:12:46.437+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Tue Feb 14 08:12:46 UTC 2017","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_173857896_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2017-02-16T08:19:25.261+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-11413/watchers","watchCount":2,"isWatching":false},"created":"2017-02-14T08:01:47.430+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[],"issuelinks":[],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2017-02-16T08:19:25.317+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[],"timeoriginalestimate":null,"description":"I have open source hadoop version 2.7.3 cluster (2 Masters + 3 Slaves) installed on AWS EC2 instances. I am using the cluster to integrate it with Kafka Connect. \n\nThe setup of cluster was done last month and setup of kafka connect was completed last fortnight. Since then, we were able to operate the kafka topic records on our HDFS and do various operations.\n\nSince last afternoon, I find that any kafka topic is not getting committed to the cluster. When I tried to open the older files, I started getting below error. When I copy a new file to the cluster from local, it comes and gets opened but after some time, again starts showing similar IOException:\n\n==========================================================\n17/02/14 07:57:55 INFO hdfs.DFSClient: No node available for BP-1831277630-10.16.37.124-1484306078618:blk_1073793876_55013 file=/test/inputdata/derby.log\n17/02/14 07:57:55 INFO hdfs.DFSClient: Could not obtain BP-1831277630-10.16.37.124-1484306078618:blk_1073793876_55013 from any node: java.io.IOException: No live nodes contain block BP-1831277630-10.16.37.124-1484306078618:blk_1073793876_55013 after checking nodes = [], ignoredNodes = null No live nodes contain current block Block locations: Dead nodes: . Will get new block locations from namenode and retry...\n17/02/14 07:57:55 WARN hdfs.DFSClient: DFS chooseDataNode: got # 1 IOException, will wait for 499.3472970548959 msec.\n17/02/14 07:57:55 INFO hdfs.DFSClient: No node available for BP-1831277630-10.16.37.124-1484306078618:blk_1073793876_55013 file=/test/inputdata/derby.log\n17/02/14 07:57:55 INFO hdfs.DFSClient: Could not obtain BP-1831277630-10.16.37.124-1484306078618:blk_1073793876_55013 from any node: java.io.IOException: No live nodes contain block BP-1831277630-10.16.37.124-1484306078618:blk_1073793876_55013 after checking nodes = [], ignoredNodes = null No live nodes contain current block Block locations: Dead nodes: . Will get new block locations from namenode and retry...\n17/02/14 07:57:55 WARN hdfs.DFSClient: DFS chooseDataNode: got # 2 IOException, will wait for 4988.873277172643 msec.\n17/02/14 07:58:00 INFO hdfs.DFSClient: No node available for BP-1831277630-10.16.37.124-1484306078618:blk_1073793876_55013 file=/test/inputdata/derby.log\n17/02/14 07:58:00 INFO hdfs.DFSClient: Could not obtain BP-1831277630-10.16.37.124-1484306078618:blk_1073793876_55013 from any node: java.io.IOException: No live nodes contain block BP-1831277630-10.16.37.124-1484306078618:blk_1073793876_55013 after checking nodes = [], ignoredNodes = null No live nodes contain current block Block locations: Dead nodes: . Will get new block locations from namenode and retry...\n17/02/14 07:58:00 WARN hdfs.DFSClient: DFS chooseDataNode: got # 3 IOException, will wait for 8598.311122824263 msec.\n17/02/14 07:58:09 WARN hdfs.DFSClient: Could not obtain block: BP-1831277630-10.16.37.124-1484306078618:blk_1073793876_55013 file=/test/inputdata/derby.log No live nodes contain current block Block locations: Dead nodes: . Throwing a BlockMissingException\n17/02/14 07:58:09 WARN hdfs.DFSClient: Could not obtain block: BP-1831277630-10.16.37.124-1484306078618:blk_1073793876_55013 file=/test/inputdata/derby.log No live nodes contain current block Block locations: Dead nodes: . Throwing a BlockMissingException\n17/02/14 07:58:09 WARN hdfs.DFSClient: DFS Read\norg.apache.hadoop.hdfs.BlockMissingException: Could not obtain block: BP-1831277630-10.16.37.124-1484306078618:blk_1073793876_55013 file=/test/inputdata/derby.log\n        at org.apache.hadoop.hdfs.DFSInputStream.chooseDataNode(DFSInputStream.java:983)\n        at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:642)\n        at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:882)\n        at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)\n        at java.io.DataInputStream.read(DataInputStream.java:100)\n        at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:85)\n        at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:59)\n        at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:119)\n        at org.apache.hadoop.fs.shell.Display$Cat.printToStdout(Display.java:107)\n        at org.apache.hadoop.fs.shell.Display$Cat.processPath(Display.java:102)\n        at org.apache.hadoop.fs.shell.Command.processPaths(Command.java:317)\n        at org.apache.hadoop.fs.shell.Command.processPathArgument(Command.java:289)\n        at org.apache.hadoop.fs.shell.Command.processArgument(Command.java:271)\n        at org.apache.hadoop.fs.shell.Command.processArguments(Command.java:255)\n        at org.apache.hadoop.fs.shell.Command.processRawArguments(Command.java:201)\n        at org.apache.hadoop.fs.shell.Command.run(Command.java:165)\n        at org.apache.hadoop.fs.FsShell.run(FsShell.java:287)\n        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)\n        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:84)\n        at org.apache.hadoop.fs.FsShell.main(FsShell.java:340)\ncat: Could not obtain block: BP-1831277630-10.16.37.124-1484306078618:blk_1073793876_55013 file=/test/inputdata/derby.log\n==========================================================\n\nWhen I do : hdfs fsck / , I get:\n==========================================================\n Total size:    667782677 B\n Total dirs:    406\n Total files:   44485\n Total symlinks:                0\n Total blocks (validated):      43767 (avg. block size 15257 B)\n  ********************************\n  UNDER MIN REPL'D BLOCKS:      43766 (99.99772 %)\n  dfs.namenode.replication.min: 1\n  CORRUPT FILES:        43766\n  MISSING BLOCKS:       43766\n  MISSING SIZE:         667781648 B\n  CORRUPT BLOCKS:       43766\n  ********************************\n Minimally replicated blocks:   1 (0.0022848265 %)\n Over-replicated blocks:        0 (0.0 %)\n Under-replicated blocks:       0 (0.0 %)\n Mis-replicated blocks:         0 (0.0 %)\n Default replication factor:    3\n Average block replication:     6.8544796E-5\n Corrupt blocks:                43766\n Missing replicas:              0 (0.0 %)\n Number of data-nodes:          3\n Number of racks:               1\nFSCK ended at Tue Feb 14 07:59:10 UTC 2017 in 932 milliseconds\n\n\nThe filesystem under path '/' is CORRUPT\n==========================================================\n\nThat means, all my files got corrupted somehow. \n\nI want to recover my HDFS and fix the corrupt health status. Also, I would like to understand, how such an issue occurred suddenly and how to prevent it in future?\n\nMany thanks,\nNishant Verma ","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12333995","id":"12333995","description":"2.7.3 release","name":"2.7.3","archived":false,"released":true,"releaseDate":"2016-08-25"}],"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"HDFS fsck command shows health as corrupt for '/'","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=NishantVerma","name":"NishantVerma","key":"nishantverma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Nishant Verma","active":true,"timeZone":"Etc/UTC"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=NishantVerma","name":"NishantVerma","key":"nishantverma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Nishant Verma","active":true,"timeZone":"Etc/UTC"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/13042855/comment/15865333","id":"15865333","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cheersyang","name":"cheersyang","key":"cheersyang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cheersyang&avatarId=23772","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cheersyang&avatarId=23772","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cheersyang&avatarId=23772","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cheersyang&avatarId=23772"},"displayName":"Weiwei Yang","active":true,"timeZone":"Asia/Shanghai"},"body":"Hi [~NishantVerma]\n\nCan you post this to user mailing list or stack overflow instead? JIRA is used to track bugs/dev-tasks, not user issues.\nI suggest you to take a look at namenode/datanode logs see if something goes wrong.\nThanks","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cheersyang","name":"cheersyang","key":"cheersyang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cheersyang&avatarId=23772","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cheersyang&avatarId=23772","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cheersyang&avatarId=23772","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cheersyang&avatarId=23772"},"displayName":"Weiwei Yang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-02-14T08:12:46.437+0000","updated":"2017-02-14T08:14:13.943+0000"}],"maxResults":1,"total":1,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-11413/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i3a1lz:"}}