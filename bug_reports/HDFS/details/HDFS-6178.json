{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12705847","self":"https://issues.apache.org/jira/rest/api/2/issue/12705847","key":"HDFS-6178","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12326264","id":"12326264","description":"2.5.0 release","name":"2.5.0","archived":false,"released":true,"releaseDate":"2014-08-11"}],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2014-04-01T04:04:11.259+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Tue Apr 22 15:01:22 UTC 2014","customfield_12310420":"384171","customfield_12312320":null,"customfield_12310222":"10002_*:*_1_*:*_1229592080_*|*_1_*:*_1_*:*_570998866_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2014-04-21T23:38:02.753+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-6178/watchers","watchCount":9,"isWatching":false},"created":"2014-04-01T03:28:11.845+0000","customfield_12310192":null,"customfield_12310191":[{"self":"https://issues.apache.org/jira/rest/api/2/customFieldOption/10343","value":"Reviewed","id":"10343"}],"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"2.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[],"issuelinks":[],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mingma","name":"mingma","key":"mingma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ming Ma","active":true,"timeZone":"America/Los_Angeles"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2014-08-15T05:41:21.818+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12312926","id":"12312926","name":"namenode"}],"timeoriginalestimate":null,"description":"Currently decommissioning machines in HA-enabled cluster requires running refreshNodes in both active and standby nodes. Sometimes decommissioning won't finish from standby NN's point of view.  Here is the diagnosis of why it could happen.\n\nStandby NN's blockManager manages blocks replication and block invalidation as if it is the active NN; even though DNs will ignore block commands coming from standby NN. When standby NN makes block operation decisions such as the target of block replication and the node to remove excess blocks from, the decision is independent of active NN. So active NN and standby NN could have different states. When we try to decommission nodes on standby nodes; such state inconsistency might prevent standby NN from making progress. Here is an example.\n\nMachine A\nMachine B\nMachine C\nMachine D\nMachine E\nMachine F\nMachine G\nMachine H\n\n1. For a given block, both active and standby have 5 replicas on machine A, B, C, D, E. So both active and standby decide to pick excess nodes to invalidate.\n\nActive picked D and E as excess DNs. After the next block reports from D and E, active NN has 3 active replicas (A, B, C), 0 excess replica.\n\n{noformat}\n2014-03-27 01:50:14,410 INFO BlockStateChange: BLOCK* chooseExcessReplicates: (E:50010, blk_-5207804474559026159_121186764) is added to invalidated blocks set\n2014-03-27 01:50:15,539 INFO BlockStateChange: BLOCK* chooseExcessReplicates: (D:50010, blk_-5207804474559026159_121186764) is added to invalidated blocks set\n{noformat}\n\nStandby pick C, E as excess DNs. Given DNs ignore commands from standby, After the next block reports from C, D, E,  standby has 2 active replicas (A, B), 1 excess replica (C).\n\n{noformat}\n2014-03-27 01:51:49,543 INFO BlockStateChange: BLOCK* chooseExcessReplicates: (E:50010, blk_-5207804474559026159_121186764) is added to invalidated blocks set\n2014-03-27 01:51:49,894 INFO BlockStateChange: BLOCK* chooseExcessReplicates: (C:50010, blk_-5207804474559026159_121186764) is added to invalidated blocks set\n{noformat}\n\n\n2. Machine A decomm request was sent to standby. Standby only had one live replica and picked machine G, H as targets, but given standby commands was ignored by DNs, G, H remained in pending replication queue until they are timed out. At this point, you have one decommissioning replica (A), 1 active replica (B), one excess replica (C).\n{noformat}\n2014-03-27 04:42:52,258 INFO BlockStateChange: BLOCK* ask A:50010 to replicate blk_-5207804474559026159_121186764 to datanode(s) G:50010 H:50010\n{noformat}\n\n3. Machine A decomm request was sent to active NN. Active NN picked machine F as the target. It finished properly. So active NN had 3 active replicas (B, C, F), one decommissioned replica (A).\n\n{noformat}\n2014-03-27 04:44:15,239 INFO BlockStateChange: BLOCK* ask 10.42.246.110:50010 to replicate blk_-5207804474559026159_121186764 to datanode(s) F:50010\n2014-03-27 04:44:16,083 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: F:50010 is added to blk_-5207804474559026159_121186764 size 7100065\n{noformat}\n\n4. Standby NN picked up F as a new replica. Thus standby had one decommissioning replica (A), 2 active replicas (B, F), one excess replica (C). Standby NN kept trying to schedule replication work, but DNs ignored the commands.\n\n{noformat}\n2014-03-27 04:44:16,084 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: F:50010 is added to blk_-5207804474559026159_121186764 size 7100065\n\n2014-03-28 23:06:11,970 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Block: blk_-5207804474559026159_121186764, Expected Replicas: 3, live replicas: 2, corrupt replicas: 0, decommissioned replicas: 1, excess replicas: 1, Is Open File: false, Datanodes having this block: C:50010 B:50010 A:50010 F:50010 , Current Datanode: A:50010, Is current datanode decommissioning: true\n{noformat}","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12639019","id":"12639019","filename":"HDFS-6178.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mingma","name":"mingma","key":"mingma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ming Ma","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-04-07T17:26:44.443+0000","size":14440,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12639019/HDFS-6178.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12639289","id":"12639289","filename":"HDFS-6178-2.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mingma","name":"mingma","key":"mingma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ming Ma","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-04-08T22:53:40.297+0000","size":14816,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12639289/HDFS-6178-2.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"384439","customfield_12312823":null,"summary":"Decommission on standby NN couldn't finish","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mingma","name":"mingma","key":"mingma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ming Ma","active":true,"timeZone":"America/Los_Angeles"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mingma","name":"mingma","key":"mingma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ming Ma","active":true,"timeZone":"America/Los_Angeles"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12705847/comment/13956077","id":"13956077","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=azuryy","name":"azuryy","key":"azuryy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Fengdong Yu","active":true,"timeZone":"Etc/UTC"},"body":"Thanks for the detail report, but generally, we just decommission DNs on the active node, right?\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=azuryy","name":"azuryy","key":"azuryy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Fengdong Yu","active":true,"timeZone":"Etc/UTC"},"created":"2014-04-01T04:04:11.259+0000","updated":"2014-04-01T04:04:11.259+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12705847/comment/13956101","id":"13956101","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mingma","name":"mingma","key":"mingma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ming Ma","active":true,"timeZone":"America/Los_Angeles"},"body":"Somehow we have to define the proper decommission operation process. We need to update SNN exclude files at some point so that if NN fails over, it can have consistent view of what machines have been decommissioned. For example, we can try something like,\n\n1. Update excludes files on both active and standby.\n2. refreshNodes on active NN. Wait for it to complete. Hope it doesn't fail over before completion.\n3. Don't refreshNodes on SNN. Administrators understand the SNN webUI won't be consistent with active NN.\n4. Some time later after fail over happens, Administrators will refreshNodes on the new active. The new active will try to decomm these nodes again and quickly find out blocks on these nodes have sufficient replicas somewhere.\n\nHowever, failover can happen during decomm, ideally we want to have preserve the decomm state over to the new active, for example via Zookeeper.\n\nBTW, why does standby NN need to manage under replication and over replication given DNs will ignore them anyway?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mingma","name":"mingma","key":"mingma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ming Ma","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-04-01T04:49:53.771+0000","updated":"2014-04-01T04:49:53.771+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12705847/comment/13956163","id":"13956163","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mingma","name":"mingma","key":"mingma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ming Ma","active":true,"timeZone":"America/Los_Angeles"},"body":"To handle the automatic failover scenario, maybe we can have old SNN invoke refreshNodes when it becomes active NN. That will allow the decomm to continue.\n\nIf we don't want to allow people to run \"dfsadmin -refreshNodes\" on SNN, perhaps we want to improve the tool and webUI to provide the proper status.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mingma","name":"mingma","key":"mingma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ming Ma","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-04-01T06:36:02.996+0000","updated":"2014-04-01T06:36:02.996+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12705847/comment/13957028","id":"13957028","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jingzhao","name":"jingzhao","key":"jingzhao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jing Zhao","active":true,"timeZone":"America/Los_Angeles"},"body":"I guess we can let people only run refreshNodes on ANN. In that case, we may have the following:\n# If the decommission finishes before any NN failover, the scenarios in the description can happen, i.e., SBN may have made inconsistent decision and keep trying the decommission. However, its commands will be ignored by DNs. And when failover happens, since the original SBN will clear all the replication queue and cached DN commands, finally this NN will generate the replication queues based on the correct information.\n# If NN failover happens during the the decommission (the replication for the decommission is still on-going), still, the original SBN will clear all the replication queues and re-initialize them based on incoming block reports. Then if we run the refreshNodes on this NN, the NN may achieve a correct decision.\n# We may want to disable the replication monitor for the SBN so that it will not try to send replication/invalidate commands to DNs.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jingzhao","name":"jingzhao","key":"jingzhao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jing Zhao","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-04-01T21:23:44.276+0000","updated":"2014-04-01T21:23:44.276+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12705847/comment/13957308","id":"13957308","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mingma","name":"mingma","key":"mingma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ming Ma","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks, Jing, Fengdong. It sounds like we can go with the \"only decomm ANN\" approach; the correctness can be guaranteed. However, it will be useful to further simplify the operations and improve SBN webUI quality. To summarize operational steps.\n\nOption 1 - No code change; people have to ignore SBN webUI as the data is misleading.\n1. Update excludes files on both ANN and SBN.\n2. Run \"dfsadmin -refreshNodes\" only on ANN. Wait for it to complete.\n3. If decomm finishes before any failover, do nothing. SBN webUI doesn't have updated node status.\n4. If there is a failover before decomm, someone or script external to HDFS has to run \"dfsadmin -refreshNodes\" on the new ANN so that decomm can continue.\n\nOption 2 - Code change to simplify the process and SBN web UI.\n1. When old SBN become new ANN, it calls refreshNodes in FSNamesystem.startActiveServices. With this, option 1's step 4 can be skipped.\n2. SBN can throws some exception when someone tries to run \"dfsadmin -refreshNodes\". That will make it clear not to run the command on SBN.\n3. Make SBN webUI correct. For example, it can choose not to display # of dead/live/decommissioning/decommissioned nodes. Such data could become stale overtime people update include and exclude files but only run \"dfsadmin -refreshNodes\" on ANN.\n\nSeparately I can open another jira to disable the replication monitor for SBN.\n\nAny comments?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mingma","name":"mingma","key":"mingma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ming Ma","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-04-02T03:51:03.970+0000","updated":"2014-04-02T03:51:03.970+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12705847/comment/13957959","id":"13957959","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jingzhao","name":"jingzhao","key":"jingzhao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jing Zhao","active":true,"timeZone":"America/Los_Angeles"},"body":"Actually we do not need to push the refreshNodes in SBN to after failover? We can run refreshNodes in ANN and SBN around the same time and just disable the replication monitor for SBN. In that case the only side effect is that SBN can have a different internal view about replication.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jingzhao","name":"jingzhao","key":"jingzhao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jing Zhao","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-04-02T18:01:25.172+0000","updated":"2014-04-02T18:01:25.172+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12705847/comment/13958035","id":"13958035","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mingma","name":"mingma","key":"mingma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ming Ma","active":true,"timeZone":"America/Los_Angeles"},"body":"Ah, good point. If we disable the replication monitor for SBN, refreshNodes on SBN will still put nodes in decommissioning state, eventually after data is replicated to other nodes, SBN webUI will show those nodes have been decommissioned.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mingma","name":"mingma","key":"mingma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ming Ma","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-04-02T18:56:12.984+0000","updated":"2014-04-02T18:56:12.984+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12705847/comment/13958051","id":"13958051","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"body":"Is this issue same as HDFS-3744?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-04-02T19:09:13.331+0000","updated":"2014-04-02T19:09:13.331+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12705847/comment/13958528","id":"13958528","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mingma","name":"mingma","key":"mingma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ming Ma","active":true,"timeZone":"America/Los_Angeles"},"body":"Uma, I think they are related. Although it seems the patch in HDFS-3744 tries to enable the ability to run \"dfsadmin -refreshNode\" once to hit both ANN and SBN. This jira tried to address the inconsistent state between ANN and SBN after you run \"dfsadmin -refreshNode\" on both ANN and SBN, regardless of whether you run \"dfsadmin -refreshNode\" once or sequentially on ANN and SBN.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mingma","name":"mingma","key":"mingma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ming Ma","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-04-03T05:24:17.667+0000","updated":"2014-04-03T05:24:17.667+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12705847/comment/13962035","id":"13962035","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mingma","name":"mingma","key":"mingma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ming Ma","active":true,"timeZone":"America/Los_Angeles"},"body":"Here is the fix. Couple notes:\n\n1. It seems the code has already prevent SBN from updating excess blocks for common case like addStoredBlock. The case that is missing is node recommission scenario. So the fix is at recommission layer instead of fixing it inside processOverReplicatedBlock.\n2. The fix in ReplicationMonitor to not do replication work isn't necessary to address this specific issue.\n3. The fix has been tested manually in a real cluster. The added test case reproduced the excess replica scenario.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mingma","name":"mingma","key":"mingma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ming Ma","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-04-07T17:26:44.448+0000","updated":"2014-04-07T17:26:44.448+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12705847/comment/13962243","id":"13962243","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:green}+1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12639019/HDFS-6178.patch\n  against trunk revision .\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.\n\n    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/6604//testReport/\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/6604//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2014-04-07T20:56:00.781+0000","updated":"2014-04-07T20:56:00.781+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12705847/comment/13963464","id":"13963464","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jingzhao","name":"jingzhao","key":"jingzhao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jing Zhao","active":true,"timeZone":"America/Los_Angeles"},"body":"The patch looks pretty good to me. One question: do we also want to add the isPopulatingReplQueues() check in BlockManager#isReplicationInProgress, when it adds the block to neededReplications?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jingzhao","name":"jingzhao","key":"jingzhao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jing Zhao","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-04-08T21:25:28.871+0000","updated":"2014-04-08T21:25:28.871+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12705847/comment/13963571","id":"13963571","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mingma","name":"mingma","key":"mingma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ming Ma","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks, Jing. Updated patch per suggestion.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mingma","name":"mingma","key":"mingma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ming Ma","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-04-08T22:53:40.302+0000","updated":"2014-04-08T22:53:40.302+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12705847/comment/13963717","id":"13963717","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:green}+1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12639289/HDFS-6178-2.patch\n  against trunk revision .\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.\n\n    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/6623//testReport/\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/6623//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2014-04-09T02:16:59.756+0000","updated":"2014-04-09T02:16:59.756+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12705847/comment/13976185","id":"13976185","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jingzhao","name":"jingzhao","key":"jingzhao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jing Zhao","active":true,"timeZone":"America/Los_Angeles"},"body":"+1 for the latest patch. I will commit it shortly.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jingzhao","name":"jingzhao","key":"jingzhao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jing Zhao","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-04-21T23:33:21.651+0000","updated":"2014-04-21T23:33:21.651+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12705847/comment/13976193","id":"13976193","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jingzhao","name":"jingzhao","key":"jingzhao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jing Zhao","active":true,"timeZone":"America/Los_Angeles"},"body":"I've committed this to trunk and branch-2. Thanks for the contribution, [~mingma]!","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jingzhao","name":"jingzhao","key":"jingzhao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jing Zhao","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-04-21T23:38:02.779+0000","updated":"2014-04-21T23:38:02.779+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12705847/comment/13976204","id":"13976204","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"SUCCESS: Integrated in Hadoop-trunk-Commit #5547 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/5547/])\nHDFS-6178. Decommission on standby NN couldn't finish. Contributed by Ming Ma. (jing9: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1589002)\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDecommission.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2014-04-21T23:46:18.749+0000","updated":"2014-04-21T23:46:18.749+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12705847/comment/13976757","id":"13976757","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"SUCCESS: Integrated in Hadoop-Yarn-trunk #548 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/548/])\nHDFS-6178. Decommission on standby NN couldn't finish. Contributed by Ming Ma. (jing9: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1589002)\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDecommission.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2014-04-22T13:30:46.626+0000","updated":"2014-04-22T13:30:46.626+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12705847/comment/13976803","id":"13976803","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"SUCCESS: Integrated in Hadoop-Hdfs-trunk #1740 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1740/])\nHDFS-6178. Decommission on standby NN couldn't finish. Contributed by Ming Ma. (jing9: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1589002)\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDecommission.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2014-04-22T14:04:40.938+0000","updated":"2014-04-22T14:04:40.938+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12705847/comment/13976885","id":"13976885","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"SUCCESS: Integrated in Hadoop-Mapreduce-trunk #1765 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1765/])\nHDFS-6178. Decommission on standby NN couldn't finish. Contributed by Ming Ma. (jing9: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1589002)\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDecommission.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2014-04-22T15:01:22.530+0000","updated":"2014-04-22T15:01:22.530+0000"}],"maxResults":20,"total":20,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-6178/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i1u6nr:"}}