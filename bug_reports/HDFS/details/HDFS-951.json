{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12455379","self":"https://issues.apache.org/jira/rest/api/2/issue/12455379","key":"HDFS-951","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/8","id":"8","description":"The described issue is not actually a problem - it is as designed.","name":"Not A Problem"},"customfield_12312322":null,"customfield_12310220":"2010-02-05T15:05:55.926+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Thu Apr 03 02:40:54 UTC 2014","customfield_12310420":"16688","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_131154748244_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2014-04-03T02:40:54.855+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-951/watchers","watchCount":9,"isWatching":false},"created":"2010-02-05T02:48:26.657+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[],"issuelinks":[{"id":"12333814","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12333814","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"inwardIssue":{"id":"12387571","key":"HDFS-278","self":"https://issues.apache.org/jira/rest/api/2/issue/12387571","fields":{"summary":"Should DFS outputstream's close wait forever?","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/4","id":"4","description":"An improvement or enhancement to an existing feature or task.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype","name":"Improvement","subtask":false,"avatarId":21140}}}}],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2014-04-03T02:40:54.897+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[],"timeoriginalestimate":null,"description":"processDatanodeError-> setupPipelineForAppendOrRecovery  will set streamerClosed to be true if all nodes in the pipeline failed in the past, and just return.\nBack to run() in data streammer,  the logic \n if (streamerClosed || hasError || dataQueue.size() == 0 || !clientRunning) {\n                continue;\n  }\nwill just let set closed=true in closeInternal().\n\nAnd DataOutputStream will not get a chance to clean up. The DataOutputStream will throw exception or return null for following write/close.\nIt will leave the file in writing in incomplete state.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"113235","customfield_12312823":null,"summary":"DFSClient should handle all nodes in a pipeline failed.","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=he+yongqiang","name":"he yongqiang","key":"he yongqiang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"He Yongqiang","active":true,"timeZone":"Etc/UTC"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=he+yongqiang","name":"he yongqiang","key":"he yongqiang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"He Yongqiang","active":true,"timeZone":"Etc/UTC"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12455379/comment/12830125","id":"12830125","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"body":"If all datanodes in the pipleline are dead, then the application cannot write anymore to the file. (This can be improved, of course). Are you saying that throwing exceptions to the write/close call (after all datanodes in pipeline have failed) is a problem? \n\nOr are you saying that when all datanodes in the pipeline fail, all resources associated with that OutputStream should be automatically released?\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"created":"2010-02-05T15:05:55.926+0000","updated":"2010-02-05T15:05:55.926+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12455379/comment/12830136","id":"12830136","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=he+yongqiang","name":"he yongqiang","key":"he yongqiang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"He Yongqiang","active":true,"timeZone":"Etc/UTC"},"body":"Throwing exception at future close() and write() is perfectly fine.\n\nI am saying the second one. \nAlso the file will leave in incomplete/being create state if that DfsClient  instance does not get a chance to close. (which is common for many daemon apps which use hdfs as the backend). ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=he+yongqiang","name":"he yongqiang","key":"he yongqiang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"He Yongqiang","active":true,"timeZone":"Etc/UTC"},"created":"2010-02-05T15:33:04.076+0000","updated":"2010-02-05T15:33:04.076+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12455379/comment/12830148","id":"12830148","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"What version are you seeing this issue in? I noticed something similar when producing HDFS-915 on trunk, but haven't seen it on 0.20.1","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2010-02-05T16:04:17.384+0000","updated":"2010-02-05T16:04:17.384+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12455379/comment/12830447","id":"12830447","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=he+yongqiang","name":"he yongqiang","key":"he yongqiang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"He Yongqiang","active":true,"timeZone":"Etc/UTC"},"body":"@Todd,\nThe problem was seen in hadoop-0.19.2, not sure about 0.20.1","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=he+yongqiang","name":"he yongqiang","key":"he yongqiang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"He Yongqiang","active":true,"timeZone":"Etc/UTC"},"created":"2010-02-06T03:51:25.336+0000","updated":"2010-02-06T03:51:25.336+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12455379/comment/12830448","id":"12830448","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=he+yongqiang","name":"he yongqiang","key":"he yongqiang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"He Yongqiang","active":true,"timeZone":"Etc/UTC"},"body":"Btw, the code line in the description is from trunk. It seems the problem is still there in the client code.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=he+yongqiang","name":"he yongqiang","key":"he yongqiang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"He Yongqiang","active":true,"timeZone":"Etc/UTC"},"created":"2010-02-06T03:55:00.702+0000","updated":"2010-02-06T03:55:00.702+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12455379/comment/12830456","id":"12830456","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"I'm not quite understanding what you're describing, I think.\n\nIf all of the datanodes fail, the last block is in an indeterminate state - we don't know what length ever made it to the DNs, so we can't really close the file properly. I suppose we could use the length from the last acked seqno, but the DNs will still have the replicas in the \"rbw\" state. There is some kind of state transition for recovery of rbw replicas described in the HDFS-265 document - I don't recall off the top of my head if it will function if none of the DNs are up.\n\nIf you wait an hour for the hard lease limit, does the file end up in some kind of state that you expect?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2010-02-06T04:36:37.298+0000","updated":"2010-02-06T04:36:37.298+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12455379/comment/12830479","id":"12830479","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=he+yongqiang","name":"he yongqiang","key":"he yongqiang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"He Yongqiang","active":true,"timeZone":"Etc/UTC"},"body":">>If all of the datanodes fail, the last block is in an indeterminate state\nYes, i knew this is main problem.  i think there should be some policy for handling that.\n>>If you wait an hour for the hard lease limit\ni am not sure if i get what i expect after one hour. But it will be not nice at all for users with respect their user experience. for example, if you upload a file to a website and you get to know sth after 1 hour, how that would be? (this is just an example, and of course there are workarounds for this example.)","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=he+yongqiang","name":"he yongqiang","key":"he yongqiang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"He Yongqiang","active":true,"timeZone":"Etc/UTC"},"created":"2010-02-06T06:13:16.262+0000","updated":"2010-02-06T06:13:16.262+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12455379/comment/12830480","id":"12830480","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dongtalk%40gmail.com","name":"dongtalk@gmail.com","key":"dongtalk@gmail.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yajun Dong","active":true,"timeZone":"Etc/UTC"},"body":"> Also the file will leave in incomplete/being create state if that DfsClient instance does not get a chance to close.\n> But it will be not nice at all for users with respect their user experience. \nAgreed. \n\nI come across this problem, DFSClient should complete those creating files when IOExceptions encoutered. \n\nBut Normally we could not complete these files successfully before all blocks of creating files are reported to NameNode, In short: the last block is in indeterminate state at this time.\n\nin this case, the only one option I think is delete the last failing block and then complete/close the file.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dongtalk%40gmail.com","name":"dongtalk@gmail.com","key":"dongtalk@gmail.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yajun Dong","active":true,"timeZone":"Etc/UTC"},"created":"2010-02-06T06:27:44.993+0000","updated":"2010-02-06T06:27:44.993+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12455379/comment/12901124","id":"12901124","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"body":"This is actually more general that just a hang-on-close. A writer will not be able to allocate a new block for a file if a  previous (penultimate) block does not have any good replica. this case does happen in real-life if all the existing replicas of a block happen to fail, thus making the application hang indefinitely. can we somehow allow the application to get an IO error and bail out from the write/close call?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"created":"2010-08-22T02:32:33.853+0000","updated":"2010-08-22T02:32:33.853+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12455379/comment/13958467","id":"13958467","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"body":"I guess that this is not a problem anymore. Please feel free to reopen this if I am wrong. Resolving ...","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-04-03T02:40:54.893+0000","updated":"2014-04-03T02:40:54.893+0000"}],"maxResults":10,"total":10,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-951/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i0jqkn:"}}