{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"13103161","self":"https://issues.apache.org/jira/rest/api/2/issue/13103161","key":"HDFS-12487","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":"2017-09-19T16:38:16.200+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Tue Mar 20 22:49:32 UTC 2018","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":0,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-12487/watchers","watchCount":4,"isWatching":false},"created":"2017-09-19T07:25:29.897+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"2.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":0,"aggregatetimeoriginalestimate":0,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12341433","id":"12341433","description":"3.0.0 GA release","name":"3.0.0","archived":false,"released":true,"releaseDate":"2017-12-13"}],"issuelinks":[],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=liumihust","name":"liumihust","key":"liumihust","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10445","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10445","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10445","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10445"},"displayName":"liumi","active":true,"timeZone":"Etc/UTC"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2018-03-20T22:49:32.936+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/10002","description":"A patch for this issue has been uploaded to JIRA by a contributor.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/document.png","name":"Patch Available","id":"10002","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/4","id":4,"key":"indeterminate","colorName":"yellow","name":"In Progress"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12313153","id":"12313153","name":"balancer & mover"},{"self":"https://issues.apache.org/jira/rest/api/2/component/12330206","id":"12330206","name":"diskbalancer"}],"timeoriginalestimate":0,"description":"BlockIteratorImpl.nextBlock() will look for the blocks in the source volume, if there are no blocks any more, it will return null up to DiskBalancer.getBlockToCopy(). However, the DiskBalancer.getBlockToCopy() will check whether it's a valid block.\nWhen I look into the FsDatasetSpi.isValidBlock(), I find that it doesn't check the null pointer! In fact, we firstly need to check whether it's null or not, or exception will occur.\nThis bug is hard to find, because the DiskBalancer hardly copy all the data of one volume to others. Even if some times we may copy all the data of one volume to other volumes, when the bug occurs, the copy process has already done.\nHowever, when we try to copy all the data of two or more volumes to other volumes in more than one step, the thread will be shut down, which is caused by the bug above.\nThe bug can fixed by two ways:\n1)Before the call of FsDatasetSpi.isValidBlock(), we check the null pointer\n2)Check the null pointer inside the implementation of FsDatasetSpi.isValidBlock()","customfield_10010":null,"timetracking":{"originalEstimate":"0h","remainingEstimate":"0h","originalEstimateSeconds":0,"remainingEstimateSeconds":0},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12342772","id":"12342772","description":"","name":"3.2.0","archived":false,"released":false}],"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12888223","id":"12888223","filename":"HDFS-12487.002.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=liumihust","name":"liumihust","key":"liumihust","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10445","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10445","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10445","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10445"},"displayName":"liumi","active":true,"timeZone":"Etc/UTC"},"created":"2017-09-21T06:59:16.609+0000","size":969,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12888223/HDFS-12487.002.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12888415","id":"12888415","filename":"HDFS-12487.003.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=liumihust","name":"liumihust","key":"liumihust","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10445","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10445","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10445","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10445"},"displayName":"liumi","active":true,"timeZone":"Etc/UTC"},"created":"2017-09-22T01:44:27.256+0000","size":987,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12888415/HDFS-12487.003.patch"}],"aggregatetimeestimate":0,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"FsDatasetSpi.isValidBlock() lacks null pointer check inside and neither do the callers","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=liumihust","name":"liumihust","key":"liumihust","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10445","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10445","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10445","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10445"},"displayName":"liumi","active":true,"timeZone":"Etc/UTC"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=liumihust","name":"liumihust","key":"liumihust","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10445","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10445","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10445","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10445"},"displayName":"liumi","active":true,"timeZone":"Etc/UTC"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":"CentOS 6.8 x64\nCPU:4 core\nMemory:16GB\nHadoop: Release 3.0.0-alpha4\n","customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/13103161/comment/16172000","id":"16172000","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=anu","name":"anu","key":"anu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Anu Engineer","active":true,"timeZone":"America/Los_Angeles"},"body":"[~liumihust] Welcome to Apache. Thanks for filing this.  Generally we attach a patch (diff file) of sources to a JIRA to indicate to Jenkins that it needs to pick up this change and build/test the changes you are proposing.\n\nHere is the process to do that.\n\n1. Get the Hadoop Code base --> \"*git clone http;//github.....*\"\n2. make the changes in code -- in this case the if check that you want to add.\n3. compile the code base --  I usually run '*mvn clean install -DskipTests=true -Dmaven.javadoc.skip=true -DskipShade*'\n4. If the build works, please create a patch -- **git diff  > ~/HDFS-12487.001.patch**  or *git diff  --no-prefix > ~/HDFS-12487.001.patch*\n5. Then you can make sure that your patch works, the following commands will clean the git repo --\n   *git reset --hard; git clean -f -d*\"\n6. Now we can test the patch -- from your hadoop directory please run '*./dev-support/bin/smart-apply-patch ~/HDFS-12487.001.patch*'\n7. This will apply the patch locally which means that Jenkins will be able to apply it too.\n8. I generally run one more step, I clean the directory again and I run \"*/dev-support/bin/test-patch ~/HDFS-12487.001.patch*\" This will flag checkstyle, findbugs issues that Jenkins would spot for you, so you can avoid a around of fixing and updating the patch. The report will contain file names which you need to open to find out what is the real issue.\n9. Once all of this is done, you come to JIRA, click on More->Attach files \n10. Then submit patch, Jenkins will pick up your patch, apply to Hadoop trunk, run all tests and other tools and create a report. \n11. Then one of the contributors/comitters will give you coe review comments or help you to commit the patch.\n\nI really appreciate you taking the effort to bring your patch to Apache. In case you want a better reference here is the link to the HowToContribute Hadoop Wiki.\n\nhttps://wiki.apache.org/hadoop/HowToContribute\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=anu","name":"anu","key":"anu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Anu Engineer","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-09-19T16:38:16.200+0000","updated":"2017-09-19T16:38:16.200+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13103161/comment/16172012","id":"16172012","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=anu","name":"anu","key":"anu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Anu Engineer","active":true,"timeZone":"America/Los_Angeles"},"body":"[~liumihust] I have added you to the contributors list, So you can assign these JIRAs to yourself. Right now I am assigning this to you. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=anu","name":"anu","key":"anu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Anu Engineer","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-09-19T16:49:44.463+0000","updated":"2017-09-19T16:49:44.463+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13103161/comment/16172563","id":"16172563","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=liumihust","name":"liumihust","key":"liumihust","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10445","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10445","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10445","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10445"},"displayName":"liumi","active":true,"timeZone":"Etc/UTC"},"body":"[~anu] Thank you.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=liumihust","name":"liumihust","key":"liumihust","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10445","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10445","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10445","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10445"},"displayName":"liumi","active":true,"timeZone":"Etc/UTC"},"created":"2017-09-20T01:00:06.946+0000","updated":"2017-09-20T01:00:06.946+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13103161/comment/16172775","id":"16172775","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 16m  7s{color} | {color:blue} Docker mode activated. {color} |\n|| || || || {color:brown} Prechecks {color} ||\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |\n|| || || || {color:brown} trunk Compile Tests {color} ||\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 14m 30s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 50s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 37s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 55s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 43s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 41s{color} | {color:green} trunk passed {color} |\n|| || || || {color:brown} Patch Compile Tests {color} ||\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 49s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 47s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 47s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 33s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 54s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 50s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 37s{color} | {color:green} the patch passed {color} |\n|| || || || {color:brown} Other Tests {color} ||\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}118m 31s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 37s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black}161m 18s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| Failed junit tests | hadoop.hdfs.server.datanode.TestDirectoryScanner |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure090 |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure150 |\n|   | hadoop.hdfs.server.datanode.fsdataset.impl.TestLazyPersistReplicaRecovery |\n|   | hadoop.hdfs.TestTrashWithEncryptionZones |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure050 |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure080 |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure070 |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure160 |\n| Timed out junit tests | org.apache.hadoop.hdfs.TestFileChecksum |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:71bbb86 |\n| JIRA Issue | HDFS-12487 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12888004/HDFS-12487.001.patch |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux b436984e4e1b 3.13.0-129-generic #178-Ubuntu SMP Fri Aug 11 12:48:20 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / a9019e1 |\n| Default Java | 1.8.0_144 |\n| findbugs | v3.1.0-RC1 |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/21233/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |\n|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/21233/testReport/ |\n| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/21233/console |\n| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2017-09-20T05:52:12.639+0000","updated":"2017-09-20T05:52:12.639+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13103161/comment/16173432","id":"16173432","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=anu","name":"anu","key":"anu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Anu Engineer","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks for the patch. I know the first time it is a lot of work to set up the system. Thanks for doing that.\n\nOne small review comment: Can we please add a Log statement before we return?\nI was thinking something like this.\n{code}\nLOG.info(\"NextBlock call returned null. No valid blocks to copy.  {}\", item.toJson());\n{code}\n\nWhen you attach the next patch, just increment the 001. to be 002, That is, please name your new patch {{HDFS-12487.002.patch}}\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=anu","name":"anu","key":"anu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Anu Engineer","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-09-20T16:19:42.000+0000","updated":"2017-09-20T17:55:59.662+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13103161/comment/16174505","id":"16174505","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 19s{color} | {color:blue} Docker mode activated. {color} |\n|| || || || {color:brown} Prechecks {color} ||\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |\n|| || || || {color:brown} trunk Compile Tests {color} ||\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 14m  0s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 53s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 37s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 56s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 44s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 41s{color} | {color:green} trunk passed {color} |\n|| || || || {color:brown} Patch Compile Tests {color} ||\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 49s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 46s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 46s{color} | {color:green} the patch passed {color} |\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 33s{color} | {color:orange} hadoop-hdfs-project/hadoop-hdfs: The patch generated 1 new + 3 unchanged - 0 fixed = 4 total (was 3) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 55s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m  1s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 39s{color} | {color:green} the patch passed {color} |\n|| || || || {color:brown} Other Tests {color} ||\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}116m 31s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 17s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black}143m  3s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| Failed junit tests | hadoop.hdfs.server.datanode.TestDataNodeErasureCodingMetrics |\n|   | hadoop.hdfs.server.blockmanagement.TestBlockStatsMXBean |\n|   | hadoop.hdfs.TestErasureCodeBenchmarkThroughput |\n|   | hadoop.hdfs.server.namenode.TestFsck |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:71bbb86 |\n| JIRA Issue | HDFS-12487 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12888223/HDFS-12487.002.patch |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux 4fcab466122a 3.13.0-123-generic #172-Ubuntu SMP Mon Jun 26 18:04:35 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / 8b33663 |\n| Default Java | 1.8.0_144 |\n| findbugs | v3.1.0-RC1 |\n| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/21268/artifact/patchprocess/diff-checkstyle-hadoop-hdfs-project_hadoop-hdfs.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/21268/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |\n|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/21268/testReport/ |\n| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/21268/console |\n| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2017-09-21T09:34:43.686+0000","updated":"2017-09-21T09:34:43.686+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13103161/comment/16174947","id":"16174947","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=anu","name":"anu","key":"anu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Anu Engineer","active":true,"timeZone":"America/Los_Angeles"},"body":"[~liumihust] Thank you for the fix. Once Jenkins runs it gives us some feedback. In this patch, everything looks good except for a small checkstyle issue.\n\nhttps://builds.apache.org/job/PreCommit-HDFS-Build/21268/artifact/patchprocess/diff-checkstyle-hadoop-hdfs-project_hadoop-hdfs.txt\n\nPlease click on the link above ( copied from the Jenkins report above)\n\nGenerally, I would have said I will fix that issue while committing, but part of the reason we are doing this JIRA is to get you familiar with how Apache works, so you can bring in all the cool stuff you have done already. \n\nAlso when we update the patches we leave the older version of the code in place. So when you fix this checkStyle issues, please create a new file {{HDFS-12487.003.patch}} and attach it. You don't need to remove the {{.002} patch Jenkins will automatically pick up the latest version.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=anu","name":"anu","key":"anu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Anu Engineer","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-09-21T15:30:52.976+0000","updated":"2017-09-21T15:30:52.976+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13103161/comment/16175850","id":"16175850","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 34s{color} | {color:blue} Docker mode activated. {color} |\n|| || || || {color:brown} Prechecks {color} ||\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |\n|| || || || {color:brown} trunk Compile Tests {color} ||\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 14m  3s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 55s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 38s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 59s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 46s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 42s{color} | {color:green} trunk passed {color} |\n|| || || || {color:brown} Patch Compile Tests {color} ||\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 54s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 50s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 50s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 35s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 54s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 52s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 38s{color} | {color:green} the patch passed {color} |\n|| || || || {color:brown} Other Tests {color} ||\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 80m  5s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  1m  5s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black}107m 53s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| Failed junit tests | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure000 |\n|   | hadoop.hdfs.server.namenode.ha.TestHAAppend |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure210 |\n|   | hadoop.hdfs.TestReadStripedFileWithMissingBlocks |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure130 |\n|   | hadoop.hdfs.TestDistributedFileSystem |\n|   | hadoop.hdfs.TestReconstructStripedFile |\n|   | hadoop.hdfs.security.TestDelegationTokenForProxyUser |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure030 |\n| Timed out junit tests | org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshot |\n|   | org.apache.hadoop.hdfs.server.namenode.snapshot.TestRenameWithSnapshots |\n|   | org.apache.hadoop.hdfs.server.namenode.TestINodeAttributeProvider |\n|   | org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData |\n|   | org.apache.hadoop.hdfs.server.namenode.TestNNStorageRetentionFunctional |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:71bbb86 |\n| JIRA Issue | HDFS-12487 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12888415/HDFS-12487.003.patch |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux c0b5e55cc9b4 3.13.0-129-generic #178-Ubuntu SMP Fri Aug 11 12:48:20 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / bfd1a72 |\n| Default Java | 1.8.0_144 |\n| findbugs | v3.1.0-RC1 |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/21289/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |\n|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/21289/testReport/ |\n| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/21289/console |\n| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2017-09-22T03:40:55.314+0000","updated":"2017-09-22T03:40:55.314+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13103161/comment/16407187","id":"16407187","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=genericqa","name":"genericqa","key":"genericqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=genericqa&avatarId=33630","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=genericqa&avatarId=33630","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=genericqa&avatarId=33630","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=genericqa&avatarId=33630"},"displayName":"genericqa","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 19s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |\r\n|| || || || {color:brown} trunk Compile Tests {color} ||\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 19m 44s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m  1s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 52s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  7s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 12m 32s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 55s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 48s{color} | {color:green} trunk passed {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m  7s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m  0s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  1m  0s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 53s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  7s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 11m 43s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 18s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 49s{color} | {color:green} the patch passed {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 80m 30s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 24s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black}137m 53s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Reason || Tests ||\r\n| Failed junit tests | hadoop.hdfs.server.namenode.TestNameNodeMetadataConsistency |\r\n|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:d4cc50f |\r\n| JIRA Issue | HDFS-12487 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12888415/HDFS-12487.003.patch |\r\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |\r\n| uname | Linux 80435b134fab 3.13.0-139-generic #188-Ubuntu SMP Tue Jan 9 14:43:09 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | /testptch/patchprocess/precommit/personality/provided.sh |\r\n| git revision | trunk / fe224ff |\r\n| maven | version: Apache Maven 3.3.9 |\r\n| Default Java | 1.8.0_151 |\r\n| findbugs | v3.1.0-RC1 |\r\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/23573/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |\r\n|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/23573/testReport/ |\r\n| Max. process+thread count | 3546 (vs. ulimit of 10000) |\r\n| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |\r\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/23573/console |\r\n| Powered by | Apache Yetus 0.8.0-SNAPSHOT   http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=genericqa","name":"genericqa","key":"genericqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=genericqa&avatarId=33630","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=genericqa&avatarId=33630","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=genericqa&avatarId=33630","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=genericqa&avatarId=33630"},"displayName":"genericqa","active":true,"timeZone":"Etc/UTC"},"created":"2018-03-20T22:49:32.936+0000","updated":"2018-03-20T22:49:32.936+0000"}],"maxResults":9,"total":9,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-12487/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i3k80v:"}}