{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"13071789","self":"https://issues.apache.org/jira/rest/api/2/issue/13071789","key":"HDFS-11821","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/3","id":"3","description":"The problem is a duplicate of an existing issue.","name":"Duplicate"},"customfield_12312322":null,"customfield_12310220":"2017-05-14T21:58:03.822+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Fri Aug 17 11:47:00 UTC 2018","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_2501433_*|*_3_*:*_2_*:*_72254386_*|*_5_*:*_1_*:*_0_*|*_10002_*:*_1_*:*_39713173812","customfield_12312321":null,"resolutiondate":"2018-08-17T11:47:00.381+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-11821/watchers","watchCount":7,"isWatching":false},"created":"2017-05-13T23:34:50.767+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/4","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/minor.svg","name":"Minor","id":"4"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"2.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12327181","id":"12327181","description":"2.6.0 release","name":"2.6.0","archived":false,"released":true,"releaseDate":"2014-11-18"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12337976","id":"12337976","name":"3.0.0-alpha2","archived":false,"released":true,"releaseDate":"2017-01-25"}],"issuelinks":[],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wchevreuil","name":"wchevreuil","key":"wchevreuil","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wellington Chevreuil","active":true,"timeZone":"Europe/London"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2018-08-17T11:47:00.396+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12329603","id":"12329603","name":"hdfs"}],"timeoriginalestimate":null,"description":"*BlockManager* keeps a separate metric for number of missing blocks with replication factor of 1. This is returned by *BlockManager.getMissingReplOneBlocksCount()* method currently, and that's what is displayed on below attribute for *dfsadmin -report* (in below example, there's one corrupt block that relates to a file with replication factor of 1):\n\n{noformat}\n...\nMissing blocks (with replication factor 1): 1\n...\n{noformat}\n\nHowever, if the related file gets deleted, (for instance, using hdfs fsck -delete option), this metric never gets updated, and *dfsadmin -report* will keep reporting a missing block, even though the file does not exist anymore. The only workaround available is to restart the NN, so that this metric will be cleared.\n\nThis can be easily reproduced by forcing a replication factor 1 file corruption such as follows:\n\n1) Put a file into hdfs with replication factor 1:\n\n{noformat}\n$ hdfs dfs -Ddfs.replication=1 -put test_corrupt /\n$ hdfs dfs -ls /\n\n-rw-r--r--   1 hdfs     supergroup         19 2017-05-10 09:21 /test_corrupt\n\n{noformat}\n\n2) Find related block for the file and delete it from DN:\n\n{noformat}\n$ hdfs fsck /test_corrupt -files -blocks -locations\n\n...\n/test_corrupt 19 bytes, 1 block(s):  OK\n0. BP-782213640-172.31.113.82-1494420317936:blk_1073742742_1918 len=19 Live_repl=1 [DatanodeInfoWithStorage[172.31.112.178:20002,DS-a0dc0b30-a323-4087-8c36-26ffdfe44f46,DISK]]\n\nStatus: HEALTHY\n...\n\n$ find /dfs/dn/ -name blk_1073742742*\n\n/dfs/dn/current/BP-782213640-172.31.113.82-1494420317936/current/finalized/subdir0/subdir3/blk_1073742742\n/dfs/dn/current/BP-782213640-172.31.113.82-1494420317936/current/finalized/subdir0/subdir3/blk_1073742742_1918.meta\n\n$ rm -rf /dfs/dn/current/BP-782213640-172.31.113.82-1494420317936/current/finalized/subdir0/subdir3/blk_1073742742\n$ rm -rf /dfs/dn/current/BP-782213640-172.31.113.82-1494420317936/current/finalized/subdir0/subdir3/blk_1073742742_1918.meta\n\n{noformat}\n\n3) Running fsck will report the corruption as expected:\n\n{noformat}\n$ hdfs fsck /test_corrupt -files -blocks -locations\n\n...\n/test_corrupt 19 bytes, 1 block(s): \n/test_corrupt: CORRUPT blockpool BP-782213640-172.31.113.82-1494420317936 block blk_1073742742\n MISSING 1 blocks of total size 19 B\n...\nTotal blocks (validated):\t1 (avg. block size 19 B)\n  ********************************\n  UNDER MIN REPL'D BLOCKS:\t1 (100.0 %)\n  dfs.namenode.replication.min:\t1\n  CORRUPT FILES:\t1\n  MISSING BLOCKS:\t1\n  MISSING SIZE:\t\t19 B\n  CORRUPT BLOCKS: \t1\n...\n{noformat}\n\n4) Same for *dfsadmin -report*\n\n{noformat}\n$ hdfs dfsadmin -report\n...\nUnder replicated blocks: 1\nBlocks with corrupt replicas: 0\nMissing blocks: 1\nMissing blocks (with replication factor 1): 1\n...\n{noformat}\n\n5) Running *fsck -delete* option does cause fsck to report correct information about corrupt block, but dfsadmin still shows the corrupt block:\n\n{noformat}\n\n$ hdfs fsck /test_corrupt -delete\n...\n$ hdfs fsck /\n...\nThe filesystem under path '/' is HEALTHY\n...\n\n$ hdfs dfsadmin -report\n...\nUnder replicated blocks: 0\nBlocks with corrupt replicas: 0\nMissing blocks: 0\nMissing blocks (with replication factor 1): 1\n...\n{noformat}\n\nThe problem seems to be on *BlockManager.removeBlock()* method, which in turn uses util class *LowRedundancyBlocks* that classifies blocks according to the current replication level, including blocks currently marked as corrupt. \n\nThe related metric showed on *dfsadmin -report* for corrupt blocks with replication factor 1 is tracked on this *LowRedundancyBlocks*. Whenever a block is marked as corrupt and it has replication factor of 1, the related metric is updated. When removing the block, though, *BlockManager.removeBlock()* is calling *LowRedundancyBlocks.remove(BlockInfo block, int priLevel)*, which does not check if the given block was previously marked as corrupt and had replication factor 1, which would require for updating the metric.\n\nAm shortly proposing a patch that seems to fix this by making *BlockManager.removeBlock()*  call *LowRedundancyBlocks.remove(BlockInfo block, int oldReplicas, int oldReadOnlyReplicas, int outOfServiceReplicas, int oldExpectedReplicas)* instead, which does update the metric properly.\n","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12867968","id":"12867968","filename":"HDFS-11821-1.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wchevreuil","name":"wchevreuil","key":"wchevreuil","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wellington Chevreuil","active":true,"timeZone":"Europe/London"},"created":"2017-05-13T23:49:50.880+0000","size":3722,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12867968/HDFS-11821-1.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12867997","id":"12867997","filename":"HDFS-11821-2.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wchevreuil","name":"wchevreuil","key":"wchevreuil","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wellington Chevreuil","active":true,"timeZone":"Europe/London"},"created":"2017-05-14T20:14:28.160+0000","size":3727,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12867997/HDFS-11821-2.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"BlockManager.getMissingReplOneBlocksCount() does not report correct value if corrupt file with replication factor of 1 gets deleted","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wchevreuil","name":"wchevreuil","key":"wchevreuil","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wellington Chevreuil","active":true,"timeZone":"Europe/London"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wchevreuil","name":"wchevreuil","key":"wchevreuil","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wellington Chevreuil","active":true,"timeZone":"Europe/London"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/13071789/comment/16009553","id":"16009553","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wchevreuil","name":"wchevreuil","key":"wchevreuil","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wellington Chevreuil","active":true,"timeZone":"Europe/London"},"body":"First patch with initial solution proposed, plus unit test for this scenario.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wchevreuil","name":"wchevreuil","key":"wchevreuil","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wellington Chevreuil","active":true,"timeZone":"Europe/London"},"created":"2017-05-13T23:49:50.888+0000","updated":"2017-05-13T23:49:50.888+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13071789/comment/16009834","id":"16009834","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wchevreuil","name":"wchevreuil","key":"wchevreuil","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wellington Chevreuil","active":true,"timeZone":"Europe/London"},"body":"Submitting a 2nd patch with checkstyles fixes.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wchevreuil","name":"wchevreuil","key":"wchevreuil","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wellington Chevreuil","active":true,"timeZone":"Europe/London"},"created":"2017-05-14T20:14:28.171+0000","updated":"2017-05-14T20:14:28.171+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13071789/comment/16009865","id":"16009865","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 23s{color} | {color:blue} Docker mode activated. {color} |\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 2 new or modified test files. {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 13m 31s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 49s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 39s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 52s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 15s{color} | {color:green} trunk passed {color} |\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  1m 40s{color} | {color:red} hadoop-hdfs-project/hadoop-hdfs in trunk has 10 extant Findbugs warnings. {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 41s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 47s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 45s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 45s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 35s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 50s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 12s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 44s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 37s{color} | {color:green} the patch passed {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 63m 38s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 19s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black} 89m 39s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| Failed junit tests | hadoop.hdfs.TestMaintenanceState |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure080 |\n|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting |\n|   | hadoop.hdfs.TestDFSRSDefault10x4StripedOutputStreamWithFailure |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:14b5c93 |\n| JIRA Issue | HDFS-11821 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12867997/HDFS-11821-2.patch |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux 9009754900a3 3.13.0-107-generic #154-Ubuntu SMP Tue Dec 20 09:57:27 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / 6600abb |\n| Default Java | 1.8.0_121 |\n| findbugs | v3.1.0-RC1 |\n| findbugs | https://builds.apache.org/job/PreCommit-HDFS-Build/19430/artifact/patchprocess/branch-findbugs-hadoop-hdfs-project_hadoop-hdfs-warnings.html |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/19430/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |\n|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/19430/testReport/ |\n| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/19430/console |\n| Powered by | Apache Yetus 0.5.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2017-05-14T21:58:03.822+0000","updated":"2017-05-14T21:58:03.822+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13071789/comment/16010913","id":"16010913","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wchevreuil","name":"wchevreuil","key":"wchevreuil","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wellington Chevreuil","active":true,"timeZone":"Europe/London"},"body":"I had reviewed the failed tests, but it does not seem related to the code changed on this patch. This are not failing on my local builder either. Please let me know on any suggestions and/or possible improvements.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wchevreuil","name":"wchevreuil","key":"wchevreuil","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wellington Chevreuil","active":true,"timeZone":"Europe/London"},"created":"2017-05-15T17:07:39.312+0000","updated":"2017-05-15T17:07:39.312+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13071789/comment/16153288","id":"16153288","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wchevreuil","name":"wchevreuil","key":"wchevreuil","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wellington Chevreuil","active":true,"timeZone":"Europe/London"},"body":"Any feedbacks?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wchevreuil","name":"wchevreuil","key":"wchevreuil","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wellington Chevreuil","active":true,"timeZone":"Europe/London"},"created":"2017-09-05T08:50:23.881+0000","updated":"2017-09-05T08:50:23.881+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13071789/comment/16153459","id":"16153459","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 13s{color} | {color:blue} Docker mode activated. {color} |\n|| || || || {color:brown} Prechecks {color} ||\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 2 new or modified test files. {color} |\n|| || || || {color:brown} trunk Compile Tests {color} ||\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 14m 14s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 48s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 40s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 55s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 42s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 42s{color} | {color:green} trunk passed {color} |\n|| || || || {color:brown} Patch Compile Tests {color} ||\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 48s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 45s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 45s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 36s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 50s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 45s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 37s{color} | {color:green} the patch passed {color} |\n|| || || || {color:brown} Other Tests {color} ||\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 91m  9s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 16s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black}117m 15s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| Failed junit tests | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure140 |\n|   | hadoop.hdfs.TestFileAppendRestart |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure080 |\n|   | hadoop.hdfs.TestReadStripedFileWithDecoding |\n|   | hadoop.hdfs.TestLeaseRecoveryStriped |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure120 |\n|   | hadoop.hdfs.TestPipelines |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure070 |\n| Timed out junit tests | org.apache.hadoop.hdfs.TestWriteReadStripedFile |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:71bbb86 |\n| JIRA Issue | HDFS-11821 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12867997/HDFS-11821-2.patch |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux ef38ac3f9bec 3.13.0-119-generic #166-Ubuntu SMP Wed May 3 12:18:55 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / ed162b7 |\n| Default Java | 1.8.0_144 |\n| findbugs | v3.1.0-RC1 |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/20998/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |\n|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/20998/testReport/ |\n| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/20998/console |\n| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2017-09-05T10:48:20.262+0000","updated":"2017-09-05T10:48:20.262+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13071789/comment/16154282","id":"16154282","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"body":"Thank you for the report Wellington! I'm sorry you didn't get adequate attention for the issue until now.\n\nI have confirmed that the problem is easily replicated thanks to your detailed instructions on trunk (3.1.0-SNAPSHOT). (Except for one minor addition: I had to -cat the file for HDFS to recognize that the file was corrupt). Thank you also for the patch. I'll review it shortly.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-09-05T20:50:12.400+0000","updated":"2017-09-05T22:38:28.097+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13071789/comment/16154536","id":"16154536","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"body":"My concern with your patch is that remove will now be a bit slower. I think I remember there used to be a time when deletes were holding up the lock for a long time. [~kihwal] Do you have an objection?\n\nI'm also wondering what happens when the information returned by {{countNodes}} is inaccurate (i.e. HDFS hasn't yet realized that the block is corrupt)\n\nAlso, the test failures seem related.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-09-05T23:11:36.730+0000","updated":"2017-09-05T23:11:36.730+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13071789/comment/16158762","id":"16158762","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wchevreuil","name":"wchevreuil","key":"wchevreuil","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wellington Chevreuil","active":true,"timeZone":"Europe/London"},"body":"Thanks for the review and relevant comments [~raviprak]! Regarding the tests, I have these passing locally. Also, apart from *hadoop.hdfs.TestDFSStripedOutputStreamWithFailure080*, these are totally different from previous build. Also, I don't think the patch changes would influence pipeline/append/reads, as it's only concerning to metrics update. Pasting test output snippets from my local build:\n\n{noformat}\n-------------------------------------------------------\n T E S T S\n-------------------------------------------------------\nRunning org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure140\nTests run: 14, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 85.39 sec - in org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure140\n\nResults :\n\nTests run: 14, Failures: 0, Errors: 0, Skipped: 0\n...\n-------------------------------------------------------\n T E S T S\n-------------------------------------------------------\nRunning org.apache.hadoop.hdfs.TestFileAppendRestart\nTests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 14.935 sec - in org.apache.hadoop.hdfs.TestFileAppendRestart\n\nResults :\n\nTests run: 3, Failures: 0, Errors: 0, Skipped: 0\n...\nRunning org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure080\nTests run: 14, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 121.347 sec - in org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure080\n\nResults :\n\nTests run: 14, Failures: 0, Errors: 0, Skipped: 0\n...\n-------------------------------------------------------\n T E S T S\n-------------------------------------------------------\nRunning org.apache.hadoop.hdfs.TestReadStripedFileWithDecoding\nTests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 75.274 sec - in org.apache.hadoop.hdfs.TestReadStripedFileWithDecoding\n\nResults :\n\nTests run: 5, Failures: 0, Errors: 0, Skipped: 0\n...\n-------------------------------------------------------\n T E S T S\n-------------------------------------------------------\nRunning org.apache.hadoop.hdfs.TestLeaseRecoveryStriped\nTests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 36.307 sec - in org.apache.hadoop.hdfs.TestLeaseRecoveryStriped\n\nResults :\n\nTests run: 1, Failures: 0, Errors: 0, Skipped: 0\n...\n-------------------------------------------------------\n T E S T S\n-------------------------------------------------------\nRunning org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure120\nTests run: 14, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 62.726 sec - in org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure120\n\nResults :\n\nTests run: 14, Failures: 0, Errors: 0, Skipped: 0\n...\n-------------------------------------------------------\n T E S T S\n-------------------------------------------------------\nRunning org.apache.hadoop.hdfs.TestPipelines\nTests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.92 sec - in org.apache.hadoop.hdfs.TestPipelines\n\nResults :\n\nTests run: 1, Failures: 0, Errors: 0, Skipped: 0\n...\n-------------------------------------------------------\n T E S T S\n-------------------------------------------------------\nRunning org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure070\nTests run: 14, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 81.293 sec - in org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure070\n\nResults :\n\nTests run: 14, Failures: 0, Errors: 0, Skipped: 0\n...\n-------------------------------------------------------\n T E S T S\n-------------------------------------------------------\nRunning org.apache.hadoop.hdfs.TestWriteReadStripedFile\nTests run: 17, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 73.311 sec - in org.apache.hadoop.hdfs.TestWriteReadStripedFile\n\nResults :\n\nTests run: 17, Failures: 0, Errors: 0, Skipped: 0\n{noformat} \n\nbq. My concern with your patch is that remove will now be a bit slower. I think I remember there used to be a time when deletes were holding up the lock for a long time. Kihwal Lee Do you have an objection?\nI guess the major concern here is that *countNodes* method iterates over the block *StorageInfo* objects, checking the replica state on each storage to decide how is replication health. I suppose this is limited by the block replication factor, so it wouldn't be large loop. Is this a correct assumption or would there still be some other overheads that could impact delete performance?\n\nbq. I'm also wondering what happens when the information returned by countNodes is inaccurate (i.e. HDFS hasn't yet realized that the block is corrupt)\nIn that case, I believe the block would not be on any of the priority queues from *LowRedundancyBlocks*. Call to *LowRedundancyBlocks.remove* would not find any block then, so no counters would be updated, what I think is the correct behaviour. What do you feel?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wchevreuil","name":"wchevreuil","key":"wchevreuil","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wellington Chevreuil","active":true,"timeZone":"Europe/London"},"created":"2017-09-08T15:04:57.849+0000","updated":"2017-09-08T15:04:57.849+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13071789/comment/16202602","id":"16202602","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wchevreuil","name":"wchevreuil","key":"wchevreuil","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wellington Chevreuil","active":true,"timeZone":"Europe/London"},"body":"Any insights from anyone?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wchevreuil","name":"wchevreuil","key":"wchevreuil","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wellington Chevreuil","active":true,"timeZone":"Europe/London"},"created":"2017-10-12T20:50:15.118+0000","updated":"2017-10-12T20:50:15.118+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13071789/comment/16211803","id":"16211803","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi Wellington!\r\nThanks for your explanation. I'm sorry I've been tardy on this issue. Thank you for the ping. I took some time to step through the debugger and understand what's going on. If you set a breakpoint [here|https://github.com/apache/hadoop/blob/4ab0c8f96a41c573cc1f1e71c18871d243f952b9/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/LowRedundancyBlocks.java#L378], you'll see that remove is being called with priority level 5. Hence the check on [line 385|https://github.com/apache/hadoop/blob/4ab0c8f96a41c573cc1f1e71c18871d243f952b9/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/LowRedundancyBlocks.java#L385] is failing (which would correctly allow corruptReplicationOneBlocks to be decremented). I just tested this small fix which doesn't increase the time taken to delete the blocks : \r\n{code}\r\n$ git diff\r\ndiff --git a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/LowRedundancyBlocks.java b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/LowRedundancyBlocks.java\r\nindex 347d606a04e..e3f228d2947 100644\r\n--- a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/LowRedundancyBlocks.java\r\n+++ b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/LowRedundancyBlocks.java\r\n@@ -365,7 +365,7 @@ boolean remove(BlockInfo block, int priLevel, int oldExpectedReplicas) {\r\n           NameNode.blockStateChangeLog.debug(\r\n               \"BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block\" +\r\n                   \" {} from priority queue {}\", block, i);\r\n-          decrementBlockStat(block, priLevel, oldExpectedReplicas);\r\n+          decrementBlockStat(block, i, oldExpectedReplicas);\r\n           return true;\r\n         }\r\n       }\r\n{code}\r\nCould you please test this too?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-10-19T21:52:53.091+0000","updated":"2017-10-19T21:52:53.091+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13071789/comment/16558006","id":"16558006","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shashikant","name":"shashikant","key":"shashikant","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Shashikant Banerjee","active":true,"timeZone":"Asia/Kolkata"},"body":"[~raviprak], [~wchevreuil], I think this issue is addressed with HDFS-13048.  Can you please confirm?\r\n\r\n ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shashikant","name":"shashikant","key":"shashikant","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Shashikant Banerjee","active":true,"timeZone":"Asia/Kolkata"},"created":"2018-07-26T07:26:55.470+0000","updated":"2018-07-26T07:26:55.470+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13071789/comment/16558010","id":"16558010","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=genericqa","name":"genericqa","key":"genericqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=genericqa&avatarId=33630","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=genericqa&avatarId=33630","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=genericqa&avatarId=33630","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=genericqa&avatarId=33630"},"displayName":"genericqa","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m  0s{color} | {color:blue} Docker mode activated. {color} |\r\n| {color:red}-1{color} | {color:red} patch {color} | {color:red}  0m  6s{color} | {color:red} HDFS-11821 does not apply to trunk. Rebase required? Wrong Branch? See https://wiki.apache.org/hadoop/HowToContribute for help. {color} |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| JIRA Issue | HDFS-11821 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12867997/HDFS-11821-2.patch |\r\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/24660/console |\r\n| Powered by | Apache Yetus 0.8.0-SNAPSHOT   http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=genericqa","name":"genericqa","key":"genericqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=genericqa&avatarId=33630","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=genericqa&avatarId=33630","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=genericqa&avatarId=33630","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=genericqa&avatarId=33630"},"displayName":"genericqa","active":true,"timeZone":"Etc/UTC"},"created":"2018-07-26T07:30:39.388+0000","updated":"2018-07-26T07:30:39.388+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13071789/comment/16583810","id":"16583810","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wchevreuil","name":"wchevreuil","key":"wchevreuil","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wellington Chevreuil","active":true,"timeZone":"Europe/London"},"body":"Hi [~shashikant], [~raviprak],\r\n\r\nThanks for your reviews. The code base for trunk branch from where this proposed patch was created didn't have *decrementBlockStat* calls inside *removeBlock* method [~raviprak] mentioned in his last comment. The [~raviprak] suggested does fix this issue.\r\n\r\n \r\n\r\nAlso, HDFS-13048 seems to fix the problem, as mentioned by [~shashikant]. So I guess we are good to close this jira. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wchevreuil","name":"wchevreuil","key":"wchevreuil","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wellington Chevreuil","active":true,"timeZone":"Europe/London"},"created":"2018-08-17T11:45:23.891+0000","updated":"2018-08-17T11:45:23.891+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13071789/comment/16583813","id":"16583813","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wchevreuil","name":"wchevreuil","key":"wchevreuil","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wellington Chevreuil","active":true,"timeZone":"Europe/London"},"body":"This had taken too much to be reviewed, so a newer Jira HDFS-13048 ended up fixing this. Thank you all for the pointers.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wchevreuil","name":"wchevreuil","key":"wchevreuil","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Wellington Chevreuil","active":true,"timeZone":"Europe/London"},"created":"2018-08-17T11:47:00.393+0000","updated":"2018-08-17T11:47:00.393+0000"}],"maxResults":15,"total":15,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-11821/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i3exxj:"}}