{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12709014","self":"https://issues.apache.org/jira/rest/api/2/issue/12709014","key":"HDFS-6254","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/8","id":"8","description":"The described issue is not actually a problem - it is as designed.","name":"Not A Problem"},"customfield_12312322":null,"customfield_12310220":"2014-04-17T12:42:35.019+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Mon Apr 28 02:16:57 UTC 2014","customfield_12310420":"387337","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_636844445_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2014-04-24T18:12:56.163+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-6254/watchers","watchCount":4,"isWatching":false},"created":"2014-04-17T09:18:51.751+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"1.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12325049","id":"12325049","description":"2.2.0 release","name":"2.2.0","archived":false,"released":true,"releaseDate":"2013-10-15"}],"issuelinks":[{"id":"12393651","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12393651","type":{"id":"12310000","name":"Duplicate","inward":"is duplicated by","outward":"duplicates","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/12310000"},"outwardIssue":{"id":"12444379","key":"HDFS-866","self":"https://issues.apache.org/jira/rest/api/2/issue/12444379","fields":{"summary":"libhdfs with gdb got SEGV","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2014-08-07T19:01:45.632+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12313126","id":"12313126","name":"libhdfs","description":"The C++ interface to HDFS."}],"timeoriginalestimate":null,"description":"When namenode is not started, the libhdfs client will cause segment fault while connecting.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12642139","id":"12642139","filename":"test.cpp","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=huangkx","name":"huangkx","key":"huangkx","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"huang ken","active":true,"timeZone":"Asia/Shanghai"},"created":"2014-04-27T15:05:02.448+0000","size":1382,"mimeType":"text/x-c","content":"https://issues.apache.org/jira/secure/attachment/12642139/test.cpp"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"387599","customfield_12312823":null,"summary":"hdfsConnect segment fault where namenode not connected","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=huangkx","name":"huangkx","key":"huangkx","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"huang ken","active":true,"timeZone":"Asia/Shanghai"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=huangkx","name":"huangkx","key":"huangkx","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"huang ken","active":true,"timeZone":"Asia/Shanghai"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":"Linux Centos 64bit","customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12709014/comment/13972891","id":"13972891","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"A lot more information is going to be needed to look at this, especially hadoop version.\n\nBut... any segment fault is invariably one of\n\n# A sign that you're having DRAM errors. \n# a sign of a JVM problem\n# a sign of an OS problem.\n\nI'd guess for #2, with the fix being: update your JVM to version 7u51 -or the openjdk one. If it still surfaces there, this is going to have to be a problem to take up with the JVM team, because it's too removed from the Java code for the Hadoop team to address.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2014-04-17T12:42:35.019+0000","updated":"2014-04-17T12:42:35.019+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12709014/comment/13973439","id":"13973439","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"body":"Shortening description and moving backtrace to comment:\n\nCore was generated by `./test -d'.\nProgram terminated with signal 6, Aborted.\n#0 0x0000003735c328e5 in raise () from /lib64/libc.so.6\nMissing separate debuginfos, use: debuginfo-install glibc-2.12-1.107.el6_4.5.x86_64 jdk-1.7.0_21-fcs.x86_64 keyutils-libs-1.4-4.el6.x86_64 krb5-libs-1.10.3-10.el6_4.6.x86_64 libcom_err-1.41.12-14.el6_4.4.x86_64 libgcc-4.4.7-3.el6.x86_64 libselinux-2.0.94-5.3.el6_4.1.x86_64 libstdc++-4.4.7-3.el6.x86_64 libxml2-2.7.6-12.el6_4.1.x86_64 zlib-1.2.3-29.el6.x86_64\n(gdb) bt\n#0 0x0000003735c328e5 in raise () from /lib64/libc.so.6\n#1 0x0000003735c340c5 in abort () from /lib64/libc.so.6\n#2 0x00007f1beacba865 in os::abort(bool) () from /usr/java/jdk1.7.0_21/jre/lib/amd64/server/libjvm.so\n#3 0x00007f1beae1ab77 in VMError::report_and_die() () from /usr/java/jdk1.7.0_21/jre/lib/amd64/server/libjvm.so\n#4 0x00007f1beacbe370 in JVM_handle_linux_signal () from /usr/java/jdk1.7.0_21/jre/lib/amd64/server/libjvm.so\n#5 <signal handler called>\n#6 0x00007f1beaad8691 in jni_invoke_nonstatic(JNIEnv_, JavaValue, _jobject*, JNICallType, _jmethodID*, JNI_ArgumentPusher*, Thread*) () from /usr/java/jdk1.7.0_21/jre/lib/amd64/server/libjvm.so\n#7 0x00007f1beaaf3ed0 in jni_CallBooleanMethodV () from /usr/java/jdk1.7.0_21/jre/lib/amd64/server/libjvm.so\n#8 0x00007f1beb2a1487 in invokeMethod (env=0x2fd01d8, retval=0x7fff94dcb3f0, methType=INSTANCE, instObj=0x7f1bb8009640, \nclassName=0x7f1beb2a8350 \"org/apache/hadoop/fs/FileSystem\", methName=0x7f1beb2a8674 \"exists\", \nmethSignature=0x7f1beb2a8e90 \"(Lorg/apache/hadoop/fs/Path;)Z\")\nat /home/hkx/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/native/libhdfs/jni_helper.c:252\n#9 0x00007f1beb2a39b5 in hdfsExists (fs=0x7f1bb8009640, path=<value optimized out>)\nat /home/hkx/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/native/libhdfs/hdfs.c:1366\n#10 0x0000000000411561 in CChildProcess::CombineFile (this=0x7fff94dccd20, objFileName=..., vcSortInfo=<value optimized out>, \nfiles_map=Traceback (most recent call last):\nFile \"/usr/lib64/../share/gdb/python/libstdcxx/v6/printers.py\", line 382, in children\nvaluetype = self.val.type.template_argument(1)\nRuntimeError: No type named hdfsFile_internal.\nstd::map with 0 elements, fs=0x7f1bb8009640) at CChildProcess.cpp:267\n#11 0x00000000004120f0 in CChildProcess::Run (this=0x7fff94dccd20) at CChildProcess.cpp:116\n#12 0x000000000040d8cb in CProcessMgr::StartAProcess (this=0x19d1820, strCustomID=\"(\", pChildProcess=0x7fff94dccd20)\nat CProcessMgr.cpp:112\n#13 0x000000000041091e in CTimerService::Run (this=0x7fff94dcd280) at CTimerService.cpp:46\n#14 0x000000000040db74 in main (argc=<value optimized out>, argv=<value optimized out>) at main.cpp:92\n(gdb) quit\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-04-17T21:29:24.164+0000","updated":"2014-04-17T21:29:24.164+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12709014/comment/13973441","id":"13973441","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"body":"I see a hint in the backtrace that this is 2.2.0:\n\n{code}\n#9 0x00007f1beb2a39b5 in hdfsExists (fs=0x7f1bb8009640, path=<value optimized out>)\nat /home/hkx/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/native/libhdfs/hdfs.c:1366\n{code}\n\n[~huangkx], do you happen to know if this happens with the recently release 2.4.0 or current trunk too?\n\nThis is our C code calling back into the Java layer for {{FileSystem#exists}}, so it's possible we're doing something wrong there.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-04-17T21:29:43.391+0000","updated":"2014-04-17T21:29:43.391+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12709014/comment/13975358","id":"13975358","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=huangkx","name":"huangkx","key":"huangkx","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"huang ken","active":true,"timeZone":"Asia/Shanghai"},"body":"I haven't test 2.4.0 or current trunk yet.I'll attach my test result as soon as possible.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=huangkx","name":"huangkx","key":"huangkx","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"huang ken","active":true,"timeZone":"Asia/Shanghai"},"created":"2014-04-21T02:55:54.880+0000","updated":"2014-04-21T02:55:54.880+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12709014/comment/13975468","id":"13975468","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=huangkx","name":"huangkx","key":"huangkx","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"huang ken","active":true,"timeZone":"Asia/Shanghai"},"body":"Steve Loughran, #1. Updated jdk version to 7u55, also segment fault.\nChris Nauroth ,   #2. Updated hadoop version to 2.4.0, also segment fault.\n\nNo matter which version of hadoop i use, hdfsConnect() never return error or NULL, until i call hdfsCreateDirectory() or hdfsExists(), is it right ?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=huangkx","name":"huangkx","key":"huangkx","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"huang ken","active":true,"timeZone":"Asia/Shanghai"},"created":"2014-04-21T07:35:46.885+0000","updated":"2014-04-21T07:35:46.885+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12709014/comment/13975480","id":"13975480","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=huangkx","name":"huangkx","key":"huangkx","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"huang ken","active":true,"timeZone":"Asia/Shanghai"},"body":"Lastest backtrace as followed:\n\n#0  0x0000003735c328e5 in raise () from /lib64/libc.so.6\n#1  0x0000003735c340c5 in abort () from /lib64/libc.so.6\n#2  0x00007fddc4901535 in os::abort(bool) () from /usr/java/jdk1.7.0_55/jre/lib/amd64/server/libjvm.so\n#3  0x00007fddc4a80457 in VMError::report_and_die() () from /usr/java/jdk1.7.0_55/jre/lib/amd64/server/libjvm.so\n#4  0x00007fddc4905ebf in JVM_handle_linux_signal () from /usr/java/jdk1.7.0_55/jre/lib/amd64/server/libjvm.so\n#5  <signal handler called>\n#6  0x00007fddc471dac8 in jni_invoke_nonstatic(JNIEnv_*, JavaValue*, _jobject*, JNICallType, _jmethodID*, JNI_ArgumentPusher*, Thread*) () from /usr/java/jdk1.7.0_55/jre/lib/amd64/server/libjvm.so\n#7  0x00007fddc4730629 in jni_CallBooleanMethodV () from /usr/java/jdk1.7.0_55/jre/lib/amd64/server/libjvm.so\n#8  0x00007fddc4f59847 in invokeMethod (env=0x15de9e8, retval=0x7fffa6d2bbd0, methType=INSTANCE, instObj=0x2074998, \n    className=0x7fddc4f603d0 \"org/apache/hadoop/fs/FileSystem\", methName=0x7fddc4f60692 \"mkdirs\", \n    methSignature=0x7fddc4f61038 \"(Lorg/apache/hadoop/fs/Path;)Z\")\n    at /home/hkx/hadoop-2.4.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/native/libhdfs/jni_helper.c:252\n#9  0x00007fddc4f5affa in hdfsCreateDirectory (fs=0x2074998, path=0x7fffa6d2c308 \"/tmp/root/00000629/\")\n    at /home/hkx/hadoop-2.4.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/native/libhdfs/hdfs.c:1865\n#10 0x00000000004115f3 in CChildProcess::CombineFile (this=0x7fffa6d2d510, objFileName=..., vcSortInfo=<value optimized out>, \n    files_map=Traceback (most recent call last):\n  File \"/usr/lib64/../share/gdb/python/libstdcxx/v6/printers.py\", line 382, in children\n    valuetype = self.val.type.template_argument(1)\nRuntimeError: No type named hdfsFile_internal.\nstd::map with 0 elements, fs=0x2074998) at CChildProcess.cpp:283\n#11 0x00000000004120f4 in CChildProcess::Run (this=0x7fffa6d2d510) at CChildProcess.cpp:122\n#12 0x000000000040d8f3 in CProcessMgr::StartAProcess (this=0xa34f30, strCustomID=\"\\210\", pChildProcess=0x7fffa6d2d510)\n    at CProcessMgr.cpp:114\n#13 0x000000000041094e in CTimerService::Run (this=0x7fffa6d2da70) at CTimerService.cpp:46\n#14 0x000000000040dba4 in main (argc=<value optimized out>, argv=<value optimized out>) at main.cpp:92","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=huangkx","name":"huangkx","key":"huangkx","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"huang ken","active":true,"timeZone":"Asia/Shanghai"},"created":"2014-04-21T08:09:20.742+0000","updated":"2014-04-21T08:09:20.742+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12709014/comment/13975755","id":"13975755","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"thanks for the details. Looking at the latest trace, it's when then native code calls back into java for a mkdirs(path) operation -it could be that something being passed down is null or otherwise uninitialized.\n\nThat the limit of my JNI knowledge -anyone else got any ideas?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2014-04-21T17:29:19.394+0000","updated":"2014-04-21T17:29:19.394+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12709014/comment/13976037","id":"13976037","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"body":"The line numbers in the latest backtrace match up with the current trunk code.  Thank you for retesting.\n\n{{hdfsConnect}} is supposed to return {{NULL}} if the connection fails.  This is covered by tests in a few places, such as test_libhdfs_read.c:\n\n{code}\n    hdfsFS fs = hdfsConnect(\"default\", 0);\n    if (!fs) {\n        fprintf(stderr, \"Oops! Failed to connect to hdfs!\\n\");\n        exit(-1);\n    } \n{code}\n\n[~huangkx], are you not seeing a {{NULL}} return in your environment?  Can you post a minimal code snippet that repros the problem for you?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-04-21T21:08:24.192+0000","updated":"2014-04-21T21:08:24.192+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12709014/comment/13976126","id":"13976126","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"body":"To clarify my earlier comment, the test is probably not actually covering the case of a connection failure, because it waits for the cluster to be running in the background before starting.  It would still be interesting to see the code sample that you're using though.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-04-21T22:32:29.574+0000","updated":"2014-04-21T22:32:29.574+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12709014/comment/13976299","id":"13976299","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=huangkx","name":"huangkx","key":"huangkx","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"huang ken","active":true,"timeZone":"Asia/Shanghai"},"body":"test.cpp:\nint main()\n{\n\thdfsFS fs = NULL;\n\tfs = hdfsConnect(\"172.16.19.222\", 8020); // romote host is unavailable\n\tif (!fs)\n\t{\n\t\tprintf(\"HDFS connect error!\\n\");\n\t\treturn -1;\n\t}\n\telse \n\t{\n\t\tprintf(\"HDFS connect OK.\\n\");\n\t}\n\tif (hdfsCreateDirectory(fs, \"/tmp/root/\") != 0 )\n\t{\n\t\tprintf(\"Create dir error!\\n\");\n\t\treturn -1;\n\t}\n\telse\n\t{\n\t\tprintf(\"Create dir Ok.\\n\");\n\t\treturn 0;\n\t}\n}\n\nWhat puzzled me is following two scenarios:\n\n#scenario 1:compile test.cpp & run\n[root@datanode test]# ./a.out \n2014-04-22 09:48:34,106 WARN  util.NativeCodeLoader (NativeCodeLoader.java:<clinit>(62)) - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\nHDFS connect OK.\nhdfsCreateDirectory(/tmp/root/): FileSystem#mkdirs error:\njava.net.ConnectException: Call From datanode2/172.16.18.238 to 172.16.19.222:8020 failed on connection exception: java.net.ConnectException: Connection timed out; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused\n        at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n        at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)\n        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n        at java.lang.reflect.Constructor.newInstance(Constructor.java:526)\n        at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)\n        at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)\n        at org.apache.hadoop.ipc.Client.call(Client.java:1351)\n        at org.apache.hadoop.ipc.Client.call(Client.java:1300)\n        at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)\n        at com.sun.proxy.$Proxy9.mkdirs(Unknown Source)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:606)\n        at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:186)\n        at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)\n        at com.sun.proxy.$Proxy9.mkdirs(Unknown Source)\n        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.mkdirs(ClientNamenodeProtocolTranslatorPB.java:467)\n        at org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:2394)\n        at org.apache.hadoop.hdfs.DFSClient.mkdirs(DFSClient.java:2365)\n        at org.apache.hadoop.hdfs.DistributedFileSystem$16.doCall(DistributedFileSystem.java:817)\n        at org.apache.hadoop.hdfs.DistributedFileSystem$16.doCall(DistributedFileSystem.java:813)\n        at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)\n        at org.apache.hadoop.hdfs.DistributedFileSystem.mkdirsInternal(DistributedFileSystem.java:813)\n        at org.apache.hadoop.hdfs.DistributedFileSystem.mkdirs(DistributedFileSystem.java:806)\n        at org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:1933)\nCaused by: java.net.ConnectException: Connection timed out\n        at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n        at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)\n        at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)\n        at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)\n        at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)\n        at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:547)\n        at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:642)\n        at org.apache.hadoop.ipc.Client$Connection.access$2600(Client.java:314)\n        at org.apache.hadoop.ipc.Client.getConnection(Client.java:1399)\n        at org.apache.hadoop.ipc.Client.call(Client.java:1318)\n        ... 19 more\nCreate dir error!\n\n#scenario  2:compile test.cpp & gdb\n[root@datanode2 test3]# gdb a.out \nGNU gdb (GDB) Red Hat Enterprise Linux (7.2-56.el6)\nCopyright (C) 2010 Free Software Foundation, Inc.\nLicense GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>\nThis is free software: you are free to change and redistribute it.\nThere is NO WARRANTY, to the extent permitted by law.  Type \"show copying\"\nand \"show warranty\" for details.\nThis GDB was configured as \"x86_64-redhat-linux-gnu\".\nFor bug reporting instructions, please see:\n<http://www.gnu.org/software/gdb/bugs/>...\nReading symbols from /root/test3/a.out...done.\n(gdb) l\n1       //g++ -g test.cpp -L/home/hkx/hadoop-2.2.0-src/hadoop-dist/target/hadoop-2.2.0/lib/native -I/home/hkx/hadoop-2.2.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/native/libhdfs -I/home/yjx/JDK/jdk1.6.0_24/include -I/home/yjx/JDK/jdk1.6.0_24/include/linux -lhdfs\n2       #include <stdio.h>\n3       #include <stdlib.h>\n4       #include \"hdfs.h\"\n5\n6       int main()\n7       {\n8               hdfsFS fs = NULL;\n9               fs = hdfsConnect(\"172.16.19.222\", 8020);\n10              if (!fs)\n(gdb) b test.cpp:8\nBreakpoint 1 at 0x40071c: file test.cpp, line 8.\n(gdb) r\nStarting program: /root/test3/a.out \n[Thread debugging using libthread_db enabled]\n\nBreakpoint 1, main () at test.cpp:8\n8               hdfsFS fs = NULL;\nMissing separate debuginfos, use: debuginfo-install glibc-2.12-1.80.el6_3.6.x86_64 jdk-1.7.0_55-fcs.x86_64 libgcc-4.4.6-4.el6.x86_64 libstdc++-4.4.6-4.el6.x86_64\n(gdb) n\n9               fs = hdfsConnect(\"172.16.19.222\", 8020);\n(gdb) p fs\n$1 = (hdfsFS) 0x0\n(gdb) n\n[New Thread 0x7ffff23aa700 (LWP 3218)]\n[New Thread 0x7ffff22a9700 (LWP 3219)]\n[New Thread 0x7ffff21a8700 (LWP 3220)]\n[New Thread 0x7ffff20a7700 (LWP 3221)]\n[New Thread 0x7ffff0740700 (LWP 3222)]\n[New Thread 0x7ffff063f700 (LWP 3223)]\n[New Thread 0x7ffff053e700 (LWP 3224)]\n[New Thread 0x7ffff043d700 (LWP 3225)]\n[New Thread 0x7ffff033c700 (LWP 3226)]\n[New Thread 0x7ffff023b700 (LWP 3227)]\n[New Thread 0x7ffff013a700 (LWP 3228)]\n[New Thread 0x7fffebfff700 (LWP 3229)]\n\nProgram received signal SIGSEGV, Segmentation fault.\n0x00007ffff24155ca in ?? ()\n(gdb) bt\n#0  0x00007ffff24155ca in ?? ()\n#1  0x0000000000615000 in ?? ()\n#2  0x00000000f506d712 in ?? ()\n#3  0x0000000000615000 in ?? ()\n#4  0x00000000f5084c68 in ?? ()\n#5  0x000000000000001b in ?? ()\n#6  0x0000000000000000 in ?? ()\n(gdb) quit\nA debugging session is active.\n\n        Inferior 1 [process 3214] will be killed.\n\nQuit anyway? (y or n) y\n\nIn scenario 1, do return connect OK and fail in hdfsCreateDirectory(). \nIn scenario 2, got sigsegv while connect to a host unavailable(not matter remote host is available or not).Seems can't debug it using gdb.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=huangkx","name":"huangkx","key":"huangkx","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"huang ken","active":true,"timeZone":"Asia/Shanghai"},"created":"2014-04-22T02:11:59.053+0000","updated":"2014-04-22T02:11:59.053+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12709014/comment/13980038","id":"13980038","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"body":"[~huangkx], thanks again for the code sample.  I confirmed that the same behavior happens for me: run the program directly and I get the expected connection failure error, but run it under gdb and it dies with SIGSEGV.\n\nI think the problem we're seeing is that the JVM actually traps SIGSEGV and runs its own signal handler to attempt recovery.  This is part of how the JVM interacts with the kernel to manage memory.  For example, see this code in OpenJDK:\n\nhttp://hg.openjdk.java.net/jdk6/jdk6/hotspot/file/tip/src/os/linux/vm/os_linux.cpp#l3873\n\ngdb's own signal handling appears to be interfering with this and choosing to suspend when it encounters a SIGSEGV.  This doesn't really represent a bug in the libhdfs code.  In fact, if I resume execution after the SIGSEGV by using the \"fg\" command, then it proceeds as expected, and I see the connection failure.\n\nIf you don't want gdb to suspend when it sees a SIGSEGV, then another option is to change its signal handling behavior by running this command:\n{code}\n(gdb) handle SIGSEGV nostop\n{code}\n\nBTW, I noticed a bug in the code sample you provided.  It does not call {{hdfsDisconnect}} on the allocated {{hdfsFS}} to free resources.  This is something that you'll want to add in your real code to avoid leaks.  Also note that the {{hdfsConnect}} function has been deprecated in favor of {{hdfsBuilderConnect}}.  For full details on this, refer to the hdfs.h header file.\n\nAt this point, I'm going to resolve this issue, because this behavior does not represent a bug in the libhdfs code.  I hope this was helpful.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-04-24T18:12:33.741+0000","updated":"2014-04-24T18:12:33.741+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12709014/comment/13980812","id":"13980812","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=huangkx","name":"huangkx","key":"huangkx","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"huang ken","active":true,"timeZone":"Asia/Shanghai"},"body":"Chris Nauroth, thanks a lot for your explanation about gdb SIGSEGV handling & programming advice.\nBut <b>hdfsConnect</b> or <b>hdfsBuilderConnect</b> do return <b>not NULL</b> while namenode not connected in my test, not the same as the declaration in hdfs.h. Is it right ?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=huangkx","name":"huangkx","key":"huangkx","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"huang ken","active":true,"timeZone":"Asia/Shanghai"},"created":"2014-04-25T08:54:36.014+0000","updated":"2014-04-25T08:54:36.014+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12709014/comment/13981175","id":"13981175","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"body":"[~huangkx], yes, you're correct.  Neither {{hdfsConnect}} nor {{hdfsBuilderConnect}} actually initiates a network connection.  Instead, they \"connect\" an {{hdfsFS}} struct to an underlying Java {{FileSystem}}.  Basically, this stuff is all wrappers over {{FileSystem#get}} in the Java layer.  There is no actual interaction with the HDFS daemons until you use it with a function like {{hdfsCreateDirectory}}.  Our use of the word \"connect\" in the function names is perhaps slightly misleading.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-04-25T15:51:47.706+0000","updated":"2014-04-25T15:51:47.706+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12709014/comment/13982351","id":"13982351","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=huangkx","name":"huangkx","key":"huangkx","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"huang ken","active":true,"timeZone":"Asia/Shanghai"},"body":"Chris Nauroth, thanks again for your explanation.I've retested my test case as followedï¼š\n1. Use hdfsBuilderConnect(connect to a remote host unavailable).\n2. Because of hdfsBuilderConnect not initiates a network connection, so continue to use hdfsCreateDirectory, then it failed with NoRouteToHostException.\n3. But if reconnect, SIGSEGV catched.\nIs it right ? test.cpp attached.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=huangkx","name":"huangkx","key":"huangkx","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"huang ken","active":true,"timeZone":"Asia/Shanghai"},"created":"2014-04-27T15:04:34.582+0000","updated":"2014-04-27T15:04:34.582+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12709014/comment/13982392","id":"13982392","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"body":"Regarding this line of code:\n\n{code}\n\t\tfs = hdfsBuilderConnect(bld);    //core dump here\n{code}\n\nThis is attempting to use a {{hdfsBuilder}} that had already been used in an earlier {{hdfsBuilderConnect}} call.  This is invalid usage and could very well produce a segfault.  The docs for {{hdfsBuilderConnect}} state that it always frees the builder, regardless of the outcome:\n\n{code}\n     * The HDFS builder will be freed, whether or not the connection was\n     * successful.\n{code}\n\nRelated to this, the docs for {{hdfsFreeBuilder}} state that you normally wouldn't need to call it directly:\n\n{code}\n     * It is normally not necessary to call this function since\n     * hdfsBuilderConnect frees the builder.\n{code}\n\nThe only time you'd need to call {{hdfsFreeBuilder}} yourself directly is if you allocated one by calling {{hdfsNewBuilder}}, but then never called {{hdfsBuilderConnect}}.  I don't see a path through your code sample that can cause that to happen, so I expect you can remove the null checks on {{bld}} followed by the calls to {{hdfsFreeBuilder}}.\n\nIf there are any additional libhdfs usage questions, I recommend emailing user@hadoop.apache.org.  This is the best venue for support.  Jira is intended for reporting of bugs only, and in this case, we haven't seen any actual bugs in libhdfs.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-04-27T16:56:33.710+0000","updated":"2014-04-27T16:56:33.710+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12709014/comment/13982708","id":"13982708","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=huangkx","name":"huangkx","key":"huangkx","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"huang ken","active":true,"timeZone":"Asia/Shanghai"},"body":"Sorry for misreport, and thank you very much for patience.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=huangkx","name":"huangkx","key":"huangkx","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"huang ken","active":true,"timeZone":"Asia/Shanghai"},"created":"2014-04-28T02:16:57.951+0000","updated":"2014-04-28T02:16:57.951+0000"}],"maxResults":16,"total":16,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-6254/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i1uq3r:"}}