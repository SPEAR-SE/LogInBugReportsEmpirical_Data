{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12748760","self":"https://issues.apache.org/jira/rest/api/2/issue/12748760","key":"HDFS-7256","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/8","id":"8","description":"The described issue is not actually a problem - it is as designed.","name":"Not A Problem"},"customfield_12312322":null,"customfield_12310220":"2014-10-17T02:43:29.891+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Fri Mar 20 01:05:22 UTC 2015","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_12519428_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2014-10-17T02:46:03.181+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-7256/watchers","watchCount":2,"isWatching":false},"created":"2014-10-16T23:17:23.791+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12327181","id":"12327181","description":"2.6.0 release","name":"2.6.0","archived":false,"released":true,"releaseDate":"2014-11-18"}],"issuelinks":[],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hitliuyi","name":"hitliuyi","key":"hitliuyi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yi Liu","active":true,"timeZone":"Asia/Shanghai"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2015-03-20T01:05:22.914+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12323800","id":"12323800","name":"encryption"},{"self":"https://issues.apache.org/jira/rest/api/2/component/12313400","id":"12313400","name":"security"}],"timeoriginalestimate":null,"description":"Hit an error on \"RemoteException: Key ezkey1 doesn't exist.\" when creating EZ with a Key created after NN starts.\n\nBriefly check the code and found that the KeyProivder is loaded by FSN only at the NN start. My work around is to restart the NN which triggers the reload of Key Provider. Is this expected?\n\nRepro Steps:\n\nCreate a new Key after NN and KMS starts\nhadoop/bin/hadoop key create ezkey1 -size 256 -provider jceks://file/home/hadoop/kms.keystore\n\nList Keys\nhadoop@SaturnVm:~/deploy$ hadoop/bin/hadoop key list -provider jceks://file/home/hadoop/kms.keystore -metadata\nListing keys for KeyProvider: jceks://file/home/hadoop/kms.keystore\nezkey1 : cipher: AES/CTR/NoPadding, length: 256, description: null, created: Thu Oct 16 18:51:30 EDT 2014, version: 1, attributes: null\nkey2 : cipher: AES/CTR/NoPadding, length: 128, description: null, created: Tue Oct 14 19:44:09 EDT 2014, version: 1, attributes: null\nkey1 : cipher: AES/CTR/NoPadding, length: 128, description: null, created: Tue Oct 14 17:52:36 EDT 2014, version: 1, attributes: null\n\nCreate Encryption Zone\nhadoop/bin/hdfs dfs -mkdir /Ez1\nhadoop@SaturnVm:~/deploy$ hadoop/bin/hdfs crypto -createZone -keyName ezkey1 -path /Ez1\nRemoteException: Key ezkey1 doesn't exist.\n","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"Encryption Key created in Java Key Store after Namenode start unavailable for EZ Creation ","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xyao","name":"xyao","key":"xyao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xiaoyu Yao","active":true,"timeZone":"America/Los_Angeles"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xyao","name":"xyao","key":"xyao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xiaoyu Yao","active":true,"timeZone":"America/Los_Angeles"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12748760/comment/14174669","id":"14174669","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hitliuyi","name":"hitliuyi","key":"hitliuyi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yi Liu","active":true,"timeZone":"Asia/Shanghai"},"body":"Thanks [~xyao] for testing this, this should be not an issue. Let me explain below.\n\nHDFS encryption at rest requires user to configure a KMS, and the backing KeyProvider of KMS can be a {{JavaKeyStoreProvider}} or a third-party keystore which implements Hadoop {{KeyProvider}} interface.\nIn your case, {{JavaKeyStoreProvider}} is used directly, actually both FSN and DFSClient will have KeyProvider instance (different), FSN uses KeyProvider instance to get EncryptionZone key and get Encrypted data encryption keys, and DFSClient uses KeyProvider instance to decrypt the data encryption keys.  JavaKeyStoreProvider uses local java keystore file, it can't satisfy multiple nodes accessing. \n\"hadoop key create ...\" command constructs its KeyProvider instance in client side, and create/flush key to java keystore file, and FSN will not reload the java keystore file. That's the reason why you see the exception.\n\nSo please configure a KMS and the backing KeyProvider could be a {{JavaKeyStoreProvider}}, for more information, please refer to the fs-encryption/KMS user doc.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hitliuyi","name":"hitliuyi","key":"hitliuyi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yi Liu","active":true,"timeZone":"Asia/Shanghai"},"created":"2014-10-17T02:43:29.891+0000","updated":"2014-10-17T02:43:29.891+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12748760/comment/14174672","id":"14174672","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hitliuyi","name":"hitliuyi","key":"hitliuyi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yi Liu","active":true,"timeZone":"Asia/Shanghai"},"body":"I mark it as \"Not a Problem\", please feel free to reopen it if you have different  opinions.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hitliuyi","name":"hitliuyi","key":"hitliuyi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yi Liu","active":true,"timeZone":"Asia/Shanghai"},"created":"2014-10-17T02:46:03.209+0000","updated":"2014-10-17T02:46:03.209+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12748760/comment/14174744","id":"14174744","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xyao","name":"xyao","key":"xyao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xiaoyu Yao","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks [~hitliuyi] for the detail explanation.  I configured my test environment based on HDFS-6134 proposal: https://issues.apache.org/jira/secure/attachment/12660368/HDFSDataatRestEncryption.pdf. \nCan you point me the link to fs-encryption/KMS user doc if there is a different one?\n\nI do have a KMS setup with JavaKeyStoreProvider pointing to the same java key store file. \nBased on your suggestion, I just switch to use 'kms://http@localhost:16000/kms' instead of the java key store file \n'jceks://file/home/hadoop/kms.keystore' directly for the 'dfs.encryption.key.provider.uri' in hdfs-site.xml and 'hadoop.security.crypto.jce.provider' in core-site.xml.\n\nBelow I have two follow up questions when executing the the 'hadoop key' command after the change. Can you confirm if these are expected or not?\n\n1. Have to specify -provider explicitly even though hadoop.security.crypto.jce.provider='kms://http@localhost:16000/kms' is configured in core-site.xml.\n\nhadoop@hadoopdev:~/deploy$ hadoop/bin/hadoop key list\nThere are no non-transient KeyProviders configured.\nUse the -provider option to specify a provider. If you\nwant to list a transient provider then you must use the\n-provider argument.\n\n2. Keys are returned with -provider specified but WARN message is logged in kms.log on Anonymous request. My understanding is that KMS should proxy user 'hadoop' based the proxy user setting below. Do I miss anything?\n \nhadoop@hadoopdev:~/deploy$ hadoop/bin/hadoop key list -provider kms://http@localhost:16000/kms\nListing keys for KeyProvider: KMSClientProvider[http://localhost:16000/kms/v1/]\nkey1\n\n{code}\n2014-10-16 22:08:38,386 WARN  AuthenticationFilter - Authentication exception: Anonymous requests are disallowed\norg.apache.hadoop.security.authentication.client.AuthenticationException: Anonymous requests are disallowed\n        at org.apache.hadoop.security.authentication.server.PseudoAuthenticationHandler.authenticate(PseudoAuthenticationHandler.java:184)\n        at org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticationHandler.authenticate(DelegationTokenAuthenticationHandler.java:330)\n        at org.apache.hadoop.security.authentication.server.AuthenticationFilter.doFilter(AuthenticationFilter.java:507)\n        at org.apache.hadoop.crypto.key.kms.server.KMSAuthenticationFilter.doFilter(KMSAuthenticationFilter.java:129)\n        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:235)\n        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206)\n        at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:233)\n        at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:191)\n        at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:127)\n        at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:103)\n        at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:109)\n        at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:293)\n        at org.apache.coyote.http11.Http11Processor.process(Http11Processor.java:861)\n        at org.apache.coyote.http11.Http11Protocol$Http11ConnectionHandler.process(Http11Protocol.java:606)\n        at org.apache.tomcat.util.net.JIoEndpoint$Worker.run(JIoEndpoint.java:489)\n        at java.lang.Thread.run(Thread.java:745)\n{/code}\n\nThe client runs with user 'hadoop'. The proxyuser and delegation token(use default) are set up in kms-site.xml. \n  <!-- proxyuser configuration for user named:  hadoop-->\n  <property>\n    <name>hadoop.kms.proxyuser.hadoop.users</name>\n    <value>*</value>\n  </property> \n...","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xyao","name":"xyao","key":"xyao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xiaoyu Yao","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-10-17T05:40:20.883+0000","updated":"2014-10-17T05:40:20.883+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12748760/comment/14174804","id":"14174804","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hitliuyi","name":"hitliuyi","key":"hitliuyi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yi Liu","active":true,"timeZone":"Asia/Shanghai"},"body":"Thanks [~xyao].  \n*For your question 1:*\nPlease don't specify {{hadoop.security.crypto.jce.provider}}, it's a jce provider used for jce cryptocodec.  Not for key provider uri. \nSo please configure in hdfs-site.xml\n{code}\n<property>\n    <name>dfs.encryption.key.provider.uri</name>\n    <value>kms://http@localhost:16000/kms</value>\n</property>\n{code}\nAnd in kms-site.xml\n{code}\n<property>\n    <name>hadoop.kms.key.provider.uri</name>\n    <value>jceks://file@/home/hadoop/kms.keystore</value>\n  </property>\n{code}\n\nWhen you use hadoop key shell, please specify \n{code}\n-provider kms://http@localhost:16000/kms\n{code}\nIf you don't want specify {{-provider}} every time, please configure in core-site.xml\n{code}\n\n<property>\n    <name>hadoop.security.key.provider.path</name>\n    <value>kms://http@localhost:16000/kms</value>\n  </property>\n{code}\n\n*For your question 2:*\nFor the warning, you see it from kms log?\nIf so, It's a warning and doesn't affect functionality, if kerberos is *not* enabled, the request sent to kms is without an user for the first time, but it will fail and trigger authenticatation again with the user name, then it successes. \nThere was ever a bug (HADOOP-11151) to let request having an user name for the first time in non-secured mode, let me check in latest trunk whether it's fixed, if not, I can fix that.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hitliuyi","name":"hitliuyi","key":"hitliuyi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yi Liu","active":true,"timeZone":"Asia/Shanghai"},"created":"2014-10-17T07:19:36.764+0000","updated":"2014-10-17T07:19:36.764+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12748760/comment/14174813","id":"14174813","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hitliuyi","name":"hitliuyi","key":"hitliuyi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yi Liu","active":true,"timeZone":"Asia/Shanghai"},"body":"[~xyao], ideally the hdfs encryption is recommended used in secured environment(keberos enabled), and in this case, there is no this warning.\n\nFurthermore\n\n{quote}\nThe client runs with user 'hadoop'. The proxyuser and delegation token(use default) are set up in kms-site.xml. \n<!-- proxyuser configuration for user named: hadoop-->\n<property>\n<name>hadoop.kms.proxyuser.hadoop.users</name>\n<value>*</value>\n</property> \n{quote}\nYour use case is not the proxyuser, the reason is as I said in above comment.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hitliuyi","name":"hitliuyi","key":"hitliuyi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yi Liu","active":true,"timeZone":"Asia/Shanghai"},"created":"2014-10-17T07:32:24.968+0000","updated":"2014-10-17T07:32:24.968+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12748760/comment/14174818","id":"14174818","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hitliuyi","name":"hitliuyi","key":"hitliuyi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yi Liu","active":true,"timeZone":"Asia/Shanghai"},"body":"{quote}\nCan you point me the link to fs-encryption/KMS user doc if there is a different one\n{quote}\nHDFS encryption is not included in 2.5.1 or before, so there is no on-line document, I mean you could compile the user doc using:\n{{mvn clean site; mvn site:stage -DstagingDirectory=/tmp/hadoop-site}}\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hitliuyi","name":"hitliuyi","key":"hitliuyi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yi Liu","active":true,"timeZone":"Asia/Shanghai"},"created":"2014-10-17T07:38:58.223+0000","updated":"2014-10-17T07:38:58.223+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12748760/comment/14174859","id":"14174859","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hitliuyi","name":"hitliuyi","key":"hitliuyi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yi Liu","active":true,"timeZone":"Asia/Shanghai"},"body":"For the warning, I found KMS client or HttpFS client always try {{KerberosAuthenticator}} first, then will trigger a fallback if server is not security enabled.  So we can ignore that warning and it appears in non-secured mode.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hitliuyi","name":"hitliuyi","key":"hitliuyi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yi Liu","active":true,"timeZone":"Asia/Shanghai"},"created":"2014-10-17T08:53:10.664+0000","updated":"2014-10-17T08:53:10.664+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12748760/comment/14174896","id":"14174896","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xyao","name":"xyao","key":"xyao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xiaoyu Yao","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks [~hitliuyi] again for the clarification. Three more follow up questions:\n1. KMS and Hadoop Key Shell allows creating keys of length > 128. But HDFS seems to have a hard limitation of AES-CTS 128 only. Is this expected?\n\nhadoop@hadoopdev:~/deploy$ hadoop/bin/hadoop key list -metadata\n\nListing keys for KeyProvider: KMSClientProvider[http://localhost:16000/kms/v1/]\nkey2 : cipher: AES/CTR/NoPadding, length: 256, description: null, created: Thu Oct 16 22:42:20 PDT 2014, version: 1, attributes: [key.acl.name=key2]\nkey1 : cipher: AES/CTR/NoPadding, length: 128, description: null, created: Thu Oct 16 14:28:53 PDT 2014, version: 1, attributes: null\n\nhadoop@hadoopdev:~/deploy$ hadoop/bin/hdfs crypto -createZone -path /ez2 -keyName key2\nRemoteException: java.util.concurrent.ExecutionException: java.io.IOException: java.io.IOException: java.util.concurrent.ExecutionException: java.io.IOException: java.security.InvalidKeyException: Illegal key size \n\n2. Thanks for pointing me the 'hadoop.security.key.provider.path'. That's exactly what I'm looking for. However, I did not find it as it is hard coded in KeyProviderFactory.java, which is different from other security configuration keys in CommonConfigurationKeysPublic.java. If this key is targeted for public usage, I would suggest to put it in CommonConfigurationKeysPublic.java and also include in the hadoop key shell help message.\n\n3. The document mentioned that copy file between EZs with different EZ-keys or copy file form EZ to non-EZ directory are not allowed. But my test shows it works completely fine. Is this explicitly blocked or just not recommended?\n\n\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xyao","name":"xyao","key":"xyao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xiaoyu Yao","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-10-17T09:45:28.156+0000","updated":"2014-10-17T09:45:28.156+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12748760/comment/14175101","id":"14175101","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hitliuyi","name":"hitliuyi","key":"hitliuyi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yi Liu","active":true,"timeZone":"Asia/Shanghai"},"body":"Thanks [~xyao] for trying this. Responses to your comments:\n\n*1.*  I think you are using java JCE crypto codec (If openssl is not configured or incorrect version, JCE will be used), by default, JCE only supports 128bits, if you want to use 256bits, you need to download additional thing from Oracle.\n\n*2.* Ideally {{hadoop.security.key.provider.path}} is better in _CommonConfigurationKeysPublic_, it's committed early and we do not modified it later.\n\n*3.* You are talking about *rename* which is not allowed between EZs with different EZ-keys or from EZ to non-EZ directly, but {{cp}} is allowed.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hitliuyi","name":"hitliuyi","key":"hitliuyi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yi Liu","active":true,"timeZone":"Asia/Shanghai"},"created":"2014-10-17T14:38:21.737+0000","updated":"2014-10-17T14:38:21.737+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12748760/comment/14175105","id":"14175105","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hitliuyi","name":"hitliuyi","key":"hitliuyi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yi Liu","active":true,"timeZone":"Asia/Shanghai"},"body":"For *rename*, actually only allowed in same EZ,  not allowed between EZs even with same EZ-keys.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hitliuyi","name":"hitliuyi","key":"hitliuyi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yi Liu","active":true,"timeZone":"Asia/Shanghai"},"created":"2014-10-17T14:42:26.317+0000","updated":"2014-10-17T14:42:26.317+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12748760/comment/14370241","id":"14370241","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xyao","name":"xyao","key":"xyao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xiaoyu Yao","active":true,"timeZone":"America/Los_Angeles"},"body":"bq. If you don't want specify -provider every time, please configure in core-site.xml\n\n{code}\n<property>\n    <name>hadoop.security.key.provider.path</name>\n    <value>kms://http@localhost:16000/kms</value>\n  </property>\n{code}\n\nIs there any purpose of *hadoop.security.key.provider.path*? I can't find any document about this. When we have this added in a Kerberos environment. HiveServer2 queries failed to get DelegationToken from KMS. Is there any know issue with this?\n\n{code}\nselect count(*), symbol from stocks group by symbol;\nINFO  : Number of reduce tasks not specified. Estimated from input data size: 7\nINFO  : In order to change the average load for a reducer (in bytes):\nINFO  :   set hive.exec.reducers.bytes.per.reducer=<number>\nINFO  : In order to limit the maximum number of reducers:\nINFO  :   set hive.exec.reducers.max=<number>\nINFO  : In order to set a constant number of reducers:\nINFO  :   set mapreduce.job.reduces=<number>\nINFO  : Cleaning up the staging area /user/hehe/.staging/job_1426024489715_0006\nERROR : Job Submission failed with exception 'java.io.IOException(org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt))'\njava.io.IOException: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)\n\tat org.apache.hadoop.crypto.key.kms.KMSClientProvider.addDelegationTokens(KMSClientProvider.java:794)\n\tat org.apache.hadoop.crypto.key.KeyProviderDelegationTokenExtension.addDelegationTokens(KeyProviderDelegationTokenExtension.java:86)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem.addDelegationTokens(DistributedFileSystem.java:2046)\n\tat org.apache.hadoop.mapreduce.security.TokenCache.obtainTokensForNamenodesInternal(TokenCache.java:121)\n\tat org.apache.hadoop.mapreduce.security.TokenCache.obtainTokensForNamenodesInternal(TokenCache.java:100)\n\tat org.apache.hadoop.mapreduce.security.TokenCache.obtainTokensForNamenodes(TokenCache.java:80)\n\tat org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:459)\n\tat org.apache.hadoop.mapreduce.Job$10.run(Job.java:1296)\n\tat org.apache.hadoop.mapreduce.Job$10.run(Job.java:1293)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:415)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)\n\tat org.apache.hadoop.mapreduce.Job.submit(Job.java:1293)\n\tat org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:562)\n\tat org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:557)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:415)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)\n\tat org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:557)\n\tat org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:548)\n\tat org.apache.hadoop.hive.ql.exec.mr.ExecDriver.execute(ExecDriver.java:429)\n\tat org.apache.hadoop.hive.ql.exec.mr.MapRedTask.execute(MapRedTask.java:137)\n\tat org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:160)\n\tat org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:85)\n\tat org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1604)\n\tat org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1364)\n\tat org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1177)\n\tat org.apache.hadoop.hive.ql.Driver.run(Driver.java:1004)\n\tat org.apache.hadoop.hive.ql.Driver.run(Driver.java:999)\n\tat org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:144)\n\tat org.apache.hive.service.cli.operation.SQLOperation.access$100(SQLOperation.java:69)\n\tat org.apache.hive.service.cli.operation.SQLOperation$1$1.run(SQLOperation.java:196)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:415)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)\n\tat org.apache.hadoop.hive.shims.HadoopShimsSecure.doAs(HadoopShimsSecure.java:536)\n\tat org.apache.hive.service.cli.operation.SQLOperation$1.run(SQLOperation.java:208)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)\n\tat org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:306)\n\tat org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:196)\n\tat org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticator.authenticate(DelegationTokenAuthenticator.java:127)\n\tat org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:216)\n\tat org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticator.doDelegationTokenOperation(DelegationTokenAuthenticator.java:284)\n\tat org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticator.getDelegationToken(DelegationTokenAuthenticator.java:165)\n\tat org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticatedURL.getDelegationToken(DelegationTokenAuthenticatedURL.java:371)\n\tat org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticatedURL.getDelegationToken(DelegationTokenAuthenticatedURL.java:348)\n\tat org.apache.hadoop.crypto.key.kms.KMSClientProvider.addDelegationTokens(KMSClientProvider.java:786)\n\t... 41 more\nCaused by: GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)\n\tat sun.security.jgss.krb5.Krb5InitCredential.getInstance(Krb5InitCredential.java:147)\n\tat sun.security.jgss.krb5.Krb5MechFactory.getCredentialElement(Krb5MechFactory.java:121)\n\tat sun.security.jgss.krb5.Krb5MechFactory.getMechanismContext(Krb5MechFactory.java:187)\n\tat sun.security.jgss.GSSManagerImpl.getMechanismContext(GSSManagerImpl.java:223)\n\tat sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:212)\n\tat sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179)\n\tat org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:285)\n\tat org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:261)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:415)\n\tat org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:261)\n\t... 49 more\n\nError: Error while processing statement: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.mr.MapRedTask (state=08S01,code=1)\n{code}\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xyao","name":"xyao","key":"xyao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xiaoyu Yao","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-03-19T22:21:42.030+0000","updated":"2015-03-19T22:21:42.030+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12748760/comment/14370483","id":"14370483","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hitliuyi","name":"hitliuyi","key":"hitliuyi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yi Liu","active":true,"timeZone":"Asia/Shanghai"},"body":"Hi Xiaoyu, {{hadoop.security.key.provider.path}} is only used as the default key provider when you use {{hadoop key}} command.\nThe failure you got is not related to this, it's because the kerberos authentication failed, I think your local keberos ticket cache (tgt) is out of date or you have not done a \"kinit\".   Even you remove this config, you can still get the same issue.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hitliuyi","name":"hitliuyi","key":"hitliuyi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yi Liu","active":true,"timeZone":"Asia/Shanghai"},"created":"2015-03-20T01:05:22.914+0000","updated":"2015-03-20T01:05:22.914+0000"}],"maxResults":12,"total":12,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-7256/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i219vz:"}}