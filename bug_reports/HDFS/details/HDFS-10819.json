{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"13001537","self":"https://issues.apache.org/jira/rest/api/2/issue/13001537","key":"HDFS-10819","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":"2016-08-31T20:40:47.931+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Wed Oct 05 00:42:23 UTC 2016","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-10819/watchers","watchCount":9,"isWatching":false},"created":"2016-08-31T01:56:24.140+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"1.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12335732","id":"12335732","description":"3.0.0-alpha1 release","name":"3.0.0-alpha1","archived":false,"released":true,"releaseDate":"2016-09-03"}],"issuelinks":[{"id":"12479112","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12479112","type":{"id":"10020","name":"Cloners","inward":"is cloned by","outward":"is a clone of","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10020"},"outwardIssue":{"id":"12998565","key":"HDFS-10780","self":"https://issues.apache.org/jira/rest/api/2/issue/12998565","fields":{"summary":"Block replication not proceeding after pipeline recovery -- TestDataNodeHotSwapVolumes fails","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/10002","description":"A patch for this issue has been uploaded to JIRA by a contributor.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/document.png","name":"Patch Available","id":"10002","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/4","id":4,"key":"indeterminate","colorName":"yellow","name":"In Progress"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=manojg","name":"manojg","key":"manojg","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Manoj Govindassamy","active":true,"timeZone":"America/Los_Angeles"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2016-10-05T00:42:23.299+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/10002","description":"A patch for this issue has been uploaded to JIRA by a contributor.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/document.png","name":"Patch Available","id":"10002","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/4","id":4,"key":"indeterminate","colorName":"yellow","name":"In Progress"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12329603","id":"12329603","name":"hdfs"}],"timeoriginalestimate":null,"description":"TestDataNodeHotSwapVolumes occasionally fails in the unit test testRemoveVolumeBeingWrittenForDatanode.  Data write pipeline can have issues as there could be timeouts, data node not reachable etc, and in this test case it was more of induced one as one of the volumes in a datanode is removed while block write is in progress. Digging further in the logs, when the problem happens in the write pipeline, the error recovery is not happening as expected leading to block replication never catching up.\n\nThough this problem has same signature as in HDFS-10780, from the logs it looks like the code paths taken are totally different and so the root cause could be different as well.\n","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12826475","id":"12826475","filename":"HDFS-10819.001.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=manojg","name":"manojg","key":"manojg","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Manoj Govindassamy","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-08-31T19:04:25.969+0000","size":2884,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12826475/HDFS-10819.001.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"BlockManager fails to store a good block for a datanode storage after it reported a corrupt block — block replication stuck","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=manojg","name":"manojg","key":"manojg","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Manoj Govindassamy","active":true,"timeZone":"America/Los_Angeles"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=manojg","name":"manojg","key":"manojg","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Manoj Govindassamy","active":true,"timeZone":"America/Los_Angeles"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/13001537/comment/15452935","id":"15452935","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=manojg","name":"manojg","key":"manojg","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Manoj Govindassamy","active":true,"timeZone":"America/Los_Angeles"},"body":"\nHere is the log snippet from a failed test which is totally different from the signatures in HDFS-10780\n\n{noformat}\n\n1148 2016-08-25 18:21:19,853 [ReplicationMonitor] WARN  net.NetworkTopology (NetworkTopology.java:chooseRandom(816)) - Failed to find datanode (scope=\"\" excludedScope=\"/default-rack\").\n1149 2016-08-25 18:21:19,853 [ReplicationMonitor] WARN  blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(402)) - Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy\n1150 2016-08-25 18:21:19,854 [ReplicationMonitor] WARN  net.NetworkTopology (NetworkTopology.java:chooseRandom(816)) - Failed to find datanode (scope=\"\" excludedScope=\"/default-rack\").\n1151 2016-08-25 18:21:19,854 [ReplicationMonitor] WARN  blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(402)) - Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy\n1152 2016-08-25 18:21:19,854 [ReplicationMonitor] WARN  protocol.BlockStoragePolicy (BlockStoragePolicy.java:chooseStorageTypes(161)) - Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK, ARCHIVE], removed=[DISK],      policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})\n1153 2016-08-25 18:21:19,854 [ReplicationMonitor] WARN  blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(402)) - Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) All required storage types are unavailable:  unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}\n1154 2016-08-25 18:21:19,854 [ReplicationMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1680)) - BLOCK* neededReconstruction = 1 pendingReconstruction = 0\n1155 2016-08-25 18:21:20,071 [DataNode: [[[DISK]file:/Users/manoj/work/ups-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/, [DISK]file:/Users/manoj/work/ups-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:63869] DEBUG datanode.DataNode (BPServiceActor.java:sendHeartBeat(500)) - Sending heartbeat with 1 storage reports from service actor: Block pool BP-1210227499-172.16.3.66-1472174461128 (Datanode Uuid a8be1f44-ba6d-4a90-a380-ccab72e69aeb) service to localhost/127.0.0.1:63869\n1156 2016-08-25 18:21:20,684 [DataNode: [[[DISK]file:/Users/manoj/work/ups-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/, [DISK]file:/Users/manoj/work/ups-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/]]  heartbeating to localhost/127.0.0.1:63869] DEBUG datanode.DataNode (BPServiceActor.java:sendHeartBeat(500)) - Sending heartbeat with 2 storage reports from service actor: Block pool BP-1210227499-172.16.3.66-1472174461128 (Datanode Uuid ce51d074-8231-4ca6-8dff-21de2281910b) service to localhost/127.0.0.1:63869\n1157 2016-08-25 18:21:20,684 [DataNode: [[[DISK]file:/Users/manoj/work/ups-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/, [DISK]file:/Users/manoj/work/ups-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/]]  heartbeating to localhost/127.0.0.1:63869] DEBUG datanode.DataNode (BPServiceActor.java:sendHeartBeat(500)) - Sending heartbeat with 2 storage reports from service actor: Block pool BP-1210227499-172.16.3.66-1472174461128 (Datanode Uuid 31f5b7d6-6d2e-4410-8ca8-27bfe5b768fc) service to localhost/127.0.0.1:63869\n1158 2016-08-25 18:21:20,688 [IPC Server handler 0 on 63869] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7015)) - allowed=true       ugi=manoj (auth:SIMPLE) ip=/127.0.0.1   cmd=getfileinfo src=/test       dst=null        perm=null       proto=rpc\n1159 2016-08-25 18:21:20,690 [IPC Server handler 9 on 63869] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1109)) - blocks = [blk_1073741825_1002]\n1160 2016-08-25 18:21:20,690 [IPC Server handler 9 on 63869] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7015)) - allowed=true       ugi=manoj (auth:SIMPLE) ip=/127.0.0.1   cmd=open        src=/test       dst=null        perm=null       proto=rpc\n1161 Block 0 of file /test has replication factor 2 (desired 3); locations 127.0.0.1:63870 127.0.0.1:63874\n1162 2016-08-25 18:21:21,072 [DataNode: [[[DISK]file:/Users/manoj/work/ups-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/, [DISK]file:/Users/manoj/work/ups-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:63869] DEB     UG datanode.DataNode (BPServiceActor.java:sendHeartBeat(500)) - Sending heartbeat with 1 storage reports from service actor: Block pool BP-1210227499-172.16.3.66-1472174461128 (Datanode Uuid a8be1f44-ba6d-4a90-a380-ccab72e69aeb) service to localhost/127.0.0.1:63869\n1163 2016-08-25 18:21:21,690 [DataNode: [[[DISK]file:/Users/manoj/work/ups-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/, [DISK]file:/Users/manoj/work/ups-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/]]  heartbeating to localhost/127.0.0.1:63869] DEB     UG datanode.DataNode (BPServiceActor.java:sendHeartBeat(500)) - Sending heartbeat with 2 storage reports from service actor: Block pool BP-1210227499-172.16.3.66-1472174461128 (Datanode Uuid ce51d074-8231-4ca6-8dff-21de2281910b) service to localhost/127.0.0.1:63869\n1164 2016-08-25 18:21:21,690 [DataNode: [[[DISK]file:/Users/manoj/work/ups-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/, [DISK]file:/Users/manoj/work/ups-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/]]  heartbeating to localhost/127.0.0.1:63869] DEB     UG datanode.DataNode (BPServiceActor.java:sendHeartBeat(500)) - Sending heartbeat with 2 storage reports from service actor: Block pool BP-1210227499-172.16.3.66-1472174461128 (Datanode Uuid 31f5b7d6-6d2e-4410-8ca8-27bfe5b768fc) service to localhost/127.0.0.1:63869\n\n\n1165 2016-08-25 18:21:21,696 [IPC Server handler 3 on 63869] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7015)) - allowed=true       ugi=manoj (auth:SIMPLE) ip=/127.0.0.1   cmd=getfileinfo src=/test       dst=null        perm=null       proto=rpc\n1166 2016-08-25 18:21:21,698 [IPC Server handler 2 on 63869] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1109)) - blocks = [blk_1073741825_1002]\n1167 2016-08-25 18:21:21,698 [IPC Server handler 2 on 63869] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7015)) - allowed=true       ugi=manoj (auth:SIMPLE) ip=/127.0.0.1   cmd=open        src=/test       dst=null        perm=null       proto=rpc\n1168 Block 0 of file /test has replication factor 2 (desired 3); locations 127.0.0.1:63874 127.0.0.1:63870\n\n\n1169 2016-08-25 18:21:22,078 [DataNode: [[[DISK]file:/Users/manoj/work/ups-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/, [DISK]file:/Users/manoj/work/ups-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:63869] DEB     UG datanode.DataNode (BPServiceActor.java:sendHeartBeat(500)) - Sending heartbeat with 1 storage reports from service actor: Block pool BP-1210227499-172.16.3.66-1472174461128 (Datanode Uuid a8be1f44-ba6d-4a90-a380-ccab72e69aeb) service to localhost/127.0.0.1:63869\n1170 2016-08-25 18:21:22,691 [DataNode: [[[DISK]file:/Users/manoj/work/ups-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/, [DISK]file:/Users/manoj/work/ups-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/]]  heartbeating to localhost/127.0.0.1:63869] DEB     UG datanode.DataNode (BPServiceActor.java:sendHeartBeat(500)) - Sending heartbeat with 2 storage reports from service actor: Block pool BP-1210227499-172.16.3.66-1472174461128 (Datanode Uuid 31f5b7d6-6d2e-4410-8ca8-27bfe5b768fc) service to localhost/127.0.0.1:63869\n1171 2016-08-25 18:21:22,691 [DataNode: [[[DISK]file:/Users/manoj/work/ups-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/, [DISK]file:/Users/manoj/work/ups-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/]]  heartbeating to localhost/127.0.0.1:63869] DEB     UG datanode.DataNode (BPServiceActor.java:sendHeartBeat(500)) - Sending heartbeat with 2 storage reports from service actor: Block pool BP-1210227499-172.16.3.66-1472174461128 (Datanode Uuid ce51d074-8231-4ca6-8dff-21de2281910b) service to localhost/127.0.0.1:63869\n1172 2016-08-25 18:21:22,703 [IPC Server handler 4 on 63869] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7015)) - allowed=true       ugi=manoj (auth:SIMPLE) ip=/127.0.0.1   cmd=getfileinfo src=/test       dst=null        perm=null       proto=rpc\n1173 2016-08-25 18:21:22,704 [IPC Server handler 5 on 63869] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1109)) - blocks = [blk_1073741825_1002]\n1174 2016-08-25 18:21:22,704 [IPC Server handler 5 on 63869] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7015)) - allowed=true       ugi=manoj (auth:SIMPLE) ip=/127.0.0.1   cmd=open        src=/test       dst=null        perm=null       proto=rpc\n1175 Block 0 of file /test has replication factor 2 (desired 3); locations 127.0.0.1:63870 127.0.0.1:63874\n{noformat}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=manojg","name":"manojg","key":"manojg","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Manoj Govindassamy","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-08-31T18:13:11.038+0000","updated":"2016-08-31T18:13:11.038+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13001537/comment/15453079","id":"15453079","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=manojg","name":"manojg","key":"manojg","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Manoj Govindassamy","active":true,"timeZone":"America/Los_Angeles"},"body":"*Problem:*\n— BlockManager reports incorrect replica count for a file block even after successful replication to all replicas, \n— TestDataNodeHotSwapVolumes fails with “TimeoutException: Timed out waiting for /test to reach 3 replicas” error\n\n*Analysis:*\n- Client wrote data to DN1 as part of the initial write pipeline DN1 -> Dn2 -> DN3 \n— DN1 persisted (say in storage volume *S1*) the block BLK_xyz_001, mirrored the block to downstreams and was waiting for the ack back.\n- Later, one of the storage volumes in DN1 (say S2) was removed. Client detects pipeline issue, triggers pipeline recovery and gets the new write pipeline as DN2 —> DN3 \n— On a successful {{FSNameSystem::updatePipeline}} request from Client, NameNode bumps up the Generation Stamp (from 001 to 002) of the UnderConstruction (that is, the last) block of the file.\n- Client writes the new allocated Block BLK_xyz_002 to the new write pipeline nodes. (DN2 and DN3) \n- Client closed the file stream. NameNode ran the LowRedundancy checker for all the blocks in the file. Detected the block BLK_xyz having a replication factor of 2 Vs the expected 3.\n- NameNode asked DN2 to replicate BLK_xyz_002 to DN1. Say DN1 persisted BLK_xyz_002 onto storage volume *S1* again.\n- Now DN1 sends IBR to NameNode with the RECEIVED_BLOCK info about BLK_xyz_002 on *S1*\n\n- BlockManager processed the incremental block report from DN1, was trying to store (metadata) the block BLK_xyz_002 for DN1 on storage *S1*\n- But, DN1 S1 already had BLK_xyz_001 and was marked corrupted later as part of pipeline update. The check at line 2878 thus failed.\n- So, when a storage had a corrupt block and later when the same storage reported a good block, BlockManager fails to update block --> datanode mapping and prune neededReconstruction list. Refer: {{BlockManager::addStoredBlock}}\n\n{noformat}\n\n  2871   void addStoredBlockUnderConstruction(StatefulBlockInfo ucBlock,    \n  2872       DatanodeStorageInfo storageInfo) throws IOException {    \n  2873     BlockInfo block = ucBlock.storedBlock;\n  2874     block.getUnderConstructionFeature().addReplicaIfNotPresent(    \n  2875         storageInfo, ucBlock.reportedBlock, ucBlock.reportedState);\n  2876 \n  2877     if (ucBlock.reportedState == ReplicaState.FINALIZED &&\n  2878         (block.findStorageInfo(storageInfo) < 0)) {    \n  2879       addStoredBlock(block, ucBlock.reportedBlock, storageInfo, null, true);\n  2880     }   \n  2881   }   \n\n{noformat}\n\n- Replication Monitor which runs continuously tried to reconstruct the block on DN1, but {{BlockPlacementPolicyDefault}} failed to find the choose the same target\n\n{noformat}\n1148 2016-08-25 18:21:19,853 [ReplicationMonitor] WARN  net.NetworkTopology (NetworkTopology.java:chooseRandom(816)) - Failed to find datanode (scope=\"\" excludedScope=\"/default-rack\").\n1149 2016-08-25 18:21:19,853 [ReplicationMonitor] WARN  blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(402)) - Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy\n1150 2016-08-25 18:21:19,854 [ReplicationMonitor] WARN  net.NetworkTopology (NetworkTopology.java:chooseRandom(816)) - Failed to find datanode (scope=\"\" excludedScope=\"/default-rack\").\n1151 2016-08-25 18:21:19,854 [ReplicationMonitor] WARN  blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(402)) - Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy\n1152 2016-08-25 18:21:19,854 [ReplicationMonitor] WARN  protocol.BlockStoragePolicy (BlockStoragePolicy.java:chooseStorageTypes(161)) - Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK, ARCHIVE], removed=[DISK],      policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})\n1153 2016-08-25 18:21:19,854 [ReplicationMonitor] WARN  blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(402)) - Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) All required storage types are unavailable:  unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}\n1154 2016-08-25 18:21:19,854 [ReplicationMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1680)) - BLOCK* neededReconstruction = 1 pendingReconstruction = 0\n{noformat}\n\n\n*Fix:*\n\n- {{BlockManager::addStoredBlockUnderConstruction}} should not check for block --> datanode storage mapping for invoking BlockManager::addStoredBlock\n- {{BlockManager::addStoredBlock}} already handles Block addition/replacement/already_exists cases. And, more importantly it also prunes the {{LowRedundancyBlocks}} list\n\nAttached patch has the fix. Also, updated the unit test TestDataNodeHotSwapVolumes#testRemoveVolumeBeingWrittenForDatanode to expose race conditions which helped to recreate the above problem frequently. With the proposed fix, BlockManager handles the case properly and the test passes.\n\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=manojg","name":"manojg","key":"manojg","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Manoj Govindassamy","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-08-31T19:04:26.080+0000","updated":"2016-08-31T19:04:26.080+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13001537/comment/15453300","id":"15453300","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 21s{color} | {color:blue} Docker mode activated. {color} |\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  6m 47s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 43s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 28s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 51s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 12s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 44s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 56s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 49s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 45s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 45s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 25s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 51s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 10s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 51s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 53s{color} | {color:green} the patch passed {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 72m 46s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 18s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black} 92m  6s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| Failed junit tests | hadoop.hdfs.server.datanode.TestDataNodeHotSwapVolumes |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:9560f25 |\n| JIRA Issue | HDFS-10819 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12826475/HDFS-10819.001.patch |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux 89adb670a904 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / 01721dd |\n| Default Java | 1.8.0_101 |\n| findbugs | v3.0.0 |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/16597/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |\n|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/16597/testReport/ |\n| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/16597/console |\n| Powered by | Apache Yetus 0.4.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2016-08-31T20:40:47.931+0000","updated":"2016-08-31T20:40:47.931+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13001537/comment/15453308","id":"15453308","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=manojg","name":"manojg","key":"manojg","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Manoj Govindassamy","active":true,"timeZone":"America/Los_Angeles"},"body":"Unit test failure is not related to the patch. Have seen same failures earlier, without the patch.\njava.lang.AssertionError: expected:<0> but was:<9580424252>\n\tat org.junit.Assert.fail(Assert.java:88)\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=manojg","name":"manojg","key":"manojg","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Manoj Govindassamy","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-08-31T20:44:36.107+0000","updated":"2016-08-31T20:44:36.107+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13001537/comment/15459764","id":"15459764","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=andrew.wang","name":"andrew.wang","key":"andrew.wang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=andrew.wang&avatarId=19230","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=andrew.wang&avatarId=19230","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=andrew.wang&avatarId=19230","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=andrew.wang&avatarId=19230"},"displayName":"Andrew Wang","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks for working on this Manoj. Great investigation here.\n\nIIUC this is going to be a problem mostly for small clusters, right? We need to have a collision between two genstamps of the same block.\n\nWould this also be addressed by having the NN first invalidate the corrupt replica before replicating the correct one? I'm wondering if the safer fix is to wait for this invalidation by excluding nodes with corrupt replicas when doing block placement.\n\nAlso curious, would invalidation eventually fix this case, or is it truly stuck? That seems like another bug we should address.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=andrew.wang","name":"andrew.wang","key":"andrew.wang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=andrew.wang&avatarId=19230","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=andrew.wang&avatarId=19230","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=andrew.wang&avatarId=19230","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=andrew.wang&avatarId=19230"},"displayName":"Andrew Wang","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-09-02T22:32:31.944+0000","updated":"2016-09-02T22:32:31.944+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13001537/comment/15459935","id":"15459935","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=manojg","name":"manojg","key":"manojg","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Manoj Govindassamy","active":true,"timeZone":"America/Los_Angeles"},"body":"[~andrew.wang],\n\nThanks for reviewing the patch.\n\n{quote}We need to have a collision between two genstamps of the same block.{quote}\nMore importantly, if the same storage volume in DN happens to hold a block and its various genstamps, then without fix NN will not \"store\" the blocks with recent/higher genstamps. \n\n{quote}Would this also be addressed by having the NN first invalidate the corrupt replica before replicating the correct one{quote}\n{{BlockManager#markBlockAsCorrupt}} already tries to invalidate the corrupt blocks. But block invalidations are postponed if any of the replica are stale  and might not be invalidated for some time and will delay the block reaching to replication factor.\n\n{quote}Also curious, would invalidation eventually fix this case, or is it truly stuck?\n{code}\n    // add block to the datanode\n    AddBlockResult result = storageInfo.addBlock(storedBlock, reportedBlock);\n\n    if (result == AddBlockResult.ADDED) {\n    .. ..\n    } else if (result == AddBlockResult.REPLACED) {\n    .. .. \n    } else {\n      // if the same block is added again and the replica was corrupt\n      // previously because of a wrong gen stamp, remove it from the\n      // corrupt block list.\n      corruptReplicas.removeFromCorruptReplicasMap(block, node,\n          Reason.GENSTAMP_MISMATCH);\n      curReplicaDelta = 0;\n      blockLog.debug(\"BLOCK* addStoredBlock: Redundant addStoredBlock request\"\n              + \" received for {} on node {} size {}\", storedBlock, node,\n          storedBlock.getNumBytes());\n    }\n{code}\n\nAs you see above, there is code already in {{BlockManager#addStoredBlock}} to handle the case we are interested in -- Block with latest GS on the same storage volume. Except, the caller {{BlockManager#addStoredBlockUnderConstruction}} is mistakenly skipping the block and not allowing the other module to handle the case properly. Haven't explored the invalidation path fully and not sure if it solve the problem for testRemoveVolumeBeingWrittenForDatanode. Please let me know I need to explore this path.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=manojg","name":"manojg","key":"manojg","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Manoj Govindassamy","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-09-02T23:59:47.506+0000","updated":"2016-09-02T23:59:47.506+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13001537/comment/15547214","id":"15547214","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=manojg","name":"manojg","key":"manojg","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Manoj Govindassamy","active":true,"timeZone":"America/Los_Angeles"},"body":"[~andrew.wang],\n\n{quote} Also curious, would invalidation eventually fix this case, or is it truly stuck? {quote}\n* I find it totally stuck in this test case as we have only 3 DNs and the expected Replication factor is also 3. \n* Block invalidation was not going through and the replication factor failed to catch up. The reason why Block Invalidation at DataNode didn't go through was because the disk which held the block is already closed as it was removed.\n\n{noformat}\n 730 2016-10-04 15:52:30,709 WARN  impl.FsDatasetImpl (FsDatasetImpl.java:invalidate(1990)) - Volume /Users/manoj/work/cdh-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current is closed, ignore the deletion task for block ReplicaBeingWritten, blk_1073741825_1001, RBW\n 731   getNumBytes()     = 512\n 732   getBytesOnDisk()  = 512\n 733   getVisibleLength()= 512\n 734   getVolume()       = /Users/manoj/work/cdh-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current\n 735   getBlockFile()    = /Users/manoj/work/cdh-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-473099417-172.16.3.66-1475621545787/current/rbw/blk_1073741825\n 736   bytesAcked=512\n 737   bytesOnDisk=512\n{noformat}\n\nThe core fix here is letting {{BlockManager#addStoredBlockUnderConstruction}} invoke {{addStoredBlock}} for all Finalized blocks and let addStoredBlocks decide on (which is already happening) follow up actions of invalidations removal of corrupt replicas. \n\n[~andrew.wang], [~eddyxu], would like to hear your further thoughts on this.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=manojg","name":"manojg","key":"manojg","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Manoj Govindassamy","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-10-05T00:42:23.299+0000","updated":"2016-10-05T00:42:23.299+0000"}],"maxResults":7,"total":7,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-10819/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i331o7:"}}