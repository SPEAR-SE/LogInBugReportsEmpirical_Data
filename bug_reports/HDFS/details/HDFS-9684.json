{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12933321","self":"https://issues.apache.org/jira/rest/api/2/issue/12933321","key":"HDFS-9684","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/3","id":"3","description":"The problem is a duplicate of an existing issue.","name":"Duplicate"},"customfield_12312322":null,"customfield_12310220":"2016-01-22T15:06:05.905+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Tue Apr 19 02:41:17 UTC 2016","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_1256169_*|*_5_*:*_1_*:*_0_*|*_10002_*:*_1_*:*_628181879","customfield_12312321":null,"resolutiondate":"2016-01-29T18:46:56.564+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-9684/watchers","watchCount":8,"isWatching":false},"created":"2016-01-22T11:56:18.634+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/1","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/blocker.svg","name":"Blocker","id":"1"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"1.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12331979","id":"12331979","description":"2.7.1 release","name":"2.7.1","archived":false,"released":true,"releaseDate":"2015-07-06"}],"issuelinks":[{"id":"12455864","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12455864","type":{"id":"12310000","name":"Duplicate","inward":"is duplicated by","outward":"duplicates","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/12310000"},"outwardIssue":{"id":"12863061","key":"HDFS-9046","self":"https://issues.apache.org/jira/rest/api/2/issue/12863061","fields":{"summary":"Any Error during BPOfferService run can leads to Missing DN.","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/10002","description":"A patch for this issue has been uploaded to JIRA by a contributor.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/document.png","name":"Patch Available","id":"10002","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/4","id":4,"key":"indeterminate","colorName":"yellow","name":"In Progress"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12455495","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12455495","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"inwardIssue":{"id":"12514962","key":"HDFS-2182","self":"https://issues.apache.org/jira/rest/api/2/issue/12514962","fields":{"summary":"Exceptions in DataXceiver#run can result in a zombie datanode ","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12455494","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12455494","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"inwardIssue":{"id":"12527380","key":"HDFS-2452","self":"https://issues.apache.org/jira/rest/api/2/issue/12527380","fields":{"summary":"OutOfMemoryError in DataXceiverServer takes down the DataNode","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=surendrasingh","name":"surendrasingh","key":"surendrasingh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=surendrasingh&avatarId=30759","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=surendrasingh&avatarId=30759","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=surendrasingh&avatarId=30759","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=surendrasingh&avatarId=30759"},"displayName":"Surendra Singh Lilhore","active":true,"timeZone":"Etc/UTC"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2016-04-19T02:41:17.702+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12312927","id":"12312927","name":"datanode"}],"timeoriginalestimate":null,"description":"{noformat}\njava.lang.OutOfMemoryError: unable to create new native thread\n\tat java.lang.Thread.start0(Native Method)\n\tat java.lang.Thread.start(Thread.java:714)\n\tat org.apache.hadoop.hdfs.server.datanode.DataNode.transferBlock(DataNode.java:1999)\n\tat org.apache.hadoop.hdfs.server.datanode.DataNode.transferBlocks(DataNode.java:2008)\n\tat org.apache.hadoop.hdfs.server.datanode.BPOfferService.processCommandFromActive(BPOfferService.java:657)\n\tat org.apache.hadoop.hdfs.server.datanode.BPOfferService.processCommandFromActor(BPOfferService.java:615)\n\tat org.apache.hadoop.hdfs.server.datanode.BPServiceActor.processCommand(BPServiceActor.java:857)\n\tat org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:671)\n\tat org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:823)\n\tat java.lang.Thread.run(Thread.java:745)\n{noformat}","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12783819","id":"12783819","filename":"HDFS-9684.01.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=surendrasingh","name":"surendrasingh","key":"surendrasingh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=surendrasingh&avatarId=30759","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=surendrasingh&avatarId=30759","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=surendrasingh&avatarId=30759","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=surendrasingh&avatarId=30759"},"displayName":"Surendra Singh Lilhore","active":true,"timeZone":"Etc/UTC"},"created":"2016-01-22T12:06:08.546+0000","size":1269,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12783819/HDFS-9684.01.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"DataNode stopped sending heartbeat after getting OutOfMemoryError form DataTransfer thread.","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=surendrasingh","name":"surendrasingh","key":"surendrasingh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=surendrasingh&avatarId=30759","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=surendrasingh&avatarId=30759","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=surendrasingh&avatarId=30759","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=surendrasingh&avatarId=30759"},"displayName":"Surendra Singh Lilhore","active":true,"timeZone":"Etc/UTC"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=surendrasingh","name":"surendrasingh","key":"surendrasingh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=surendrasingh&avatarId=30759","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=surendrasingh&avatarId=30759","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=surendrasingh&avatarId=30759","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=surendrasingh&avatarId=30759"},"displayName":"Surendra Singh Lilhore","active":true,"timeZone":"Etc/UTC"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12933321/comment/15112361","id":"15112361","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=surendrasingh","name":"surendrasingh","key":"surendrasingh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=surendrasingh&avatarId=30759","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=surendrasingh&avatarId=30759","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=surendrasingh&avatarId=30759","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=surendrasingh&avatarId=30759"},"displayName":"Surendra Singh Lilhore","active":true,"timeZone":"Etc/UTC"},"body":"Here the problem is, {{DataNode.transferBlock()}} will start one thread to transfer block.\n{code}\n       new Daemon(new DataTransfer(xferTargets, xferTargetStorageTypes, block,\n            BlockConstructionStage.PIPELINE_SETUP_CREATE, \"\")).start();\n{code}\n but JVM is not able start new thread, so it will throw {{OutOfMemoryError}} and this will cause to interrupt {{BPServiceActor}} thread.\n\nAttached initial patch...\nPlease review ...","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=surendrasingh","name":"surendrasingh","key":"surendrasingh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=surendrasingh&avatarId=30759","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=surendrasingh&avatarId=30759","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=surendrasingh&avatarId=30759","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=surendrasingh&avatarId=30759"},"displayName":"Surendra Singh Lilhore","active":true,"timeZone":"Etc/UTC"},"created":"2016-01-22T12:16:59.785+0000","updated":"2016-01-22T12:16:59.785+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12933321/comment/15112512","id":"15112512","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 0s {color} | {color:blue} Docker mode activated. {color} |\n| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:red}-1{color} | {color:red} test4tests {color} | {color:red} 0m 0s {color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 7m 34s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 0m 50s {color} | {color:green} trunk passed with JDK v1.8.0_66 {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 0m 43s {color} | {color:green} trunk passed with JDK v1.7.0_91 {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 16s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 0m 52s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 13s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 1m 58s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 17s {color} | {color:green} trunk passed with JDK v1.8.0_66 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 54s {color} | {color:green} trunk passed with JDK v1.7.0_91 {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 0m 49s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 0m 48s {color} | {color:green} the patch passed with JDK v1.8.0_66 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 0m 48s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 0m 41s {color} | {color:green} the patch passed with JDK v1.7.0_91 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 0m 41s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 17s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 0m 51s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 10s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green} 0m 0s {color} | {color:green} Patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 2m 9s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 13s {color} | {color:green} the patch passed with JDK v1.8.0_66 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 51s {color} | {color:green} the patch passed with JDK v1.7.0_91 {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 78m 52s {color} | {color:red} hadoop-hdfs in the patch failed with JDK v1.8.0_66. {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 61m 6s {color} | {color:red} hadoop-hdfs in the patch failed with JDK v1.7.0_91. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green} 0m 22s {color} | {color:green} Patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black} 167m 24s {color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| JDK v1.8.0_66 Failed junit tests | hadoop.hdfs.server.blockmanagement.TestBlockManager |\n|   | hadoop.hdfs.server.namenode.TestDecommissioningStatus |\n|   | hadoop.hdfs.server.namenode.ha.TestFailureToReadEdits |\n|   | hadoop.hdfs.TestDFSClientRetries |\n|   | hadoop.hdfs.server.datanode.TestBlockScanner |\n| JDK v1.7.0_91 Failed junit tests | hadoop.hdfs.shortcircuit.TestShortCircuitCache |\n|   | hadoop.hdfs.server.namenode.ha.TestFailureToReadEdits |\n|   | hadoop.hdfs.TestDFSClientRetries |\n|   | hadoop.hdfs.server.datanode.TestBlockScanner |\n|   | hadoop.hdfs.TestBlockStoragePolicy |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:0ca8df7 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12783819/HDFS-9684.01.patch |\n| JIRA Issue | HDFS-9684 |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux 8866cee493b8 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / 0bae506 |\n| Default Java | 1.7.0_91 |\n| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_66 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_91 |\n| findbugs | v3.0.0 |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/14202/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.8.0_66.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/14202/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.7.0_91.txt |\n| unit test logs |  https://builds.apache.org/job/PreCommit-HDFS-Build/14202/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.8.0_66.txt https://builds.apache.org/job/PreCommit-HDFS-Build/14202/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.7.0_91.txt |\n| JDK v1.7.0_91  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/14202/testReport/ |\n| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |\n| Max memory used | 77MB |\n| Powered by | Apache Yetus 0.2.0-SNAPSHOT   http://yetus.apache.org |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/14202/console |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2016-01-22T15:06:05.905+0000","updated":"2016-01-22T15:06:05.905+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12933321/comment/15115523","id":"15115523","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"body":"That usually means the ulimit is reached. What is the max Xceiver limit in the datanode config? And what is the datanode user's limit on fork/clone? I.e. {{ulimit -u}}.  On a rare occasion, the system can run out of PID. I think the default on most linux distros is 32K. You can raise it if that's causing the problem.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"created":"2016-01-25T16:49:56.437+0000","updated":"2016-01-25T16:49:56.437+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12933321/comment/15116906","id":"15116906","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=surendrasingh","name":"surendrasingh","key":"surendrasingh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=surendrasingh&avatarId=30759","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=surendrasingh&avatarId=30759","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=surendrasingh&avatarId=30759","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=surendrasingh&avatarId=30759"},"displayName":"Surendra Singh Lilhore","active":true,"timeZone":"Etc/UTC"},"body":"Thanks [~kihwal] for comments.\n\nYes, ulimit is reached and this we did intentionally for reliability testing. We just want to see if the datanode recover automatically or not after removing the fault.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=surendrasingh","name":"surendrasingh","key":"surendrasingh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=surendrasingh&avatarId=30759","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=surendrasingh&avatarId=30759","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=surendrasingh&avatarId=30759","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=surendrasingh&avatarId=30759"},"displayName":"Surendra Singh Lilhore","active":true,"timeZone":"Etc/UTC"},"created":"2016-01-26T08:07:25.007+0000","updated":"2016-01-26T08:07:25.007+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12933321/comment/15117387","id":"15117387","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"body":"If we are to make datanode recoverable from such conditions, we need to take care of other essential services running in datanode. E.g. I've seen DU threads silently terminating, causing storage report to be stale. Sometimes crippled datanodes keep heartbeating so clients are sent there and cause more failures.  It feels like we need a self healthcheck in datanode along with recovery mechanism. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"created":"2016-01-26T15:32:28.285+0000","updated":"2016-01-26T15:32:28.285+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12933321/comment/15119871","id":"15119871","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=surendrasingh","name":"surendrasingh","key":"surendrasingh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=surendrasingh&avatarId=30759","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=surendrasingh&avatarId=30759","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=surendrasingh&avatarId=30759","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=surendrasingh&avatarId=30759"},"displayName":"Surendra Singh Lilhore","active":true,"timeZone":"Etc/UTC"},"body":"Yes, DN should have some healthcheck to monitor all the service threads.\n\nFor OutOfMemoryError one discussion happened in HDFS-2911 and I think conclusion is to kill the DN in case of OOM.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=surendrasingh","name":"surendrasingh","key":"surendrasingh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=surendrasingh&avatarId=30759","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=surendrasingh&avatarId=30759","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=surendrasingh&avatarId=30759","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=surendrasingh&avatarId=30759"},"displayName":"Surendra Singh Lilhore","active":true,"timeZone":"Etc/UTC"},"created":"2016-01-27T17:48:37.463+0000","updated":"2016-01-27T17:48:37.463+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12933321/comment/15122615","id":"15122615","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"body":"This is likely to be a duplicate of HDFS-9046, though I have not reviewed either of the patches in enough detail to say for sure.\n\nbq. ...I think conclusion is to kill the DN in case of OOM.\n\nIn general, I am opposed to attempting recovery from {{OutOfMemoryError}}, especially if it's a true memory allocation problem and not thread exhaustion like shown here.  The trouble with trying to recover is that it's extremely difficult to predict what state we were in right before the memory allocation failed, and therefore we can't tell what kind of repair work might be required.  It would be easy to end up with an internal data structure half-modified with no way to either roll back or roll forward to complete the modification later.  Then, the process keeps running in an indeterminate state that we never anticipated, so its behavior will be unpredictable.\n\nAlas, we already have established code that tries to recover from {{OutOfMemoryError}}, most notably in the RPC {{Server}}.  Some of us prefer to launch the JVM with the {{-XX:OnOutOfMemoryError}} argument set so that the process kills itself.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-01-29T00:32:35.103+0000","updated":"2016-01-29T00:32:35.103+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12933321/comment/15123088","id":"15123088","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=surendrasingh","name":"surendrasingh","key":"surendrasingh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=surendrasingh&avatarId=30759","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=surendrasingh&avatarId=30759","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=surendrasingh&avatarId=30759","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=surendrasingh&avatarId=30759"},"displayName":"Surendra Singh Lilhore","active":true,"timeZone":"Etc/UTC"},"body":"Thanks [~cnauroth].\n\nYes, it is duplicate of HDFS-9046.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=surendrasingh","name":"surendrasingh","key":"surendrasingh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=surendrasingh&avatarId=30759","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=surendrasingh&avatarId=30759","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=surendrasingh&avatarId=30759","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=surendrasingh&avatarId=30759"},"displayName":"Surendra Singh Lilhore","active":true,"timeZone":"Etc/UTC"},"created":"2016-01-29T06:52:03.684+0000","updated":"2016-01-29T06:52:03.684+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12933321/comment/15194914","id":"15194914","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=walter.k.su","name":"walter.k.su","key":"walter.k.su","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Walter Su","active":true,"timeZone":"Asia/Shanghai"},"body":"I have seen a case DN got command from NN to transfer huge numbers of blocks. There's 7000+ threads at its peak. I don't  advocate recover from {{OutOfMemoryError}}. But it's our responsibility not to create too much threads at first place.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=walter.k.su","name":"walter.k.su","key":"walter.k.su","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Walter Su","active":true,"timeZone":"Asia/Shanghai"},"created":"2016-03-15T08:22:32.754+0000","updated":"2016-03-15T08:22:32.754+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12933321/comment/15247037","id":"15247037","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=walter.k.su","name":"walter.k.su","key":"walter.k.su","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Walter Su","active":true,"timeZone":"Asia/Shanghai"},"body":"My previous comment is incorrect. It turns out that the MR tasks swallowed all the virtual memories.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=walter.k.su","name":"walter.k.su","key":"walter.k.su","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Walter Su","active":true,"timeZone":"Asia/Shanghai"},"created":"2016-04-19T02:41:17.702+0000","updated":"2016-04-19T02:41:17.702+0000"}],"maxResults":10,"total":10,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-9684/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i2ruaf:"}}