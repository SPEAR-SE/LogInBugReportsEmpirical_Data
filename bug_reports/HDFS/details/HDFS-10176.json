{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12951063","self":"https://issues.apache.org/jira/rest/api/2/issue/12951063","key":"HDFS-10176","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":"2016-03-17T20:35:15.444+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Thu Nov 24 20:45:44 UTC 2016","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-10176/watchers","watchCount":5,"isWatching":false},"created":"2016-03-17T01:49:52.404+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12327584","id":"12327584","description":"2.7.0 release","name":"2.7.0","archived":false,"released":true,"releaseDate":"2015-04-20"}],"issuelinks":[],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2016-11-24T20:45:44.185+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12319200","id":"12319200","name":"webhdfs","description":"WebHDFS: HTTP REST API for HDFS"}],"timeoriginalestimate":null,"description":"http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/WebHDFS.html#List_a_Directory\n\nTimes, names, sizes would allow a Web client to offer a richer experience to its user:\n{code}\n{\n        \"accessTime\"      : 1320171722771,\n        \"blockSize\"       : 33554432,\n        \"group\"           : \"supergroup\",\n        \"length\"          : 24930,\n        \"modificationTime\": 1320171722771,\n        \"owner\"           : \"webuser\",\n        \"pathSuffix\"      : \"a.patch\",\n        \"permission\"      : \"644\",\n        \"replication\"     : 1,\n        \"type\"            : \"FILE\"\n      },\n{code}","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"WebHdfs LISTSTATUS does not offer any sorting","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=romainr","name":"romainr","key":"romainr","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Romain Rigaux","active":true,"timeZone":"Etc/UTC"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=romainr","name":"romainr","key":"romainr","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Romain Rigaux","active":true,"timeZone":"Etc/UTC"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12951063/comment/15200320","id":"15200320","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=andrew.wang","name":"andrew.wang","key":"andrew.wang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=andrew.wang&avatarId=19230","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=andrew.wang&avatarId=19230","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=andrew.wang&avatarId=19230","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=andrew.wang&avatarId=19230"},"displayName":"Andrew Wang","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi Romain, is the request to expose additional fields in the [Java FileStatus object|https://github.com/apache/hadoop/blob/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FileStatus.java]? Or you want sorting on these different fields?\n\nWe do pagination right now based on the path since that's the primary key. I'd rather implement different sort orders on the client-side to avoid additional NN overhead.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=andrew.wang","name":"andrew.wang","key":"andrew.wang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=andrew.wang&avatarId=19230","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=andrew.wang&avatarId=19230","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=andrew.wang&avatarId=19230","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=andrew.wang&avatarId=19230"},"displayName":"Andrew Wang","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-03-17T20:35:15.444+0000","updated":"2016-03-17T20:35:15.444+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12951063/comment/15200709","id":"15200709","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=romainr","name":"romainr","key":"romainr","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Romain Rigaux","active":true,"timeZone":"Etc/UTC"},"body":"Sorting on the existing files. \n\nFor example, if a client, let's say a Web server, wants to display the latest 100 files of a directory, and there are 100 000 files, it needs to pull all the files and sort it himself. If the users wants to sort on another criteria, the client needs to re-fetch all the 100 000 files and sort again (as Web is stateless). We lose the benefit of the future pagination HDFS-9366 at the same time. \n\nHence the long term solution / advantage of doing everything at the source, especially if pagination is implemented (limited set to sort), the sorting should not add too much NN overhead (and we also skip the cost of the current massive LISTDIR calls).\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=romainr","name":"romainr","key":"romainr","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Romain Rigaux","active":true,"timeZone":"Etc/UTC"},"created":"2016-03-18T00:37:17.831+0000","updated":"2016-03-18T00:37:17.831+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12951063/comment/15685217","id":"15685217","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lucaslm","name":"lucaslm","key":"lucaslm","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Lucas Lustosa Madureira","active":true,"timeZone":"Etc/UTC"},"body":"Greetings\n\nI gave it a try on resolving his issue.\nAs I understand it, the WebHDFS is supposed to expose the methods of [org.apache.hadoop.fs.FileSystem|https://hadoop.apache.org/docs/current/api/org/apache/hadoop/fs/FileSystem.html]. As it stands, this class does not have a version of listStatus that supports ordering. Ideally, to solving this issue involves adding such method to this class. Adding this method was easy enough (take a look at [this patch|http://pastebin.com/raw/R4G5FjQq]).\nThe next step should be to modify the WebHDFS url to understand a new parameter, for instance:\n\n{code:borderStyle=solid}\ncurl -i  \"http://<HOST>:<PORT>/webhdfs/v1/<PATH>?op=LISTSTATUS[&orderBy=<ORDERBY>]\"\n{code}\n\nThen it would be necessary to check if the parameter is set and call the appropriate version of listStatus.\nUnfortunately I could not figure this part. I could verify that the request to the URL above is (at least partially) fulfilled by the class [org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods|https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/web/resources/NamenodeWebHdfsMethods.java]. Looking at the class [org.apache.hadoop.hdfs.web.WebHdfsFileSystem|https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java], I got the impression that this class somehow causes the code on NamenodeWebHdfsMethods to run. If that is what happens, I think I need to know which part of the code calls WebHdfsFileSystem.listStatus, and apply there the changes proposed on the previous paragraph.\nUnfortunatelly I could not figure this out, specially as there is no documentation of the inner workings of the hadoop project.\nTo add to my confusion, there are also the classes at [org.apache.hadoop.http|https://github.com/apache/hadoop/tree/trunk/hadoop-hdfs-project/hadoop-hdfs-httpfs/src/main/java/org/apache/hadoop/fs/http], which I am not sure are related to WebHdfs or not (they also deal with http requests and hdfs).\nShould I make no progress, at least this comment is a starting point for anyone who tries to address this issue.\n\nPS. How do you guys package a new hadoop source? It takes me almost half an hour to package it with maven, even though I only change a few lines of a file.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lucaslm","name":"lucaslm","key":"lucaslm","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Lucas Lustosa Madureira","active":true,"timeZone":"Etc/UTC"},"created":"2016-11-22T00:27:32.938+0000","updated":"2016-11-22T00:27:32.938+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12951063/comment/15694182","id":"15694182","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lucaslm","name":"lucaslm","key":"lucaslm","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Lucas Lustosa Madureira","active":true,"timeZone":"Etc/UTC"},"body":"I've noticed the class FileSystem has been updated. Here is the [new patch|http://pastebin.com/raw/c9C56CE7] against the [latest commit|https://github.com/apache/hadoop/commit/01665e456de8d79000ce273dded5ea53aa62965a].","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lucaslm","name":"lucaslm","key":"lucaslm","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Lucas Lustosa Madureira","active":true,"timeZone":"Etc/UTC"},"created":"2016-11-24T20:45:44.185+0000","updated":"2016-11-24T20:45:44.185+0000"}],"maxResults":4,"total":4,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-10176/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i2usxj:"}}