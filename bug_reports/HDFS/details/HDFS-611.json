{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12435284","self":"https://issues.apache.org/jira/rest/api/2/issue/12435284","key":"HDFS-611","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12314046","id":"12314046","description":"","name":"0.21.0","archived":false,"released":true,"releaseDate":"2010-08-23"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12318243","id":"12318243","description":"1.0.0 release","name":"1.0.0","archived":false,"released":true,"releaseDate":"2011-12-27"}],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2009-09-10T16:47:39.889+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Wed Nov 09 21:33:08 UTC 2011","customfield_12310420":"16831","customfield_12312320":null,"customfield_12310222":"10002_*:*_6_*:*_1070558200_*|*_1_*:*_6_*:*_4198262039_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2009-11-10T07:40:22.117+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-611/watchers","watchCount":14,"isWatching":false},"created":"2009-09-10T08:06:41.878+0000","customfield_12310192":null,"customfield_12310191":[{"self":"https://issues.apache.org/jira/rest/api/2/customFieldOption/10343","value":"Reviewed","id":"10343"}],"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"12.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12314048","id":"12314048","description":"","name":"0.20.1","archived":false,"released":true,"releaseDate":"2009-09-01"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12314046","id":"12314046","description":"","name":"0.21.0","archived":false,"released":true,"releaseDate":"2010-08-23"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12314241","id":"12314241","description":"","name":"0.22.0","archived":false,"released":true,"releaseDate":"2011-12-10"}],"issuelinks":[{"id":"12328246","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12328246","type":{"id":"10032","name":"Blocker","inward":"is blocked by","outward":"blocks","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10032"},"inwardIssue":{"id":"12443050","key":"HADOOP-6433","self":"https://issues.apache.org/jira/rest/api/2/issue/12443050","fields":{"summary":"Add AsyncDiskService that is used in both hdfs and mapreduce","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/2","id":"2","description":"A new feature of the product, which has yet to be developed.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype","name":"New Feature","subtask":false,"avatarId":21141}}}},{"id":"12327797","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12327797","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"12440607","key":"MAPREDUCE-1213","self":"https://issues.apache.org/jira/rest/api/2/issue/12440607","fields":{"summary":"TaskTrackers restart is very slow because it deletes distributed cache directory synchronously","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12326794","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12326794","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"inwardIssue":{"id":"12357496","key":"HADOOP-774","self":"https://issues.apache.org/jira/rest/api/2/issue/12357496","fields":{"summary":"Datanodes fails to heartbeat when a directory with a large number of blocks is deleted","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12326795","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12326795","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"inwardIssue":{"id":"12362347","key":"HADOOP-994","self":"https://issues.apache.org/jira/rest/api/2/issue/12362347","fields":{"summary":"DFS Scalability : a BlockReport that returns large number of blocks-to-be-deleted cause datanode to lost connectivity to namenode","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=zshao","name":"zshao","key":"zshao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=zshao&avatarId=14358","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=zshao&avatarId=14358","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=zshao&avatarId=14358","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=zshao&avatarId=14358"},"displayName":"Zheng Shao","active":true,"timeZone":"America/Los_Angeles"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2011-11-09T21:33:08.684+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12312927","id":"12312927","name":"datanode"}],"timeoriginalestimate":null,"description":"I am seeing that when we delete a large directory that has plenty of blocks, the heartbeat times from datanodes increase significantly from the normal value of 3 seconds to as large as 50 seconds or so. The heartbeat thread in the Datanode deletes a bunch of blocks sequentially, this causes the heartbeat times to increase.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12318243","id":"12318243","description":"1.0.0 release","name":"1.0.0","archived":false,"released":true,"releaseDate":"2011-12-27"}],"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12423495","id":"12423495","filename":"HDFS-611.branch-19.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=zshao","name":"zshao","key":"zshao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=zshao&avatarId=14358","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=zshao&avatarId=14358","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=zshao&avatarId=14358","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=zshao&avatarId=14358"},"displayName":"Zheng Shao","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-10-28T21:40:39.676+0000","size":8497,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12423495/HDFS-611.branch-19.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12423523","id":"12423523","filename":"HDFS-611.branch-19.v2.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=zshao","name":"zshao","key":"zshao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=zshao&avatarId=14358","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=zshao&avatarId=14358","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=zshao&avatarId=14358","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=zshao&avatarId=14358"},"displayName":"Zheng Shao","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-10-29T01:43:52.914+0000","size":7887,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12423523/HDFS-611.branch-19.v2.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12423500","id":"12423500","filename":"HDFS-611.branch-20.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=zshao","name":"zshao","key":"zshao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=zshao&avatarId=14358","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=zshao&avatarId=14358","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=zshao&avatarId=14358","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=zshao&avatarId=14358"},"displayName":"Zheng Shao","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-10-28T22:13:14.305+0000","size":8499,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12423500/HDFS-611.branch-20.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12423524","id":"12423524","filename":"HDFS-611.branch-20.v2.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=zshao","name":"zshao","key":"zshao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=zshao&avatarId=14358","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=zshao&avatarId=14358","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=zshao&avatarId=14358","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=zshao&avatarId=14358"},"displayName":"Zheng Shao","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-10-29T01:44:08.376+0000","size":7889,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12423524/HDFS-611.branch-20.v2.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12424512","id":"12424512","filename":"HDFS-611.branch-20.v6.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=zshao","name":"zshao","key":"zshao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=zshao&avatarId=14358","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=zshao&avatarId=14358","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=zshao&avatarId=14358","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=zshao&avatarId=14358"},"displayName":"Zheng Shao","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-11-10T21:37:38.216+0000","size":14797,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12424512/HDFS-611.branch-20.v6.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12423501","id":"12423501","filename":"HDFS-611.trunk.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=zshao","name":"zshao","key":"zshao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=zshao&avatarId=14358","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=zshao&avatarId=14358","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=zshao&avatarId=14358","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=zshao&avatarId=14358"},"displayName":"Zheng Shao","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-10-28T22:13:30.590+0000","size":8452,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12423501/HDFS-611.trunk.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12423525","id":"12423525","filename":"HDFS-611.trunk.v2.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=zshao","name":"zshao","key":"zshao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=zshao&avatarId=14358","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=zshao&avatarId=14358","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=zshao&avatarId=14358","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=zshao&avatarId=14358"},"displayName":"Zheng Shao","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-10-29T01:44:23.745+0000","size":7842,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12423525/HDFS-611.trunk.v2.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12423671","id":"12423671","filename":"HDFS-611.trunk.v3.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=zshao","name":"zshao","key":"zshao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=zshao&avatarId=14358","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=zshao&avatarId=14358","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=zshao&avatarId=14358","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=zshao&avatarId=14358"},"displayName":"Zheng Shao","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-10-30T08:25:24.553+0000","size":12145,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12423671/HDFS-611.trunk.v3.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12423872","id":"12423872","filename":"HDFS-611.trunk.v4.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=zshao","name":"zshao","key":"zshao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=zshao&avatarId=14358","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=zshao&avatarId=14358","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=zshao&avatarId=14358","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=zshao&avatarId=14358"},"displayName":"Zheng Shao","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-11-03T01:00:29.686+0000","size":15031,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12423872/HDFS-611.trunk.v4.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12424003","id":"12424003","filename":"HDFS-611.trunk.v5.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=zshao","name":"zshao","key":"zshao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=zshao&avatarId=14358","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=zshao&avatarId=14358","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=zshao&avatarId=14358","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=zshao&avatarId=14358"},"displayName":"Zheng Shao","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-11-04T04:20:15.262+0000","size":15032,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12424003/HDFS-611.trunk.v5.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12424171","id":"12424171","filename":"HDFS-611.trunk.v6.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=zshao","name":"zshao","key":"zshao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=zshao&avatarId=14358","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=zshao&avatarId=14358","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=zshao&avatarId=14358","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=zshao&avatarId=14358"},"displayName":"Zheng Shao","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-11-06T00:28:49.962+0000","size":15059,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12424171/HDFS-611.trunk.v6.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12502841","id":"12502841","filename":"HDFS-611-branch-0.20-security.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jnp","name":"jnp","key":"jnp","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jitendra Nath Pandey","active":true,"timeZone":"Etc/UTC"},"created":"2011-11-07T23:27:25.737+0000","size":14566,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12502841/HDFS-611-branch-0.20-security.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"14236","customfield_12312823":null,"summary":"Heartbeats times from Datanodes increase when there are plenty of blocks to delete","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12435284/comment/12753499","id":"12753499","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"body":"This patch uses a pool of threads to delete block files on the datanodes. By default, a pool of 5 threads is used but this value canbe overridden by a config parameter hdfs.datanode.delete.threadpool.size.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"created":"2009-09-10T08:22:33.614+0000","updated":"2009-09-10T08:22:33.614+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12435284/comment/12753697","id":"12753697","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"body":"Why not instead have a queue of blocks to delete and a single thread that deletes them?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-09-10T16:47:39.889+0000","updated":"2009-09-10T16:47:39.889+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12435284/comment/12753839","id":"12753839","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"body":"That os certainly possible. On the other hand, what I have learnt is that deleting a file in ext3 is slow, especially if the file is big because ext3 will synchornously access all indirect blocks and free them, thus requiring more disk IOs. The speed of deletion is dependent on the size of the file. This means that if we have a single thread in the Datanode doing all the deletes, it might not be able to keep up if the incoming rate of blocks-to-be-deleted is high. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"created":"2009-09-10T21:53:34.635+0000","updated":"2009-09-10T21:53:34.635+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12435284/comment/12753861","id":"12753861","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"body":"If it's i/o bound it could make sense to have one thread per volume.  The datanode knows the number of volumes and could use that instead of a config option.  But do you really think a single thread would get so far behind that the queue of blocks to delete would exhaust the datanode's heap?  Most datanodes only have a few thousand blocks, don't they?  And not using all of the i/o bandwidth for block deletion might be a feature.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-09-10T22:25:31.511+0000","updated":"2009-09-10T22:25:31.511+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12435284/comment/12753866","id":"12753866","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"body":"> The datanode knows the number of volumes and could use that instead of a config option\n\nThis makes sense to me.\n\n> But do you really think a single thread would get so far behind that the queue of blocks to delete would exhaust the datanode's heap\n\nI will test how fact a file deletion on ext3 is. will report back with some numbers.\n\nAnother thing that I am keeping in mind is that if a thread asyncronously processes block file deletions while freeing the heartbeat thread to continue hearbeating to the namenode might introduce new race conditions. Let's assume that a blockfile deletion request is queud up. Then the datanode decides to send a block report and will report that block to the NN. Then the async trhead will start prcessing items from the queue and delete the block file. This could be bad! The Nameode will think that the datanode has this block whereas actually it is now gone from the datanode. \n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"created":"2009-09-10T22:34:04.685+0000","updated":"2009-09-10T22:34:04.685+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12435284/comment/12753869","id":"12753869","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=eli","name":"eli","key":"eli","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eli Collins","active":true,"timeZone":"America/Los_Angeles"},"body":"Why is the heartbeat thread involved with block deletion?  \n\nPer the fifth comment in HDFS-599 can someone explain in general why the failure detection code is not encapsulated from the rest of the daemon? If it were a separate module it seems that we wouldn't have to worry about RPC priorities, JVM GC, block deletion, etc interfering with it.\n\nThanks,\nEli","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=eli","name":"eli","key":"eli","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eli Collins","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-09-10T22:39:50.818+0000","updated":"2009-09-10T22:39:50.818+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12435284/comment/12753883","id":"12753883","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"body":"> Why is the heartbeat thread involved with block deletion?\n\nThe namenode returns lists of blocks to delete in heartbeat responses.\n\n>  The Nameode will think that the datanode has this block whereas actually it is now gone from the datanode.\n\nThe datanode might remove blocks immediately from its in-memory lists that are used to generate block reports but the background thread could remove the actual block files.  If the datanode crashes then the discrepancy between what's on disk and what the namenode thinks should be on disk will be resolved at restart when it sends its initial block report.  Could that work?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-09-10T23:07:26.436+0000","updated":"2009-09-10T23:07:26.436+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12435284/comment/12754040","id":"12754040","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"body":"> The datanode might remove blocks immediately from its in-memory lists that are used to generate block reports but the background thread could remove the actual block files\n\nthat will work too. will submit a patch soon.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"created":"2009-09-11T08:17:29.836+0000","updated":"2009-09-11T08:17:29.836+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12435284/comment/12766851","id":"12766851","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=zshao","name":"zshao","key":"zshao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=zshao&avatarId=14358","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=zshao&avatarId=14358","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=zshao&avatarId=14358","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=zshao&avatarId=14358"},"displayName":"Zheng Shao","active":true,"timeZone":"America/Los_Angeles"},"body":"+1 on the idea.\n\nEncountered this bug on 0.19 when doing a HDFS stress test - DataNode was not able to send received block list, so client gets \"block not replicated\" exception.\n\nI think we can start with 1 thread per volumn, and in case it cannot keep up, we can make that \"1\" configurable.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=zshao","name":"zshao","key":"zshao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=zshao&avatarId=14358","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=zshao&avatarId=14358","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=zshao&avatarId=14358","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=zshao&avatarId=14358"},"displayName":"Zheng Shao","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-10-17T07:27:07.861+0000","updated":"2009-10-17T07:27:07.861+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12435284/comment/12771127","id":"12771127","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=zshao","name":"zshao","key":"zshao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=zshao&avatarId=14358","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=zshao&avatarId=14358","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=zshao&avatarId=14358","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=zshao&avatarId=14358"},"displayName":"Zheng Shao","active":true,"timeZone":"America/Los_Angeles"},"body":"This patch adds a new class BlockFileDeleter, which delete block files asynchronously using one ThreadPoolExecutor for each volume. BlockFileDeleter is used internally in FSDataset.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=zshao","name":"zshao","key":"zshao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=zshao&avatarId=14358","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=zshao&avatarId=14358","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=zshao&avatarId=14358","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=zshao&avatarId=14358"},"displayName":"Zheng Shao","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-10-28T21:40:39.734+0000","updated":"2009-10-28T21:40:39.734+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12435284/comment/12771153","id":"12771153","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=zshao","name":"zshao","key":"zshao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=zshao&avatarId=14358","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=zshao&avatarId=14358","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=zshao&avatarId=14358","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=zshao&avatarId=14358"},"displayName":"Zheng Shao","active":true,"timeZone":"America/Los_Angeles"},"body":"Tested on a 4-node hadoop-0.19 cluster. We are able to write new large files smoothly (without any BlockNotReplicateException which is caused by slow heartbeats) right after deleting a lot of blocks.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=zshao","name":"zshao","key":"zshao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=zshao&avatarId=14358","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=zshao&avatarId=14358","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=zshao&avatarId=14358","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=zshao&avatarId=14358"},"displayName":"Zheng Shao","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-10-28T22:15:36.022+0000","updated":"2009-10-28T22:15:36.022+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12435284/comment/12771163","id":"12771163","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"body":"I looked at the version for trunk.\n\nThe call to volume.decDfsUsed(blockSize)() is being called from the background BlockFileDeleter thread. This might not be protected by the FSDataSet lock anymore.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"created":"2009-10-28T22:32:17.940+0000","updated":"2009-10-28T22:32:17.940+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12435284/comment/12771181","id":"12771181","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=zshao","name":"zshao","key":"zshao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=zshao&avatarId=14358","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=zshao&avatarId=14358","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=zshao&avatarId=14358","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=zshao&avatarId=14358"},"displayName":"Zheng Shao","active":true,"timeZone":"America/Los_Angeles"},"body":"There are 3 approaches:\nA1. Decrement the dfs usage when we schedule the task.\nA2. Pass a handle of FSDataset to BlockFileDeleter ctor, so we can do \"synchronized(fsdataset) { ... }\" in the BlockFileDeleteTask\nA3. Add a method in FSDataset for decrementing the dfs usage for a volume.\n\nA1 is not good because the dfs usage won't be accurate.\nA3 is changing the interface - but the method to decrement dfs usage shouldn't be exposed from FSDataset I think.\nI prefer A2.\n\nWill that work?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=zshao","name":"zshao","key":"zshao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=zshao&avatarId=14358","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=zshao&avatarId=14358","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=zshao&avatarId=14358","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=zshao&avatarId=14358"},"displayName":"Zheng Shao","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-10-28T23:02:01.745+0000","updated":"2009-10-28T23:02:01.745+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12435284/comment/12771191","id":"12771191","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=zshao","name":"zshao","key":"zshao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=zshao&avatarId=14358","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=zshao&avatarId=14358","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=zshao&avatarId=14358","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=zshao&avatarId=14358"},"displayName":"Zheng Shao","active":true,"timeZone":"America/Los_Angeles"},"body":"A4. Do \"synchronized(fsdataset)\" in \"void decDfsUsed(...)\". That function is called only from \"BlockFileDeleteTask\" now.\nA5. Do \"synchronized void decDfsUsed(...)\". This will move the lock down to the volume, to make it faster.\n\nAlthough A5 might help us avoid some contentions, I don't see any code that locks a volume. I guess we always lock the FSDataset.\n\nI prefer A4 the best.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=zshao","name":"zshao","key":"zshao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=zshao&avatarId=14358","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=zshao&avatarId=14358","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=zshao&avatarId=14358","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=zshao&avatarId=14358"},"displayName":"Zheng Shao","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-10-28T23:18:46.412+0000","updated":"2009-10-28T23:18:46.412+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12435284/comment/12771207","id":"12771207","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"body":"# Do we still need to send a partial list of blocks from the name-node in the BlockCommand? This was the reason we did it in the first place, right? So may be now we can send all blocks at once while data-node controls how fast it removes them.\n# I'd suggest something with Replica instead of Block, like ReplicaFileDeleter. Data-nodes store *replicas* of *blocks* known to the name-node.\n# There are 27 unnecessary imports in the new file, it would be good to clean this up.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-10-28T23:57:29.489+0000","updated":"2009-10-28T23:57:29.489+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12435284/comment/12771214","id":"12771214","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"body":"4. In {{FSDataset.invalidate(Block[])}} you expose inner class {{BlockFileDeleteClass}}. I think it would be better to hide everything inside the {{BlockFileDeleter}}. Just replace lines 1610-1617 with one call {{deleter.deleteFile(v, file, metaFile, ...)}}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-10-29T00:11:15.683+0000","updated":"2009-10-29T00:11:15.683+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12435284/comment/12771226","id":"12771226","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"-1 overall.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12423501/HDFS-611.trunk.patch\n  against trunk revision 830003.\n\n    +1 @author.  The patch does not contain any @author tags.\n\n    -1 tests included.  The patch doesn't appear to include any new or modified tests.\n                        Please justify why no new tests are needed for this patch.\n                        Also please list what manual steps were performed to verify this patch.\n\n    +1 javadoc.  The javadoc tool did not generate any warning messages.\n\n    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.\n\n    +1 findbugs.  The patch does not introduce any new Findbugs warnings.\n\n    +1 release audit.  The applied patch does not increase the total number of release audit warnings.\n\n    -1 core tests.  The patch failed core unit tests.\n\n    +1 contrib tests.  The patch passed contrib unit tests.\n\nTest results: http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h5.grid.sp2.yahoo.net/86/testReport/\nFindbugs warnings: http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h5.grid.sp2.yahoo.net/86/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html\nCheckstyle results: http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h5.grid.sp2.yahoo.net/86/artifact/trunk/build/test/checkstyle-errors.html\nConsole output: http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h5.grid.sp2.yahoo.net/86/console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2009-10-29T00:51:20.950+0000","updated":"2009-10-29T00:51:20.950+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12435284/comment/12771253","id":"12771253","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=zshao","name":"zshao","key":"zshao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=zshao&avatarId=14358","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=zshao&avatarId=14358","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=zshao&avatarId=14358","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=zshao&avatarId=14358"},"displayName":"Zheng Shao","active":true,"timeZone":"America/Los_Angeles"},"body":"Made 2 changes:\n# Follow the approach A4 above for the lock\n# Removed the used imports\n\nRegarding the other comments:\n1. Most of the classes in DataNode are named Block* although some of them represent a replica as well. From consistency point of view, it seems to me BlockFileDeleter is a better name.\n2. I think it still makes sense to limit the number of block invalidation requests per heartbeat. We don't want a single heartbeat to be too big. I agree the limit can set to something much bigger, e.g. 1000 or 5000.\n3. I like the abstraction of creating a task using the 5 arguments, and then do \"execute(Task)\". This makes it easy to add new fields to the Task. Also it mimics the ThreadPoolExecutor.execute(...) function which makes it clearer that the operation is asynchronous.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=zshao","name":"zshao","key":"zshao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=zshao&avatarId=14358","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=zshao&avatarId=14358","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=zshao&avatarId=14358","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=zshao&avatarId=14358"},"displayName":"Zheng Shao","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-10-29T01:43:52.975+0000","updated":"2009-10-29T01:43:52.975+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12435284/comment/12771311","id":"12771311","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"-1 overall.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12423525/HDFS-611.trunk.v2.patch\n  against trunk revision 830804.\n\n    +1 @author.  The patch does not contain any @author tags.\n\n    -1 tests included.  The patch doesn't appear to include any new or modified tests.\n                        Please justify why no new tests are needed for this patch.\n                        Also please list what manual steps were performed to verify this patch.\n\n    +1 javadoc.  The javadoc tool did not generate any warning messages.\n\n    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.\n\n    +1 findbugs.  The patch does not introduce any new Findbugs warnings.\n\n    +1 release audit.  The applied patch does not increase the total number of release audit warnings.\n\n    -1 core tests.  The patch failed core unit tests.\n\n    +1 contrib tests.  The patch passed contrib unit tests.\n\nTest results: http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h5.grid.sp2.yahoo.net/88/testReport/\nFindbugs warnings: http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h5.grid.sp2.yahoo.net/88/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html\nCheckstyle results: http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h5.grid.sp2.yahoo.net/88/artifact/trunk/build/test/checkstyle-errors.html\nConsole output: http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h5.grid.sp2.yahoo.net/88/console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2009-10-29T07:13:52.117+0000","updated":"2009-10-29T07:13:52.117+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12435284/comment/12771871","id":"12771871","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=zshao","name":"zshao","key":"zshao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=zshao&avatarId=14358","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=zshao&avatarId=14358","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=zshao&avatarId=14358","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=zshao&avatarId=14358"},"displayName":"Zheng Shao","active":true,"timeZone":"America/Los_Angeles"},"body":"Added a test case. Also changed the maximum number of block invalidation commands per heartbeat to 1000. That will make heartbeat response size ~ 100K, which maps to ~1ms on a 1Gbps NIC. This in turn maps to the capability of serving ~3000 nodes with 3 second heartbeat latency.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=zshao","name":"zshao","key":"zshao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=zshao&avatarId=14358","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=zshao&avatarId=14358","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=zshao&avatarId=14358","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=zshao&avatarId=14358"},"displayName":"Zheng Shao","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-10-30T08:25:24.599+0000","updated":"2009-10-30T08:25:24.599+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12435284/comment/12771872","id":"12771872","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=zshao","name":"zshao","key":"zshao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=zshao&avatarId=14358","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=zshao&avatarId=14358","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=zshao&avatarId=14358","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=zshao&avatarId=14358"},"displayName":"Zheng Shao","active":true,"timeZone":"America/Los_Angeles"},"body":"The change of maximum block invalidation commands per heartbeat is for Konstantin's point 4 above.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=zshao","name":"zshao","key":"zshao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=zshao&avatarId=14358","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=zshao&avatarId=14358","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=zshao&avatarId=14358","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=zshao&avatarId=14358"},"displayName":"Zheng Shao","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-10-30T08:26:44.649+0000","updated":"2009-10-30T08:26:44.649+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12435284/comment/12771901","id":"12771901","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"-1 overall.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12423671/HDFS-611.trunk.v3.patch\n  against trunk revision 831170.\n\n    +1 @author.  The patch does not contain any @author tags.\n\n    +1 tests included.  The patch appears to include 4 new or modified tests.\n\n    +1 javadoc.  The javadoc tool did not generate any warning messages.\n\n    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.\n\n    +1 findbugs.  The patch does not introduce any new Findbugs warnings.\n\n    +1 release audit.  The applied patch does not increase the total number of release audit warnings.\n\n    -1 core tests.  The patch failed core unit tests.\n\n    +1 contrib tests.  The patch passed contrib unit tests.\n\nTest results: http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h5.grid.sp2.yahoo.net/90/testReport/\nFindbugs warnings: http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h5.grid.sp2.yahoo.net/90/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html\nCheckstyle results: http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h5.grid.sp2.yahoo.net/90/artifact/trunk/build/test/checkstyle-errors.html\nConsole output: http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h5.grid.sp2.yahoo.net/90/console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2009-10-30T10:27:26.260+0000","updated":"2009-10-30T10:27:26.260+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12435284/comment/12772113","id":"12772113","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"body":"> This in turn maps to the capability of serving ~3000 nodes with 3 second heartbeat latency. \n\nThis makes sense. I hope it's not going to come to that all heartbeats will remove 1000 blocks on all nodes.\n\n> Most of the classes in DataNode are named Block* \n\nTraditionally hdfs did not distinguish between blocks and their replicas, which we found very confusing while implementing append and tried to call new classes Replica*. So yes you see a lot of Block* classes, but it would be really good to turn this in the right direction. Wouldn't you agree that \"replica\" is a more precise term for a copy of a block on a specific data-node.\n\n> I like the abstraction of creating a task using the 5 arguments, and then do \"execute(Task)\". \n\nI think the abstraction should provide an api to delete replica files independently on whether it is multi-threaded or single-threaded, so it makes sense to me to keep the implementation details concealed in the deleter.\n\nLooked into the implementation details a bit. By default ThreadPoolExecutor sets allowCoreThreadTimeOut to false, which means the threads never shutdown even if there are no deletes. I would rather pay the price of restarting threads when new deletes arrive than keep those threads running forever. Data-nodes spawn a lot of threads besides the deletion. Besides, it will also automatically take care of the condition when a volume dies and we remove it from FSVolumeSet. It would be a waist to keep a thread around for a dead volume.\n\nThe key for the HashMap of threads is the reference to the volume. This is based on that you do not explicitly define equals() and hashCode() for FSVolume. Currently we do not alter instances of volumes, but if we ever do this could be a problem. May be it is better to use volume's directory as the key in the HashMap.\nYou still need to remove the HashMap entry, when the volume is removed from the system.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-10-30T21:57:44.957+0000","updated":"2009-10-30T21:57:44.957+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12435284/comment/12772783","id":"12772783","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=zshao","name":"zshao","key":"zshao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=zshao&avatarId=14358","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=zshao&avatarId=14358","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=zshao&avatarId=14358","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=zshao&avatarId=14358"},"displayName":"Zheng Shao","active":true,"timeZone":"America/Los_Angeles"},"body":"In light of some other discussions related to async deletion in JobTracker when it restarts, I will rename BlockFileDeleter to AsyncDiskService, and move BlockFileDeleteTask inside the FSDataset class. In this way, it will be easier to move AsyncDiskService to common and reuse it in the JobTracker in the future.\n\n> Traditionally hdfs did not distinguish between blocks and their replicas, which we found very confusing while implementing append and tried to call new classes Replica*. So yes you see a lot of Block* classes, but it would be really good to turn this in the right direction. Wouldn't you agree that \"replica\" is a more precise term for a copy of a block on a specific data-node.\n\nI agree. My initial thought was that we should do that change in a single transaction for everything, otherwise having both old and new conventions will make the things even more confusing. \n\n> I think the abstraction should provide an api to delete replica files independently on whether it is multi-threaded or single-threaded, so it makes sense to me to keep the implementation details concealed in the deleter.\n\nUsers might need to know if an operation is sync or async. I will add a deleteAsync method.\n\n> allowCoreThreadTimeOut \n\nAgree. I will add that.\n\n> The key for the HashMap of threads is the reference to the volume\n\nThat makes sense. I will change the key of the HashMap to File, which represents the currentDir of the FSVolume.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=zshao","name":"zshao","key":"zshao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=zshao&avatarId=14358","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=zshao&avatarId=14358","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=zshao&avatarId=14358","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=zshao&avatarId=14358"},"displayName":"Zheng Shao","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-11-03T00:30:31.736+0000","updated":"2009-11-03T00:30:31.736+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12435284/comment/12772799","id":"12772799","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=zshao","name":"zshao","key":"zshao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=zshao&avatarId=14358","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=zshao&avatarId=14358","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=zshao&avatarId=14358","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=zshao&avatarId=14358"},"displayName":"Zheng Shao","active":true,"timeZone":"America/Los_Angeles"},"body":"HDFS-611.trunk.v4.patch does the job of what I described above.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=zshao","name":"zshao","key":"zshao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=zshao&avatarId=14358","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=zshao&avatarId=14358","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=zshao&avatarId=14358","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=zshao&avatarId=14358"},"displayName":"Zheng Shao","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-11-03T00:55:44.948+0000","updated":"2009-11-03T00:55:44.948+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12435284/comment/12772852","id":"12772852","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"-1 overall.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12423872/HDFS-611.trunk.v4.patch\n  against trunk revision 832118.\n\n    +1 @author.  The patch does not contain any @author tags.\n\n    +1 tests included.  The patch appears to include 4 new or modified tests.\n\n    +1 javadoc.  The javadoc tool did not generate any warning messages.\n\n    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.\n\n    +1 findbugs.  The patch does not introduce any new Findbugs warnings.\n\n    +1 release audit.  The applied patch does not increase the total number of release audit warnings.\n\n    -1 core tests.  The patch failed core unit tests.\n\n    -1 contrib tests.  The patch failed contrib unit tests.\n\nTest results: http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h5.grid.sp2.yahoo.net/92/testReport/\nFindbugs warnings: http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h5.grid.sp2.yahoo.net/92/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html\nCheckstyle results: http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h5.grid.sp2.yahoo.net/92/artifact/trunk/build/test/checkstyle-errors.html\nConsole output: http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h5.grid.sp2.yahoo.net/92/console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2009-11-03T02:58:51.039+0000","updated":"2009-11-03T02:58:51.039+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12435284/comment/12773105","id":"12773105","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=zshao","name":"zshao","key":"zshao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=zshao&avatarId=14358","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=zshao&avatarId=14358","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=zshao&avatarId=14358","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=zshao&avatarId=14358"},"displayName":"Zheng Shao","active":true,"timeZone":"America/Los_Angeles"},"body":"Re-trigger unit tests.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=zshao","name":"zshao","key":"zshao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=zshao&avatarId=14358","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=zshao&avatarId=14358","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=zshao&avatarId=14358","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=zshao&avatarId=14358"},"displayName":"Zheng Shao","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-11-03T18:35:29.718+0000","updated":"2009-11-03T18:35:29.718+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12435284/comment/12773163","id":"12773163","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"-1 overall.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12423872/HDFS-611.trunk.v4.patch\n  against trunk revision 832118.\n\n    +1 @author.  The patch does not contain any @author tags.\n\n    +1 tests included.  The patch appears to include 4 new or modified tests.\n\n    +1 javadoc.  The javadoc tool did not generate any warning messages.\n\n    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.\n\n    +1 findbugs.  The patch does not introduce any new Findbugs warnings.\n\n    +1 release audit.  The applied patch does not increase the total number of release audit warnings.\n\n    -1 core tests.  The patch failed core unit tests.\n\n    -1 contrib tests.  The patch failed contrib unit tests.\n\nTest results: http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h5.grid.sp2.yahoo.net/93/testReport/\nFindbugs warnings: http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h5.grid.sp2.yahoo.net/93/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html\nCheckstyle results: http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h5.grid.sp2.yahoo.net/93/artifact/trunk/build/test/checkstyle-errors.html\nConsole output: http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h5.grid.sp2.yahoo.net/93/console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2009-11-03T20:15:40.656+0000","updated":"2009-11-03T20:15:40.656+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12435284/comment/12773368","id":"12773368","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"body":"I like AsyncDiskService. Not sure about MR usage but we can definitely add more data-node operations under the class that require async operations.\nTwo things:\n# It would look really good if you could move the deleteAsync() method together with the static class ReplicaFileDeleteClass inside AsyncDiskService. I understand your motivation that you want to keep AsyncDiskService independent of data-node connotations if the goal is to reuse it in MR, but this could be done by simple factoring our the common base class if such usage in MR will ever materialize.\n# A nit: could you convert the comment for AsyncDiskService to JavaDoc comment by just adding one more star.\n\nOther than that the patch looks good. Test failure is related to HDFS-733.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-11-04T03:22:08.571+0000","updated":"2009-11-04T03:22:08.571+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12435284/comment/12773376","id":"12773376","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=zshao","name":"zshao","key":"zshao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=zshao&avatarId=14358","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=zshao&avatarId=14358","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=zshao&avatarId=14358","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=zshao&avatarId=14358"},"displayName":"Zheng Shao","active":true,"timeZone":"America/Los_Angeles"},"body":"\nbq. It would look really good if you could move the deleteAsync() method together with the static class ReplicaFileDeleteClass inside AsyncDiskService. I understand your motivation that you want to keep AsyncDiskService independent of data-node connotations if the goal is to reuse it in MR, but this could be done by simple factoring our the common base class if such usage in MR will ever materialize.\n\nFor the MR usage, I am think about moving the AsyncDiskService class directly to common. Aggregation seems better than inheritance here, just like ThreadPool (I guess we don't extend ThreadPoolExecutor for different types of Tasks).\n\nIt seems to me that AsyncDiskService should not need to have knowledge of whatever Task is requested by the caller. In particular, the decDfsUsage call in the ReplicaFileDeletionTask is closely related to FSDataSet, and should be maintain inside FSDataSet. What do you think?\n\nbq. A nit: could you convert the comment for AsyncDiskService to JavaDoc comment by just adding one more star.\n\nAdded the missing \"*\" for javadoc.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=zshao","name":"zshao","key":"zshao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=zshao&avatarId=14358","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=zshao&avatarId=14358","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=zshao&avatarId=14358","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=zshao&avatarId=14358"},"displayName":"Zheng Shao","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-11-04T04:20:15.295+0000","updated":"2009-11-04T04:20:15.295+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12435284/comment/12774062","id":"12774062","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"body":"It is better to keep the whole implementation in one place rather than sread it between classes. That makes it modifications easier.\nWhen you decide to move AsyncDiskService to common you can move current implementation of it and create a new class DataNodeAsyncDiskService, which either extends AsyncDiskService or encapsulates it, whatever is better.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-11-05T20:24:29.452+0000","updated":"2009-11-05T20:24:29.452+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12435284/comment/12774070","id":"12774070","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=zshao","name":"zshao","key":"zshao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=zshao&avatarId=14358","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=zshao&avatarId=14358","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=zshao&avatarId=14358","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=zshao&avatarId=14358"},"displayName":"Zheng Shao","active":true,"timeZone":"America/Los_Angeles"},"body":"bq. It is better to keep the whole implementation in one place rather than sread it between classes. That makes it modifications easier.\nI agree with the principle but I feel the ReplicaFileDeleteTask is part of the implementation of FSDataset, not part of AsyncDiskService.\n\nbq. When you decide to move AsyncDiskService to common you can move current implementation of it and create a new class DataNodeAsyncDiskService, which either extends AsyncDiskService or encapsulates it, whatever is better.\n\nIf we do the way as in the patch, we just need to move the AsyncDiskService - no code change (except the package name) is required.\n\nBy the way, do you think it makes sense to add an option to delete in async or sync mode? I can easily add an option for that by calling \"task.run()\" instead of \"asyncDiskService.execute(task)\".\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=zshao","name":"zshao","key":"zshao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=zshao&avatarId=14358","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=zshao&avatarId=14358","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=zshao&avatarId=14358","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=zshao&avatarId=14358"},"displayName":"Zheng Shao","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-11-05T20:50:53.727+0000","updated":"2009-11-05T20:50:53.727+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12435284/comment/12774155","id":"12774155","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=zshao","name":"zshao","key":"zshao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=zshao&avatarId=14358","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=zshao&avatarId=14358","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=zshao&avatarId=14358","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=zshao&avatarId=14358"},"displayName":"Zheng Shao","active":true,"timeZone":"America/Los_Angeles"},"body":"Moved ReplicaFileDeletionTask and deleteAsync into FSDatasetAsyncDiskService.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=zshao","name":"zshao","key":"zshao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=zshao&avatarId=14358","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=zshao&avatarId=14358","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=zshao&avatarId=14358","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=zshao&avatarId=14358"},"displayName":"Zheng Shao","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-11-06T00:28:50.230+0000","updated":"2009-11-06T00:28:50.230+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12435284/comment/12774194","id":"12774194","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"-1 overall.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12424171/HDFS-611.trunk.v6.patch\n  against trunk revision 832585.\n\n    +1 @author.  The patch does not contain any @author tags.\n\n    +1 tests included.  The patch appears to include 4 new or modified tests.\n\n    +1 javadoc.  The javadoc tool did not generate any warning messages.\n\n    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.\n\n    +1 findbugs.  The patch does not introduce any new Findbugs warnings.\n\n    +1 release audit.  The applied patch does not increase the total number of release audit warnings.\n\n    -1 core tests.  The patch failed core unit tests.\n\n    -1 contrib tests.  The patch failed contrib unit tests.\n\nTest results: http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h2.grid.sp2.yahoo.net/67/testReport/\nFindbugs warnings: http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h2.grid.sp2.yahoo.net/67/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html\nCheckstyle results: http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h2.grid.sp2.yahoo.net/67/artifact/trunk/build/test/checkstyle-errors.html\nConsole output: http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h2.grid.sp2.yahoo.net/67/console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2009-11-06T03:07:33.305+0000","updated":"2009-11-06T03:07:33.305+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12435284/comment/12774509","id":"12774509","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"body":"+1 This looks good.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-11-07T00:35:05.674+0000","updated":"2009-11-07T00:35:05.674+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12435284/comment/12774751","id":"12774751","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"body":"I was able to recreate the test failure with TestBlockReport... not sure yet on whether this test failure is because of this patch or not.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"created":"2009-11-08T10:08:03.190+0000","updated":"2009-11-08T10:08:03.190+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12435284/comment/12775257","id":"12775257","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=zshao","name":"zshao","key":"zshao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=zshao&avatarId=14358","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=zshao&avatarId=14358","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=zshao&avatarId=14358","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=zshao&avatarId=14358"},"displayName":"Zheng Shao","active":true,"timeZone":"America/Los_Angeles"},"body":"Dhruba, can you check if your workspace has HDFS-733 in? That was committed on 11/6 by Konstantin, and it should fix the TestBlockReport test failure.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=zshao","name":"zshao","key":"zshao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=zshao&avatarId=14358","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=zshao&avatarId=14358","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=zshao&avatarId=14358","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=zshao&avatarId=14358"},"displayName":"Zheng Shao","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-11-10T02:40:24.595+0000","updated":"2009-11-10T02:40:24.595+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12435284/comment/12775338","id":"12775338","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"body":"I committed it to trunk. Thanks Zheng!","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"created":"2009-11-10T07:40:22.052+0000","updated":"2009-11-10T07:40:22.052+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12435284/comment/12775339","id":"12775339","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"body":"The reason I did not commit it to 0.20 and 0.21 is because this is not a regression.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"created":"2009-11-10T07:40:59.343+0000","updated":"2009-11-10T07:40:59.343+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12435284/comment/12775349","id":"12775349","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"Integrated in Hadoop-Hdfs-trunk-Commit #103 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-Hdfs-trunk-Commit/103/])\n    . Prevent DataNode heartbeat times from increasing even when\nthe DataNode has many blocks to delete. (Zheng Shao via dhruba)\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2009-11-10T08:22:25.246+0000","updated":"2009-11-10T08:22:25.246+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12435284/comment/12775404","id":"12775404","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"Integrated in Hadoop-Hdfs-trunk #136 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-Hdfs-trunk/136/])\n    . Prevent DataNode heartbeat times from increasing even when\nthe DataNode has many blocks to delete. (Zheng Shao via dhruba)\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2009-11-10T13:06:22.783+0000","updated":"2009-11-10T13:06:22.783+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12435284/comment/12776093","id":"12776093","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=zshao","name":"zshao","key":"zshao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=zshao&avatarId=14358","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=zshao&avatarId=14358","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=zshao&avatarId=14358","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=zshao&avatarId=14358"},"displayName":"Zheng Shao","active":true,"timeZone":"America/Los_Angeles"},"body":"Attaching the patch for hadoop 0.20.\nAlthough we don't need it for apache hadoop 0.20, we can include it into Yahoo and Cloudera's hadoop 0.20 distribution if it approves to be useful.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=zshao","name":"zshao","key":"zshao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=zshao&avatarId=14358","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=zshao&avatarId=14358","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=zshao&avatarId=14358","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=zshao&avatarId=14358"},"displayName":"Zheng Shao","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-11-10T21:37:38.254+0000","updated":"2009-11-10T21:37:38.254+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12435284/comment/12776726","id":"12776726","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"Integrated in Hdfs-Patch-h5.grid.sp2.yahoo.net #104 (See [http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h5.grid.sp2.yahoo.net/104/])\n    ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2009-11-11T23:12:00.606+0000","updated":"2009-11-11T23:12:00.606+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12435284/comment/12777201","id":"12777201","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"Integrated in Hdfs-Patch-h2.grid.sp2.yahoo.net #72 (See [http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h2.grid.sp2.yahoo.net/72/])\n    ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2009-11-12T21:18:28.836+0000","updated":"2009-11-12T21:18:28.836+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12435284/comment/12792372","id":"12792372","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dongtalk%40gmail.com","name":"dongtalk@gmail.com","key":"dongtalk@gmail.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yajun Dong","active":true,"timeZone":"Etc/UTC"},"body":"hi, all, Heartbeats times from Datanodes will also increase when there are plenty of blocks to report. \n\npartial Datanode log of Hadoop-0.19.2:\n2009-12-18 01:45:19,434 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: BlockReport of 67275 blocks got processed in 862837 msecs","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dongtalk%40gmail.com","name":"dongtalk@gmail.com","key":"dongtalk@gmail.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yajun Dong","active":true,"timeZone":"Etc/UTC"},"created":"2009-12-18T06:54:54.450+0000","updated":"2009-12-18T06:54:54.450+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12435284/comment/13145938","id":"13145938","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jnp","name":"jnp","key":"jnp","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jitendra Nath Pandey","active":true,"timeZone":"Etc/UTC"},"body":"Patch for branch-0.20-security is attached.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jnp","name":"jnp","key":"jnp","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jitendra Nath Pandey","active":true,"timeZone":"Etc/UTC"},"created":"2011-11-07T23:27:25.826+0000","updated":"2011-11-07T23:27:25.826+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12435284/comment/13145942","id":"13145942","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=aaa","name":"aaa","key":"aaa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=aaa&avatarId=16832","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=aaa&avatarId=16832","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=aaa&avatarId=16832","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=aaa&avatarId=16832"},"displayName":"Amr Awadallah","active":true,"timeZone":"America/Los_Angeles"},"body":"I am out of office on a business trip for next couple of days. I will\nbe slower than usual in responding to emails. If this is urgent then\nplease call my cell phone (or send an SMS), otherwise I will reply to\nyour email next week when I get back.\n\nThanks for your patience,\n\n-- amr\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=aaa","name":"aaa","key":"aaa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=aaa&avatarId=16832","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=aaa&avatarId=16832","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=aaa&avatarId=16832","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=aaa&avatarId=16832"},"displayName":"Amr Awadallah","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-11-07T23:30:52.483+0000","updated":"2011-11-07T23:30:52.483+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12435284/comment/13147305","id":"13147305","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"body":"+1 the 0.20s patch looks good.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-11-09T21:33:08.623+0000","updated":"2011-11-09T21:33:08.623+0000"}],"maxResults":48,"total":48,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-611/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i02slz:"}}