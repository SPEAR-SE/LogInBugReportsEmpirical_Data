{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"13142773","self":"https://issues.apache.org/jira/rest/api/2/issue/13142773","key":"HDFS-13236","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":"2018-03-08T17:51:26.976+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Wed Jul 04 06:19:33 UTC 2018","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-13236/watchers","watchCount":5,"isWatching":false},"created":"2018-03-06T07:07:00.153+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12341433","id":"12341433","description":"3.0.0 GA release","name":"3.0.0","archived":false,"released":true,"releaseDate":"2017-12-13"}],"issuelinks":[{"id":"12537744","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12537744","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"13169999","key":"HDFS-13718","self":"https://issues.apache.org/jira/rest/api/2/issue/13169999","fields":{"summary":"So many NotEnoughReplicasException in active NN logs","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}}],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2018-07-04T06:20:23.514+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12319803","id":"12319803","name":"journal-node","description":"Journal Node for the QJM"},{"self":"https://issues.apache.org/jira/rest/api/2/component/12312926","id":"12312926","name":"namenode"}],"timeoriginalestimate":null,"description":"After update Hadoop from 2.7.3 to 3.0.0 standby NN down with error encountered while tailing edits from JN:\r\n{code:java}\r\nFeb 28 01:58:31 srvd2135 datalab-namenode[15566]: 2018-02-28 01:58:31,594 INFO [FSImageSaver for /one/hadoop-data/dfs of type IMAGE_AND_EDITS] FSImageFormatProtobuf - Image file /one/hadoop-data/dfs/current/fsimage.ckpt_00000000012748979\r\n98 of size 4595971949 bytes saved in 93 seconds.\r\nFeb 28 01:58:33 srvd2135 datalab-namenode[15566]: 2018-02-28 01:58:33,445 INFO [Standby State Checkpointer] NNStorageRetentionManager - Going to retain 2 images with txid >= 1274897935\r\nFeb 28 01:58:33 srvd2135 datalab-namenode[15566]: 2018-02-28 01:58:33,445 INFO [Standby State Checkpointer] NNStorageRetentionManager - Purging old image FSImageFile(file=/one/hadoop-data/dfs/current/fsimage_0000000001274897875, cpktTxId\r\n=0000000001274897875)\r\nFeb 28 01:58:34 srvd2135 datalab-namenode[15566]: 2018-02-28 01:58:34,660 INFO [Edit log tailer] FSImage - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@6a168e6f expecting start txid #1274897999\r\nFeb 28 01:58:34 srvd2135 datalab-namenode[15566]: 2018-02-28 01:58:34,660 INFO [Edit log tailer] FSImage - Start loading edits file http://srvd87.local:8480/getJournal?jid=datalab-hadoop-backup&segmentTxId=1274897999&storageInfo=-64%3A10\r\n56233980%3A0%3ACID-1fba08aa-c8bd-4217-aef5-6ed206893848&inProgressOk=true, http://srve2916.local:8480/getJournal?jid=datalab-hadoop-backup&segmentTxId=1274897999&storageInfo=-64%3A1056233980%3A0%3ACID-1fba08aa-c8bd-4217-aef5-6ed206893848&\r\ninProgressOk=true\r\nFeb 28 01:58:34 srvd2135 datalab-namenode[15566]: 2018-02-28 01:58:34,661 INFO [Edit log tailer] RedundantEditLogInputStream - Fast-forwarding stream 'http://srvd87.local:8480/getJournal?jid=datalab-hadoop-backup&segmentTxId=1274897999&s\r\ntorageInfo=-64%3A1056233980%3A0%3ACID-1fba08aa-c8bd-4217-aef5-6ed206893848&inProgressOk=true, http://srve2916.local:8480/getJournal?jid=datalab-hadoop-backup&segmentTxId=1274897999&storageInfo=-64%3A1056233980%3A0%3ACID-1fba08aa-c8bd-4217\r\n-aef5-6ed206893848&inProgressOk=true' to transaction ID 1274897999\r\nFeb 28 01:58:34 srvd2135 datalab-namenode[15566]: 2018-02-28 01:58:34,661 INFO [Edit log tailer] RedundantEditLogInputStream - Fast-forwarding stream 'http://srvd87.local:8480/getJournal?jid=datalab-hadoop-backup&segmentTxId=1274897999&storageInfo=-64%3A1056233980%3A0%3ACID-1fba08aa-c8bd-4217-aef5-6ed206893848&inProgressOk=true' to transaction ID 1274897999\r\nFeb 28 01:58:34 srvd2135 datalab-namenode[15566]: 2018-02-28 01:58:34,680 ERROR [Edit log tailer] FSEditLogLoader - Encountered exception on operation AddOp [length=0, inodeId=145550319, path=/kafka/parquet/infrastructureGrace/date=2018-02-28/_temporary/1/_temporary/attempt_1516181147167_20856_r_000098_0/part-r-00098.gz.parquet, replication=3, mtime=1519772206615, atime=1519772206615, blockSize=134217728, blocks=[], permissions=root:supergroup:rw-r--r--, aclEntries=null, clientName=DFSClient_attempt_1516181147167_20856_r_000098_0_1523538799_1, clientMachine=10.137.2.142, overwrite=false, RpcClientId=, RpcCallId=271996603, storagePolicyId=0, erasureCodingPolicyId=0, opCode=OP_ADD, txid=1274898002]\r\nFeb 28 01:58:34 srvd2135 datalab-namenode[15566]: java.lang.IllegalArgumentException: Invalid clientId - length is 0 expected length 16\r\nFeb 28 01:58:34 srvd2135 datalab-namenode[15566]: at com.google.common.base.Preconditions.checkArgument(Preconditions.java:92)\r\nFeb 28 01:58:34 srvd2135 datalab-namenode[15566]: at org.apache.hadoop.ipc.RetryCache$CacheEntry.<init>(RetryCache.java:74)\r\nFeb 28 01:58:34 srvd2135 datalab-namenode[15566]: at org.apache.hadoop.ipc.RetryCache$CacheEntry.<init>(RetryCache.java:86)\r\nFeb 28 01:58:34 srvd2135 datalab-namenode[15566]: at org.apache.hadoop.ipc.RetryCache$CacheEntryWithPayload.<init>(RetryCache.java:163)\r\nFeb 28 01:58:34 srvd2135 datalab-namenode[15566]: at org.apache.hadoop.ipc.RetryCache.addCacheEntryWithPayload(RetryCache.java:322)\r\nFeb 28 01:58:34 srvd2135 datalab-namenode[15566]: at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.addCacheEntryWithPayload(FSNamesystem.java:946)\r\nFeb 28 01:58:34 srvd2135 datalab-namenode[15566]: at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.applyEditLogOp(FSEditLogLoader.java:397)\r\nFeb 28 01:58:34 srvd2135 datalab-namenode[15566]: at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadEditRecords(FSEditLogLoader.java:249)\r\nFeb 28 01:58:34 srvd2135 datalab-namenode[15566]: at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadFSEdits(FSEditLogLoader.java:158)\r\nFeb 28 01:58:34 srvd2135 datalab-namenode[15566]: at org.apache.hadoop.hdfs.server.namenode.FSImage.loadEdits(FSImage.java:882)\r\nFeb 28 01:58:34 srvd2135 datalab-namenode[15566]: at org.apache.hadoop.hdfs.server.namenode.FSImage.loadEdits(FSImage.java:863)\r\nFeb 28 01:58:34 srvd2135 datalab-namenode[15566]: at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:293)\r\nFeb 28 01:58:34 srvd2135 datalab-namenode[15566]: at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:427)\r\nFeb 28 01:58:34 srvd2135 datalab-namenode[15566]: at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$400(EditLogTailer.java:380)\r\nFeb 28 01:58:34 srvd2135 datalab-namenode[15566]: at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:397)\r\nFeb 28 01:58:34 srvd2135 datalab-namenode[15566]: at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:481)\r\nFeb 28 01:58:34 srvd2135 datalab-namenode[15566]: at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:393)\r\nFeb 28 01:58:34 srvd2135 datalab-namenode[15566]: 2018-02-28 01:58:34,688 FATAL [Edit log tailer] EditLogTailer - Unknown error encountered while tailing edits. Shutting down standby NN.\r\nFeb 28 01:58:34 srvd2135 datalab-namenode[15566]: java.io.IOException: java.lang.IllegalStateException: Cannot skip to less than the current value (=145550319), where newValue=145550318\r\nFeb 28 01:58:34 srvd2135 datalab-namenode[15566]: at org.apache.hadoop.hdfs.server.namenode.FSDirectory.resetLastInodeId(FSDirectory.java:1941)\r\nFeb 28 01:58:34 srvd2135 datalab-namenode[15566]: at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadEditRecords(FSEditLogLoader.java:298)\r\nFeb 28 01:58:34 srvd2135 datalab-namenode[15566]: at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadFSEdits(FSEditLogLoader.java:158)\r\nFeb 28 01:58:34 srvd2135 datalab-namenode[15566]: at org.apache.hadoop.hdfs.server.namenode.FSImage.loadEdits(FSImage.java:882)\r\nFeb 28 01:58:34 srvd2135 datalab-namenode[15566]: at org.apache.hadoop.hdfs.server.namenode.FSImage.loadEdits(FSImage.java:863)\r\nFeb 28 01:58:34 srvd2135 datalab-namenode[15566]: at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:293)\r\nFeb 28 01:58:34 srvd2135 datalab-namenode[15566]: at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:427)\r\nFeb 28 01:58:34 srvd2135 datalab-namenode[15566]: at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$400(EditLogTailer.java:380)\r\nFeb 28 01:58:34 srvd2135 datalab-namenode[15566]: at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:397)\r\nFeb 28 01:58:34 srvd2135 datalab-namenode[15566]: at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:481)\r\nFeb 28 01:58:34 srvd2135 datalab-namenode[15566]: at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:393)\r\nFeb 28 01:58:34 srvd2135 datalab-namenode[15566]: Caused by: java.lang.IllegalStateException: Cannot skip to less than the current value (=145550319), where newValue=145550318\r\nFeb 28 01:58:34 srvd2135 datalab-namenode[15566]: at org.apache.hadoop.util.SequentialNumber.skipTo(SequentialNumber.java:58)\r\nFeb 28 01:58:34 srvd2135 datalab-namenode[15566]: at org.apache.hadoop.hdfs.server.namenode.FSDirectory.resetLastInodeId(FSDirectory.java:1939)\r\nFeb 28 01:58:34 srvd2135 datalab-namenode[15566]: ... 10 more\r\nFeb 28 01:58:34 srvd2135 datalab-namenode[15566]: 2018-02-28 01:58:34,708  INFO [Edit log tailer] ExitUtil - Exiting with status 1: java.io.IOException: java.lang.IllegalStateException: Cannot skip to less than the current value (=145550319), where newValue=145550318\r\nFeb 28 01:58:34 srvd2135 datalab-namenode[15566]: 2018-02-28 01:58:34,722 INFO [pool-1-thread-1] NameNode - SHUTDOWN_MSG:\r\nFeb 28 01:58:34 srvd2135 datalab-namenode[15566]: /************************************************************\r\nFeb 28 01:58:34 srvd2135 datalab-namenode[15566]: SHUTDOWN_MSG: Shutting down NameNode at srvd2135.local/10.137.2.39\r\n{code}\r\n \r\nIn JN logs: \r\n{code:java}\r\nFeb 28 01:57:51 srvd87 datalab-journalnode[29960]: 2018-02-28 01:57:51,552 INFO [IPC Server handler 4 on 8485] FileJournalManager - Finalizing edits file /one/hadoop-data/journal/datalab-hadoop-backup/current/edits_inprogress_00000\r\n00001274897999 -> /one/hadoop-data/journal/datalab-hadoop-backup/current/edits_0000000001274897999-0000000001274898515\r\nFeb 28 01:58:34 srvd87 datalab-journalnode[29960]: 2018-02-28 01:58:34,671 INFO [qtp414690789-164] TransferFsImage - Sending fileName: /one/hadoop-data/journal/datalab-hadoop-backup/current/edits_0000000001274897999-0000000001274898515, fileSize: 80772. Sent total: 80772 bytes. Size of last segment intended to send: -1 bytes.\r\n{code}\r\n{code:java}\r\n$ zgrep -c 'Size of last segment intended to send' archive/datalab-journalnode.log-20180{22*,3*}.gz\r\narchive/datalab-journalnode.log-20180227.gz:0    #hadoop 2.7.3\r\narchive/datalab-journalnode.log-20180301.gz:109  #hadoop 3.0.0\r\narchive/datalab-journalnode.log-20180302.gz:111  #hadoop 3.0.0\r\narchive/datalab-journalnode.log-20180304.gz:0    #hadoop 2.7.3\r\n{code}","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"Standby NN down with error encountered while tailing edits","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=_ph","name":"_ph","key":"_ph","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=_ph&avatarId=34760","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=_ph&avatarId=34760","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=_ph&avatarId=34760","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=_ph&avatarId=34760"},"displayName":"Yuriy Malygin","active":true,"timeZone":"Europe/Moscow"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=_ph","name":"_ph","key":"_ph","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=_ph&avatarId=34760","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=_ph&avatarId=34760","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=_ph&avatarId=34760","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=_ph&avatarId=34760"},"displayName":"Yuriy Malygin","active":true,"timeZone":"Europe/Moscow"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/13142773/comment/16391622","id":"16391622","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"body":"For block placement differences, {{DFSNetworkTopology}} is new in Hadoop 3. It might be related. See HDFS-11419. [~vagarychen] might be able to tell whether it is related.\r\n\r\nMissing Client ID is very strange as it has a call ID. Both come from the handler's thread local variable set by the RPC server. The client ID field  isn't the last field in the edit either. It is created when a RPC client is created and this is set in the connection context header. It is all internal and automatic. I don't know what happens when the connection is dropped before edit logging, while the call is still being processed. [~daryn], does server reset the client ID in this case?\r\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"created":"2018-03-08T17:51:26.976+0000","updated":"2018-03-08T17:51:26.976+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13142773/comment/16531085","id":"16531085","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=forchard","name":"forchard","key":"forchard","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=34058","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34058","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34058","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34058"},"displayName":"Francisco Orchard","active":true,"timeZone":"Europe/Paris"},"body":"Hi all,\r\n\r\nWe are having the same issue after upgrading from 2.8.2 to 3.1.0, we have a cluster with one name node 3 datanodes and no journal node, that worked without issues during an entire year. The upgrade went fine but problem started after a system maintenance that restarted all nodes. Here are the main information on the log\r\n\r\n2018-07-03 10:57:35,543 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream '/space/hadoop/hadoop_run/head_node/current/edits_0000000000023174228-0000000000023184599' \r\nto transaction ID 23174224 \r\n2018-07-03 10:57:35,575 ERROR org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader: Encountered exception on operation AddOp [length=0, inodeId=6383051, path=/spark/.sparkStaging/application_1530536780991_0001/commons-compress-1.14.jar, replication=3, mtime=1530538999482, atime=1530538999482, blockSize=134217728, blocks=[], permissions=spark:hadoop:rw-r--r--, aclEntries=null, clientName=DFSClient_NONMAPREDUCE_291933719_1, clientMachine=10.1.19.65, overwrite=true, RpcClientId=, RpcCallId=269330502, storagePolicyId=0, erasureCodingPolicyId=0, opCode=OP_ADD, txid=23174233]\r\njava.lang.IllegalArgumentException: Invalid clientId - length is 0 expected length 16\r\n at com.google.common.base.Preconditions.checkArgument(Preconditions.java:88)\r\n at org.apache.hadoop.ipc.RetryCache$CacheEntry.<init>(RetryCache.java:74)\r\n at org.apache.hadoop.ipc.RetryCache$CacheEntry.<init>(RetryCache.java:86)\r\n at org.apache.hadoop.ipc.RetryCache$CacheEntryWithPayload.<init>(RetryCache.java:163)\r\n at org.apache.hadoop.ipc.RetryCache.addCacheEntryWithPayload(RetryCache.java:322)\r\n at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.addCacheEntryWithPayload(FSNamesystem.java:960)\r\n at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.applyEditLogOp(FSEditLogLoader.java:397)\r\n at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadEditRecords(FSEditLogLoader.java:249)\r\n at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadFSEdits(FSEditLogLoader.java:158)\r\n at org.apache.hadoop.hdfs.server.namenode.FSImage.loadEdits(FSImage.java:888)\r\n at org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:745)\r\n at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:323)\r\n at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:1086)\r\n at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:714)\r\n at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:669)\r\n at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:731)\r\n at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:968)\r\n at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:947)\r\n at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1674)\r\n at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1741)\r\n2018-07-03 10:57:35,577 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Encountered exception loading fsimage\r\njava.io.IOException: java.lang.IllegalStateException: Cannot skip to less than the current value (=6383051), where newValue=6383050\r\n at org.apache.hadoop.hdfs.server.namenode.FSDirectory.resetLastInodeId(FSDirectory.java:1945)\r\n at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadEditRecords(FSEditLogLoader.java:298)\r\n at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadFSEdits(FSEditLogLoader.java:158)\r\n at org.apache.hadoop.hdfs.server.namenode.FSImage.loadEdits(FSImage.java:888)\r\n at org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:745)\r\n at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:323)\r\n at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:1086)\r\n at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:714)\r\n at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:669)\r\n at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:731)\r\n at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:968)\r\n at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:947)\r\n at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1674)\r\n at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1741)\r\nCaused by: java.lang.IllegalStateException: Cannot skip to less than the current value (=6383051), where newValue=6383050\r\n at org.apache.hadoop.util.SequentialNumber.skipTo(SequentialNumber.java:58)\r\n at org.apache.hadoop.hdfs.server.namenode.FSDirectory.resetLastInodeId(FSDirectory.java:1943)\r\n ... 13 more","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=forchard","name":"forchard","key":"forchard","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=34058","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34058","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34058","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34058"},"displayName":"Francisco Orchard","active":true,"timeZone":"Europe/Paris"},"created":"2018-07-03T09:25:02.348+0000","updated":"2018-07-03T09:25:02.348+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13142773/comment/16531135","id":"16531135","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=linyiqun","name":"linyiqun","key":"linyiqun","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=linyiqun&avatarId=25258","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=linyiqun&avatarId=25258","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=linyiqun&avatarId=25258","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=linyiqun&avatarId=25258"},"displayName":"Yiqun Lin","active":true,"timeZone":"Asia/Shanghai"},"body":"Hi [~_ph], as I see you reported two problems when upgrading the cluster. Looks like they are unrelated. Could you file a new JIRA for tracking Rack Awareness problem you found? And let this JIRA focus on SBN tailing edits error.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=linyiqun","name":"linyiqun","key":"linyiqun","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=linyiqun&avatarId=25258","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=linyiqun&avatarId=25258","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=linyiqun&avatarId=25258","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=linyiqun&avatarId=25258"},"displayName":"Yiqun Lin","active":true,"timeZone":"Asia/Shanghai"},"created":"2018-07-03T09:58:06.758+0000","updated":"2018-07-03T09:58:06.758+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13142773/comment/16531436","id":"16531436","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"body":"The \"restart fails after upgrade\" issue is being addressed in HDFS-13596. Workaround is to do \"saveNamespace\" against the active NN after an upgrade from 2.x to 3.x. The Standby NN will need to be re-bootstrapped.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"created":"2018-07-03T13:53:06.534+0000","updated":"2018-07-03T13:58:55.063+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13142773/comment/16532302","id":"16532302","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=_ph","name":"_ph","key":"_ph","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=_ph&avatarId=34760","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=_ph&avatarId=34760","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=_ph&avatarId=34760","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=_ph&avatarId=34760"},"displayName":"Yuriy Malygin","active":true,"timeZone":"Europe/Moscow"},"body":"Hi [~linyiqun], I create additional issue about _NotEnoughReplicasException_ - HDFS-13718.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=_ph","name":"_ph","key":"_ph","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=_ph&avatarId=34760","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=_ph&avatarId=34760","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=_ph&avatarId=34760","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=_ph&avatarId=34760"},"displayName":"Yuriy Malygin","active":true,"timeZone":"Europe/Moscow"},"created":"2018-07-04T06:19:33.784+0000","updated":"2018-07-04T06:19:33.784+0000"}],"maxResults":5,"total":5,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-13236/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i3qwtj:"}}