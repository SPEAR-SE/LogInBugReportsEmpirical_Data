{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12555960","self":"https://issues.apache.org/jira/rest/api/2/issue/12555960","key":"HDFS-3429","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12323274","id":"12323274","description":"2.0.3-alpha release","name":"2.0.3-alpha","archived":false,"released":true,"releaseDate":"2013-02-14"}],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2012-05-16T06:54:30.087+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Tue Jan 15 13:20:56 UTC 2013","customfield_12310420":"239573","customfield_12312320":null,"customfield_12310222":"10002_*:*_1_*:*_9655383804_*|*_1_*:*_1_*:*_11392458140_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2013-01-14T20:47:52.662+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-3429/watchers","watchCount":37,"isWatching":false},"created":"2012-05-16T06:10:30.765+0000","customfield_12310192":null,"customfield_12310191":[{"self":"https://issues.apache.org/jira/rest/api/2/customFieldOption/10343","value":"Reviewed","id":"10343"}],"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"6.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12320353","id":"12320353","description":"hadoop-2.0.0-alpha release","name":"2.0.0-alpha","archived":false,"released":true,"releaseDate":"2012-05-23"}],"issuelinks":[{"id":"12357926","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12357926","type":{"id":"10032","name":"Blocker","inward":"is blocked by","outward":"blocks","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10032"},"outwardIssue":{"id":"12607846","key":"HBASE-6798","self":"https://issues.apache.org/jira/rest/api/2/issue/12607846","fields":{"summary":"HDFS always read checksum form meta file","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/1","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/blocker.svg","name":"Blocker","id":"1"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12358118","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12358118","type":{"id":"10032","name":"Blocker","inward":"is blocked by","outward":"blocks","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10032"},"inwardIssue":{"id":"12608728","key":"HBASE-6868","self":"https://issues.apache.org/jira/rest/api/2/issue/12608728","fields":{"summary":"Skip checksum is broke; are we double-checksumming by default?","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/1","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/blocker.svg","name":"Blocker","id":"1"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2014-09-03T23:09:04.454+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12312927","id":"12312927","name":"datanode"},{"self":"https://issues.apache.org/jira/rest/api/2/component/12316501","id":"12316501","name":"performance","description":"Tag for performance related improvements/optimizations"}],"timeoriginalestimate":null,"description":"Currently, even if the client does not want to verify checksums, the datanode reads them anyway and sends them over the wire. This means that performance improvements like HBase's application-level checksums don't have much benefit when reading through the datanode, since the DN is still causing seeks into the checksum file.\n\n(Credit goes to Dhruba for discovering this - filing on his behalf)","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12564769","id":"12564769","filename":"hdfs-3429.txt","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2013-01-14T20:34:41.604+0000","size":19599,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12564769/hdfs-3429.txt"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12553067","id":"12553067","filename":"hdfs-3429.txt","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2012-11-12T03:37:51.089+0000","size":21060,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12553067/hdfs-3429.txt"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12552936","id":"12552936","filename":"hdfs-3429.txt","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2012-11-10T00:59:52.826+0000","size":34497,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12552936/hdfs-3429.txt"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12546141","id":"12546141","filename":"hdfs-3429.txt","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2012-09-22T00:53:40.112+0000","size":34466,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12546141/hdfs-3429.txt"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12554468","id":"12554468","filename":"hdfs-3429-0.20.2.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=liulei.cn","name":"liulei.cn","key":"liulei.cn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"LiuLei","active":true,"timeZone":"Asia/Shanghai"},"created":"2012-11-21T08:39:48.033+0000","size":24611,"mimeType":"text/x-diff","content":"https://issues.apache.org/jira/secure/attachment/12554468/hdfs-3429-0.20.2.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12552806","id":"12552806","filename":"hdfs-3429-0.20.2.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=liulei.cn","name":"liulei.cn","key":"liulei.cn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"LiuLei","active":true,"timeZone":"Asia/Shanghai"},"created":"2012-11-09T10:04:40.649+0000","size":4692,"mimeType":"text/x-diff","content":"https://issues.apache.org/jira/secure/attachment/12552806/hdfs-3429-0.20.2.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"2359","customfield_12312823":null,"summary":"DataNode reads checksums even if client does not need them","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12555960/comment/13276524","id":"13276524","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dennyy","name":"dennyy","key":"dennyy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Denny Ye","active":true,"timeZone":"Asia/Harbin"},"body":"hi Todd, referred with this problem you raised. I have a question. Can we support additional interface for reading block content from DataNode for local process or application to avoid the verification?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dennyy","name":"dennyy","key":"dennyy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Denny Ye","active":true,"timeZone":"Asia/Harbin"},"created":"2012-05-16T06:54:30.087+0000","updated":"2012-05-16T06:54:30.087+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12555960/comment/13276533","id":"13276533","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"We already have a flag on the stream that determines whether the checksum is to be verified. The issue is that we don't plumb it down to the DN, so the DN is reading useless data in these cases. This should not affect user APIs.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2012-05-16T07:12:25.036+0000","updated":"2012-05-16T07:12:25.036+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12555960/comment/13276537","id":"13276537","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"body":"For the records, if you switch-on local read shortcircuit, then the read of the checksum file is avoided.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"created":"2012-05-16T07:13:59.157+0000","updated":"2012-05-16T07:13:59.157+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12555960/comment/13460972","id":"13460972","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"Here's a prelim patch for this. It seems to work in my testing - I tested manually by stracing the datanode process and ensuring it doesn't open the checksum file when I run \"hadoop fs -cat -ignoreCrc\". I also extended an existing parallel pread test to run this code path to check that we're getting the offset calculations right, etc.\n\nWill probably want to clean this up a bit more before commit, but posting here to get QA results and in case anyone wants to try it.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2012-09-22T00:53:40.114+0000","updated":"2012-09-22T00:53:40.114+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12555960/comment/13461028","id":"13461028","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stack","name":"stack","key":"stack","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"stack","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks for having a go at this one Todd.\n\n{code}\n-    if ( bytesPerChecksum <= 0 ) {\n+    if ( type != Type.NULL && bytesPerChecksum <= 0 ) {\n{code}\n\nType.NULL + bytesPerChecksum <= 0 is the flag that means 'skip checksum'?  If so, a comment wouldn't be amiss here.\n\nWhy not just let it fall through to Type.NULL?  It'll return DataChecksum w/ ChecksumNull.\n\nIts ok adding extra param here:\n\n{code}\n-      final long length) throws IOException;\n+      final long length,\n+      final boolean sendChecksum) throws IOException;\n{code}\n\nIt won't break the protocol?  We can go against older versions of 2.0.x-alpha?  I suppose we're pb'ing -- I can see that later in patch -- so probably fine?\n\nIs this change related?  (Reading more, it just looks like you just moved the check higher up in the method -- ok)\n\n{code}\n+      length = length < 0 ? replicaVisibleLength : length;\n{code}\n\nSpacing:\n\n{code}\n+        \tif (metaIn == null) {\n{code}\n\nJavadoc param name does not match name you have in method sig: maxBytesToSend\n\nLooks like this patch defaults reading the checksum and sending it to the client.  Is that new?  Sending client the checksum?  The verify flag is already in the proto just not hooked up?\n\nI got lost trying to follow the sizings in BlockSender... if its wrong, failure should be pretty spectacular.\n\nPatch looks good Todd.\n\n\n\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stack","name":"stack","key":"stack","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"stack","active":true,"timeZone":"America/Los_Angeles"},"created":"2012-09-22T05:25:08.838+0000","updated":"2012-09-22T05:25:08.838+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12555960/comment/13461031","id":"13461031","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stack","name":"stack","key":"stack","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"stack","active":true,"timeZone":"America/Los_Angeles"},"body":"I ran the tests included in patch locally and all passed.  Let me see what happens when hbase wants to do the checksumming...","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stack","name":"stack","key":"stack","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"stack","active":true,"timeZone":"America/Los_Angeles"},"created":"2012-09-22T05:58:01.875+0000","updated":"2012-09-22T05:58:01.875+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12555960/comment/13461045","id":"13461045","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"Hey Stack, thanks for taking a look. I'll address the review comments in the next iteration, and clean up comments etc in the code.\n\nIt is indeed wire-compatible due to checksumming. Also, the existing behavior is to send the checksums to the client and verify them there (not on the DataNode). So we're maintaining that by default, and just providing the new flag to have the DN not read and not send.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2012-09-22T07:14:04.444+0000","updated":"2012-09-22T07:14:04.444+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12555960/comment/13462464","id":"13462464","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"-1 overall.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12546141/hdfs-3429.txt\n  against trunk revision .\n\n    +1 @author.  The patch does not contain any @author tags.\n\n    +1 tests included.  The patch appears to include 4 new or modified test files.\n\n    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.\n\n    +1 javadoc.  The javadoc tool did not generate any warning messages.\n\n    +1 eclipse:eclipse.  The patch built with eclipse:eclipse.\n\n    +1 findbugs.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.\n\n    +1 release audit.  The applied patch does not increase the total number of release audit warnings.\n\n    -1 core tests.  The patch failed these unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs:\n\n                  org.apache.hadoop.hdfs.TestDFSUpgradeFromImage\n\n    +1 contrib tests.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/3228//testReport/\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/3228//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2012-09-25T05:52:34.919+0000","updated":"2012-09-25T05:52:34.919+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12555960/comment/13463148","id":"13463148","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"The failed test seems like it might be legit. I will look into it.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2012-09-25T19:41:51.790+0000","updated":"2012-09-25T19:41:51.790+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12555960/comment/13467176","id":"13467176","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yuzhihong%40gmail.com","name":"yuzhihong@gmail.com","key":"yuzhihong@gmail.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ted Yu","active":true,"timeZone":"America/Los_Angeles"},"body":"Pardon my limited knowledge of hdfs.\n{code}\n+      boolean needToReadChecksum = verifyChecksum || sendChecksum;\n{code}\nThe variable name might be a bit confusing where checksum reading depends on sendChecksum flag.\n{code}\n-      checksumSize = checksum.getChecksumSize();\n-      length = length < 0 ? replicaVisibleLength : length;\n{code}\nWhy was the length adjustment omitted in BlockSender ctor ?\n{code}\n+   * @param maxChunks maximum number of bytes to send. If checksums are\n{code}\nThe above javadoc is inconsistent with the following code change:\n{code}\n-  private int sendPacket(ByteBuffer pkt, int maxChunks, OutputStream out,\n+  private int sendPacket(ByteBuffer pkt, int maxBytesToSend, OutputStream out,\n{code}\n{code}\n+    // Number of chunks be sent in the packet\n+    int numChunks = shouldReadChecksum() ? numberOfChunks(dataLen) : 0;\n{code}\nIf we don't need to read checksum, why would numChunks be 0 ?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yuzhihong%40gmail.com","name":"yuzhihong@gmail.com","key":"yuzhihong@gmail.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ted Yu","active":true,"timeZone":"America/Los_Angeles"},"created":"2012-10-01T20:47:31.555+0000","updated":"2012-10-01T20:47:31.555+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12555960/comment/13493693","id":"13493693","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=liulei.cn","name":"liulei.cn","key":"liulei.cn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"LiuLei","active":true,"timeZone":"Asia/Shanghai"},"body":"hi Todd,\nI am using the hadoop-0.20.2, so I want to fix the problem in hadoop-0.20.2, can you give me some advices about how to fix problem in hadoop-0.20.2?\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=liulei.cn","name":"liulei.cn","key":"liulei.cn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"LiuLei","active":true,"timeZone":"Asia/Shanghai"},"created":"2012-11-09T02:39:05.063+0000","updated":"2012-11-09T02:39:05.063+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12555960/comment/13493865","id":"13493865","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=liulei.cn","name":"liulei.cn","key":"liulei.cn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"LiuLei","active":true,"timeZone":"Asia/Shanghai"},"body":"patch for hadoop-0.20.2","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=liulei.cn","name":"liulei.cn","key":"liulei.cn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"LiuLei","active":true,"timeZone":"Asia/Shanghai"},"created":"2012-11-09T10:04:40.660+0000","updated":"2012-11-09T10:04:40.660+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12555960/comment/13493874","id":"13493874","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12552806/hdfs-3429-0.20.2.patch\n  against trunk revision .\n\n    {color:red}-1 patch{color}.  The patch command could not apply the patch.\n\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/3473//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2012-11-09T10:12:52.240+0000","updated":"2012-11-09T10:12:52.240+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12555960/comment/13494480","id":"13494480","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"bq. The variable name might be a bit confusing where checksum reading depends on sendChecksum flag.\n\nNot sure what you mean. We need to read the checksum off disk in either of two cases:\n- verifyChecksum: we plan to verify it on the server side\n- sendChecksum: we plan to send it to the client\n\nThese flags are used independently for various purposes, eg:\n- Block scanner: the BlockSender is \"sending\" to a null sink, with the verifyChecksum flag set. This causes it to throw an error if the checksum doesn't match. \n- Normal read: the DataNode doesn't verify the checksum - instead, it just sends it to the client who verifies it\n- Checksum-less read: neither verifies nor sends -- in this case, we don't want to read it off disk.\n\nbq. Why was the length adjustment omitted in BlockSender ctor ?\n\nIt wasn't ommitted, just moved to a different part of the function.\n\nbq. The above javadoc is inconsistent with the following code change:\nFixed\n\nbq. If we don't need to read checksum, why would numChunks be 0 ?\n\nIf we're not reading checksums, then we don't need to \"chunk\" the data at all - we can send exactly as many bytes as are requested or fit into the packet. The concept of chunks is itself only relevant in the context of checksummed data. I'll add more commentary here.\n\nbq. I am using the hadoop-0.20.2, so I want to fix the problem in hadoop-0.20.2, can you give me some advices about how to fix problem in hadoop-0.20.2?\n\nI don't know if it's going to be possible to fix this for 0.20.2 without breaking wire compatibility. The patch you uploaded is likely not sufficient - have you tested it? Let's get this into trunk and branch-2 before worrying about an old maintenance branch.\n\nbq. The failed test seems like it might be legit. I will look into it.\n\nIndeed the failed test turned out to be because the upgrade test used files with checksums of length 60, which didn't divide evenly into the configured packet size. The new patch rounds down the packet size to align to a chunk boundary, which fixed the test.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2012-11-10T00:59:25.523+0000","updated":"2012-11-10T00:59:25.523+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12555960/comment/13494571","id":"13494571","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12552936/hdfs-3429.txt\n  against trunk revision .\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:green}+1 tests included{color}.  The patch appears to include 4 new or modified test files.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:\n\n                  org.apache.hadoop.hdfs.TestDFSShell\n                  org.apache.hadoop.hdfs.TestFSInputChecker\n                  org.apache.hadoop.hdfs.TestPread\n                  org.apache.hadoop.hdfs.TestParallelRead\n                  org.apache.hadoop.hdfs.server.balancer.TestBalancerWithEncryptedTransfer\n                  org.apache.hadoop.hdfs.server.balancer.TestBalancerWithHANameNodes\n                  org.apache.hadoop.hdfs.TestSmallBlock\n\n    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/3480//testReport/\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/3480//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2012-11-10T05:37:48.572+0000","updated":"2012-11-10T05:37:48.572+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12555960/comment/13494594","id":"13494594","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=liulei.cn","name":"liulei.cn","key":"liulei.cn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"LiuLei","active":true,"timeZone":"Asia/Shanghai"},"body":"I say my understand for this problem, there are two purposes the DN need to read checksum form meta file.\n1. Server need to verify checksum, example Block scanner.\n2. DFSClient need to verify checksum, in te case, DN read checksum but don't verify checnk,  instead , DN send checksum to DFSClient, DFSClient verify checksum.\n\nSo we need to two parameters to indicate the two purposes.\n1. Constructor of BlockSender class has contained one verifyChecksum parameter, that can represent Server whether verify checksum.\n2. FileSystem.setVerifyChecksum(boolean verifyChecksum) method can represent DFSClient whether verify checksum, so we need to send the parameter value to DN, and add one isClientVerifyChecksum parameter in BlockSender constructor。\n\nIf verifyChecksum and isClientVerifyChecksum parameters all are false, DN don't need to read checksum, and only need to send data to client, in the case, we only need to create one DataChecksum.CHECKSUM_NULL instance, the instance can guarantee DN don't read checksum form meta file（because the checksumSize of the DataChecksum.CHECKSUM_NULL instance is 0）.\n\n\nThe patch I commit contain these modifies. \n\n\n\n \n\n \n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=liulei.cn","name":"liulei.cn","key":"liulei.cn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"LiuLei","active":true,"timeZone":"Asia/Shanghai"},"created":"2012-11-10T09:26:48.501+0000","updated":"2012-11-10T09:26:48.501+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12555960/comment/13495072","id":"13495072","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"Aha, I understand now what your patch is doing - the advantage of my earlier version was that it didn't enforce any \"chunking\" on the data path, but it made the code more complicated.\n\nHere's an updated version of my trunk patch which takes an approach more similar to Liu Lei's. The patch should be smaller, and seems to still work.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2012-11-12T03:37:51.091+0000","updated":"2012-11-12T03:37:51.091+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12555960/comment/13495094","id":"13495094","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:green}+1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12553067/hdfs-3429.txt\n  against trunk revision .\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:green}+1 tests included{color}.  The patch appears to include 4 new or modified test files.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.\n\n    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/3482//testReport/\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/3482//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2012-11-12T05:16:17.202+0000","updated":"2012-11-12T05:16:17.202+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12555960/comment/13497715","id":"13497715","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=liulei.cn","name":"liulei.cn","key":"liulei.cn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"LiuLei","active":true,"timeZone":"Asia/Shanghai"},"body":"hi, I want to fix the problem in hadoop-0.20.2,  for compatibility， the DataTransferProtocol.DATA_TRANSFER_VERSION value need to be modified.  DataTransferProtocol.DATA_TRANSFER_VERSION value  is 16 in my current hadoop version.  I want to modify the value to 17, can I do that?  If not,  what value is appropriate？","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=liulei.cn","name":"liulei.cn","key":"liulei.cn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"LiuLei","active":true,"timeZone":"Asia/Shanghai"},"created":"2012-11-15T02:38:54.029+0000","updated":"2012-11-15T02:38:54.029+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12555960/comment/13501772","id":"13501772","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=liulei.cn","name":"liulei.cn","key":"liulei.cn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"LiuLei","active":true,"timeZone":"Asia/Shanghai"},"body":"The new patch for 0.20.2, include below content\n1. Fix the TestDataTransferProtocol unit test\n2. Modify the DataTransferProtocol.DATA_TRANSFER_VERSION value to 18","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=liulei.cn","name":"liulei.cn","key":"liulei.cn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"LiuLei","active":true,"timeZone":"Asia/Shanghai"},"created":"2012-11-21T08:39:48.035+0000","updated":"2012-11-21T08:39:48.035+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12555960/comment/13501774","id":"13501774","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12554468/hdfs-3429-0.20.2.patch\n  against trunk revision .\n\n    {color:red}-1 patch{color}.  The patch command could not apply the patch.\n\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/3552//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2012-11-21T08:44:18.124+0000","updated":"2012-11-21T08:44:18.124+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12555960/comment/13502463","id":"13502463","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"Hi Liu Lei. FYI, since 0.20.x and 1.0.x are stable branches, we can't make protocol-incompatible changes like this. We either need to figure out a creative hack which would allow for wire compatibility, or else keep this feature only targeted at 2.x, where protobufs allow us to safely make these types of changes.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2012-11-22T00:09:09.733+0000","updated":"2012-11-22T00:09:09.733+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12555960/comment/13530955","id":"13530955","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xieliang007","name":"xieliang007","key":"xieliang007","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10434","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10434","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10434","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10434"},"displayName":"Liang Xie","active":true,"timeZone":"Asia/Shanghai"},"body":"[~tlipcon], i applied your latest patch with a nit change: DataChecksum.Type.NULL => DataChecksum.CHECKSUM_NULL\nIn one of our test scenario(100% random read[get], less than 1% cache hit), we got about 2% qps improvement.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xieliang007","name":"xieliang007","key":"xieliang007","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10434","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10434","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10434","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10434"},"displayName":"Liang Xie","active":true,"timeZone":"Asia/Shanghai"},"created":"2012-12-13T12:37:13.407+0000","updated":"2012-12-13T12:37:13.407+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12555960/comment/13531350","id":"13531350","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"Hi Liang. That seems like a lower improvement than expected. What is the ratio of working set vs RAM size? Are you using a version of HBase which has the HFile-checksums built in?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2012-12-13T19:18:32.456+0000","updated":"2012-12-13T19:18:32.456+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12555960/comment/13531964","id":"13531964","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xieliang007","name":"xieliang007","key":"xieliang007","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10434","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10434","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10434","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10434"},"displayName":"Liang Xie","active":true,"timeZone":"Asia/Shanghai"},"body":"[~tlipcon], i am kicking another run with lower io request,  the previous senario was FULL io-bound both w/ & w/a the patch, maybe confuse the comparison","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xieliang007","name":"xieliang007","key":"xieliang007","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10434","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10434","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10434","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10434"},"displayName":"Liang Xie","active":true,"timeZone":"Asia/Shanghai"},"created":"2012-12-14T03:51:34.047+0000","updated":"2012-12-14T03:51:34.047+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12555960/comment/13531966","id":"13531966","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xieliang007","name":"xieliang007","key":"xieliang007","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10434","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10434","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10434","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10434"},"displayName":"Liang Xie","active":true,"timeZone":"Asia/Shanghai"},"body":"we use hbase 0.94.2 with hbase.regionserver.checksum.verify enabled","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xieliang007","name":"xieliang007","key":"xieliang007","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10434","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10434","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10434","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10434"},"displayName":"Liang Xie","active":true,"timeZone":"Asia/Shanghai"},"created":"2012-12-14T03:52:45.213+0000","updated":"2012-12-14T03:52:45.213+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12555960/comment/13532161","id":"13532161","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xieliang007","name":"xieliang007","key":"xieliang007","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10434","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10434","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10434","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10434"},"displayName":"Liang Xie","active":true,"timeZone":"Asia/Shanghai"},"body":"still no obvious difference be found at another 100%read scenario withou IO-bound\n\ni did \"strace -p <DN pid> -f -tt -T -e trace=file -o bbb\" during a several minutes run（without patch）,then:\ngrep \"current/finalized\" bbb|wc -l\n16905\ngrep meta bbb|wc -l\n9858\ngrep meta bbb|grep open|wc -l\n3286\ngrep meta bbb|grep stat|wc -l\n6572\ngrep meta bbb|grep \"\\\".*\\\"\" -o|sort -n |uniq -c|wc -l\n303\nAnd most of those meta files size are several hundred of kilobytes, further more, our OS has a default read_ahead_kb: 128\nso the benefit was not obvious seems make sense as well. Any idea, [~tlipcon] ?\n\nBut i am +1 for this patch, due to it can reduce some unnecessary IO & system call","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xieliang007","name":"xieliang007","key":"xieliang007","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10434","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10434","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10434","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10434"},"displayName":"Liang Xie","active":true,"timeZone":"Asia/Shanghai"},"created":"2012-12-14T08:35:28.061+0000","updated":"2012-12-14T08:35:28.061+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12555960/comment/13532724","id":"13532724","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"Hi Liang. I'm not sure if 0.94.2 has the code right to take advantage of this new feature quite yet -- given you see a bunch of the .meta files being read, it seems like it doesn't. So, that would explain why you don't see a performance difference.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2012-12-14T22:21:42.250+0000","updated":"2012-12-14T22:21:42.250+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12555960/comment/13532891","id":"13532891","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xieliang007","name":"xieliang007","key":"xieliang007","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10434","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10434","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10434","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10434"},"displayName":"Liang Xie","active":true,"timeZone":"Asia/Shanghai"},"body":"O, [~tlipcon], you missed my words: \"without patch\"\n\nthe strace showed the statistic without patch.  \nAfter applied the patch, i could not see so much meta files be opened","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xieliang007","name":"xieliang007","key":"xieliang007","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10434","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10434","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10434","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10434"},"displayName":"Liang Xie","active":true,"timeZone":"Asia/Shanghai"},"created":"2012-12-15T02:04:25.797+0000","updated":"2012-12-15T02:04:25.797+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12555960/comment/13532895","id":"13532895","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xieliang007","name":"xieliang007","key":"xieliang007","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10434","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10434","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10434","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10434"},"displayName":"Liang Xie","active":true,"timeZone":"Asia/Shanghai"},"body":"and the hbase-secific issue is :  HBASE-5074 , fixed at 0.94.0","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xieliang007","name":"xieliang007","key":"xieliang007","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10434","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10434","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10434","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10434"},"displayName":"Liang Xie","active":true,"timeZone":"Asia/Shanghai"},"created":"2012-12-15T02:06:11.397+0000","updated":"2012-12-15T02:06:11.397+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12555960/comment/13534501","id":"13534501","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"Hi Liang. In order to see a better improvement from this patch, you'd need a dataset per node which is on the order of 100x bigger than the available buffer cache -- ie so that the checksums themselves do not fit in cache. Talking with folks at Facebook, where they have a similar improvement in place, they saw a ~30-40% improvement in random read performance due to a similar reduction in IOPS. I believe they have TBs of data per node in this cluster.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2012-12-18T01:17:57.307+0000","updated":"2012-12-18T01:17:57.307+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12555960/comment/13534510","id":"13534510","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=atm","name":"atm","key":"atm","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=atm&avatarId=14136","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=atm&avatarId=14136","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=atm&avatarId=14136","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=atm&avatarId=14136"},"displayName":"Aaron T. Myers","active":true,"timeZone":"America/Los_Angeles"},"body":"+1, the latest patch looks pretty good to me. My only advice would be to make TestPread#testPreadDFSNoChecksum also test the non-transferTo path for completeness, but I doubt seriously doing so will expose any bugs.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=atm","name":"atm","key":"atm","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=atm&avatarId=14136","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=atm&avatarId=14136","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=atm&avatarId=14136","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=atm&avatarId=14136"},"displayName":"Aaron T. Myers","active":true,"timeZone":"America/Los_Angeles"},"created":"2012-12-18T01:30:00.427+0000","updated":"2012-12-18T01:30:00.427+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12555960/comment/13534548","id":"13534548","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xieliang007","name":"xieliang007","key":"xieliang007","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10434","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10434","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10434","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10434"},"displayName":"Liang Xie","active":true,"timeZone":"Asia/Shanghai"},"body":"[~tlipcon], en, sounds good for your point, i'll rerun under the suggest workload this week if get a chance:)","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xieliang007","name":"xieliang007","key":"xieliang007","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10434","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10434","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10434","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10434"},"displayName":"Liang Xie","active":true,"timeZone":"Asia/Shanghai"},"created":"2012-12-18T02:25:06.332+0000","updated":"2012-12-18T02:25:06.332+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12555960/comment/13538830","id":"13538830","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xieliang007","name":"xieliang007","key":"xieliang007","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10434","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10434","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10434","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10434"},"displayName":"Liang Xie","active":true,"timeZone":"Asia/Shanghai"},"body":"i'm sorry, i didn't have a test env to retry this week...","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xieliang007","name":"xieliang007","key":"xieliang007","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10434","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10434","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10434","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10434"},"displayName":"Liang Xie","active":true,"timeZone":"Asia/Shanghai"},"created":"2012-12-22T15:35:46.710+0000","updated":"2012-12-22T15:35:46.710+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12555960/comment/13549588","id":"13549588","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xieliang007","name":"xieliang007","key":"xieliang007","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10434","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10434","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10434","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10434"},"displayName":"Liang Xie","active":true,"timeZone":"Asia/Shanghai"},"body":"I re-verified it with:  1)5T+ test-data 2)5 dn/rs 3)random get\neach run the whole hdfs/hbase cluster was restarted and the os cached was cleared.\nThe applied latency value is nearly half of the original un-applied value,   thanks again, [~tlipcon]","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xieliang007","name":"xieliang007","key":"xieliang007","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10434","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10434","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10434","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10434"},"displayName":"Liang Xie","active":true,"timeZone":"Asia/Shanghai"},"created":"2013-01-10T13:05:15.729+0000","updated":"2013-01-10T13:05:15.729+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12555960/comment/13549902","id":"13549902","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"Great, thanks Liang for the help with testing! I think this needs to be rebased a little bit before it's committed, but I'll work on it.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2013-01-10T18:46:45.300+0000","updated":"2013-01-10T18:46:45.300+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12555960/comment/13553090","id":"13553090","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"Turns out this didn't need rebasing. This is the same patch, but also included the single-line test improvement that Aaron suggested above.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2013-01-14T20:34:41.608+0000","updated":"2013-01-14T20:34:41.608+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12555960/comment/13553100","id":"13553100","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"Committed to trunk and branch-2. (didn't wait for Jenkins since this patch is equivalent to the previous patch, just one test line added, and I re-ran that test manually).","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2013-01-14T20:47:52.690+0000","updated":"2013-01-14T20:47:52.690+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12555960/comment/13553105","id":"13553105","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"Integrated in Hadoop-trunk-Commit #3226 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/3226/])\n    HDFS-3429. DataNode reads checksums even if client does not need them. Contributed by Todd Lipcon. (Revision 1433117)\n\n     Result = SUCCESS\ntodd : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1433117\nFiles : \n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/RemoteBlockReader.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/RemoteBlockReader2.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/DataTransferProtocol.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/Receiver.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/Sender.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockPoolSliceScanner.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockSender.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/proto/datatransfer.proto\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDataTransferProtocol.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestParallelRead.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestParallelReadUtil.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestPread.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2013-01-14T20:55:41.190+0000","updated":"2013-01-14T20:55:41.190+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12555960/comment/13553195","id":"13553195","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12564769/hdfs-3429.txt\n  against trunk revision .\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:green}+1 tests included{color}.  The patch appears to include 4 new or modified test files.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.\n\n        {color:red}-1 release audit{color}.  The applied patch generated 2 release audit warnings.\n\n    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.\n\n    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/3835//testReport/\nRelease audit warnings: https://builds.apache.org/job/PreCommit-HDFS-Build/3835//artifact/trunk/patchprocess/patchReleaseAuditProblems.txt\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/3835//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2013-01-14T22:17:00.605+0000","updated":"2013-01-14T22:17:00.605+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12555960/comment/13553248","id":"13553248","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"The release audit warnings above are a side effect of HADOOP-9097 (unrelated to this patch). Commented there.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2013-01-14T23:12:59.550+0000","updated":"2013-01-14T23:12:59.550+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12555960/comment/13553659","id":"13553659","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"Integrated in Hadoop-Yarn-trunk #97 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/97/])\n    HDFS-3429. DataNode reads checksums even if client does not need them. Contributed by Todd Lipcon. (Revision 1433117)\n\n     Result = SUCCESS\ntodd : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1433117\nFiles : \n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/RemoteBlockReader.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/RemoteBlockReader2.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/DataTransferProtocol.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/Receiver.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/Sender.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockPoolSliceScanner.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockSender.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/proto/datatransfer.proto\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDataTransferProtocol.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestParallelRead.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestParallelReadUtil.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestPread.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2013-01-15T10:47:59.191+0000","updated":"2013-01-15T10:47:59.191+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12555960/comment/13553758","id":"13553758","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"Integrated in Hadoop-Hdfs-trunk #1286 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1286/])\n    HDFS-3429. DataNode reads checksums even if client does not need them. Contributed by Todd Lipcon. (Revision 1433117)\n\n     Result = FAILURE\ntodd : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1433117\nFiles : \n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/RemoteBlockReader.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/RemoteBlockReader2.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/DataTransferProtocol.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/Receiver.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/Sender.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockPoolSliceScanner.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockSender.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/proto/datatransfer.proto\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDataTransferProtocol.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestParallelRead.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestParallelReadUtil.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestPread.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2013-01-15T12:54:26.051+0000","updated":"2013-01-15T12:54:26.051+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12555960/comment/13553791","id":"13553791","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"Integrated in Hadoop-Mapreduce-trunk #1314 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1314/])\n    HDFS-3429. DataNode reads checksums even if client does not need them. Contributed by Todd Lipcon. (Revision 1433117)\n\n     Result = FAILURE\ntodd : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1433117\nFiles : \n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/RemoteBlockReader.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/RemoteBlockReader2.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/DataTransferProtocol.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/Receiver.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/Sender.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockPoolSliceScanner.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockSender.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/proto/datatransfer.proto\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDataTransferProtocol.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestParallelRead.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestParallelReadUtil.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestPread.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2013-01-15T13:20:56.835+0000","updated":"2013-01-15T13:20:56.835+0000"}],"maxResults":44,"total":44,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-3429/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i00rbr:"}}