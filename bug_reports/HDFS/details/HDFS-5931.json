{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12694582","self":"https://issues.apache.org/jira/rest/api/2/issue/12694582","key":"HDFS-5931","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":"2014-02-11T21:06:04.878+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Fri Jun 05 00:42:39 UTC 2015","customfield_12310420":"373090","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-5931/watchers","watchCount":5,"isWatching":false},"created":"2014-02-11T20:22:35.011+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":["BB2015-05-TBR"],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"3.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12325049","id":"12325049","description":"2.2.0 release","name":"2.2.0","archived":false,"released":true,"releaseDate":"2013-10-15"}],"issuelinks":[],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kanaka","name":"kanaka","key":"kanaka","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kanaka&avatarId=24828","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kanaka&avatarId=24828","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kanaka&avatarId=24828","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kanaka&avatarId=24828"},"displayName":"Kanaka Kumar Avvaru","active":true,"timeZone":"Asia/Kolkata"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2015-06-05T00:42:39.901+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12312927","id":"12312927","name":"datanode"},{"self":"https://issues.apache.org/jira/rest/api/2/component/12312926","id":"12312926","name":"namenode"}],"timeoriginalestimate":null,"description":"This is to report some improvements and potential bug fixes to some error handling code. Also attaching a patch for review.\n\nDetails in the first comment.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12628321","id":"12628321","filename":"hdfs-5931.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=d.yuan","name":"d.yuan","key":"d.yuan","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ding Yuan","active":true,"timeZone":"Etc/UTC"},"created":"2014-02-11T20:24:21.121+0000","size":7709,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12628321/hdfs-5931.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12628390","id":"12628390","filename":"hdfs-5931-v2.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=d.yuan","name":"d.yuan","key":"d.yuan","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ding Yuan","active":true,"timeZone":"Etc/UTC"},"created":"2014-02-12T00:49:31.371+0000","size":7585,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12628390/hdfs-5931-v2.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12628500","id":"12628500","filename":"hdfs-5931-v3.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=d.yuan","name":"d.yuan","key":"d.yuan","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ding Yuan","active":true,"timeZone":"Etc/UTC"},"created":"2014-02-12T15:19:12.103+0000","size":8662,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12628500/hdfs-5931-v3.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"373391","customfield_12312823":null,"summary":"Potential bugs and improvements for exception handlers","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=d.yuan","name":"d.yuan","key":"d.yuan","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ding Yuan","active":true,"timeZone":"Etc/UTC"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=d.yuan","name":"d.yuan","key":"d.yuan","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ding Yuan","active":true,"timeZone":"Etc/UTC"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12694582/comment/13898313","id":"13898313","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=atm","name":"atm","key":"atm","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=atm&avatarId=14136","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=atm&avatarId=14136","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=atm&avatarId=14136","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=atm&avatarId=14136"},"displayName":"Aaron T. Myers","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi Ding, thanks a lot for the report. Usually we try to keep the description of a JIRA short since it's reproduced in every email update about the JIRA. You are encouraged to put detailed descriptions in the first comment of the JIRA. I'm reproducing them here for you:\n\nDescription of issues from Ding Yuan:\n\n==========================\nCase 1:\norg/apache/hadoop/hdfs/server/namenode/FSEditLog.java\n\nIn recoverUnclosedStreams, purgeLogsOlderThan, and endCurrentLogSegment,\nwhen not enough journals are found, mapJournalsAndReportErrors throws IOException.\nWhile in some other cases (such as in logEdit()), this case would be handled by a\nlater call to logSync(), which will terminate, but in these three methods these exceptions\nmight be swallowed since logSync() won't be called in anytime soon.\n\nPropose to immediately handle such cases as in logSync().\n\n{noformat}\n  synchronized void recoverUnclosedStreams() {\n    Preconditions.checkState(\n        state == State.BETWEEN_LOG_SEGMENTS,\n        \"May not recover segments - wrong state: %s\", state);\n     try {\n       journalSet.recoverUnfinalizedSegments();\n     } catch (IOException ex) {\n-      // All journals have failed, it is handled in logSync.\n-      // TODO: are we sure this is OK?\n+        //All journals have failed, handle it here.\n+        final String msg =\n+                \"Could not find enough journals. \"\n+            LOG.fatal(msg, new Exception());\n+            IOUtils.cleanup(LOG, journalSet);\n+            terminate(1, msg);\n     }\n   }\n{noformat}\n==========================================\n\n==========================\nCase 2:\nFile: \"org/apache/hadoop/hdfs/server/datanode/BlockPoolSliceStorage.java\"\n\n{noformat}\n@@ -446,6 +446,8 @@\n           deleteDir(tmpDir);\n         } catch (IOException ex) {\n           LOG.error(\"Finalize upgrade for \" + dataDirPath + \" failed.\", ex);\n+          return; // return so users will not see confusing log messages where\n+                  // \"failed\" is immediately followed by \"complete\"\n         }\n         LOG.info(\"Finalize upgrade for \" + dataDirPath + \" is complete.\");\n       }\n{noformat}\n\n In this case, the log can be confusing if deleteDir failed:\n\"Finalize upgrade failed\" message will be immediately followed by \"Finalize upgrade is complete\".\n\nSame pattern can be seen at:\n  Line: 600, File: \"org/apache/hadoop/hdfs/server/datanode/DataStorage.java\"\n  Line: 1250, File: \"org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java\"\n==========================================\n\n==========================\nCase 3:\nFile: \"org/apache/hadoop/hdfs/server/datanode/BPServiceActor.java\"\n\nThe log message doesn't include the exception cause.\n\n{noformat}\n@@ -167,9 +167,9 @@\n         LOG.debug(this + \" received versionRequest response: \" + nsInfo);\n         break;\n       } catch(SocketTimeoutException e) {  // namenode is busy\n-        LOG.warn(\"Problem connecting to server: \" + nnAddr);\n+        LOG.warn(\"Problem connecting to server: \" + nnAddr, e);\n       } catch(IOException e ) {  // namenode is not available\n-        LOG.warn(\"Problem connecting to server: \" + nnAddr);\n+        LOG.warn(\"Problem connecting to server: \" + nnAddr, e);\n       }\n{noformat}\n==========================================\n\n==========================\nCase 4:\nFile: \"org/apache/hadoop/hdfs/server/datanode/BlockSender.java\"\n\n{noformat}\n@@ -371,6 +371,7 @@\n    IOException ioe = null;\n    if (blockInFd != null &&\n        ((dropCacheBehindAllReads) ||\n         (dropCacheBehindLargeReads && isLongRead()))) {\n      try {\n        NativeIO.POSIX.getCacheManipulator().posixFadviseIfPossible(\n            block.getBlockName(), blockInFd, lastCacheDropOffset,\n            offset - lastCacheDropOffset,\n            NativeIO.POSIX.POSIX_FADV_DONTNEED);\n      } catch (IOException e) {\n        LOG.warn(\"Unable to drop cache on file close\", e);\n+       ioe = e;\n      }\n    }\n\n    if(checksumIn!=null) {\n      try {\n        checksumIn.close(); // close checksum file\n      } catch (IOException e) {\n        ioe = e;\n      }\n      checksumIn = null;\n\n .. ..\n    if (ioe!=null) {\n      throw ioe;\n    }\n{noformat}\n\nIt's unclear why exception from posixFadviceIfPossible is not returned to the caller.\n==========================================\n\n==========================\nCase 5:\nFile: org/apache/hadoop/hdfs/server/datanode/DataXceiver.java\n\n{noformat}\n    } finally {\n      dataXceiverServer.balanceThrottler.release();\n      if (isOpSuccess) {\n@@ -751,7 +751,8 @@\n         try {\n           // send one last byte to indicate that the resource is cleaned.\n           reply.writeChar('d');\n-        } catch (IOException ignored) {\n+        } catch (IOException e) {\n+          LOG.warn(\"Exception caught after copy block succeeded \" + e);\n         }\n       }\n       IOUtils.closeStream(reply);\n{noformat}\n\nIt is unclear why the IOException is not logged.\n\nSimilar case:\n  Line: 876, File: \"org/apache/hadoop/hdfs/server/datanode/DataXceiver.java\"\n==========================================\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=atm","name":"atm","key":"atm","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=atm&avatarId=14136","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=atm&avatarId=14136","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=atm&avatarId=14136","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=atm&avatarId=14136"},"displayName":"Aaron T. Myers","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-02-11T21:06:04.878+0000","updated":"2014-02-11T21:06:04.878+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12694582/comment/13898401","id":"13898401","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=d.yuan","name":"d.yuan","key":"d.yuan","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ding Yuan","active":true,"timeZone":"Etc/UTC"},"body":"Thanks Aaron!","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=d.yuan","name":"d.yuan","key":"d.yuan","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ding Yuan","active":true,"timeZone":"Etc/UTC"},"created":"2014-02-11T22:20:45.453+0000","updated":"2014-02-11T22:20:45.453+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12694582/comment/13898474","id":"13898474","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12628321/hdfs-5931.patch\n  against trunk revision .\n\n    {color:red}-1 patch{color}.  The patch command could not apply the patch.\n\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/6114//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2014-02-11T23:11:29.627+0000","updated":"2014-02-11T23:11:29.627+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12694582/comment/13898572","id":"13898572","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=d.yuan","name":"d.yuan","key":"d.yuan","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ding Yuan","active":true,"timeZone":"Etc/UTC"},"body":"Don't know why the previous patch cannot be applied by Hadoop QA. Attaching -v2 that is applied to the newly checked out trunk.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=d.yuan","name":"d.yuan","key":"d.yuan","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ding Yuan","active":true,"timeZone":"Etc/UTC"},"created":"2014-02-12T00:49:31.376+0000","updated":"2014-02-12T00:49:31.376+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12694582/comment/13898763","id":"13898763","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12628390/hdfs-5931-v2.patch\n  against trunk revision .\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.\n                        Please justify why no new tests are needed for this patch.\n                        Also please list what manual steps were performed to verify this patch.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:\n\n                  org.apache.hadoop.hdfs.qjournal.TestNNWithQJM\n\n    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/6117//testReport/\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/6117//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2014-02-12T04:03:27.694+0000","updated":"2014-02-12T04:03:27.694+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12694582/comment/13899180","id":"13899180","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=d.yuan","name":"d.yuan","key":"d.yuan","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ding Yuan","active":true,"timeZone":"Etc/UTC"},"body":"A new patch fixing the test error. The reason hdfs-5931-v2.patch broke the test is that TestNNWithQJM#testMismatchedNNIsRejected() expects the exception message \"Unable to start log segment 1: too few journals\" thrown by FSEditLog.startLogSegment. Now this \"too few journals\" will be detected earlier by recoverUnclosedStreams, and therefore aborts earlier. This seems to be more reasonable as if we cannot even find enough journal in recoverUnclosedStreams, we should not proceed to startLogSegment and wait until then to reject this case.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=d.yuan","name":"d.yuan","key":"d.yuan","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ding Yuan","active":true,"timeZone":"Etc/UTC"},"created":"2014-02-12T15:19:12.108+0000","updated":"2014-02-12T15:19:12.108+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12694582/comment/13899325","id":"13899325","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12628500/hdfs-5931-v3.patch\n  against trunk revision .\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:\n\n                  org.apache.hadoop.hdfs.TestClientReportBadBlock\n\n    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/6123//testReport/\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/6123//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2014-02-12T17:44:30.087+0000","updated":"2014-02-12T17:44:30.087+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12694582/comment/13899893","id":"13899893","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=d.yuan","name":"d.yuan","key":"d.yuan","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ding Yuan","active":true,"timeZone":"Etc/UTC"},"body":"Sorry but I am confused by the Hadoop QA's report of failed test above. I ran TestClientReportBadBlock locally against my patch and all three tests seem to have passed. By looking at the test code I could not see why it can fail on the patch...  Could someone please advise?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=d.yuan","name":"d.yuan","key":"d.yuan","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ding Yuan","active":true,"timeZone":"Etc/UTC"},"created":"2014-02-13T01:30:37.228+0000","updated":"2014-02-13T01:30:37.228+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12694582/comment/13907848","id":"13907848","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=d.yuan","name":"d.yuan","key":"d.yuan","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ding Yuan","active":true,"timeZone":"Etc/UTC"},"body":"Hi [~atm], I took another close look at the test output. It seems the SocketTimeoutException might not be caused by my patch (I ran the test on my machine and it passed). Is there any chance to comment on this patch, and if indeed the test was broke by the patch or there is any other problems with my patch I can further fix it?\n\nThanks,","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=d.yuan","name":"d.yuan","key":"d.yuan","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ding Yuan","active":true,"timeZone":"Etc/UTC"},"created":"2014-02-21T01:34:47.471+0000","updated":"2014-02-21T01:34:47.471+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12694582/comment/14525733","id":"14525733","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"\\\\\n\\\\\n| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | pre-patch |  15m  3s | Pre-patch trunk compilation is healthy. |\n| {color:green}+1{color} | @author |   0m  0s | The patch does not contain any @author tags. |\n| {color:green}+1{color} | tests included |   0m  0s | The patch appears to include 1 new or modified test files. |\n| {color:green}+1{color} | javac |   7m 45s | There were no new javac warning messages. |\n| {color:green}+1{color} | javadoc |   9m 49s | There were no new javadoc warning messages. |\n| {color:green}+1{color} | release audit |   0m 22s | The applied patch does not increase the total number of release audit warnings. |\n| {color:red}-1{color} | checkstyle |   2m 16s | The applied patch generated  499 new checkstyle issues (total was , now 499). |\n| {color:green}+1{color} | whitespace |   0m  0s | The patch has no lines that end in whitespace. |\n| {color:green}+1{color} | install |   1m 36s | mvn install still works. |\n| {color:green}+1{color} | eclipse:eclipse |   0m 33s | The patch built with eclipse:eclipse. |\n| {color:green}+1{color} | findbugs |   3m  7s | The patch does not introduce any new Findbugs (version 2.0.3) warnings. |\n| {color:green}+1{color} | native |   3m 23s | Pre-build of native portion |\n| {color:red}-1{color} | hdfs tests | 165m 58s | Tests failed in hadoop-hdfs. |\n| | | 209m 58s | |\n\\\\\n\\\\\n|| Reason || Tests ||\n| Failed unit tests | hadoop.hdfs.qjournal.TestNNWithQJM |\n|   | hadoop.hdfs.server.namenode.metrics.TestNameNodeMetrics |\n| Timed out tests | org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestLazyPersistFiles |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Patch URL | http://issues.apache.org/jira/secure/attachment/12628500/hdfs-5931-v3.patch |\n| Optional Tests | javadoc javac unit findbugs checkstyle |\n| git revision | trunk / a319771 |\n| checkstyle |  https://builds.apache.org/job/PreCommit-HDFS-Build/10724/artifact/patchprocess/diffcheckstylehadoop-hdfs.txt |\n| hadoop-hdfs test log | https://builds.apache.org/job/PreCommit-HDFS-Build/10724/artifact/patchprocess/testrun_hadoop-hdfs.txt |\n| Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/10724/testReport/ |\n| Java | 1.7.0_55 |\n| uname | Linux asf903.gq1.ygridcore.net 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/10724/console |\n\n\nThis message was automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2015-05-03T09:06:21.033+0000","updated":"2015-05-03T09:06:21.033+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12694582/comment/14525899","id":"14525899","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"\\\\\n\\\\\n| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | pre-patch |  14m 33s | Pre-patch trunk compilation is healthy. |\n| {color:green}+1{color} | @author |   0m  0s | The patch does not contain any @author tags. |\n| {color:green}+1{color} | tests included |   0m  0s | The patch appears to include 1 new or modified test files. |\n| {color:green}+1{color} | javac |   7m 27s | There were no new javac warning messages. |\n| {color:green}+1{color} | javadoc |   9m 33s | There were no new javadoc warning messages. |\n| {color:green}+1{color} | release audit |   0m 22s | The applied patch does not increase the total number of release audit warnings. |\n| {color:red}-1{color} | checkstyle |   2m 14s | The applied patch generated  1 new checkstyle issues (total was 501, now 500). |\n| {color:green}+1{color} | whitespace |   0m  0s | The patch has no lines that end in whitespace. |\n| {color:green}+1{color} | install |   1m 32s | mvn install still works. |\n| {color:green}+1{color} | eclipse:eclipse |   0m 33s | The patch built with eclipse:eclipse. |\n| {color:green}+1{color} | findbugs |   3m  3s | The patch does not introduce any new Findbugs (version 2.0.3) warnings. |\n| {color:green}+1{color} | native |   3m 12s | Pre-build of native portion |\n| {color:red}-1{color} | hdfs tests | 165m 46s | Tests failed in hadoop-hdfs. |\n| | | 208m 20s | |\n\\\\\n\\\\\n|| Reason || Tests ||\n| Failed unit tests | hadoop.hdfs.server.namenode.metrics.TestNameNodeMetrics |\n|   | hadoop.hdfs.qjournal.TestNNWithQJM |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Patch URL | http://issues.apache.org/jira/secure/attachment/12628500/hdfs-5931-v3.patch |\n| Optional Tests | javadoc javac unit findbugs checkstyle |\n| git revision | trunk / a319771 |\n| checkstyle |  https://builds.apache.org/job/PreCommit-HDFS-Build/10749/artifact/patchprocess/diffcheckstylehadoop-hdfs.txt |\n| hadoop-hdfs test log | https://builds.apache.org/job/PreCommit-HDFS-Build/10749/artifact/patchprocess/testrun_hadoop-hdfs.txt |\n| Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/10749/testReport/ |\n| Java | 1.7.0_55 |\n| uname | Linux asf905.gq1.ygridcore.net 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/10749/console |\n\n\nThis message was automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2015-05-03T16:48:24.250+0000","updated":"2015-05-03T16:48:24.250+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12694582/comment/14558848","id":"14558848","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kanaka","name":"kanaka","key":"kanaka","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kanaka&avatarId=24828","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kanaka&avatarId=24828","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kanaka&avatarId=24828","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kanaka&avatarId=24828"},"displayName":"Kanaka Kumar Avvaru","active":true,"timeZone":"Asia/Kolkata"},"body":"Will update the patch for QA reported errors. [~d.yuan], please free to assign to you if you want to work on this JIRA","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kanaka","name":"kanaka","key":"kanaka","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kanaka&avatarId=24828","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kanaka&avatarId=24828","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kanaka&avatarId=24828","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kanaka&avatarId=24828"},"displayName":"Kanaka Kumar Avvaru","active":true,"timeZone":"Asia/Kolkata"},"created":"2015-05-26T08:22:40.448+0000","updated":"2015-05-26T08:22:40.448+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12694582/comment/14573883","id":"14573883","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"body":"Please add tests for the FSEditLog changes.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-06-05T00:41:46.045+0000","updated":"2015-06-05T00:41:46.045+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12694582/comment/14573885","id":"14573885","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"body":"BTW, what are the \"potential bugs\"?  Could you explain?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-06-05T00:42:39.901+0000","updated":"2015-06-05T00:42:39.901+0000"}],"maxResults":14,"total":14,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-5931/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i1sanj:"}}