{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12601656","self":"https://issues.apache.org/jira/rest/api/2/issue/12601656","key":"HDFS-3770","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":"2012-08-08T03:17:58.846+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Wed Aug 15 13:20:13 UTC 2012","customfield_12310420":"240696","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-3770/watchers","watchCount":6,"isWatching":false},"created":"2012-08-07T02:54:12.478+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":["test-fail"],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12335732","id":"12335732","description":"3.0.0-alpha1 release","name":"3.0.0-alpha1","archived":false,"released":true,"releaseDate":"2016-09-03"}],"issuelinks":[{"id":"12355856","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12355856","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"12600037","key":"HDFS-3719","self":"https://issues.apache.org/jira/rest/api/2/issue/12600037","fields":{"summary":"Re-enable append-related tests in TestFileConcurrentReader","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/4","description":"This issue was once resolved, but the resolution was deemed incorrect. From here issues are either marked assigned or resolved.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/reopened.png","name":"Reopened","id":"4","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}}],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2016-05-12T18:13:09.215+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12312916","id":"12312916","name":"test"}],"timeoriginalestimate":null,"description":"TestFileConcurrentReader#testUnfinishedBlockCRCErrorTransferToAppend failed on [a recent job|https://builds.apache.org/job/PreCommit-HDFS-Build/2959]. Looks like a race in the test. The failure is due to a ChecksumException but that's likely due to the DFSOutputstream getting interrupted on close. Looking at the relevant code, waitForAckedSeqno is getting an InterruptedException waiting on dataQueue, looks like there are uses of interrupt where we're not first notifying dataQueue, or waiting for the notifications to be delivered.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"4537","customfield_12312823":null,"summary":"TestFileConcurrentReader#testUnfinishedBlockCRCErrorTransferToAppend failed","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=eli","name":"eli","key":"eli","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eli Collins","active":true,"timeZone":"America/Los_Angeles"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=eli","name":"eli","key":"eli","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eli Collins","active":true,"timeZone":"America/Los_Angeles"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12601656/comment/13429679","id":"13429679","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=eli","name":"eli","key":"eli","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eli Collins","active":true,"timeZone":"America/Los_Angeles"},"body":"Here's the relevant portion of the log:\n\nException in thread \"Thread-2125\" java.lang.RuntimeException: org.apache.hadoop.fs.ChecksumException: Checksum error: /block-being-written-to at 1072128 exp: 1082174632 got: -132500175\n\tat org.apache.hadoop.hdfs.TestFileConcurrentReader$4.run(TestFileConcurrentReader.java:383)\n\tat java.lang.Thread.run(Thread.java:662)\nCaused by: org.apache.hadoop.fs.ChecksumException: Checksum error: /block-being-written-to at 1072128 exp: 1082174632 got: -132500175\n\tat org.apache.hadoop.util.DataChecksum.verifyChunkedSums(DataChecksum.java:297)\n\tat org.apache.hadoop.hdfs.RemoteBlockReader2.verifyPacketChecksums(RemoteBlockReader2.java:221)\n\tat org.apache.hadoop.hdfs.RemoteBlockReader2.readNextPacket(RemoteBlockReader2.java:191)\n\tat org.apache.hadoop.hdfs.RemoteBlockReader2.read(RemoteBlockReader2.java:130)\n\tat org.apache.hadoop.hdfs.DFSInputStream$ByteArrayStrategy.doRead(DFSInputStream.java:526)\n\tat org.apache.hadoop.hdfs.DFSInputStream.readBuffer(DFSInputStream.java:578)\n\tat org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:632)\n\tat org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:673)\n\tat java.io.DataInputStream.read(DataInputStream.java:83)\n\tat org.apache.hadoop.hdfs.TestFileConcurrentReader.tailFile(TestFileConcurrentReader.java:440)\n\tat org.apache.hadoop.hdfs.TestFileConcurrentReader.access$200(TestFileConcurrentReader.java:54)\n\tat org.apache.hadoop.hdfs.TestFileConcurrentReader$4.run(TestFileConcurrentReader.java:379)\n\t... 1 more\nException in thread \"Thread-2124\" java.lang.RuntimeException: java.io.InterruptedIOException: Interrupted while waiting for data to be acknowledged by pipeline\n\tat org.apache.hadoop.hdfs.TestFileConcurrentReader$3.run(TestFileConcurrentReader.java:367)\n\tat java.lang.Thread.run(Thread.java:662)\nCaused by: java.io.InterruptedIOException: Interrupted while waiting for data to be acknowledged by pipeline\n\tat org.apache.hadoop.hdfs.DFSOutputStream.waitForAckedSeqno(DFSOutputStream.java:1649)\n\tat org.apache.hadoop.hdfs.DFSOutputStream.flushInternal(DFSOutputStream.java:1633)\n\tat org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:1718)\n\tat org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:71)\n\tat org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:99)\n\tat org.apache.hadoop.hdfs.TestFileConcurrentReader$3.run(TestFileConcurrentReader.java:363)\n\nAnd this as well..\n\n2012-08-06 23:38:14,373 INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(4727)) - *DIR* NameNode.reportBadBlocks\n2012-08-06 23:38:14,374 INFO  hdfs.StateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(66)) - BLOCK NameSystem.addToCorruptReplicasMap: blk_4844811661965065785 added as corrupt on 127.0.0.1:33823 by /127.0.0.1 because client machine reported it\n2012-08-06 23:38:14,375 ERROR hdfs.TestFileConcurrentReader (TestFileConcurrentReader.java:run(381)) - error tailing file /block-being-written-to\norg.apache.hadoop.fs.ChecksumException: Checksum error: /block-being-written-to at 1072128 exp: 1082174632 got: -132500175\n\tat org.apache.hadoop.util.DataChecksum.verifyChunkedSums(DataChecksum.java:297)\n\tat org.apache.hadoop.hdfs.RemoteBlockReader2.verifyPacketChecksums(RemoteBlockReader2.java:221)\n\tat org.apache.hadoop.hdfs.RemoteBlockReader2.readNextPacket(RemoteBlockReader2.java:191)\n\tat org.apache.hadoop.hdfs.RemoteBlockReader2.read(RemoteBlockReader2.java:130)\n\tat org.apache.hadoop.hdfs.DFSInputStream$ByteArrayStrategy.doRead(DFSInputStream.java:526)\n\tat org.apache.hadoop.hdfs.DFSInputStream.readBuffer(DFSInputStream.java:578)\n\tat org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:632)\n\tat org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:673)\n\tat java.io.DataInputStream.read(DataInputStream.java:83)\n\tat org.apache.hadoop.hdfs.TestFileConcurrentReader.tailFile(TestFileConcurrentReader.java:440)\n\tat org.apache.hadoop.hdfs.TestFileConcurrentReader.access$200(TestFileConcurrentReader.java:54)\n\tat org.apache.hadoop.hdfs.TestFileConcurrentReader$4.run(TestFileConcurrentReader.java:379)\n\tat java.lang.Thread.run(Thread.java:662)\n2012-08-06 23:38:14,376 ERROR hdfs.TestFileConcurrentReader (TestFileConcurrentReader.java:run(393)) - error in tailer\njava.lang.RuntimeException: org.apache.hadoop.fs.ChecksumException: Checksum error: /block-being-written-to at 1072128 exp: 1082174632 got: -132500175\n\tat org.apache.hadoop.hdfs.TestFileConcurrentReader$4.run(TestFileConcurrentReader.java:383)\n\tat java.lang.Thread.run(Thread.java:662)\nCaused by: org.apache.hadoop.fs.ChecksumException: Checksum error: /block-being-written-to at 1072128 exp: 1082174632 got: -132500175\n\tat org.apache.hadoop.util.DataChecksum.verifyChunkedSums(DataChecksum.java:297)\n\tat org.apache.hadoop.hdfs.RemoteBlockReader2.verifyPacketChecksums(RemoteBlockReader2.java:221)\n\tat org.apache.hadoop.hdfs.RemoteBlockReader2.readNextPacket(RemoteBlockReader2.java:191)\n\tat org.apache.hadoop.hdfs.RemoteBlockReader2.read(RemoteBlockReader2.java:130)\n\tat org.apache.hadoop.hdfs.DFSInputStream$ByteArrayStrategy.doRead(DFSInputStream.java:526)\n\tat org.apache.hadoop.hdfs.DFSInputStream.readBuffer(DFSInputStream.java:578)\n\tat org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:632)\n\tat org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:673)\n\tat java.io.DataInputStream.read(DataInputStream.java:83)\n\tat org.apache.hadoop.hdfs.TestFileConcurrentReader.tailFile(TestFileConcurrentReader.java:440)\n\tat org.apache.hadoop.hdfs.TestFileConcurrentReader.access$200(TestFileConcurrentReader.java:54)\n\tat org.apache.hadoop.hdfs.TestFileConcurrentReader$4.run(TestFileConcurrentReader.java:379)\n\t... 1 more\n2012-08-06 23:38:14,377 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(267)) - allowed=true\tugi=jenkins (auth:SIMPLE)\tip=/127.0.0.1\tcmd=append\tsrc=/block-being-written-to\tdst=null\tperm=null\n2012-08-06 23:38:14,377 DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(1329)) - computePacketChunkSize: src=/block-being-written-to, chunkSize=442, chunksPerPacket=1, packetSize=475\n2012-08-06 23:38:14,378 DEBUG hdfs.DFSClient (DFSOutputStream.java:queueCurrentPacket(1342)) - Queued packet 0\n2012-08-06 23:38:14,378 DEBUG hdfs.DFSClient (DFSOutputStream.java:waitForAckedSeqno(1638)) - Waiting for ack for: 0\n2012-08-06 23:38:14,378 DEBUG hdfs.DFSClient (DFSOutputStream.java:run(466)) - Append to block BP-402451742-67.195.138.20-1344296267847:blk_4844811661965065785_2099\n2012-08-06 23:38:14,378 ERROR hdfs.TestFileConcurrentReader (TestFileConcurrentReader.java:run(365)) - error in writer\njava.io.InterruptedIOException: Interrupted while waiting for data to be acknowledged by pipeline\n\tat org.apache.hadoop.hdfs.DFSOutputStream.waitForAckedSeqno(DFSOutputStream.java:1649)\n\tat org.apache.hadoop.hdfs.DFSOutputStream.flushInternal(DFSOutputStream.java:1633)\n\tat org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:1718)\n\tat org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:71)\n\tat org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:99)\n\tat org.apache.hadoop.hdfs.TestFileConcurrentReader$3.run(TestFileConcurrentReader.java:363)\n\tat java.lang.Thread.run(Thread.java:662)\n2012-08-06 23:38:14,379 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1317)) - Shutting down the Mini HDFS Cluster\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=eli","name":"eli","key":"eli","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eli Collins","active":true,"timeZone":"America/Los_Angeles"},"created":"2012-08-07T02:55:10.069+0000","updated":"2012-08-07T02:55:10.069+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12601656/comment/13429681","id":"13429681","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=eli","name":"eli","key":"eli","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eli Collins","active":true,"timeZone":"America/Los_Angeles"},"body":"HDFS-3719 recently re-enabled this test btw.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=eli","name":"eli","key":"eli","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eli Collins","active":true,"timeZone":"America/Los_Angeles"},"created":"2012-08-07T02:56:30.285+0000","updated":"2012-08-07T02:56:30.285+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12601656/comment/13430831","id":"13430831","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"I don't think the interruption is related -- I think we have some kind of subtle race on the DN side with the \"recomputing last chunk\" when appending to a partial chunk - basically the same issue as HDFS-1057 but specific to right as the file is reopened for append.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2012-08-08T03:17:58.846+0000","updated":"2012-08-08T03:17:58.846+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12601656/comment/13430833","id":"13430833","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"Basically: when the reader opens the file, the file is closed, so it's not instanceof {{ReplicaBeingWritten}}. So, it doesn't do the special re-computation of the last checksum chunk at EOF. But, then, after the file is open, another writer comes along and appends. Then the BlockSender doesn't do the workaround for this race, and we end up with the same issue as described in that other JIRA.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2012-08-08T03:20:51.662+0000","updated":"2012-08-08T03:20:51.662+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12601656/comment/13433416","id":"13433416","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"Integrated in Hadoop-Hdfs-trunk-Commit #2637 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk-Commit/2637/])\n    Revert HDFS-3719. See discussion there and HDFS-3770 for more info. (Revision 1372544)\n\n     Result = SUCCESS\natm : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1372544\nFiles : \n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileConcurrentReader.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2012-08-13T18:54:45.624+0000","updated":"2012-08-13T18:54:45.624+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12601656/comment/13433420","id":"13433420","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"Integrated in Hadoop-Common-trunk-Commit #2572 (See [https://builds.apache.org/job/Hadoop-Common-trunk-Commit/2572/])\n    Revert HDFS-3719. See discussion there and HDFS-3770 for more info. (Revision 1372544)\n\n     Result = SUCCESS\natm : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1372544\nFiles : \n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileConcurrentReader.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2012-08-13T18:56:19.567+0000","updated":"2012-08-13T18:56:19.567+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12601656/comment/13433458","id":"13433458","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"Integrated in Hadoop-Mapreduce-trunk-Commit #2593 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk-Commit/2593/])\n    Revert HDFS-3719. See discussion there and HDFS-3770 for more info. (Revision 1372544)\n\n     Result = FAILURE\natm : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1372544\nFiles : \n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileConcurrentReader.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2012-08-13T19:37:37.889+0000","updated":"2012-08-13T19:37:37.889+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12601656/comment/13435044","id":"13435044","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"Integrated in Hadoop-Hdfs-trunk #1135 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1135/])\n    Revert HDFS-3719. See discussion there and HDFS-3770 for more info. (Revision 1372544)\n\n     Result = FAILURE\natm : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1372544\nFiles : \n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileConcurrentReader.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2012-08-15T13:00:54.280+0000","updated":"2012-08-15T13:00:54.280+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12601656/comment/13435073","id":"13435073","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"Integrated in Hadoop-Mapreduce-trunk #1167 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1167/])\n    Revert HDFS-3719. See discussion there and HDFS-3770 for more info. (Revision 1372544)\n\n     Result = FAILURE\natm : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1372544\nFiles : \n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileConcurrentReader.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2012-08-15T13:20:13.274+0000","updated":"2012-08-15T13:20:13.274+0000"}],"maxResults":9,"total":9,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-3770/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i014qn:"}}