{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"13151268","self":"https://issues.apache.org/jira/rest/api/2/issue/13151268","key":"HDFS-13419","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":"2018-04-10T14:51:16.855+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Wed Apr 11 03:36:22 UTC 2018","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-13419/watchers","watchCount":4,"isWatching":false},"created":"2018-04-10T03:19:46.246+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/4","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/minor.svg","name":"Minor","id":"4"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[],"issuelinks":[],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2018-04-11T03:36:22.896+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"components":[],"timeoriginalestimate":null,"description":"i was testing hdfs delegation token expired problem use spark streaming, if i set my batch interval small than 10 sec, my spark streaming program will not dead, but if batch interval was setted bigger than 10 sec, the spark streaming program will dead because of hdfs delegation token expire problem, and the exception as follows\r\n\r\n{code:java}\r\norg.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): token (HDFS_DELEGATION_TOKEN token 14042 for test) is expired\r\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1468)\r\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1399)\r\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)\r\n\tat com.sun.proxy.$Proxy11.getListing(Unknown Source)\r\n\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getListing(ClientNamenodeProtocolTranslatorPB.java:554)\r\n\tat sun.reflect.GeneratedMethodAccessor40.invoke(Unknown Source)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:606)\r\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)\r\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)\r\n\tat com.sun.proxy.$Proxy12.getListing(Unknown Source)\r\n\tat org.apache.hadoop.hdfs.DFSClient.listPaths(DFSClient.java:1969)\r\n\tat org.apache.hadoop.hdfs.DFSClient.listPaths(DFSClient.java:1952)\r\n\tat org.apache.hadoop.hdfs.DistributedFileSystem.listStatusInternal(DistributedFileSystem.java:693)\r\n\tat org.apache.hadoop.hdfs.DistributedFileSystem.access$600(DistributedFileSystem.java:105)\r\n\tat org.apache.hadoop.hdfs.DistributedFileSystem$15.doCall(DistributedFileSystem.java:755)\r\n\tat org.apache.hadoop.hdfs.DistributedFileSystem$15.doCall(DistributedFileSystem.java:751)\r\n\tat org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)\r\n\tat org.apache.hadoop.hdfs.DistributedFileSystem.listStatus(DistributedFileSystem.java:751)\r\n\tat com.envisioncn.arch.App$2$1.call(App.java:120)\r\n\tat com.envisioncn.arch.App$2$1.call(App.java:91)\r\n\tat org.apache.spark.api.java.JavaRDDLike$$anonfun$foreachPartition$1.apply(JavaRDDLike.scala:218)\r\n\tat org.apache.spark.api.java.JavaRDDLike$$anonfun$foreachPartition$1.apply(JavaRDDLike.scala:218)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$foreachPartition$1$$anonfun$apply$28.apply(RDD.scala:902)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$foreachPartition$1$$anonfun$apply$28.apply(RDD.scala:902)\r\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1899)\r\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1899)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:86)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\r\n\tat java.lang.Thread.run(Thread.java:745)\r\n{code}\r\n\r\nthe spark streaming program only call FileSystem.listStatus function in every batch\r\n\r\n{code:java}\r\n                        FileSystem fs = FileSystem.get(new Configuration());\r\n                        FileStatus[] status =  fs.listStatus(new Path(\"/\"));\r\n\r\n                        for(FileStatus status1 : status){\r\n                            System.out.println(status1.getPath());\r\n                        }\r\n{code}\r\n\r\nand i found when hadoop client send rpc request to server, it will first get a connection object and set up the connection if the connection dose not exists.And  it will get a SaslRpcClient to connect to the server side in the connection setup stage.Also server will authenticate the client at the connection setup stage. But if the connection exists, client will use the existed connection, so the authentication stage will not happen. \r\n\r\nThe connection between client and server will be closed if it's idle time exceeds ipc.client.connection.maxidletime, and ipc.client.connection.maxidletime default value is 10sec. Therefore, if i continue send request to server at fixed interval as long as the interval small than 10sec, the connection will not be closed, so delegation token expire problem will not happen.\r\n\r\n\r\n\r\n ","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"client can communicate to server even if hdfs delegation token expired","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=saiergon","name":"saiergon","key":"saiergon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"wangqiang.shen","active":true,"timeZone":"Asia/Shanghai"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=saiergon","name":"saiergon","key":"saiergon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"wangqiang.shen","active":true,"timeZone":"Asia/Shanghai"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/13151268/comment/16432402","id":"16432402","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"body":"Yes, a token is checked on connection establishment. If the connection stays up, token expiration won't affect on-going requests. \r\nDo you have a use case that require connection to be closed by server on token expiration?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"created":"2018-04-10T14:51:16.855+0000","updated":"2018-04-10T14:51:16.855+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13151268/comment/16433353","id":"16433353","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=saiergon","name":"saiergon","key":"saiergon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"wangqiang.shen","active":true,"timeZone":"Asia/Shanghai"},"body":"I don't have this use case, but i think sink token has expire time, we should prevent the use of token to access services if it was expired. Is that right?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=saiergon","name":"saiergon","key":"saiergon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"wangqiang.shen","active":true,"timeZone":"Asia/Shanghai"},"created":"2018-04-11T03:36:22.896+0000","updated":"2018-04-11T03:36:22.896+0000"}],"maxResults":2,"total":2,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-13419/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i3scnz:"}}