{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12720586","self":"https://issues.apache.org/jira/rest/api/2/issue/12720586","key":"HDFS-6515","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":"2014-07-02T08:26:58.468+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Sat Sep 30 00:46:00 UTC 2017","customfield_12310420":"398785","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-6515/watchers","watchCount":14,"isWatching":false},"created":"2014-06-11T13:51:28.610+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":["BB2015-05-TBR","hadoop","test"],"customfield_12312333":null,"customfield_12310230":"testPageRounder, FsDatasetCache","customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"2.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12326143","id":"12326143","description":"2.4.0 release","name":"2.4.0","archived":false,"released":true,"releaseDate":"2014-04-07"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12326696","id":"12326696","description":"2.4.1 bug-fix release","name":"2.4.1","archived":false,"released":true,"releaseDate":"2014-06-30"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12335732","id":"12335732","description":"3.0.0-alpha1 release","name":"3.0.0-alpha1","archived":false,"released":true,"releaseDate":"2016-09-03"}],"issuelinks":[{"id":"12435366","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12435366","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"12834615","key":"HDFS-8520","self":"https://issues.apache.org/jira/rest/api/2/issue/12834615","fields":{"summary":"Patch for PPC64 block size","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12508899","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12508899","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"13018291","key":"HDFS-11110","self":"https://issues.apache.org/jira/rest/api/2/issue/13018291","fields":{"summary":"Hardcoded BLOCK SIZE value of 4096 is not appropriate for PowerPC","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/10002","description":"A patch for this issue has been uploaded to JIRA by a contributor.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/document.png","name":"Patch Available","id":"10002","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/4","id":4,"key":"indeterminate","colorName":"yellow","name":"In Progress"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}}],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2017-09-30T00:48:06.114+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12312927","id":"12312927","name":"datanode"}],"timeoriginalestimate":null,"description":"I have an issue with test :\n   testPageRounder\n  (org.apache.hadoop.hdfs.server.datanode.TestFsDatasetCache)\non Linux/PowerPC.\n\nOn Linux/Intel, test runs fine.\n\nOn Linux/PowerPC, I have:\ntestPageRounder(org.apache.hadoop.hdfs.server.datanode.TestFsDatasetCache)  Time elapsed: 64.037 sec  <<< ERROR!\njava.lang.Exception: test timed out after 60000 milliseconds\n\nLooking at details, I see that some \"Failed to cache \" messages appear in the traces. Only 10 on Intel, but 186 on PPC64.\n\nOn PPC64, it looks like some thread is waiting for something that never happens, generating a TimeOut.\n\nI'm now using IBM JVM, however I've just checked that the issue also appears with OpenJDK.\n\nI'm now using Hadoop latest, however, the issue appeared within Hadoop 2.4.0 .\n\nI need help for understanding what the test is doing, what traces are expected, in order to understand what/where is the root cause.\n","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12654094","id":"12654094","filename":"HDFS-6515-1.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=Mickael+Olivier","name":"Mickael Olivier","key":"mickael olivier","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Mickael Olivier","active":true,"timeZone":"Europe/Berlin"},"created":"2014-07-04T12:08:32.232+0000","size":1945,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12654094/HDFS-6515-1.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12677586","id":"12677586","filename":"HDFS-6515-2.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=trex58","name":"trex58","key":"trex58","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Tony Reix","active":true,"timeZone":"Etc/UTC"},"created":"2014-10-28T11:15:35.128+0000","size":1929,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12677586/HDFS-6515-2.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"398907","customfield_12312823":null,"summary":"testPageRounder   (org.apache.hadoop.hdfs.server.datanode.TestFsDatasetCache)","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=trex58","name":"trex58","key":"trex58","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Tony Reix","active":true,"timeZone":"Etc/UTC"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=trex58","name":"trex58","key":"trex58","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Tony Reix","active":true,"timeZone":"Etc/UTC"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":"Linux on PPC64\nTested with Hadoop 3.0.0 SNAPSHOT, on RHEL 6.5, on Ubuntu 14.04, on Fedora 19, using mvn -Dtest=TestFsDatasetCache#testPageRounder -X test","customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12720586/comment/14029201","id":"14029201","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=trex58","name":"trex58","key":"trex58","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Tony Reix","active":true,"timeZone":"Etc/UTC"},"body":"More data:\n\nThe \"Failed to cache... message\" is issued due to a method returning -1.\nThis reserve() method from class UsedBytesCount from file FsDatasetCache.java is very simple :\n\n    long reserve(long count) {\n      count = rounder.round(count);\n      while (true) {\n        long cur = usedBytes.get();\n        long next = cur + count;\n        if (next > maxBytes) {\n          return -1;\n        }\n        if (usedBytes.compareAndSet(cur, next)) {\n          return next;\n        }\n      }\n\nAdding some traces before and after the \"if (next > maxBytes)e test,\n\nhere is what we see on x86_64:\n\n@@reserve:: count: 4096 | cur: 0 | next: 4096 | maxBytes: 65536\\0A\n@@reserve:: count: 4096 | cur: 4096 | next: 8192 | maxBytes: 65536\\0A\n@@reserve:: count: 4096 | cur: 8192 | next: 12288 | maxBytes: 65536\\0A\n@@reserve:: count: 4096 | cur: 12288 | next: 16384 | maxBytes: 65536\\0A\n@@reserve:: count: 4096 | cur: 16384 | next: 20480 | maxBytes: 65536\\0A\n@@reserve:: count: 4096 | cur: 0 | next: 4096 | maxBytes: 65536\\0A\n@@reserve:: count: 4096 | cur: 0 | next: 4096 | maxBytes: 65536\\0A\n........ about 30 more lines\n@@reserve:: count: 4096 | cur: 65536 | next: 69632 | maxBytes: 65536\\0A\n  <-------- ERROR -1\n  <-------- ERROR -1\nFailed to cache 1073741841_BP-798842898-127.0.1.1-1402491181446: could not reserve 4096 more bytes in the cache: dfs.datanode.max.locked.memory of 65536 exceeded.\nFailed to cache 1073741842_BP-798842898-127.0.1.1-1402491181446: could not reserve 4096 more bytes in the cache: dfs.datanode.max.locked.memory of 65536 exceeded.\n\nand on PPC64:\n\n@@reserve:: count: 4096 | cur: 0 | next: 4096 | maxBytes: 65536\\0A\n@@reserve:: count: 4096 | cur: 4096 | next: 8192 | maxBytes: 65536\\0A\n@@reserve:: count: 4096 | cur: 8192 | next: 12288 | maxBytes: 65536\\0A\n@@reserve:: count: 4096 | cur: 8192 | next: 12288 | maxBytes: 65536\\0A\n@@reserve:: count: 4096 | cur: 12288 | next: 16384 | maxBytes: 65536\\0A\n@@reserve:: count: 4096 | cur: 16384 | next: 20480 | maxBytes: 65536\\0A\n@@reserve:: count: 65536 | cur: 0 | next: 65536 | maxBytes: 65536\\0A\n@@reserve:: count: 65536 | cur:65536 | next: 131072 | maxBytes: 65536\\0A\n  <-------- ERROR -1\n@@reserve:: count: 65536 | cur: 0 | next: 65536 | maxBytes: 65536\\0A\n@@reserve:: count: 65536 | cur: 0 | next: 65536 | maxBytes: 65536\\0A\n  <-------- ERROR -1\nFailed to cache 1073741825_BP-1511666005-127.0.1.1-1402063542502: could not reserve 65536 more bytes in the c ache: dfs.datanode.max.locked.memory of 65536 exceeded.\n\nThis requires much more investigation. I'm now trying to understand what the HDFS cache mecanism is supposed to do.\n\n=================================\n\nI noticed:\nx86_64: @@reserve:: count: 4096 | cur: 0 | next: 4096 | maxBytes: 65536\\0A\nPPC64 : @@reserve:: count: 65536 | cur: 0 | next: 65536 | maxBytes: 65536\\0A\n\ncount has not the same value.\n\nLooking at CachingTask.run() method :\n    public void run() {\n      boolean success = false;\n      FileInputStream blockIn = null, metaIn = null;\n      MappableBlock mappableBlock = null;\n      ExtendedBlock extBlk = new ExtendedBlock(key.getBlockPoolId(),\n          key.getBlockId(), length, genstamp);\n      LOG.warn(\"@@run:: key: \"+key+\" | blockFileName: \"+blockFileName+\" | length: \"+length+\" | genstamp: \"+genstamp);\n      long newUsedBytes = usedBytesCount.reserve(length);\nand adding traces, I clearly see that, on PPC64, length changes from 512 to 65536, passing by 4096 and 16384, though it is always 512 or 4096 on x86_64.\n\nPPC64 :\n/finalized/blk_1073741825 | length: 512 | genstamp: 1001\n/finalized/blk_1073741826 | length: 512 | genstamp: 1002\n/finalized/blk_1073741828 | length: 512 | genstamp: 1004\n/finalized/blk_1073741827 | length: 512 | genstamp: 1003\n/finalized/blk_1073741829 | length: 512 | genstamp: 1005\n/finalized/blk_1073741826 | length: 65536 | genstamp: 1002\n/finalized/blk_1073741825 | length: 65536 | genstamp: 1001\n/finalized/blk_1073741825 | length: 65536 | genstamp: 1001\n/finalized/blk_1073741825 | length: 65536 | genstamp: 1001\n/finalized/blk_1073741825 | length: 4096 | genstamp: 1001\n/finalized/blk_1073741825 | length: 16384 | genstamp: 1001\n/finalized/blk_1073741825 | length: 65536 | genstamp: 1001\n/finalized/blk_1073741825 | length: 65536 | genstamp: 1001\n\nx86_64:\n/finalized/blk_1073741825 | length: 4096 | genstamp: 1001\\0A\n/finalized/blk_1073741826 | length: 4096 | genstamp: 1002\\0A\n/finalized/blk_1073741827 | length: 4096 | genstamp: 1003\\0A\n/finalized/blk_1073741828 | length: 4096 | genstamp: 1004\\0A\n/finalized/blk_1073741829 | length: 4096 | genstamp: 1005\\0A\n/finalized/blk_1073741825 | length: 4096 | genstamp: 1001\\0A\n/finalized/blk_1073741825 | length: 4096 | genstamp: 1001\\0A\n/finalized/blk_1073741826 | length: 4096 | genstamp: 1002\\0A\n/finalized/blk_1073741826 | length: 4096 | genstamp: 1002\\0A\n/finalized/blk_1073741827 | length: 4096 | genstamp: 1003\\0A\n/finalized/blk_1073741827 | length: 4096 | genstamp: 1003\\0A\n/finalized/blk_1073741828 | length: 4096 | genstamp: 1004\\0A\n/finalized/blk_1073741828 | length: 4096 | genstamp: 1004\\0A\n/finalized/blk_1073741829 | length: 4096 | genstamp: 1005\\0A\n/finalized/blk_1073741829 | length: 4096 | genstamp: 1005\\0A\n/finalized/blk_1073741825 | length: 4096 | genstamp: 1001\\0A\n/finalized/blk_1073741826 | length: 4096 | genstamp: 1002\\0A\n/finalized/blk_1073741827 | length: 4096 | genstamp: 1003\\0A\n/finalized/blk_1073741828 | length: 4096 | genstamp: 1004\\0A\n/finalized/blk_1073741829 | length: 4096 | genstamp: 1005\\0A\n/finalized/blk_1073741830 | length: 4096 | genstamp: 1006\\0A\n/finalized/blk_1073741831 | length: 4096 | genstamp: 1007\\0A\n/finalized/blk_1073741832 | length: 4096 | genstamp: 1008\\0A\n/finalized/blk_1073741833 | length: 4096 | genstamp: 1009\\0A\n/finalized/blk_1073741834 | length: 4096 | genstamp: 1010\\0A\n/finalized/blk_1073741835 | length: 4096 | genstamp: 1011\\0A\n/finalized/blk_1073741836 | length: 4096 | genstamp: 1012\\0A\n/finalized/blk_1073741837 | length: 4096 | genstamp: 1013\\0A\n/finalized/blk_1073741838 | length: 4096 | genstamp: 1014\\0A\n/finalized/blk_1073741839 | length: 4096 | genstamp: 1015\\0A\n/finalized/blk_1073741840 | length: 4096 | genstamp: 1016\\0A\n/finalized/blk_1073741841 | length: 4096 | genstamp: 1017\\0A\n/finalized/blk_1073741842 | length: 4096 | genstamp: 1018\\0A\n/finalized/blk_1073741843 | length: 4096 | genstamp: 1019\\0A\n/finalized/blk_1073741844 | length: 4096 | genstamp: 1020\\0A\n/finalized/blk_1073741825 | length: 4096 | genstamp: 1001\\0A\n/finalized/blk_1073741826 | length: 4096 | genstamp: 1002\\0A\n/finalized/blk_1073741827 | length: 4096 | genstamp: 1003\\0A\n/finalized/blk_1073741828 | length: 4096 | genstamp: 1004\\0A\n/finalized/blk_1073741829 | length: 4096 | genstamp: 1005\\0A\n/finalized/blk_1073741825 | length: 512 | genstamp: 1001\\0A\n/finalized/blk_1073741826 | length: 512 | genstamp: 1002\\0A\n/finalized/blk_1073741828 | length: 512 | genstamp: 1004\\0A\n/finalized/blk_1073741827 | length: 512 | genstamp: 1003\\0A\n/finalized/blk_1073741829 | length: 512 | genstamp: 1005\\0A\n/finalized/blk_1073741825 | length: 4096 | genstamp: 1001\\0A\n/finalized/blk_1073741826 | length: 4096 | genstamp: 1002\\0A\n/finalized/blk_1073741827 | length: 4096 | genstamp: 1003\\0A\n/finalized/blk_1073741829 | length: 4096 | genstamp: 1005\\0A\n/finalized/blk_1073741831 | length: 4096 | genstamp: 1007\\0A\n/finalized/blk_1073741833 | length: 4096 | genstamp: 1009\\0A\n/finalized/blk_1073741835 | length: 4096 | genstamp: 1011\\0A\n/finalized/blk_1073741837 | length: 4096 | genstamp: 1013\\0A\n/finalized/blk_1073741839 | length: 4096 | genstamp: 1015\\0A\n/finalized/blk_1073741828 | length: 4096 | genstamp: 1004\\0A\n/finalized/blk_1073741830 | length: 4096 | genstamp: 1006\\0A\n/finalized/blk_1073741841 | length: 4096 | genstamp: 1017\\0A\n/finalized/blk_1073741832 | length: 4096 | genstamp: 1008\\0A\n/finalized/blk_1073741834 | length: 4096 | genstamp: 1010\\0A\n/finalized/blk_1073741836 | length: 4096 | genstamp: 1012\\0A\n/finalized/blk_1073741838 | length: 4096 | genstamp: 1014\\0A\n/finalized/blk_1073741840 | length: 4096 | genstamp: 1016\\0A\n/finalized/blk_1073741825 | length: 4096 | genstamp: 1001\\0A\n/finalized/blk_1073741825 | length: 4096 | genstamp: 1001\\0A\n\n\n=================================================================\n\n\nHere are the main classes & methods dealing with getting the length:\n\npublic class Block implements Writable, Comparable<Block> {\n...\n  public long getNumBytes() {\n    return numBytes;\n  }\n...\n}\n\npublic interface Replica {\n...\n}\n\nabstract public class ReplicaInfo extends Block implements Replica {\n...\n}\n\npublic class FinalizedReplica extends ReplicaInfo {\n  @Override\n  public long getVisibleLength() {\n    return getNumBytes(); // all bytes are visible\n  }\n}\n\nclass ReplicaMap {\n...\n  ReplicaInfo get(String bpid, long blockId) {\n    checkBlockPool(bpid);\n    synchronized(mutex) {\n      Map<Long, ReplicaInfo> m = map.get(bpid);\n      return m != null ? m.get(blockId) : null;\n    }\n  }\n...\n}\n\nclass FsDatasetImpl implements FsDatasetSpi<FsVolumeImpl {\n\nfinal ReplicaMap volumeMap;\n\nprivate void cacheBlock(String bpid, long blockId) {\n...\n    long length, genstamp;\n...\n   ReplicaInfo info = volumeMap.get(bpid, blockId);\n...\n   length = info.getVisibleLength();\n...\n    cacheManager.cacheBlock(blockId, bpid, blockFileName, length, genstamp, volumeExecutor);\n...\n}\n\ncacheBlock(long blockId, String bpid, String blockFileName, long length, long genstamp, Executor volumeExecutor)\n{\n....\n         volumeExecutor.execute(new CachingTask(key, blockFileName, length, genstamp));\n}\n\npublic class FsDatasetCache {\n...\n\nprivate class CachingTask implements Runnable {\n...\n    private final long length;\n...\n\n    CachingTask(ExtendedBlockId key, String blockFileName, long length, long genstamp) {\n...\n      this.length = length;\n...\n    }\n\n    @Override\n    public void run() {\n....\n      ExtendedBlock extBlk = new ExtendedBlock(key.getBlockPoolId(), key.getBlockId(), length, genstamp);\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=trex58","name":"trex58","key":"trex58","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Tony Reix","active":true,"timeZone":"Etc/UTC"},"created":"2014-06-12T14:33:10.501+0000","updated":"2014-06-12T14:33:10.501+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12720586/comment/14029234","id":"14029234","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=trex58","name":"trex58","key":"trex58","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Tony Reix","active":true,"timeZone":"Etc/UTC"},"body":"grep \"waiting for \" Issue3.testPageRounder.5 | grep cached\n\ngives on PPC64:\n\n(TestFsDatasetCache.java:get(530)) - waiting for 1 to be cached.   Right now only 0 blocks are cached.\\0A\n(TestFsDatasetCache.java:get(563)) - waiting for directive 2 to be cached.  stats = {bytesNeeded: 65536\\2C bytesCached: 0\\2C filesNeeded: 1\\2C filesCached: 0\\2C hasExpired: false}\\0A\n(TestFsDatasetCache.java:get(563)) - waiting for directive 2 to be cached.  stats = {bytesNeeded: 65536\\2C bytesCached: 0\\2C filesNeeded: 1\\2C filesCached: 0\\2C hasExpired: false}\\0A\n(TestFsDatasetCache.java:get(563)) - waiting for directive 2 to be cached.  stats = {bytesNeeded: 65536\\2C bytesCached: 0\\2C filesNeeded: 1\\2C filesCached: 0\\2C hasExpired: false}\\0A\n\nand on x86_64 :\n\n(TestFsDatasetCache.java:get(530)) - waiting for 16 to be cached.   Right now only 0 blocks are cached.\\0A\n(TestFsDatasetCache.java:get(563)) - waiting for directive 2 to be cached.  stats = {bytesNeeded: 4096\\2C bytesCached: 0\\2C filesNeeded: 1\\2C filesCached: 0\\2C hasExpired: false}\\0A\n(TestFsDatasetCache.java:get(563)) - waiting for directive 2 to be cached.  stats = {bytesNeeded: 4096\\2C bytesCached: 0\\2C filesNeeded: 1\\2C filesCached: 0\\2C hasExpired: false}\\0A\n(TestFsDatasetCache.java:get(563)) - waiting for directive 2 to be cached.  stats = {bytesNeeded: 4096\\2C bytesCached: 0\\2C filesNeeded: 1\\2C filesCached: 0\\2C hasExpired: false}\\0A\n\nPPC64:   bytesNeeded: 65536\nx86_64: bytesNeeded: 4096\n\n\n\nnativeio.NativeIO (NativeIO.java:mlock(160)) - mlocking /home/tony/hadoop-3.X.Y-FromGitHub/hadoop-common/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-2013187742-127.0.1.1-1402063475487/current/finalized/blk_1073741825\\0A\n\nUsing mlock() is done 10 times on PPC64 and 44 times on x86_64 .","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=trex58","name":"trex58","key":"trex58","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Tony Reix","active":true,"timeZone":"Etc/UTC"},"created":"2014-06-12T15:12:30.736+0000","updated":"2014-06-12T15:12:30.736+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12720586/comment/14049734","id":"14049734","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=Mickael+Olivier","name":"Mickael Olivier","key":"mickael olivier","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Mickael Olivier","active":true,"timeZone":"Europe/Berlin"},"body":"As said on https://issues.apache.org/jira/browse/HDFS-6608, the bug might be related to the hard-coded limit maxBytes = 65536 bytes, assigned at the begining of the TestFsDatasetCache.java file as follows : \n\n// Most Linux installs allow a default of 64KB locked memory\nprivate static final long CACHE_CAPACITY = 64 * 1024;\nconf.setLong(DFSConfigKeys.DFS_DATANODE_MAX_LOCKED_MEMORY_KEY,\n        CACHE_CAPACITY);\n\nThen on FsDatasetCache we have\n\nthis.maxBytes = dataset.datanode.getDnConf().getMaxLockedMemory();\nThis call gets back the value.\n\nSo I actually tried to come with something like \nprivate static final long CACHE_CAPACITY = 16 * 64 * 1024;\n\nForking I indeed retrieve in the logs maxBytes : 1048576\\0A !\nBut the count value is now capped at 4096, which is weird. So I finally get\n\nverifyExpectedCacheUsage: have 20480/327680 bytes cached; 5/5 blocks cached. memlock limit = 1125899906842624.  Waiting...\\0A\n\neach time the supplier tries to check the cache is used as expected.\nThough it seems all 5 blocks are cached, the osPageSize on the size of the cache is still 4096. Which is what should be changed !\n\npublic long round(long count) {\n      long newCount = \n          (count + (osPageSize - 1)) / osPageSize;\n      return newCount * osPageSize;\n    }\n\nprivate final long osPageSize =\n        NativeIO.POSIX.getCacheManipulator().getOperatingSystemPageSize();\n\nThat should give 65536 again so when reserving 512 bytes, we should have newCount = 1, returning 65536 bytes to reserve.\nWhy is that not the case ? (First step is  @@reserve:: count : 4096 | next : 4096 | maxBytes : 1048576\\0A)\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=Mickael+Olivier","name":"Mickael Olivier","key":"mickael olivier","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Mickael Olivier","active":true,"timeZone":"Europe/Berlin"},"created":"2014-07-02T08:26:58.468+0000","updated":"2014-07-02T08:26:58.468+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12720586/comment/14052389","id":"14052389","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=Mickael+Olivier","name":"Mickael Olivier","key":"mickael olivier","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Mickael Olivier","active":true,"timeZone":"Europe/Berlin"},"body":"This patch does 2 things that should NOT modify the behavior before applying it when used with systems with a PAGE_SIZE of 4096 :\n\n1 - Change in TestFsDatasetCache.java\n\\- private static final long CACHE_CAPACITY = 64 * 1024;\n+ private static final long CACHE_CAPACITY = 16 * PAGE_SIZE;\n\n2 - Change in NativeIO.java, class NoMlockCacheManipulator\n\n\\- public long getOperatingSystemPageSize() { return 4096; }\n+ public long getOperatingSystemPageSize() { return NativeIO.getOperatingSystemPageSize(); }\n\nThe first change is motivated by the fact that on systems with a page size of, e.g. 65536 bytes, we could only reserve one page in the cache for testing. \n\nThe second is motivated by the fact that on systems with a page size of, e.g. 65536 bytes, saying it is 4096 leaded method verifyExpectedCacheUsage to fail even when the suited number of blocks was reserved (i.e. leading to a timeout)","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=Mickael+Olivier","name":"Mickael Olivier","key":"mickael olivier","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Mickael Olivier","active":true,"timeZone":"Europe/Berlin"},"created":"2014-07-04T12:07:33.906+0000","updated":"2014-07-04T12:07:33.906+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12720586/comment/14052390","id":"14052390","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=Mickael+Olivier","name":"Mickael Olivier","key":"mickael olivier","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Mickael Olivier","active":true,"timeZone":"Europe/Berlin"},"body":"Patch for the issue, see release notes","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=Mickael+Olivier","name":"Mickael Olivier","key":"mickael olivier","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Mickael Olivier","active":true,"timeZone":"Europe/Berlin"},"created":"2014-07-04T12:08:32.235+0000","updated":"2014-07-04T12:08:32.235+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12720586/comment/14052511","id":"14052511","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12654094/HDFS-6515-1.patch\n  against trunk revision .\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:red}-1 core tests{color}.  The following test timeouts occurred in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs:\n\norg.apache.hadoop.http.TestHttpServer\n\n    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/7283//testReport/\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/7283//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2014-07-04T15:28:41.089+0000","updated":"2014-07-04T15:28:41.089+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12720586/comment/14053603","id":"14053603","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=Mickael+Olivier","name":"Mickael Olivier","key":"mickael olivier","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Mickael Olivier","active":true,"timeZone":"Europe/Berlin"},"body":"The test class that failed because of a timeout seems unreleated to my modifications as it does not seem to have anything to do with the filesystem. I cannot retrieve it on Jenkins test results, and on eclipse I see a TestHttpServer that is in the http package, not the hdfs one.\n\nOther tests that were not skipped seem to path without any failure, but the console output log is disturbing as there are several weird exceptions. I wonder weither it is possible to resubmit the patch using -X option or not.\n\nErrors I found are :\n\nhdfsOpenFile(/tlhData0001/file1): FileSystem#open((Lorg/apache/hadoop/fs/Path;I)Lorg/apache/hadoop/fs/FSDataInputStream;) error\nhdfsOpenFile(/tlhData0002/file1): FileSystem#open((Lorg/apache/hadoop/fs/Path;I)Lorg/apache/hadoop/fs/FSDataInputStream;) error\nERROR: cannot open an hdfs file in mode 0x3\njava.io.FileNotFoundException: File does not exist: /tlhData0002/file1\nERROR: cannot open an hdfs file in mode 0x3\nhdfsOpenFile(/tlhData0000/file1): FileSystem#open((Lorg/apache/hadoop/fs/Path;I)Lorg/apache/hadoop/fs/FSDataInputStream;) error\n\nBut these might not be what we are looking for.\n\nOn the other hand, the only reference to TestHttpServer is :\n\nRunning org.apache.hadoop.http.TestHttpServer\n\nWhen running mvn -Dtest=TestHttpServer test -X on my ubuntu VB, and on my ppc (RHEL 6.5), it successfully builds on my side.\nWhat kind of environment are you using for testing ?\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=Mickael+Olivier","name":"Mickael Olivier","key":"mickael olivier","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Mickael Olivier","active":true,"timeZone":"Europe/Berlin"},"created":"2014-07-07T12:39:17.207+0000","updated":"2014-07-07T12:39:17.207+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12720586/comment/14184927","id":"14184927","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12654094/HDFS-6515-1.patch\n  against trunk revision caecd9f.\n\n    {color:red}-1 patch{color}.  The patch command could not apply the patch.\n\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/8549//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2014-10-27T07:51:17.021+0000","updated":"2014-10-27T07:51:17.021+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12720586/comment/14186625","id":"14186625","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=trex58","name":"trex58","key":"trex58","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Tony Reix","active":true,"timeZone":"Etc/UTC"},"body":"Hello\nReading the console output, I see nothing related to the patch that could be the root cause of the failure.\n\nThe error seems to be around:\n\nHDFS-6515 patch is being downloaded at Mon Oct 27 07:51:14 UTC 2014 from\nhttp://issues.apache.org/jira/secure/attachment/12654094/HDFS-6515-1.patch\ncp: cannot stat '/home/jenkins/buildSupport/lib/*': No such file or directory\nThe patch does not appear to apply with p0 to p2\nPATCH APPLICATION FAILED\n\nwhere the error deals with some lib stored in Jenkins directory.\n\nOn my side, I gonna check that the patch works fine on the branch 'trunk'.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=trex58","name":"trex58","key":"trex58","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Tony Reix","active":true,"timeZone":"Etc/UTC"},"created":"2014-10-28T09:15:01.744+0000","updated":"2014-10-28T09:15:01.744+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12720586/comment/14186650","id":"14186650","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=trex58","name":"trex58","key":"trex58","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Tony Reix","active":true,"timeZone":"Etc/UTC"},"body":"Patching the trunk of Hadoop Common trunk from official GitHub with the patch provided here works perfectly :\n\n$ patch -p0 < ../HDFS-6515-1.patch \npatching file hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/nativeio/NativeIO.java\nHunk #1 succeeded at 166 (offset 1 line).\npatching file hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestFsDatasetCache.java\n\nI've checked the 2 files and they are OK.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=trex58","name":"trex58","key":"trex58","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Tony Reix","active":true,"timeZone":"Etc/UTC"},"created":"2014-10-28T09:40:14.662+0000","updated":"2014-10-28T09:40:14.662+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12720586/comment/14186699","id":"14186699","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=trex58","name":"trex58","key":"trex58","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Tony Reix","active":true,"timeZone":"Etc/UTC"},"body":"There is an issue on Hadoop Common GitHub Web page:\n downloading \"ZIP File\" from \"Download ZIP\" button generated a set of source code that is old, probably dated August 23th, since the latest commit displayed is said to be:\n     Arpit Agarwal arp7 authored on 23 Aug     latest commit 42a61a4fbc\n\nWhen getting Hadoop Common source code with \"git clone\", I see that the patch fails.\n\nI've change the patch, and tested it on a \"git clone\", and that works.\nI gonna push a new patch now.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=trex58","name":"trex58","key":"trex58","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Tony Reix","active":true,"timeZone":"Etc/UTC"},"created":"2014-10-28T11:09:48.813+0000","updated":"2014-10-28T11:09:48.813+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12720586/comment/14186701","id":"14186701","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=trex58","name":"trex58","key":"trex58","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Tony Reix","active":true,"timeZone":"Etc/UTC"},"body":"Source code of Hadoop has changed since the patch was produced.\nI gonna provide a new version of the patch, that works with today's code.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=trex58","name":"trex58","key":"trex58","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Tony Reix","active":true,"timeZone":"Etc/UTC"},"created":"2014-10-28T11:11:09.024+0000","updated":"2014-10-28T11:11:09.024+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12720586/comment/14186705","id":"14186705","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=trex58","name":"trex58","key":"trex58","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Tony Reix","active":true,"timeZone":"Etc/UTC"},"body":"Previous patch has been updated to work with current Hadoop code.\n\n$ patch -p0 < /tmp/HDFS-6515-2.patch \npatching file hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/nativeio/NativeIO.java\nHunk #1 succeeded at 171 (offset 6 lines).\npatching file hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestFsDatasetCache.java\n\n git status\n# On branch trunk\n# Changes not staged for commit:\n#   (use \"git add <file>...\" to update what will be committed)\n#   (use \"git checkout -- <file>...\" to discard changes in working directory)\n#\n#\tmodified:   hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/nativeio/NativeIO.java\n#\tmodified:   hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestFsDatasetCache.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=trex58","name":"trex58","key":"trex58","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Tony Reix","active":true,"timeZone":"Etc/UTC"},"created":"2014-10-28T11:14:11.412+0000","updated":"2014-10-28T11:14:11.412+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12720586/comment/14186737","id":"14186737","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12677586/HDFS-6515-2.patch\n  against trunk revision c9bec46.\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:red}-1 findbugs{color}.  The patch appears to cause Findbugs (version 2.0.3) to fail.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:green}+1 core tests{color}.  The patch passed unit tests in .\n\n    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/8567//testReport/\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/8567//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2014-10-28T11:53:46.991+0000","updated":"2014-10-28T11:53:46.991+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12720586/comment/14186918","id":"14186918","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=trex58","name":"trex58","key":"trex58","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Tony Reix","active":true,"timeZone":"Etc/UTC"},"body":"Test report says:\n  [INFO] BUILD SUCCESS\nbut there are errors after:\n - Determining number of patched Findbugs warnings :\n  /home/jenkins/j/home/jenkins/jenkins-slave/workspace/PreCommit-HDFS-Build@2/dev-support/test-patch.sh: line 622:  2899 Killed enkins-slave/workspace/PreCommit-HDFS-Build@2/dev-support/test-patch.sh: line 622:  2899 Killed \n - Running tests:\n /bin/grep: /home/jenkins/jenkins-slave/workspace/PreCommit-HDFS-Build@2/../patchprocess/patch: No such file or directory\n\n {color:red}-1 findbugs{color}.  The patch appears to cause Findbugs (version 2.0.3) to fail.\n\n - Checking the integrity of system test framework code.:\n   mv: cannot stat '/home/jenkins/jenkins-slave/workspace/PreCommit-HDFS-Build@2/../patchprocess': No such file or directory\n\nI'm now running:\n   mvn clean test findbugs:findbugs -DskipTests -DHadoopPatchProcess\nin my environment, with trunk patched with 6515, in order to understand what's wrong.\n\nResult:\n[INFO] Apache Hadoop Project POM ......................... FAILURE [1:20.245s]\n[ERROR] Failed to execute goal org.codehaus.mojo:findbugs-maven-plugin:2.3.2:findbugs (default-cli) on project hadoop-project: Execution default-cli of goal org.codehaus.mojo:findbugs-maven-plugin:2.3.2:findbugs failed: Plugin org.codehaus.mojo:findbugs-maven-plugin:2.3.2 or one of its dependencies could not be resolved: Could not transfer artifact asm:asm-xml:jar:3.1 from/to central (http://repo.maven.apache.org/maven2): Read timed out -> [Help 1]\n\nRetesting with -X and Oracle 1.7 JVM instead of IBM JVM:\nResult of: \n    mvn -X test findbugs:findbugs -DskipTests -DHadoopPatchProcess -l mvn.findbugs.OpenJDK.res\nin my environment (Ubuntu 14.04/Intel, Maven 3.0.4) is :\n BUILD SUCCESS","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=trex58","name":"trex58","key":"trex58","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Tony Reix","active":true,"timeZone":"Etc/UTC"},"created":"2014-10-28T15:02:37.396+0000","updated":"2014-10-28T15:02:37.396+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12720586/comment/14188143","id":"14188143","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=trex58","name":"trex58","key":"trex58","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Tony Reix","active":true,"timeZone":"Etc/UTC"},"body":"It seems that https://issues.apache.org/jira/browse/HADOOP-10926 is the root cause of this HDFS-6515 patch to fail.\nSome Jenkins internal issue.\nSee: https://issues.apache.org/jira/browse/HADOOP-10926?focusedCommentId=14187146&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14187146\nHope this will be fixed soon.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=trex58","name":"trex58","key":"trex58","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Tony Reix","active":true,"timeZone":"Etc/UTC"},"created":"2014-10-29T08:51:38.837+0000","updated":"2014-10-29T08:51:38.837+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12720586/comment/14365406","id":"14365406","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12677586/HDFS-6515-2.patch\n  against trunk revision 7179f94.\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs:\n\n                  org.apache.hadoop.hdfs.server.blockmanagement.TestDatanodeManager\n                  org.apache.hadoop.hdfs.TestEncryptionZonesWithKMS\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/9918//testReport/\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/9918//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2015-03-17T16:10:05.849+0000","updated":"2015-03-17T16:10:05.849+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12720586/comment/14366742","id":"14366742","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=Ayappan","name":"Ayappan","key":"ayappan","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ayappan","active":true,"timeZone":"Asia/Kolkata"},"body":"Above testcases are unrelated to this patch","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=Ayappan","name":"Ayappan","key":"ayappan","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ayappan","active":true,"timeZone":"Asia/Kolkata"},"created":"2015-03-18T06:59:42.340+0000","updated":"2015-03-18T06:59:42.340+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12720586/comment/14372943","id":"14372943","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinodkv","name":"vinodkv","key":"vinodkv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinod Kumar Vavilapalli","active":true,"timeZone":"America/Los_Angeles"},"body":"Seems like a long standing test-issue. Moving out of 2.7 which is close.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinodkv","name":"vinodkv","key":"vinodkv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinod Kumar Vavilapalli","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-03-21T18:31:18.467+0000","updated":"2015-03-21T18:31:18.467+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12720586/comment/14529832","id":"14529832","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tony.reix%40atos.net","name":"tony.reix@atos.net","key":"tony.reix@atos.net","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Tony Reix","active":true,"timeZone":"Etc/UTC"},"body":"I am out of my office from September 26th till October 3rd.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tony.reix%40atos.net","name":"tony.reix@atos.net","key":"tony.reix@atos.net","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Tony Reix","active":true,"timeZone":"Etc/UTC"},"created":"2015-05-06T03:32:41.215+0000","updated":"2015-05-06T03:32:41.215+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12720586/comment/14711289","id":"14711289","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"\\\\\n\\\\\n| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:red}-1{color} | pre-patch |  19m 34s | Pre-patch trunk has 4 extant Findbugs (version 3.0.0) warnings. |\n| {color:green}+1{color} | @author |   0m  0s | The patch does not contain any @author tags. |\n| {color:green}+1{color} | tests included |   0m  0s | The patch appears to include 1 new or modified test files. |\n| {color:green}+1{color} | javac |   7m 56s | There were no new javac warning messages. |\n| {color:green}+1{color} | javadoc |  10m  0s | There were no new javadoc warning messages. |\n| {color:green}+1{color} | release audit |   0m 23s | The applied patch does not increase the total number of release audit warnings. |\n| {color:green}+1{color} | checkstyle |   2m 36s | There were no new checkstyle issues. |\n| {color:green}+1{color} | whitespace |   0m  0s | The patch has no lines that end in whitespace. |\n| {color:green}+1{color} | install |   1m 29s | mvn install still works. |\n| {color:green}+1{color} | eclipse:eclipse |   0m 32s | The patch built with eclipse:eclipse. |\n| {color:green}+1{color} | findbugs |   4m 28s | The patch does not introduce any new Findbugs (version 3.0.0) warnings. |\n| {color:green}+1{color} | common tests |  23m  1s | Tests passed in hadoop-common. |\n| {color:red}-1{color} | hdfs tests | 161m 42s | Tests failed in hadoop-hdfs. |\n| | | 231m 44s | |\n\\\\\n\\\\\n|| Reason || Tests ||\n| Failed unit tests | hadoop.hdfs.server.blockmanagement.TestPendingInvalidateBlock |\n|   | hadoop.hdfs.server.namenode.TestDeleteRace |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Patch URL | http://issues.apache.org/jira/secure/attachment/12677586/HDFS-6515-2.patch |\n| Optional Tests | javadoc javac unit findbugs checkstyle |\n| git revision | trunk / eee0d45 |\n| Pre-patch Findbugs warnings | https://builds.apache.org/job/PreCommit-HDFS-Build/12112/artifact/patchprocess/trunkFindbugsWarningshadoop-hdfs.html |\n| hadoop-common test log | https://builds.apache.org/job/PreCommit-HDFS-Build/12112/artifact/patchprocess/testrun_hadoop-common.txt |\n| hadoop-hdfs test log | https://builds.apache.org/job/PreCommit-HDFS-Build/12112/artifact/patchprocess/testrun_hadoop-hdfs.txt |\n| Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/12112/testReport/ |\n| Java | 1.7.0_55 |\n| uname | Linux asf901.gq1.ygridcore.net 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/12112/console |\n\n\nThis message was automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2015-08-25T13:50:54.754+0000","updated":"2015-08-25T13:50:54.754+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12720586/comment/15252977","id":"15252977","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=andrew.wang","name":"andrew.wang","key":"andrew.wang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=andrew.wang&avatarId=19230","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=andrew.wang&avatarId=19230","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=andrew.wang&avatarId=19230","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=andrew.wang&avatarId=19230"},"displayName":"Andrew Wang","active":true,"timeZone":"America/Los_Angeles"},"body":"I'm downgrading the priority of this issue, since lack of PPC support is not a regression.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=andrew.wang","name":"andrew.wang","key":"andrew.wang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=andrew.wang&avatarId=19230","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=andrew.wang&avatarId=19230","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=andrew.wang&avatarId=19230","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=andrew.wang&avatarId=19230"},"displayName":"Andrew Wang","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-04-21T23:12:57.748+0000","updated":"2016-04-21T23:12:57.748+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12720586/comment/15253226","id":"15253226","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 12s {color} | {color:blue} Docker mode activated. {color} |\n| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green} 0m 0s {color} | {color:green} The patch appears to include 1 new or modified test files. {color} |\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue} 0m 14s {color} | {color:blue} Maven dependency ordering for branch {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 6m 40s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 6m 0s {color} | {color:green} trunk passed with JDK v1.8.0_77 {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 6m 41s {color} | {color:green} trunk passed with JDK v1.7.0_95 {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 1m 6s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 51s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 27s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 3m 32s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 2m 2s {color} | {color:green} trunk passed with JDK v1.8.0_77 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 2m 51s {color} | {color:green} trunk passed with JDK v1.7.0_95 {color} |\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue} 0m 29s {color} | {color:blue} Maven dependency ordering for patch {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 1m 27s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 5m 54s {color} | {color:green} the patch passed with JDK v1.8.0_77 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 5m 54s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 6m 44s {color} | {color:green} the patch passed with JDK v1.7.0_95 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 6m 44s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 1m 5s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 48s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 27s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green} 0m 0s {color} | {color:green} Patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 3m 53s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 58s {color} | {color:green} the patch passed with JDK v1.8.0_77 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 2m 53s {color} | {color:green} the patch passed with JDK v1.7.0_95 {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 7m 29s {color} | {color:red} hadoop-common in the patch failed with JDK v1.8.0_77. {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 57m 13s {color} | {color:red} hadoop-hdfs in the patch failed with JDK v1.8.0_77. {color} |\n| {color:green}+1{color} | {color:green} unit {color} | {color:green} 7m 47s {color} | {color:green} hadoop-common in the patch passed with JDK v1.7.0_95. {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 52m 10s {color} | {color:red} hadoop-hdfs in the patch failed with JDK v1.7.0_95. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green} 0m 25s {color} | {color:green} Patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black} 184m 41s {color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| JDK v1.8.0_77 Failed junit tests | hadoop.ipc.TestRPC |\n|   | hadoop.hdfs.server.blockmanagement.TestComputeInvalidateWork |\n|   | hadoop.hdfs.TestFileAppend |\n|   | hadoop.hdfs.shortcircuit.TestShortCircuitCache |\n| JDK v1.7.0_95 Failed junit tests | hadoop.hdfs.server.namenode.TestDecommissioningStatus |\n|   | hadoop.hdfs.TestHFlush |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:fbe3e86 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12677586/HDFS-6515-2.patch |\n| JIRA Issue | HDFS-6515 |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux e71d87890843 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / 14ab7a8 |\n| Default Java | 1.7.0_95 |\n| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_77 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_95 |\n| findbugs | v3.0.0 |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/15248/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.8.0_77.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/15248/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.8.0_77.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/15248/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.7.0_95.txt |\n| unit test logs |  https://builds.apache.org/job/PreCommit-HDFS-Build/15248/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.8.0_77.txt https://builds.apache.org/job/PreCommit-HDFS-Build/15248/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.8.0_77.txt https://builds.apache.org/job/PreCommit-HDFS-Build/15248/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.7.0_95.txt |\n| JDK v1.7.0_95  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/15248/testReport/ |\n| modules | C:  hadoop-common-project/hadoop-common   hadoop-hdfs-project/hadoop-hdfs  U: . |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/15248/console |\n| Powered by | Apache Yetus 0.2.0   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2016-04-22T02:42:39.616+0000","updated":"2016-04-22T02:42:39.616+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12720586/comment/15806329","id":"15806329","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 12s{color} | {color:blue} Docker mode activated. {color} |\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 15s{color} | {color:blue} Maven dependency ordering for branch {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 12m 59s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 10m 10s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m 33s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  2m  5s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 35s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  3m 17s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 33s{color} | {color:green} trunk passed {color} |\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 16s{color} | {color:blue} Maven dependency ordering for patch {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m 28s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  9m 42s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  9m 42s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m 38s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  2m  0s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 38s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  3m 37s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 33s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  8m 17s{color} | {color:green} hadoop-common in the patch passed. {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 67m 53s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 35s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black}131m 28s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| Failed junit tests | hadoop.hdfs.server.namenode.ha.TestEditLogTailer |\n| Timed out junit tests | org.apache.hadoop.hdfs.server.blockmanagement.TestBlockStatsMXBean |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:a9ad5d6 |\n| JIRA Issue | HDFS-6515 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12677586/HDFS-6515-2.patch |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux 286e68157eeb 3.13.0-103-generic #150-Ubuntu SMP Thu Nov 24 10:34:17 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / 71a4acf |\n| Default Java | 1.8.0_111 |\n| findbugs | v3.0.0 |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/18086/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |\n|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/18086/testReport/ |\n| modules | C: hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs U: . |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/18086/console |\n| Powered by | Apache Yetus 0.5.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2017-01-07T00:51:44.337+0000","updated":"2017-01-07T00:51:44.337+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12720586/comment/16082999","id":"16082999","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 12s{color} | {color:blue} Docker mode activated. {color} |\n|| || || || {color:brown} Prechecks {color} ||\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |\n|| || || || {color:brown} trunk Compile Tests {color} ||\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 16s{color} | {color:blue} Maven dependency ordering for branch {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 14m  0s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 14m 22s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m 58s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  2m 36s{color} | {color:green} trunk passed {color} |\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  1m 50s{color} | {color:red} hadoop-hdfs-project/hadoop-hdfs in trunk has 10 extant Findbugs warnings. {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 38s{color} | {color:green} trunk passed {color} |\n|| || || || {color:brown} Patch Compile Tests {color} ||\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 14s{color} | {color:blue} Maven dependency ordering for patch {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m 27s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 10m 52s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 10m 52s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m 56s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  2m 28s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  3m 27s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 36s{color} | {color:green} the patch passed {color} |\n|| || || || {color:brown} Other Tests {color} ||\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}  8m 21s{color} | {color:red} hadoop-common in the patch failed. {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 66m 19s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 37s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black}136m 50s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| Failed junit tests | hadoop.net.TestClusterTopology |\n|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting |\n|   | hadoop.hdfs.TestDFSStripedInputStreamWithRandomECPolicy |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:14b5c93 |\n| JIRA Issue | HDFS-6515 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12677586/HDFS-6515-2.patch |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux 9379d19d37e4 3.13.0-119-generic #166-Ubuntu SMP Wed May 3 12:18:55 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / 12c8fdc |\n| Default Java | 1.8.0_131 |\n| findbugs | v3.1.0-RC1 |\n| findbugs | https://builds.apache.org/job/PreCommit-HDFS-Build/20236/artifact/patchprocess/branch-findbugs-hadoop-hdfs-project_hadoop-hdfs-warnings.html |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/20236/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/20236/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |\n|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/20236/testReport/ |\n| modules | C: hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs U: . |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/20236/console |\n| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2017-07-11T21:15:24.978+0000","updated":"2017-07-11T21:15:24.978+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12720586/comment/16186523","id":"16186523","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=asuresh","name":"asuresh","key":"asuresh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun Suresh","active":true,"timeZone":"America/Los_Angeles"},"body":"Is this still on target for 2.9.0 ? If not, can we we push this out to the next major release ?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=asuresh","name":"asuresh","key":"asuresh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun Suresh","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-09-29T21:42:29.558+0000","updated":"2017-09-29T21:42:29.558+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12720586/comment/16186754","id":"16186754","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 15s{color} | {color:blue} Docker mode activated. {color} |\n|| || || || {color:brown} Prechecks {color} ||\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |\n|| || || || {color:brown} trunk Compile Tests {color} ||\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 14s{color} | {color:blue} Maven dependency ordering for branch {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 12m 15s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 13m 43s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m 45s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 46s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 11m 16s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 47s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 21s{color} | {color:green} trunk passed {color} |\n|| || || || {color:brown} Patch Compile Tests {color} ||\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 13s{color} | {color:blue} Maven dependency ordering for patch {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m 16s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  9m 55s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  9m 55s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m 42s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 43s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green}  6m 56s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  3m 12s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 22s{color} | {color:green} the patch passed {color} |\n|| || || || {color:brown} Other Tests {color} ||\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}  7m  2s{color} | {color:red} hadoop-common in the patch failed. {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 85m 28s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |\n| {color:red}-1{color} | {color:red} asflicense {color} | {color:red}  0m 25s{color} | {color:red} The patch generated 1 ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black}161m 59s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| Failed junit tests | hadoop.fs.shell.TestCopyFromLocal |\n|   | hadoop.net.TestDNS |\n|   | hadoop.security.TestRaceWhenRelogin |\n|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting |\n|   | hadoop.hdfs.web.TestWebHdfsTimeouts |\n|   | hadoop.hdfs.server.datanode.TestNNHandlesCombinedBlockReport |\n| Timed out junit tests | org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure |\n|   | org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager |\n|   | org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure140 |\n|   | org.apache.hadoop.hdfs.qjournal.client.TestQJMWithFaults |\n|   | org.apache.hadoop.hdfs.qjournal.client.TestEpochsAreUnique |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:71bbb86 |\n| JIRA Issue | HDFS-6515 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12677586/HDFS-6515-2.patch |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |\n| uname | Linux 867963fe6d61 4.4.0-43-generic #63-Ubuntu SMP Wed Oct 12 13:48:03 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / 373d0a5 |\n| Default Java | 1.8.0_144 |\n| findbugs | v3.1.0-RC1 |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/21452/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/21452/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |\n|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/21452/testReport/ |\n| asflicense | https://builds.apache.org/job/PreCommit-HDFS-Build/21452/artifact/patchprocess/patch-asflicense-problems.txt |\n| modules | C: hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs U: . |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/21452/console |\n| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2017-09-30T00:46:00.409+0000","updated":"2017-09-30T00:46:00.409+0000"}],"maxResults":27,"total":27,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-6515/votes","votes":1,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i1wnl3:"}}