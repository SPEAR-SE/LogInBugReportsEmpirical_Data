{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12630627","self":"https://issues.apache.org/jira/rest/api/2/issue/12630627","key":"HDFS-4467","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":"2013-02-04T22:57:21.532+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Mon May 06 08:51:37 UTC 2013","customfield_12310420":"311123","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-4467/watchers","watchCount":6,"isWatching":false},"created":"2013-02-04T12:08:15.764+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":"libhdfs","customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12322463","id":"12322463","description":"maintenance release on branch-1.0","name":"1.0.4","archived":false,"released":true,"releaseDate":"2012-10-12"}],"issuelinks":[{"id":"12363937","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12363937","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"inwardIssue":{"id":"12596332","key":"HDFS-3579","self":"https://issues.apache.org/jira/rest/api/2/issue/12596332","fields":{"summary":"libhdfs: fix exception handling","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}}],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2013-05-06T08:51:37.006+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12313126","id":"12313126","name":"libhdfs","description":"The C++ interface to HDFS."}],"timeoriginalestimate":null,"description":"Connecting to HDFS using the libhdfs compiled library gives a segmentation vault and memory leaks; easily verifiable by valgrind.\n\nEven a simple application program given below has memory leaks:\n\n\n#include \"hdfs.h\"\n#include <iostream>\n\nint main(int argc, char **argv) {\n\n    hdfsFS fs = hdfsConnect(\"localhost\", 9000);\n    const char* writePath = \"/tmp/testfile.txt\";\n    hdfsFile writeFile = hdfsOpenFile(fs, writePath, O_WRONLY|O_CREAT, 0, 0, 0);\n    if(!writeFile) {\n          fprintf(stderr, \"Failed to open %s for writing!\\n\", writePath);\n          exit(-1);\n    }\n    char* buffer = \"Hello, World!\";\n    tSize num_written_bytes = hdfsWrite(fs, writeFile, (void*)buffer, strlen(buffer)+1);\n    if (hdfsFlush(fs, writeFile)) {\n           fprintf(stderr, \"Failed to 'flush' %s\\n\", writePath);\n          exit(-1);\n    }\n   hdfsCloseFile(fs, writeFile);\n}\n\n\nshell>valgrind  --leak-check=full ./sample\n\n==12773== LEAK SUMMARY:\n==12773==    definitely lost: 7,893 bytes in 21 blocks\n==12773==    indirectly lost: 4,460 bytes in 23 blocks\n==12773==      possibly lost: 119,833 bytes in 121 blocks\n==12773==    still reachable: 1,349,514 bytes in 8,953 blocks\n\n","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"311471","customfield_12312823":null,"summary":"Segmentation fault in libhdfs while connecting to HDFS, in an application populating Hive Tables","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shubhangi","name":"shubhangi","key":"shubhangi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Shubhangi Garg","active":true,"timeZone":"Etc/UTC"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shubhangi","name":"shubhangi","key":"shubhangi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Shubhangi Garg","active":true,"timeZone":"Etc/UTC"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":"Ubuntu 12.04 (32 bit), application in C++, hadoop 1.0.4","customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12630627/comment/13570134","id":"13570134","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shubhangi","name":"shubhangi","key":"shubhangi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Shubhangi Garg","active":true,"timeZone":"Etc/UTC"},"body":"I am using libhdfs to import data into HDFS from different databases, and populate Hive tables. However, to manipulate HDFS I am using libhdfs; which has segmentation faults. \n\nHowever, even a sample program as above gives a memory leak!","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shubhangi","name":"shubhangi","key":"shubhangi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Shubhangi Garg","active":true,"timeZone":"Etc/UTC"},"created":"2013-02-04T12:22:42.543+0000","updated":"2013-02-04T12:22:42.543+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12630627/comment/13570723","id":"13570723","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi Shubhangi,\n\nThere were a bunch of memory leaks and other problems that I fixed in libhdfs.  Some of those fixes didn't make it back to branch-1.  If you want, you can check out the attached JIRA and consider a backport.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-02-04T22:57:21.532+0000","updated":"2013-02-04T22:57:21.532+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12630627/comment/13571150","id":"13571150","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shubhangi","name":"shubhangi","key":"shubhangi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Shubhangi Garg","active":true,"timeZone":"Etc/UTC"},"body":"Hello Colin,\n\nThank you for the reply and the link. \n\nYes, that will be a good idea to backport it to the current version.\nAre you planning to have a hadoop release sometime near, with the fixes back ported?\nIf there can be anything I can contribute from my side to the code, I am eager to do it.\nThanks.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shubhangi","name":"shubhangi","key":"shubhangi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Shubhangi Garg","active":true,"timeZone":"Etc/UTC"},"created":"2013-02-05T08:31:45.363+0000","updated":"2013-02-05T08:31:45.363+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12630627/comment/13649587","id":"13649587","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=suo+tong","name":"suo tong","key":"suo tong","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"suo tong","active":true,"timeZone":"Etc/UTC"},"body":"hi，Shubhangi Garg。 what is the situation of segmentation fault happened? In my program, if i use a byte with 1M stack space, it will cause the segmentation fault. Below is the code:\n    #include \"hdfs.h\"\n    \n-   int main(int argc, char **argv) {\n|       char b[1024000] = {0};\n|       hdfsFS fs = hdfsConnect(\"default\", 0); \n|-      if (!fs) {\n||          fprintf(stderr, \"Oops! Failed to connect to hdfs!\\n\");\n||          exit(-1);\n||      }   \n|   \n|       hdfsDisconnect(fs);\n|       return 0;\n|   }\n\nthe core file shows the core stack in JNI_CreateJavaVM\n\n(gdb) where\n#0  0x000000302af3f53e in vfprintf () from /lib64/tls/libc.so.6\n#1  0x000000302af61f54 in vsnprintf () from /lib64/tls/libc.so.6\n#2  0x000000302af48001 in snprintf () from /lib64/tls/libc.so.6\n#3  0x0000002a95c6351b in os::dll_build_name () from ..//../java6/jre/lib/amd64/server/libjvm.so\n#4  0x0000002a958caae2 in ClassLoader::load_zip_library () from ..//../java6/jre/lib/amd64/server/libjvm.so\n#5  0x0000002a958cbe37 in ClassLoader::initialize () from ..//../java6/jre/lib/amd64/server/libjvm.so\n#6  0x0000002a958cbfe9 in classLoader_init () from ..//../java6/jre/lib/amd64/server/libjvm.so\n#7  0x0000002a95a03ef7 in init_globals () from ..//../java6/jre/lib/amd64/server/libjvm.so\n#8  0x0000002a95d748b4 in Threads::create_vm () from ..//../java6/jre/lib/amd64/server/libjvm.so\n#9  0x0000002a95a72180 in JNI_CreateJavaVM () from ..//../java6/jre/lib/amd64/server/libjvm.so\n#10 0x0000002a9616b742 in getJNIEnv () at hdfsJniHelper.c:503\n#11 0x0000002a96164fd7 in hdfsConnectAsUser (host=0x400900 \"03\" <Address 0x400906 out of bounds>, port=0, user=0x0, password=0x0) at hdfs.c:201\n#12 0x00000000004007bf in main ()\n\nDoes any one meet this problem? I guess this may be a bug of JDK, i have no idea with it","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=suo+tong","name":"suo tong","key":"suo tong","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"suo tong","active":true,"timeZone":"Etc/UTC"},"created":"2013-05-06T08:30:01.549+0000","updated":"2013-05-06T08:30:01.549+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12630627/comment/13649599","id":"13649599","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shubhangi","name":"shubhangi","key":"shubhangi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Shubhangi Garg","active":true,"timeZone":"Etc/UTC"},"body":"Hi Suo Tong,\n\nThe problem still persists for me, and I get memory leaks using hdfsConnect() functions from libhdfs.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shubhangi","name":"shubhangi","key":"shubhangi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Shubhangi Garg","active":true,"timeZone":"Etc/UTC"},"created":"2013-05-06T08:51:37.006+0000","updated":"2013-05-06T08:51:37.006+0000"}],"maxResults":5,"total":5,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-4467/votes","votes":1,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i1hoyn:"}}