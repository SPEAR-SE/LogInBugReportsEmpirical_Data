{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12819229","self":"https://issues.apache.org/jira/rest/api/2/issue/12819229","key":"HDFS-8093","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/3","id":"3","description":"The problem is a duplicate of an existing issue.","name":"Duplicate"},"customfield_12312322":null,"customfield_12310220":"2015-07-16T12:57:01.644+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Wed Aug 24 16:51:00 UTC 2016","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_18059286156_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2015-11-03T08:49:46.936+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-8093/watchers","watchCount":12,"isWatching":false},"created":"2015-04-08T08:21:40.819+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12327181","id":"12327181","description":"2.6.0 release","name":"2.6.0","archived":false,"released":true,"releaseDate":"2014-11-18"}],"issuelinks":[{"id":"12447658","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12447658","type":{"id":"12310000","name":"Duplicate","inward":"is duplicated by","outward":"duplicates","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/12310000"},"outwardIssue":{"id":"12909880","key":"HDFS-9365","self":"https://issues.apache.org/jira/rest/api/2/issue/12909880","fields":{"summary":"Balancer does not work with the HDFS-6376 HA setup","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}}],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2016-08-24T16:51:12.055+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12313153","id":"12313153","name":"balancer & mover"}],"timeoriginalestimate":null,"description":"HDFS balancer run during several hours blancing blocs beetween datanode, it ended by failing with the following error.\n\ngetStoredBlock function return a null BlockInfo.\n\njava.io.IOException: Bad response ERROR for block BP-970443206-192.168.0.208-1397583979378:blk_1086729930_13046030 from datanode 192.168.0.18:1004\n        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer$ResponseProcessor.run(DFSOutputStream.java:897)\n15/04/08 05:52:51 WARN hdfs.DFSClient: Error Recovery for block BP-970443206-192.168.0.208-1397583979378:blk_1086729930_13046030 in pipeline 192.168.0.63:1004, 192.168.0.1:1004, 192.168.0.18:1004: bad datanode 192.168.0.18:1004\n15/04/08 05:52:51 WARN hdfs.DFSClient: DataStreamer Exception\norg.apache.hadoop.ipc.RemoteException(java.io.IOException): BP-970443206-192.168.0.208-1397583979378:blk_1086729930_13046030 does not exist or is not under Constructionnull\n        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkUCBlock(FSNamesystem.java:6913)\n        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.updateBlockForPipeline(FSNamesystem.java:6980)\n        at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.updateBlockForPipeline(NameNodeRpcServer.java:717)\n        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.updateBlockForPipeline(ClientNamenodeProtocolServerSideTranslatorPB.java:931)\n        at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n        at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)\n        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)\n        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2039)\n        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2035)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:415)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)\n        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2033)\n\n        at org.apache.hadoop.ipc.Client.call(Client.java:1468)\n        at org.apache.hadoop.ipc.Client.call(Client.java:1399)\n        at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)\n        at com.sun.proxy.$Proxy11.updateBlockForPipeline(Unknown Source)\n        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.updateBlockForPipeline(ClientNamenodeProtocolTranslatorPB.java:877)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:606)\n        at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)\n        at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)\n        at com.sun.proxy.$Proxy12.updateBlockForPipeline(Unknown Source)\n        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1266)\n        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:1004)\n        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:548)\n15/04/08 05:52:51 ERROR hdfs.DFSClient: Failed to close inode 19801755\norg.apache.hadoop.ipc.RemoteException(java.io.IOException): BP-970443206-192.168.0.208-1397583979378:blk_1086729930_13046030 does not exist or is not under Constructionnull\n        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkUCBlock(FSNamesystem.java:6913)\n        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.updateBlockForPipeline(FSNamesystem.java:6980)\n        at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.updateBlockForPipeline(NameNodeRpcServer.java:717)\n        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.updateBlockForPipeline(ClientNamenodeProtocolServerSideTranslatorPB.java:931)\n        at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n        at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)\n        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)\n        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2039)\n        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2035)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:415)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)\n        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2033)\n\n        at org.apache.hadoop.ipc.Client.call(Client.java:1468)\n        at org.apache.hadoop.ipc.Client.call(Client.java:1399)\n        at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)\n        at com.sun.proxy.$Proxy11.updateBlockForPipeline(Unknown Source)\n        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.updateBlockForPipeline(ClientNamenodeProtocolTranslatorPB.java:877)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:606)\n        at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)\n        at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)\n        at com.sun.proxy.$Proxy12.updateBlockForPipeline(Unknown Source)\n        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1266)\n        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:1004)\n        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:548)","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"blk does not exist or is not under Constructionnull","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=Alexandre+LINTE","name":"Alexandre LINTE","key":"alexandre linte","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"LINTE","active":true,"timeZone":"Etc/UTC"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=Alexandre+LINTE","name":"Alexandre LINTE","key":"alexandre linte","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"LINTE","active":true,"timeZone":"Etc/UTC"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":"Centos 6.5","customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12819229/comment/14629671","id":"14629671","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=neillfontes","name":"neillfontes","key":"neillfontes","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Neill Lima","active":true,"timeZone":"Europe/Berlin"},"body":"./hadoop fsck /\n\nReturns what on your case? I am having this problem after changing some IP and DNS information on the boxes that run Hadoop. In my case the older IP address is shown in some BPs.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=neillfontes","name":"neillfontes","key":"neillfontes","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Neill Lima","active":true,"timeZone":"Europe/Berlin"},"created":"2015-07-16T12:57:01.644+0000","updated":"2015-07-16T12:57:01.644+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12819229/comment/14696757","id":"14696757","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=fborchers","name":"fborchers","key":"fborchers","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=fborchers&avatarId=20231","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=fborchers&avatarId=20231","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=fborchers&avatarId=20231","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=fborchers&avatarId=20231"},"displayName":"Felix Borchers","active":true,"timeZone":"Europe/Berlin"},"body":"I have a very similar problem while running the balancer.\n{{hdfs fsck /}} returned HEALTHY and the block, causing the balancer to throw an exception is not in the HDFS anymore.\n{{hdfs fsck / -files -blocks | grep blk_1074256920_516292}} - returned nothing\n\nDigging in the logs of the DataNode shows, that the block was deleted on the node.  (see below for log file excerpt)\nDigging in the logs of the NameNode shows, something like \"block .... does not belong to any file\" (see below for log file excerpt)\n\nIt seems, there is a problem with removed/deleted blocks ?!\n\nDataNode Logs\n=============\nonly lines with: blk_1074256920_516292 displayed:\n{code}\n2015-08-14 00:30:03,893 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-322804774-10.13.54.1-1412684451669:blk_1074256920_516292 src: /10.13.53.16:37605 dest: /10.13.53.19:50010\n2015-08-14 00:30:07,841 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1074256920_516292 file /data/is24/hadoop/1/dfs/dataNode/current/BP-322804774-10.13.54.1-1412684451669/current/rbw/blk_1074256920 for deletion\n2015-08-14 00:30:09,092 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-322804774-10.13.54.1-1412684451669 blk_1074256920_516292 file /data/is24/hadoop/1/dfs/dataNode/current/BP-322804774-10.13.54.1-1412684451669/current/rbw/blk_1074256920\norg.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Cannot append to a non-existent replica BP-322804774-10.13.54.1-1412684451669:blk_1074256920_516292\n2015-08-14 00:46:44,916 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-322804774-10.13.54.1-1412684451669:blk_1074256920_516292, type=LAST_IN_PIPELINE, downstreams=0:[]\norg.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Cannot append to a non-existent replica BP-322804774-10.13.54.1-1412684451669:blk_1074256920_516292\n2015-08-14 00:46:44,916 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-322804774-10.13.54.1-1412684451669:blk_1074256920_516292, type=LAST_IN_PIPELINE, downstreams=0:[] terminating\n{code}\n\nNameNode Logs\n=============\n\nonly lines with: blk_1074256920_516292 displayed:\n\n{code}\n2015-08-14 00:30:03,843 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /system/balancer.id. BP-322804774-10.13.54.1-1412684451669 blk_1074256920_516292{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-4db312aa-bc23-47dc-b768-52a2d72b09d3:NORMAL:10.13.53.30:50010|RBW], ReplicaUnderConstruction[[DISK]DS-c7db1b58-8e25-435f-8af8-08b6754c021c:NORMAL:10.13.53.16:50010|RBW], ReplicaUnderConstruction[[DISK]DS-4457ae11-7684-4187-b4ad-56466d79fba2:NORMAL:10.13.53.19:50010|RBW]]}\n2015-08-14 00:30:04,000 INFO BlockStateChange: BLOCK* addBlock: c blk_1074256920_516292 on node 10.13.53.16:50010 size 134217728 does not belong to any file\n2015-08-14 00:30:04,000 INFO BlockStateChange: BLOCK* InvalidateBlocks: add blk_1074256920_516292 to 10.13.53.16:50010\n2015-08-14 00:30:04,000 INFO BlockStateChange: BLOCK* BlockManager: ask 10.13.53.16:50010 to delete [blk_1074256920_516292]\n2015-08-14 00:30:04,840 INFO BlockStateChange: BLOCK* addBlock: block blk_1074256920_516292 on node 10.13.53.19:50010 size 134217728 does not belong to any file\n2015-08-14 00:30:04,840 INFO BlockStateChange: BLOCK* InvalidateBlocks: add blk_1074256920_516292 to 10.13.53.19:50010\n2015-08-14 00:30:05,925 INFO BlockStateChange: BLOCK* addBlock: block blk_1074256920_516292 on node 10.13.53.30:50010 size 134217728 does not belong to any file\n2015-08-14 00:30:05,925 INFO BlockStateChange: BLOCK* InvalidateBlocks: add blk_1074256920_516292 to 10.13.53.30:50010\n2015-08-14 00:30:07,000 INFO BlockStateChange: BLOCK* BlockManager: ask 10.13.53.19:50010 to delete [blk_1074208004_467362, blk_1074224392_483753, blk_1074093070_352362, blk_1074240530_499900, blk_1074256920_516292, blk_1074224154_483515, blk_1074240554_499924, blk_1074240556_499926, blk_1074240561_499931, blk_1074224178_483539, blk_1074240563_499933, blk_1074207795_467153, blk_1074093108_352429, blk_1074207797_467155, blk_1073798197_57374, blk_1074224182_483543, blk_1074240569_499939, blk_1074207802_467160, blk_1074224187_483548, blk_1074224188_483549, blk_1074207805_467163, blk_1074158653_418001, blk_1074207806_467164, blk_1074224191_483552, blk_1074207809_467167, blk_1074207817_467175, blk_1074207818_467176, blk_1074207820_467178, blk_1074207822_467180, blk_1074207830_467188, blk_1074224216_483577, blk_1074224217_483578, blk_1073798237_57414, blk_1073929310_188502, blk_1074207843_467201, blk_1073847400_106577, blk_1074207852_467210, blk_1074207856_467214, blk_1074207868_467226, blk_1074207870_467228, blk_1074207871_467229, blk_1073912966_172154, blk_1073781895_41072, blk_1074207879_467237, blk_1074093193_352516, blk_1074207881_467239, blk_1074207884_467242, blk_1074142350_401677, blk_1074207887_467245, blk_1074207891_467249, blk_1074224277_483638, blk_1074224278_483639, blk_1074207895_467253, blk_1074207897_467255, blk_1074240668_500038, blk_1074240672_500042, blk_1074207907_467265, blk_1074207908_467266, blk_1074207912_467270, blk_1074191530_450887, blk_1074191533_450890, blk_1074207918_467276, blk_1074191534_450891, blk_1074224303_483664, blk_1074224304_483665, blk_1074224306_483667, blk_1074207927_467285, blk_1074191547_450904, blk_1074224316_483677, blk_1074011325_270529, blk_1074191550_450907, blk_1074240706_500076, blk_1073863875_123053, blk_1073863884_123062, blk_1074093266_352589, blk_1074093267_352590, blk_1074093268_352591, blk_1074093269_352592, blk_1074093270_352593, blk_1074175191_434548, blk_1074093271_352594, blk_1074093272_352595, blk_1074175192_434549, blk_1074093273_352596, blk_1074175193_434550, blk_1074093274_352597, blk_1074093275_352598, blk_1074175195_434552, blk_1074093276_352599, blk_1074207965_467323, blk_1074175198_434555, blk_1074175199_434556, blk_1073798369_57546, blk_1074191589_450946, blk_1074191590_450947, blk_1074224365_483726, blk_1074224366_483727, blk_1074207982_467340, blk_1074224379_483740]\n2015-08-14 00:30:07,000 INFO BlockStateChange: BLOCK* BlockManager: ask 10.13.53.30:50010 to delete [blk_1074256368_515740, blk_1074256514_515886, blk_1074256371_515743, blk_1074256372_515744, blk_1074256517_515889, blk_1074256920_516292, blk_1074256382_515754]\n2015-08-14 00:46:44,953 WARN org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:hdfs (auth:SIMPLE) cause:java.io.IOException: BP-322804774-10.13.54.1-1412684451669:blk_1074256920_516292 does not exist or is not under Constructionnull\njava.io.IOException: BP-322804774-10.13.54.1-1412684451669:blk_1074256920_516292 does not exist or is not under Constructionnull\n{code}\n\nbalancer logs\n===========\n\n{code}\n2015-08-14 00:30:02,889 INFO org.apache.hadoop.hdfs.server.balancer.Balancer: Using a threshold of 5.0\n...\n2015-08-14 00:46:44,903 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /racks/rack/10.13.53.11:50010\n2015-08-14 00:46:44,903 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /racks/rack/10.13.53.13:50010\n2015-08-14 00:46:44,903 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /racks/rack/10.13.53.14:50010\n2015-08-14 00:46:44,903 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /racks/rack/10.13.53.30:50010\n2015-08-14 00:46:44,903 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /racks/rack/10.13.53.15:50010\n2015-08-14 00:46:44,903 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /racks/rack/10.13.53.17:50010\n2015-08-14 00:46:44,903 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /racks/rack/10.13.53.12:50010\n2015-08-14 00:46:44,903 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /racks/rack/10.13.53.18:50010\n2015-08-14 00:46:44,903 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /racks/rack/10.13.53.16:50010\n2015-08-14 00:46:44,903 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /racks/rack/10.13.53.19:50010\n2015-08-14 00:46:44,903 INFO org.apache.hadoop.hdfs.server.balancer.Balancer: 1 over-utilized: [10.13.53.30:50010:DISK]\n2015-08-14 00:46:44,903 INFO org.apache.hadoop.hdfs.server.balancer.Balancer: 0 underutilized: []\n2015-08-14 00:46:44,903 INFO org.apache.hadoop.hdfs.server.balancer.Balancer: Need to move 3.21 GB to make the cluster balanced.\n2015-08-14 00:46:44,904 INFO org.apache.hadoop.hdfs.server.balancer.Balancer: Decided to move 1.17 GB bytes from 10.13.53.30:50010:DISK to 10.13.53.11:50010:DISK\n2015-08-14 00:46:44,904 INFO org.apache.hadoop.hdfs.server.balancer.Balancer: Will move 1.17 GB in this iteration\n2015-08-14 00:46:44,919 WARN org.apache.hadoop.hdfs.DFSClient: DFSOutputStream ResponseProcessor exception  for block BP-322804774-10.13.54.1-1412684451669:blk_1074256920_516292\njava.io.IOException: Bad response ERROR for block BP-322804774-10.13.54.1-1412684451669:blk_1074256920_516292 from datanode DatanodeInfoWithStorage[10.13.53.19:50010,DS-4457ae11-7684-4187-b4ad-56466d79fba2,DISK]\nat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer$ResponseProcessor.run(DFSOutputStream.java:909)\n2015-08-14 00:46:44,922 WARN org.apache.hadoop.hdfs.DFSClient: Error Recovery for block BP-322804774-10.13.54.1-1412684451669:blk_1074256920_516292 in pipeline DatanodeInfoWithStorage[10.13.53.30:50010,DS-4db312aa-bc23-47dc-b768-52a2d72b09d3,DISK], DatanodeInfoWithStorage[10.13.53.16:50010,DS-c7db1b58-8e25-435f-8af8-08b6754c021c,DISK], DatanodeInfoWithStorage[10.13.53.19:50010,DS-4457ae11-7684-4187-b4ad-56466d79fba2,DISK]: bad datanode DatanodeInfoWithStorage[10.13.53.19:50010,DS-4457ae11-7684-4187-b4ad-56466d79fba2,DISK]\n2015-08-14 00:46:44,958 WARN org.apache.hadoop.hdfs.DFSClient: DataStreamer Exception\norg.apache.hadoop.ipc.RemoteException(java.io.IOException): BP-322804774-10.13.54.1-1412684451669:blk_1074256920_516292 does not exist or is not under Constructionnull\nat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkUCBlock(FSNamesystem.java:7027)\nat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.updateBlockForPipeline(FSNamesystem.java:7094)\nat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.updateBlockForPipeline(NameNodeRpcServer.java:748)\nat org.apache.hadoop.hdfs.server.namenode.AuthorizationProviderProxyClientProtocol.updateBlockForPipeline(AuthorizationProviderProxyClientProtocol.java:637)\nat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.updateBlockForPipeline(ClientNamenodeProtocolServerSideTranslatorPB.java:932)\nat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\nat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)\nat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1060)\nat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)\nat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2040)\nat java.security.AccessController.doPrivileged(Native Method)\nat javax.security.auth.Subject.doAs(Subject.java:422)\nat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1671)\nat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2038)\n\nat org.apache.hadoop.ipc.Client.call(Client.java:1468)\nat org.apache.hadoop.ipc.Client.call(Client.java:1399)\nat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)\nat com.sun.proxy.$Proxy11.updateBlockForPipeline(Unknown Source)\nat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.updateBlockForPipeline(ClientNamenodeProtocolTranslatorPB.java:877)\nat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\nat java.lang.reflect.Method.invoke(Method.java:497)\nat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)\nat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)\nat com.sun.proxy.$Proxy12.updateBlockForPipeline(Unknown Source)\nat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1278)\nat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:1016)\nat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:560)\n2015-08-14 00:46:44,978 ERROR org.apache.hadoop.hdfs.DFSClient: Failed to close inode 709042\norg.apache.hadoop.ipc.RemoteException(java.io.IOException): BP-322804774-10.13.54.1-1412684451669:blk_1074256920_516292 does not exist or is not under Constructionnull\nat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkUCBlock(FSNamesystem.java:7027)\nat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.updateBlockForPipeline(FSNamesystem.java:7094)\nat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.updateBlockForPipeline(NameNodeRpcServer.java:748)\nat org.apache.hadoop.hdfs.server.namenode.AuthorizationProviderProxyClientProtocol.updateBlockForPipeline(AuthorizationProviderProxyClientProtocol.java:637)\nat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.updateBlockForPipeline(ClientNamenodeProtocolServerSideTranslatorPB.java:932)\nat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\nat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)\nat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1060)\nat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)\nat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2040)\nat java.security.AccessController.doPrivileged(Native Method)\nat javax.security.auth.Subject.doAs(Subject.java:422)\nat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1671)\nat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2038)\n\nat org.apache.hadoop.ipc.Client.call(Client.java:1468)\nat org.apache.hadoop.ipc.Client.call(Client.java:1399)\nat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)\nat com.sun.proxy.$Proxy11.updateBlockForPipeline(Unknown Source)\nat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.updateBlockForPipeline(ClientNamenodeProtocolTranslatorPB.java:877)\nat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\nat java.lang.reflect.Method.invoke(Method.java:497)\nat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)\nat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)\nat com.sun.proxy.$Proxy12.updateBlockForPipeline(Unknown Source)\nat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1278)\nat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:1016)\nat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:560)\n{code}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=fborchers","name":"fborchers","key":"fborchers","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=fborchers&avatarId=20231","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=fborchers&avatarId=20231","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=fborchers&avatarId=20231","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=fborchers&avatarId=20231"},"displayName":"Felix Borchers","active":true,"timeZone":"Europe/Berlin"},"created":"2015-08-14T09:27:44.598+0000","updated":"2015-08-14T09:27:44.598+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12819229/comment/14697395","id":"14697395","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"body":"The file /system/balancer.id seems to be deleted.  Could you grep /system/balancer.id from the NN log?\n\nAlso, are there other log messages between 2015-08-14 00:30:03,843 and 2015-08-14 00:30:04,000?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-08-14T17:09:26.663+0000","updated":"2015-08-14T17:09:26.663+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12819229/comment/14698672","id":"14698672","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=fborchers","name":"fborchers","key":"fborchers","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=fborchers&avatarId=20231","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=fborchers&avatarId=20231","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=fborchers&avatarId=20231","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=fborchers&avatarId=20231"},"displayName":"Felix Borchers","active":true,"timeZone":"Europe/Berlin"},"body":"grep /system/balancer.id hadoop-hdfs-namenode-devhmn02.rz.is.log.1\n\n{code}\n...\n2015-08-14 00:30:03,843 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /system/balancer.id. BP-322804774-10.13.54.1-1412684451669 blk_1074256920_516292{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-4db312aa-bc23-47dc-b768-52a2d72b09d3:NORMAL:10.13.53.30:50010|RBW], ReplicaUnderConstruction[[DISK]DS-c7db1b58-8e25-435f-8af8-08b6754c021c:NORMAL:10.13.53.16:50010|RBW], ReplicaUnderConstruction[[DISK]DS-4457ae11-7684-4187-b4ad-56466d79fba2:NORMAL:10.13.53.19:50010|RBW]]}\n2015-08-14 00:30:03,958 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /system/balancer.id for DFSClient_NONMAPREDUCE_-1841368225_1\n2015-08-14 00:30:03,986 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /system/balancer.id. BP-322804774-10.13.54.1-1412684451669 blk_1074256921_516293{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-8f3d8860-b977-4b7b-b681-d25c112ad1f3:NORMAL:10.13.53.14:50010|RBW], ReplicaUnderConstruction[[DISK]DS-abb5362f-6d29-478f-a678-53f09c096871:NORMAL:10.13.53.12:50010|RBW], ReplicaUnderConstruction[[DISK]DS-b02f3ebc-955e-4e11-82df-dc51278dc06f:NORMAL:10.13.53.17:50010|RBW]]}\n2015-08-14 00:30:04,002 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /system/balancer.id for DFSClient_NONMAPREDUCE_-1841368225_1\n2015-08-14 00:46:44,975 WARN org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:hdfs (auth:SIMPLE) cause:org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException: No lease on /system/balancer.id (inode 709043): File does not exist. Holder DFSClient_NONMAPREDUCE_-1841368225_1 does not have any open files.\n2015-08-14 00:46:44,975 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 8020, call org.apache.hadoop.hdfs.protocol.ClientProtocol.complete from 10.13.52.1:58633 Call#220 Retry#0: org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException: No lease on /system/balancer.id (inode 709043): File does not exist. Holder DFSClient_NONMAPREDUCE_-1841368225_1 does not have any open files.\n...\n{code}\n\nThe LogMessages are between the two timestamps are:\n{code}\n2015-08-14 00:30:03,843 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /system/balancer.id. BP-322804774-10.13.54.1-1412684451669 blk_1074256920_516292{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-4db312aa-bc23-47dc-b768-52a2d72b09d3:NORMAL:10.13.53.30:50010|RBW], ReplicaUnderConstruction[[DISK]DS-c7db1b58-8e25-435f-8af8-08b6754c021c:NORMAL:10.13.53.16:50010|RBW], ReplicaUnderConstruction[[DISK]DS-4457ae11-7684-4187-b4ad-56466d79fba2:NORMAL:10.13.53.19:50010|RBW]]}\n2015-08-14 00:30:03,958 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /system/balancer.id for DFSClient_NONMAPREDUCE_-1841368225_1\n2015-08-14 00:30:03,986 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /system/balancer.id. BP-322804774-10.13.54.1-1412684451669 blk_1074256921_516293{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-8f3d8860-b977-4b7b-b681-d25c112ad1f3:NORMAL:10.13.53.14:50010|RBW], ReplicaUnderConstruction[[DISK]DS-abb5362f-6d29-478f-a678-53f09c096871:NORMAL:10.13.53.12:50010|RBW], ReplicaUnderConstruction[[DISK]DS-b02f3ebc-955e-4e11-82df-dc51278dc06f:NORMAL:10.13.53.17:50010|RBW]]}\n2015-08-14 00:30:04,000 INFO BlockStateChange: BLOCK* addBlock: block blk_1074256920_516292 on node 10.13.53.16:50010 size 134217728 does not belong to any file\n2015-08-14 00:30:04,000 INFO BlockStateChange: BLOCK* InvalidateBlocks: add blk_1074256920_516292 to 10.13.53.16:50010\n2015-08-14 00:30:04,000 INFO BlockStateChange: BLOCK* BlockManager: ask 10.13.53.16:50010 to delete [blk_1074256920_516292]\n2015-08-14 00:30:04,000 INFO BlockStateChange: BLOCK* BlockManager: ask 10.13.53.14:50010 to delete [blk_1074256910_516282]\n2015-08-14 00:30:04,002 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /system/balancer.id for DFSClient_NONMAPREDUCE_-1841368225_1\n2015-08-14 00:30:04,213 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.13.53.14:50010 is added to blk_1074256517_515889 size 9460\n2015-08-14 00:30:04,214 INFO BlockStateChange: BLOCK* InvalidateBlocks: add blk_1074256517_515889 to 10.13.53.30:50010\n2015-08-14 00:30:04,214 INFO BlockStateChange: BLOCK* chooseExcessReplicates: ([DISK]DS-4db312aa-bc23-47dc-b768-52a2d72b09d3:NORMAL:10.13.53.30:50010, blk_1074256517_515889) is added to invalidated blocks set\n{code}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=fborchers","name":"fborchers","key":"fborchers","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=fborchers&avatarId=20231","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=fborchers&avatarId=20231","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=fborchers&avatarId=20231","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=fborchers&avatarId=20231"},"displayName":"Felix Borchers","active":true,"timeZone":"Europe/Berlin"},"created":"2015-08-16T13:52:36.116+0000","updated":"2015-08-16T13:52:36.116+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12819229/comment/14986922","id":"14986922","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xyao","name":"xyao","key":"xyao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xiaoyu Yao","active":true,"timeZone":"America/Los_Angeles"},"body":"[~fborchers], do you have namenode HA setup? If yes, does it still repro when you explicitly specify active NN as follows?\n{code}\nhdfs balancer -fs http://activeNN:8020 -threshold 5\n{code}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xyao","name":"xyao","key":"xyao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xiaoyu Yao","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-11-03T08:41:44.603+0000","updated":"2015-11-03T08:41:44.603+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12819229/comment/14986927","id":"14986927","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=Alexandre+LINTE","name":"Alexandre LINTE","key":"alexandre linte","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"LINTE","active":true,"timeZone":"Etc/UTC"},"body":"No more mistakes for me with secure hadoop 2.7.1 and namenode HA settings for balancer.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=Alexandre+LINTE","name":"Alexandre LINTE","key":"alexandre linte","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"LINTE","active":true,"timeZone":"Etc/UTC"},"created":"2015-11-03T08:45:15.885+0000","updated":"2015-11-03T08:45:15.885+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12819229/comment/14986929","id":"14986929","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xyao","name":"xyao","key":"xyao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xiaoyu Yao","active":true,"timeZone":"America/Los_Angeles"},"body":"[~Alexandre LINTE], thanks for the confirmation!. This one can be resolved as a dup of HDFS-9364 [~szetszwo] is working on.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xyao","name":"xyao","key":"xyao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xiaoyu Yao","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-11-03T08:49:21.048+0000","updated":"2015-11-03T08:49:21.048+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12819229/comment/14986930","id":"14986930","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xyao","name":"xyao","key":"xyao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xiaoyu Yao","active":true,"timeZone":"America/Los_Angeles"},"body":"It should be HDFS-9365. I can't edit my previous comments after it is posted. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xyao","name":"xyao","key":"xyao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Xiaoyu Yao","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-11-03T08:52:10.192+0000","updated":"2015-11-03T08:52:10.192+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12819229/comment/15435064","id":"15435064","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=max_datapath","name":"max_datapath","key":"max_datapath","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Max Schmidt","active":true,"timeZone":"Europe/Berlin"},"body":"I am still facing this issue on my namenode (just happened once while creating a file with a java client), from my namenode.log:\n\n{code}\njava.io.IOException: BP-1876130894-10.5.0.4-1469019082320:blk_1073787208_63449 does not exist or is not under Constructionnull\n        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkUCBlock(FSNamesystem.java:6238)\n        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.updateBlockForPipeline(FSNamesystem.java:6305)\n        at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.updateBlockForPipeline(NameNodeRpcServer.java:804)\n        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.updateBlockForPipeline(ClientNamenodeProtocolServerSideTranslatorPB.java:955)\n        at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n        at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)\n        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:969)\n        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)\n        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:422)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)\n        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)\n{code}\n\nIam using hadoop 2.7.1 with the corresponding java libraries.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=max_datapath","name":"max_datapath","key":"max_datapath","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Max Schmidt","active":true,"timeZone":"Europe/Berlin"},"created":"2016-08-24T14:55:50.261+0000","updated":"2016-08-24T14:55:50.261+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12819229/comment/15435275","id":"15435275","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"body":"Then your cluster probably doesn't have HDFS-9365 which was committed to 2.7.3.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-08-24T16:51:00.484+0000","updated":"2016-08-24T16:51:00.484+0000"}],"maxResults":10,"total":10,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-8093/votes","votes":1,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i2cyi7:"}}