{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12527380","self":"https://issues.apache.org/jira/rest/api/2/issue/12527380","key":"HDFS-2452","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12314241","id":"12314241","description":"","name":"0.22.0","archived":false,"released":true,"releaseDate":"2011-12-10"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12315571","id":"12315571","description":"","name":"0.23.0","archived":false,"released":true,"releaseDate":"2011-11-11"}],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2011-10-17T02:14:17.574+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Wed Oct 26 20:55:02 UTC 2011","customfield_12310420":"87551","customfield_12312320":null,"customfield_12310222":"10002_*:*_1_*:*_85220483_*|*_1_*:*_2_*:*_265127403_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2011-10-21T02:50:06.501+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-2452/watchers","watchCount":8,"isWatching":false},"created":"2011-10-17T01:30:58.725+0000","customfield_12310192":null,"customfield_12310191":[{"self":"https://issues.apache.org/jira/rest/api/2/customFieldOption/10343","value":"Reviewed","id":"10343"}],"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"12.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12314241","id":"12314241","description":"","name":"0.22.0","archived":false,"released":true,"releaseDate":"2011-12-10"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12315571","id":"12315571","description":"","name":"0.23.0","archived":false,"released":true,"releaseDate":"2011-11-11"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12320353","id":"12320353","description":"hadoop-2.0.0-alpha release","name":"2.0.0-alpha","archived":false,"released":true,"releaseDate":"2012-05-23"}],"issuelinks":[{"id":"12455494","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12455494","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"12933321","key":"HDFS-9684","self":"https://issues.apache.org/jira/rest/api/2/issue/12933321","fields":{"summary":"DataNode stopped sending heartbeat after getting OutOfMemoryError form DataTransfer thread.","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/1","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/blocker.svg","name":"Blocker","id":"1"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12364020","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12364020","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"12631148","key":"HDFS-4475","self":"https://issues.apache.org/jira/rest/api/2/issue/12631148","fields":{"summary":"OutOfMemory by BPServiceActor.offerService() takes down DataNode","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12345601","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12345601","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"inwardIssue":{"id":"12532095","key":"HDFS-2573","self":"https://issues.apache.org/jira/rest/api/2/issue/12532095","fields":{"summary":"TestFiDataXceiverServer is failing, not testing OOME","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2016-01-26T15:32:27.669+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12312927","id":"12312927","name":"datanode"}],"timeoriginalestimate":null,"description":"OutOfMemoryError brings down DataNode, when DataXceiverServer tries to spawn a new data transfer thread.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12500308","id":"12500308","filename":"HDFS-2452.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-10-22T06:32:58.997+0000","size":9157,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12500308/HDFS-2452.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12500291","id":"12500291","filename":"HDFS-2452.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cos","name":"cos","key":"cos","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cos&avatarId=16741","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cos&avatarId=16741","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cos&avatarId=16741","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cos&avatarId=16741"},"displayName":"Konstantin Boudnik","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-10-22T04:41:18.264+0000","size":8222,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12500291/HDFS-2452.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12499965","id":"12499965","filename":"HDFS-2452-22branch_with-around_.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cos","name":"cos","key":"cos","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cos&avatarId=16741","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cos&avatarId=16741","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cos&avatarId=16741","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cos&avatarId=16741"},"displayName":"Konstantin Boudnik","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-10-20T22:23:57.413+0000","size":8071,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12499965/HDFS-2452-22branch_with-around_.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12499963","id":"12499963","filename":"HDFS-2452-22branch_with-around_.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cos","name":"cos","key":"cos","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cos&avatarId=16741","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cos&avatarId=16741","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cos&avatarId=16741","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cos&avatarId=16741"},"displayName":"Konstantin Boudnik","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-10-20T22:20:22.231+0000","size":2661,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12499963/HDFS-2452-22branch_with-around_.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12499440","id":"12499440","filename":"HDFS-2452-22branch.1.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-10-17T21:07:08.640+0000","size":5595,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12499440/HDFS-2452-22branch.1.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12499915","id":"12499915","filename":"HDFS-2452-22Branch.2.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-10-20T19:42:22.034+0000","size":8088,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12499915/HDFS-2452-22Branch.2.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12499807","id":"12499807","filename":"HDFS-2452-22branch.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cos","name":"cos","key":"cos","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cos&avatarId=16741","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cos&avatarId=16741","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cos&avatarId=16741","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cos&avatarId=16741"},"displayName":"Konstantin Boudnik","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-10-20T04:11:54.559+0000","size":7413,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12499807/HDFS-2452-22branch.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12499793","id":"12499793","filename":"HDFS-2452-22branch.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cos","name":"cos","key":"cos","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cos&avatarId=16741","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cos&avatarId=16741","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cos&avatarId=16741","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cos&avatarId=16741"},"displayName":"Konstantin Boudnik","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-10-20T00:53:14.413+0000","size":7581,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12499793/HDFS-2452-22branch.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12499624","id":"12499624","filename":"HDFS-2452-22branch.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cos","name":"cos","key":"cos","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cos&avatarId=16741","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cos&avatarId=16741","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cos&avatarId=16741","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cos&avatarId=16741"},"displayName":"Konstantin Boudnik","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-10-19T02:00:28.632+0000","size":5794,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12499624/HDFS-2452-22branch.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12499412","id":"12499412","filename":"HDFS-2452-22branch.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-10-17T18:36:48.972+0000","size":6147,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12499412/HDFS-2452-22branch.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12500305","id":"12500305","filename":"HDFS-2452-Trunk.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-10-22T06:03:46.706+0000","size":9143,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12500305/HDFS-2452-Trunk.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12500294","id":"12500294","filename":"HDFS-2452-Trunk-src-fix.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-10-22T05:05:50.350+0000","size":3316,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12500294/HDFS-2452-Trunk-src-fix.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"52922","customfield_12312823":null,"summary":"OutOfMemoryError in DataXceiverServer takes down the DataNode","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12527380/comment/13128568","id":"13128568","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"body":"I carried out a high-load test on a cluster running Hadoop 0.22. Because of the high load several DataNodes ran out of memory and died. The reason is that OutOfMemoryError occurred when DataXceiverServer.run() was starting a new DataXceiver, which is treated as a fatal error by current implementation.\n{code}\n2011-10-11 17:56:07,228 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration( ... ):\nDataXceiveServer: Exiting due to:java.lang.OutOfMemoryError: unable to create new native thread\n        at java.lang.Thread.start0(Native Method)\n        at java.lang.Thread.start(Thread.java:640)\n        at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:137)\n        at java.lang.Thread.run(Thread.java:662)\n{code}\nIn order to reproduce it one can write a unit test, which mocks {{DataXceiver.start()}} method to throw OutOfMemoryError.\nI think DataXceiverServer should have a special catch statement for OutOfMemoryError, where it goes to a sleep for say 60 seconds and then go back to the main loop.\nA word of caution here, as {{DataXceiver()}} constructor puts the socket into {{childSockets}}, and if the error happens in start() there will be nobody to remove it. It think it is better to move line {{dataXceiverServer.childSockets.put(s, s);}} from the {{DataXceiver()}} constructor into the {{DataXceiver.run()}} method.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-10-17T01:54:36.532+0000","updated":"2011-10-17T01:54:36.532+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12527380/comment/13128572","id":"13128572","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"body":"I believe the same error exists in trunk.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-10-17T01:58:16.987+0000","updated":"2011-10-17T01:58:16.987+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12527380/comment/13128577","id":"13128577","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"body":"Yes , currently we are handling only SocketTimeOutException and IOExceptions\n\n{code}\n} catch (SocketTimeoutException ignored) {\n        // wake up to see if should continue to run\n      } catch (IOException ie) {\n        LOG.warn(datanode.dnRegistration + \":DataXceiveServer: \" \n                                + StringUtils.stringifyException(ie));\n      } catch (Throwable te) {\n        LOG.error(datanode.dnRegistration + \":DataXceiveServer: Exiting due to:\" \n                                 + StringUtils.stringifyException(te));\n        datanode.shouldRun = false;\n      }\n{code}\n\nthanks\nUma","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-10-17T02:14:17.574+0000","updated":"2011-10-17T02:14:17.574+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12527380/comment/13128594","id":"13128594","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"body":"I just verified trunk code and security barnch code. There we handled one more case for AsynchronousCloseException.\n\n{code}\n} catch (SocketTimeoutException ignored) {\n        // wake up to see if should continue to run\n      } catch (AsynchronousCloseException ace) {\n        // another thread closed our listener socket - that's expected during shutdown,\n        // but not in other circumstances\n        if (datanode.shouldRun) {\n          LOG.warn(datanode.getMachineName() + \":DataXceiverServer: \", ace);\n        }\n      } catch (IOException ie) {\n        LOG.warn(datanode.getMachineName() + \":DataXceiverServer: \", ie);\n      } catch (Throwable te) {\n        LOG.error(datanode.getMachineName()\n            + \":DataXceiverServer: Exiting due to: \", te);\n        datanode.shouldRun = false;\n      }\n{code}\n\n\nThis particular AsynchronousCloseException is missed in 22 branch. Is it intentional for 22?\n\nIn security branch, handling is different \n{code}\ncatch (AsynchronousCloseException ace) {\n          LOG.warn(datanode.dnRegistration + \":DataXceiveServer:\"\n                  + StringUtils.stringifyException(ace));\n          datanode.shouldRun = false;\n      } \n{code}\n here setting datanode.shouldRun = false. So, here it is just for logging?\n\nI am confusing about this exception handling here. why it is different for branch by branch?\n\n\nthanks\nUma\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-10-17T02:28:25.004+0000","updated":"2011-10-17T02:28:25.004+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12527380/comment/13128636","id":"13128636","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cos","name":"cos","key":"cos","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cos&avatarId=16741","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cos&avatarId=16741","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cos&avatarId=16741","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cos&avatarId=16741"},"displayName":"Konstantin Boudnik","active":true,"timeZone":"America/Los_Angeles"},"body":"I think the main reason for different handling is how patches are being committed to active branches ;(","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cos","name":"cos","key":"cos","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cos&avatarId=16741","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cos&avatarId=16741","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cos&avatarId=16741","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cos&avatarId=16741"},"displayName":"Konstantin Boudnik","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-10-17T04:07:53.926+0000","updated":"2011-10-17T04:07:53.926+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12527380/comment/13128652","id":"13128652","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks Cos for taking a look.\nOk then, shall we make the changes same as trunk?\n\n@ Konstantin Shvachko: Before going, one more question is , we made the maxXeivercount check after starting the thread.\n{code}\n// Make sure the xceiver count is not exceeded\n        int curXceiverCount = datanode.getXceiverCount();\n        if (curXceiverCount > dataXceiverServer.maxXceiverCount) {\n          throw new IOException(\"xceiverCount \" + curXceiverCount\n                                + \" exceeds the limit of concurrent xcievers \"\n                                + dataXceiverServer.maxXceiverCount);\n        }\n{code}\n  in your case, whether system is not able to handle configured thread count itself?\n\nAnd also, can we move this check before starting the new thread?\n\nThanks\nUma\n ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-10-17T04:38:06.002+0000","updated":"2011-10-17T04:38:06.002+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12527380/comment/13128663","id":"13128663","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=praveenkjvs","name":"praveenkjvs","key":"praveenkjvs","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10438","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10438","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10438","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10438"},"displayName":"Praveen Kumar K J V S","active":true,"timeZone":"Asia/Kolkata"},"body":"I think the check has to be done before starting the thread. Also in DataNode.java, the method getXceiverCount() is using ThreadGroup.activeCount() which only returns the estimate of number of threads running in a thread-group. This information has to be used for only informational purpose (look at the java docs), but we are using for controlling the state of the Data-Node. \n\nMy suggestion would be to use a variable to track the number of active threads or better a thread pool. Even better if we are able to dynamically control the value of this variable, so that we get max throughput from the data-node.\n\nThanks,\nPraveen Kumar K J V S","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=praveenkjvs","name":"praveenkjvs","key":"praveenkjvs","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10438","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10438","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10438","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10438"},"displayName":"Praveen Kumar K J V S","active":true,"timeZone":"Asia/Kolkata"},"created":"2011-10-17T04:56:29.480+0000","updated":"2011-10-17T04:56:29.480+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12527380/comment/13129070","id":"13129070","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"body":"Let's fix one thing at a time.\n# AsynchronousCloseException handling was introduced to 0.23 in HDFS-2286. We can apply this patch to 0.22, but it is mostly a nuisance rather than a bug.\n# It could be better to check XceiverCount before starting the thread, but it should work fine as it is now, because the check is done before actually executing the command. Please file a separate jira on this if not filed already.\n# Dynamic control of DataNode resources is a good idea. Probably worth a separate jira too.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-10-17T18:38:10.564+0000","updated":"2011-10-17T18:38:10.564+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12527380/comment/13129075","id":"13129075","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"body":"Updated the patch (22branch) for Review!\n\nPatch contains: \n  1) handled the OutOfMemoryError \n  2) closed the sockets on IOExceptions\n  3) Handled AsynchronousCloseException , as trunk changes.\n  4) moved the childsockets.put to run method.\n\nOnce it is approved, i will upload for trunk!\n\n@Praveen\nYes, I too think that check should be before starting the new thread. I think we can handle it as part of other JIRA. \n\nThanks\nUma","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-10-17T18:44:04.382+0000","updated":"2011-10-17T18:44:04.382+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12527380/comment/13129083","id":"13129083","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"body":"{quote}\nAsynchronousCloseException handling was introduced to 0.23 in HDFS-2286. We can apply this patch to 0.22, but it is mostly a nuisance rather than a bug.\n{quote}\n Konstantin, sorry, I did not see your comment above. I included AsynchronousCloseException  also in this patch. You want me to remove? (or) it is ok for this now?\n ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-10-17T18:54:24.458+0000","updated":"2011-10-17T18:54:24.458+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12527380/comment/13129130","id":"13129130","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"body":"- Uma, yes let's split it into 2 patches: one for HDFS-2286. I'll commit it first, then this one. Otherwise things will get messy.\n- The fix looks good. A suggestion for better logging and commenting. In the comment you can say something like \"// DataNode can run out of memory if there is too many transfers. Log the event, sleep for 30 seconds, other transfers may complete be then.\"\nIn log message you can say something like LOG.warn(\"DataNode is out of memory. Will retry in 30 seconds.\", e);\n- For the test. You actually need to mock Daemon.start() method if possible. In your patch OutOfMemoryError comes from DataXceiver() constructor. In the exception I posted it is thrown in Thread.start().","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-10-17T20:06:38.048+0000","updated":"2011-10-17T20:06:38.048+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12527380/comment/13129137","id":"13129137","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cos","name":"cos","key":"cos","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cos&avatarId=16741","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cos&avatarId=16741","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cos&avatarId=16741","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cos&avatarId=16741"},"displayName":"Konstantin Boudnik","active":true,"timeZone":"America/Los_Angeles"},"body":"+1 on the splitting it.\nI would also suggest to pay attention to the formatting of the patch e.g. spaces before '{', etc.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cos","name":"cos","key":"cos","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cos&avatarId=16741","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cos&avatarId=16741","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cos&avatarId=16741","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cos&avatarId=16741"},"displayName":"Konstantin Boudnik","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-10-17T20:17:48.927+0000","updated":"2011-10-17T20:17:48.927+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12527380/comment/13129158","id":"13129158","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks a lot for the review!\n\nI have updated the patch for HDFS-2286. Can you please take a look. So, that i can rebase this patch again.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-10-17T20:41:04.151+0000","updated":"2011-10-17T20:41:04.151+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12527380/comment/13129204","id":"13129204","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"body":"{quote}The fix looks good. A suggestion for better logging and commenting. In the comment you can say something like \"// DataNode can run out of memory if there is too many transfers. Log the event, sleep for 30 seconds, other transfers may complete be then.\"\n{quote}\nfixed\n{quote}\nIn log message you can say something like LOG.warn(\"DataNode is out of memory. Will retry in 30 seconds.\", e);\n{quote}\nDone\n{quote}\nFor the test. You actually need to mock Daemon.start() method if possible. In your patch OutOfMemoryError comes from DataXceiver() constructor. In the exception I posted it is thrown in Thread.start().\n{quote}\nI tried to mock start. But i could not do it because the thread is just local referance. So i couldnot inject mock obj here. So, to replicate the scenario, i throwed the OoutOfMemoryError from getConf.\n\nThanks\nUma","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-10-17T21:13:10.851+0000","updated":"2011-10-17T21:13:10.851+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12527380/comment/13129220","id":"13129220","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"-1 overall.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12499440/HDFS-2452-22branch.1.patch\n  against trunk revision .\n\n    +1 @author.  The patch does not contain any @author tags.\n\n    +1 tests included.  The patch appears to include 3 new or modified tests.\n\n    -1 patch.  The patch command could not apply the patch.\n\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/1371//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2011-10-17T21:23:43.905+0000","updated":"2011-10-17T21:23:43.905+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12527380/comment/13129407","id":"13129407","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"-1 overall.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12499440/HDFS-2452-22branch.1.patch\n  against trunk revision .\n\n    +1 @author.  The patch does not contain any @author tags.\n\n    +1 tests included.  The patch appears to include 3 new or modified tests.\n\n    -1 patch.  The patch command could not apply the patch.\n\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/1375//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2011-10-18T01:43:59.863+0000","updated":"2011-10-18T01:43:59.863+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12527380/comment/13129439","id":"13129439","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"body":"Can you mock datanode.getXceiverCount() to throw OutOfMemoryError on the second call. That way the error will come from DataXceiver.run(). Also forgot to mention last time you do not need to sleep(30sec) in the test. Checking alive once should be fine.\nA javaDoc for the test description would be good to have.\nPlease don't do Patch Available for 0.22 pathces. This only triggers Jenkins build failures. We will have to run test and test-patch locally anyway before committing.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-10-18T02:45:49.578+0000","updated":"2011-10-18T02:45:49.578+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12527380/comment/13129464","id":"13129464","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cos","name":"cos","key":"cos","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cos&avatarId=16741","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cos&avatarId=16741","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cos&avatarId=16741","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cos&avatarId=16741"},"displayName":"Konstantin Boudnik","active":true,"timeZone":"America/Los_Angeles"},"body":"bq. Also forgot to mention last time you do not need to sleep(30sec) in the test. Checking alive once should be fine.\nWhich makes the test to be compatible with unit test defs (e.g. running under 10 seconds)","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cos","name":"cos","key":"cos","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cos&avatarId=16741","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cos&avatarId=16741","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cos&avatarId=16741","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cos&avatarId=16741"},"displayName":"Konstantin Boudnik","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-10-18T03:57:05.612+0000","updated":"2011-10-18T03:57:05.612+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12527380/comment/13129486","id":"13129486","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks a lot for taking a look.\nOk fine...I thought to test exact case even after one round retry.\nI will not remove complete wait there, because Test may complete before exactly spawning the new thread. So, i am planning to put wait of 100ms.\n\n{quote}\nCan you mock datanode.getXceiverCount() to throw OutOfMemoryError on the second call. That way the error will come from DataXceiver.run()\n{quote}\n Here the problem is, DataXceiver thread already handled the Throwable there. So, the exception will be handled silently and log the error. So, it will not reach to our exception block.\n\n{code}\n catch (Throwable t) {\n      LOG.error(datanode.dnRegistration + \":DataXceiver, at \" +\n        s.toString(), t);\n    }\n{code}\n\nThanks\nUma","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-10-18T04:57:49.653+0000","updated":"2011-10-18T04:57:49.653+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12527380/comment/13129876","id":"13129876","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"body":"Sleeping an arbitrary # of seconds is not a good solution, as it makes tests flaky, passing on some nodes and failing on other because of different environments. If you need to wait, then wait for a specific event (thread started in the case) rather than relying on passing time.\n\n> DataXceiver thread already handled the Throwable there.\n\nYou are right, mocking getXceiverCount() doesn't work. May be Cos can help with that.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-10-18T17:28:01.990+0000","updated":"2011-10-18T17:28:01.990+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12527380/comment/13130015","id":"13130015","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cos","name":"cos","key":"cos","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cos&avatarId=16741","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cos&avatarId=16741","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cos&avatarId=16741","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cos&avatarId=16741"},"displayName":"Konstantin Boudnik","active":true,"timeZone":"America/Los_Angeles"},"body":"We aren't running auto-validation of .22 patches anyway.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cos","name":"cos","key":"cos","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cos&avatarId=16741","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cos&avatarId=16741","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cos&avatarId=16741","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cos&avatarId=16741"},"displayName":"Konstantin Boudnik","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-10-18T20:54:17.166+0000","updated":"2011-10-18T20:54:17.166+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12527380/comment/13130311","id":"13130311","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cos","name":"cos","key":"cos","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cos&avatarId=16741","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cos&avatarId=16741","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cos&avatarId=16741","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cos&avatarId=16741"},"displayName":"Konstantin Boudnik","active":true,"timeZone":"America/Los_Angeles"},"body":"With respect to the case I think getting rid of Mockito.doThrow and spying on {{DataXceiverServer}} should do the trick.\nSo, something along the lines \n\n{code}\n...\n    DataNode dn = Mockito.mock(DataNode.class);\n    DataXceiverServer server = new DataXceiverServer(sock, new Configuration(),\n        dn);\n    DataXceiverServer spyServer = spy(server);\n    doThrow(new OutOfMemoryError(\"Faulting...\")).when(spyServer).run();\n    dn.shouldRun = true;\n...\n{code}\nwould work, I believe. Fixed patch version is attached.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cos","name":"cos","key":"cos","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cos&avatarId=16741","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cos&avatarId=16741","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cos&avatarId=16741","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cos&avatarId=16741"},"displayName":"Konstantin Boudnik","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-10-19T02:00:28.734+0000","updated":"2011-10-19T02:00:28.734+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12527380/comment/13130321","id":"13130321","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi Konstantin,\nThanks a lot for the review!\n\n{quote}\nSleeping an arbitrary # of seconds is not a good solution, as it makes tests flaky, passing on some nodes and failing on other because of different environments. If you need to wait, then wait for a specific event (thread started in the case) rather than relying on passing time.\n{quote}\nWe can set max time for test is 30secs (@Test(timeout=30000)). \nIn testcase, I will close the sockets immediately when we get the OutOfMemoryError. Here i will use the CounDownLatch(1) in my stubbed Socket close method to latch.countDown(). So, main thread (test) will do latch.await(). After this i can assert for thread alive or not.\nIf you like this approach, i will go ahead with it.\n\n{quote}\nYou are right, mocking getXceiverCount() doesn't work. May be Cos can help with that.\n{quote}\nCos, do you have any other suggestion here?\n\nThanks\nUma\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-10-19T02:25:47.404+0000","updated":"2011-10-19T02:25:47.404+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12527380/comment/13130323","id":"13130323","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cos","name":"cos","key":"cos","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cos&avatarId=16741","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cos&avatarId=16741","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cos&avatarId=16741","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cos&avatarId=16741"},"displayName":"Konstantin Boudnik","active":true,"timeZone":"America/Los_Angeles"},"body":"Did you see [my comment| https://issues.apache.org/jira/browse/HDFS-2452?focusedCommentId=13130311&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13130311] and the new patch?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cos","name":"cos","key":"cos","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cos&avatarId=16741","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cos&avatarId=16741","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cos&avatarId=16741","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cos&avatarId=16741"},"displayName":"Konstantin Boudnik","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-10-19T02:30:21.686+0000","updated":"2011-10-19T02:30:21.686+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12527380/comment/13130328","id":"13130328","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"body":"Hey Cos,\n I just reviewed the patch. The problem is not for mocking the DataXciverServer#run method.\n{code}\n DataXceiverServer spyServer = spy(server);\n    doThrow(new OutOfMemoryError(\"Faulting...\")).when(spyServer).run();\n{code}\n\n We need to mock DataXceiver#run method.\nModified TestCase doesn't test the expected functionality. \nThe problem to mock DataXceiver is , we can not get the reference of DataXceiver out. \nIn real case we are getting the OutOfMemoryError from thread#start() native method before reaching run method itself.\nThat is the reason i trowed the exception from DataXceiver  constructor ( from dn.getConf()). Because we could not mock the start method of thread.\n\nTest may pass because, main thread(test main) can complete before exactly completing the run method of DataXceiverServer#run. For solving this, i suggested one approach in my above comment.\n\n\nThanks\nUma","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-10-19T03:09:26.125+0000","updated":"2011-10-19T03:09:26.125+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12527380/comment/13130333","id":"13130333","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cos","name":"cos","key":"cos","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cos&avatarId=16741","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cos&avatarId=16741","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cos&avatarId=16741","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cos&avatarId=16741"},"displayName":"Konstantin Boudnik","active":true,"timeZone":"America/Los_Angeles"},"body":"Right, I agree - there's no way in the current implementation to mock this internal instance of DataXceiver.\nI see how it can be done using fault injection with ease, but I am not sure if you guys want to consider such approach.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cos","name":"cos","key":"cos","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cos&avatarId=16741","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cos&avatarId=16741","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cos&avatarId=16741","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cos&avatarId=16741"},"displayName":"Konstantin Boudnik","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-10-19T03:34:58.302+0000","updated":"2011-10-19T03:34:58.302+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12527380/comment/13131024","id":"13131024","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"body":"> Here i will use the CounDownLatch(1) in my stubbed Socket\n\nUma, this sounds like a good plan.\n\n> I see how it can be done using fault injection with ease\n\nCos, good idea, why not.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-10-19T21:35:01.396+0000","updated":"2011-10-19T21:35:01.396+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12527380/comment/13131027","id":"13131027","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"body":"Are the 2 paths above mutually exclusive?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-10-19T21:36:09.899+0000","updated":"2011-10-19T21:36:09.899+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12527380/comment/13131239","id":"13131239","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cos","name":"cos","key":"cos","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cos&avatarId=16741","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cos&avatarId=16741","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cos&avatarId=16741","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cos&avatarId=16741"},"displayName":"Konstantin Boudnik","active":true,"timeZone":"America/Los_Angeles"},"body":"Here's fault inject test (with aspects and whatnot) which guarantees that OOM will happen first thing when DataXceiver#run() is executed.\n\nUma, please do whatever you need with latches to achieve desired result in the test.\nRunning fault injection tests is easy. Something like\n{{ant -Dtestcase=TestFiDataXceiverServer run-test-hdfs-fault-inject -Dtest.output=true}} should help.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cos","name":"cos","key":"cos","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cos&avatarId=16741","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cos&avatarId=16741","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cos&avatarId=16741","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cos&avatarId=16741"},"displayName":"Konstantin Boudnik","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-10-20T00:53:14.498+0000","updated":"2011-10-20T00:53:14.498+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12527380/comment/13131352","id":"13131352","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cos","name":"cos","key":"cos","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cos&avatarId=16741","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cos&avatarId=16741","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cos&avatarId=16741","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cos&avatarId=16741"},"displayName":"Konstantin Boudnik","active":true,"timeZone":"America/Los_Angeles"},"body":"a tiny oops in the patch.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cos","name":"cos","key":"cos","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cos&avatarId=16741","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cos&avatarId=16741","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cos&avatarId=16741","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cos&avatarId=16741"},"displayName":"Konstantin Boudnik","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-10-20T04:11:54.661+0000","updated":"2011-10-20T04:11:54.661+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12527380/comment/13131964","id":"13131964","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"body":"Here is a patch with CountDownLatch.\n\nOther changes in previous patch is:\n \n1) fixed one null pointer, which is caused because of not mocking the getConf on DN.\n Added the mock in test. \n \n2) DataXceiverAspects file apache header was not a header comment\n    {code}\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n{code}\nupdated it.\n\n3) System.setProperty(\"fi.enabledOOM\", null); also changed to System.setProperty(\"fi.enabledOOM\", \"false\");\n   because can not set null in props.\n   Also changed the check in aspectj file to check with true.\n\n\nTo be frank, i am not familiar with aspectJ programs. \nSo, requesting Cos to review once with my changes. One more thing is when i ran the tests with your command, i don't see any aspects injected in to DataXceiver.class and not running test. Not sure my compilations has the problems with aspectj. Since this is urgent for some of the load tests running by Konstantin, i updated the patch here.\n\nKonstantin, can you check the patch and give the test run once.\n\n\nThanks,\nUma","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-10-20T19:59:11.292+0000","updated":"2011-10-20T19:59:11.292+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12527380/comment/13131976","id":"13131976","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cos","name":"cos","key":"cos","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cos&avatarId=16741","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cos&avatarId=16741","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cos&avatarId=16741","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cos&avatarId=16741"},"displayName":"Konstantin Boudnik","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks for fixing aspect code Uma - I was doing it in a hassle last night and did a suboptimal job apparently.\nAspects should be injected in 'injectfaults' target which is called by the test target. You don't need to have anything else to make it happen: all components of AOP framework are in place by default. \n\nI have applied your patch and ran the test and I see that injected code is working as expected. I see many OOM errors thrown from a huge number of the DataXceiver threads like this\n{noformat}\n    [junit] Exception in thread \"org.apache.hadoop.hdfs.server.datanode.DataXceiver@7e3feb83\" java.lang.OutOfMemoryError: Pretend there's no more memory\n    [junit]     at org.apache.hadoop.hdfs.server.datanode.DataXceiverAspects.ajc$before$org_apache_hadoop_hdfs_server_datanode_DataXceiverAspects$1$1a38ea(DataXceiverAspects.aj:36)    [junit]     at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:120)    [junit]     at java.lang.Thread.run(Thread.java:680)    \n    [junit] Exception in thread \"org.apache.hadoop.hdfs.server.datanode.DataXceiver@29b18dc0\" java.lang.OutOfMemoryError: Pretend there's no more memory\n    [junit]     at org.apache.hadoop.hdfs.server.datanode.DataXceiverAspects.ajc$before$org_apache_hadoop_hdfs_server_datanode_DataXceiverAspects$1$1a38ea(DataXceiverAspects.aj:36)    [junit]     at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:120)    [junit]     at java.lang.Thread.run(Thread.java:680)\n{noformat}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cos","name":"cos","key":"cos","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cos&avatarId=16741","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cos&avatarId=16741","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cos&avatarId=16741","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cos&avatarId=16741"},"displayName":"Konstantin Boudnik","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-10-20T20:10:03.892+0000","updated":"2011-10-20T20:10:03.892+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12527380/comment/13131978","id":"13131978","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cos","name":"cos","key":"cos","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cos&avatarId=16741","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cos&avatarId=16741","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cos&avatarId=16741","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cos&avatarId=16741"},"displayName":"Konstantin Boudnik","active":true,"timeZone":"America/Los_Angeles"},"body":"I have ran the test twice: it passed once and crashed the second time.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cos","name":"cos","key":"cos","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cos&avatarId=16741","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cos&avatarId=16741","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cos&avatarId=16741","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cos&avatarId=16741"},"displayName":"Konstantin Boudnik","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-10-20T20:10:43.277+0000","updated":"2011-10-20T20:10:43.277+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12527380/comment/13131979","id":"13131979","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cos","name":"cos","key":"cos","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cos&avatarId=16741","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cos&avatarId=16741","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cos&avatarId=16741","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cos&avatarId=16741"},"displayName":"Konstantin Boudnik","active":true,"timeZone":"America/Los_Angeles"},"body":"And yes - patch looks good to me overall.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cos","name":"cos","key":"cos","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cos&avatarId=16741","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cos&avatarId=16741","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cos&avatarId=16741","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cos&avatarId=16741"},"displayName":"Konstantin Boudnik","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-10-20T20:12:23.468+0000","updated":"2011-10-20T20:12:23.468+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12527380/comment/13132059","id":"13132059","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"body":"I think test wont work as expected because, throwing exception from run will not get propagated to parent thread. Silently child threads will die.\nI am not sure,we can throw the exception before actually spawning the thread.\n\nI feel simple, the option would be from DataXceiver Constructor.\n\n\nThanks\nUma","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-10-20T21:26:46.886+0000","updated":"2011-10-20T21:26:46.886+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12527380/comment/13132067","id":"13132067","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"body":"Cos, do we have the option in aspectJ to throw the exception before invoking run. \nHere the expectation is that, injected exception should be propagated to DataXceiverServer try-catch block.\nThat will not happen with current case, t","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-10-20T21:34:04.392+0000","updated":"2011-10-20T21:34:04.392+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12527380/comment/13132113","id":"13132113","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cos","name":"cos","key":"cos","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cos&avatarId=16741","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cos&avatarId=16741","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cos&avatarId=16741","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cos&avatarId=16741"},"displayName":"Konstantin Boudnik","active":true,"timeZone":"America/Los_Angeles"},"body":"Uma, we can throw an exception instead of calling run() method. In this case before(...): advice has to be replaced with void around(...): one (see new patch).\n\nOr, doing this before invoking run() means that it should be happening in DataXceiverServer, right? They the patch needs to be slightly different and we need to instrument DataXceiverServer instead of DataXceiver. Sorry, I am confused.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cos","name":"cos","key":"cos","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cos&avatarId=16741","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cos&avatarId=16741","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cos&avatarId=16741","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cos&avatarId=16741"},"displayName":"Konstantin Boudnik","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-10-20T22:20:22.331+0000","updated":"2011-10-20T22:20:22.331+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12527380/comment/13132290","id":"13132290","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"body":"I ran the test several times. It is working fine now.\nI also ran the test target, which passed.\n+1 on the patch. Tanks Cos and Uma for working on this.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-10-21T02:42:26.072+0000","updated":"2011-10-21T02:42:26.072+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12527380/comment/13132291","id":"13132291","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cos","name":"cos","key":"cos","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cos&avatarId=16741","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cos&avatarId=16741","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cos&avatarId=16741","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cos&avatarId=16741"},"displayName":"Konstantin Boudnik","active":true,"timeZone":"America/Los_Angeles"},"body":"I have committed it to branch-0.22. Thanks Uma.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cos","name":"cos","key":"cos","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cos&avatarId=16741","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cos&avatarId=16741","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cos&avatarId=16741","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cos&avatarId=16741"},"displayName":"Konstantin Boudnik","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-10-21T02:50:06.579+0000","updated":"2011-10-21T02:50:06.579+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12527380/comment/13132673","id":"13132673","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"Integrated in Hadoop-Hdfs-22-branch #101 (See [https://builds.apache.org/job/Hadoop-Hdfs-22-branch/101/])\n    HDFS-2452. OutOfMemoryError in DataXceiverServer takes down the DataNode. Contributed by Uma Maheswara Rao.\n\ncos : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1187168\nFiles : \n* /hadoop/common/branches/branch-0.22/hdfs/CHANGES.txt\n* /hadoop/common/branches/branch-0.22/hdfs/src/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java\n* /hadoop/common/branches/branch-0.22/hdfs/src/java/org/apache/hadoop/hdfs/server/datanode/DataXceiverServer.java\n* /hadoop/common/branches/branch-0.22/hdfs/src/test/aop/org/apache/hadoop/hdfs/server/datanode/DataXceiverAspects.aj\n* /hadoop/common/branches/branch-0.22/hdfs/src/test/aop/org/apache/hadoop/hdfs/server/datanode/TestFiDataXceiverServer.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2011-10-21T13:48:18.313+0000","updated":"2011-10-21T13:48:18.313+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12527380/comment/13132717","id":"13132717","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi Cos,\n\n Looks that aspects not working reliably.Still it is throwing the error after spawning the DataXceiver thread. So, parent thread (DataXceiverServer) is not getting that exception.\n\n[junit]  at java.lang.Thread.run(Thread.java:662)\n    [junit] Exception in thread \"org.apache.hadoop.hdfs.server.datanode.DataXceiver@6e2335\" java.lang.OutOfMemoryError: Pretend there's no more memory\n    [junit]  at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run_aroundBody1$advice(DataXceiver.java:36)\n    [junit]  at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:1)\n    [junit]  at java.lang.Thread.run(Thread.java:662)\n    [junit] Exception in thread \"org.apache.hadoop.hdfs.server.datanode.DataXceiver@576165\" java.lang.OutOfMemoryError: Pretend there's no more memory\n    [junit]  at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run_aroundBody1$advice(DataXceiver.java:36)\n    [junit]  at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:1)","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-10-21T14:54:50.481+0000","updated":"2011-10-21T14:54:50.481+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12527380/comment/13132785","id":"13132785","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cos","name":"cos","key":"cos","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cos&avatarId=16741","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cos&avatarId=16741","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cos&avatarId=16741","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cos&avatarId=16741"},"displayName":"Konstantin Boudnik","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi Uma.\n\nAspect either work on not :) - they are just a pieces of byte code physically inserted into the target class. The reason you see {{DataXceiver.java:36}} in the stack is because there's no source code line anymore to tie with.\nAn easy way to find out what's going on is to disassemble the class file. When you do it you see this:\n{code}\n59     DataNode getDataNode()\n60     {\n61         return datanode;\n62     }\n63 \n64     public void run()\n65     {\n66         run_aroundBody1$advice(this, DataXceiverAspects.aspectOf(), this, null);\n67     }\n68 \n69     protected void opReadBlock(DataInputStream in, Block block, long startOffset, long length, String clientName,\n70             Token blockToken)\n71         throws IOException\n{code}\nI'd say it should work as expected. If an unexpected behavior is seen it is likely that we instrumented it on somewhat incorrect assumptions. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cos","name":"cos","key":"cos","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cos&avatarId=16741","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cos&avatarId=16741","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cos&avatarId=16741","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cos&avatarId=16741"},"displayName":"Konstantin Boudnik","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-10-21T16:18:51.321+0000","updated":"2011-10-21T16:18:51.321+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12527380/comment/13132836","id":"13132836","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"body":"We should make a patch for trunk too.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-10-21T17:14:15.461+0000","updated":"2011-10-21T17:14:15.461+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12527380/comment/13132941","id":"13132941","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cos","name":"cos","key":"cos","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cos&avatarId=16741","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cos&avatarId=16741","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cos&avatarId=16741","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cos&avatarId=16741"},"displayName":"Konstantin Boudnik","active":true,"timeZone":"America/Los_Angeles"},"body":"Right. However, patch for trunk will depends on completion of Mavenization work. Right now fault-injection is _completely_ unsupported by trunk build system. Pity ;(","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cos","name":"cos","key":"cos","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cos&avatarId=16741","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cos&avatarId=16741","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cos&avatarId=16741","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cos&avatarId=16741"},"displayName":"Konstantin Boudnik","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-10-21T19:02:14.314+0000","updated":"2011-10-21T19:02:14.314+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12527380/comment/13132949","id":"13132949","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"body":"Let's commit the fix and file another jira for the test, dependent on the mavenization progress.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-10-21T19:09:45.390+0000","updated":"2011-10-21T19:09:45.390+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12527380/comment/13133242","id":"13133242","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cos","name":"cos","key":"cos","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cos&avatarId=16741","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cos&avatarId=16741","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cos&avatarId=16741","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cos&avatarId=16741"},"displayName":"Konstantin Boudnik","active":true,"timeZone":"America/Los_Angeles"},"body":"Here's a patch for trunk. Something wrong with my ant installation or something and maven complains that it can't run the build. Thus, I can't verify it right now - will do later.\n\nThe patch also contains new test and instrumentation but it won't be verified until AOP is fixed in trunk.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cos","name":"cos","key":"cos","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cos&avatarId=16741","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cos&avatarId=16741","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cos&avatarId=16741","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cos&avatarId=16741"},"displayName":"Konstantin Boudnik","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-10-22T04:41:18.357+0000","updated":"2011-10-22T04:41:18.357+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12527380/comment/13133247","id":"13133247","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"body":"Sorry for coming late, Thanks a lot for making the patch on trunk as well!\n\nCos, Patch mostly looks good. But one problem is IOUtils.socketClose() repeated in the patch. Because socket close already handle in try block itself for IOEceptions. To avoid confusions i just made it sync with 22 as well.\n\nHere is a patch for trunk (only src changes). I will file separate JIRA for faultinjection test.\n\nThanks,\nUma","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-10-22T05:05:50.405+0000","updated":"2011-10-22T05:05:50.405+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12527380/comment/13133254","id":"13133254","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cos","name":"cos","key":"cos","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cos&avatarId=16741","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cos&avatarId=16741","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cos&avatarId=16741","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cos&avatarId=16741"},"displayName":"Konstantin Boudnik","active":true,"timeZone":"America/Los_Angeles"},"body":"Uma, actually there's no need for a separate patch: FI test will be picked up automatically once someone (likely to be me though) get AOP fixed in maven env.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cos","name":"cos","key":"cos","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cos&avatarId=16741","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cos&avatarId=16741","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cos&avatarId=16741","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cos&avatarId=16741"},"displayName":"Konstantin Boudnik","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-10-22T05:54:28.671+0000","updated":"2011-10-22T05:54:28.671+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12527380/comment/13133258","id":"13133258","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"body":"Here is a patch for trunk with test.\n1. In trunk code, InputStream getting logic has been moced to DataXceiver constructor. So, we need to stub getInputStream also.Updated with this change in test.\n\nThanks\nUma","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-10-22T06:03:46.762+0000","updated":"2011-10-22T06:03:46.762+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12527380/comment/13133261","id":"13133261","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cos","name":"cos","key":"cos","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cos&avatarId=16741","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cos&avatarId=16741","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cos&avatarId=16741","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cos&avatarId=16741"},"displayName":"Konstantin Boudnik","active":true,"timeZone":"America/Los_Angeles"},"body":"Coupla nits:\n- {{+        new Daemon(datanode.threadGroup, new DataXceiver(s, datanode, this)).start();}} is too long. Should be longer than 80 chars.\n- you don't need to change the name for every new patch: JIRA will make sure that the latest one is shown as 'enabled'. Custom naming is confusing, actually.\n- nice catch with IS' getter: I've missed it completely\nLooks good otherwise.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cos","name":"cos","key":"cos","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cos&avatarId=16741","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cos&avatarId=16741","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cos&avatarId=16741","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cos&avatarId=16741"},"displayName":"Konstantin Boudnik","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-10-22T06:10:02.869+0000","updated":"2011-10-22T06:10:02.869+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12527380/comment/13133270","id":"13133270","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks for the review!\n{quote}\n# + new Daemon(datanode.threadGroup, new DataXceiver(s, datanode, this)).start(); is too long. Should be longer than 80 chars.\n# you don't need to change the name for every new patch: JIRA will make sure that the latest one is shown as 'enabled'. Custom naming is confusing, actually.\n{quote}\nwrapped it.\nI have been observing in other JIRAs with this namings;). To avoid confusions, i just named it with JIRA id.\n\nThanks\nUma","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-10-22T06:32:31.652+0000","updated":"2011-10-22T06:32:31.652+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12527380/comment/13133275","id":"13133275","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cos","name":"cos","key":"cos","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cos&avatarId=16741","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cos&avatarId=16741","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cos&avatarId=16741","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cos&avatarId=16741"},"displayName":"Konstantin Boudnik","active":true,"timeZone":"America/Los_Angeles"},"body":"+1 looks good.\nAs for the naming: [JIRA].patch stands for trunk patch, IMO. Any branch designations can be add as qualifiers. Thanks","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cos","name":"cos","key":"cos","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cos&avatarId=16741","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cos&avatarId=16741","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cos&avatarId=16741","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cos&avatarId=16741"},"displayName":"Konstantin Boudnik","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-10-22T06:49:52.882+0000","updated":"2011-10-22T06:49:52.882+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12527380/comment/13133535","id":"13133535","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"-1 overall.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12500308/HDFS-2452.patch\n  against trunk revision .\n\n    +1 @author.  The patch does not contain any @author tags.\n\n    +1 tests included.  The patch appears to include 6 new or modified tests.\n\n    +1 javadoc.  The javadoc tool did not generate any warning messages.\n\n    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.\n\n    +1 findbugs.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.\n\n    +1 release audit.  The applied patch does not increase the total number of release audit warnings.\n\n    -1 core tests.  The patch failed these unit tests:\n                  org.apache.hadoop.hdfs.server.namenode.TestBackupNode\n                  org.apache.hadoop.hdfs.TestFileAppend2\n                  org.apache.hadoop.hdfs.TestBalancerBandwidth\n                  org.apache.hadoop.hdfs.TestRestartDFS\n                  org.apache.hadoop.hdfs.TestDistributedFileSystem\n                  org.apache.hadoop.hdfs.server.datanode.TestDeleteBlockPool\n\n    +1 contrib tests.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/1417//testReport/\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/1417//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2011-10-23T01:44:43.421+0000","updated":"2011-10-23T01:44:43.421+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12527380/comment/13133565","id":"13133565","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"body":"Test failures are not related to this patch!","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-10-23T03:28:11.680+0000","updated":"2011-10-23T03:28:11.680+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12527380/comment/13133724","id":"13133724","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"Integrated in Hadoop-Hdfs-trunk-Commit #1218 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk-Commit/1218/])\n    HDFS-2452. OutOfMemoryError in DataXceiverServer takes down the DataNode. Contributed by Uma Maheswara Rao.\n\nshv : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1187965\nFiles : \n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiverServer.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/aop/org/apache/hadoop/hdfs/server/datanode/DataXceiverAspects.aj\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/aop/org/apache/hadoop/hdfs/server/datanode/TestFiDataXceiverServer.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2011-10-23T20:21:28.955+0000","updated":"2011-10-23T20:21:28.955+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12527380/comment/13133726","id":"13133726","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"Integrated in Hadoop-Common-trunk-Commit #1140 (See [https://builds.apache.org/job/Hadoop-Common-trunk-Commit/1140/])\n    HDFS-2452. OutOfMemoryError in DataXceiverServer takes down the DataNode. Contributed by Uma Maheswara Rao.\n\nshv : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1187965\nFiles : \n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiverServer.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/aop/org/apache/hadoop/hdfs/server/datanode/DataXceiverAspects.aj\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/aop/org/apache/hadoop/hdfs/server/datanode/TestFiDataXceiverServer.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2011-10-23T20:22:39.512+0000","updated":"2011-10-23T20:22:39.512+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12527380/comment/13133731","id":"13133731","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"body":"I just committed this to trun and branch 0.23. Thank you Uma.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-10-23T20:30:02.631+0000","updated":"2011-10-23T20:30:02.631+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12527380/comment/13133733","id":"13133733","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"Integrated in Hadoop-Common-0.23-Commit #43 (See [https://builds.apache.org/job/Hadoop-Common-0.23-Commit/43/])\n    HDFS-2452. OutOfMemoryError in DataXceiverServer takes down the DataNode. Contributed by Uma Maheswara Rao.\n\nshv : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1187969\nFiles : \n* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt\n* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java\n* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiverServer.java\n* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/test/aop/org/apache/hadoop/hdfs/server/datanode/DataXceiverAspects.aj\n* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/test/aop/org/apache/hadoop/hdfs/server/datanode/TestFiDataXceiverServer.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2011-10-23T20:30:59.927+0000","updated":"2011-10-23T20:30:59.927+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12527380/comment/13133734","id":"13133734","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"Integrated in Hadoop-Hdfs-0.23-Commit #44 (See [https://builds.apache.org/job/Hadoop-Hdfs-0.23-Commit/44/])\n    HDFS-2452. OutOfMemoryError in DataXceiverServer takes down the DataNode. Contributed by Uma Maheswara Rao.\n\nshv : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1187969\nFiles : \n* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt\n* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java\n* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiverServer.java\n* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/test/aop/org/apache/hadoop/hdfs/server/datanode/DataXceiverAspects.aj\n* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/test/aop/org/apache/hadoop/hdfs/server/datanode/TestFiDataXceiverServer.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2011-10-23T20:31:07.245+0000","updated":"2011-10-23T20:31:07.245+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12527380/comment/13133742","id":"13133742","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"Integrated in Hadoop-Mapreduce-trunk-Commit #1155 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk-Commit/1155/])\n    HDFS-2452. OutOfMemoryError in DataXceiverServer takes down the DataNode. Contributed by Uma Maheswara Rao.\n\nshv : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1187965\nFiles : \n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiverServer.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/aop/org/apache/hadoop/hdfs/server/datanode/DataXceiverAspects.aj\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/aop/org/apache/hadoop/hdfs/server/datanode/TestFiDataXceiverServer.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2011-10-23T20:44:35.695+0000","updated":"2011-10-23T20:44:35.695+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12527380/comment/13133743","id":"13133743","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"Integrated in Hadoop-Mapreduce-0.23-Commit #43 (See [https://builds.apache.org/job/Hadoop-Mapreduce-0.23-Commit/43/])\n    HDFS-2452. OutOfMemoryError in DataXceiverServer takes down the DataNode. Contributed by Uma Maheswara Rao.\n\nshv : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1187969\nFiles : \n* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt\n* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java\n* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiverServer.java\n* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/test/aop/org/apache/hadoop/hdfs/server/datanode/DataXceiverAspects.aj\n* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/test/aop/org/apache/hadoop/hdfs/server/datanode/TestFiDataXceiverServer.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2011-10-23T20:52:42.889+0000","updated":"2011-10-23T20:52:42.889+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12527380/comment/13134027","id":"13134027","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"Integrated in Hadoop-Hdfs-0.23-Build #49 (See [https://builds.apache.org/job/Hadoop-Hdfs-0.23-Build/49/])\n    HDFS-2452. OutOfMemoryError in DataXceiverServer takes down the DataNode. Contributed by Uma Maheswara Rao.\n\nshv : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1187969\nFiles : \n* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt\n* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java\n* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiverServer.java\n* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/test/aop/org/apache/hadoop/hdfs/server/datanode/DataXceiverAspects.aj\n* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/test/aop/org/apache/hadoop/hdfs/server/datanode/TestFiDataXceiverServer.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2011-10-24T12:43:10.818+0000","updated":"2011-10-24T12:43:10.818+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12527380/comment/13134049","id":"13134049","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"Integrated in Hadoop-Mapreduce-trunk #870 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/870/])\n    HDFS-2452. OutOfMemoryError in DataXceiverServer takes down the DataNode. Contributed by Uma Maheswara Rao.\n\nshv : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1187965\nFiles : \n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiverServer.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/aop/org/apache/hadoop/hdfs/server/datanode/DataXceiverAspects.aj\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/aop/org/apache/hadoop/hdfs/server/datanode/TestFiDataXceiverServer.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2011-10-24T13:18:45.560+0000","updated":"2011-10-24T13:18:45.560+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12527380/comment/13134053","id":"13134053","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"Integrated in Hadoop-Mapreduce-0.23-Build #61 (See [https://builds.apache.org/job/Hadoop-Mapreduce-0.23-Build/61/])\n    HDFS-2452. OutOfMemoryError in DataXceiverServer takes down the DataNode. Contributed by Uma Maheswara Rao.\n\nshv : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1187969\nFiles : \n* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt\n* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java\n* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiverServer.java\n* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/test/aop/org/apache/hadoop/hdfs/server/datanode/DataXceiverAspects.aj\n* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/test/aop/org/apache/hadoop/hdfs/server/datanode/TestFiDataXceiverServer.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2011-10-24T13:20:08.198+0000","updated":"2011-10-24T13:20:08.198+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12527380/comment/13134060","id":"13134060","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"Integrated in Hadoop-Hdfs-trunk #841 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/841/])\n    HDFS-2452. OutOfMemoryError in DataXceiverServer takes down the DataNode. Contributed by Uma Maheswara Rao.\n\nshv : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1187965\nFiles : \n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiverServer.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/aop/org/apache/hadoop/hdfs/server/datanode/DataXceiverAspects.aj\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/aop/org/apache/hadoop/hdfs/server/datanode/TestFiDataXceiverServer.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2011-10-24T13:26:53.309+0000","updated":"2011-10-24T13:26:53.309+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12527380/comment/13135712","id":"13135712","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"body":"As Jakob noted to me the patch that went into trunk still has the 30 sec sleep in the test, while in the patch for 0.22 branch it was eliminated. Uma, do you know what happened there?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-10-26T05:01:19.547+0000","updated":"2011-10-26T05:01:19.547+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12527380/comment/13135898","id":"13135898","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi Konstantin,\n \n I just compared the code with trunk and 0.22 branch. I don't see any difference, except getInputStream stub and there is no sleeps as well!.\n\nI think, i he may be pointing about source code 30sec sleep or may be about testcase timeout. That will be the failure case. If CountDownLatch does not decrement the count then, latch.await() may wait forever. So , to avaoid this, we gave 30000ms as testcase timeout. This will be the failure case.\nIf that is the case, we need to correct the actual testcase problem first. Why it is not throwing the OutOfMemory Error from aspectj mocks and did he provided any trace? If you get any trace please provide, i will take a look.\n\none more point is, some one started looking on AspectJ on trunk? if yes, can you share the options to run the aspectJ on trunk if you have idea?\n\nThanks,\nUma","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-10-26T12:30:06.885+0000","updated":"2011-10-26T12:30:06.885+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12527380/comment/13136164","id":"13136164","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cos","name":"cos","key":"cos","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cos&avatarId=16741","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cos&avatarId=16741","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cos&avatarId=16741","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cos&avatarId=16741"},"displayName":"Konstantin Boudnik","active":true,"timeZone":"America/Los_Angeles"},"body":"bq. If you get any trace please provide, i will take a look.\nI don't think there will be traces - aspectj support is totally broken in trunk and it hasn't been fixed yet. Hopefully, I will have some spare time to work on it. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cos","name":"cos","key":"cos","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cos&avatarId=16741","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cos&avatarId=16741","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cos&avatarId=16741","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cos&avatarId=16741"},"displayName":"Konstantin Boudnik","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-10-26T17:59:26.641+0000","updated":"2011-10-26T17:59:26.641+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12527380/comment/13136364","id":"13136364","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"body":"Sorry guys, everything is ok. I was looking in the wrong place. Juggling too many things.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-10-26T20:55:02.719+0000","updated":"2011-10-26T20:55:02.719+0000"}],"maxResults":69,"total":69,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-2452/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i09fd3:"}}