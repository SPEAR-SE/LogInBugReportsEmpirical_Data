{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12962759","self":"https://issues.apache.org/jira/rest/api/2/issue/12962759","key":"HDFS-10333","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12329057","id":"12329057","description":"2.8.0 release","name":"2.8.0","archived":false,"released":true,"releaseDate":"2017-03-22"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12335732","id":"12335732","description":"3.0.0-alpha1 release","name":"3.0.0-alpha1","archived":false,"released":true,"releaseDate":"2016-09-03"}],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2016-05-09T11:43:59.522+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Mon May 16 11:40:41 UTC 2016","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_1087137696_*|*_5_*:*_1_*:*_0_*|*_10002_*:*_1_*:*_581243946","customfield_12312321":null,"resolutiondate":"2016-05-16T05:16:03.913+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-10333/watchers","watchCount":7,"isWatching":false},"created":"2016-04-26T21:49:42.361+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"1.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[],"issuelinks":[],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=linyiqun","name":"linyiqun","key":"linyiqun","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=linyiqun&avatarId=25258","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=linyiqun&avatarId=25258","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=linyiqun&avatarId=25258","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=linyiqun&avatarId=25258"},"displayName":"Yiqun Lin","active":true,"timeZone":"Asia/Shanghai"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2016-08-30T01:16:31.333+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12329603","id":"12329603","name":"hdfs"}],"timeoriginalestimate":null,"description":"Java8 (I used JAVA_HOME=/opt/toolchain/jdk1.8.0_25):\n\n{code}\n------------------------------------------------------\n T E S T S\n-------------------------------------------------------\nJava HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize=768m; support was removed in 8.0\nRunning org.apache.hadoop.hdfs.TestFileAppend\nTests run: 12, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 27.75 sec <<< FAILURE! - in org.apache.hadoop.hdfs.TestFileAppend\ntestMultipleAppends(org.apache.hadoop.hdfs.TestFileAppend)  Time elapsed: 3.674 sec  <<< ERROR!\njava.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43067,DS-cf80da41-3697-4afa-8f89-93693cd5035d,DISK], DatanodeInfoWithStorage[127.0.0.1:32946,DS-3b08422c-959e-42f0-a624-91b2524c4371,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43067,DS-cf80da41-3697-4afa-8f89-93693cd5035d,DISK], DatanodeInfoWithStorage[127.0.0.1:32946,DS-3b08422c-959e-42f0-a624-91b2524c4371,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.\n        at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1166)\n        at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1232)\n        at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1423)\n        at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1338)\n        at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1321)\n        at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:599)\n\n\n{code}\n\nHowever, when I run with Java1.7, the test is sometimes successful, and it sometimes fails with \n{code}\nTests run: 12, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 41.32 sec <<< FAILURE! - in org.apache.hadoop.hdfs.TestFileAppend\ntestMultipleAppends(org.apache.hadoop.hdfs.TestFileAppend)  Time elapsed: 9.099 sec  <<< ERROR!\njava.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:49006,DS-498240fa-d1c7-4ba1-b97e-a1761cbbefa5,DISK], DatanodeInfoWithStorage[127.0.0.1:43097,DS-b83b49ce-fc14-4b9e-a3fc-7df2cd9fc753,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:49006,DS-498240fa-d1c7-4ba1-b97e-a1761cbbefa5,DISK], DatanodeInfoWithStorage[127.0.0.1:43097,DS-b83b49ce-fc14-4b9e-a3fc-7df2cd9fc753,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.\n\tat org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1162)\n\tat org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1232)\n\tat org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1423)\n\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1338)\n\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1321)\n\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:599)\n\n{code}\n\n\nThe failure of this test is intermittent, but it fails pretty often.\n\n\n\n","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12329057","id":"12329057","description":"2.8.0 release","name":"2.8.0","archived":false,"released":true,"releaseDate":"2017-03-22"}],"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12802974","id":"12802974","filename":"HDFS-10333.001.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=linyiqun","name":"linyiqun","key":"linyiqun","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=linyiqun&avatarId=25258","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=linyiqun&avatarId=25258","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=linyiqun&avatarId=25258","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=linyiqun&avatarId=25258"},"displayName":"Yiqun Lin","active":true,"timeZone":"Asia/Shanghai"},"created":"2016-05-09T11:48:56.671+0000","size":1251,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12802974/HDFS-10333.001.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"Intermittent org.apache.hadoop.hdfs.TestFileAppend failure in trunk","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12962759/comment/15276253","id":"15276253","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=linyiqun","name":"linyiqun","key":"linyiqun","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=linyiqun&avatarId=25258","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=linyiqun&avatarId=25258","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=linyiqun&avatarId=25258","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=linyiqun&avatarId=25258"},"displayName":"Yiqun Lin","active":true,"timeZone":"Asia/Shanghai"},"body":"I tested this test and other similar tests in {{TestFileAppend}} in my local. I found connection refused happed sometimes due to socket io timeout. This are logs\n{code}\n2016-05-09 17:33:49,828 [DataXceiver for client DFSClient_NONMAPREDUCE_140749666_1 at /127.0.0.1:58040 [Receiving block BP-2032095287-127.0.0.1-1462786332089:blk_1073741827_1003]] ERROR datanode.DataNode (DataXceiver.java:run(316)) - 127.0.0.1:58021:DataXceiver error processing WRITE_BLOCK operation  src: /127.0.0.1:58040 dst: /127.0.0.1:58021\njava.net.ConnectException: Connection refused\n\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)\n\tat org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)\n\tat org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)\n\tat org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)\n\tat org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:746)\n\tat org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:171)\n\tat org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:105)\n\tat org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:289)\n\tat java.lang.Thread.run(Thread.java:745)\n{code}\nAnd then this will cause IOException and set first target node as a bad node(actually it means  datanode that failed in connection setup)into the response.\n{code}\n        } catch (IOException e) {\n          if (isClient) {\n            BlockOpResponseProto.newBuilder()\n              .setStatus(ERROR)\n               // NB: Unconditionally using the xfer addr w/o hostname\n              .setFirstBadLink(targets[0].getXferAddr())\n              .build()\n              .writeDelimitedTo(replyOut);\n            replyOut.flush();\n          }\n{code}\nAnd this node index will be set into errorState and then marked this node as bad node. The code will not return false here\n{code}\nif (!errorState.hasDatanodeError() && !shouldHandleExternalError()) {\n      return false;\n}\n{code}\n,then continue to execute {{setupPipelineForAppendOrRecovery}} in {{processDatanodeOrExternalError}}. And finally it will print the msg \"no more good datanodes being available to replace a bad datanode on the existing pipeline\".\n\nSo we should disable the property {{dfs.client.block.write.replace-datanode-on-failure.enable}}, and there is no need to set policy of {{dfs.client.block.write.replace-datanode-on-failure.policy}} here. The test will failed once the socket io timeout happens. In addition, the similar test {{TestFileAppend#testMultiAppend2}} has already disabled this.\n\nI will post a patch for this later, thanks review.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=linyiqun","name":"linyiqun","key":"linyiqun","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=linyiqun&avatarId=25258","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=linyiqun&avatarId=25258","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=linyiqun&avatarId=25258","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=linyiqun&avatarId=25258"},"displayName":"Yiqun Lin","active":true,"timeZone":"Asia/Shanghai"},"created":"2016-05-09T11:43:59.522+0000","updated":"2016-05-09T11:43:59.522+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12962759/comment/15276285","id":"15276285","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=linyiqun","name":"linyiqun","key":"linyiqun","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=linyiqun&avatarId=25258","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=linyiqun&avatarId=25258","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=linyiqun&avatarId=25258","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=linyiqun&avatarId=25258"},"displayName":"Yiqun Lin","active":true,"timeZone":"Asia/Shanghai"},"body":"Sorry, I correct the opinion before:\n{quote}\nThe test will failed once the socket io timeout happens\n{quote}\nThis should be modify as The test will has a more chance to fail once socket io timeout frquently happen over a period of time.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=linyiqun","name":"linyiqun","key":"linyiqun","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=linyiqun&avatarId=25258","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=linyiqun&avatarId=25258","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=linyiqun&avatarId=25258","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=linyiqun&avatarId=25258"},"displayName":"Yiqun Lin","active":true,"timeZone":"Asia/Shanghai"},"created":"2016-05-09T12:13:09.790+0000","updated":"2016-05-09T12:13:09.790+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12962759/comment/15276409","id":"15276409","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 11s {color} | {color:blue} Docker mode activated. {color} |\n| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green} 0m 0s {color} | {color:green} The patch appears to include 1 new or modified test files. {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 6m 49s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 0m 38s {color} | {color:green} trunk passed with JDK v1.8.0_91 {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 0m 41s {color} | {color:green} trunk passed with JDK v1.7.0_95 {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 27s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 0m 51s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 13s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 1m 55s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 5s {color} | {color:green} trunk passed with JDK v1.8.0_91 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 46s {color} | {color:green} trunk passed with JDK v1.7.0_95 {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 0m 46s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 0m 35s {color} | {color:green} the patch passed with JDK v1.8.0_91 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 0m 35s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 0m 38s {color} | {color:green} the patch passed with JDK v1.7.0_95 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 0m 38s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 23s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 0m 48s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 11s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green} 0m 0s {color} | {color:green} Patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 2m 5s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 0m 59s {color} | {color:green} the patch passed with JDK v1.8.0_91 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 42s {color} | {color:green} the patch passed with JDK v1.7.0_95 {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 57m 3s {color} | {color:red} hadoop-hdfs in the patch failed with JDK v1.8.0_91. {color} |\n| {color:green}+1{color} | {color:green} unit {color} | {color:green} 54m 45s {color} | {color:green} hadoop-hdfs in the patch passed with JDK v1.7.0_95. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green} 0m 24s {color} | {color:green} Patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black} 136m 57s {color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| JDK v1.8.0_91 Failed junit tests | hadoop.hdfs.shortcircuit.TestShortCircuitCache |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:cf2ee45 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12802974/HDFS-10333.001.patch |\n| JIRA Issue | HDFS-10333 |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux beb0d668ac24 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / 411fb4b |\n| Default Java | 1.7.0_95 |\n| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_91 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_95 |\n| findbugs | v3.0.0 |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/15396/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.8.0_91.txt |\n| unit test logs |  https://builds.apache.org/job/PreCommit-HDFS-Build/15396/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.8.0_91.txt |\n| JDK v1.7.0_95  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/15396/testReport/ |\n| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/15396/console |\n| Powered by | Apache Yetus 0.2.0   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2016-05-09T14:15:34.375+0000","updated":"2016-05-09T14:15:34.375+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12962759/comment/15284153","id":"15284153","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=andrew.wang","name":"andrew.wang","key":"andrew.wang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=andrew.wang&avatarId=19230","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=andrew.wang&avatarId=19230","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=andrew.wang&avatarId=19230","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=andrew.wang&avatarId=19230"},"displayName":"Andrew Wang","active":true,"timeZone":"America/Los_Angeles"},"body":"LGTM +1, committed back through branch-2.8. Thank you for the contribution [~linyiqun]!","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=andrew.wang","name":"andrew.wang","key":"andrew.wang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=andrew.wang&avatarId=19230","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=andrew.wang&avatarId=19230","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=andrew.wang&avatarId=19230","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=andrew.wang&avatarId=19230"},"displayName":"Andrew Wang","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-05-16T05:16:03.966+0000","updated":"2016-05-16T05:16:03.966+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12962759/comment/15284172","id":"15284172","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"FAILURE: Integrated in Hadoop-trunk-Commit #9764 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/9764/])\nHDFS-10333. Intermittent org.apache.hadoop.hdfs.TestFileAppend failure (wang: rev 45788204ae2ac82ccb3b4fe2fd22aead1dd79f0d)\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileAppend.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2016-05-16T05:42:03.161+0000","updated":"2016-05-16T05:42:03.161+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12962759/comment/15284405","id":"15284405","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=linyiqun","name":"linyiqun","key":"linyiqun","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=linyiqun&avatarId=25258","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=linyiqun&avatarId=25258","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=linyiqun&avatarId=25258","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=linyiqun&avatarId=25258"},"displayName":"Yiqun Lin","active":true,"timeZone":"Asia/Shanghai"},"body":"Thanks [~andrew.wang] for commit!","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=linyiqun","name":"linyiqun","key":"linyiqun","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=linyiqun&avatarId=25258","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=linyiqun&avatarId=25258","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=linyiqun&avatarId=25258","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=linyiqun&avatarId=25258"},"displayName":"Yiqun Lin","active":true,"timeZone":"Asia/Shanghai"},"created":"2016-05-16T11:40:41.426+0000","updated":"2016-05-16T11:40:41.426+0000"}],"maxResults":6,"total":6,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-10333/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i2ws1r:"}}