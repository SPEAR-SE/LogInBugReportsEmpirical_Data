{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12511082","self":"https://issues.apache.org/jira/rest/api/2/issue/12511082","key":"HDFS-2095","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/3","id":"3","description":"The problem is a duplicate of an existing issue.","name":"Duplicate"},"customfield_12312322":null,"customfield_12310220":"2011-06-21T11:22:44.224+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Fri Apr 05 22:02:22 UTC 2013","customfield_12310420":"125","customfield_12312320":null,"customfield_12310222":"10002_*:*_1_*:*_56544540303_*|*_1_*:*_1_*:*_105714_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2013-04-05T22:02:21.997+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-2095/watchers","watchCount":11,"isWatching":false},"created":"2011-06-21T11:11:36.054+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"4.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12314046","id":"12314046","description":"","name":"0.21.0","archived":false,"released":true,"releaseDate":"2010-08-23"}],"issuelinks":[{"id":"12382681","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12382681","type":{"id":"12310000","name":"Duplicate","inward":"is duplicated by","outward":"duplicates","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/12310000"},"outwardIssue":{"id":"12636288","key":"HDFS-4581","self":"https://issues.apache.org/jira/rest/api/2/issue/12636288","fields":{"summary":"DataNode#checkDiskError should not be called on network errors","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12345793","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12345793","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"inwardIssue":{"id":"12532854","key":"YARN-92","self":"https://issues.apache.org/jira/rest/api/2/issue/12532854","fields":{"summary":"NM disk failure detection only covers local dirs ","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/7","id":"7","description":"The sub-task of the issue","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype","name":"Sub-task","subtask":true,"avatarId":21146}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2014-02-07T23:13:31.157+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12312927","id":"12312927","name":"datanode"}],"timeoriginalestimate":null,"description":"\nI can see that if data node receives some IO error, this can cause checkDir storm.\nWhat I mean:\n1) any error produces DataNode.checkDiskError call\n2) this call locks volume:\n java.lang.Thread.State: RUNNABLE\n       at java.io.UnixFileSystem.getBooleanAttributes0(Native Method)\n       at java.io.UnixFileSystem.getBooleanAttributes(UnixFileSystem.java:228)\n       at java.io.File.exists(File.java:733)\n       at org.apache.hadoop.util.DiskChecker.mkdirsWithExistsCheck(DiskChecker.java:65)\n       at org.apache.hadoop.util.DiskChecker.checkDir(DiskChecker.java:86)\n       at org.apache.hadoop.hdfs.server.datanode.FSDataset$FSDir.checkDirTree(FSDataset.java:228)\n       at org.apache.hadoop.hdfs.server.datanode.FSDataset$FSDir.checkDirTree(FSDataset.java:232)\n       at org.apache.hadoop.hdfs.server.datanode.FSDataset$FSDir.checkDirTree(FSDataset.java:232)\n       at org.apache.hadoop.hdfs.server.datanode.FSDataset$FSDir.checkDirTree(FSDataset.java:232)\n       at org.apache.hadoop.hdfs.server.datanode.FSDataset$FSVolume.checkDirs(FSDataset.java:414)\n       at org.apache.hadoop.hdfs.server.datanode.FSDataset$FSVolumeSet.checkDirs(FSDataset.java:617)\n       - locked <0x000000080a8faec0> (a org.apache.hadoop.hdfs.server.datanode.FSDataset$FSVolumeSet)\n       at org.apache.hadoop.hdfs.server.datanode.FSDataset.checkDataDir(FSDataset.java:1681)\n       at org.apache.hadoop.hdfs.server.datanode.DataNode.checkDiskError(DataNode.java:745)\n       at org.apache.hadoop.hdfs.server.datanode.DataNode.checkDiskError(DataNode.java:735)\n       at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.close(BlockReceiver.java:202)\n       at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:151)\n       at org.apache.hadoop.io.IOUtils.closeStream(IOUtils.java:167)\n       at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:646)\n       at org.apache.hadoop.hdfs.server.datanode.DataXceiver.opWriteBlock(DataXceiver.java:352)\n       at org.apache.hadoop.hdfs.protocol.DataTransferProtocol$Receiver.opWriteBlock(DataTransferProtocol.java:390)\n       at org.apache.hadoop.hdfs.protocol.DataTransferProtocol$Receiver.processOp(DataTransferProtocol.java:331)\n       at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:111)\n       at java.lang.Thread.run(Thread.java:619)\n\n3) This produces timeouts on other calls, e.g.\n2011-06-17 17:35:03,922 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: checkDiskError: exception:\njava.io.InterruptedIOException\n       at java.io.FileOutputStream.writeBytes(Native Method)\n       at java.io.FileOutputStream.write(FileOutputStream.java:260)\n       at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)\n       at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)\n       at java.io.DataOutputStream.flush(DataOutputStream.java:106)\n       at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.close(BlockReceiver.java:183)\n       at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:151)\n       at org.apache.hadoop.io.IOUtils.closeStream(IOUtils.java:167)\n       at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:646)\n       at org.apache.hadoop.hdfs.server.datanode.DataXceiver.opWriteBlock(DataXceiver.java:352)\n       at org.apache.hadoop.hdfs.protocol.DataTransferProtocol$Receiver.opWriteBlock(DataTransferProtocol.java:390)\n       at org.apache.hadoop.hdfs.protocol.DataTransferProtocol$Receiver.processOp(DataTransferProtocol.java:331)\n       at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:111)\n       at java.lang.Thread.run(Thread.java:619)\n\n4) This, in turn, produces more \"dir check calls\".\n\n5) All the cluster works very slow because of half-working node.\n","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12572915","id":"12572915","filename":"HDFS-2095.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rohit_kochar","name":"rohit_kochar","key":"rohit_kochar","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rohit Kochar","active":true,"timeZone":"Asia/Kolkata"},"created":"2013-03-09T14:43:41.666+0000","size":2543,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12572915/HDFS-2095.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12483425","id":"12483425","filename":"patch.diff","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tivv","name":"tivv","key":"tivv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tivv&avatarId=16734","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tivv&avatarId=16734","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tivv&avatarId=16734","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tivv&avatarId=16734"},"displayName":"Vitalii Tymchyshyn","active":true,"timeZone":"America/New_York"},"created":"2011-06-22T10:34:22.981+0000","size":1179,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12483425/patch.diff"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12483269","id":"12483269","filename":"patch2.diff","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tivv","name":"tivv","key":"tivv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tivv&avatarId=16734","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tivv&avatarId=16734","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tivv&avatarId=16734","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tivv&avatarId=16734"},"displayName":"Vitalii Tymchyshyn","active":true,"timeZone":"America/New_York"},"created":"2011-06-21T11:21:03.810+0000","size":1119,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12483269/patch2.diff"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12492453","id":"12492453","filename":"pathch3.diff","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tivv","name":"tivv","key":"tivv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tivv&avatarId=16734","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tivv&avatarId=16734","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tivv&avatarId=16734","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tivv&avatarId=16734"},"displayName":"Vitalii Tymchyshyn","active":true,"timeZone":"America/New_York"},"created":"2011-08-31T12:59:18.227+0000","size":2834,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12492453/pathch3.diff"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"113772","customfield_12312823":null,"summary":"org.apache.hadoop.hdfs.server.datanode.DataNode#checkDiskError produces check storm making data node unavailable","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tivv","name":"tivv","key":"tivv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tivv&avatarId=16734","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tivv&avatarId=16734","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tivv&avatarId=16734","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tivv&avatarId=16734"},"displayName":"Vitalii Tymchyshyn","active":true,"timeZone":"America/New_York"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tivv","name":"tivv","key":"tivv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tivv&avatarId=16734","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tivv&avatarId=16734","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tivv&avatarId=16734","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tivv&avatarId=16734"},"displayName":"Vitalii Tymchyshyn","active":true,"timeZone":"America/New_York"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12511082/comment/13052482","id":"13052482","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tivv","name":"tivv","key":"tivv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tivv&avatarId=16734","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tivv&avatarId=16734","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tivv&avatarId=16734","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tivv&avatarId=16734"},"displayName":"Vitalii Tymchyshyn","active":true,"timeZone":"America/New_York"},"body":"This is against 0.21 release","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tivv","name":"tivv","key":"tivv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tivv&avatarId=16734","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tivv&avatarId=16734","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tivv&avatarId=16734","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tivv&avatarId=16734"},"displayName":"Vitalii Tymchyshyn","active":true,"timeZone":"America/New_York"},"created":"2011-06-21T11:12:33.688+0000","updated":"2011-06-21T11:12:33.688+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12511082/comment/13052484","id":"13052484","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tivv","name":"tivv","key":"tivv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tivv&avatarId=16734","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tivv&avatarId=16734","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tivv&avatarId=16734","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tivv&avatarId=16734"},"displayName":"Vitalii Tymchyshyn","active":true,"timeZone":"America/New_York"},"body":"This is done against project root & second file changes (imports) are removed","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tivv","name":"tivv","key":"tivv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tivv&avatarId=16734","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tivv&avatarId=16734","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tivv&avatarId=16734","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tivv&avatarId=16734"},"displayName":"Vitalii Tymchyshyn","active":true,"timeZone":"America/New_York"},"created":"2011-06-21T11:21:03.844+0000","updated":"2011-06-21T11:21:03.844+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12511082/comment/13052485","id":"13052485","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"-1 overall.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12483269/patch2.diff\n  against trunk revision 1137675.\n\n    +1 @author.  The patch does not contain any @author tags.\n\n    -1 tests included.  The patch doesn't appear to include any new or modified tests.\n                        Please justify why no new tests are needed for this patch.\n                        Also please list what manual steps were performed to verify this patch.\n\n    -1 patch.  The patch command could not apply the patch.\n\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/804//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2011-06-21T11:22:44.224+0000","updated":"2011-06-21T11:22:44.224+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12511082/comment/13052651","id":"13052651","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"Hi. Can you check if this still exists in trunk and if so prepare a patch against trunk? Thanks.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2011-06-21T16:39:59.460+0000","updated":"2011-06-21T16:39:59.460+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12511082/comment/13052664","id":"13052664","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tivv","name":"tivv","key":"tivv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tivv&avatarId=16734","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tivv&avatarId=16734","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tivv&avatarId=16734","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tivv&avatarId=16734"},"displayName":"Vitalii Tymchyshyn","active":true,"timeZone":"America/New_York"},"body":"I will try, but I can't be sure that same exceptions or code pathes are used.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tivv","name":"tivv","key":"tivv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tivv&avatarId=16734","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tivv&avatarId=16734","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tivv&avatarId=16734","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tivv&avatarId=16734"},"displayName":"Vitalii Tymchyshyn","active":true,"timeZone":"America/New_York"},"created":"2011-06-21T17:08:12.636+0000","updated":"2011-06-21T17:08:12.636+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12511082/comment/13053159","id":"13053159","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tivv","name":"tivv","key":"tivv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tivv&avatarId=16734","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tivv&avatarId=16734","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tivv&avatarId=16734","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tivv&avatarId=16734"},"displayName":"Vitalii Tymchyshyn","active":true,"timeZone":"America/New_York"},"body":"A trunk patch. Node: Better looking into code it seems that it is not needed to rethrow InterruptedIOException","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tivv","name":"tivv","key":"tivv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tivv&avatarId=16734","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tivv&avatarId=16734","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tivv&avatarId=16734","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tivv&avatarId=16734"},"displayName":"Vitalii Tymchyshyn","active":true,"timeZone":"America/New_York"},"created":"2011-06-22T10:34:23.001+0000","updated":"2011-06-22T10:34:23.001+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12511082/comment/13053196","id":"13053196","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"-1 overall.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12483425/patch.diff\n  against trunk revision 1138262.\n\n    +1 @author.  The patch does not contain any @author tags.\n\n    -1 tests included.  The patch doesn't appear to include any new or modified tests.\n                        Please justify why no new tests are needed for this patch.\n                        Also please list what manual steps were performed to verify this patch.\n\n    +1 javadoc.  The javadoc tool did not generate any warning messages.\n\n    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.\n\n    +1 findbugs.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.\n\n    +1 release audit.  The applied patch does not increase the total number of release audit warnings.\n\n    -1 core tests.  The patch failed these core unit tests:\n                  org.apache.hadoop.hdfs.TestMultiThreadedHflush\n\n    +1 contrib tests.  The patch passed contrib unit tests.\n\n    +1 system test framework.  The patch passed system test framework compile.\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/816//testReport/\nFindbugs warnings: https://builds.apache.org/job/PreCommit-HDFS-Build/816//artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/816//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2011-06-22T11:56:25.847+0000","updated":"2011-06-22T11:56:25.847+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12511082/comment/13093793","id":"13093793","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tivv","name":"tivv","key":"tivv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tivv&avatarId=16734","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tivv&avatarId=16734","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tivv&avatarId=16734","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tivv&avatarId=16734"},"displayName":"Vitalii Tymchyshyn","active":true,"timeZone":"America/New_York"},"body":"I've got today one more stack trace that forced \"disk check\": \n\n2011-08-30 14:48:39,010 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: checkDiskError: exception: \njava.io.IOException: Broken pipe\n        at sun.nio.ch.FileDispatcher.write0(Native Method)\n        at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:29)\n        at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:104)\n        at sun.nio.ch.IOUtil.write(IOUtil.java:75)\n        at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:334)\n        at org.apache.hadoop.net.SocketOutputStream$Writer.performIO(SocketOutputStream.java:60)\n        at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)\n        at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:151)\n        at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:112)\n        at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:105)\n        at java.io.DataOutputStream.writeShort(DataOutputStream.java:150)\n        at org.apache.hadoop.hdfs.protocol.DataTransferProtocol$PipelineAck.write(DataTransferProtocol.java:543)\n        at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:916)\n        at java.lang.Thread.run(Thread.java:619)\n\nIt seems that BlockReceiver$PacketResponder.run do not distinguish between disk errors and network errors and runs checkDiskError in any case. And checkDiskError is very time consuming if you have a lot of directories. So, actually there are next problems to be fixed:\n 1) checkDiskError should not be called on network errors\n 2) checkDiskError should either not lock the whole data dir or be much more lighter.\nIn any case, why the whole tree (dirs only!) is analyzed? Is it because of possible multiple mount  points possible in there? In any case, checking every single directory looks like overkill for me. In my case, it simply makes node \"dead\".","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tivv","name":"tivv","key":"tivv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tivv&avatarId=16734","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tivv&avatarId=16734","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tivv&avatarId=16734","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tivv&avatarId=16734"},"displayName":"Vitalii Tymchyshyn","active":true,"timeZone":"America/New_York"},"created":"2011-08-30T15:06:54.798+0000","updated":"2011-08-30T15:06:54.798+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12511082/comment/13094497","id":"13094497","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tivv","name":"tivv","key":"tivv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tivv&avatarId=16734","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tivv&avatarId=16734","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tivv&avatarId=16734","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tivv&avatarId=16734"},"displayName":"Vitalii Tymchyshyn","active":true,"timeZone":"America/New_York"},"body":"OK, today I've got intensive \"dead node\" storm because of this problem, so my next patch follows. It allows to specify maximum depth to scan in checkDisError","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tivv","name":"tivv","key":"tivv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tivv&avatarId=16734","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tivv&avatarId=16734","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tivv&avatarId=16734","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tivv&avatarId=16734"},"displayName":"Vitalii Tymchyshyn","active":true,"timeZone":"America/New_York"},"created":"2011-08-31T12:57:43.722+0000","updated":"2011-08-31T12:57:43.722+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12511082/comment/13094500","id":"13094500","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tivv","name":"tivv","key":"tivv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tivv&avatarId=16734","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tivv&avatarId=16734","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tivv&avatarId=16734","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tivv&avatarId=16734"},"displayName":"Vitalii Tymchyshyn","active":true,"timeZone":"America/New_York"},"body":"Introduce new parameter to limit checkDiskError depth. Default value of -1 means no limit","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tivv","name":"tivv","key":"tivv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tivv&avatarId=16734","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tivv&avatarId=16734","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tivv&avatarId=16734","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tivv&avatarId=16734"},"displayName":"Vitalii Tymchyshyn","active":true,"timeZone":"America/New_York"},"created":"2011-08-31T12:59:18.246+0000","updated":"2011-08-31T12:59:18.246+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12511082/comment/13094503","id":"13094503","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"-1 overall.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12492453/pathch3.diff\n  against trunk revision .\n\n    +1 @author.  The patch does not contain any @author tags.\n\n    -1 tests included.  The patch doesn't appear to include any new or modified tests.\n                        Please justify why no new tests are needed for this patch.\n                        Also please list what manual steps were performed to verify this patch.\n\n    -1 patch.  The patch command could not apply the patch.\n\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/1182//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2011-08-31T13:03:42.042+0000","updated":"2011-08-31T13:03:42.042+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12511082/comment/13499133","id":"13499133","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"What do some other folks think about Vitalii's approach? It looks like the code which recursively scans the entire drive is fairly ancient, not sure why we decided to do that.\n\nAnother approach would be to do the scanning without holding the volume lock - similar to how we now do block report gathering in branch-1 (HDFS-2379)","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2012-11-16T20:50:15.843+0000","updated":"2012-11-16T20:50:15.843+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12511082/comment/13500037","id":"13500037","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=inder","name":"inder","key":"inder","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Inder SIngh","active":true,"timeZone":"Etc/UTC"},"body":"Folks,\n\nwe are hitting this in production with the same kinda of effects mentioned here. We are running cdh3u3. \nTill the time the fix makes it into another update, can anyone suggest any mechanism to work-around this problem.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=inder","name":"inder","key":"inder","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Inder SIngh","active":true,"timeZone":"Etc/UTC"},"created":"2012-11-19T06:02:32.772+0000","updated":"2012-11-19T06:02:32.772+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12511082/comment/13502607","id":"13502607","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=inder","name":"inder","key":"inder","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Inder SIngh","active":true,"timeZone":"Etc/UTC"},"body":"After looking at the code in detail i am wondering why do we need to do checkDiskError() for all IOExceptions in PacketResponder if it's JOB is to just send ACKS.\n\nConnection Reset By Peer, Interrupted Channel Exception are all types of IOException and should not causes checkDisk().\n\nWhat do you folks think about it?\n\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=inder","name":"inder","key":"inder","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Inder SIngh","active":true,"timeZone":"Etc/UTC"},"created":"2012-11-22T06:21:09.386+0000","updated":"2012-11-22T06:21:09.386+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12511082/comment/13510717","id":"13510717","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"body":"bq. Another approach would be to do the scanning without holding the volume lock - similar to how we now do block report gathering in branch-1 (HDFS-2379)\n\nI think this approach might be better.  Sometimes, flaky disks experience long I/O pauses, so it seems unwise in general to be holding an important lock while doing this kind of thing.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"created":"2012-12-05T19:44:48.372+0000","updated":"2012-12-05T19:44:48.372+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12511082/comment/13593673","id":"13593673","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rohit_kochar","name":"rohit_kochar","key":"rohit_kochar","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rohit Kochar","active":true,"timeZone":"Asia/Kolkata"},"body":"Even we have hit this issue in production.In our case most of checkDiskError() invocations are happening due to network related exceptions in BlockReciever$PacketResponder.run() and DataNode$DataTransfer.run().\nSince the current code has a common catch clause for all types of exceptions hence even for network related IO Exceptions chedkDiskError() in executed which lead to check storm thereby slowing the datanode.\n\nOne way to fix this could be to check in the catch clause that whether the class of exception belongs to \"java.net\" package and in those cases skip checking the disk.\n\nFolks,\nPlease suggest if you think that above mentioned fix is the right approach to go about.\nI can than submit the patch for this issue.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rohit_kochar","name":"rohit_kochar","key":"rohit_kochar","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rohit Kochar","active":true,"timeZone":"Asia/Kolkata"},"created":"2013-03-05T17:57:52.777+0000","updated":"2013-03-05T17:57:52.777+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12511082/comment/13597958","id":"13597958","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rohit_kochar","name":"rohit_kochar","key":"rohit_kochar","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rohit Kochar","active":true,"timeZone":"Asia/Kolkata"},"body":"This patch avoids running checkdisk when a socket timeout occurs or any other socket exception is thrown.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rohit_kochar","name":"rohit_kochar","key":"rohit_kochar","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rohit Kochar","active":true,"timeZone":"Asia/Kolkata"},"created":"2013-03-09T14:43:41.685+0000","updated":"2013-03-09T14:43:41.685+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12511082/comment/13597992","id":"13597992","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12572915/HDFS-2095.patch\n  against trunk revision .\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.\n                        Please justify why no new tests are needed for this patch.\n                        Also please list what manual steps were performed to verify this patch.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.\n\n    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/4065//testReport/\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/4065//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2013-03-09T16:26:19.731+0000","updated":"2013-03-09T16:26:19.731+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12511082/comment/13598543","id":"13598543","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rohit_kochar","name":"rohit_kochar","key":"rohit_kochar","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rohit Kochar","active":true,"timeZone":"Asia/Kolkata"},"body":"Since my patch only resolves part of this issues i.e invocation of checkDiskError on network related problems.\nHence creating a new jira for the same and submitting this patch there.\nNew jira: https://issues.apache.org/jira/browse/HDFS-4581","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rohit_kochar","name":"rohit_kochar","key":"rohit_kochar","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rohit Kochar","active":true,"timeZone":"Asia/Kolkata"},"created":"2013-03-11T05:06:18.767+0000","updated":"2013-03-11T05:06:18.767+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12511082/comment/13624114","id":"13624114","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"This seems to have been fully duplicated by HDFS-4581","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2013-04-05T22:02:22.052+0000","updated":"2013-04-05T22:02:22.052+0000"}],"maxResults":20,"total":20,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-2095/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i0jtvz:"}}