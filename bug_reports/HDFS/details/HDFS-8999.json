{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12861071","self":"https://issues.apache.org/jira/rest/api/2/issue/12861071","key":"HDFS-8999","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12329057","id":"12329057","description":"2.8.0 release","name":"2.8.0","archived":false,"released":true,"releaseDate":"2017-03-22"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12335732","id":"12335732","description":"3.0.0-alpha1 release","name":"3.0.0-alpha1","archived":false,"released":true,"releaseDate":"2016-09-03"}],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2015-09-01T20:46:18.469+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Wed Feb 03 02:15:22 UTC 2016","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_10181490838_*|*_5_*:*_1_*:*_0_*|*_10002_*:*_1_*:*_2639517810","customfield_12312321":null,"resolutiondate":"2016-01-28T02:45:19.700+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-8999/watchers","watchCount":31,"isWatching":false},"created":"2015-09-01T17:21:51.107+0000","customfield_12310192":null,"customfield_12310191":[{"self":"https://issues.apache.org/jira/rest/api/2/customFieldOption/10343","value":"Reviewed","id":"10343"}],"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"12.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[],"issuelinks":[{"id":"12436659","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12436659","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"inwardIssue":{"id":"12465184","key":"HDFS-1172","self":"https://issues.apache.org/jira/rest/api/2/issue/12465184","fields":{"summary":"Blocks in newly completed files are considered under-replicated too quickly","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12480199","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12480199","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"inwardIssue":{"id":"13000562","key":"HDFS-10810","self":"https://issues.apache.org/jira/rest/api/2/issue/13000562","fields":{"summary":" Setreplication removing block from underconstrcution temporarily when batch IBR is enabled.","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12460237","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12460237","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"inwardIssue":{"id":"12828061","key":"HDFS-8344","self":"https://issues.apache.org/jira/rest/api/2/issue/12828061","fields":{"summary":"NameNode doesn't recover lease for files with missing blocks","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/10002","description":"A patch for this issue has been uploaded to JIRA by a contributor.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/document.png","name":"Patch Available","id":"10002","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/4","id":4,"key":"indeterminate","colorName":"yellow","name":"In Progress"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12455577","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12455577","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"inwardIssue":{"id":"12934323","key":"HDFS-9710","self":"https://issues.apache.org/jira/rest/api/2/issue/12934323","fields":{"summary":"Change DN to send block receipt IBRs in batches","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/4","id":"4","description":"An improvement or enhancement to an existing feature or task.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype","name":"Improvement","subtask":false,"avatarId":21140}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2016-09-13T21:05:59.481+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12312926","id":"12312926","name":"namenode"}],"timeoriginalestimate":null,"description":"This comes out of a discussion in HDFS-8763. Pasting [~jingzhao]'s comment from the jira:\n\n{quote}\n...whether we need to let NameNode wait for all the block_received msgs to announce the replica is safe. Looking into the code, now we have\n\n   # NameNode knows the DataNodes involved when initially setting up the writing pipeline\n   # If any DataNode fails during the writing, client bumps the GS and finally reports all the DataNodes included in the new pipeline to NameNode through the updatePipeline RPC.\n   # When the client received the ack for the last packet of the block (and before the client tries to close the file on NameNode), the replica has been finalized in all the DataNodes.\n\nThen in this case, when NameNode receives the close request from the client, the NameNode already knows the latest replicas for the block. Currently the checkReplication call only counts in all the replicas that NN has already received the block_received msg, but based on the above #2 and #3, it may be safe to also count in all the replicas in the BlockUnderConstructionFeature#replicas?\n{quote}","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12779645","id":"12779645","filename":"h8999_20151228.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-12-28T13:33:09.509+0000","size":17989,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12779645/h8999_20151228.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12780573","id":"12780573","filename":"h8999_20160106.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-01-05T16:35:54.410+0000","size":25677,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12780573/h8999_20160106.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12780722","id":"12780722","filename":"h8999_20160106b.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-01-06T09:45:51.000+0000","size":27376,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12780722/h8999_20160106b.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12780748","id":"12780748","filename":"h8999_20160106c.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-01-06T12:55:21.829+0000","size":27394,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12780748/h8999_20160106c.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12781596","id":"12781596","filename":"h8999_20160111.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-01-11T16:47:26.936+0000","size":36438,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12781596/h8999_20160111.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12782093","id":"12782093","filename":"h8999_20160113.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-01-13T17:36:11.100+0000","size":38503,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12782093/h8999_20160113.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12782183","id":"12782183","filename":"h8999_20160114.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-01-14T02:35:35.863+0000","size":38060,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12782183/h8999_20160114.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12783589","id":"12783589","filename":"h8999_20160121.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-01-21T13:47:28.056+0000","size":37965,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12783589/h8999_20160121.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12783701","id":"12783701","filename":"h8999_20160121b.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jingzhao","name":"jingzhao","key":"jingzhao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jing Zhao","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-01-21T23:18:05.536+0000","size":36471,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12783701/h8999_20160121b.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12784804","id":"12784804","filename":"h8999_20160121c_branch-2.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-01-28T02:41:08.518+0000","size":34250,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12784804/h8999_20160121c_branch-2.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12784330","id":"12784330","filename":"h8999_20160121c_branch-2.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-01-26T03:15:49.646+0000","size":40964,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12784330/h8999_20160121c_branch-2.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12784314","id":"12784314","filename":"h8999_20160121c.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-01-26T02:28:06.032+0000","size":37774,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12784314/h8999_20160121c.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"Allow a file to be closed with COMMITTED but not yet COMPLETE blocks.","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jnp","name":"jnp","key":"jnp","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jitendra Nath Pandey","active":true,"timeZone":"Etc/UTC"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jnp","name":"jnp","key":"jnp","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jitendra Nath Pandey","active":true,"timeZone":"Etc/UTC"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12861071/comment/14726153","id":"14726153","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=daryn","name":"daryn","key":"daryn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Daryn Sharp","active":true,"timeZone":"America/Chicago"},"body":"I'd be interested in your thoughts on:  if we are going to trust the client, do we even need IBRs?  How do the failure modes change?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=daryn","name":"daryn","key":"daryn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Daryn Sharp","active":true,"timeZone":"America/Chicago"},"created":"2015-09-01T20:46:18.469+0000","updated":"2015-09-01T20:46:18.469+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12861071/comment/14726300","id":"14726300","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jingzhao","name":"jingzhao","key":"jingzhao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jing Zhao","active":true,"timeZone":"America/Los_Angeles"},"body":"bq. if we are going to trust the client, do we even need IBRs?\n\nYeah, I have the same question here. [~szetszwo] once mentioned the IBR actually could fix some data inconsistency. If we still need IBRs, can we change its sending mechanism from block-triggering to periodical?\n\nAlso currently we trust the client on the length of the file/block. In HDFS-8498 [~daryn] you mentioned you had seen this caused data corruption. Could you please provide more details about the corruption so that we can understand if we can really trust the client?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jingzhao","name":"jingzhao","key":"jingzhao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jing Zhao","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-09-01T22:12:18.309+0000","updated":"2015-09-01T22:12:18.309+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12861071/comment/14726445","id":"14726445","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"body":"The current logic as I remember it when it was designed way back:\n- Only the client can be trusted about the length of the block, because it knows how many bytes it pushed to the DNs.\n- DataNodes do not determine the length of the block, only the length of the replica in its possession. Because DNs do not sync replica data to disk, and because irresponsible users, or untrusted scripts, or bugs in local fs can damage replica files.\n- When the client allocates a new block or closes the file, it also confirms the length of the last written block. That block goes into COMMITTED state, but can still remain under-construction until minimal number of replicas are reported by DNs.\n- IBRs (via blockReceivedAndDeleted()) confirm that replicas actually exist on DNs and have the expected length.\n- The block needs to be COMMITTED and reported by the minimal number of DNs in order to go into COMPLETE state.\n\n[The append design document|https://issues.apache.org/jira/secure/attachment/12445209/appendDesign3.pdf] is somewhat outdated by now, but still gives a good idea how it was intended. Need to think more about this optimization proposal.\nIn general I'd leave the data pipeline alone (as a rather delicate subject) unless there is a clear bug.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-09-01T23:57:10.786+0000","updated":"2015-09-01T23:57:10.786+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12861071/comment/14727883","id":"14727883","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jingzhao","name":"jingzhao","key":"jingzhao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jing Zhao","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks for the comments, [~shv]. So one of the motivations for this simplification is to decrease the total number of messages sent from DNs to NN. Recently we saw in a real cluster because a large amount of writing was happening, the IBR from DNs finally overwhelmed NN and caused congestion of the RPC queue. Of course the main cause of the issue is that these writing generated a lot of small blocks and files. But towards improving HDFS's scalability and capability for handling small files, it may be worth exploring this optimization.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jingzhao","name":"jingzhao","key":"jingzhao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jing Zhao","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-09-02T19:24:53.022+0000","updated":"2015-09-02T19:24:53.022+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12861071/comment/14729407","id":"14729407","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=daryn","name":"daryn","key":"daryn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Daryn Sharp","active":true,"timeZone":"America/Chicago"},"body":"My rhetorical question to provoke thought was misunderstood.  I was not implying we should eliminate IBRs.  They do fix data inconsistency and ensure the NN stays in sync with the DNs state.  I would never rely on the client as an authoritative source of what's on a DN.\n\nbq. So one of the motivations for this simplification is to decrease the total number of messages sent from DNs to NN. Recently we saw in a real cluster because a large amount of writing was happening, the IBR from DNs finally overwhelmed NN and caused congestion of the RPC queue.\n\nHappens all the time.  Ironically I've been testing a patch to aggregate IBRs.  No pipeline or DN changes necessary.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=daryn","name":"daryn","key":"daryn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Daryn Sharp","active":true,"timeZone":"America/Chicago"},"created":"2015-09-03T17:11:16.218+0000","updated":"2015-09-03T17:11:16.218+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12861071/comment/14733172","id":"14733172","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"body":"Spent some time browsing jira. This issue was discussed earlier in HDFS-1172 (linking).\n# NN cannot rely on locations reported by the client (or a primary DN) because it leads to a race condition between the client report and block reports from the DN, that contains the replica. The block report may not contain the replica that was reported by the client. As noted in [Hairong's comment|https://issues.apache.org/jira/browse/HDFS-1172?focusedCommentId=12874030&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-12874030]\n# [~hairong] proposed a solution, which makes NN place replicas that were not yet reported by DNs into {{pendingReplication}} queue instead of {{neededRepication}}. This is absolutely logical, because NN knows that missing replicas were in the succeeded pipeline and can assume they will be reported soon.\n\nI don't know why HDFS-1172 was never committed. May be it is time to revisit it now.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-09-06T23:32:53.570+0000","updated":"2015-09-06T23:32:53.570+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12861071/comment/15060253","id":"15060253","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"body":"Well, HDFS-1172 is in.  If NN has an ability to correctly fix the locations based on IBRs and eventually using FBRs, it will be okay to not wait for IBRs before completing the block.\n\nAs for availability, a datanode can crash right after finalizing a block but before sending the IBR. But it could also crash right after sending the IBR. Timing-wise, the two are not very different. I don't think waiting for the IBR adds much value in this regard.\n\nFor correctness, we need to think about the new \"race\" between addBlock()/complete() from clients and IBRs from datanodes. E.g. there are places that ignore inconsistency while a block is under construction. It could create other issues especially when recovery is involved.  NN might incorrectly mark a replica as corrupt or have more locations than committed and do not know which are valid (this sometimes happens today).\n\nConceptually, namenode knows exactly where the replicas of an under-construction blocks are. If any of them changes, the client is supposed to call updatePipeline().  So, closing without waiting for IBRs seems reasonable.  However, the difficulty arises because the locations can change quickly by replication and balancing. I.e. namenode cannot reliably reject bogus locations. It has to record all reported locations whether it thinks they are corrupt or not.  When recoverClose() is involved, it can be even more confusing, as multiple IBRs with a different gen stamp comes from the datanode.  Namenode currently doesn't deal with this very well. It needs to be properly addressed before or with this JIRA.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"created":"2015-12-16T16:32:08.432+0000","updated":"2015-12-16T16:32:08.432+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12861071/comment/15064771","id":"15064771","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"body":"Kihwal, I did not understand exactly what you propose. But it seems that the following two of your statements contradict each other.\n- ??NN might incorrectly mark a replica as corrupt or have more locations than committed and do not know which are valid??\n- ??Conceptually, namenode knows exactly where the replicas of an under-construction blocks are.??\n\nI think the first is correct as NameNode knows only where the replicas should be, but never knows where they actually are at any given moment. And the same is with clients.\n\nI was talking about the following race condition. Suppose we let NN complete the block based on client locations, and it does. Then FBR comes from DN. The FBR could have been formed before the the replica was received by DN, and therefore will NOT contain the new replica. Because the block is complete, NN will _incorrectly_ remove the valid replica.\n\nI think HDFS-1172 fixed the problem with closing. The replications are not starting immediately, so DN's have a chance to IBR remaining replicas. If they don't, these replicas will eventually be moved from pendingReplication into neededReplication, and then replicated.\n\nDon't see any problems and don't think anything needs to be done here?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-12-18T21:13:27.127+0000","updated":"2015-12-18T21:13:27.127+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12861071/comment/15064975","id":"15064975","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jnp","name":"jnp","key":"jnp","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jitendra Nath Pandey","active":true,"timeZone":"Etc/UTC"},"body":"[~shv], the goal of this jira is to allow closing the files without waiting for IBRs from DN. This will also reduce the pressure on DNs to quickly send {{blockReceived}} messages, and allow sending IBRs at longer intervals to reduce the number of RPCs to NN. As mentioned by [~jingzhao] in an earlier comment, it has been observed in real clusters where IBRs overwhelmed the NN and clients failed to close the files.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jnp","name":"jnp","key":"jnp","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jitendra Nath Pandey","active":true,"timeZone":"Etc/UTC"},"created":"2015-12-18T23:40:46.126+0000","updated":"2015-12-18T23:40:46.126+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12861071/comment/15065088","id":"15065088","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jingzhao","name":"jingzhao","key":"jingzhao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jing Zhao","active":true,"timeZone":"America/Los_Angeles"},"body":"To allow the client to close the file without waiting for IBR, and to fix the race condition mentioned by [~shv], we may have to add some extra information on NN to identify replicas that have only been reported by the client but have been confirmed by the DataNodes. These replicas can be treated the same as the current expected replicas of a committed block.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jingzhao","name":"jingzhao","key":"jingzhao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jing Zhao","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-12-19T00:51:53.737+0000","updated":"2015-12-19T00:51:53.737+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12861071/comment/15065165","id":"15065165","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"body":">  the goal of this jira is to allow closing the files without waiting for IBRs from DN.\n\nWhy? Here are some arguments against doing it:\n\n# _NN only waits for one replica_, then it can close the file. Before HDFS-1172 the problem was, that NN would immediately start replicating the block without waiting for remaining IBRs. This overwhelmed NN even more. HDFS-1172 solved it by placing replicas are in pendingReplication, so DNs have more time to IBR.\n# If 1 is too much, _one can cause immediate close of a file by setting minimum replication to 0_ instead of default 1. It is a configuration change, no need for code changes.\n# _Client can only be trusted to report replica length, but not its locations._ NN and clients know only where replicas should be, but not where they are. NN trusting clients about locations is an induced knowledge, more like in gossip protocols.\n# _Race condition between client and FBR reporting._ Why should one deal with this and potentially other races, which we haven't thought about yet, if it works as is.\n# _Delaying IBRs, will not solve the NN overwhelming problem._ People will just add more DNs, and the problem comes back.\nNN limits HDFS scalability, everybody knows it, just keep your scale right.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-12-19T02:23:20.147+0000","updated":"2015-12-19T02:23:20.147+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12861071/comment/15067293","id":"15067293","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jnp","name":"jnp","key":"jnp","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jitendra Nath Pandey","active":true,"timeZone":"Etc/UTC"},"body":" The clients do know the data pipeline and so does the NN. Therefore, at the instant pipeline closes, client and NN know the location of the blocks. The blocks can move anywhere afterwards, but that is no worse than a DN sending an IBR, but loosing the block immediately afterwards.\n\n  Every system has certain scalability limits, but if a design choice can push the limit a bit higher, its not a bad idea to explore. The problems will come back with more writers and more DNs, but at least at a higher level of scale.\n\n Agreed, we need a solution to the race condition, the direction that [~jingzhao] mentioned in his last comment, seems promising.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jnp","name":"jnp","key":"jnp","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jitendra Nath Pandey","active":true,"timeZone":"Etc/UTC"},"created":"2015-12-22T00:01:56.687+0000","updated":"2015-12-22T00:01:56.687+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12861071/comment/15067675","id":"15067675","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"body":"> 4. Race condition between client and FBR reporting. ...\n\nIf the block is kept in the COMMIT state, then there is no race condition (since there is no change compared with the current implementation.)\n\nIn this JIRA, we may change the code to allow closing a file even if the last block is in COMMIT state.  When a reader try to read the last block of the file, NN responses all the stored locations.  Do you see any problem in this scheme?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-12-22T07:21:34.243+0000","updated":"2015-12-22T07:21:34.243+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12861071/comment/15067679","id":"15067679","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"body":"> ... we may change the code to allow closing a file even if the last block is in COMMIT state. ...\n\nIn order to avoid data loss of closed files, we are better to allow it only when the number of replicas is greater than 1.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-12-22T07:25:02.876+0000","updated":"2015-12-22T07:25:02.876+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12861071/comment/15068676","id":"15068676","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"body":"Before commenting on suggested solutions let me ask the following questions:\n# Has anybody tried to run the same workload on the same size cluster with a version of HDFS that has HDFS-1172 in it?\nAgain, HDFS-1172 reduced the replication load on NN in extreme case (1-block files) by a factor of at least 2. Did it help?\n# Has anybody tried to set minimum replication to 0 on the same size cluster? Did it help?\nAsking this, because it is easy to change configuration, while the performance will be the same as with the discussed proposal.\nSo if the config change doesn't help the proposed change won't help either.\n# Does anybody have material estimates on scalability gains with this fix?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-12-22T20:24:12.888+0000","updated":"2015-12-22T20:24:12.888+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12861071/comment/15072691","id":"15072691","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi [~shv], we did see a huge number of block receipts which eventually slowed down NN in some clusters.  Therefore, we would like to reduce the block receipt RPCs.\n\nI suggest that we change the code to allow closing a file even if the last block is in COMMITTED state in this JIRA and then change DN to send IBRs in batches in another JIRA.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-12-28T12:50:10.800+0000","updated":"2015-12-28T12:50:10.800+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12861071/comment/15072721","id":"15072721","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"body":"h8999_20151228.patch: allow file to be closed if the last block is COMMITTED.\n\nThe patch is not ready yet.  Just want to run tests on it.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-12-28T13:33:09.513+0000","updated":"2015-12-28T13:33:09.513+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12861071/comment/15072854","id":"15072854","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 0s {color} | {color:blue} Docker mode activated. {color} |\n| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green} 0m 0s {color} | {color:green} The patch appears to include 3 new or modified test files. {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 8m 54s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 0m 47s {color} | {color:green} trunk passed with JDK v1.8.0_66 {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 0m 47s {color} | {color:green} trunk passed with JDK v1.7.0_91 {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 17s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 0m 59s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 15s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 1m 53s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 5s {color} | {color:green} trunk passed with JDK v1.8.0_66 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 46s {color} | {color:green} trunk passed with JDK v1.7.0_91 {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 0m 44s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 0m 35s {color} | {color:green} the patch passed with JDK v1.8.0_66 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 0m 35s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 0m 38s {color} | {color:green} the patch passed with JDK v1.7.0_91 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 0m 38s {color} | {color:green} the patch passed {color} |\n| {color:red}-1{color} | {color:red} checkstyle {color} | {color:red} 0m 15s {color} | {color:red} Patch generated 2 new checkstyle issues in hadoop-hdfs-project/hadoop-hdfs (total was 498, now 496). {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 0m 48s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 11s {color} | {color:green} the patch passed {color} |\n| {color:red}-1{color} | {color:red} whitespace {color} | {color:red} 0m 0s {color} | {color:red} The patch has 1 line(s) that end in whitespace. Use git apply --whitespace=fix. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 1m 59s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 2s {color} | {color:green} the patch passed with JDK v1.8.0_66 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 41s {color} | {color:green} the patch passed with JDK v1.7.0_91 {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 61m 28s {color} | {color:red} hadoop-hdfs in the patch failed with JDK v1.8.0_66. {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 61m 5s {color} | {color:red} hadoop-hdfs in the patch failed with JDK v1.7.0_91. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green} 0m 21s {color} | {color:green} Patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black} 150m 7s {color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| JDK v1.8.0_66 Failed junit tests | hadoop.hdfs.TestBlocksScheduledCounter |\n|   | hadoop.hdfs.TestMissingBlocksAlert |\n|   | hadoop.hdfs.TestFileAppend2 |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure160 |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure110 |\n|   | hadoop.hdfs.TestAppendDifferentChecksum |\n| JDK v1.7.0_91 Failed junit tests | hadoop.hdfs.TestDFSClientExcludedNodes |\n|   | hadoop.hdfs.TestRollingUpgrade |\n|   | hadoop.hdfs.server.balancer.TestBalancerWithMultipleNameNodes |\n|   | hadoop.hdfs.TestAppendDifferentChecksum |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:0ca8df7 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12779645/h8999_20151228.patch |\n| JIRA Issue | HDFS-8999 |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux a45508b99c22 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / a0249da |\n| Default Java | 1.7.0_91 |\n| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_66 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_91 |\n| findbugs | v3.0.0 |\n| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/14000/artifact/patchprocess/diff-checkstyle-hadoop-hdfs-project_hadoop-hdfs.txt |\n| whitespace | https://builds.apache.org/job/PreCommit-HDFS-Build/14000/artifact/patchprocess/whitespace-eol.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/14000/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.8.0_66.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/14000/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.7.0_91.txt |\n| unit test logs |  https://builds.apache.org/job/PreCommit-HDFS-Build/14000/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.8.0_66.txt https://builds.apache.org/job/PreCommit-HDFS-Build/14000/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.7.0_91.txt |\n| JDK v1.7.0_91  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/14000/testReport/ |\n| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |\n| Max memory used | 75MB |\n| Powered by | Apache Yetus 0.2.0-SNAPSHOT   http://yetus.apache.org |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/14000/console |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2015-12-28T16:08:52.706+0000","updated":"2015-12-28T16:08:52.706+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12861071/comment/15073339","id":"15073339","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"body":"What is \"the block receipt RPC\"? Which RPC is that?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-12-29T01:18:14.101+0000","updated":"2015-12-29T01:18:14.101+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12861071/comment/15073432","id":"15073432","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"body":"It is the blockReceivedAndDeleted RPC, aka IBR.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-12-29T03:35:30.910+0000","updated":"2015-12-29T03:35:30.910+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12861071/comment/15074148","id":"15074148","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"body":"Thought so. But\n# The IBR problem is solved by HDFS-1172. That is why I am asking if anybody tried it to confirm.\n# Here you are optimizing completeBlock(), not IBR, which I don't know how substantial it is, if at all.\n\nIs my reasoning understood?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-12-29T18:36:43.481+0000","updated":"2015-12-29T18:36:43.481+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12861071/comment/15074407","id":"15074407","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jingzhao","name":"jingzhao","key":"jingzhao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jing Zhao","active":true,"timeZone":"America/Los_Angeles"},"body":"bq. Here you are optimizing completeBlock(), not IBR, which I don't know how substantial it is, if at all.\n\nbq. I suggest that we change the code to allow closing a file even if the last block is in COMMITTED state in this JIRA and then change DN to send IBRs in batches in another JIRA.\n\nI think Nicholas's comment has summarized our final goal: to decrease the total number of IBR. Currently writing a block with 3 replicas can easily generate >6 RPCs, which greatly limits the scalability of HDFS handling small files. We should explore if we can batch IBR and let DN send them periodically. The first step will be breaking the dependency between {{completeFile}} and IBR.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jingzhao","name":"jingzhao","key":"jingzhao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jing Zhao","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-12-29T23:12:56.530+0000","updated":"2015-12-29T23:12:56.530+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12861071/comment/15074573","id":"15074573","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"body":"> 1. The IBR problem is solved by HDFS-1172. That is why I am asking if anybody tried it to confirm.\n\nIt did not reduce the number of IBR RPCs which is the problem we are trying to solve here today.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-12-30T02:50:28.403+0000","updated":"2015-12-30T02:50:28.403+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12861071/comment/15075180","id":"15075180","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=walter.k.su","name":"walter.k.su","key":"walter.k.su","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Walter Su","active":true,"timeZone":"Asia/Shanghai"},"body":"Suppose client writes 3 files sequentially (files are related and must be write in order):\nf0b0, f0b1, f0b2, f0b3, f1b0, f2b0\nThen\nadding f0b2 will wait f0b0 completed,\nadding f0b3 will wait f0b1 completed,\nadding f1b0 won't wait f0b3\nadding f2b0 won't wait f1b0\n\nIs it strange? If we gonna do this, does it mean {{addBlock(..)}} can apply the same change?\nIf block size is small or client writes lots of small files, we have lots of committed blocks. And, what's the meaning of \"minRepl\"? Why we need \"committed\" and \"completed\"? The whole point is to let client know the data is safe so it can continue.\nI don't worry about safety since acked empty_last_packet means block files are flushed/closed and is safe in DNs, it's just not reported.\nAgreed race condition mentioned by Konstantin Shvachko is possible.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=walter.k.su","name":"walter.k.su","key":"walter.k.su","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Walter Su","active":true,"timeZone":"Asia/Shanghai"},"created":"2015-12-30T16:39:34.720+0000","updated":"2015-12-30T16:39:34.720+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12861071/comment/15083176","id":"15083176","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"body":"> Is it strange? If we gonna do this, does it mean addBlock(..) can apply the same change?\n\n[~walter.k.su], your example is interesting.  As you mentioned, addBlock(..) waits for the second-last block.  close() still waits for the second-last block.  Two methods are the same in this sense.\n\nIndeed, we may change addBlock(..) to wait for the third-last block.  However, we don't see a need for the moment.\n\n> If block size is small or client writes lots of small files, we have lots of committed blocks. ...\n\nWithin a short period of time, it is correct that we have a lot of committed blocks.  This is the problem we try to solve here -- datanode send an accumulated block receipt instead of a block receipt for each block within a short period of time in order to reduce the number of RPCs to NN.\n\n> ... And, what's the meaning of \"minRepl\"? Why we need \"committed\" and \"completed\"? ...\n\nHistorically, the notion of minRepl existed before we introduced the notions of COMMITTED and COMPLETE blocks for append.  These two states are still useful for append after the change.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-01-05T14:59:45.183+0000","updated":"2016-01-05T14:59:45.183+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12861071/comment/15083331","id":"15083331","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"body":"h8999_20160106.patch:\n- When closing a file with the last block COMMITTED, make sure getNumExpectedLocations() > 1.\n- When appending to a file with the last block COMMITTED, throw LastBlockNotYetCompleteException (a new exception).  Client will retry for a few seconds.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-01-05T16:35:54.414+0000","updated":"2016-01-05T16:35:54.414+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12861071/comment/15083624","id":"15083624","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 0s {color} | {color:blue} Docker mode activated. {color} |\n| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green} 0m 0s {color} | {color:green} The patch appears to include 3 new or modified test files. {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 7m 48s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 2m 1s {color} | {color:green} trunk passed with JDK v1.8.0_66 {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 1m 36s {color} | {color:green} trunk passed with JDK v1.7.0_91 {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 28s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 25s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 26s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 3m 41s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 26s {color} | {color:green} trunk passed with JDK v1.8.0_66 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 2m 11s {color} | {color:green} trunk passed with JDK v1.7.0_91 {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 1m 16s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 1m 25s {color} | {color:green} the patch passed with JDK v1.8.0_66 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 1m 25s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 1m 35s {color} | {color:green} the patch passed with JDK v1.7.0_91 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 1m 35s {color} | {color:green} the patch passed {color} |\n| {color:red}-1{color} | {color:red} checkstyle {color} | {color:red} 0m 28s {color} | {color:red} Patch generated 4 new checkstyle issues in hadoop-hdfs-project (total was 633, now 632). {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 22s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 21s {color} | {color:green} the patch passed {color} |\n| {color:red}-1{color} | {color:red} whitespace {color} | {color:red} 0m 0s {color} | {color:red} The patch has 2 line(s) that end in whitespace. Use git apply --whitespace=fix. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 4m 13s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 18s {color} | {color:green} the patch passed with JDK v1.8.0_66 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 2m 12s {color} | {color:green} the patch passed with JDK v1.7.0_91 {color} |\n| {color:green}+1{color} | {color:green} unit {color} | {color:green} 1m 1s {color} | {color:green} hadoop-hdfs-client in the patch passed with JDK v1.8.0_66. {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 68m 46s {color} | {color:red} hadoop-hdfs in the patch failed with JDK v1.8.0_66. {color} |\n| {color:green}+1{color} | {color:green} unit {color} | {color:green} 0m 56s {color} | {color:green} hadoop-hdfs-client in the patch passed with JDK v1.7.0_91. {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 66m 36s {color} | {color:red} hadoop-hdfs in the patch failed with JDK v1.7.0_91. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green} 0m 22s {color} | {color:green} Patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black} 175m 57s {color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| JDK v1.8.0_66 Failed junit tests | hadoop.hdfs.TestBlockStoragePolicy |\n|   | hadoop.hdfs.security.TestDelegationTokenForProxyUser |\n|   | hadoop.hdfs.server.namenode.TestINodeAttributeProvider |\n|   | hadoop.hdfs.server.namenode.TestFSImageWithSnapshot |\n| JDK v1.7.0_91 Failed junit tests | hadoop.hdfs.server.datanode.TestDiskError |\n|   | hadoop.hdfs.server.balancer.TestBalancer |\n|   | hadoop.hdfs.server.namenode.snapshot.TestSnapshot |\n|   | hadoop.hdfs.server.namenode.ha.TestFailureToReadEdits |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure110 |\n|   | hadoop.hdfs.TestFileStatus |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:0ca8df7 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12780573/h8999_20160106.patch |\n| JIRA Issue | HDFS-8999 |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux fd589ee144b6 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / 96d8f1d |\n| Default Java | 1.7.0_91 |\n| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_66 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_91 |\n| findbugs | v3.0.0 |\n| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/14029/artifact/patchprocess/diff-checkstyle-hadoop-hdfs-project.txt |\n| whitespace | https://builds.apache.org/job/PreCommit-HDFS-Build/14029/artifact/patchprocess/whitespace-eol.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/14029/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.8.0_66.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/14029/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.7.0_91.txt |\n| unit test logs |  https://builds.apache.org/job/PreCommit-HDFS-Build/14029/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.8.0_66.txt https://builds.apache.org/job/PreCommit-HDFS-Build/14029/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.7.0_91.txt |\n| JDK v1.7.0_91  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/14029/testReport/ |\n| modules | C: hadoop-hdfs-project/hadoop-hdfs hadoop-hdfs-project/hadoop-hdfs-client U: hadoop-hdfs-project |\n| Max memory used | 76MB |\n| Powered by | Apache Yetus 0.2.0-SNAPSHOT   http://yetus.apache.org |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/14029/console |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2016-01-05T19:34:32.297+0000","updated":"2016-01-05T19:34:32.297+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12861071/comment/15084058","id":"15084058","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jingzhao","name":"jingzhao","key":"jingzhao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jing Zhao","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks for the patch, [~szetszwo]! The patch looks good to me. Comments and question:\n# AccessControlException is for security, thus instead of extending it, it's better to let LastBlockNotYetCompleteException extend IOException, or even RetriableException if we want to enable retry for client?\n# Should we be more aggressive and allow all the blocks to be in committed state? Otherwise we will still have issue when IBRs are sent periodically.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jingzhao","name":"jingzhao","key":"jingzhao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jing Zhao","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-01-05T23:34:23.497+0000","updated":"2016-01-05T23:34:23.497+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12861071/comment/15084414","id":"15084414","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jingzhao","name":"jingzhao","key":"jingzhao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jing Zhao","active":true,"timeZone":"America/Los_Angeles"},"body":"Another question is whether we should update the new logic from HDFS-1172 and HDFS-9535. In HDFS-1172, we add the replica to the pending queue only when there are already >=1 live replicas. Now since the client can close the file without waiting for the IBR, we will add the block into the UnderReplicated queue with {{QUEUE_WITH_CORRUPT_BLOCKS}} priority. I think maybe we should still put the block into the pending queue in this scenario.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jingzhao","name":"jingzhao","key":"jingzhao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jing Zhao","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-01-06T00:08:49.560+0000","updated":"2016-01-06T00:08:49.560+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12861071/comment/15085316","id":"15085316","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"body":"> 2. Should we be more aggressive and allow all the blocks to be in committed state? Otherwise we will still have issue when IBRs are sent periodically.\n\nLet's test with the last block to see if it already solves the problem.  I hesitates to be so aggressive.\n\nFor addBlock, I think it is okay since it waits for the second-last block (not the last block).  The client has to take time to write a full block so that there should be enough time for the block receipts to come.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-01-06T09:44:09.483+0000","updated":"2016-01-06T09:44:09.483+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12861071/comment/15085322","id":"15085322","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"body":"h8999_20160106b.patch: addresses Jing's comment.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-01-06T09:45:51.011+0000","updated":"2016-01-06T09:45:51.011+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12861071/comment/15085482","id":"15085482","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 0s {color} | {color:blue} Docker mode activated. {color} |\n| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green} 0m 0s {color} | {color:green} The patch appears to include 3 new or modified test files. {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 7m 54s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 1m 35s {color} | {color:green} trunk passed with JDK v1.8.0_66 {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 1m 38s {color} | {color:green} trunk passed with JDK v1.7.0_91 {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 31s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 29s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 26s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 3m 52s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 28s {color} | {color:green} trunk passed with JDK v1.8.0_66 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 2m 13s {color} | {color:green} trunk passed with JDK v1.7.0_91 {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 1m 19s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 1m 36s {color} | {color:green} the patch passed with JDK v1.8.0_66 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 1m 36s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 1m 38s {color} | {color:green} the patch passed with JDK v1.7.0_91 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 1m 38s {color} | {color:green} the patch passed {color} |\n| {color:red}-1{color} | {color:red} checkstyle {color} | {color:red} 0m 29s {color} | {color:red} Patch generated 4 new checkstyle issues in hadoop-hdfs-project (total was 633, now 632). {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 24s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 22s {color} | {color:green} the patch passed {color} |\n| {color:red}-1{color} | {color:red} whitespace {color} | {color:red} 0m 0s {color} | {color:red} The patch has 3 line(s) that end in whitespace. Use git apply --whitespace=fix. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 4m 5s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 25s {color} | {color:green} the patch passed with JDK v1.8.0_66 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 2m 10s {color} | {color:green} the patch passed with JDK v1.7.0_91 {color} |\n| {color:green}+1{color} | {color:green} unit {color} | {color:green} 0m 50s {color} | {color:green} hadoop-hdfs-client in the patch passed with JDK v1.8.0_66. {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 55m 44s {color} | {color:red} hadoop-hdfs in the patch failed with JDK v1.8.0_66. {color} |\n| {color:green}+1{color} | {color:green} unit {color} | {color:green} 0m 54s {color} | {color:green} hadoop-hdfs-client in the patch passed with JDK v1.7.0_91. {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 55m 4s {color} | {color:red} hadoop-hdfs in the patch failed with JDK v1.7.0_91. {color} |\n| {color:red}-1{color} | {color:red} asflicense {color} | {color:red} 0m 19s {color} | {color:red} Patch generated 1 ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black} 151m 15s {color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| JDK v1.8.0_66 Failed junit tests | hadoop.hdfs.TestModTime |\n|   | hadoop.hdfs.server.namenode.TestFSEditLogLoader |\n|   | hadoop.hdfs.server.namenode.TestFileContextAcl |\n|   | hadoop.hdfs.TestErasureCodingPolicies |\n|   | hadoop.hdfs.TestPread |\n|   | hadoop.fs.contract.hdfs.TestHDFSContractOpen |\n|   | hadoop.hdfs.TestFileStatus |\n|   | hadoop.fs.contract.hdfs.TestHDFSContractAppend |\n|   | hadoop.hdfs.server.namenode.ha.TestBootstrapStandby |\n|   | hadoop.hdfs.server.datanode.TestBlockReplacement |\n|   | hadoop.hdfs.server.namenode.snapshot.TestSnapshotBlocksMap |\n|   | hadoop.hdfs.server.blockmanagement.TestNodeCount |\n|   | hadoop.hdfs.server.datanode.TestHSync |\n|   | hadoop.fs.contract.hdfs.TestHDFSContractSeek |\n|   | hadoop.hdfs.server.namenode.TestFSImageWithXAttr |\n|   | hadoop.hdfs.server.namenode.TestFSImageWithAcl |\n|   | hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA |\n|   | hadoop.hdfs.server.namenode.snapshot.TestAclWithSnapshot |\n|   | hadoop.hdfs.server.namenode.TestNameNodeMXBean |\n|   | hadoop.hdfs.TestDFSOutputStream |\n|   | hadoop.hdfs.TestDFSPermission |\n|   | hadoop.hdfs.TestEncryptionZonesWithKMS |\n|   | hadoop.hdfs.server.namenode.TestINodeFile |\n|   | hadoop.hdfs.TestSetTimes |\n|   | hadoop.hdfs.server.namenode.TestNamenodeRetryCache |\n|   | hadoop.hdfs.TestHDFSFileSystemContract |\n|   | hadoop.hdfs.TestEncryptionZones |\n|   | hadoop.hdfs.TestAppendDifferentChecksum |\n|   | hadoop.hdfs.TestFileAppend2 |\n|   | hadoop.hdfs.TestAppendSnapshotTruncate |\n|   | hadoop.hdfs.server.namenode.TestEditLog |\n|   | hadoop.hdfs.TestFileStatusWithECPolicy |\n|   | hadoop.hdfs.TestWriteReadStripedFile |\n|   | hadoop.hdfs.TestQuota |\n|   | hadoop.hdfs.tools.offlineEditsViewer.TestOfflineEditsViewer |\n|   | hadoop.hdfs.TestDFSStripedOutputStream |\n|   | hadoop.hdfs.server.namenode.ha.TestStandbyIsHot |\n|   | hadoop.fs.contract.hdfs.TestHDFSContractConcat |\n|   | hadoop.fs.contract.hdfs.TestHDFSContractRootDirectory |\n|   | hadoop.hdfs.TestHFlush |\n|   | hadoop.hdfs.TestBlockStoragePolicy |\n|   | hadoop.hdfs.server.namenode.snapshot.TestSnapshotFileLength |\n|   | hadoop.hdfs.TestFileCreation |\n|   | hadoop.hdfs.server.namenode.ha.TestXAttrsWithHA |\n|   | hadoop.hdfs.server.namenode.TestFSImageWithSnapshot |\n|   | hadoop.hdfs.TestDFSShell |\n|   | hadoop.fs.TestHDFSFileContextMainOperations |\n|   | hadoop.fs.TestGlobPaths |\n|   | hadoop.hdfs.server.namenode.ha.TestHarFileSystemWithHA |\n|   | hadoop.hdfs.TestDistributedFileSystem |\n|   | hadoop.hdfs.server.namenode.TestNameNodeAcl |\n|   | hadoop.cli.TestHDFSCLI |\n|   | hadoop.hdfs.TestReplaceDatanodeOnFailure |\n|   | hadoop.hdfs.server.namenode.TestFavoredNodesEndToEnd |\n|   | hadoop.hdfs.server.namenode.TestFSImage |\n| JDK v1.8.0_66 Timed out junit tests | org.apache.hadoop.hdfs.server.namenode.TestNNThroughputBenchmark |\n| JDK v1.7.0_91 Failed junit tests | hadoop.hdfs.TestModTime |\n|   | hadoop.hdfs.server.namenode.TestFSEditLogLoader |\n|   | hadoop.hdfs.server.namenode.TestFileContextAcl |\n|   | hadoop.hdfs.TestErasureCodingPolicies |\n|   | hadoop.hdfs.TestPread |\n|   | hadoop.fs.contract.hdfs.TestHDFSContractOpen |\n|   | hadoop.hdfs.TestFileStatus |\n|   | hadoop.fs.contract.hdfs.TestHDFSContractAppend |\n|   | hadoop.hdfs.server.namenode.ha.TestBootstrapStandby |\n|   | hadoop.hdfs.server.namenode.snapshot.TestSnapshotBlocksMap |\n|   | hadoop.hdfs.server.blockmanagement.TestNodeCount |\n|   | hadoop.hdfs.server.datanode.TestHSync |\n|   | hadoop.fs.contract.hdfs.TestHDFSContractSeek |\n|   | hadoop.hdfs.server.namenode.TestFSImageWithXAttr |\n|   | hadoop.hdfs.server.namenode.TestFSImageWithAcl |\n|   | hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA |\n|   | hadoop.hdfs.server.namenode.snapshot.TestAclWithSnapshot |\n|   | hadoop.hdfs.server.namenode.TestNameNodeMXBean |\n|   | hadoop.hdfs.TestDFSOutputStream |\n|   | hadoop.hdfs.TestDFSPermission |\n|   | hadoop.hdfs.TestEncryptionZonesWithKMS |\n|   | hadoop.hdfs.TestCrcCorruption |\n|   | hadoop.hdfs.server.namenode.TestINodeFile |\n|   | hadoop.hdfs.TestSetTimes |\n|   | hadoop.hdfs.server.namenode.TestNamenodeRetryCache |\n|   | hadoop.hdfs.TestHDFSFileSystemContract |\n|   | hadoop.hdfs.TestEncryptionZones |\n|   | hadoop.hdfs.TestAppendDifferentChecksum |\n|   | hadoop.hdfs.TestFileAppend2 |\n|   | hadoop.hdfs.TestAppendSnapshotTruncate |\n|   | hadoop.hdfs.server.namenode.TestEditLog |\n|   | hadoop.hdfs.TestFileStatusWithECPolicy |\n|   | hadoop.hdfs.TestWriteReadStripedFile |\n|   | hadoop.hdfs.TestQuota |\n|   | hadoop.hdfs.tools.offlineEditsViewer.TestOfflineEditsViewer |\n|   | hadoop.hdfs.TestDFSStripedOutputStream |\n|   | hadoop.hdfs.server.namenode.ha.TestStandbyIsHot |\n|   | hadoop.fs.contract.hdfs.TestHDFSContractConcat |\n|   | hadoop.fs.contract.hdfs.TestHDFSContractRootDirectory |\n|   | hadoop.hdfs.TestHFlush |\n|   | hadoop.hdfs.TestBlockStoragePolicy |\n|   | hadoop.hdfs.server.namenode.snapshot.TestSnapshotFileLength |\n|   | hadoop.hdfs.TestFileCreation |\n|   | hadoop.hdfs.server.namenode.ha.TestXAttrsWithHA |\n|   | hadoop.hdfs.server.namenode.TestFSImageWithSnapshot |\n|   | hadoop.hdfs.TestDFSShell |\n|   | hadoop.fs.TestHDFSFileContextMainOperations |\n|   | hadoop.fs.TestGlobPaths |\n|   | hadoop.hdfs.server.namenode.ha.TestHarFileSystemWithHA |\n|   | hadoop.hdfs.TestDistributedFileSystem |\n|   | hadoop.hdfs.server.namenode.TestNameNodeAcl |\n|   | hadoop.cli.TestHDFSCLI |\n|   | hadoop.hdfs.TestReplaceDatanodeOnFailure |\n|   | hadoop.hdfs.server.namenode.TestFavoredNodesEndToEnd |\n|   | hadoop.hdfs.server.namenode.TestFSImage |\n| JDK v1.7.0_91 Timed out junit tests | org.apache.hadoop.hdfs.server.namenode.TestNNThroughputBenchmark |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:0ca8df7 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12780722/h8999_20160106b.patch |\n| JIRA Issue | HDFS-8999 |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux 434db39bf81c 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / 2d16f40 |\n| Default Java | 1.7.0_91 |\n| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_66 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_91 |\n| findbugs | v3.0.0 |\n| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/14041/artifact/patchprocess/diff-checkstyle-hadoop-hdfs-project.txt |\n| whitespace | https://builds.apache.org/job/PreCommit-HDFS-Build/14041/artifact/patchprocess/whitespace-eol.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/14041/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.8.0_66.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/14041/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.7.0_91.txt |\n| unit test logs |  https://builds.apache.org/job/PreCommit-HDFS-Build/14041/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.8.0_66.txt https://builds.apache.org/job/PreCommit-HDFS-Build/14041/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.7.0_91.txt |\n| JDK v1.7.0_91  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/14041/testReport/ |\n| asflicense | https://builds.apache.org/job/PreCommit-HDFS-Build/14041/artifact/patchprocess/patch-asflicense-problems.txt |\n| modules | C: hadoop-hdfs-project/hadoop-hdfs hadoop-hdfs-project/hadoop-hdfs-client U: hadoop-hdfs-project |\n| Max memory used | 75MB |\n| Powered by | Apache Yetus 0.2.0-SNAPSHOT   http://yetus.apache.org |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/14041/console |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2016-01-06T12:19:50.652+0000","updated":"2016-01-06T12:19:50.652+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12861071/comment/15085505","id":"15085505","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"body":"h8999_20160106c.patch: fixes a NPE.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-01-06T12:55:21.833+0000","updated":"2016-01-06T12:55:21.833+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12861071/comment/15085715","id":"15085715","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 0s {color} | {color:blue} Docker mode activated. {color} |\n| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green} 0m 0s {color} | {color:green} The patch appears to include 3 new or modified test files. {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 7m 28s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 1m 28s {color} | {color:green} trunk passed with JDK v1.8.0_66 {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 1m 34s {color} | {color:green} trunk passed with JDK v1.7.0_91 {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 29s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 24s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 27s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 3m 46s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 27s {color} | {color:green} trunk passed with JDK v1.8.0_66 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 2m 20s {color} | {color:green} trunk passed with JDK v1.7.0_91 {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 1m 24s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 1m 34s {color} | {color:green} the patch passed with JDK v1.8.0_66 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 1m 34s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 1m 37s {color} | {color:green} the patch passed with JDK v1.7.0_91 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 1m 37s {color} | {color:green} the patch passed {color} |\n| {color:red}-1{color} | {color:red} checkstyle {color} | {color:red} 0m 30s {color} | {color:red} Patch generated 4 new checkstyle issues in hadoop-hdfs-project (total was 633, now 632). {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 24s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 21s {color} | {color:green} the patch passed {color} |\n| {color:red}-1{color} | {color:red} whitespace {color} | {color:red} 0m 0s {color} | {color:red} The patch has 3 line(s) that end in whitespace. Use git apply --whitespace=fix. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 4m 10s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 20s {color} | {color:green} the patch passed with JDK v1.8.0_66 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 2m 6s {color} | {color:green} the patch passed with JDK v1.7.0_91 {color} |\n| {color:green}+1{color} | {color:green} unit {color} | {color:green} 0m 51s {color} | {color:green} hadoop-hdfs-client in the patch passed with JDK v1.8.0_66. {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 68m 33s {color} | {color:red} hadoop-hdfs in the patch failed with JDK v1.8.0_66. {color} |\n| {color:green}+1{color} | {color:green} unit {color} | {color:green} 0m 55s {color} | {color:green} hadoop-hdfs-client in the patch passed with JDK v1.7.0_91. {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 66m 16s {color} | {color:red} hadoop-hdfs in the patch failed with JDK v1.7.0_91. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green} 0m 21s {color} | {color:green} Patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black} 174m 43s {color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| JDK v1.8.0_66 Failed junit tests | hadoop.hdfs.server.namenode.TestNameNodeMetadataConsistency |\n|   | hadoop.hdfs.server.blockmanagement.TestBlockManager |\n|   | hadoop.hdfs.server.namenode.snapshot.TestSnapshotFileLength |\n|   | hadoop.hdfs.TestAclsEndToEnd |\n|   | hadoop.hdfs.server.namenode.TestNamenodeCapacityReport |\n|   | hadoop.hdfs.server.namenode.ha.TestStandbyIsHot |\n|   | hadoop.fs.viewfs.TestViewFileSystemHdfs |\n| JDK v1.7.0_91 Failed junit tests | hadoop.hdfs.TestBlockStoragePolicy |\n|   | hadoop.hdfs.server.namenode.ha.TestStandbyIsHot |\n|   | hadoop.hdfs.server.blockmanagement.TestNodeCount |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:0ca8df7 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12780748/h8999_20160106c.patch |\n| JIRA Issue | HDFS-8999 |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux d8068254a3c9 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / 2d16f40 |\n| Default Java | 1.7.0_91 |\n| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_66 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_91 |\n| findbugs | v3.0.0 |\n| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/14043/artifact/patchprocess/diff-checkstyle-hadoop-hdfs-project.txt |\n| whitespace | https://builds.apache.org/job/PreCommit-HDFS-Build/14043/artifact/patchprocess/whitespace-eol.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/14043/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.8.0_66.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/14043/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.7.0_91.txt |\n| unit test logs |  https://builds.apache.org/job/PreCommit-HDFS-Build/14043/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.8.0_66.txt https://builds.apache.org/job/PreCommit-HDFS-Build/14043/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.7.0_91.txt |\n| JDK v1.7.0_91  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/14043/testReport/ |\n| modules | C: hadoop-hdfs-project/hadoop-hdfs hadoop-hdfs-project/hadoop-hdfs-client U: hadoop-hdfs-project |\n| Max memory used | 76MB |\n| Powered by | Apache Yetus 0.2.0-SNAPSHOT   http://yetus.apache.org |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/14043/console |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2016-01-06T15:53:17.298+0000","updated":"2016-01-06T15:53:17.298+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12861071/comment/15086101","id":"15086101","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jingzhao","name":"jingzhao","key":"jingzhao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jing Zhao","active":true,"timeZone":"America/Los_Angeles"},"body":"# How about making BlockNotYetCompleteException simply an IOException and then in {{appendFile}} wrapping it inside of a {{RetriableException}} (like the current {{checkNameNodeSafeMode}})? In this way we can depend on the existing retry logic fo {{RetriableException}} and do not need to have explicit retry in {{callAppend}}.\n# We may need a unit test for the append retry in a block-not-yet-complete scenario.\n# In {{commitOrCompleteLastBlock}} and {{addStoredBlock}}, looks like we do not need the {{hasMinStorage}} check when adding the replicas to the pending queue? Otherwise the block may be later put into the under-replicated queue with {{QUEUE_WITH_CORRUPT_BLOCKS}} priority. If this change makes sense to you, we may also need another unit test here.\n{code}\n    if (hasMinStorage(lastBlock)) {\n      if (b) {\n        addExpectedReplicasToPending(lastBlock, bc);\n      }\n{code}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jingzhao","name":"jingzhao","key":"jingzhao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jing Zhao","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-01-06T19:18:49.960+0000","updated":"2016-01-06T19:18:49.960+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12861071/comment/15086562","id":"15086562","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"body":"COMPLETE state used to mean that the number of reported replicas is {{>= minReplication}}, not {{> 1}}. Would make sense to me to retain this logic.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-01-07T00:20:57.095+0000","updated":"2016-01-07T00:20:57.095+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12861071/comment/15086570","id":"15086570","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"body":"> Let's test with the last block to see if it already solves the problem. I hesitates to be so aggressive.\n\nDid you test without this patch? How? May be the problem is already solved just with HDFS-1172, as I argued above.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-01-07T00:26:38.664+0000","updated":"2016-01-07T00:26:38.664+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12861071/comment/15088369","id":"15088369","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=drankye","name":"drankye","key":"drankye","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Kai Zheng","active":true,"timeZone":"Asia/Chongqing"},"body":"This isn't a review but just want to understand the work. Some minor comments or questions by the way. Thanks for clarifying.\nRegarding the following codes:\n{code}\n-      if (lastBlock != null && lastBlock.isComplete()\n+      if (lastBlock != null) {\n+        if (lastBlock.getBlockUCState() == BlockUCState.COMMITTED) {\n+          throw new BlockNotYetCompleteException(\"append: lastBlock=\"\n+              + lastBlock + \" of src=\" + path\n+              + \" is COMMITTED but not yet COMPLETE.\");\n+        } else if (lastBlock.isComplete()\n           && !blockManager.isSufficientlyReplicated(lastBlock)) {\n-        throw new IOException(\"append: lastBlock=\" + lastBlock + \" of src=\"\n-            + path + \" is not sufficiently replicated yet.\");\n+          throw new IOException(\"append: lastBlock=\" + lastBlock + \" of src=\"\n+              + path + \" is not sufficiently replicated yet.\");\n+        }\n{code}\n* {{lastBlock.isComplete}} means the block has minimal replicas. From the header comment of {{isSufficientlyReplicated}}, it also means the block has minimal replicas. Actually it does check if the block has minimal live or available replicas. So suggest refine the method comment and the IOException message to avoid confusion here.\n* Would we have a method like {{isCommitted}} similar to {{isComplete}}?\n* In comments for {{BlockUCState.COMPLETE}}, it says when a block is in this state then it's not going to be modified. Is this out of sync since a complete block can append?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=drankye","name":"drankye","key":"drankye","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Kai Zheng","active":true,"timeZone":"Asia/Chongqing"},"created":"2016-01-07T23:21:53.341+0000","updated":"2016-01-07T23:21:53.341+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12861071/comment/15092260","id":"15092260","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"body":"h8999_20160111.patch:\n- The new behavior is configurable.  The default is disabled.\n- Allow closing a file with multiple COMMITTED blocks.\n- Use minReplication instead of 1.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-01-11T16:47:26.940+0000","updated":"2016-01-11T16:47:26.940+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12861071/comment/15092262","id":"15092262","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"body":"Will add some tests for the new behavior.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-01-11T16:49:39.754+0000","updated":"2016-01-11T16:49:39.754+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12861071/comment/15092446","id":"15092446","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 0s {color} | {color:blue} Docker mode activated. {color} |\n| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green} 0m 0s {color} | {color:green} The patch appears to include 4 new or modified test files. {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 8m 8s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 1m 35s {color} | {color:green} trunk passed with JDK v1.8.0_66 {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 1m 38s {color} | {color:green} trunk passed with JDK v1.7.0_91 {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 35s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 32s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 27s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 4m 5s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 34s {color} | {color:green} trunk passed with JDK v1.8.0_66 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 2m 21s {color} | {color:green} trunk passed with JDK v1.7.0_91 {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 1m 23s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 1m 34s {color} | {color:green} the patch passed with JDK v1.8.0_66 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 1m 34s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 1m 36s {color} | {color:green} the patch passed with JDK v1.7.0_91 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 1m 36s {color} | {color:green} the patch passed {color} |\n| {color:red}-1{color} | {color:red} checkstyle {color} | {color:red} 0m 35s {color} | {color:red} Patch generated 7 new checkstyle issues in hadoop-hdfs-project (total was 1045, now 1046). {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 27s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 23s {color} | {color:green} the patch passed {color} |\n| {color:red}-1{color} | {color:red} whitespace {color} | {color:red} 0m 0s {color} | {color:red} The patch has 3 line(s) that end in whitespace. Use git apply --whitespace=fix. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 4m 19s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 29s {color} | {color:green} the patch passed with JDK v1.8.0_66 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 2m 14s {color} | {color:green} the patch passed with JDK v1.7.0_91 {color} |\n| {color:green}+1{color} | {color:green} unit {color} | {color:green} 0m 56s {color} | {color:green} hadoop-hdfs-client in the patch passed with JDK v1.8.0_66. {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 64m 37s {color} | {color:red} hadoop-hdfs in the patch failed with JDK v1.8.0_66. {color} |\n| {color:green}+1{color} | {color:green} unit {color} | {color:green} 1m 6s {color} | {color:green} hadoop-hdfs-client in the patch passed with JDK v1.7.0_91. {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 0m 30s {color} | {color:red} hadoop-hdfs in the patch failed with JDK v1.7.0_91. {color} |\n| {color:red}-1{color} | {color:red} asflicense {color} | {color:red} 0m 25s {color} | {color:red} Patch generated 2 ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black} 107m 36s {color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| JDK v1.8.0_66 Failed junit tests | hadoop.hdfs.TestHDFSFileSystemContract |\n|   | hadoop.hdfs.TestEncryptedTransfer |\n|   | hadoop.hdfs.TestClientProtocolForPipelineRecovery |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure160 |\n|   | hadoop.hdfs.TestDecommission |\n|   | hadoop.hdfs.TestFileAppend4 |\n|   | hadoop.hdfs.TestDFSShell |\n|   | hadoop.hdfs.TestBlockReaderLocalLegacy |\n|   | hadoop.fs.TestWebHdfsFileContextMainOperations |\n|   | hadoop.hdfs.server.mover.TestStorageMover |\n|   | hadoop.hdfs.server.datanode.TestDataNodeMetrics |\n|   | hadoop.hdfs.TestPersistBlocks |\n|   | hadoop.hdfs.server.datanode.TestBlockScanner |\n|   | hadoop.hdfs.TestLeaseRecovery2 |\n|   | hadoop.hdfs.TestLeaseRecovery |\n|   | hadoop.hdfs.TestReplaceDatanodeOnFailure |\n|   | hadoop.hdfs.TestReadStripedFileWithDecoding |\n|   | hadoop.fs.TestSymlinkHdfsFileSystem |\n|   | hadoop.fs.TestSWebHdfsFileContextMainOperations |\n|   | hadoop.hdfs.TestDataTransferProtocol |\n|   | hadoop.hdfs.TestQuota |\n|   | hadoop.hdfs.web.TestWebHdfsFileSystemContract |\n|   | hadoop.hdfs.TestEncryptionZones |\n|   | hadoop.hdfs.TestGetFileChecksum |\n|   | hadoop.hdfs.TestFileAppend |\n|   | hadoop.hdfs.server.balancer.TestBalancer |\n|   | hadoop.hdfs.server.balancer.TestBalancerWithNodeGroup |\n|   | hadoop.hdfs.server.namenode.TestAddOverReplicatedStripedBlocks |\n|   | hadoop.hdfs.TestEncryptionZonesWithKMS |\n|   | hadoop.fs.TestSymlinkHdfsFileContext |\n|   | hadoop.hdfs.security.TestDelegationTokenForProxyUser |\n|   | hadoop.hdfs.tools.offlineEditsViewer.TestOfflineEditsViewer |\n|   | hadoop.hdfs.TestFileAppendRestart |\n|   | hadoop.cli.TestHDFSCLI |\n|   | hadoop.fs.TestHDFSFileContextMainOperations |\n|   | hadoop.hdfs.TestReadWhileWriting |\n|   | hadoop.hdfs.TestFileAppend3 |\n|   | hadoop.hdfs.server.namenode.TestNNThroughputBenchmark |\n|   | hadoop.hdfs.TestDFSUpgradeFromImage |\n|   | hadoop.fs.contract.hdfs.TestHDFSContractAppend |\n|   | hadoop.hdfs.web.TestWebHdfsWithMultipleNameNodes |\n|   | hadoop.fs.permission.TestStickyBit |\n| JDK v1.8.0_66 Timed out junit tests | org.apache.hadoop.hdfs.server.balancer.TestBalancerWithSaslDataTransfer |\n|   | org.apache.hadoop.hdfs.server.mover.TestMover |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:0ca8df7 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12781596/h8999_20160111.patch |\n| JIRA Issue | HDFS-8999 |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux f941efa8b529 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / 8c1adea |\n| Default Java | 1.7.0_91 |\n| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_66 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_91 |\n| findbugs | v3.0.0 |\n| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/14087/artifact/patchprocess/diff-checkstyle-hadoop-hdfs-project.txt |\n| whitespace | https://builds.apache.org/job/PreCommit-HDFS-Build/14087/artifact/patchprocess/whitespace-eol.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/14087/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.8.0_66.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/14087/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.7.0_91.txt |\n| unit test logs |  https://builds.apache.org/job/PreCommit-HDFS-Build/14087/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.8.0_66.txt |\n| JDK v1.7.0_91  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/14087/testReport/ |\n| asflicense | https://builds.apache.org/job/PreCommit-HDFS-Build/14087/artifact/patchprocess/patch-asflicense-problems.txt |\n| modules | C: hadoop-hdfs-project/hadoop-hdfs hadoop-hdfs-project/hadoop-hdfs-client U: hadoop-hdfs-project |\n| Max memory used | 75MB |\n| Powered by | Apache Yetus 0.2.0-SNAPSHOT   http://yetus.apache.org |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/14087/console |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2016-01-11T18:36:30.977+0000","updated":"2016-01-11T18:36:30.977+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12861071/comment/15093496","id":"15093496","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"body":"> COMPLETE state used to mean that the number of reported replicas is >= minReplication, not > 1. ...\n\nThe previous patch did not change any logic of block COMPLETE state.  It checked if #locations > 1 before allowing close a file with COMMITTED blocks.\n\nIt makes sense to change it to > minReplication.  Note that it is > but not >= since we don't want to allow closing file if #locations == minReplication.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-01-12T07:58:13.883+0000","updated":"2016-01-12T07:58:13.883+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12861071/comment/15093635","id":"15093635","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 0s {color} | {color:blue} Docker mode activated. {color} |\n| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green} 0m 0s {color} | {color:green} The patch appears to include 4 new or modified test files. {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 7m 39s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 1m 25s {color} | {color:green} trunk passed with JDK v1.8.0_66 {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 1m 34s {color} | {color:green} trunk passed with JDK v1.7.0_91 {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 34s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 29s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 27s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 3m 47s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 28s {color} | {color:green} trunk passed with JDK v1.8.0_66 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 2m 11s {color} | {color:green} trunk passed with JDK v1.7.0_91 {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 1m 17s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 1m 23s {color} | {color:green} the patch passed with JDK v1.8.0_66 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 1m 23s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 1m 30s {color} | {color:green} the patch passed with JDK v1.7.0_91 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 1m 30s {color} | {color:green} the patch passed {color} |\n| {color:red}-1{color} | {color:red} checkstyle {color} | {color:red} 0m 32s {color} | {color:red} Patch generated 7 new checkstyle issues in hadoop-hdfs-project (total was 1043, now 1044). {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 20s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 22s {color} | {color:green} the patch passed {color} |\n| {color:red}-1{color} | {color:red} whitespace {color} | {color:red} 0m 0s {color} | {color:red} The patch has 3 line(s) that end in whitespace. Use git apply --whitespace=fix. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 4m 13s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 22s {color} | {color:green} the patch passed with JDK v1.8.0_66 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 2m 7s {color} | {color:green} the patch passed with JDK v1.7.0_91 {color} |\n| {color:green}+1{color} | {color:green} unit {color} | {color:green} 0m 49s {color} | {color:green} hadoop-hdfs-client in the patch passed with JDK v1.8.0_66. {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 65m 35s {color} | {color:red} hadoop-hdfs in the patch failed with JDK v1.8.0_66. {color} |\n| {color:green}+1{color} | {color:green} unit {color} | {color:green} 0m 56s {color} | {color:green} hadoop-hdfs-client in the patch passed with JDK v1.7.0_91. {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 64m 41s {color} | {color:red} hadoop-hdfs in the patch failed with JDK v1.7.0_91. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green} 0m 21s {color} | {color:green} Patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black} 169m 52s {color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| JDK v1.8.0_66 Failed junit tests | hadoop.hdfs.server.datanode.TestFsDatasetCache |\n|   | hadoop.hdfs.server.namenode.TestDecommissioningStatus |\n| JDK v1.7.0_91 Failed junit tests | hadoop.hdfs.server.namenode.snapshot.TestSnapshotFileLength |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:0ca8df7 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12781596/h8999_20160111.patch |\n| JIRA Issue | HDFS-8999 |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux e06d69e7c815 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / 1715864 |\n| Default Java | 1.7.0_91 |\n| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_66 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_91 |\n| findbugs | v3.0.0 |\n| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/14098/artifact/patchprocess/diff-checkstyle-hadoop-hdfs-project.txt |\n| whitespace | https://builds.apache.org/job/PreCommit-HDFS-Build/14098/artifact/patchprocess/whitespace-eol.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/14098/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.8.0_66.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/14098/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.7.0_91.txt |\n| unit test logs |  https://builds.apache.org/job/PreCommit-HDFS-Build/14098/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.8.0_66.txt https://builds.apache.org/job/PreCommit-HDFS-Build/14098/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.7.0_91.txt |\n| JDK v1.7.0_91  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/14098/testReport/ |\n| modules | C: hadoop-hdfs-project/hadoop-hdfs hadoop-hdfs-project/hadoop-hdfs-client U: hadoop-hdfs-project |\n| Max memory used | 75MB |\n| Powered by | Apache Yetus 0.2.0-SNAPSHOT   http://yetus.apache.org |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/14098/console |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2016-01-12T09:49:47.392+0000","updated":"2016-01-12T09:49:47.392+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12861071/comment/15094154","id":"15094154","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"body":"> 1.   How about making BlockNotYetCompleteException simply an IOException ...\n\nSure\n\n> 2.   We may need a unit test for the append retry in a block-not-yet-complete scenario.\n\nTestAppendDifferentChecksum#testAlgoSwitchRandomized has a similar scenario.  I am also going to add a new test.\n\n> 3.    In commitOrCompleteLastBlock and addStoredBlock, looks like we do not need the hasMinStorage check when adding the replicas to the pending queue? ...\n\nI like to keep the hasMinStorage check since commitOrCompleteLastBlock and addStoredBlock check whether a block is updated from COMMITTED to COMPLETE.  If yes, added it to pendingReplications.\n\nIn this patch, we allow file close for COMMITTED blocks.  I think we should add the COMMITTED blocks to pendingReplications when the file is being closed.  The existing logic (add a block to pendingReplications if it changes from COMMITTED to COMPLETE) should not be changed.  How does it sound to you?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-01-12T16:08:49.687+0000","updated":"2016-01-12T16:08:49.687+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12861071/comment/15096644","id":"15096644","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"body":"h8999_20160113.patch: adds a test and fixes some bugs.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-01-13T17:36:11.104+0000","updated":"2016-01-13T17:36:11.104+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12861071/comment/15097320","id":"15097320","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 0s {color} | {color:blue} Docker mode activated. {color} |\n| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green} 0m 0s {color} | {color:green} The patch appears to include 5 new or modified test files. {color} |\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue} 0m 26s {color} | {color:blue} Maven dependency ordering for branch {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 7m 56s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 2m 5s {color} | {color:green} trunk passed with JDK v1.8.0_66 {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 1m 49s {color} | {color:green} trunk passed with JDK v1.7.0_91 {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 34s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 29s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 27s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 4m 18s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 50s {color} | {color:green} trunk passed with JDK v1.8.0_66 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 2m 14s {color} | {color:green} trunk passed with JDK v1.7.0_91 {color} |\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue} 0m 16s {color} | {color:blue} Maven dependency ordering for patch {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 1m 18s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 1m 27s {color} | {color:green} the patch passed with JDK v1.8.0_66 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 1m 27s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 1m 36s {color} | {color:green} the patch passed with JDK v1.7.0_91 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 1m 36s {color} | {color:green} the patch passed {color} |\n| {color:red}-1{color} | {color:red} checkstyle {color} | {color:red} 0m 33s {color} | {color:red} Patch generated 7 new checkstyle issues in hadoop-hdfs-project (total was 1043, now 1044). {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 25s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 23s {color} | {color:green} the patch passed {color} |\n| {color:red}-1{color} | {color:red} whitespace {color} | {color:red} 0m 0s {color} | {color:red} The patch has 4 line(s) that end in whitespace. Use git apply --whitespace=fix. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 4m 2s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 23s {color} | {color:green} the patch passed with JDK v1.8.0_66 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 2m 7s {color} | {color:green} the patch passed with JDK v1.7.0_91 {color} |\n| {color:green}+1{color} | {color:green} unit {color} | {color:green} 0m 51s {color} | {color:green} hadoop-hdfs-client in the patch passed with JDK v1.8.0_66. {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 169m 26s {color} | {color:red} hadoop-hdfs in the patch failed with JDK v1.8.0_66. {color} |\n| {color:green}+1{color} | {color:green} unit {color} | {color:green} 0m 57s {color} | {color:green} hadoop-hdfs-client in the patch passed with JDK v1.7.0_91. {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 168m 56s {color} | {color:red} hadoop-hdfs in the patch failed with JDK v1.7.0_91. {color} |\n| {color:red}-1{color} | {color:red} asflicense {color} | {color:red} 0m 30s {color} | {color:red} Patch generated 1 ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black} 381m 34s {color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| JDK v1.8.0_66 Failed junit tests | hadoop.hdfs.TestParallelShortCircuitRead |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure150 |\n|   | hadoop.fs.contract.hdfs.TestHDFSContractMkdir |\n|   | hadoop.hdfs.TestBlockStoragePolicy |\n|   | hadoop.hdfs.TestEncryptedTransfer |\n|   | hadoop.hdfs.server.namenode.snapshot.TestSnapshotMetrics |\n|   | hadoop.hdfs.TestDFSInotifyEventInputStream |\n|   | hadoop.hdfs.TestFileLengthOnClusterRestart |\n|   | hadoop.hdfs.TestAppendSnapshotTruncate |\n|   | hadoop.hdfs.server.namenode.snapshot.TestSnapshottableDirListing |\n|   | hadoop.hdfs.TestRead |\n|   | hadoop.hdfs.TestBlocksScheduledCounter |\n|   | hadoop.hdfs.server.namenode.TestDiskspaceQuotaUpdate |\n|   | hadoop.hdfs.TestDFSPermission |\n|   | hadoop.hdfs.server.namenode.TestCheckpoint |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure200 |\n|   | hadoop.hdfs.TestReplaceDatanodeOnFailure |\n|   | hadoop.hdfs.TestRemoteBlockReader2 |\n|   | hadoop.hdfs.server.namenode.TestStartup |\n|   | hadoop.hdfs.TestDFSStorageStateRecovery |\n|   | hadoop.hdfs.TestRemoteBlockReader |\n|   | hadoop.hdfs.TestMultiThreadedHflush |\n|   | hadoop.fs.contract.hdfs.TestHDFSContractRename |\n|   | hadoop.hdfs.TestDFSClientFailover |\n|   | hadoop.hdfs.TestBlockReaderLocal |\n|   | hadoop.hdfs.server.mover.TestMover |\n|   | hadoop.hdfs.server.blockmanagement.TestOverReplicatedBlocks |\n|   | hadoop.hdfs.server.namenode.web.resources.TestWebHdfsDataLocality |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure |\n|   | hadoop.hdfs.TestLeaseRecovery2 |\n|   | hadoop.fs.loadGenerator.TestLoadGenerator |\n|   | hadoop.hdfs.server.namenode.TestLargeDirectoryDelete |\n|   | hadoop.hdfs.TestWriteConfigurationToDFS |\n|   | hadoop.fs.TestFcHdfsSetUMask |\n|   | hadoop.hdfs.TestPread |\n|   | hadoop.hdfs.server.namenode.TestFSEditLogLoader |\n|   | hadoop.hdfs.server.datanode.TestFsDatasetCacheRevocation |\n|   | hadoop.hdfs.server.namenode.ha.TestQuotasWithHA |\n|   | hadoop.hdfs.crypto.TestHdfsCryptoStreams |\n|   | hadoop.fs.viewfs.TestViewFsFileStatusHdfs |\n|   | hadoop.hdfs.server.datanode.TestReadOnlySharedStorage |\n|   | hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewerForAcl |\n|   | hadoop.hdfs.web.TestHttpsFileSystem |\n|   | hadoop.tracing.TestTracingShortCircuitLocalRead |\n|   | hadoop.hdfs.server.namenode.TestFSDirectory |\n|   | hadoop.hdfs.server.datanode.TestBlockScanner |\n|   | hadoop.hdfs.server.namenode.TestNameNodeMetadataConsistency |\n|   | hadoop.tracing.TestTracing |\n|   | hadoop.hdfs.server.datanode.fsdataset.impl.TestInterDatanodeProtocol |\n|   | hadoop.hdfs.server.namenode.snapshot.TestNestedSnapshots |\n|   | hadoop.hdfs.server.datanode.fsdataset.impl.TestLazyPersistFiles |\n|   | hadoop.hdfs.TestParallelRead |\n|   | hadoop.hdfs.TestDFSStripedInputStream |\n|   | hadoop.hdfs.TestRestartDFS |\n|   | hadoop.fs.TestWebHdfsFileContextMainOperations |\n|   | hadoop.hdfs.TestParallelShortCircuitReadNoChecksum |\n|   | hadoop.hdfs.server.blockmanagement.TestSequentialBlockId |\n|   | hadoop.hdfs.server.blockmanagement.TestNameNodePrunesMissingStorages |\n|   | hadoop.hdfs.TestSetTimes |\n|   | hadoop.hdfs.TestParallelShortCircuitLegacyRead |\n|   | hadoop.hdfs.server.blockmanagement.TestPendingInvalidateBlock |\n|   | hadoop.hdfs.server.blockmanagement.TestBlockTokenWithDFS |\n|   | hadoop.hdfs.TestReadStripedFileWithMissingBlocks |\n|   | hadoop.hdfs.TestDatanodeDeath |\n|   | hadoop.hdfs.server.namenode.ha.TestPipelinesFailover |\n|   | hadoop.hdfs.tools.offlineEditsViewer.TestOfflineEditsViewer |\n|   | hadoop.fs.TestFcHdfsCreateMkdir |\n|   | hadoop.hdfs.TestHFlush |\n|   | hadoop.hdfs.server.namenode.ha.TestFailoverWithBlockTokensEnabled |\n|   | hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication |\n|   | hadoop.hdfs.server.namenode.ha.TestDNFencing |\n|   | hadoop.hdfs.TestDFSRollback |\n|   | hadoop.hdfs.TestDFSUpgrade |\n|   | hadoop.fs.TestFcHdfsPermission |\n|   | hadoop.hdfs.TestClientBlockVerification |\n|   | hadoop.hdfs.server.namenode.snapshot.TestSnapshotBlocksMap |\n|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration |\n|   | hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewerWithStripedBlocks |\n|   | hadoop.hdfs.server.namenode.TestNamenodeRetryCache |\n|   | hadoop.hdfs.server.datanode.TestFsDatasetCache |\n|   | hadoop.hdfs.server.datanode.TestBlockHasMultipleReplicasOnSameDN |\n|   | hadoop.hdfs.TestMissingBlocksAlert |\n|   | hadoop.hdfs.server.namenode.TestNNThroughputBenchmark |\n|   | hadoop.hdfs.server.namenode.ha.TestHAMetrics |\n|   | hadoop.hdfs.TestQuota |\n|   | hadoop.hdfs.server.balancer.TestBalancerWithEncryptedTransfer |\n|   | hadoop.hdfs.server.namenode.snapshot.TestFileContextSnapshot |\n|   | hadoop.hdfs.server.namenode.TestQuotaByStorageType |\n|   | hadoop.hdfs.server.namenode.snapshot.TestSnapshotDeletion |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure060 |\n|   | hadoop.hdfs.server.namenode.TestParallelImageWrite |\n|   | hadoop.hdfs.tools.TestDebugAdmin |\n|   | hadoop.hdfs.server.datanode.TestDiskError |\n|   | hadoop.hdfs.server.namenode.snapshot.TestRenameWithSnapshots |\n|   | hadoop.hdfs.server.namenode.TestNameEditsConfigs |\n|   | hadoop.hdfs.server.namenode.TestSnapshotPathINodes |\n|   | hadoop.hdfs.server.namenode.TestFavoredNodesEndToEnd |\n|   | hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer |\n|   | hadoop.hdfs.shortcircuit.TestShortCircuitCache |\n|   | hadoop.hdfs.server.balancer.TestBalancerWithNodeGroup |\n|   | hadoop.hdfs.server.datanode.TestDnRespectsBlockReportSplitThreshold |\n|   | hadoop.hdfs.server.namenode.snapshot.TestSnapshotNameWithInvalidCharacters |\n|   | hadoop.hdfs.TestModTime |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure120 |\n|   | hadoop.hdfs.server.blockmanagement.TestBlockManager |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure180 |\n|   | hadoop.hdfs.TestSetrepIncreasing |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure040 |\n|   | hadoop.hdfs.TestGetBlocks |\n|   | hadoop.hdfs.TestDFSStartupVersions |\n|   | hadoop.hdfs.TestReadWhileWriting |\n|   | hadoop.hdfs.TestRenameWhileOpen |\n|   | hadoop.tools.TestJMXGet |\n|   | hadoop.hdfs.shortcircuit.TestShortCircuitLocalRead |\n|   | hadoop.hdfs.TestHDFSFileSystemContract |\n|   | hadoop.hdfs.TestFileAppend4 |\n|   | hadoop.hdfs.TestRecoverStripedFile |\n|   | hadoop.hdfs.server.namenode.TestAddBlock |\n|   | hadoop.hdfs.TestDataTransferKeepalive |\n|   | hadoop.hdfs.server.datanode.TestDataNodeMetrics |\n|   | hadoop.hdfs.server.balancer.TestBalancerWithHANameNodes |\n|   | hadoop.security.TestPermissionSymlinks |\n|   | hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA |\n|   | hadoop.hdfs.server.namenode.TestINodeFile |\n|   | hadoop.hdfs.server.balancer.TestBalancerWithSaslDataTransfer |\n|   | hadoop.hdfs.TestFileAppend2 |\n|   | hadoop.hdfs.TestErasureCodeBenchmarkThroughput |\n|   | hadoop.hdfs.TestSetrepDecreasing |\n|   | hadoop.hdfs.server.namenode.TestProcessCorruptBlocks |\n|   | hadoop.hdfs.security.TestDelegationTokenForProxyUser |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure140 |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure100 |\n|   | hadoop.hdfs.server.namenode.TestAuditLogs |\n|   | hadoop.fs.TestSWebHdfsFileContextMainOperations |\n|   | hadoop.hdfs.TestInjectionForSimulatedStorage |\n|   | hadoop.hdfs.server.namenode.TestFsck |\n|   | hadoop.hdfs.TestErasureCodingPolicyWithSnapshot |\n|   | hadoop.fs.contract.hdfs.TestHDFSContractDelete |\n|   | hadoop.hdfs.TestLocalDFS |\n|   | hadoop.hdfs.server.namenode.TestListCorruptFileBlocks |\n|   | hadoop.hdfs.TestCrcCorruption |\n|   | hadoop.hdfs.TestListFilesInFileContext |\n|   | hadoop.hdfs.TestDataTransferProtocol |\n|   | hadoop.hdfs.TestConnCache |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure170 |\n|   | hadoop.hdfs.server.namenode.TestStripedINodeFile |\n|   | hadoop.hdfs.TestGetFileChecksum |\n|   | hadoop.hdfs.server.blockmanagement.TestBlocksWithNotEnoughRacks |\n|   | hadoop.hdfs.TestFileAppend |\n|   | hadoop.hdfs.TestReservedRawPaths |\n|   | hadoop.hdfs.TestReadStripedFileWithDecoding |\n|   | hadoop.hdfs.server.datanode.TestDataNodeRollingUpgrade |\n|   | hadoop.hdfs.TestDisableConnCache |\n|   | hadoop.hdfs.server.datanode.fsdataset.impl.TestLazyPersistReplicaPlacement |\n|   | hadoop.hdfs.server.datanode.TestIncrementalBrVariations |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure160 |\n|   | hadoop.hdfs.TestParallelShortCircuitReadUnCached |\n|   | hadoop.hdfs.TestDecommission |\n|   | hadoop.fs.TestUrlStreamHandler |\n|   | hadoop.hdfs.TestSeekBug |\n|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure |\n|   | hadoop.hdfs.security.token.block.TestBlockToken |\n|   | hadoop.hdfs.server.namenode.snapshot.TestSetQuotaWithSnapshot |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure020 |\n|   | hadoop.fs.TestEnhancedByteBufferAccess |\n|   | hadoop.hdfs.TestDFSFinalize |\n|   | hadoop.hdfs.TestDFSMkdirs |\n|   | hadoop.hdfs.server.namenode.snapshot.TestSnapshotRename |\n|   | hadoop.hdfs.TestDFSClientExcludedNodes |\n|   | hadoop.hdfs.TestRollingUpgrade |\n|   | hadoop.hdfs.server.namenode.TestFSImage |\n|   | hadoop.hdfs.server.balancer.TestBalancer |\n|   | hadoop.hdfs.server.datanode.TestNNHandlesBlockReportPerStorage |\n|   | hadoop.hdfs.TestSafeModeWithStripedFile |\n|   | hadoop.fs.TestHDFSFileContextMainOperations |\n|   | hadoop.hdfs.TestSafeMode |\n|   | hadoop.hdfs.server.namenode.TestBackupNode |\n|   | hadoop.hdfs.server.namenode.ha.TestStandbyCheckpoints |\n|   | hadoop.hdfs.server.datanode.TestDataNodeHotSwapVolumes |\n|   | hadoop.hdfs.server.namenode.ha.TestStandbyBlockManagement |\n|   | hadoop.hdfs.TestWriteRead |\n|   | hadoop.hdfs.server.namenode.snapshot.TestSnapshotFileLength |\n|   | hadoop.hdfs.TestWriteReadStripedFile |\n|   | hadoop.hdfs.server.namenode.snapshot.TestSnapshotDiffReport |\n|   | hadoop.hdfs.TestExternalBlockReader |\n|   | hadoop.hdfs.server.namenode.TestMetaSave |\n|   | hadoop.fs.contract.hdfs.TestHDFSContractAppend |\n|   | hadoop.hdfs.TestDFSStripedOutputStream |\n|   | hadoop.fs.contract.hdfs.TestHDFSContractOpen |\n|   | hadoop.hdfs.server.namenode.TestAddStripedBlocks |\n|   | hadoop.hdfs.TestFileCreation |\n|   | hadoop.hdfs.server.namenode.snapshot.TestSnapshot |\n|   | hadoop.hdfs.server.mover.TestStorageMover |\n|   | hadoop.hdfs.TestClientReportBadBlock |\n|   | hadoop.hdfs.server.namenode.TestAddBlockRetry |\n|   | hadoop.hdfs.TestDistributedFileSystem |\n|   | hadoop.hdfs.TestFileCorruption |\n|   | hadoop.hdfs.server.namenode.TestHDFSConcat |\n|   | hadoop.hdfs.server.datanode.fsdataset.impl.TestSpaceReservation |\n|   | hadoop.hdfs.web.TestWebHdfsFileSystemContract |\n|   | hadoop.hdfs.server.datanode.TestBlockReplacement |\n|   | hadoop.hdfs.TestClose |\n|   | hadoop.hdfs.server.namenode.metrics.TestNameNodeMetrics |\n|   | hadoop.hdfs.TestAbandonBlock |\n|   | hadoop.hdfs.TestDFSShell |\n|   | hadoop.hdfs.TestDFSInputStream |\n|   | hadoop.hdfs.TestLeaseRecovery |\n|   | hadoop.hdfs.server.namenode.ha.TestSeveralNameNodes |\n|   | hadoop.hdfs.server.datanode.TestTriggerBlockReport |\n|   | hadoop.hdfs.TestWriteBlockGetsBlockLengthHint |\n|   | hadoop.hdfs.server.blockmanagement.TestRBWBlockInvalidation |\n|   | hadoop.hdfs.server.namenode.ha.TestPendingCorruptDnMessages |\n|   | hadoop.fs.viewfs.TestViewFsHdfs |\n|   | hadoop.hdfs.TestFSInputChecker |\n|   | hadoop.fs.contract.hdfs.TestHDFSContractConcat |\n|   | hadoop.hdfs.server.namenode.TestFileLimit |\n|   | hadoop.fs.viewfs.TestViewFileSystemAtHdfsRoot |\n|   | hadoop.hdfs.server.balancer.TestBalancerWithMultipleNameNodes |\n|   | hadoop.hdfs.TestHDFSTrash |\n|   | hadoop.hdfs.server.datanode.TestCachingStrategy |\n|   | hadoop.hdfs.TestSmallBlock |\n|   | hadoop.hdfs.TestReplication |\n|   | hadoop.hdfs.server.namenode.ha.TestHAAppend |\n|   | hadoop.hdfs.server.datanode.fsdataset.impl.TestScrLazyPersistFiles |\n|   | hadoop.cli.TestAclCLI |\n|   | hadoop.fs.TestSymlinkHdfsFileContext |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure050 |\n|   | hadoop.hdfs.server.namenode.snapshot.TestINodeFileUnderConstructionWithSnapshot |\n|   | hadoop.hdfs.TestFileAppendRestart |\n|   | hadoop.fs.TestSymlinkHdfsFileSystem |\n|   | hadoop.hdfs.TestFileAppend3 |\n|   | hadoop.hdfs.server.namenode.TestFileContextXAttr |\n|   | hadoop.hdfs.server.blockmanagement.TestBlockStatsMXBean |\n|   | hadoop.fs.TestUnbuffer |\n|   | hadoop.hdfs.TestPipelines |\n|   | hadoop.hdfs.server.namenode.TestDecommissioningStatus |\n|   | hadoop.hdfs.server.namenode.ha.TestHASafeMode |\n|   | hadoop.hdfs.web.TestWebHdfsWithMultipleNameNodes |\n|   | hadoop.hdfs.server.namenode.metrics.TestNNMetricFilesInGetListingOps |\n|   | hadoop.hdfs.TestBlockReaderFactory |\n|   | hadoop.hdfs.server.namenode.TestNamenodeCapacityReport |\n|   | hadoop.hdfs.server.namenode.snapshot.TestSnapshotReplication |\n|   | hadoop.hdfs.server.namenode.ha.TestStandbyIsHot |\n|   | hadoop.hdfs.server.namenode.TestFileTruncate |\n|   | hadoop.hdfs.TestFSOutputSummer |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure070 |\n|   | hadoop.hdfs.server.blockmanagement.TestSequentialBlockGroupId |\n|   | hadoop.hdfs.TestBlockReaderLocalLegacy |\n|   | hadoop.hdfs.server.namenode.TestFSImageWithSnapshot |\n|   | hadoop.hdfs.TestFsShellPermission |\n|   | hadoop.hdfs.server.datanode.fsdataset.impl.TestLazyWriter |\n|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting |\n|   | hadoop.hdfs.server.blockmanagement.TestPendingReplication |\n|   | hadoop.hdfs.server.namenode.ha.TestHAStateTransitions |\n|   | hadoop.hdfs.TestEncryptionZones |\n|   | hadoop.hdfs.server.namenode.TestCommitBlockWithInvalidGenStamp |\n|   | hadoop.hdfs.server.blockmanagement.TestUnderReplicatedBlocks |\n|   | hadoop.hdfs.TestFileConcurrentReader |\n|   | hadoop.hdfs.server.blockmanagement.TestNodeCount |\n|   | hadoop.fs.viewfs.TestViewFsDefaultValue |\n|   | hadoop.hdfs.TestAppendDifferentChecksum |\n|   | hadoop.hdfs.TestEncryptionZonesWithHA |\n|   | hadoop.hdfs.server.namenode.TestCacheDirectives |\n|   | hadoop.hdfs.server.namenode.ha.TestHarFileSystemWithHA |\n|   | hadoop.hdfs.server.namenode.TestQuotaWithStripedBlocks |\n|   | hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewerForContentSummary |\n|   | hadoop.hdfs.TestFileStatus |\n|   | hadoop.hdfs.web.TestWebHDFSXAttr |\n|   | hadoop.hdfs.server.namenode.TestNameNodeXAttr |\n|   | hadoop.hdfs.server.datanode.TestHSync |\n|   | hadoop.hdfs.protocol.datatransfer.sasl.TestSaslDataTransfer |\n|   | hadoop.fs.viewfs.TestViewFileSystemHdfs |\n|   | hadoop.hdfs.server.namenode.TestRecoverStripedBlocks |\n|   | hadoop.hdfs.TestParallelUnixDomainRead |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure030 |\n|   | hadoop.hdfs.tools.TestStoragePolicyCommands |\n|   | hadoop.hdfs.TestDFSRemove |\n|   | hadoop.fs.viewfs.TestViewFsAtHdfsRoot |\n|   | hadoop.hdfs.server.datanode.TestNNHandlesCombinedBlockReport |\n|   | hadoop.hdfs.server.datanode.TestDeleteBlockPool |\n|   | hadoop.hdfs.TestDFSClientRetries |\n|   | hadoop.hdfs.server.blockmanagement.TestComputeInvalidateWork |\n|   | hadoop.hdfs.TestListFilesInDFS |\n|   | hadoop.hdfs.server.namenode.TestAddOverReplicatedStripedBlocks |\n|   | hadoop.hdfs.server.namenode.TestHostsFiles |\n|   | hadoop.fs.contract.hdfs.TestHDFSContractCreate |\n|   | hadoop.fs.permission.TestStickyBit |\n|   | hadoop.hdfs.web.TestFSMainOperationsWebHdfs |\n|   | hadoop.hdfs.TestEncryptionZonesWithKMS |\n|   | hadoop.fs.TestSymlinkHdfsDisable |\n|   | hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot |\n|   | hadoop.hdfs.TestDFSRename |\n|   | hadoop.hdfs.server.namenode.TestDeleteRace |\n|   | hadoop.hdfs.TestLease |\n|   | hadoop.hdfs.TestLargeBlock |\n|   | hadoop.hdfs.server.namenode.TestFsckWithMultipleNameNodes |\n|   | hadoop.hdfs.security.TestDelegationToken |\n|   | hadoop.hdfs.TestClientProtocolForPipelineRecovery |\n|   | hadoop.security.TestPermission |\n|   | hadoop.hdfs.server.datanode.TestDirectoryScanner |\n|   | hadoop.hdfs.web.TestWebHDFS |\n|   | hadoop.fs.contract.hdfs.TestHDFSContractSeek |\n|   | hadoop.hdfs.server.datanode.fsdataset.impl.TestDatanodeRestart |\n|   | hadoop.fs.shell.TestHdfsTextCommand |\n|   | hadoop.hdfs.server.namenode.snapshot.TestGetContentSummaryWithSnapshot |\n|   | hadoop.hdfs.TestBlockMissingException |\n| JDK v1.8.0_66 Timed out junit tests | org.apache.hadoop.hdfs.server.blockmanagement.TestBlockTokenWithDFSStriped |\n|   | org.apache.hadoop.hdfs.server.namenode.TestBlockUnderConstruction |\n|   | org.apache.hadoop.hdfs.TestPersistBlocks |\n|   | org.apache.hadoop.cli.TestHDFSCLI |\n| JDK v1.7.0_91 Failed junit tests | hadoop.hdfs.TestParallelShortCircuitRead |\n|   | hadoop.fs.contract.hdfs.TestHDFSContractMkdir |\n|   | hadoop.hdfs.TestBlockStoragePolicy |\n|   | hadoop.hdfs.TestEncryptedTransfer |\n|   | hadoop.hdfs.server.namenode.snapshot.TestSnapshotMetrics |\n|   | hadoop.hdfs.TestDFSInotifyEventInputStream |\n|   | hadoop.hdfs.TestFileLengthOnClusterRestart |\n|   | hadoop.hdfs.TestAppendSnapshotTruncate |\n|   | hadoop.hdfs.server.namenode.snapshot.TestSnapshottableDirListing |\n|   | hadoop.hdfs.TestRead |\n|   | hadoop.hdfs.TestBlocksScheduledCounter |\n|   | hadoop.hdfs.server.namenode.TestDiskspaceQuotaUpdate |\n|   | hadoop.hdfs.TestDFSPermission |\n|   | hadoop.hdfs.server.namenode.TestCheckpoint |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure200 |\n|   | hadoop.hdfs.TestReplaceDatanodeOnFailure |\n|   | hadoop.hdfs.TestRemoteBlockReader2 |\n|   | hadoop.hdfs.server.namenode.TestStartup |\n|   | hadoop.hdfs.TestDFSStorageStateRecovery |\n|   | hadoop.hdfs.TestRemoteBlockReader |\n|   | hadoop.hdfs.TestMultiThreadedHflush |\n|   | hadoop.fs.contract.hdfs.TestHDFSContractRename |\n|   | hadoop.hdfs.TestDFSClientFailover |\n|   | hadoop.hdfs.TestBlockReaderLocal |\n|   | hadoop.hdfs.server.mover.TestMover |\n|   | hadoop.hdfs.server.blockmanagement.TestOverReplicatedBlocks |\n|   | hadoop.hdfs.server.namenode.web.resources.TestWebHdfsDataLocality |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure |\n|   | hadoop.hdfs.TestLeaseRecovery2 |\n|   | hadoop.fs.loadGenerator.TestLoadGenerator |\n|   | hadoop.hdfs.server.namenode.TestLargeDirectoryDelete |\n|   | hadoop.hdfs.TestWriteConfigurationToDFS |\n|   | hadoop.fs.TestFcHdfsSetUMask |\n|   | hadoop.hdfs.TestPread |\n|   | hadoop.hdfs.server.namenode.TestFSEditLogLoader |\n|   | hadoop.hdfs.server.datanode.TestFsDatasetCacheRevocation |\n|   | hadoop.hdfs.server.namenode.ha.TestQuotasWithHA |\n|   | hadoop.hdfs.crypto.TestHdfsCryptoStreams |\n|   | hadoop.fs.viewfs.TestViewFsFileStatusHdfs |\n|   | hadoop.hdfs.server.datanode.TestReadOnlySharedStorage |\n|   | hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewerForAcl |\n|   | hadoop.hdfs.web.TestHttpsFileSystem |\n|   | hadoop.tracing.TestTracingShortCircuitLocalRead |\n|   | hadoop.hdfs.server.namenode.TestFSDirectory |\n|   | hadoop.hdfs.server.datanode.TestBlockScanner |\n|   | hadoop.hdfs.server.namenode.TestNameNodeMetadataConsistency |\n|   | hadoop.tracing.TestTracing |\n|   | hadoop.hdfs.server.datanode.fsdataset.impl.TestInterDatanodeProtocol |\n|   | hadoop.hdfs.server.namenode.snapshot.TestNestedSnapshots |\n|   | hadoop.hdfs.server.datanode.fsdataset.impl.TestLazyPersistFiles |\n|   | hadoop.hdfs.TestParallelRead |\n|   | hadoop.hdfs.TestDFSStripedInputStream |\n|   | hadoop.hdfs.TestRestartDFS |\n|   | hadoop.fs.TestWebHdfsFileContextMainOperations |\n|   | hadoop.hdfs.TestParallelShortCircuitReadNoChecksum |\n|   | hadoop.hdfs.server.blockmanagement.TestSequentialBlockId |\n|   | hadoop.hdfs.server.blockmanagement.TestNameNodePrunesMissingStorages |\n|   | hadoop.hdfs.TestSetTimes |\n|   | hadoop.hdfs.TestParallelShortCircuitLegacyRead |\n|   | hadoop.hdfs.server.blockmanagement.TestPendingInvalidateBlock |\n|   | hadoop.hdfs.server.blockmanagement.TestBlockTokenWithDFS |\n|   | hadoop.hdfs.TestReadStripedFileWithMissingBlocks |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure210 |\n|   | hadoop.hdfs.TestDatanodeDeath |\n|   | hadoop.hdfs.server.namenode.ha.TestPipelinesFailover |\n|   | hadoop.hdfs.tools.offlineEditsViewer.TestOfflineEditsViewer |\n|   | hadoop.fs.TestFcHdfsCreateMkdir |\n|   | hadoop.hdfs.TestHFlush |\n|   | hadoop.hdfs.server.namenode.ha.TestFailoverWithBlockTokensEnabled |\n|   | hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication |\n|   | hadoop.hdfs.server.namenode.ha.TestDNFencing |\n|   | hadoop.hdfs.TestDFSRollback |\n|   | hadoop.hdfs.TestDFSUpgrade |\n|   | hadoop.fs.TestFcHdfsPermission |\n|   | hadoop.hdfs.TestClientBlockVerification |\n|   | hadoop.hdfs.server.namenode.snapshot.TestSnapshotBlocksMap |\n|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration |\n|   | hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewerWithStripedBlocks |\n|   | hadoop.hdfs.server.namenode.TestNamenodeRetryCache |\n|   | hadoop.hdfs.server.datanode.TestFsDatasetCache |\n|   | hadoop.hdfs.server.datanode.TestBlockHasMultipleReplicasOnSameDN |\n|   | hadoop.hdfs.TestMissingBlocksAlert |\n|   | hadoop.hdfs.server.namenode.TestNNThroughputBenchmark |\n|   | hadoop.hdfs.server.namenode.ha.TestHAMetrics |\n|   | hadoop.hdfs.TestQuota |\n|   | hadoop.hdfs.server.balancer.TestBalancerWithEncryptedTransfer |\n|   | hadoop.hdfs.server.namenode.snapshot.TestFileContextSnapshot |\n|   | hadoop.hdfs.server.namenode.TestQuotaByStorageType |\n|   | hadoop.hdfs.server.namenode.snapshot.TestSnapshotDeletion |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure060 |\n|   | hadoop.hdfs.server.namenode.TestParallelImageWrite |\n|   | hadoop.hdfs.tools.TestDebugAdmin |\n|   | hadoop.hdfs.server.datanode.TestDiskError |\n|   | hadoop.hdfs.server.namenode.snapshot.TestRenameWithSnapshots |\n|   | hadoop.hdfs.server.namenode.TestNameEditsConfigs |\n|   | hadoop.hdfs.server.namenode.TestSnapshotPathINodes |\n|   | hadoop.hdfs.server.namenode.TestFavoredNodesEndToEnd |\n|   | hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer |\n|   | hadoop.hdfs.shortcircuit.TestShortCircuitCache |\n|   | hadoop.hdfs.server.balancer.TestBalancerWithNodeGroup |\n|   | hadoop.hdfs.server.datanode.TestDnRespectsBlockReportSplitThreshold |\n|   | hadoop.hdfs.server.namenode.snapshot.TestSnapshotNameWithInvalidCharacters |\n|   | hadoop.hdfs.TestModTime |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure120 |\n|   | hadoop.hdfs.server.blockmanagement.TestBlockManager |\n|   | hadoop.hdfs.TestSetrepIncreasing |\n|   | hadoop.hdfs.TestGetBlocks |\n|   | hadoop.hdfs.TestDFSStartupVersions |\n|   | hadoop.hdfs.TestReadWhileWriting |\n|   | hadoop.hdfs.TestRenameWhileOpen |\n|   | hadoop.tools.TestJMXGet |\n|   | hadoop.hdfs.shortcircuit.TestShortCircuitLocalRead |\n|   | hadoop.hdfs.TestHDFSFileSystemContract |\n|   | hadoop.hdfs.TestFileAppend4 |\n|   | hadoop.hdfs.TestRecoverStripedFile |\n|   | hadoop.hdfs.server.namenode.TestAddBlock |\n|   | hadoop.hdfs.TestDataTransferKeepalive |\n|   | hadoop.hdfs.server.datanode.TestDataNodeMetrics |\n|   | hadoop.hdfs.server.balancer.TestBalancerWithHANameNodes |\n|   | hadoop.security.TestPermissionSymlinks |\n|   | hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA |\n|   | hadoop.hdfs.server.namenode.TestINodeFile |\n|   | hadoop.hdfs.server.balancer.TestBalancerWithSaslDataTransfer |\n|   | hadoop.hdfs.TestFileAppend2 |\n|   | hadoop.hdfs.TestErasureCodeBenchmarkThroughput |\n|   | hadoop.hdfs.TestSetrepDecreasing |\n|   | hadoop.hdfs.server.namenode.TestProcessCorruptBlocks |\n|   | hadoop.hdfs.security.TestDelegationTokenForProxyUser |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure140 |\n|   | hadoop.hdfs.server.namenode.TestAuditLogs |\n|   | hadoop.fs.TestSWebHdfsFileContextMainOperations |\n|   | hadoop.hdfs.TestInjectionForSimulatedStorage |\n|   | hadoop.hdfs.server.namenode.TestFsck |\n|   | hadoop.hdfs.TestErasureCodingPolicyWithSnapshot |\n|   | hadoop.fs.contract.hdfs.TestHDFSContractDelete |\n|   | hadoop.hdfs.TestLocalDFS |\n|   | hadoop.hdfs.server.namenode.TestListCorruptFileBlocks |\n|   | hadoop.hdfs.TestCrcCorruption |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure090 |\n|   | hadoop.hdfs.TestListFilesInFileContext |\n|   | hadoop.hdfs.TestDataTransferProtocol |\n|   | hadoop.hdfs.TestConnCache |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure170 |\n|   | hadoop.hdfs.server.namenode.TestStripedINodeFile |\n|   | hadoop.hdfs.TestGetFileChecksum |\n|   | hadoop.hdfs.server.blockmanagement.TestBlocksWithNotEnoughRacks |\n|   | hadoop.hdfs.TestFileAppend |\n|   | hadoop.hdfs.TestReservedRawPaths |\n|   | hadoop.hdfs.TestReadStripedFileWithDecoding |\n|   | hadoop.hdfs.server.datanode.TestDataNodeRollingUpgrade |\n|   | hadoop.hdfs.TestDisableConnCache |\n|   | hadoop.hdfs.server.datanode.fsdataset.impl.TestLazyPersistReplicaPlacement |\n|   | hadoop.hdfs.server.datanode.TestIncrementalBrVariations |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure160 |\n|   | hadoop.hdfs.TestParallelShortCircuitReadUnCached |\n|   | hadoop.hdfs.TestDecommission |\n|   | hadoop.fs.TestUrlStreamHandler |\n|   | hadoop.hdfs.TestSeekBug |\n|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure |\n|   | hadoop.hdfs.security.token.block.TestBlockToken |\n|   | hadoop.hdfs.server.namenode.snapshot.TestSetQuotaWithSnapshot |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure020 |\n|   | hadoop.fs.TestEnhancedByteBufferAccess |\n|   | hadoop.hdfs.TestDFSFinalize |\n|   | hadoop.hdfs.TestDFSMkdirs |\n|   | hadoop.hdfs.server.namenode.snapshot.TestSnapshotRename |\n|   | hadoop.hdfs.TestDFSClientExcludedNodes |\n|   | hadoop.hdfs.TestRollingUpgrade |\n|   | hadoop.hdfs.server.namenode.TestFSImage |\n|   | hadoop.hdfs.server.balancer.TestBalancer |\n|   | hadoop.hdfs.server.datanode.TestNNHandlesBlockReportPerStorage |\n|   | hadoop.hdfs.TestSafeModeWithStripedFile |\n|   | hadoop.fs.TestHDFSFileContextMainOperations |\n|   | hadoop.hdfs.TestSafeMode |\n|   | hadoop.hdfs.server.namenode.TestBackupNode |\n|   | hadoop.hdfs.server.namenode.ha.TestStandbyCheckpoints |\n|   | hadoop.hdfs.server.datanode.TestDataNodeHotSwapVolumes |\n|   | hadoop.hdfs.server.namenode.ha.TestStandbyBlockManagement |\n|   | hadoop.hdfs.TestWriteRead |\n|   | hadoop.hdfs.server.namenode.snapshot.TestSnapshotFileLength |\n|   | hadoop.hdfs.TestWriteReadStripedFile |\n|   | hadoop.hdfs.server.namenode.snapshot.TestSnapshotDiffReport |\n|   | hadoop.hdfs.TestExternalBlockReader |\n|   | hadoop.hdfs.server.namenode.TestMetaSave |\n|   | hadoop.fs.contract.hdfs.TestHDFSContractAppend |\n|   | hadoop.hdfs.TestDFSStripedOutputStream |\n|   | hadoop.fs.contract.hdfs.TestHDFSContractOpen |\n|   | hadoop.hdfs.server.namenode.TestAddStripedBlocks |\n|   | hadoop.hdfs.TestFileCreation |\n|   | hadoop.hdfs.server.namenode.snapshot.TestSnapshot |\n|   | hadoop.hdfs.server.mover.TestStorageMover |\n|   | hadoop.hdfs.TestClientReportBadBlock |\n|   | hadoop.hdfs.server.namenode.TestAddBlockRetry |\n|   | hadoop.hdfs.TestDistributedFileSystem |\n|   | hadoop.hdfs.TestFileCorruption |\n|   | hadoop.hdfs.server.namenode.TestHDFSConcat |\n|   | hadoop.hdfs.server.datanode.fsdataset.impl.TestSpaceReservation |\n|   | hadoop.hdfs.web.TestWebHdfsFileSystemContract |\n|   | hadoop.hdfs.server.datanode.TestBlockReplacement |\n|   | hadoop.hdfs.TestClose |\n|   | hadoop.hdfs.server.namenode.metrics.TestNameNodeMetrics |\n|   | hadoop.hdfs.TestAbandonBlock |\n|   | hadoop.hdfs.TestDFSShell |\n|   | hadoop.hdfs.TestDFSInputStream |\n|   | hadoop.hdfs.TestLeaseRecovery |\n|   | hadoop.hdfs.server.namenode.ha.TestSeveralNameNodes |\n|   | hadoop.hdfs.server.datanode.TestTriggerBlockReport |\n|   | hadoop.hdfs.TestWriteBlockGetsBlockLengthHint |\n|   | hadoop.hdfs.server.blockmanagement.TestRBWBlockInvalidation |\n|   | hadoop.hdfs.server.namenode.ha.TestPendingCorruptDnMessages |\n|   | hadoop.fs.viewfs.TestViewFsHdfs |\n|   | hadoop.hdfs.TestFSInputChecker |\n|   | hadoop.fs.contract.hdfs.TestHDFSContractConcat |\n|   | hadoop.hdfs.server.namenode.TestFileLimit |\n|   | hadoop.fs.viewfs.TestViewFileSystemAtHdfsRoot |\n|   | hadoop.hdfs.server.balancer.TestBalancerWithMultipleNameNodes |\n|   | hadoop.hdfs.TestHDFSTrash |\n|   | hadoop.hdfs.server.datanode.TestCachingStrategy |\n|   | hadoop.hdfs.TestSmallBlock |\n|   | hadoop.hdfs.TestReplication |\n|   | hadoop.hdfs.server.namenode.ha.TestHAAppend |\n|   | hadoop.hdfs.server.datanode.fsdataset.impl.TestScrLazyPersistFiles |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure110 |\n|   | hadoop.cli.TestAclCLI |\n|   | hadoop.fs.TestSymlinkHdfsFileContext |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure130 |\n|   | hadoop.hdfs.server.namenode.snapshot.TestINodeFileUnderConstructionWithSnapshot |\n|   | hadoop.hdfs.TestFileAppendRestart |\n|   | hadoop.fs.TestSymlinkHdfsFileSystem |\n|   | hadoop.hdfs.TestFileAppend3 |\n|   | hadoop.hdfs.server.namenode.TestFileContextXAttr |\n|   | hadoop.hdfs.server.blockmanagement.TestBlockStatsMXBean |\n|   | hadoop.fs.TestUnbuffer |\n|   | hadoop.hdfs.TestPipelines |\n|   | hadoop.hdfs.server.namenode.TestDecommissioningStatus |\n|   | hadoop.hdfs.server.namenode.ha.TestHASafeMode |\n|   | hadoop.hdfs.web.TestWebHdfsWithMultipleNameNodes |\n|   | hadoop.hdfs.server.namenode.metrics.TestNNMetricFilesInGetListingOps |\n|   | hadoop.hdfs.TestBlockReaderFactory |\n|   | hadoop.hdfs.server.namenode.TestNamenodeCapacityReport |\n|   | hadoop.hdfs.server.namenode.snapshot.TestSnapshotReplication |\n|   | hadoop.hdfs.server.namenode.ha.TestStandbyIsHot |\n|   | hadoop.hdfs.server.namenode.TestFileTruncate |\n|   | hadoop.hdfs.TestFSOutputSummer |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure070 |\n|   | hadoop.hdfs.server.blockmanagement.TestSequentialBlockGroupId |\n|   | hadoop.hdfs.TestBlockReaderLocalLegacy |\n|   | hadoop.hdfs.server.namenode.TestFSImageWithSnapshot |\n|   | hadoop.hdfs.TestFsShellPermission |\n|   | hadoop.hdfs.server.datanode.fsdataset.impl.TestLazyWriter |\n|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting |\n|   | hadoop.hdfs.server.blockmanagement.TestPendingReplication |\n|   | hadoop.hdfs.server.namenode.ha.TestHAStateTransitions |\n|   | hadoop.hdfs.TestEncryptionZones |\n|   | hadoop.hdfs.server.namenode.TestCommitBlockWithInvalidGenStamp |\n|   | hadoop.hdfs.server.blockmanagement.TestUnderReplicatedBlocks |\n|   | hadoop.hdfs.TestFileConcurrentReader |\n|   | hadoop.hdfs.server.blockmanagement.TestNodeCount |\n|   | hadoop.fs.viewfs.TestViewFsDefaultValue |\n|   | hadoop.hdfs.TestAppendDifferentChecksum |\n|   | hadoop.hdfs.TestEncryptionZonesWithHA |\n|   | hadoop.hdfs.server.namenode.TestCacheDirectives |\n|   | hadoop.hdfs.server.namenode.ha.TestHarFileSystemWithHA |\n|   | hadoop.hdfs.server.namenode.TestQuotaWithStripedBlocks |\n|   | hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewerForContentSummary |\n|   | hadoop.hdfs.TestFileStatus |\n|   | hadoop.hdfs.web.TestWebHDFSXAttr |\n|   | hadoop.hdfs.server.namenode.TestNameNodeXAttr |\n|   | hadoop.hdfs.server.datanode.TestHSync |\n|   | hadoop.hdfs.protocol.datatransfer.sasl.TestSaslDataTransfer |\n|   | hadoop.fs.viewfs.TestViewFileSystemHdfs |\n|   | hadoop.hdfs.server.namenode.TestRecoverStripedBlocks |\n|   | hadoop.hdfs.TestParallelUnixDomainRead |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure030 |\n|   | hadoop.hdfs.tools.TestStoragePolicyCommands |\n|   | hadoop.hdfs.TestDFSRemove |\n|   | hadoop.fs.viewfs.TestViewFsAtHdfsRoot |\n|   | hadoop.hdfs.server.datanode.TestNNHandlesCombinedBlockReport |\n|   | hadoop.hdfs.server.datanode.TestDeleteBlockPool |\n|   | hadoop.hdfs.TestDFSClientRetries |\n|   | hadoop.hdfs.server.blockmanagement.TestComputeInvalidateWork |\n|   | hadoop.hdfs.TestListFilesInDFS |\n|   | hadoop.hdfs.server.namenode.TestAddOverReplicatedStripedBlocks |\n|   | hadoop.hdfs.server.namenode.TestHostsFiles |\n|   | hadoop.fs.contract.hdfs.TestHDFSContractCreate |\n|   | hadoop.fs.permission.TestStickyBit |\n|   | hadoop.hdfs.web.TestFSMainOperationsWebHdfs |\n|   | hadoop.hdfs.TestEncryptionZonesWithKMS |\n|   | hadoop.fs.TestSymlinkHdfsDisable |\n|   | hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot |\n|   | hadoop.hdfs.TestDFSRename |\n|   | hadoop.hdfs.server.namenode.TestDeleteRace |\n|   | hadoop.hdfs.TestLease |\n|   | hadoop.hdfs.TestLargeBlock |\n|   | hadoop.hdfs.server.namenode.TestFsckWithMultipleNameNodes |\n|   | hadoop.hdfs.security.TestDelegationToken |\n|   | hadoop.hdfs.TestClientProtocolForPipelineRecovery |\n|   | hadoop.security.TestPermission |\n|   | hadoop.hdfs.server.datanode.TestDirectoryScanner |\n|   | hadoop.hdfs.web.TestWebHDFS |\n|   | hadoop.fs.contract.hdfs.TestHDFSContractSeek |\n|   | hadoop.hdfs.server.datanode.fsdataset.impl.TestDatanodeRestart |\n|   | hadoop.fs.shell.TestHdfsTextCommand |\n|   | hadoop.hdfs.server.namenode.snapshot.TestGetContentSummaryWithSnapshot |\n|   | hadoop.hdfs.TestBlockMissingException |\n| JDK v1.7.0_91 Timed out junit tests | org.apache.hadoop.hdfs.server.blockmanagement.TestBlockTokenWithDFSStriped |\n|   | org.apache.hadoop.hdfs.server.namenode.TestBlockUnderConstruction |\n|   | org.apache.hadoop.hdfs.TestPersistBlocks |\n|   | org.apache.hadoop.cli.TestHDFSCLI |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:0ca8df7 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12782093/h8999_20160113.patch |\n| JIRA Issue | HDFS-8999 |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux 49ac6fcf836c 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / c722b62 |\n| Default Java | 1.7.0_91 |\n| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_66 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_91 |\n| findbugs | v3.0.0 |\n| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/14113/artifact/patchprocess/diff-checkstyle-hadoop-hdfs-project.txt |\n| whitespace | https://builds.apache.org/job/PreCommit-HDFS-Build/14113/artifact/patchprocess/whitespace-eol.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/14113/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.8.0_66.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/14113/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.7.0_91.txt |\n| unit test logs |  https://builds.apache.org/job/PreCommit-HDFS-Build/14113/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.8.0_66.txt https://builds.apache.org/job/PreCommit-HDFS-Build/14113/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.7.0_91.txt |\n| JDK v1.7.0_91  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/14113/testReport/ |\n| asflicense | https://builds.apache.org/job/PreCommit-HDFS-Build/14113/artifact/patchprocess/patch-asflicense-problems.txt |\n| modules | C:  hadoop-hdfs-project/hadoop-hdfs-client   hadoop-hdfs-project/hadoop-hdfs  U: hadoop-hdfs-project |\n| Max memory used | 76MB |\n| Powered by | Apache Yetus 0.2.0-SNAPSHOT   http://yetus.apache.org |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/14113/console |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2016-01-14T00:00:05.191+0000","updated":"2016-01-14T00:00:05.191+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12861071/comment/15097479","id":"15097479","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"body":"Oops, the index calculated was incorrect in the last patch.\n\nh8999_20160114.patch: fixes the bug.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-01-14T02:35:35.868+0000","updated":"2016-01-14T02:35:35.868+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12861071/comment/15097717","id":"15097717","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 0s {color} | {color:blue} Docker mode activated. {color} |\n| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green} 0m 0s {color} | {color:green} The patch appears to include 5 new or modified test files. {color} |\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue} 0m 30s {color} | {color:blue} Maven dependency ordering for branch {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 9m 21s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 2m 4s {color} | {color:green} trunk passed with JDK v1.8.0_66 {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 2m 2s {color} | {color:green} trunk passed with JDK v1.7.0_91 {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 39s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 41s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 32s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 4m 52s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 52s {color} | {color:green} trunk passed with JDK v1.8.0_66 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 2m 38s {color} | {color:green} trunk passed with JDK v1.7.0_91 {color} |\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue} 0m 20s {color} | {color:blue} Maven dependency ordering for patch {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 1m 36s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 1m 53s {color} | {color:green} the patch passed with JDK v1.8.0_66 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 1m 53s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 1m 48s {color} | {color:green} the patch passed with JDK v1.7.0_91 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 1m 48s {color} | {color:green} the patch passed {color} |\n| {color:red}-1{color} | {color:red} checkstyle {color} | {color:red} 0m 40s {color} | {color:red} Patch generated 7 new checkstyle issues in hadoop-hdfs-project (total was 1043, now 1044). {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 30s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 22s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green} 0m 0s {color} | {color:green} Patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 3m 58s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 27s {color} | {color:green} the patch passed with JDK v1.8.0_66 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 2m 9s {color} | {color:green} the patch passed with JDK v1.7.0_91 {color} |\n| {color:green}+1{color} | {color:green} unit {color} | {color:green} 0m 50s {color} | {color:green} hadoop-hdfs-client in the patch passed with JDK v1.8.0_66. {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 67m 16s {color} | {color:red} hadoop-hdfs in the patch failed with JDK v1.8.0_66. {color} |\n| {color:green}+1{color} | {color:green} unit {color} | {color:green} 0m 55s {color} | {color:green} hadoop-hdfs-client in the patch passed with JDK v1.7.0_91. {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 66m 18s {color} | {color:red} hadoop-hdfs in the patch failed with JDK v1.7.0_91. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green} 0m 21s {color} | {color:green} Patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black} 180m 40s {color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| JDK v1.8.0_66 Failed junit tests | hadoop.hdfs.server.namenode.TestStartup |\n|   | hadoop.hdfs.server.datanode.TestBlockScanner |\n|   | hadoop.hdfs.server.datanode.TestDataNodeHotSwapVolumes |\n| JDK v1.7.0_91 Failed junit tests | hadoop.hdfs.server.namenode.ha.TestBootstrapStandbyWithQJM |\n|   | hadoop.hdfs.server.namenode.TestStartup |\n|   | hadoop.hdfs.TestRollingUpgrade |\n|   | hadoop.hdfs.web.TestWebHDFS |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:0ca8df7 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12782183/h8999_20160114.patch |\n| JIRA Issue | HDFS-8999 |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux 1c82269e3867 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / 8315582 |\n| Default Java | 1.7.0_91 |\n| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_66 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_91 |\n| findbugs | v3.0.0 |\n| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/14117/artifact/patchprocess/diff-checkstyle-hadoop-hdfs-project.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/14117/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.8.0_66.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/14117/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.7.0_91.txt |\n| unit test logs |  https://builds.apache.org/job/PreCommit-HDFS-Build/14117/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.8.0_66.txt https://builds.apache.org/job/PreCommit-HDFS-Build/14117/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.7.0_91.txt |\n| JDK v1.7.0_91  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/14117/testReport/ |\n| modules | C:  hadoop-hdfs-project/hadoop-hdfs-client   hadoop-hdfs-project/hadoop-hdfs  U: hadoop-hdfs-project |\n| Max memory used | 76MB |\n| Powered by | Apache Yetus 0.2.0-SNAPSHOT   http://yetus.apache.org |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/14117/console |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2016-01-14T06:47:36.863+0000","updated":"2016-01-14T06:47:36.863+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12861071/comment/15107589","id":"15107589","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jingzhao","name":"jingzhao","key":"jingzhao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jing Zhao","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks for updating the patch, Nicholas! The current patch looks good to me. Some minors:\n# Will the current default retry policy retry the append RPC for RetriableException? In that case we do not need to retry explicitly in {{callAppend}}?\n# We can always use {{getMinStorageNum}} instead of adding {{BlockManager#getMinReplication}} since we already check if the block/file is striped.\n# In FSEditLogLoader, when applying OP_ClOSE, all the blocks are forced to close. Thus looks like we can blindly complete the file without bringing in the committed block logic.\n{code}\n-        fsNamesys.leaseManager.removeLeases(Lists.newArrayList(file.getId()));\n-        file.toCompleteFile(file.getModificationTime());\n+        fsNamesys.removeLeaseAndCompleteFile(file);\n{code}\n# We now have two places in {{completeFileInternal}} to add committed blocks into the pending queue: one is in {{commitOrCompleteLastBlock}}, and the other is {{addCommittedBlocksToPending}}. Do we still need the first one? Looks like we can now remove the changes from HDFS-1172 and HDFS-9535.\n{code}\n    // commit the last block and complete it if it has minimum replicas\n    fsn.commitOrCompleteLastBlock(pendingFile, iip, last);\n\n    if (!fsn.checkFileProgress(src, pendingFile, true)) {\n      return false;\n    }\n\n    fsn.addCommittedBlocksToPending(pendingFile);\n{code}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jingzhao","name":"jingzhao","key":"jingzhao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jing Zhao","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-01-19T22:33:32.670+0000","updated":"2016-01-19T22:33:32.670+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12861071/comment/15108228","id":"15108228","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"body":"> 1. Will the current default retry policy retry the append RPC for RetriableException? In that case we do not need to retry explicitly in callAppend?\n\nNo, it does not work for non-HA setup.  The test will fail if we do not retry explicitly in callAppend.\n\nWill address your comment in the next patch.  Thanks a lot!","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-01-20T08:47:52.114+0000","updated":"2016-01-20T08:47:52.114+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12861071/comment/15110495","id":"15110495","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"body":"> We can always use getMinStorageNum instead of adding BlockManager#getMinReplication ...\n\nThere is a problem: getMinStorageNum requires a BlockInfo as parameter but there is no BlockInfo in finalizeINodeFileUnderConstruction and removeLeaseAndCompleteFile, where getMinReplication is invoked.\n\nWe may pass the BlockManager object to INodeFile.toCompleteFile, then assertAllBlocksComplete and then checkBlockComplete which has BlockInfo objects available.  However, it does not good to pass the BlockManager object down the road.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-01-21T12:15:55.689+0000","updated":"2016-01-21T12:15:55.689+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12861071/comment/15110573","id":"15110573","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"body":"> We now have two places in completeFileInternal to add committed blocks into the pending queue: one is in commitOrCompleteLastBlock, and the other is addCommittedBlocksToPending. Do we still need the first one? Looks like we can now remove the changes from HDFS-1172 and HDFS-9535. \n\nI think we still need the changes from HDFS-1172 and HDFS-9535 since they add newly COMPLETE blocks to pending replication.  The current patch adds COMMITTED blocks to pending replication.  If we remove the changes, the newly COMPLETE blocks won't be added to pending replication.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-01-21T13:26:40.186+0000","updated":"2016-01-21T13:26:40.186+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12861071/comment/15110602","id":"15110602","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"body":"h8999_20160121.patch: keeps original FSEditLogLoader behavior.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-01-21T13:47:28.060+0000","updated":"2016-01-21T13:47:28.060+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12861071/comment/15111083","id":"15111083","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 0s {color} | {color:blue} Docker mode activated. {color} |\n| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green} 0m 0s {color} | {color:green} The patch appears to include 5 new or modified test files. {color} |\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue} 0m 31s {color} | {color:blue} Maven dependency ordering for branch {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 13m 0s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 4m 23s {color} | {color:green} trunk passed with JDK v1.8.0_66 {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 2m 17s {color} | {color:green} trunk passed with JDK v1.7.0_91 {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 54s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 2m 37s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 49s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 6m 44s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 3m 31s {color} | {color:green} trunk passed with JDK v1.8.0_66 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 3m 34s {color} | {color:green} trunk passed with JDK v1.7.0_91 {color} |\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue} 0m 18s {color} | {color:blue} Maven dependency ordering for patch {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 1m 48s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 2m 25s {color} | {color:green} the patch passed with JDK v1.8.0_66 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 2m 25s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 1m 57s {color} | {color:green} the patch passed with JDK v1.7.0_91 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 1m 57s {color} | {color:green} the patch passed {color} |\n| {color:red}-1{color} | {color:red} checkstyle {color} | {color:red} 0m 43s {color} | {color:red} hadoop-hdfs-project: patch generated 4 new + 1029 unchanged - 3 fixed = 1033 total (was 1032) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 51s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 26s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green} 0m 0s {color} | {color:green} Patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 5m 29s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 2m 9s {color} | {color:green} the patch passed with JDK v1.8.0_66 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 3m 1s {color} | {color:green} the patch passed with JDK v1.7.0_91 {color} |\n| {color:green}+1{color} | {color:green} unit {color} | {color:green} 1m 16s {color} | {color:green} hadoop-hdfs-client in the patch passed with JDK v1.8.0_66. {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 114m 17s {color} | {color:red} hadoop-hdfs in the patch failed with JDK v1.8.0_66. {color} |\n| {color:green}+1{color} | {color:green} unit {color} | {color:green} 1m 37s {color} | {color:green} hadoop-hdfs-client in the patch passed with JDK v1.7.0_91. {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 120m 38s {color} | {color:red} hadoop-hdfs in the patch failed with JDK v1.7.0_91. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green} 0m 40s {color} | {color:green} Patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black} 301m 9s {color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| JDK v1.8.0_66 Failed junit tests | hadoop.hdfs.server.datanode.TestBlockScanner |\n|   | hadoop.hdfs.server.namenode.TestNameNodeMetadataConsistency |\n|   | hadoop.hdfs.server.namenode.TestNNThroughputBenchmark |\n|   | hadoop.hdfs.server.namenode.ha.TestEditLogTailer |\n|   | hadoop.hdfs.TestPersistBlocks |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure120 |\n|   | hadoop.hdfs.server.datanode.TestDataNodeMultipleRegistrations |\n|   | hadoop.hdfs.TestDataTransferKeepalive |\n|   | hadoop.hdfs.security.TestDelegationTokenForProxyUser |\n|   | hadoop.hdfs.TestFileAppend |\n|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure |\n|   | hadoop.hdfs.server.datanode.TestBlockReplacement |\n|   | hadoop.hdfs.server.namenode.TestDecommissioningStatus |\n|   | hadoop.hdfs.TestEncryptionZones |\n|   | hadoop.hdfs.server.datanode.TestDirectoryScanner |\n| JDK v1.7.0_91 Failed junit tests | hadoop.hdfs.server.datanode.TestBlockScanner |\n|   | hadoop.tracing.TestTracing |\n|   | hadoop.hdfs.server.namenode.ha.TestEditLogTailer |\n|   | hadoop.hdfs.security.TestDelegationTokenForProxyUser |\n|   | hadoop.hdfs.TestLocalDFS |\n|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure |\n|   | hadoop.hdfs.server.namenode.ha.TestStandbyCheckpoints |\n|   | hadoop.hdfs.server.datanode.TestBlockReplacement |\n|   | hadoop.hdfs.server.namenode.ha.TestHAAppend |\n|   | hadoop.hdfs.server.namenode.TestDecommissioningStatus |\n|   | hadoop.hdfs.qjournal.TestSecureNNWithQJM |\n|   | hadoop.hdfs.server.namenode.TestNamenodeCapacityReport |\n|   | hadoop.hdfs.TestEncryptionZones |\n|   | hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot |\n|   | hadoop.hdfs.server.datanode.TestDirectoryScanner |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:0ca8df7 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12783589/h8999_20160121.patch |\n| JIRA Issue | HDFS-8999 |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux 71160514af20 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / b7372b7 |\n| Default Java | 1.7.0_91 |\n| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_66 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_91 |\n| findbugs | v3.0.0 |\n| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/14185/artifact/patchprocess/diff-checkstyle-hadoop-hdfs-project.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/14185/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.8.0_66.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/14185/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.7.0_91.txt |\n| unit test logs |  https://builds.apache.org/job/PreCommit-HDFS-Build/14185/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.8.0_66.txt https://builds.apache.org/job/PreCommit-HDFS-Build/14185/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.7.0_91.txt |\n| JDK v1.7.0_91  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/14185/testReport/ |\n| modules | C:  hadoop-hdfs-project/hadoop-hdfs-client   hadoop-hdfs-project/hadoop-hdfs  U: hadoop-hdfs-project |\n| Max memory used | 77MB |\n| Powered by | Apache Yetus 0.2.0-SNAPSHOT   http://yetus.apache.org |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/14185/console |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2016-01-21T18:53:35.665+0000","updated":"2016-01-21T18:53:35.665+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12861071/comment/15111350","id":"15111350","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jingzhao","name":"jingzhao","key":"jingzhao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jing Zhao","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks for updating the patch, Nicholas!\n\nbq. No, it does not work for non-HA setup.\n\nYeah, for non-HA setup the retry is disabled by default. Then we need the retry in callAppend.\n\nbq. I think we still need the changes from HDFS-1172 and HDFS-9535\n\nMy original thought is maybe we can combine all the \"putting blocks into the pending queue\" logic together into your new method. But the current approach looks also fine to me.\n\nSome of the test failures look suspicious. I just started another Jenkins run.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jingzhao","name":"jingzhao","key":"jingzhao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jing Zhao","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-01-21T21:45:50.046+0000","updated":"2016-01-21T21:45:50.046+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12861071/comment/15111529","id":"15111529","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:red}-1{color} | {color:red} patch {color} | {color:red} 0m 5s {color} | {color:red} HDFS-8999 does not apply to trunk. Rebase required? Wrong Branch? See https://wiki.apache.org/hadoop/HowToContribute for help. {color} |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12783589/h8999_20160121.patch |\n| JIRA Issue | HDFS-8999 |\n| Powered by | Apache Yetus 0.2.0-SNAPSHOT   http://yetus.apache.org |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/14192/console |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2016-01-21T22:40:25.714+0000","updated":"2016-01-21T22:40:25.714+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12861071/comment/15111585","id":"15111585","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jingzhao","name":"jingzhao","key":"jingzhao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jing Zhao","active":true,"timeZone":"America/Los_Angeles"},"body":"rebase the patch.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jingzhao","name":"jingzhao","key":"jingzhao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jing Zhao","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-01-21T23:18:05.539+0000","updated":"2016-01-21T23:18:05.539+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12861071/comment/15111815","id":"15111815","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 0s {color} | {color:blue} Docker mode activated. {color} |\n| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green} 0m 0s {color} | {color:green} The patch appears to include 5 new or modified test files. {color} |\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue} 0m 20s {color} | {color:blue} Maven dependency ordering for branch {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 8m 5s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 1m 42s {color} | {color:green} trunk passed with JDK v1.8.0_66 {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 1m 26s {color} | {color:green} trunk passed with JDK v1.7.0_91 {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 34s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 27s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 25s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 3m 48s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 31s {color} | {color:green} trunk passed with JDK v1.8.0_66 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 2m 17s {color} | {color:green} trunk passed with JDK v1.7.0_91 {color} |\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue} 0m 15s {color} | {color:blue} Maven dependency ordering for patch {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 1m 18s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 1m 36s {color} | {color:green} the patch passed with JDK v1.8.0_66 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 1m 36s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 1m 21s {color} | {color:green} the patch passed with JDK v1.7.0_91 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 1m 21s {color} | {color:green} the patch passed {color} |\n| {color:red}-1{color} | {color:red} checkstyle {color} | {color:red} 0m 31s {color} | {color:red} hadoop-hdfs-project: patch generated 4 new + 1028 unchanged - 3 fixed = 1032 total (was 1031) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 23s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 20s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green} 0m 0s {color} | {color:green} Patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 4m 13s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 29s {color} | {color:green} the patch passed with JDK v1.8.0_66 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 2m 14s {color} | {color:green} the patch passed with JDK v1.7.0_91 {color} |\n| {color:green}+1{color} | {color:green} unit {color} | {color:green} 0m 55s {color} | {color:green} hadoop-hdfs-client in the patch passed with JDK v1.8.0_66. {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 63m 4s {color} | {color:red} hadoop-hdfs in the patch failed with JDK v1.8.0_66. {color} |\n| {color:green}+1{color} | {color:green} unit {color} | {color:green} 0m 56s {color} | {color:green} hadoop-hdfs-client in the patch passed with JDK v1.7.0_91. {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 56m 44s {color} | {color:red} hadoop-hdfs in the patch failed with JDK v1.7.0_91. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green} 0m 22s {color} | {color:green} Patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black} 161m 0s {color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| JDK v1.8.0_66 Failed junit tests | hadoop.hdfs.server.namenode.TestNNThroughputBenchmark |\n|   | hadoop.hdfs.TestFileAppend |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure |\n|   | hadoop.hdfs.server.datanode.TestBlockScanner |\n| JDK v1.7.0_91 Failed junit tests | hadoop.hdfs.server.datanode.fsdataset.impl.TestScrLazyPersistFiles |\n|   | hadoop.hdfs.server.namenode.TestNNThroughputBenchmark |\n|   | hadoop.hdfs.TestDFSClientRetries |\n|   | hadoop.hdfs.TestEncryptionZonesWithKMS |\n|   | hadoop.hdfs.server.datanode.TestBlockScanner |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:0ca8df7 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12783701/h8999_20160121b.patch |\n| JIRA Issue | HDFS-8999 |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux 4a6f3eb55fe1 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / f3427d3 |\n| Default Java | 1.7.0_91 |\n| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_66 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_91 |\n| findbugs | v3.0.0 |\n| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/14193/artifact/patchprocess/diff-checkstyle-hadoop-hdfs-project.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/14193/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.8.0_66.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/14193/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.7.0_91.txt |\n| unit test logs |  https://builds.apache.org/job/PreCommit-HDFS-Build/14193/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.8.0_66.txt https://builds.apache.org/job/PreCommit-HDFS-Build/14193/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.7.0_91.txt |\n| JDK v1.7.0_91  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/14193/testReport/ |\n| modules | C:  hadoop-hdfs-project/hadoop-hdfs-client   hadoop-hdfs-project/hadoop-hdfs  U: hadoop-hdfs-project |\n| Max memory used | 77MB |\n| Powered by | Apache Yetus 0.2.0-SNAPSHOT   http://yetus.apache.org |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/14193/console |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2016-01-22T02:37:07.458+0000","updated":"2016-01-22T02:37:07.458+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12861071/comment/15112820","id":"15112820","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jingzhao","name":"jingzhao","key":"jingzhao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jing Zhao","active":true,"timeZone":"America/Los_Angeles"},"body":"In the failed test ({{TestDFSClientRetries}} e.g.) I saw the following stack trace:\n{code}\norg.apache.hadoop.hdfs.server.namenode.NotReplicatedYetException: Not replicated yet: /testIdempotentAllocateBlock\n\tat org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.validateAddBlock(FSDirWriteFileOp.java:190)\n\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2395)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:797)\n\tat org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:917)\n\tat org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1684)\n\tat org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1494)\n\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:594)\n{code}\n\nCould you please check if this is caused by the patch, [~szetszwo]?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jingzhao","name":"jingzhao","key":"jingzhao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jing Zhao","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-01-22T18:25:45.896+0000","updated":"2016-01-22T18:25:45.896+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12861071/comment/15113824","id":"15113824","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"body":"The failure of TestDFSClientRetries is not related to the patch.  I can reproduce the failure without the patch in my machine.  It also failed in some other builds such as below.\n- https://builds.apache.org/job/PreCommit-HDFS-Build/14201/testReport/org.apache.hadoop.hdfs/TestDFSClientRetries/testIdempotentAllocateBlockAndClose/\n- https://builds.apache.org/job/PreCommit-HDFS-Build/14202/testReport/org.apache.hadoop.hdfs/TestDFSClientRetries/testIdempotentAllocateBlockAndClose/","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-01-23T16:36:23.046+0000","updated":"2016-01-23T16:36:23.046+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12861071/comment/15113863","id":"15113863","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"body":"Filed HDFS-9690 for the TestDFSClientRetries bug.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-01-23T17:32:33.012+0000","updated":"2016-01-23T17:32:33.012+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12861071/comment/15115710","id":"15115710","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jingzhao","name":"jingzhao","key":"jingzhao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jing Zhao","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks for verifying the test failures, Nicholas! +1 committing the latest patch to trunk. Please see if you plan to commit it to branch-2 as well. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jingzhao","name":"jingzhao","key":"jingzhao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jing Zhao","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-01-25T18:28:02.295+0000","updated":"2016-01-25T18:28:02.295+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12861071/comment/15116523","id":"15116523","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks Jing for reviewing the patch!\n\nh8999_20160121c.patch: rebases the patch for fixing import conflicts.\n\nSince the new patch only fixes imports, I will commit it without waiting for another Jenkins build.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-01-26T02:28:06.036+0000","updated":"2016-01-26T02:28:06.036+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12861071/comment/15116526","id":"15116526","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"body":"> Please see if you plan to commit it to branch-2 as well.\n\nSince the new behavior is configurable and the default is disabled, we should merge this to branch-2.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-01-26T02:30:13.972+0000","updated":"2016-01-26T02:30:13.972+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12861071/comment/15116578","id":"15116578","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"body":"h8999_20160121c_branch-2.patch: for branch-2.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-01-26T03:15:49.650+0000","updated":"2016-01-26T03:15:49.650+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12861071/comment/15116588","id":"15116588","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"FAILURE: Integrated in Hadoop-trunk-Commit #9185 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/9185/])\nHDFS-8999. Allow a file to be closed with COMMITTED but not yet COMPLETE (szetszwo: rev bd909ed9f2d853f614f04a50e2230a7932732776)\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogLoader.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestLeaseManager.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSConfigKeys.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java\n* hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSClient.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirWriteFileOp.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileAppend.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFSEditLogLoader.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/LeaseManager.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestINodeFile.java\n* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirAppendOp.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFSImage.java\n* hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DataStreamer.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2016-01-26T03:24:38.222+0000","updated":"2016-01-26T03:24:38.222+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12861071/comment/15116636","id":"15116636","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:red}-1{color} | {color:red} patch {color} | {color:red} 0m 5s {color} | {color:red} HDFS-8999 does not apply to trunk. Rebase required? Wrong Branch? See https://wiki.apache.org/hadoop/HowToContribute for help. {color} |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12784330/h8999_20160121c_branch-2.patch |\n| JIRA Issue | HDFS-8999 |\n| Powered by | Apache Yetus 0.2.0-SNAPSHOT   http://yetus.apache.org |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/14240/console |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2016-01-26T03:59:25.146+0000","updated":"2016-01-26T03:59:25.146+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12861071/comment/15116762","id":"15116762","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 0s {color} | {color:blue} Docker mode activated. {color} |\n| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green} 0m 0s {color} | {color:green} The patch appears to include 5 new or modified test files. {color} |\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue} 0m 20s {color} | {color:blue} Maven dependency ordering for branch {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 7m 50s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 1m 42s {color} | {color:green} trunk passed with JDK v1.8.0_66 {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 1m 27s {color} | {color:green} trunk passed with JDK v1.7.0_91 {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 37s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 28s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 25s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 4m 22s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 46s {color} | {color:green} trunk passed with JDK v1.8.0_66 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 2m 38s {color} | {color:green} trunk passed with JDK v1.7.0_91 {color} |\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue} 0m 21s {color} | {color:blue} Maven dependency ordering for patch {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 1m 37s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 2m 5s {color} | {color:green} the patch passed with JDK v1.8.0_66 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 2m 5s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 1m 46s {color} | {color:green} the patch passed with JDK v1.7.0_91 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 1m 46s {color} | {color:green} the patch passed {color} |\n| {color:red}-1{color} | {color:red} checkstyle {color} | {color:red} 0m 44s {color} | {color:red} hadoop-hdfs-project: patch generated 4 new + 1027 unchanged - 3 fixed = 1031 total (was 1030) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 43s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 22s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green} 0m 1s {color} | {color:green} Patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 4m 58s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 52s {color} | {color:green} the patch passed with JDK v1.8.0_66 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 2m 48s {color} | {color:green} the patch passed with JDK v1.7.0_91 {color} |\n| {color:green}+1{color} | {color:green} unit {color} | {color:green} 1m 11s {color} | {color:green} hadoop-hdfs-client in the patch passed with JDK v1.8.0_66. {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 79m 19s {color} | {color:red} hadoop-hdfs in the patch failed with JDK v1.8.0_66. {color} |\n| {color:green}+1{color} | {color:green} unit {color} | {color:green} 1m 13s {color} | {color:green} hadoop-hdfs-client in the patch passed with JDK v1.7.0_91. {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 103m 46s {color} | {color:red} hadoop-hdfs in the patch failed with JDK v1.7.0_91. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green} 0m 44s {color} | {color:green} Patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black} 230m 38s {color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| JDK v1.8.0_66 Failed junit tests | hadoop.hdfs.server.datanode.TestDirectoryScanner |\n|   | hadoop.hdfs.server.namenode.ha.TestHAAppend |\n|   | hadoop.hdfs.server.datanode.fsdataset.impl.TestLazyPersistReplicaRecovery |\n|   | hadoop.hdfs.security.TestDelegationTokenForProxyUser |\n|   | hadoop.hdfs.TestFileAppend |\n|   | hadoop.hdfs.server.namenode.ha.TestDFSUpgradeWithHA |\n|   | hadoop.hdfs.TestDFSUpgradeFromImage |\n|   | hadoop.hdfs.server.datanode.TestBlockScanner |\n| JDK v1.8.0_66 Timed out junit tests | org.apache.hadoop.hdfs.TestLeaseRecovery2 |\n|   | org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure190 |\n|   | org.apache.hadoop.hdfs.TestClientProtocolForPipelineRecovery |\n|   | org.apache.hadoop.hdfs.TestDFSRename |\n| JDK v1.7.0_91 Failed junit tests | hadoop.hdfs.server.datanode.TestDirectoryScanner |\n|   | hadoop.hdfs.TestEncryptionZones |\n|   | hadoop.hdfs.server.namenode.TestNameNodeMetadataConsistency |\n|   | hadoop.hdfs.server.namenode.ha.TestHAAppend |\n|   | hadoop.hdfs.server.namenode.TestDecommissioningStatus |\n|   | hadoop.hdfs.qjournal.TestSecureNNWithQJM |\n|   | hadoop.hdfs.TestMissingBlocksAlert |\n|   | hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider |\n|   | hadoop.hdfs.server.datanode.TestBlockScanner |\n|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:0ca8df7 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12784314/h8999_20160121c.patch |\n| JIRA Issue | HDFS-8999 |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux b6c7d7085b81 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / 2085e60 |\n| Default Java | 1.7.0_91 |\n| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_66 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_91 |\n| findbugs | v3.0.0 |\n| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/14239/artifact/patchprocess/diff-checkstyle-hadoop-hdfs-project.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/14239/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.8.0_66.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/14239/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.7.0_91.txt |\n| unit test logs |  https://builds.apache.org/job/PreCommit-HDFS-Build/14239/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.8.0_66.txt https://builds.apache.org/job/PreCommit-HDFS-Build/14239/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.7.0_91.txt |\n| JDK v1.7.0_91  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/14239/testReport/ |\n| modules | C:  hadoop-hdfs-project/hadoop-hdfs-client   hadoop-hdfs-project/hadoop-hdfs  U: hadoop-hdfs-project |\n| Max memory used | 77MB |\n| Powered by | Apache Yetus 0.2.0-SNAPSHOT   http://yetus.apache.org |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/14239/console |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2016-01-26T06:19:28.994+0000","updated":"2016-01-26T06:19:28.994+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12861071/comment/15116845","id":"15116845","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"body":"I have committed this to trunk.  Will leave this open for committing to branch-2.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-01-26T07:16:21.193+0000","updated":"2016-01-26T07:16:21.193+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12861071/comment/15118581","id":"15118581","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"body":"> ... then change DN to send IBRs in batches in another JIRA.\n\nFiled HDFS-9710.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-01-27T03:40:29.293+0000","updated":"2016-01-27T03:40:29.293+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12861071/comment/15120384","id":"15120384","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jingzhao","name":"jingzhao","key":"jingzhao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jing Zhao","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks for posting the branch-2 patch, Nicholas! The branch-2 patch looks good to me. +1. \n\nSome changes on imports can be removed. You can do it while committing the patch.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jingzhao","name":"jingzhao","key":"jingzhao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jing Zhao","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-01-27T23:19:52.965+0000","updated":"2016-01-27T23:19:52.965+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12861071/comment/15120632","id":"15120632","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks Jing for reviewing the branch-2 patch!\n\nh8999_20160121c_branch-2.patch: reverts some import changes.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-01-28T02:41:08.523+0000","updated":"2016-01-28T02:41:08.523+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12861071/comment/15120636","id":"15120636","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"body":"I have committed this.  Thanks everyone who has contributed on this.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-01-28T02:45:19.734+0000","updated":"2016-01-28T02:45:19.734+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12861071/comment/15129625","id":"15129625","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinayrpet","name":"vinayrpet","key":"vinayrpet","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinayakumar B","active":true,"timeZone":"Asia/Kolkata"},"body":"Updated the title to be same as CHANGES.txt entry.\nAlso pushed to branch-2.8, which was missed, but CHANGES.txt entry and fix versions were set to 2.8.0","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinayrpet","name":"vinayrpet","key":"vinayrpet","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinayakumar B","active":true,"timeZone":"Asia/Kolkata"},"created":"2016-02-03T02:15:22.588+0000","updated":"2016-02-03T02:15:22.588+0000"}],"maxResults":74,"total":74,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-8999/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i2jntz:"}}