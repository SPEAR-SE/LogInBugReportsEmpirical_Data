{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12824100","self":"https://issues.apache.org/jira/rest/api/2/issue/12824100","key":"HDFS-8258","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2015-04-28T01:52:37.749+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Tue Apr 28 08:07:10 UTC 2015","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_23141086671_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2016-01-19T13:08:22.182+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-8258/watchers","watchCount":3,"isWatching":false},"created":"2015-04-26T17:03:35.547+0000","customfield_12310192":"hadoop2.5","customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[],"issuelinks":[],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2016-01-19T13:08:22.210+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[],"timeoriginalestimate":null,"description":"Hi\n    I use the hadoop2.5.\n\n   The standby namenode shutdown after restart one of DNs . And I got the error with tail last logs.\n\n.......................................\n2015-04-23 15:37:39,133 INFO  BlockStateChange (BlockManager.java:logAddStoredBlock(2343)) - BLOCK* addStoredBlock: blockMap updated: 192.168.146.223:50010 is added to blk_1277475690_203782236{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-5dc915b5-a44d-441c-b960-87e875edb5a8:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-50f65630-347e-4e32-b3b9-9eb904db9577:NORMAL|RBW]]} size 0\n2015-04-23 15:37:39,137 INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(873)) - BLOCK* registerDatanode: from DatanodeRegistration(192.168.146.130, datanodeUuid=ee834f1d-ba78-48de-bd7a-c364b67b535f, infoPort=50075, ipcPort=8010, storageInfo=lv=-55;cid=CID-64dc0d1c-f525-432b-9b28-2b92262d6111;nsid=740344496;c=0) storage ee834f1d-ba78-48de-bd7a-c364b67b535f\n2015-04-23 15:37:39,138 INFO  namenode.NameNode (DatanodeManager.java:registerDatanode(881)) - BLOCK* registerDatanode: 192.168.146.130:50010\n\n2015-04-23 15:37:39,261 INFO  net.NetworkTopology (NetworkTopology.java:remove(482)) - Removing a node: /hadoop2.0/rack_/YSC801/D7_2_5/192.168.146.130:50010\n2015-04-23 15:37:39,262 INFO  net.NetworkTopology (NetworkTopology.java:add(413)) - Adding a new node: /hadoop2.0/rack_/YSC801/D7_2_5/192.168.146.130:50010\n2015-04-23 15:37:39,264 WARN  namenode.FSNamesystem \n(FSNamesystem.java:getCorruptFiles(6775)) - Get corrupt file blocks returned error: Operation category READ is not supported in state standby\n2015-04-23 15:37:39,264 FATAL blockmanagement.BlockManager (BlockManager.java:run(3390)) - ReplicationMonitor thread received Runtime exception.\njava.lang.NullPointerException\n        at java.util.TreeMap.getEntry(TreeMap.java:342)\n        at java.util.TreeMap.get(TreeMap.java:273)\n        at org.apache.hadoop.hdfs.server.blockmanagement.InvalidateBlocks.invalidateWork(InvalidateBlocks.java:137)\n        at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.invalidateWorkForOneNode(BlockManager.java:3231)\n        at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.computeInvalidateWork(BlockManager.java:1191)\n        at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.computeDatanodeWork(BlockManager.java:3431)\n        at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$ReplicationMonitor.run(BlockManager.java:3375)\n        at java.lang.Thread.run(Thread.java:744)\n2015-04-23 15:37:39,267 INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(667)) - Adding new storage ID DS-f0b04209-2f6a-491b-9f28-173c4c53d364 for DN 192.168.146.130:50010\n2015-04-23 15:37:39,268 INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(667)) - Adding new storage ID DS-d255d5a4-4543-4621-b258-4c575843f29c for DN 192.168.146.130:50010\n2015-04-23 15:37:39,268 INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(667)) - Adding new storage ID DS-4a88b36b-7ae6-4f30-b95c-0c4e47d70878 for DN 192.168.146.130:50010\n2015-04-23 15:37:39,268 INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(667)) - Adding new storage ID DS-d4166bd7-a8c0-4067-8c68-78c6c31dcd9e for DN 192.168.146.130:50010\n2015-04-23 15:37:39,268 INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(667)) - Adding new storage ID DS-468eeca6-e45c-428f-811a-71c5d1f04a9f for DN 192.168.146.130:50010\n2015-04-23 15:37:39,269 INFO  BlockStateChange (BlockManager.java:logAddStoredBlock(2343)) - BLOCK* addStoredBlock: blockMap updated: 192.168.146.34:50010 is added to blk_1253664895_179969194 size 285087186\n2015-04-23 15:37:39,271 INFO  BlockStateChange (BlockManager.java:logAddStoredBlock(2343)) - BLOCK* addStoredBlock: blockMap updated: 192.168.146.210:50010 is added to blk_1277475689_203782235{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-2feb6f2f-9d30-4edd-b3c3-101194c6bde8:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-ca6ef4dc-be77-4a27-95e1-39b4fb53933a:NORMAL|RBW]]} size 0\n2015-04-23 15:37:39,274 INFO  BlockStateChange (BlockManager.java:logAddStoredBlock(2343)) - BLOCK* addStoredBlock: blockMap updated: 192.168.146.191:50010 is added to blk_1277475690_203782236{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-5dc915b5-a44d-441c-b960-87e875edb5a8:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-50f65630-347e-4e32-b3b9-9eb904db9577:NORMAL|RBW]]} size 0\n2015-04-23 15:37:39,277 INFO  BlockStateChange (BlockManager.java:logAddStoredBlock(2343)) - BLOCK* addStoredBlock: blockMap updated: 192.168.146.34:50010 is added to blk_1083102318_9365917 size 134217728\n2015-04-23 15:37:39,277 INFO  BlockStateChange (BlockManager.java:logAddStoredBlock(2343)) - BLOCK* addStoredBlock: blockMap updated: 192.168.146.191:50010 is added to blk_1277475689_203782235{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-2feb6f2f-9d30-4edd-b3c3-101194c6bde8:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-ca6ef4dc-be77-4a27-95e1-39b4fb53933a:NORMAL|RBW]]} size 0\n2015-04-23 15:37:39,299 INFO  util.ExitUtil (ExitUtil.java:terminate(124)) - Exiting with status 1\n2015-04-23 15:37:39,301 INFO  namenode.NameNode (StringUtils.java:run(640)) - SHUTDOWN_MSG:\n/************************************************************\nSHUTDOWN_MSG: Shutting down NameNode at hadoop14667/192.168.146.67\n************************************************************/\n..........................................................................\n\n--LOG END--\n    \n      I tracked the log and looked at the InvalidateBlocks.invalidateWork method. \n\n...\nsynchronized List<Block> invalidateWork(final DatanodeDescriptor dn) {\n    final long delay = getInvalidationDelay();\n    if (delay > 0) {\n      if (BlockManager.LOG.isDebugEnabled()) {\n        BlockManager.LOG\n            .debug(\"Block deletion is delayed during NameNode startup. \"\n                       + \"The deletion will start after \" + delay + \" ms.\");\n      }\n      return null;\n    }\n    final LightWeightHashSet<Block> set = node2blocks.get(dn);\n    if (set == null) {\n      return null;\n    }\n\n    // # blocks that can be sent in one message is limited\n    final int limit = blockInvalidateLimit;\n    final List<Block> toInvalidate = set.pollN(limit);\n\n    // If we send everything in this message, remove this node entry\n    if (set.isEmpty()) {\n      remove(dn);\n    }\n\n    dn.addBlocksToBeInvalidated(toInvalidate);\n    numBlocks -= toInvalidate.size();\n    return toInvalidate;\n  }\n...\n   i noticed this line .  \n\n final LightWeightHashSet<Block> set = node2blocks.get(dn);\n\n   does not check the null at the variable of dn first. so when dn is null , occured the NullPointerException.\n\n   ReplicationMonitor thread monitors the replication state periodically . Unfortunatelly i stop a datanode with the concurrence of ReplicationMonitor run.  So treemap.get(null) throw NullPointerException.\n\n   I am not sure whether is a bug.  \n\n   If yes,  can i fixed this issue,  i check the dn null value before treemap.get(dn)?\n\n\n   \n   I hope that is helpful.\n","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"namenode  shutdown strangely","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hwbj","name":"hwbj","key":"hwbj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"wei.he","active":true,"timeZone":"Asia/Shanghai"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hwbj","name":"hwbj","key":"hwbj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"wei.he","active":true,"timeZone":"Asia/Shanghai"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":[{"self":"https://issues.apache.org/jira/rest/api/2/customFieldOption/10431","value":"Important","id":"10431"}],"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12824100/comment/14513141","id":"14513141","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hwbj","name":"hwbj","key":"hwbj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"wei.he","active":true,"timeZone":"Asia/Shanghai"},"body":"...\nif (dn==null) return null;\nfinal LightWeightHashSet<Block> set = node2blocks.get(dn);\n...","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hwbj","name":"hwbj","key":"hwbj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"wei.he","active":true,"timeZone":"Asia/Shanghai"},"created":"2015-04-26T17:15:51.265+0000","updated":"2015-04-26T17:15:51.265+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12824100/comment/14516168","id":"14516168","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=iwasakims","name":"iwasakims","key":"iwasakims","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=iwasakims&avatarId=18289","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=iwasakims&avatarId=18289","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=iwasakims&avatarId=18289","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=iwasakims&avatarId=18289"},"displayName":"Masatake Iwasaki","active":true,"timeZone":"Asia/Tokyo"},"body":"Thanks for reporting this, [~hwbj]. I thinks HDFS-7225 is fixes for this. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=iwasakims","name":"iwasakims","key":"iwasakims","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=iwasakims&avatarId=18289","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=iwasakims&avatarId=18289","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=iwasakims&avatarId=18289","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=iwasakims&avatarId=18289"},"displayName":"Masatake Iwasaki","active":true,"timeZone":"Asia/Tokyo"},"created":"2015-04-28T01:52:37.749+0000","updated":"2015-04-28T01:52:37.749+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12824100/comment/14516620","id":"14516620","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hwbj","name":"hwbj","key":"hwbj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"wei.he","active":true,"timeZone":"Asia/Shanghai"},"body":"Thanks for reply, Masatake Iwasaki","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hwbj","name":"hwbj","key":"hwbj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"wei.he","active":true,"timeZone":"Asia/Shanghai"},"created":"2015-04-28T08:07:06.875+0000","updated":"2015-04-28T08:07:06.875+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12824100/comment/14516621","id":"14516621","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hwbj","name":"hwbj","key":"hwbj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"wei.he","active":true,"timeZone":"Asia/Shanghai"},"body":"Thanks for reply, Masatake Iwasaki","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hwbj","name":"hwbj","key":"hwbj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"wei.he","active":true,"timeZone":"Asia/Shanghai"},"created":"2015-04-28T08:07:10.707+0000","updated":"2015-04-28T08:07:10.707+0000"}],"maxResults":4,"total":4,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-8258/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i2dryf:"}}