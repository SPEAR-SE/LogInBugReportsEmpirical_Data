{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12632368","self":"https://issues.apache.org/jira/rest/api/2/issue/12632368","key":"HDFS-4501","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/6","id":"6","description":"The problem isn't valid and it can't be fixed.","name":"Invalid"},"customfield_12312322":null,"customfield_12310220":"2013-02-14T13:27:44.874+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Fri Feb 15 14:05:50 UTC 2013","customfield_12310420":"312864","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_33072825_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2013-02-14T22:01:35.363+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-4501/watchers","watchCount":3,"isWatching":false},"created":"2013-02-14T12:50:22.579+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[],"issuelinks":[],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2013-02-15T14:05:50.390+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[],"timeoriginalestimate":null,"description":"fsimage and editslog are not updating \nFollowing are the logs \n\nSNN Logs:\n----------------\n2013-02-14 17:29:56,975 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0\n2013-02-14 17:29:57,039 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 10181 bytes.\n2013-02-14 17:29:57,042 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 521 bytes.\n2013-02-14 17:29:57,042 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit\n2013-02-14 17:29:57,042 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 17.77875 MB\n2013-02-14 17:29:57,042 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries\n2013-02-14 17:29:57,042 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152\n2013-02-14 17:29:57,044 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=hduser\n2013-02-14 17:29:57,044 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup\n2013-02-14 17:29:57,044 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=true\n2013-02-14 17:29:57,044 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100\n2013-02-14 17:29:57,044 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)\n2013-02-14 17:29:57,044 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times\n2013-02-14 17:29:57,045 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 89\n2013-02-14 17:29:57,059 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0\n2013-02-14 17:29:57,061 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /app/hadoop/tmp/dfs/namesecondary/current/edits of size 521 edits # 7 loaded in 0 seconds.\n2013-02-14 17:29:57,061 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0\n2013-02-14 17:29:57,121 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file of size 10181 saved in 0 seconds.\n2013-02-14 17:29:57,673 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file of size 10181 saved in 0 seconds.\n2013-02-14 17:29:58,121 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Posted URL ramesh:50070putimage=1&port=50090&machine=0.0.0.0&token=-32:1989419481:0:1360842594000:1360842284984\n2013-02-14 17:29:58,128 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint:\n2013-02-14 17:29:58,129 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.FileNotFoundException: http://ramesh:50070/getimage?putimage=1&port=50090&machine=0.0.0.0&token=-32:1989419481:0:1360842594000:1360842284984\n        at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1613)\n        at org.apache.hadoop.hdfs.server.namenode.TransferFsImage.getFileClient(TransferFsImage.java:160)\n        at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.putFSImage(SecondaryNameNode.java:377)\n        at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:418)\n        at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)\n        at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)\n        at java.lang.Thread.run(Thread.java:722)\n\n\nNN Logs:\n-----------\n\n2013-02-14 18:15:08,127 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:hduser cause:java.net.ConnectException: Connection refused\n2013-02-14 18:15:08,128 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:hduser cause:java.net.ConnectException: Connection refused\n2013-02-14 18:15:08,129 WARN org.mortbay.log: /getimage: java.io.IOException: GetImage failed. java.net.ConnectException: Connection refused\n\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)\n\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:198)\n\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)\n\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:391)\n\tat java.net.Socket.connect(Socket.java:579)\n\tat java.net.Socket.connect(Socket.java:528)\n\tat sun.net.NetworkClient.doConnect(NetworkClient.java:180)\n\tat sun.net.www.http.HttpClient.openServer(HttpClient.java:378)\n\tat sun.net.www.http.HttpClient.openServer(HttpClient.java:473)\n\tat sun.net.www.http.HttpClient.<init>(HttpClient.java:203)\n\tat sun.net.www.http.HttpClient.New(HttpClient.java:290)\n\tat sun.net.www.http.HttpClient.New(HttpClient.java:306)\n\tat sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:995)\n\tat sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:931)\n\tat sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:849)\n\tat sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1299)\n\tat org.apache.hadoop.hdfs.server.namenode.TransferFsImage.getFileClient(TransferFsImage.java:160)\n\tat org.apache.hadoop.hdfs.server.namenode.GetImageServlet$1$1.run(GetImageServlet.java:88)\n\tat org.apache.hadoop.hdfs.server.namenode.GetImageServlet$1$1.run(GetImageServlet.java:85)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:415)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)\n\tat org.apache.hadoop.hdfs.server.namenode.GetImageServlet$1.run(GetImageServlet.java:85)\n\tat org.apache.hadoop.hdfs.server.namenode.GetImageServlet$1.run(GetImageServlet.java:70)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:415)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)\n\tat org.apache.hadoop.hdfs.server.namenode.GetImageServlet.doGet(GetImageServlet.java:70)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:707)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:820)\n\tat org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:511)\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1221)\n\tat org.apache.hadoop.http.HttpServer$QuotingInputFilter.doFilter(HttpServer.java:835)\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)\n\tat org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:399)\n\tat org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216)\n\tat org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:182)\n\tat org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:766)\n\tat org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:450)\n\tat org.mortbay.jetty.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:230)\n\tat org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)\n\tat org.mortbay.jetty.Server.handle(Server.java:326)\n\tat org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:542)\n\tat org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:928)\n\tat org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:549)\n\tat org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:212)\n\tat org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404)\n\tat org.mortbay.io.nio.SelectChannelEndPoint.run(SelectChannelEndPoint.java:410)\n\tat org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:582)\n\n\nPlease help....","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"313210","customfield_12312823":null,"summary":"GetImage failed","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=janesh","name":"janesh","key":"janesh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"janesh mishra","active":true,"timeZone":"Etc/UTC"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=janesh","name":"janesh","key":"janesh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"janesh mishra","active":true,"timeZone":"Etc/UTC"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12632368/comment/13578359","id":"13578359","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"can you attach some version info to the issue? i.e. which Apache Hadoop release?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2013-02-14T13:27:44.874+0000","updated":"2013-02-14T13:27:44.874+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12632368/comment/13578728","id":"13578728","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"body":"Are you running the SNN on a separate node? If so, is the SNN http address set correctly? I think it defaults to 0.0.0.0 and when it tells NN to get the image from 0.0.0.0, NN won't be able to. \n\nPlease direct questions to the user mailing list. JIRA is for bugs.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"created":"2013-02-14T22:01:18.874+0000","updated":"2013-02-14T22:01:18.874+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12632368/comment/13578978","id":"13578978","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=janesh","name":"janesh","key":"janesh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"janesh mishra","active":true,"timeZone":"Etc/UTC"},"body":"Hi Steve,\n\nThanks for your reply.\n\n\n\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=janesh","name":"janesh","key":"janesh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"janesh mishra","active":true,"timeZone":"Etc/UTC"},"created":"2013-02-15T06:03:11.506+0000","updated":"2013-02-15T06:03:11.506+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12632368/comment/13578981","id":"13578981","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=janesh","name":"janesh","key":"janesh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"janesh mishra","active":true,"timeZone":"Etc/UTC"},"body":"Hi Steve,\nI am using hadoop 1.0.4.\n\nThanks\njanesh\n\n\n\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=janesh","name":"janesh","key":"janesh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"janesh mishra","active":true,"timeZone":"Etc/UTC"},"created":"2013-02-15T06:05:11.660+0000","updated":"2013-02-15T06:05:11.660+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12632368/comment/13579134","id":"13579134","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=janesh","name":"janesh","key":"janesh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"janesh mishra","active":true,"timeZone":"Etc/UTC"},"body":"Hi,\n\tI am new in Hadoop and i set the hadoop cluster with the help of Michell Noll Multi-Node setup (http://www.michael-noll.com/tutorials/running-hadoop-on-ubuntu-linux-multi-node-cluster/). \n\tWhen i setup the single Node Hadoop then every things works fine.\n\n\tBut in Multi Node setup i found that my fsimage and editlogs files are not updated on SNN, roll back of edit is done i have edit.new on NN\n\nLogs Form NN:\n\t2013-02-14 19:13:52,468 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:hduser cause:java.net.ConnectException: Connection refused\n\t2013-02-14 19:13:52,468 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:hduser cause:java.net.ConnectException: Connection refused\n\t2013-02-14 19:13:52,477 WARN org.mortbay.log: /getimage: java.io.IOException: GetImage failed. java.net.ConnectException: Connection refused\n\t\nLogs From SNN:\n--------------\n2013-02-14 19:13:52,350 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Posted URL namenode:50070putimage=1&port=50090&machine=0.0.0.0&token=32:1989419481:0:1360849430000:1360849122845\n2013-02-14 19:13:52,374 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint:\n2013-02-14 19:13:52,375 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.FileNotFoundException: \nhttp://namenode:50070/getimage?putimage=1&port=50090&machine=0.0.0.0&token=-32:1989419481:0:1360849430000:1360849122845\nat sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1613)\natorg.apache.hadoop.hdfs.server.namenode.TransferFsImage.getFileClient(TransferFsImage.java:160) at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.putFSImage(SecondaryNameNode.java:377)\n at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:418) at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)\n at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)\n at java.lang.Thread.run(Thread.java:722)\n\n\nMy setup includes\n\n\t        Version : hadoop-1.0.4\n\t\t1. Name Node (192.168.0.105)\n\t\t2. Secondary Name Node (192.168.0.101)\n\t\t3. Data Node (192.168.0.100)\n\n\tName Node also works as Data Node.\n\n\tConf File For Name Node:\n\tcore-hdfs.xml\n\t-------------\n\t\n\t\t<?xml version=\"1.0\"?>\n\t\t<?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?>\n\n\t\t<!-- Put site-specific property overrides in this file. -->\n\n\t\t<configuration>\n\t\t<property>\n\t\t  <name>hadoop.tmp.dir</name>\n\t\t  <value>/app/hadoop/tmp</value>\n\t\t  <description>A base for other temporary directories.</description>\n\t\t</property>\n\n\t\t<property>\n\t\t  <name>fs.default.name</name>\n\t\t  <value>hdfs://namenode:54310</value>\n\t\t  <description>The name of the default file system.  A URI whose\n\t\t  scheme and authority determine the FileSystem implementation.  The\n\t\t  uri's scheme determines the config property (fs.SCHEME.impl) naming\n\t\t  the FileSystem implementation class.  The uri's authority is used to\n\t\t  determine the host, port, etc. for a filesystem.</description>\n\t\t</property>\n\n\t\t<property>\n\t\t  <name>fs.checkpoint.period</name>\n\t\t  <value>300</value>\n\t\t  <description>The number of seconds between two periodic checkpoints.\n\t\t  </description>\n\t\t</property>\n\n\t\t</configuration>\n\n\thdfs-site.xml\n\t-------------\n\t\n\t\t<?xml version=\"1.0\"?>\n\t\t<?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?>\n\n\t\t<!-- Put site-specific property overrides in this file. -->\n\n\t\t<configuration>\n\t\t<property>\n\t\t  <name>dfs.replication</name>\n\t\t  <value>2</value>\n\t\t  <description>Default block replication.\n\t\t  The actual number of replications can be specified when the file is created.\n\t\t  The default is used if replication is not specified in create time.\n\t\t  </description>\n\t\t</property>\n\n\t\t<property>\n\t\t  <name>dfs.hosts</name>\n\t\t  <value>/usr/local/hadoop/includehosts</value>\n\t\t  <description>ips that works as datanode</description>\n\t\t</property>\n\n\t\t<property>\n\t\t  <name>dfs.namenode.secondary.http-address</name>\n\t\t  <value>secondarynamenode:50090</value>\n\t\t  <description>\n\t\t    The address and the base port on which the dfs NameNode Web UI will listen.\n\t\t    If the port is 0, the server will start on a free port.\n\t\t  </description>\n\t\t</property>\n\n\t\t<property>\n\t\t  <name>dfs.http.address</name>\n\t\t  <value>namenode:50070</value>\n\t\t  <description>\n\t\t    The address and the base port on which the dfs NameNode Web UI will listen.\n\t\t    If the port is 0, the server will start on a free port.\n\t\t  </description>\n\t\t</property>\n\n\t\t</configuration>\n\n\tI sync these file to all my nodes. (I read somewhere in Cloud Era doc that all nodes should have same conf files).\n\nPlease help me out.\n\nThanks\nJanesh\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=janesh","name":"janesh","key":"janesh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"janesh mishra","active":true,"timeZone":"Etc/UTC"},"created":"2013-02-15T12:34:37.813+0000","updated":"2013-02-15T12:34:37.813+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12632368/comment/13579195","id":"13579195","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"see also http://wiki.apache.org/hadoop/InvalidJiraIssues","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2013-02-15T14:05:50.390+0000","updated":"2013-02-15T14:05:50.390+0000"}],"maxResults":6,"total":6,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-4501/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i1hzp3:"}}