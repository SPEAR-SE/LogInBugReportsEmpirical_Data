{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12507201","self":"https://issues.apache.org/jira/rest/api/2/issue/12507201","key":"HDFS-1940","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":"2012-04-06T22:07:15.933+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Fri Apr 06 22:07:15 UTC 2012","customfield_12310420":"15360","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-1940/watchers","watchCount":5,"isWatching":false},"created":"2011-05-14T03:06:57.051+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12316319","id":"12316319","description":"","name":"0.20.204.0","archived":false,"released":true,"releaseDate":"2011-09-02"}],"issuelinks":[{"id":"12339081","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12339081","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"inwardIssue":{"id":"12497098","key":"HDFS-2137","self":"https://issues.apache.org/jira/rest/api/2/issue/12497098","fields":{"summary":"Datanode Disk Fail Inplace","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/2","id":"2","description":"A new feature of the product, which has yet to be developed.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype","name":"New Feature","subtask":false,"avatarId":21141}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bharathm","name":"bharathm","key":"bharathm","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Bharath Mundlapudi","active":true,"timeZone":"Etc/UTC"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2012-04-06T22:07:15.970+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12312927","id":"12312927","name":"datanode"}],"timeoriginalestimate":null,"description":"There is a situation where one datanode can have more than one copy of same block due to a disk fails and comes back after sometime in a datanode. And these duplicate blocks are not getting deleted even after datanode and namenode restart.\n\nThis situation can only happen in a corner case , when due to disk failure, the data block is replicated to other disk of the same datanode.\n\n\nTo simulate this scenario I copied a datablock and the associated .meta file from one disk to another disk of same datanode, so the datanode is having 2 copy of same replica. Now I restarted datanode and namenode. Still the extra data block and meta file is not deleted from the datanode\n\nls -l `find /grid/{0,1,2,3}/hadoop/var/hdfs/data/current -name blk_*`\n-rw-r--r-- 1 hdfs users 7814 May 13 21:05 /grid/1/hadoop/var/hdfs/data/current/blk_1727421609840461376\n-rw-r--r-- 1 hdfs users   71 May 13 21:05 /grid/1/hadoop/var/hdfs/data/current/blk_1727421609840461376_579992.meta\n-rw-r--r-- 1 hdfs users 7814 May 13 21:14 /grid/3/hadoop/var/hdfs/data/current/blk_1727421609840461376\n-rw-r--r-- 1 hdfs users   71 May 13 21:14 /grid/3/hadoop/var/hdfs/data/current/blk_1727421609840461376_579992.meta","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"113726","customfield_12312823":null,"summary":"Datanode can have more than one copy of same block when a failed disk is coming back in datanode","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rajsaha","name":"rajsaha","key":"rajsaha","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=rajsaha&avatarId=16507","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=rajsaha&avatarId=16507","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=rajsaha&avatarId=16507","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=rajsaha&avatarId=16507"},"displayName":"Rajit Saha","active":true,"timeZone":"America/Los_Angeles"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rajsaha","name":"rajsaha","key":"rajsaha","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=rajsaha&avatarId=16507","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=rajsaha&avatarId=16507","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=rajsaha&avatarId=16507","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=rajsaha&avatarId=16507"},"displayName":"Rajit Saha","active":true,"timeZone":"America/Los_Angeles"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12507201/comment/13033434","id":"13033434","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rajsaha","name":"rajsaha","key":"rajsaha","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=rajsaha&avatarId=16507","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=rajsaha&avatarId=16507","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=rajsaha&avatarId=16507","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=rajsaha&avatarId=16507"},"displayName":"Rajit Saha","active":true,"timeZone":"America/Los_Angeles"},"body":"In the abovementioned situation HDFS system was having 4 physical copies of same data block (blk_1727421609840461376) accross the cluster , 1 datanode was having 2 copies and another 2 different datanodes were having other 2 different copies. Now if I remove the file with -rm -skipTrash option only 3 copies of the data block is getting deleted. Only one copy (latest one , which was copied manually ) got deleted  from the datanode (which had 2 previously) ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rajsaha","name":"rajsaha","key":"rajsaha","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=rajsaha&avatarId=16507","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=rajsaha&avatarId=16507","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=rajsaha&avatarId=16507","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=rajsaha&avatarId=16507"},"displayName":"Rajit Saha","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-05-14T03:31:12.133+0000","updated":"2011-05-14T03:31:12.133+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12507201/comment/13248924","id":"13248924","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"body":"I checked in 0.23.3 (d60e9678bbc4d52fb9ab5d65363d452cc5926cff) and copying a block (and meta) file from one disk to another does not show up in fsck. The DirectoryScanner does detect the extra block which is not present in the memory map e.g. (here I had only 1 file = 1 block in HDFS and then made a copy)\n{noformat}2012-04-06 15:49:50,958 INFO  datanode.DirectoryScanner (DirectoryScanner.java:scan(389)) - BlockPool BP-1909597932-10.74.90.105-1333745027872 Total blocks: 2, missing metadata files:0, missing block files:0, missing blocks in memory:1, mismatched blocks:0{noformat}\n\nWhen I deleted the file from HDFS, I did see that the copied block (rather than the original block) got deleted. I retried this experiment, and corrupted the original block, restarted HDFS. On cat-ing the file, the original uncorrupted data was displayed from the copied block. When I corrupted the copied block, and restarted HDFS, it was not able to serve the data from the uncorrupted original block. This is a bummer. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"created":"2012-04-06T22:07:15.933+0000","updated":"2012-04-06T22:07:15.933+0000"}],"maxResults":2,"total":2,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-1940/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i0jtlr:"}}