{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12618925","self":"https://issues.apache.org/jira/rest/api/2/issue/12618925","key":"HDFS-4276","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/8","id":"8","description":"The described issue is not actually a problem - it is as designed.","name":"Not A Problem"},"customfield_12312322":null,"customfield_12310220":"2012-12-06T02:57:46.743+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Wed Apr 24 23:20:09 UTC 2013","customfield_12310420":"296191","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_12112581299_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2013-04-24T23:20:09.349+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-4276/watchers","watchCount":4,"isWatching":false},"created":"2012-12-05T18:43:48.088+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12323305","id":"12323305","description":"Hadoop Windows trunk branch","name":"trunk-win","archived":true,"released":false}],"issuelinks":[{"id":"12361092","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12361092","type":{"id":"12310010","name":"Incorporates","inward":"is part of","outward":"incorporates","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/12310010"},"inwardIssue":{"id":"12597621","key":"HDFS-3602","self":"https://issues.apache.org/jira/rest/api/2/issue/12597621","fields":{"summary":"Enhancements to HDFS for Windows Server and Windows Azure development and runtime environments","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/4","id":"4","description":"An improvement or enhancement to an existing feature or task.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype","name":"Improvement","subtask":false,"avatarId":21140}}}},{"id":"12367962","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12367962","type":{"id":"12310051","name":"Supercedes","inward":"is superceded by","outward":"supercedes","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/12310051"},"inwardIssue":{"id":"12644478","key":"HDFS-4748","self":"https://issues.apache.org/jira/rest/api/2/issue/12644478","fields":{"summary":"MiniJournalCluster#restartJournalNode leaks resources, which causes sporadic test failures","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2013-04-24T23:20:09.384+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12312926","id":"12312926","name":"namenode"}],"timeoriginalestimate":null,"description":"Multiple HDFS tests fail on Windows due to \"The process cannot access the file because another process has locked a portion of the file\".","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12323305","id":"12323305","description":"Hadoop Windows trunk branch","name":"trunk-win","archived":true,"released":false}],"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"232569","customfield_12312823":null,"summary":"HDFS tests have multiple failures on Windows due to file locking conflict","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12618925/comment/13510672","id":"13510672","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"body":"There are 6 test suites that fail on Windows due to this problem.  Perhaps the native code in HADOOP-9056 will help resolve this?\n\n{code}\ntestSelectInputStreamsMajorityDown(org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager)  Time elapsed: 1203 sec  <<< ERROR!\norg.apache.hadoop.hdfs.qjournal.client.QuorumException: Could not format one or more JournalNodes. 2 successful responses:\n127.0.0.1:64731: null [success]\n127.0.0.1:64721: null [success]\n1 exceptions thrown:\n127.0.0.1:64711: The process cannot access the file because another process has locked a portion of the file\n\tat java.io.RandomAccessFile.read(Native Method)\n\tat java.io.RandomAccessFile.readLine(RandomAccessFile.java:871)\n\tat org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.tryLock(Storage.java:664)\n\tat org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.lock(Storage.java:629)\n\tat org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:457)\n\tat org.apache.hadoop.hdfs.qjournal.server.JNStorage.analyzeStorage(JNStorage.java:190)\n\tat org.apache.hadoop.hdfs.qjournal.server.JNStorage.<init>(JNStorage.java:70)\n\tat org.apache.hadoop.hdfs.qjournal.server.Journal.<init>(Journal.java:133)\n\tat org.apache.hadoop.hdfs.qjournal.server.JournalNode.getOrCreateJournal(JournalNode.java:78)\n\tat org.apache.hadoop.hdfs.qjournal.server.JournalNodeRpcServer.format(JournalNodeRpcServer.java:138)\n\tat org.apache.hadoop.hdfs.qjournal.protocolPB.QJournalProtocolServerSideTranslatorPB.format(QJournalProtocolServerSideTranslatorPB.java:119)\n\tat org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$QJournalProtocolService$2.callBlockingMethod(QJournalProtocolProtos.java:14016)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:474)\n\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1018)\n\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1763)\n\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1759)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:396)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1437)\n\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:1757)\n\n\tat org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)\n\tat org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:213)\n\tat org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.format(QuorumJournalManager.java:200)\n\tat org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager.setup(TestQuorumJournalManager.java:94)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n\tat java.lang.reflect.Method.invoke(Method.java:597)\n\tat org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:44)\n\tat org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)\n\tat org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:41)\n\tat org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:27)\n\tat org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:31)\n\tat org.junit.runners.BlockJUnit4ClassRunner.runNotIgnored(BlockJUnit4ClassRunner.java:79)\n\tat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:71)\n\tat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:49)\n\tat org.junit.runners.ParentRunner$3.run(ParentRunner.java:193)\n\tat org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:52)\n\tat org.junit.runners.ParentRunner.runChildren(ParentRunner.java:191)\n\tat org.junit.runners.ParentRunner.access$000(ParentRunner.java:42)\n\tat org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:184)\n\tat org.junit.runners.ParentRunner.run(ParentRunner.java:236)\n\tat org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)\n\tat org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)\n\tat org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n\tat java.lang.reflect.Method.invoke(Method.java:597)\n\tat org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)\n\tat org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)\n\tat org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)\n\tat org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)\n\tat org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)\n{code}\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"created":"2012-12-05T18:44:48.814+0000","updated":"2012-12-05T18:44:48.814+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12618925/comment/13511042","id":"13511042","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ivanmi","name":"ivanmi","key":"ivanmi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ivan Mitic","active":true,"timeZone":"Europe/Berlin"},"body":"This usually means that someone did not close a handle (stream) on the file. The fix is to find a place where the stream is not closed. Native code only helps with some concurrent scenarios, IIRC, if someone wanted to delete a file while it is open (...not 100% sure though).\n\nHope this helps","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ivanmi","name":"ivanmi","key":"ivanmi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ivan Mitic","active":true,"timeZone":"Europe/Berlin"},"created":"2012-12-06T02:57:46.743+0000","updated":"2012-12-06T02:57:46.743+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12618925/comment/13530578","id":"13530578","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xgong","name":"xgong","key":"xgong","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10443","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10443","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10443","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10443"},"displayName":"Xuan Gong","active":true,"timeZone":"America/Los_Angeles"},"body":"So, for the failure we post, I think, is because in the previous test TestQuorumJournalManager #testOneJNMissingSegments, we called the function cluster.restartJournalNode, and this function is defined like this. It created a new JournalNode object, and call the start. But after the test, when we call shutdown function, in windows environment, we did not explicitly stop this new created object, that is cause the failure. So, what we can do is :\noption 1: At MiniJournalCluster.class, we can create a arrayList<JournalNode> to hold all the restartedNode, and at shutdown function, we stop all the nodes including the nodes in this arraylist.\noption 2: At MiniJournalCluster.class, In function restartJournalNode, we do not actually create a new journalNode object, just reuse the node ID which we restarted. What we can do is :\n    nodes[i] = new JournalNode();\n    nodes[i].setConf(conf);\n    nodes[i].start()\ninstead of :\n    JournalNode jt = new JournalNode();\n    jt.setConf(conf);\n    jt.start().\nBoth of two methods can fix that test case.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xgong","name":"xgong","key":"xgong","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10443","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10443","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10443","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10443"},"displayName":"Xuan Gong","active":true,"timeZone":"America/Los_Angeles"},"created":"2012-12-13T01:26:37.357+0000","updated":"2012-12-13T01:26:37.357+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12618925/comment/13530583","id":"13530583","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xgong","name":"xgong","key":"xgong","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10443","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10443","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10443","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10443"},"displayName":"Xuan Gong","active":true,"timeZone":"America/Los_Angeles"},"body":"But for next following test case, there are still other failures. For example, when we run test testOutOfSyncAtBeginningOfSegment0,testOutOfSyncAtBeginningOfSegment1 and testOutOfSyncAtBeginningOfSegment2 together, we will get test failure on testOutOfSyncAtBeginningOfSegment2.\n\norg.apache.hadoop.hdfs.qjournal.client.QuorumException: Could not format one or more JournalNodes. 2 successful responses:\n127.0.0.1:52891: null [success]\n127.0.0.1:52901: null [success]\n1 exceptions thrown:\n127.0.0.1:52911: Couldn't rename log C:\\hadoop\\hadoop-hdfs-project\\hadoop-hdfs\\build\\test\\data\\dfs\\journalnode-2\\test-journal\\current\\edits_inprogress_0000000000000000004 to C:\\hadoop\\hadoop-hdfs-project\\hadoop-hdfs\\build\\test\\data\\dfs\\journalnode-2\\test-journal\\current\\edits_inprogress_0000000000000000004.empty\n\tat org.apache.hadoop.hdfs.server.namenode.FileJournalManager$EditLogFile.renameSelf(FileJournalManager.java:505)\n\tat org.apache.hadoop.hdfs.server.namenode.FileJournalManager$EditLogFile.moveAsideEmptyFile(FileJournalManager.java:478)\n\tat org.apache.hadoop.hdfs.qjournal.server.Journal.scanStorageForLatestEdits(Journal.java:188)\n\tat org.apache.hadoop.hdfs.qjournal.server.Journal.<init>(Journal.java:142)\n\tat org.apache.hadoop.hdfs.qjournal.server.JournalNode.getOrCreateJournal(JournalNode.java:78)\n\tat org.apache.hadoop.hdfs.qjournal.server.JournalNodeRpcServer.format(JournalNodeRpcServer.java:138)\n\tat org.apache.hadoop.hdfs.qjournal.protocolPB.QJournalProtocolServerSideTranslatorPB.format(QJournalProtocolServerSideTranslatorPB.java:119)\n\tat org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$QJournalProtocolService$2.callBlockingMethod(QJournalProtocolProtos.java:14016)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:474)\n\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1018)\n\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1778)\n\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Unknown Source)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1444)\n\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:1771)\n\n\tat org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)\n\tat org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:213)\n\tat org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.format(QuorumJournalManager.java:200)\n\tat org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager.setup(TestQuorumJournalManager.java:100)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n\tat java.lang.reflect.Method.invoke(Unknown Source)\n\tat org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:44)\n\tat org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)\n\tat org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:41)\n\tat org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:27)\n\tat org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:31)\n\tat org.junit.runners.BlockJUnit4ClassRunner.runNotIgnored(BlockJUnit4ClassRunner.java:79)\n\tat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:71)\n\tat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:49)\n\tat org.junit.runners.ParentRunner$3.run(ParentRunner.java:193)\n\tat org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:52)\n\tat org.junit.runners.ParentRunner.runChildren(ParentRunner.java:191)\n\tat org.junit.runners.ParentRunner.access$000(ParentRunner.java:42)\n\tat org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:184)\n\tat org.junit.runners.ParentRunner.run(ParentRunner.java:236)\n\tat org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:50)\n\tat org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)\n\tat org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)\n\tat org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)\n\tat org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)\n\tat org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xgong","name":"xgong","key":"xgong","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10443","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10443","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10443","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10443"},"displayName":"Xuan Gong","active":true,"timeZone":"America/Los_Angeles"},"created":"2012-12-13T01:28:52.146+0000","updated":"2012-12-13T01:28:52.146+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12618925/comment/13530596","id":"13530596","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xgong","name":"xgong","key":"xgong","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10443","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10443","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10443","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10443"},"displayName":"Xuan Gong","active":true,"timeZone":"America/Los_Angeles"},"body":"I tried several ways to fix this failure:\n1. I used the ShellUtil instead of java.file.renameto() function, but I got this 127.0.0.1:53050: mv: cannot move `C:/hadoop/hadoop-hdfs-project/hadoop-hdfs/build/test/data/dfs/journalnode-2/test-journal/current/edits_inprogress_0000000000000000004' to `C:/hadoop/hadoop-hdfs-project/hadoop-hdfs/build/test/data/dfs/journalnode-2/test-journal/current/edits_inprogress_0000000000000000004.empty': Permission denied error\n2. I checked before we try to rename the file, does we grab the lock ? Actually, we did grab the lock based on the log information.\n3. After I further track the error down, I found the part of code which throws out the exception is :\n2012-12-12 17:43:11,677 ERROR security.UserGroupInformation (UserGroupInformation.java:doAs(1447)) - PriviledgedActionException as:Administrator (auth:SIMPLE) cause:java.io.IOException: Couldn't rename log C:\\hadoop\\hadoop-hdfs-project\\hadoop-hdfs\\build\\test\\data\\dfs\\journalnode-2\\test-journal\\current\\edits_inprogress_0000000000000000004 to C:\\hadoop\\hadoop-hdfs-project\\hadoop-hdfs\\build\\test\\data\\dfs\\journalnode-2\\test-journal\\current\\edits_inprogress_0000000000000000004.empty\n.\nSo, I am not sure why this happens ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xgong","name":"xgong","key":"xgong","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10443","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10443","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10443","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10443"},"displayName":"Xuan Gong","active":true,"timeZone":"America/Los_Angeles"},"created":"2012-12-13T01:44:17.146+0000","updated":"2012-12-13T01:44:17.146+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12618925/comment/13641146","id":"13641146","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"body":"I think this issue has gone out of date, so I'm resolving it.  Many of the file locking problems found earlier have been fixed.  {{TestQuorumJournalManager}} is still a problem, and I expect to post a patch on HDFS-4748 for that shortly.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-04-24T23:20:09.369+0000","updated":"2013-04-24T23:20:09.369+0000"}],"maxResults":6,"total":6,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-4276/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i146tr:"}}