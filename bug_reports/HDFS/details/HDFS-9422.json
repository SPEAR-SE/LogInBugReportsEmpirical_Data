{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12912729","self":"https://issues.apache.org/jira/rest/api/2/issue/12912729","key":"HDFS-9422","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":"2015-11-13T13:36:33.670+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Mon Nov 23 12:06:53 UTC 2015","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-9422/watchers","watchCount":10,"isWatching":false},"created":"2015-11-13T05:58:34.181+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"1.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[],"issuelinks":[],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=heliangliang","name":"heliangliang","key":"heliangliang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"He Liangliang","active":true,"timeZone":"Asia/Shanghai"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2015-11-23T12:39:01.921+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/10002","description":"A patch for this issue has been uploaded to JIRA by a contributor.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/document.png","name":"Patch Available","id":"10002","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/4","id":4,"key":"indeterminate","colorName":"yellow","name":"In Progress"}},"components":[],"timeoriginalestimate":null,"description":"In DirectoryScanner, the scan call hold the global dataset lock for quite long time (typically max value > 5 secs for 500k blocks). This will stuck the client which need acquire this lock. For applications like HBase, this will affect the latency. In fact, this lock is unnecessary.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12772150","id":"12772150","filename":"HDFS-9422.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=heliangliang","name":"heliangliang","key":"heliangliang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"He Liangliang","active":true,"timeZone":"Asia/Shanghai"},"created":"2015-11-13T08:28:07.102+0000","size":7464,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12772150/HDFS-9422.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"Unnecessary FsDatasetImpl locking in DirectoryScanner cause periodic datanode pauses","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=heliangliang","name":"heliangliang","key":"heliangliang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"He Liangliang","active":true,"timeZone":"Asia/Shanghai"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=heliangliang","name":"heliangliang","key":"heliangliang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"He Liangliang","active":true,"timeZone":"Asia/Shanghai"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12912729/comment/15003705","id":"15003705","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=heliangliang","name":"heliangliang","key":"heliangliang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"He Liangliang","active":true,"timeZone":"Asia/Shanghai"},"body":"The lock is unnecessary:\n1. getFinalizedBlocks is thread safe and the returned block list is a deep copy, so the lock does not protect any extra shared data\n2. the latter checkAndUpdate call is also thread safe and will filter out the false alarm","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=heliangliang","name":"heliangliang","key":"heliangliang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"He Liangliang","active":true,"timeZone":"Asia/Shanghai"},"created":"2015-11-13T08:28:07.106+0000","updated":"2015-11-13T08:28:07.106+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12912729/comment/15003986","id":"15003986","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=drankye","name":"drankye","key":"drankye","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Kai Zheng","active":true,"timeZone":"Asia/Chongqing"},"body":"Hi [~heliangliang],\n\nThanks for finding and reporting the issue. I took a look at your patch and I agree we'll need a better lock/sync scheme here, since the scan of disk may take much longer time than previously assumed and holding of the global lock during the time will affect other operations. However, some sync mechanism may be still needed because otherwise the diff computation result may be out of sync or incorrect if the *dataset* block map is changed during the time. We may limit the lock scope or use a fine-grained lock instead. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=drankye","name":"drankye","key":"drankye","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Kai Zheng","active":true,"timeZone":"Asia/Chongqing"},"created":"2015-11-13T13:36:33.670+0000","updated":"2015-11-13T13:36:33.670+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12912729/comment/15007908","id":"15007908","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=heliangliang","name":"heliangliang","key":"heliangliang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"He Liangliang","active":true,"timeZone":"Asia/Shanghai"},"body":"No, the lock can make NO difference, EXCEPT we move the getDiskReport() call inside the lock. But we don't need the diff in-sync because latter there will be double-check in checkAndUpdate which is protected by the lock.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=heliangliang","name":"heliangliang","key":"heliangliang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"He Liangliang","active":true,"timeZone":"Asia/Shanghai"},"created":"2015-11-17T02:53:37.649+0000","updated":"2015-11-17T02:53:37.649+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12912729/comment/15007962","id":"15007962","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=walter.k.su","name":"walter.k.su","key":"walter.k.su","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Walter Su","active":true,"timeZone":"Asia/Shanghai"},"body":"I have no idea why use Arrays.sort() instead of Collections.sort(). And why sort() need to be synchronized. I think it makes sense to remove the lock.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=walter.k.su","name":"walter.k.su","key":"walter.k.su","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Walter Su","active":true,"timeZone":"Asia/Shanghai"},"created":"2015-11-17T03:46:17.405+0000","updated":"2015-11-17T03:46:17.405+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12912729/comment/15009046","id":"15009046","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stack","name":"stack","key":"stack","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"stack","active":true,"timeZone":"America/Los_Angeles"},"body":"Patch just undoes the synchronize on dataset.  This dataset synchronize in scan has been in place for years. \n\nAs is, there are 'holes' given we let go of the dataset lock after we finish scan and before we go into the checkAndUpdate. The synchronize on dataset in scan seems gratuitous. The synchronize in checkAndUpdate seems sufficient safety doing reconcile of memory and disk state.\n\nPatch looks good to me.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stack","name":"stack","key":"stack","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"stack","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-11-17T17:10:55.694+0000","updated":"2015-11-17T17:10:55.694+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12912729/comment/15010058","id":"15010058","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=liuml07","name":"liuml07","key":"liuml07","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=liuml07&avatarId=29203","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=liuml07&avatarId=29203","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=liuml07&avatarId=29203","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=liuml07&avatarId=29203"},"displayName":"Mingliang Liu","active":true,"timeZone":"America/Los_Angeles"},"body":"Agreed. The most heavy I/O operations scanning the disk are not holding the {{dataset}} lock. The diff is out of sync, which is fine, even before this patch. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=liuml07","name":"liuml07","key":"liuml07","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=liuml07&avatarId=29203","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=liuml07&avatarId=29203","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=liuml07&avatarId=29203","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=liuml07&avatarId=29203"},"displayName":"Mingliang Liu","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-11-18T02:28:19.823+0000","updated":"2015-11-18T02:28:19.823+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12912729/comment/15010505","id":"15010505","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 13m 18s {color} | {color:blue} docker + precommit patch detected. {color} |\n| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:red}-1{color} | {color:red} test4tests {color} | {color:red} 0m 0s {color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 9m 53s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 0m 55s {color} | {color:green} trunk passed with JDK v1.8.0_66 {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 0m 52s {color} | {color:green} trunk passed with JDK v1.7.0_85 {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 19s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 3s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 16s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 2m 16s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 24s {color} | {color:green} trunk passed with JDK v1.8.0_66 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 2m 7s {color} | {color:green} trunk passed with JDK v1.7.0_85 {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 1m 0s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 0m 58s {color} | {color:green} the patch passed with JDK v1.8.0_66 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 0m 58s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 0m 54s {color} | {color:green} the patch passed with JDK v1.7.0_85 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 0m 54s {color} | {color:green} the patch passed {color} |\n| {color:red}-1{color} | {color:red} checkstyle {color} | {color:red} 0m 20s {color} | {color:red} Patch generated 4 new checkstyle issues in hadoop-hdfs-project/hadoop-hdfs (total was 48, now 48). {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 5s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 17s {color} | {color:green} the patch passed {color} |\n| {color:red}-1{color} | {color:red} whitespace {color} | {color:red} 0m 0s {color} | {color:red} The patch has 2 line(s) that end in whitespace. Use git apply --whitespace=fix. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 2m 37s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 20s {color} | {color:green} the patch passed with JDK v1.8.0_66 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 58s {color} | {color:green} the patch passed with JDK v1.7.0_85 {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 58m 58s {color} | {color:red} hadoop-hdfs in the patch failed with JDK v1.8.0_66. {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 56m 21s {color} | {color:red} hadoop-hdfs in the patch failed with JDK v1.7.0_85. {color} |\n| {color:red}-1{color} | {color:red} asflicense {color} | {color:red} 0m 21s {color} | {color:red} Patch generated 58 ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black} 161m 34s {color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| JDK v1.8.0_66 Failed junit tests | hadoop.hdfs.server.namenode.TestBackupNode |\n| JDK v1.7.0_85 Failed junit tests | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure000 |\n|   | hadoop.hdfs.TestDistributedFileSystem |\n|   | hadoop.hdfs.TestInjectionForSimulatedStorage |\n|   | hadoop.hdfs.server.blockmanagement.TestPendingInvalidateBlock |\n|   | hadoop.hdfs.server.namenode.snapshot.TestSnapshotDiffReport |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:date2015-11-18 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12772150/HDFS-9422.patch |\n| JIRA Issue | HDFS-9422 |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux b3370e9cefab 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /home/jenkins/jenkins-slave/workspace/PreCommit-HDFS-Build/patchprocess/apache-yetus-3f4279a/precommit/personality/hadoop.sh |\n| git revision | trunk / 7fab5c8 |\n| findbugs | v3.0.0 |\n| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/13544/artifact/patchprocess/diff-checkstyle-hadoop-hdfs-project_hadoop-hdfs.txt |\n| whitespace | https://builds.apache.org/job/PreCommit-HDFS-Build/13544/artifact/patchprocess/whitespace-eol.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/13544/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.8.0_66.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/13544/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.7.0_85.txt |\n| unit test logs |  https://builds.apache.org/job/PreCommit-HDFS-Build/13544/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.8.0_66.txt https://builds.apache.org/job/PreCommit-HDFS-Build/13544/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.7.0_85.txt |\n| JDK v1.7.0_85  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/13544/testReport/ |\n| asflicense | https://builds.apache.org/job/PreCommit-HDFS-Build/13544/artifact/patchprocess/patch-asflicense-problems.txt |\n| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |\n| Max memory used | 76MB |\n| Powered by | Apache Yetus   http://yetus.apache.org |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/13544/console |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2015-11-18T08:50:47.060+0000","updated":"2015-11-18T08:50:47.060+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12912729/comment/15011573","id":"15011573","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wheat9","name":"wheat9","key":"wheat9","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Haohui Mai","active":true,"timeZone":"America/Los_Angeles"},"body":"My question is why it takes 5 seconds if this is a purely in memory operations over 500k items? Can you provide the jstack when the issue happens? ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wheat9","name":"wheat9","key":"wheat9","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Haohui Mai","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-11-18T18:13:49.066+0000","updated":"2015-11-18T18:13:49.066+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12912729/comment/15022007","id":"15022007","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=heliangliang","name":"heliangliang","key":"heliangliang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"He Liangliang","active":true,"timeZone":"Asia/Shanghai"},"body":"Just record the time consumed, jstack not captured. ~5s(mean around 2s and max 5s) is indeed longer than expected. Just made a local test, sorting 500k blocks take 500ms and 5m takes 5s. So it's still a reasonable time considering the contention with cpu-loaded regionserver processes in the same box.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=heliangliang","name":"heliangliang","key":"heliangliang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"He Liangliang","active":true,"timeZone":"Asia/Shanghai"},"created":"2015-11-23T12:06:53.316+0000","updated":"2015-11-23T12:06:53.316+0000"}],"maxResults":9,"total":9,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-9422/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i2occn:"}}