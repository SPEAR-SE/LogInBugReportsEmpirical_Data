{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12718554","self":"https://issues.apache.org/jira/rest/api/2/issue/12718554","key":"HDFS-6489","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":"2014-06-05T21:06:59.264+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Fri May 18 07:06:45 UTC 2018","customfield_12310420":"396753","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-6489/watchers","watchCount":22,"isWatching":false},"created":"2014-06-05T07:32:27.937+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"8.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12325049","id":"12325049","description":"2.2.0 release","name":"2.2.0","archived":false,"released":true,"releaseDate":"2013-10-15"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12331979","id":"12331979","description":"2.7.1 release","name":"2.7.1","archived":false,"released":true,"releaseDate":"2015-07-06"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12332790","id":"12332790","description":"2.7.2 release","name":"2.7.2","archived":false,"released":true,"releaseDate":"2016-01-25"}],"issuelinks":[{"id":"12462898","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12462898","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"inwardIssue":{"id":"12920376","key":"HDFS-9530","self":"https://issues.apache.org/jira/rest/api/2/issue/12920376","fields":{"summary":"ReservedSpace is not cleared for abandoned Blocks","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/2","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/critical.svg","name":"Critical","id":"2"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}}],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2018-05-18T07:06:45.342+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/3","description":"This issue is being actively worked on at the moment by the assignee.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/inprogress.png","name":"In Progress","id":"3","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/4","id":4,"key":"indeterminate","colorName":"yellow","name":"In Progress"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12312927","id":"12312927","name":"datanode"}],"timeoriginalestimate":null,"description":"The current implementation of the Datanode will increase the DFS used space on each block write operation. This is correct in most scenario (create new file), but sometimes it will behave in-correct(append small data to a large block).\nFor example, I have a file with only one block(say, 60M). Then I try to append to it very frequently but each time I append only 10 bytes;\nThen on each append, dfs used will be increased with the length of the block(60M), not teh actual data length(10bytes).\nConsider in a scenario I use many clients to append concurrently to a large number of files (1000+), assume the block size is 32M (half of the default value), then the dfs used will be increased 1000*32M = 32G on each append to the files; but actually I only write 10K bytes; this will cause the datanode to report in-sufficient disk space on data write.\n{quote}2014-06-04 15:27:34,719 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: opWriteBlock  BP-1649188734-10.37.7.142-1398844098971:blk_1073742834_45306 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for appending to FinalizedReplica, blk_1073742834_45306, FINALIZED{quote}\nBut the actual disk usage:\n{quote}\n[root@hdsh143 ~]# df -h\nFilesystem            Size  Used Avail Use% Mounted on\n/dev/sda3              16G  2.9G   13G  20% /\ntmpfs                 1.9G   72K  1.9G   1% /dev/shm\n/dev/sda1              97M   32M   61M  35% /boot\n{quote}","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12795008","id":"12795008","filename":"HDFS-6489.001.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cheersyang","name":"cheersyang","key":"cheersyang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cheersyang&avatarId=23772","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cheersyang&avatarId=23772","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cheersyang&avatarId=23772","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cheersyang&avatarId=23772"},"displayName":"Weiwei Yang","active":true,"timeZone":"Asia/Shanghai"},"created":"2016-03-23T15:38:13.733+0000","size":9248,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12795008/HDFS-6489.001.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12795261","id":"12795261","filename":"HDFS-6489.002.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cheersyang","name":"cheersyang","key":"cheersyang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cheersyang&avatarId=23772","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cheersyang&avatarId=23772","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cheersyang&avatarId=23772","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cheersyang&avatarId=23772"},"displayName":"Weiwei Yang","active":true,"timeZone":"Asia/Shanghai"},"created":"2016-03-24T18:16:59.033+0000","size":12642,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12795261/HDFS-6489.002.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12797237","id":"12797237","filename":"HDFS-6489.003.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cheersyang","name":"cheersyang","key":"cheersyang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cheersyang&avatarId=23772","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cheersyang&avatarId=23772","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cheersyang&avatarId=23772","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cheersyang&avatarId=23772"},"displayName":"Weiwei Yang","active":true,"timeZone":"Asia/Shanghai"},"created":"2016-04-06T02:55:27.189+0000","size":14272,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12797237/HDFS-6489.003.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12801226","id":"12801226","filename":"HDFS-6489.004.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cheersyang","name":"cheersyang","key":"cheersyang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cheersyang&avatarId=23772","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cheersyang&avatarId=23772","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cheersyang&avatarId=23772","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cheersyang&avatarId=23772"},"displayName":"Weiwei Yang","active":true,"timeZone":"Asia/Shanghai"},"created":"2016-04-28T12:56:05.846+0000","size":12146,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12801226/HDFS-6489.004.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12801279","id":"12801279","filename":"HDFS-6489.005.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-04-28T17:01:42.253+0000","size":4319,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12801279/HDFS-6489.005.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12802702","id":"12802702","filename":"HDFS-6489.006.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-05-06T17:05:43.262+0000","size":6491,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12802702/HDFS-6489.006.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12803016","id":"12803016","filename":"HDFS-6489.007.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-05-09T16:18:18.751+0000","size":6790,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12803016/HDFS-6489.007.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12784153","id":"12784153","filename":"HDFS6489.java","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bograd","name":"bograd","key":"bograd","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Bogdan Raducanu","active":true,"timeZone":"Europe/Amsterdam"},"created":"2016-01-25T13:43:38.785+0000","size":1132,"mimeType":"text/x-java","content":"https://issues.apache.org/jira/secure/attachment/12784153/HDFS6489.java"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"396872","customfield_12312823":null,"summary":"DFS Used space is not correct computed on frequent append operations","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stanley_shi","name":"stanley_shi","key":"stanley_shi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"stanley shi","active":true,"timeZone":"Asia/Shanghai"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stanley_shi","name":"stanley_shi","key":"stanley_shi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"stanley shi","active":true,"timeZone":"Asia/Shanghai"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12718554/comment/14019280","id":"14019280","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=andrew.wang","name":"andrew.wang","key":"andrew.wang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=andrew.wang&avatarId=19230","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=andrew.wang&avatarId=19230","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=andrew.wang&avatarId=19230","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=andrew.wang&avatarId=19230"},"displayName":"Andrew Wang","active":true,"timeZone":"America/Los_Angeles"},"body":"This sounds like correct behavior to me. We don't know how many bytes a client is going to write to a block until it either asks for a new block or closes the file, so we conservatively say that the client might write the full block size. This makes sense to avoid writing incomplete blocks due to running out of disk space.\n\nIf you close the open streams, does the disk usage go back down? If so, I'm inclined to close as \"Not A Problem\".","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=andrew.wang","name":"andrew.wang","key":"andrew.wang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=andrew.wang&avatarId=19230","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=andrew.wang&avatarId=19230","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=andrew.wang&avatarId=19230","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=andrew.wang&avatarId=19230"},"displayName":"Andrew Wang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-06-05T21:06:59.264+0000","updated":"2014-06-05T21:06:59.264+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12718554/comment/14019492","id":"14019492","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stanley_shi","name":"stanley_shi","key":"stanley_shi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"stanley shi","active":true,"timeZone":"Asia/Shanghai"},"body":"No, the disk usage will not go back down untill after 10 minutes (the next round of \"du -sk\" is called). \n\nI printed the stack trace of the BlockPoolSlice.addBlock, which does the actual increase of the disk usage\n{quote}at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice.addBlock(BlockPoolSlice.ja\nva:157)\n        at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImpl.addBlock(FsVolumeImpl.java:1\n67)\n        at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.finalizeReplica(FsDatasetIm\npl.java:961)\n        at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.finalizeBlock(FsDatasetImpl\n.java:942)\n        at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:727)\n        at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:575)\n        at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:115)\n        at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:68)\n        at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:221)\n        at java.lang.Thread.run(Thread.java:722){quote}\nwe can see it is called at \"finalizeBlock\" phase. at this phase, we should already know how much data we wrote, then increasing the dfs usage with the total blocksize doesn't make sense.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stanley_shi","name":"stanley_shi","key":"stanley_shi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"stanley shi","active":true,"timeZone":"Asia/Shanghai"},"created":"2014-06-06T01:25:28.399+0000","updated":"2014-06-06T01:25:28.399+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12718554/comment/14026068","id":"14026068","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rguo","name":"rguo","key":"rguo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Guo Ruijing","active":true,"timeZone":"Etc/UTC"},"body":"Take example,\n\nexisting behavior:\n\n1. create file 60M with prefer block size 64M.\n2. append 10 bytes  (disk utilization is increased by 60M + 10 bytes, totally 120M + 10 bytes)\n3. append 10 bytes  (disk utilization is increased by  60M + 20 bytes, totally 120M + 30 bytes)\n4. append 10 bytes (disk utilization is increased by 60M + 30 bytes, totally 180M + 60bytes)\n\nexpected behavior:\n\n1. create file 60M with prefer block size 64M.\n2. append 10 bytes  (disk utilization is increased 10 bytes, totally 60M + 10 bytes)\n3. append 10 bytes  (disk utilization is increased 10 bytes, totally 60M + 20 bytes)\n4. append 10 bytes (disk utilization is increased 10 bytes, totally 60M + 30 bytes)","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rguo","name":"rguo","key":"rguo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Guo Ruijing","active":true,"timeZone":"Etc/UTC"},"created":"2014-06-10T02:55:58.299+0000","updated":"2014-06-10T02:55:58.299+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12718554/comment/14502637","id":"14502637","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=donglongchao","name":"donglongchao","key":"donglongchao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Longchao  Dong","active":true,"timeZone":"Asia/Shanghai"},"body":"Are there any more infomations on this issue? I am trying to solve this problem also.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=donglongchao","name":"donglongchao","key":"donglongchao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Longchao  Dong","active":true,"timeZone":"Asia/Shanghai"},"created":"2015-04-20T11:03:16.576+0000","updated":"2015-04-20T11:03:16.576+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12718554/comment/15115206","id":"15115206","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bograd","name":"bograd","key":"bograd","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Bogdan Raducanu","active":true,"timeZone":"Europe/Amsterdam"},"body":"I've recently hit this bug in 2.7.1. I attached repro code. The repro should fail with 'all datanodes are bad' exception while the datanode log will show the \"insufficient disk space\" exception.\nWhile the program is running you can see the reported \"Block pool used\" increase by a lot. A minute or two after the failure the \"Block pool used\" goes down to normal.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bograd","name":"bograd","key":"bograd","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Bogdan Raducanu","active":true,"timeZone":"Europe/Amsterdam"},"created":"2016-01-25T13:46:23.918+0000","updated":"2016-01-25T13:46:23.918+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12718554/comment/15203879","id":"15203879","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cheersyang","name":"cheersyang","key":"cheersyang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cheersyang&avatarId=23772","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cheersyang&avatarId=23772","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cheersyang&avatarId=23772","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cheersyang&avatarId=23772"},"displayName":"Weiwei Yang","active":true,"timeZone":"Asia/Shanghai"},"body":"This issue happened to us as well. We have some clients continually append data to HDFS, this causes the dfs usage jump up to a very high value and gives insufficient disk space issue just like this. It looks like HDFS refreshes the space usage in a time interval (with property fs.du.interval), default value is 600000, 10 minutes ... that means the dfs usage will be inaccurate and causing a lot of operations fail in 10 minutes (even client did close the streams). We really should have this fixed.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cheersyang","name":"cheersyang","key":"cheersyang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cheersyang&avatarId=23772","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cheersyang&avatarId=23772","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cheersyang&avatarId=23772","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cheersyang&avatarId=23772"},"displayName":"Weiwei Yang","active":true,"timeZone":"Asia/Shanghai"},"created":"2016-03-21T08:10:01.262+0000","updated":"2016-03-21T08:10:01.262+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12718554/comment/15208606","id":"15208606","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cheersyang","name":"cheersyang","key":"cheersyang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cheersyang&avatarId=23772","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cheersyang&avatarId=23772","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cheersyang&avatarId=23772","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cheersyang&avatarId=23772"},"displayName":"Weiwei Yang","active":true,"timeZone":"Asia/Shanghai"},"body":"I have a patch to fix this issue. The idea is during append, when datanode detects the space of the volume is insufficient,  instead of failing directly and trying a new node,  interrupts DURefreshThread and then evaluates the space again. This will let DU updates \"used\" variable to up-to-date, other than waiting for the long interval. \n\nI also wrote a test case, simulate a client  appends 10 bytes of data to a file continually. Before applying the patch, it fails even file system has plenty of spaces with following error \n\nbq. java.io.IOException: All datanodes DatanodeInfoWithStorage[127.0.0.1:58613,DS-a68ddbc7-2e49-428a-839b-d16bf58106fe,DISK] are bad. Aborting... ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cheersyang","name":"cheersyang","key":"cheersyang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cheersyang&avatarId=23772","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cheersyang&avatarId=23772","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cheersyang&avatarId=23772","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cheersyang&avatarId=23772"},"displayName":"Weiwei Yang","active":true,"timeZone":"Asia/Shanghai"},"created":"2016-03-23T15:36:26.111+0000","updated":"2016-03-23T15:36:26.111+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12718554/comment/15209074","id":"15209074","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 23s {color} | {color:blue} Docker mode activated. {color} |\n| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green} 0m 0s {color} | {color:green} The patch appears to include 2 new or modified test files. {color} |\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue} 1m 11s {color} | {color:blue} Maven dependency ordering for branch {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 7m 4s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 6m 4s {color} | {color:green} trunk passed with JDK v1.8.0_74 {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 6m 54s {color} | {color:green} trunk passed with JDK v1.7.0_95 {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 1m 7s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 53s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 29s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 3m 46s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 2m 4s {color} | {color:green} trunk passed with JDK v1.8.0_74 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 2m 57s {color} | {color:green} trunk passed with JDK v1.7.0_95 {color} |\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue} 0m 14s {color} | {color:blue} Maven dependency ordering for patch {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 1m 28s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 5m 56s {color} | {color:green} the patch passed with JDK v1.8.0_74 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 5m 56s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 6m 49s {color} | {color:green} the patch passed with JDK v1.7.0_95 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 6m 49s {color} | {color:green} the patch passed {color} |\n| {color:red}-1{color} | {color:red} checkstyle {color} | {color:red} 1m 8s {color} | {color:red} root: patch generated 1 new + 151 unchanged - 0 fixed = 152 total (was 151) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 53s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 30s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green} 0m 0s {color} | {color:green} Patch has no whitespace issues. {color} |\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red} 2m 20s {color} | {color:red} hadoop-hdfs-project/hadoop-hdfs generated 1 new + 0 unchanged - 0 fixed = 1 total (was 0) {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 2m 6s {color} | {color:green} the patch passed with JDK v1.8.0_74 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 2m 59s {color} | {color:green} the patch passed with JDK v1.7.0_95 {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 21m 39s {color} | {color:red} hadoop-common in the patch failed with JDK v1.8.0_74. {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 72m 2s {color} | {color:red} hadoop-hdfs in the patch failed with JDK v1.8.0_74. {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 7m 3s {color} | {color:red} hadoop-common in the patch failed with JDK v1.7.0_95. {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 75m 25s {color} | {color:red} hadoop-hdfs in the patch failed with JDK v1.7.0_95. {color} |\n| {color:red}-1{color} | {color:red} asflicense {color} | {color:red} 0m 25s {color} | {color:red} Patch generated 2 ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black} 239m 23s {color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| FindBugs | module:hadoop-hdfs-project/hadoop-hdfs |\n|  |  org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.append(String, FinalizedReplica, long, long) calls Thread.sleep() with a lock held  At FsDatasetImpl.java:Thread.sleep() with a lock held  At FsDatasetImpl.java:[line 1176] |\n| JDK v1.8.0_74 Failed junit tests | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure180 |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure020 |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure170 |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure200 |\n|   | hadoop.hdfs.TestDFSClientRetries |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure120 |\n|   | hadoop.hdfs.TestLeaseRecoveryStriped |\n|   | hadoop.hdfs.TestDFSStripedOutputStream |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure030 |\n|   | hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl |\n|   | hadoop.hdfs.server.datanode.fsdataset.impl.TestWriteToReplica |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure060 |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure190 |\n|   | hadoop.hdfs.TestEncryptedTransfer |\n| JDK v1.8.0_74 Timed out junit tests | org.apache.hadoop.util.TestNativeLibraryChecker |\n|   | org.apache.hadoop.http.TestHttpServerLifecycle |\n| JDK v1.7.0_95 Failed junit tests | hadoop.net.TestClusterTopology |\n|   | hadoop.hdfs.TestHFlush |\n|   | hadoop.hdfs.TestReplication |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure090 |\n|   | hadoop.hdfs.TestReadStripedFileWithDecoding |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure200 |\n|   | hadoop.hdfs.server.namenode.TestReconstructStripedBlocks |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure160 |\n|   | hadoop.hdfs.server.namenode.TestProcessCorruptBlocks |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure110 |\n|   | hadoop.hdfs.TestEncryptionZonesWithKMS |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure120 |\n|   | hadoop.hdfs.TestDFSStripedOutputStream |\n|   | hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl |\n|   | hadoop.hdfs.server.datanode.fsdataset.impl.TestWriteToReplica |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure060 |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure210 |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure080 |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure070 |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure190 |\n|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure040 |\n| JDK v1.7.0_95 Timed out junit tests | org.apache.hadoop.util.TestNativeLibraryChecker |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:fbe3e86 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12795008/HDFS-6489.001.patch |\n| JIRA Issue | HDFS-6489 |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux 77ab4c0dff4d 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / af1d125 |\n| Default Java | 1.7.0_95 |\n| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_74 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_95 |\n| findbugs | v3.0.0 |\n| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/14909/artifact/patchprocess/diff-checkstyle-root.txt |\n| findbugs | https://builds.apache.org/job/PreCommit-HDFS-Build/14909/artifact/patchprocess/new-findbugs-hadoop-hdfs-project_hadoop-hdfs.html |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/14909/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.8.0_74.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/14909/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.8.0_74.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/14909/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.7.0_95.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/14909/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.7.0_95.txt |\n| unit test logs |  https://builds.apache.org/job/PreCommit-HDFS-Build/14909/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.8.0_74.txt https://builds.apache.org/job/PreCommit-HDFS-Build/14909/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.8.0_74.txt https://builds.apache.org/job/PreCommit-HDFS-Build/14909/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.7.0_95.txt https://builds.apache.org/job/PreCommit-HDFS-Build/14909/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.7.0_95.txt |\n| JDK v1.7.0_95  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/14909/testReport/ |\n| asflicense | https://builds.apache.org/job/PreCommit-HDFS-Build/14909/artifact/patchprocess/patch-asflicense-problems.txt |\n| modules | C:  hadoop-common-project/hadoop-common   hadoop-hdfs-project/hadoop-hdfs  U: . |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/14909/console |\n| Powered by | Apache Yetus 0.2.0   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2016-03-23T20:09:18.210+0000","updated":"2016-03-23T20:09:18.210+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12718554/comment/15211371","id":"15211371","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 20s {color} | {color:blue} Docker mode activated. {color} |\n| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green} 0m 0s {color} | {color:green} The patch appears to include 3 new or modified test files. {color} |\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue} 0m 23s {color} | {color:blue} Maven dependency ordering for branch {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 11m 13s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 15m 20s {color} | {color:green} trunk passed with JDK v1.8.0_74 {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 11m 43s {color} | {color:green} trunk passed with JDK v1.7.0_95 {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 1m 41s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 2m 56s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 48s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 5m 20s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 3m 40s {color} | {color:green} trunk passed with JDK v1.8.0_74 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 4m 53s {color} | {color:green} trunk passed with JDK v1.7.0_95 {color} |\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue} 0m 23s {color} | {color:blue} Maven dependency ordering for patch {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 2m 24s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 15m 26s {color} | {color:green} the patch passed with JDK v1.8.0_74 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 15m 26s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 11m 42s {color} | {color:green} the patch passed with JDK v1.7.0_95 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 11m 42s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 1m 40s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 2m 54s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 45s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green} 0m 0s {color} | {color:green} Patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 6m 2s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 3m 45s {color} | {color:green} the patch passed with JDK v1.8.0_74 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 4m 52s {color} | {color:green} the patch passed with JDK v1.7.0_95 {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 13m 39s {color} | {color:red} hadoop-common in the patch failed with JDK v1.8.0_74. {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 81m 3s {color} | {color:red} hadoop-hdfs in the patch failed with JDK v1.8.0_74. {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 12m 22s {color} | {color:red} hadoop-common in the patch failed with JDK v1.7.0_95. {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 109m 7s {color} | {color:red} hadoop-hdfs in the patch failed with JDK v1.7.0_95. {color} |\n| {color:red}-1{color} | {color:red} asflicense {color} | {color:red} 0m 55s {color} | {color:red} Patch generated 2 ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black} 327m 45s {color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| JDK v1.8.0_74 Failed junit tests | hadoop.ipc.TestRPCWaitForProxy |\n|   | hadoop.fs.shell.find.TestIname |\n|   | hadoop.fs.shell.find.TestPrint0 |\n|   | hadoop.fs.shell.find.TestPrint |\n|   | hadoop.fs.shell.find.TestName |\n|   | hadoop.hdfs.server.namenode.ha.TestBootstrapStandby |\n|   | hadoop.hdfs.server.namenode.TestDeleteRace |\n|   | hadoop.hdfs.server.namenode.TestEditLog |\n|   | hadoop.hdfs.qjournal.TestSecureNNWithQJM |\n|   | hadoop.hdfs.server.namenode.ha.TestEditLogTailer |\n|   | hadoop.hdfs.TestDistributedFileSystem |\n|   | hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot |\n|   | hadoop.hdfs.security.TestDelegationTokenForProxyUser |\n|   | hadoop.hdfs.TestFileAppend |\n|   | hadoop.hdfs.TestSafeModeWithStripedFile |\n| JDK v1.8.0_74 Timed out junit tests | org.apache.hadoop.util.TestNativeLibraryChecker |\n|   | org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting |\n|   | org.apache.hadoop.hdfs.server.datanode.TestNNHandlesBlockReportPerStorage |\n|   | org.apache.hadoop.hdfs.server.datanode.TestNNHandlesCombinedBlockReport |\n|   | org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure |\n| JDK v1.7.0_95 Failed junit tests | hadoop.ipc.TestRPCWaitForProxy |\n|   | hadoop.fs.shell.find.TestIname |\n|   | hadoop.fs.shell.find.TestPrint0 |\n|   | hadoop.fs.shell.find.TestPrint |\n|   | hadoop.fs.shell.find.TestName |\n|   | hadoop.hdfs.server.datanode.TestDirectoryScanner |\n|   | hadoop.hdfs.server.namenode.ha.TestEditLogTailer |\n|   | hadoop.hdfs.server.datanode.TestDataNodeUUID |\n|   | hadoop.hdfs.server.datanode.TestDataNodeMultipleRegistrations |\n|   | hadoop.hdfs.security.TestDelegationTokenForProxyUser |\n|   | hadoop.hdfs.server.datanode.fsdataset.impl.TestWriteToReplica |\n|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure |\n| JDK v1.7.0_95 Timed out junit tests | org.apache.hadoop.util.TestNativeLibraryChecker |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:fbe3e86 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12795261/HDFS-6489.002.patch |\n| JIRA Issue | HDFS-6489 |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux ceeefd54ffd7 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / 2e1d0ff |\n| Default Java | 1.7.0_95 |\n| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_74 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_95 |\n| findbugs | v3.0.0 |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/14929/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.8.0_74.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/14929/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.8.0_74.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/14929/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.7.0_95.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/14929/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.7.0_95.txt |\n| unit test logs |  https://builds.apache.org/job/PreCommit-HDFS-Build/14929/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.8.0_74.txt https://builds.apache.org/job/PreCommit-HDFS-Build/14929/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.8.0_74.txt https://builds.apache.org/job/PreCommit-HDFS-Build/14929/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.7.0_95.txt https://builds.apache.org/job/PreCommit-HDFS-Build/14929/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.7.0_95.txt |\n| JDK v1.7.0_95  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/14929/testReport/ |\n| asflicense | https://builds.apache.org/job/PreCommit-HDFS-Build/14929/artifact/patchprocess/patch-asflicense-problems.txt |\n| modules | C:  hadoop-common-project/hadoop-common   hadoop-hdfs-project/hadoop-hdfs  U: . |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/14929/console |\n| Powered by | Apache Yetus 0.2.0   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2016-03-25T03:42:26.397+0000","updated":"2016-03-25T03:42:26.397+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12718554/comment/15214049","id":"15214049","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cheersyang","name":"cheersyang","key":"cheersyang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cheersyang&avatarId=23772","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cheersyang&avatarId=23772","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cheersyang&avatarId=23772","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cheersyang&avatarId=23772"},"displayName":"Weiwei Yang","active":true,"timeZone":"Asia/Shanghai"},"body":"Most of test failures are timeout, I can run them successfully on my laptop, the only failure was org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestWriteToReplica\n\n{quote}\nRunning org.apache.hadoop.hdfs.security.TestDelegationTokenForProxyUser\nTests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.861 sec - in org.apache.hadoop.hdfs.security.TestDelegationTokenForProxyUser\nRunning org.apache.hadoop.hdfs.server.namenode.ha.TestEditLogTailer\nTests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 28.426 sec - in org.apache.hadoop.hdfs.server.namenode.ha.TestEditLogTailer\nRunning org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestWriteToReplica\nTests run: 5, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 16.789 sec <<< FAILURE! - in org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestWriteToReplica\ntestAppend(org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestWriteToReplica)  Time elapsed: 2.146 sec  <<< FAILURE!\njava.lang.AssertionError: Should not have space to append to an RWR replicaBP-228064733-9.181.90.49-1459147940642:blk_4_2004\n\tat org.junit.Assert.fail(Assert.java:88)\n\tat org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestWriteToReplica.testAppend(TestWriteToReplica.java:181)\n\tat org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestWriteToReplica.testAppend(TestWriteToReplica.java:95)\nRunning org.apache.hadoop.hdfs.server.datanode.TestDirectoryScanner\nTests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 255.421 sec - in org.apache.hadoop.hdfs.server.datanode.TestDirectoryScanner\nRunning org.apache.hadoop.hdfs.server.datanode.TestDataNodeMultipleRegistrations\nTests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 69.761 sec - in org.apache.hadoop.hdfs.server.datanode.TestDataNodeMultipleRegistrations\nRunning org.apache.hadoop.hdfs.server.datanode.TestDataNodeUUID\nTests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.381 sec - in org.apache.hadoop.hdfs.server.datanode.TestDataNodeUUID\nRunning org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure\nTests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 36.823 sec - in org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure\n\nTests run: 35, Failures: 1, Errors: 0, Skipped: 0\n{quote}\n\nthis wasn't a code issue, this test was based on the old logic, I will upload v3 patch shortly to resolve this.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cheersyang","name":"cheersyang","key":"cheersyang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cheersyang&avatarId=23772","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cheersyang&avatarId=23772","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cheersyang&avatarId=23772","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cheersyang&avatarId=23772"},"displayName":"Weiwei Yang","active":true,"timeZone":"Asia/Shanghai"},"created":"2016-03-28T10:08:37.431+0000","updated":"2016-03-28T10:08:37.431+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12718554/comment/15227812","id":"15227812","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 8s {color} | {color:blue} Docker mode activated. {color} |\n| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green} 0m 0s {color} | {color:green} The patch appears to include 4 new or modified test files. {color} |\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue} 0m 13s {color} | {color:blue} Maven dependency ordering for branch {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 6m 31s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 6m 1s {color} | {color:green} trunk passed with JDK v1.8.0_77 {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 6m 39s {color} | {color:green} trunk passed with JDK v1.7.0_95 {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 1m 6s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 45s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 28s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 3m 25s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 2m 1s {color} | {color:green} trunk passed with JDK v1.8.0_77 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 2m 48s {color} | {color:green} trunk passed with JDK v1.7.0_95 {color} |\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue} 0m 15s {color} | {color:blue} Maven dependency ordering for patch {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 1m 26s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 5m 45s {color} | {color:green} the patch passed with JDK v1.8.0_77 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 5m 45s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 6m 31s {color} | {color:green} the patch passed with JDK v1.7.0_95 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 6m 31s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 1m 4s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 47s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 27s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green} 0m 0s {color} | {color:green} Patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 3m 58s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 58s {color} | {color:green} the patch passed with JDK v1.8.0_77 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 2m 46s {color} | {color:green} the patch passed with JDK v1.7.0_95 {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 16m 49s {color} | {color:red} hadoop-common in the patch failed with JDK v1.8.0_77. {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 67m 20s {color} | {color:red} hadoop-hdfs in the patch failed with JDK v1.8.0_77. {color} |\n| {color:green}+1{color} | {color:green} unit {color} | {color:green} 8m 58s {color} | {color:green} hadoop-common in the patch passed with JDK v1.7.0_95. {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 55m 8s {color} | {color:red} hadoop-hdfs in the patch failed with JDK v1.7.0_95. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green} 0m 24s {color} | {color:green} Patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black} 207m 6s {color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| JDK v1.8.0_77 Failed junit tests | hadoop.hdfs.server.namenode.ha.TestBootstrapStandbyWithQJM |\n|   | hadoop.hdfs.server.namenode.TestReconstructStripedBlocks |\n|   | hadoop.hdfs.TestEncryptionZones |\n| JDK v1.8.0_77 Timed out junit tests | org.apache.hadoop.http.TestHttpServerLifecycle |\n| JDK v1.7.0_95 Failed junit tests | hadoop.hdfs.server.datanode.TestDataNodeHotSwapVolumes |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:fbe3e86 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12797237/HDFS-6489.003.patch |\n| JIRA Issue | HDFS-6489 |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux 6a8c340fa461 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / 21eb428 |\n| Default Java | 1.7.0_95 |\n| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_77 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_95 |\n| findbugs | v3.0.0 |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/15084/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.8.0_77.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/15084/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.8.0_77.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/15084/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.7.0_95.txt |\n| unit test logs |  https://builds.apache.org/job/PreCommit-HDFS-Build/15084/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.8.0_77.txt https://builds.apache.org/job/PreCommit-HDFS-Build/15084/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.8.0_77.txt https://builds.apache.org/job/PreCommit-HDFS-Build/15084/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.7.0_95.txt |\n| JDK v1.7.0_95  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/15084/testReport/ |\n| modules | C:  hadoop-common-project/hadoop-common   hadoop-hdfs-project/hadoop-hdfs  U: . |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/15084/console |\n| Powered by | Apache Yetus 0.2.0   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2016-04-06T06:28:21.410+0000","updated":"2016-04-06T06:28:21.410+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12718554/comment/15234692","id":"15234692","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cheersyang","name":"cheersyang","key":"cheersyang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cheersyang&avatarId=23772","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cheersyang&avatarId=23772","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cheersyang&avatarId=23772","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cheersyang&avatarId=23772"},"displayName":"Weiwei Yang","active":true,"timeZone":"Asia/Shanghai"},"body":"These tests can run successfully on my local environment, attach the output \n{quote}\nTests run: 23, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 86.709 sec - in org.apache.hadoop.hdfs.TestEncryptionZones\nTests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 32.741 sec - in org.apache.hadoop.hdfs.server.namenode.ha.TestBootstrapStandbyWithQJM\nTests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 54.997 sec - in org.apache.hadoop.hdfs.server.namenode.TestReconstructStripedBlocks\nTests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.338 sec - in org.apache.hadoop.http.TestHttpServerLifecycle\nTests run: 12, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 77.343 sec - in org.apache.hadoop.hdfs.server.datanode.TestDataNodeHotSwapVolumes\n{quote}\nCan someone help to review this patch? Thanks a lot.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cheersyang","name":"cheersyang","key":"cheersyang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cheersyang&avatarId=23772","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cheersyang&avatarId=23772","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cheersyang&avatarId=23772","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cheersyang&avatarId=23772"},"displayName":"Weiwei Yang","active":true,"timeZone":"Asia/Shanghai"},"created":"2016-04-11T08:27:23.794+0000","updated":"2016-04-11T08:27:23.794+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12718554/comment/15250592","id":"15250592","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks for the patch [~cheersyang]! Could you please let me know which branch I should apply it against and how? I am seeing conflicts. Usually we start with patches towards trunk, and then after it gets committed to trunk, backport it to branch-2","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-04-20T20:01:39.614+0000","updated":"2016-04-20T20:01:39.614+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12718554/comment/15250626","id":"15250626","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"body":"Unfortunately I don't think your approach will work Weiwei! The du thread takes really long times. On a single datanode there may be millions of files and thus the du takes a while to complete.\nI would concur with Andrew's opinion *unless* the following is happening\n1. Appending to the same file multiple times without closing is causing DFS usage to jump by block size every time. It seems [~andrew.wang] that users are reporting such behavior. It may be worth a look\n2. We are rejecting writes on the datanodes based on (possibly outdated) information from the DU thread. If we are going to wait for the DU thread to update available space before writing, we may be rejecting for a long time.\nPlease let me know if I somehow misunderstand the issue / symptoms.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-04-20T20:17:34.831+0000","updated":"2016-04-20T20:17:34.831+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12718554/comment/15250640","id":"15250640","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"body":"From Bogdan's code (thanks for that :-) ) I see its not #1 in my comment above, but #2 that is causing the problem. I'll check to see if there is a workaround","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-04-20T20:24:55.007+0000","updated":"2016-04-20T20:24:55.007+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12718554/comment/15251140","id":"15251140","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cheersyang","name":"cheersyang","key":"cheersyang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cheersyang&avatarId=23772","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cheersyang&avatarId=23772","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cheersyang&avatarId=23772","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cheersyang&avatarId=23772"},"displayName":"Weiwei Yang","active":true,"timeZone":"Asia/Shanghai"},"body":"[~raviprak] Thanks for looking at this. \n\n#1 Yes, this issue can be reproduced with appending same file lots of times (each time we close the stream), and also appending different files. The real thing matters is you use append API quite some times in a short time window.\n\n#2 I was proposing to wait DU thread to refresh only when on a datanode, it is found the space is not enough for an append operation, this only happens at the time when that wait benefits (rather than fail). And once the space usage is updated, you would not need to wait for sometime until the problem comes up again. I'd love to know if you have any alternative approach.\n\nI'll upload a patch that can apply to latest trunk shortly. Thanks for looking into this.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cheersyang","name":"cheersyang","key":"cheersyang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cheersyang&avatarId=23772","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cheersyang&avatarId=23772","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cheersyang&avatarId=23772","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cheersyang&avatarId=23772"},"displayName":"Weiwei Yang","active":true,"timeZone":"Asia/Shanghai"},"created":"2016-04-21T02:33:15.236+0000","updated":"2016-04-21T02:33:15.236+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12718554/comment/15251992","id":"15251992","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cheersyang","name":"cheersyang","key":"cheersyang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cheersyang&avatarId=23772","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cheersyang&avatarId=23772","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cheersyang&avatarId=23772","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cheersyang&avatarId=23772"},"displayName":"Weiwei Yang","active":true,"timeZone":"Asia/Shanghai"},"body":"The conflict was caused by some changes from HADOOP-12973, I'll consolidate a patch based on that. Appreciate any comments, thanks.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cheersyang","name":"cheersyang","key":"cheersyang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cheersyang&avatarId=23772","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cheersyang&avatarId=23772","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cheersyang&avatarId=23772","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cheersyang&avatarId=23772"},"displayName":"Weiwei Yang","active":true,"timeZone":"Asia/Shanghai"},"created":"2016-04-21T14:49:55.860+0000","updated":"2016-04-21T14:49:55.860+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12718554/comment/15260954","id":"15260954","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"body":"The problem is here: https://github.com/apache/hadoop/blob/f16722d2ef31338a57a13e2c8d18c1c62d58bbaf/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/BlockPoolSlice.java#L323 . Even though this is an append, {{dfsUsage}} is incremented by the total block size every time. This can be easily seen by running the {{testFrequentAppend}} (included in Weiwei's patch) and adding a log line after line 323.\nAs far as I can see, this problem existed since 2012, but only recently did this become problematic because we started considering dfsUsed space in deciding whether to write a block or not.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-04-27T21:12:09.723+0000","updated":"2016-04-27T21:12:09.723+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12718554/comment/15262089","id":"15262089","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cheersyang","name":"cheersyang","key":"cheersyang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cheersyang&avatarId=23772","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cheersyang&avatarId=23772","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cheersyang&avatarId=23772","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cheersyang&avatarId=23772"},"displayName":"Weiwei Yang","active":true,"timeZone":"Asia/Shanghai"},"body":"Revised the patch so it can be applied to trunk. Not sure if there is better approach to resolve this, I attach the patch and appreciate any comments.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cheersyang","name":"cheersyang","key":"cheersyang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cheersyang&avatarId=23772","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cheersyang&avatarId=23772","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cheersyang&avatarId=23772","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cheersyang&avatarId=23772"},"displayName":"Weiwei Yang","active":true,"timeZone":"Asia/Shanghai"},"created":"2016-04-28T12:56:05.850+0000","updated":"2016-04-28T12:56:05.850+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12718554/comment/15262527","id":"15262527","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"body":"Here's a patch which reduces the dfsUsed space when a finalized replica is converted to an RBW (replica-being-written) on an append so that on finalization, the counts are correct. This lets {{testFrequentAppend}} pass.\n\nI'll see if it doesn't make sense to add to dfsUsed only the delta during finalize.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-04-28T17:01:42.257+0000","updated":"2016-04-28T17:01:42.257+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12718554/comment/15274356","id":"15274356","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"body":"It *did* make more sense to change only by the additional bytes appended. Here's a patch to do so. Could someone please review? ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-05-06T17:05:43.267+0000","updated":"2016-05-06T17:05:43.267+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12718554/comment/15274790","id":"15274790","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=andrew.wang","name":"andrew.wang","key":"andrew.wang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=andrew.wang&avatarId=19230","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=andrew.wang&avatarId=19230","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=andrew.wang&avatarId=19230","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=andrew.wang&avatarId=19230"},"displayName":"Andrew Wang","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi Ravi, thanks for working on this. Some comments:\n\n* Unused imports in new test\n* metaFile is unused now that the code is removed from addFinalizedBlock\n* There are multiple callers of FSDatasetImpl#finalizeReplica, and now we only increment dfsUsed when ReplicaState is RBW. Is this intended behavior?\n* If possible, I'd prefer to do this logic in FsVolumeImpl#addFinalizedBlock, since that's where other space tracking is happening.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=andrew.wang","name":"andrew.wang","key":"andrew.wang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=andrew.wang&avatarId=19230","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=andrew.wang&avatarId=19230","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=andrew.wang&avatarId=19230","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=andrew.wang&avatarId=19230"},"displayName":"Andrew Wang","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-05-06T21:52:30.213+0000","updated":"2016-05-06T21:52:30.213+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12718554/comment/15276564","id":"15276564","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"body":"Andrew! Thanks for the review. Here's a patch with the changes you suggest. I am sticking with conditional for RBW for now because 1. Its the common case, 2. RUR doesn't have {{originalBytesReserved}}.\n\nEven with this, {{dfsUsed}} and {{numblocks}} counting is all messed up. e.g. [FsDatasetImpl.removeOldBlock|https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java#L2886] calls {{decDfsUsedAndNumBlocks}} twice (so even though {{dfsUsed}} is correctly decremented, {{numBlocks}} is not) . [~brahmareddy], [~vinayrpet] am I reading this right?\n\nTo really get this sorted out, we should probably have a unit test framework that tests DN side accounting is proper for several different operations (block creation, appends, block transfer (e.g. from 1 storage to another), etc.). Unfortunately, I don't think I'll have the cycles for that. Sorry :(\nArpit has seemed amenable to [removing reservations|https://issues.apache.org/jira/browse/HDFS-9530?focusedCommentId=15248968&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-15248968] if there is some other alternative. I think we should disable the rejection of writes by DNs based on reservations until we can be sure that our accounting is correct. Just my $0.02","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-05-09T16:18:18.755+0000","updated":"2016-05-09T16:18:18.755+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12718554/comment/15276872","id":"15276872","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=andrew.wang","name":"andrew.wang","key":"andrew.wang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=andrew.wang&avatarId=19230","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=andrew.wang&avatarId=19230","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=andrew.wang&avatarId=19230","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=andrew.wang&avatarId=19230"},"displayName":"Andrew Wang","active":true,"timeZone":"America/Los_Angeles"},"body":"I guess this means that the available space block placement policy is also broken then :( Agree that we need a methodical rework.\n\nI'm a +0.5 on this patch, it looks good to me, but would need to spend more time understanding the existing accounting before I could +1. If another reviewer more familiar with this area can also review, that'd be appreciated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=andrew.wang","name":"andrew.wang","key":"andrew.wang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=andrew.wang&avatarId=19230","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=andrew.wang&avatarId=19230","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=andrew.wang&avatarId=19230","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=andrew.wang&avatarId=19230"},"displayName":"Andrew Wang","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-05-09T19:30:38.555+0000","updated":"2016-05-09T19:30:38.555+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12718554/comment/16119138","id":"16119138","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi [~brahmareddy]! Could you please update us on this issue? Also, what do you think about a robust unit-test framework to find out all these issues?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-08-08T22:37:16.107+0000","updated":"2017-08-08T22:37:16.107+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12718554/comment/16119797","id":"16119797","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brahmareddy","name":"brahmareddy","key":"brahmareddy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=brahmareddy&avatarId=24624","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=brahmareddy&avatarId=24624","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=brahmareddy&avatarId=24624","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=brahmareddy&avatarId=24624"},"displayName":"Brahma Reddy Battula","active":true,"timeZone":"Asia/Kolkata"},"body":"bq.Even with this, dfsUsed and numblocks counting is all messed up. e.g. FsDatasetImpl.removeOldBlock calls decDfsUsedAndNumBlocks twice (so even though dfsUsed is correctly decremented, numBlocks is not)\nNope. I believe you read this wrong.\n{{FsDatasetImpl#removeOldReplica}} call two seperate calls {{onBlockFileDeletion(..)}} and {{onMetaFileDeletion(...)}} for {{blockfile}} and {{metafile}} respectively.\n{code}\n    // Remove the old replicas\n    if (replicaInfo.deleteBlockData() || !replicaInfo.blockDataExists()) {\n      FsVolumeImpl volume = (FsVolumeImpl) replicaInfo.getVolume();\n      volume.onBlockFileDeletion(bpid, replicaInfo.getBytesOnDisk());\n      if (replicaInfo.deleteMetadata() || !replicaInfo.metadataExists()) {\n        volume.onMetaFileDeletion(bpid, replicaInfo.getMetadataLength());\n      }\n{code}\n\n *Code from {{FsVolumeImpl.java}}* \n{code}\n void onBlockFileDeletion(String bpid, long value) {\n    decDfsUsedAndNumBlocks(bpid, value, true);\n    if (isTransientStorage()) {\n      dataset.releaseLockedMemory(value, true);\n    }\n  }\n\n  void onMetaFileDeletion(String bpid, long value) {\n    decDfsUsedAndNumBlocks(bpid, value, false);\n  }\n\n  private void decDfsUsedAndNumBlocks(String bpid, long value,\n                                      boolean blockFileDeleted) {\n    try(AutoCloseableLock lock = dataset.acquireDatasetLock()) {\n      BlockPoolSlice bp = bpSlices.get(bpid);\n      if (bp != null) {\n        bp.decDfsUsed(value);\n        if (blockFileDeleted) {\n          bp.decrNumBlocks();\n        }\n      }\n    }\n  }\n{code}\n\n{{onBlockFileDeletion(..)}} calls {{decDfsUsedAndNumBlocks(bpid, value, true);}} with {{blockFileDeleted}} flag as {{true}} to drement the {{numblocks}},where as   {{onMetaFileDeletion(...)}} calls {{decDfsUsedAndNumBlocks(bpid, value, false);}} with {{blockFileDeleted}} flag as {{false}}.Because,no need to decrement the {{numblocks}} for metafile deletion.\n\n\nbq.Also, what do you think about a robust unit-test framework to find out all these issues?\n\nOnly way is to list all write/delete cases and write tests for that\n\n *Comments for this Jira* \n\n1) only {{incDfsUsed()}} should be used, as {{numBlocks}} will be updated during {{createRbw()}} for new blocks. For {{append}} incrementing {{numBlocks}} not required.\n2) Previous metadata length also should be deducted.\n{code}\n860\t    if(b instanceof ReplicaInfo) {\n861\t      ReplicaInfo replicaInfo  = ((ReplicaInfo) b);\n862\t      if(replicaInfo.getState() == ReplicaState.RBW) {\n863\t        ReplicaInPipeline rip = (ReplicaInPipeline) replicaInfo;\n864\t        // rip.getOriginalBytesReserved() - rip.getBytesReserved()\n865\t        // is the amount of data that was written to the replica\n866\t        long bytesAdded = rip.getOriginalBytesReserved() -\n867\t        rip.getBytesReserved() + replicaInfo.getMetaFile().length();\n868\t        incDfsUsedAndNumBlocks(bpid, bytesAdded);\n869\t      }\n870\t    }\n{code}\n\nSorry for late reply.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brahmareddy","name":"brahmareddy","key":"brahmareddy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=brahmareddy&avatarId=24624","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=brahmareddy&avatarId=24624","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=brahmareddy&avatarId=24624","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=brahmareddy&avatarId=24624"},"displayName":"Brahma Reddy Battula","active":true,"timeZone":"Asia/Kolkata"},"created":"2017-08-09T12:22:39.907+0000","updated":"2017-08-09T12:22:39.907+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12718554/comment/16120964","id":"16120964","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cheersyang","name":"cheersyang","key":"cheersyang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cheersyang&avatarId=23772","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cheersyang&avatarId=23772","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cheersyang&avatarId=23772","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cheersyang&avatarId=23772"},"displayName":"Weiwei Yang","active":true,"timeZone":"Asia/Shanghai"},"body":"I am un-assigning myself from this ticket, [~raviprak] do you want to take this over?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cheersyang","name":"cheersyang","key":"cheersyang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cheersyang&avatarId=23772","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cheersyang&avatarId=23772","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cheersyang&avatarId=23772","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cheersyang&avatarId=23772"},"displayName":"Weiwei Yang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-08-10T02:41:31.666+0000","updated":"2017-08-10T02:41:31.666+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12718554/comment/16155977","id":"16155977","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks for your reply [~brahmareddy]! Sorry about the tangent on {{FsDatasetImpl#removeOldReplica}} . I'm afraid I'm also not sure you are the point person on this. Could you please redirect me to the right person if you're not?\n\nLet's focus on the {{HDFS6489.java}} test in written and reported by Bogdan. I see that it still fails on trunk. Here's the output\n{code}\n$ java HDFS6489\ndoing small appends...\n17/09/06 13:20:25 INFO hdfs.DataStreamer: Exception in createBlockOutputStream blk_1073741835_1057\njava.io.EOFException: Unexpected EOF while trying to read response from server\n\tat org.apache.hadoop.hdfs.protocolPB.PBHelperClient.vintPrefixed(PBHelperClient.java:444)\n\tat org.apache.hadoop.hdfs.DataStreamer.createBlockOutputStream(DataStreamer.java:1750)\n\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1495)\n\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)\n\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:737)\nException in thread \"main\" java.io.IOException: All datanodes [DatanodeInfoWithStorage[127.0.0.1:9866,DS-af60f3f1-eb86-46c2-821a-8d2f1dcb339d,DISK]] are bad. Aborting...\n\tat org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1549)\n\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1483)\n\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)\n\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:737)\n{code}\nWhy do you think that is?\n\nWhere is the code you posted last? I wasn't able to find it in trunk or branch-2","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-09-06T20:23:15.893+0000","updated":"2017-09-12T05:50:20.801+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12718554/comment/16163094","id":"16163094","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brahmareddy","name":"brahmareddy","key":"brahmareddy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=brahmareddy&avatarId=24624","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=brahmareddy&avatarId=24624","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=brahmareddy&avatarId=24624","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=brahmareddy&avatarId=24624"},"displayName":"Brahma Reddy Battula","active":true,"timeZone":"Asia/Kolkata"},"body":"bq.Where is the code you posted last? I wasn't able to find it in trunk or branch-2\nit's from the patch [HDFS-6489.007.patch|https://issues.apache.org/jira/secure/attachment/12803016/HDFS-6489.007.patch] you uploaded.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brahmareddy","name":"brahmareddy","key":"brahmareddy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=brahmareddy&avatarId=24624","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=brahmareddy&avatarId=24624","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=brahmareddy&avatarId=24624","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=brahmareddy&avatarId=24624"},"displayName":"Brahma Reddy Battula","active":true,"timeZone":"Asia/Kolkata"},"created":"2017-09-12T15:10:24.665+0000","updated":"2017-09-12T15:10:24.665+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12718554/comment/16381584","id":"16381584","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=striver.wang","name":"striver.wang","key":"striver.wang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=striver.wang&avatarId=34755","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=striver.wang&avatarId=34755","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=striver.wang&avatarId=34755","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=striver.wang&avatarId=34755"},"displayName":"wangzhiyuan","active":true,"timeZone":"Etc/UTC"},"body":"Any update about this issue?   I think frequent truncate will have the same issue.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=striver.wang","name":"striver.wang","key":"striver.wang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=striver.wang&avatarId=34755","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=striver.wang&avatarId=34755","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=striver.wang&avatarId=34755","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=striver.wang&avatarId=34755"},"displayName":"wangzhiyuan","active":true,"timeZone":"Etc/UTC"},"created":"2018-03-01T06:37:12.669+0000","updated":"2018-03-01T06:37:12.669+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12718554/comment/16480265","id":"16480265","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"HI Guys,\r\n\r\nThanks for working on this issue. I have gone through the discussions, would like to share my thoughts:\r\n\r\n- The append operation tend to happen many times on the same block, this makes it easy to deny write due to incorrect DU estimation of append.\r\n- [~cheersyang]'s approach tries to remedy the situation by \"interrupts DURefreshThread and then evaluates the space again\", however, it would be too slow to help ongoing writes.\r\n- [~raviprak]'s approach tries not to include block size when incr DU when converting complete block to RBW (append). This might under estimate the disk usage, and cause over subscription of a DN capacity, and cause write to fail. The fs.du.interval is 10 minutes by default, the oversubscription (if any) can be corrected in 10 minutes (right Ravi?). So the chance of this failure is relatively low. \r\n\r\nSounds like we can go with Ravi's solution if the accounting is corrected every 10 minutes. Given that we don't have a perfect solution for this problem, and DU is an estimation anyways.\r\n\r\nWhat do you guys think?\r\n\r\nThanks.\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2018-05-18T07:06:45.342+0000","updated":"2018-05-18T07:06:45.342+0000"}],"maxResults":31,"total":31,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-6489/votes","votes":2,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i1wb1b:"}}