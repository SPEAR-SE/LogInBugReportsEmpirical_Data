{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12751016","self":"https://issues.apache.org/jira/rest/api/2/issue/12751016","key":"HDFS-7299","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":"2014-10-28T08:37:29.310+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Mon Nov 03 05:25:07 UTC 2014","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-7299/watchers","watchCount":6,"isWatching":false},"created":"2014-10-28T07:44:53.754+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12320353","id":"12320353","description":"hadoop-2.0.0-alpha release","name":"2.0.0-alpha","archived":false,"released":true,"releaseDate":"2012-05-23"}],"issuelinks":[],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2014-11-03T05:25:07.853+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"components":[],"timeoriginalestimate":null,"description":"Hadoop Namenode is getting failed because of some unexpected value of block size in fsimage.\n\nStack trace:\n{code}\n2014-10-27 16:22:12,107 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: \n/************************************************************\nSTARTUP_MSG: Starting NameNode\nSTARTUP_MSG:   host = <mastermachine-hostname>/<ip>\nSTARTUP_MSG:   args = []\nSTARTUP_MSG:   version = 2.0.0-cdh4.4.0\nSTARTUP_MSG:   classpath = /var/run/cloudera-scm-agent/process/12726-hdfs-NAMENODE:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/hue-plugins-2.5.0-cdh4.4.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/activation-1.1.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/jetty-6.1.26.cloudera.2.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/jersey-core-1.8.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/jackson-xc-1.8.8.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/jasper-compiler-5.5.23.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/guava-11.0.2.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/commons-collections-3.2.1.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/paranamer-2.3.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/commons-net-3.1.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/xz-1.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/commons-beanutils-core-1.8.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/commons-cli-1.2.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/jetty-util-6.1.26.cloudera.2.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/zookeeper-3.4.5-cdh4.4.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/jackson-mapper-asl-1.8.8.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/jackson-jaxrs-1.8.8.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/slf4j-api-1.6.1.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/stax-api-1.0.1.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/snappy-java-1.0.4.1.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/jline-0.9.94.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/commons-beanutils-1.7.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/jsp-api-2.1.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/jsr305-1.3.9.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/commons-logging-1.1.1.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/commons-digester-1.8.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/xmlenc-0.52.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/jackson-core-asl-1.8.8.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/log4j-1.2.17.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/slf4j-log4j12-1.6.1.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/jersey-server-1.8.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/servlet-api-2.5.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/jettison-1.1.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/commons-httpclient-3.1.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/commons-math-2.1.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/jets3t-0.6.1.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/commons-el-1.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/avro-1.7.4.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/commons-codec-1.4.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/commons-lang-2.5.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/jersey-json-1.8.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/kfs-0.3.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/jasper-runtime-5.5.23.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/commons-configuration-1.6.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/junit-4.8.2.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/mockito-all-1.8.5.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/commons-io-2.1.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/protobuf-java-2.4.0a.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/jsch-0.1.42.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/commons-compress-1.4.1.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/jaxb-api-2.2.2.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/jaxb-impl-2.2.3-1.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/asm-3.2.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/.//hadoop-common.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/.//hadoop-annotations.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/.//hive-serdes-1.0-SNAPSHOT.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/.//hadoop-annotations-2.0.0-cdh4.4.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/.//hadoop-common-2.0.0-cdh4.4.0-tests.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/.//hadoop-auth.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/.//hadoop-auth-2.0.0-cdh4.4.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/.//hadoop-common-2.0.0-cdh4.4.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-hdfs/./:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-hdfs/lib/jetty-6.1.26.cloudera.2.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-hdfs/lib/jersey-core-1.8.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-hdfs/lib/guava-11.0.2.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-hdfs/lib/commons-cli-1.2.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-hdfs/lib/jetty-util-6.1.26.cloudera.2.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-hdfs/lib/zookeeper-3.4.5-cdh4.4.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-hdfs/lib/jackson-mapper-asl-1.8.8.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-hdfs/lib/jline-0.9.94.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-hdfs/lib/jsp-api-2.1.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-hdfs/lib/jsr305-1.3.9.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-hdfs/lib/commons-logging-1.1.1.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-hdfs/lib/xmlenc-0.52.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-hdfs/lib/jackson-core-asl-1.8.8.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-hdfs/lib/log4j-1.2.17.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-hdfs/lib/jersey-server-1.8.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-hdfs/lib/servlet-api-2.5.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-hdfs/lib/commons-daemon-1.0.3.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-hdfs/lib/commons-el-1.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-hdfs/lib/commons-codec-1.4.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-hdfs/lib/commons-lang-2.5.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-hdfs/lib/jasper-runtime-5.5.23.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-hdfs/lib/commons-io-2.1.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-hdfs/lib/protobuf-java-2.4.0a.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-hdfs/lib/asm-3.2.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-hdfs/.//hadoop-hdfs.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-hdfs/.//hadoop-hdfs-2.0.0-cdh4.4.0-tests.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-hdfs/.//hadoop-hdfs-2.0.0-cdh4.4.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/lib/javax.inject-1.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/lib/jersey-core-1.8.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/lib/paranamer-2.3.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/lib/netty-3.2.4.Final.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/lib/xz-1.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/lib/jackson-mapper-asl-1.8.8.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/lib/snappy-java-1.0.4.1.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/lib/jackson-core-asl-1.8.8.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/lib/log4j-1.2.17.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/lib/jersey-server-1.8.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/lib/jersey-guice-1.8.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/lib/avro-1.7.4.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/lib/guice-3.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/lib/aopalliance-1.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/lib/guice-servlet-3.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/lib/commons-io-2.1.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/lib/protobuf-java-2.4.0a.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/lib/commons-compress-1.4.1.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/lib/asm-3.2.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/.//hadoop-yarn-server-tests-2.0.0-cdh4.4.0-tests.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/.//hadoop-yarn-applications-distributedshell-2.0.0-cdh4.4.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/.//hadoop-yarn-server-web-proxy.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher-2.0.0-cdh4.4.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/.//hadoop-yarn-server-nodemanager-2.0.0-cdh4.4.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/.//hadoop-yarn-server-resourcemanager.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/.//hadoop-yarn-site.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/.//hadoop-yarn-common.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/.//hadoop-yarn-site-2.0.0-cdh4.4.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/.//hadoop-yarn-server-tests-2.0.0-cdh4.4.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/.//hadoop-yarn-client.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/.//hadoop-yarn-server-resourcemanager-2.0.0-cdh4.4.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/.//hadoop-yarn-server-web-proxy-2.0.0-cdh4.4.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/.//hadoop-yarn-server-tests.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/.//hadoop-yarn-client-2.0.0-cdh4.4.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/.//hadoop-yarn-server-common-2.0.0-cdh4.4.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/.//hadoop-yarn-applications-distributedshell.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/.//hadoop-yarn-common-2.0.0-cdh4.4.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/.//hadoop-yarn-api.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/.//hadoop-yarn-server-nodemanager.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/.//hadoop-yarn-api-2.0.0-cdh4.4.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/.//hadoop-yarn-server-common.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/lib/javax.inject-1.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/lib/jersey-core-1.8.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/lib/paranamer-2.3.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/lib/netty-3.2.4.Final.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/lib/xz-1.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/lib/jackson-mapper-asl-1.8.8.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/lib/jackson-core-asl-1.8.8.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/lib/log4j-1.2.17.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/lib/jersey-server-1.8.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/lib/jersey-guice-1.8.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/lib/avro-1.7.4.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/lib/guice-3.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/lib/aopalliance-1.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/lib/guice-servlet-3.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/lib/commons-io-2.1.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/lib/protobuf-java-2.4.0a.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/lib/commons-compress-1.4.1.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/lib/asm-3.2.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/.//hadoop-streaming.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-2.0.0-cdh4.4.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/.//hadoop-distcp.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/.//hadoop-archives.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/.//hadoop-archives-2.0.0-cdh4.4.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/.//hadoop-gridmix-2.0.0-cdh4.4.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-common-2.0.0-cdh4.4.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/.//hadoop-datajoin.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/.//hadoop-rumen.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/.//hadoop-distcp-2.0.0-cdh4.4.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/.//hadoop-extras-2.0.0-cdh4.4.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins-2.0.0-cdh4.4.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/.//hadoop-rumen-2.0.0-cdh4.4.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-core.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/.//hadoop-streaming-2.0.0-cdh4.4.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-app.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle-2.0.0-cdh4.4.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/.//hadoop-mapreduce-examples-2.0.0-cdh4.4.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/.//hadoop-mapreduce-examples.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/.//hadoop-gridmix.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-2.0.0-cdh4.4.0-tests.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-core-2.0.0-cdh4.4.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-2.0.0-cdh4.4.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-app-2.0.0-cdh4.4.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/.//hadoop-datajoin-2.0.0-cdh4.4.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-common.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/.//hadoop-extras.jar:/usr/share/cmf/lib/plugins/event-publish-4.7.2-shaded.jar:/usr/share/cmf/lib/plugins/navigator-plugin-4.7.2-shaded.jar:/usr/share/cmf/lib/plugins/tt-instrumentation-4.7.2.jar\nSTARTUP_MSG:   build = file:///data/1/jenkins/workspace/generic-package-rhel64-6-0/topdir/BUILD/hadoop-2.0.0-cdh4.4.0/src/hadoop-common-project/hadoop-common -r c0eba6cd38c984557e96a16ccd7356b7de835e79; compiled by 'jenkins' on Tue Sep  3 19:33:17 PDT 2013\nSTARTUP_MSG:   java = 1.7.0_45\n************************************************************/\n2014-10-27 16:22:12,129 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]\n2014-10-27 16:22:12,695 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties\n2014-10-27 16:22:12,725 INFO org.apache.hadoop.metrics2.impl.MetricsSinkAdapter: Sink ganglia started\n2014-10-27 16:22:12,823 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).\n2014-10-27 16:22:12,823 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started\n2014-10-27 16:22:13,114 INFO org.apache.hadoop.util.HostsFileReader: Adding <IP1> to the list of included hosts from /var/run/cloudera-scm-agent/process/12726-hdfs-NAMENODE/dfs_hosts_allow.txt\n2014-10-27 16:22:13,114 INFO org.apache.hadoop.util.HostsFileReader: Adding <IP2> to the list of included hosts from /var/run/cloudera-scm-agent/process/12726-hdfs-NAMENODE/dfs_hosts_allow.txt\n2014-10-27 16:22:13,114 INFO org.apache.hadoop.util.HostsFileReader: Adding <IP3> to the list of included hosts from /var/run/cloudera-scm-agent/process/12726-hdfs-NAMENODE/dfs_hosts_allow.txt\n2014-10-27 16:22:13,114 INFO org.apache.hadoop.util.HostsFileReader: Adding <IP4> to the list of included hosts from /var/run/cloudera-scm-agent/process/12726-hdfs-NAMENODE/dfs_hosts_allow.txt\n2014-10-27 16:22:13,114 INFO org.apache.hadoop.util.HostsFileReader: Adding <IP5> to the list of included hosts from /var/run/cloudera-scm-agent/process/12726-hdfs-NAMENODE/dfs_hosts_allow.txt\n2014-10-27 16:22:13,114 INFO org.apache.hadoop.util.HostsFileReader: Adding <IP6> to the list of included hosts from /var/run/cloudera-scm-agent/process/12726-hdfs-NAMENODE/dfs_hosts_allow.txt\n2014-10-27 16:22:13,115 INFO org.apache.hadoop.util.HostsFileReader: Adding <IP7> to the list of included hosts from /var/run/cloudera-scm-agent/process/12726-hdfs-NAMENODE/dfs_hosts_allow.txt\n2014-10-27 16:22:13,115 INFO org.apache.hadoop.util.HostsFileReader: Adding <IP8> to the list of included hosts from /var/run/cloudera-scm-agent/process/12726-hdfs-NAMENODE/dfs_hosts_allow.txt\n2014-10-27 16:22:13,116 INFO org.apache.hadoop.hdfs.server.namenode.HostFileManager: read includes:\nHostSet(\n\t<IP1>->Entry{<IP1>, port=0, ipAddress=<IP1>}\n\t<IP2>->Entry{<IP2>, port=0, ipAddress=<IP2>}\n\t<IP3>->Entry{<IP3>, port=0, ipAddress=<IP3>}\n\t<IP4>->Entry{<IP4>, port=0, ipAddress=<IP4>}\n\t<IP5>->Entry{<IP5>, port=0, ipAddress=<IP5>}\n\t<IP6>->Entry{<IP6>, port=0, ipAddress=<IP6>}\n\t<IP7>->Entry{<IP7>, port=0, ipAddress=<IP7>}\n\t<IP8>->Entry{<IP8>, port=0, ipAddress=<IP8>}\n)\n2014-10-27 16:22:13,116 INFO org.apache.hadoop.hdfs.server.namenode.HostFileManager: read excludes:\nHostSet(\n)\n2014-10-27 16:22:13,144 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000\n2014-10-27 16:22:13,186 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false\n2014-10-27 16:22:13,187 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 3\n2014-10-27 16:22:13,187 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512\n2014-10-27 16:22:13,187 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1\n2014-10-27 16:22:13,187 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2\n2014-10-27 16:22:13,187 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = true\n2014-10-27 16:22:13,187 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000\n2014-10-27 16:22:13,187 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false\n2014-10-27 16:22:13,187 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000\n2014-10-27 16:22:13,192 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdfs (auth:SIMPLE)\n2014-10-27 16:22:13,192 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup\n2014-10-27 16:22:13,192 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true\n2014-10-27 16:22:13,193 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false\n2014-10-27 16:22:13,197 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true\n2014-10-27 16:22:13,421 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times\n2014-10-27 16:22:13,422 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033\n2014-10-27 16:22:13,423 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0\n2014-10-27 16:22:13,423 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000\n2014-10-27 16:22:13,675 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /opt1/dfs/nn/in_use.lock acquired by nodename 13026@<mastermachine-hostname>\n2014-10-27 16:22:14,134 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /data/dfs/nn/in_use.lock acquired by nodename 13026@<mastermachine-hostname>\n2014-10-27 16:22:14,268 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /opt2/dfs/nn/in_use.lock acquired by nodename 13026@<mastermachine-hostname>\n2014-10-27 16:22:14,361 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /opt1/dfs/nn/current\n2014-10-27 16:22:14,440 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /data/dfs/nn/current\n2014-10-27 16:22:14,475 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /opt2/dfs/nn/current\n2014-10-27 16:22:14,854 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loading image file /opt1/dfs/nn/current/fsimage_0000000000023479779 using no compression\n2014-10-27 16:22:14,854 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Number of files = 247160\n2014-10-27 16:22:16,428 ERROR org.apache.hadoop.hdfs.server.namenode.FSImage: Failed to load image from FSImageFile(file=/opt1/dfs/nn/current/fsimage_0000000000023479779, cpktTxId=0000000000023479779)\njava.io.IOException: Unexpected block size: -1945969516689645797\n\tat org.apache.hadoop.hdfs.protocol.Block.readHelper(Block.java:187)\n\tat org.apache.hadoop.hdfs.protocol.Block.readFields(Block.java:173)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImageFormat$Loader.loadINode(FSImageFormat.java:379)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImageFormat$Loader.loadDirectory(FSImageFormat.java:310)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImageFormat$Loader.loadLocalNameINodes(FSImageFormat.java:283)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImageFormat$Loader.load(FSImageFormat.java:224)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:786)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:775)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImageFile(FSImage.java:677)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:647)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:274)\n\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:639)\n\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:476)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:403)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:437)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:613)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:598)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1169)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1233)\n2014-10-27 16:22:16,442 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loading image file /data/dfs/nn/current/fsimage_0000000000023479779 using no compression\n2014-10-27 16:22:16,442 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Number of files = 247160\n2014-10-27 16:22:16,945 ERROR org.apache.hadoop.hdfs.server.namenode.FSImage: Failed to load image from FSImageFile(file=/data/dfs/nn/current/fsimage_0000000000023479779, cpktTxId=0000000000023479779)\njava.io.IOException: Unexpected block size: -1945969516689645797\n\tat org.apache.hadoop.hdfs.protocol.Block.readHelper(Block.java:187)\n\tat org.apache.hadoop.hdfs.protocol.Block.readFields(Block.java:173)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImageFormat$Loader.loadINode(FSImageFormat.java:379)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImageFormat$Loader.loadDirectory(FSImageFormat.java:310)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImageFormat$Loader.loadLocalNameINodes(FSImageFormat.java:283)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImageFormat$Loader.load(FSImageFormat.java:224)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:786)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:775)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImageFile(FSImage.java:677)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:647)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:274)\n\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:639)\n\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:476)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:403)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:437)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:613)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:598)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1169)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1233)\n2014-10-27 16:22:16,949 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loading image file /opt2/dfs/nn/current/fsimage_0000000000023479779 using no compression\n2014-10-27 16:22:16,949 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Number of files = 247160\n2014-10-27 16:22:17,407 ERROR org.apache.hadoop.hdfs.server.namenode.FSImage: Failed to load image from FSImageFile(file=/opt2/dfs/nn/current/fsimage_0000000000023479779, cpktTxId=0000000000023479779)\njava.io.IOException: Unexpected block size: -1945969516689645797\n\tat org.apache.hadoop.hdfs.protocol.Block.readHelper(Block.java:187)\n\tat org.apache.hadoop.hdfs.protocol.Block.readFields(Block.java:173)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImageFormat$Loader.loadINode(FSImageFormat.java:379)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImageFormat$Loader.loadDirectory(FSImageFormat.java:310)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImageFormat$Loader.loadLocalNameINodes(FSImageFormat.java:283)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImageFormat$Loader.load(FSImageFormat.java:224)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:786)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:775)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImageFile(FSImage.java:677)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:647)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:274)\n\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:639)\n\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:476)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:403)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:437)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:613)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:598)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1169)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1233)\n2014-10-27 16:22:17,410 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping NameNode metrics system...\n2014-10-27 16:22:17,411 INFO org.apache.hadoop.metrics2.impl.MetricsSinkAdapter: ganglia thread interrupted.\n2014-10-27 16:22:17,411 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system stopped.\n2014-10-27 16:22:17,411 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system shutdown complete.\n2014-10-27 16:22:17,411 FATAL org.apache.hadoop.hdfs.server.namenode.NameNode: Exception in namenode join\njava.io.IOException: Failed to load an FSImage file!\n\tat org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:658)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:274)\n\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:639)\n\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:476)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:403)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:437)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:613)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:598)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1169)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1233)\n2014-10-27 16:22:17,413 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 1\n2014-10-27 16:22:17,415 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: \n/************************************************************\nSHUTDOWN_MSG: Shutting down NameNode at <mastermachine-hostname>/<IP>\n************************************************************/\n{code}","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"Hadoop Namenode failing because of negative value in fsimage","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vishnuganth","name":"vishnuganth","key":"vishnuganth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vishnu Ganth","active":true,"timeZone":"Asia/Kolkata"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vishnuganth","name":"vishnuganth","key":"vishnuganth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vishnu Ganth","active":true,"timeZone":"Asia/Kolkata"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12751016/comment/14186582","id":"14186582","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=huLiu","name":"huLiu","key":"huliu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hu Liu,","active":true,"timeZone":"Etc/UTC"},"body":"It seems that the fsimage is broken. You can use the offline image viewer to confirm.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=huLiu","name":"huLiu","key":"huliu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hu Liu,","active":true,"timeZone":"Etc/UTC"},"created":"2014-10-28T08:37:29.310+0000","updated":"2014-10-28T08:37:29.310+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12751016/comment/14186678","id":"14186678","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vishnuganth","name":"vishnuganth","key":"vishnuganth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vishnu Ganth","active":true,"timeZone":"Asia/Kolkata"},"body":"[~huLiu]Thanks for the response Liu. I tried giving the command hdfs oiv -i fsimage_file -o output. I am getting the directory structure of hdfs. But how to confirm whether it is broken or working fine?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vishnuganth","name":"vishnuganth","key":"vishnuganth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vishnu Ganth","active":true,"timeZone":"Asia/Kolkata"},"created":"2014-10-28T10:29:03.511+0000","updated":"2014-10-28T10:29:03.511+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12751016/comment/14186756","id":"14186756","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=huLiu","name":"huLiu","key":"huliu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hu Liu,","active":true,"timeZone":"Etc/UTC"},"body":"If you can get the correct directory structure without any error, the fsimage should be ok.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=huLiu","name":"huLiu","key":"huliu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hu Liu,","active":true,"timeZone":"Etc/UTC"},"created":"2014-10-28T12:28:31.517+0000","updated":"2014-10-28T12:28:31.517+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12751016/comment/14186781","id":"14186781","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vishnuganth","name":"vishnuganth","key":"vishnuganth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vishnu Ganth","active":true,"timeZone":"Asia/Kolkata"},"body":"Thanks Liu. i am getting the correct directory structure using offline image viewer. So any further ways to debug this issue..","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vishnuganth","name":"vishnuganth","key":"vishnuganth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vishnu Ganth","active":true,"timeZone":"Asia/Kolkata"},"created":"2014-10-28T13:02:35.212+0000","updated":"2014-10-28T13:02:35.212+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12751016/comment/14186800","id":"14186800","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vishnuganth","name":"vishnuganth","key":"vishnuganth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vishnu Ganth","active":true,"timeZone":"Asia/Kolkata"},"body":"I found one of the file in hdfs containing negative NUM_BYTES set in fsimage.\n      INODE\n      INODE_PATH = /user/root/dir/out/part-m-05990\n      REPLICATION = 3\n      MODIFICATION_TIME = 2014-09-05 04:09\n      ACCESS_TIME = 2014-09-05 07:42\n      BLOCK_SIZE = 134217728\n      BLOCKS [NUM_BLOCKS = 1]\n        BLOCK\n          BLOCK_ID = 8582078737\n          *NUM_BYTES = -1945969516689645797*\n          GENERATION_STAMP = 5\n      NS_QUOTA = -1\n      DS_QUOTA = -1\n      PERMISSIONS\n        USER_NAME = root\n        GROUP_NAME = supergroup\n        PERMISSION_STRING = rw-r--r--\n\nIs there any way to edit the fsimage file...","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vishnuganth","name":"vishnuganth","key":"vishnuganth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vishnu Ganth","active":true,"timeZone":"Asia/Kolkata"},"created":"2014-10-28T13:21:03.039+0000","updated":"2014-10-28T13:21:03.039+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12751016/comment/14189717","id":"14189717","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vishnuganth","name":"vishnuganth","key":"vishnuganth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vishnu Ganth","active":true,"timeZone":"Asia/Kolkata"},"body":"I was able to bring the namenode up, by commenting the following lines from org.apache.hadoop.hdfs.protocol.Block.java\nif (numBytes < 0) {\n     throw new IOException(\"Unexpected block size: \" + numBytes);\n    }\n\nBut not sure how NUM_BYTES got negative value in fsimage.\n\n[~huLiu]","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vishnuganth","name":"vishnuganth","key":"vishnuganth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vishnu Ganth","active":true,"timeZone":"Asia/Kolkata"},"created":"2014-10-30T06:51:09.532+0000","updated":"2014-10-30T06:51:09.532+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12751016/comment/14192030","id":"14192030","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"body":"The file has one block and the max block size is 128MB.  What is the actual size of the block on the datanode?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"created":"2014-10-31T16:39:35.510+0000","updated":"2014-10-31T16:39:35.510+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12751016/comment/14194256","id":"14194256","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vishnuganth","name":"vishnuganth","key":"vishnuganth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vishnu Ganth","active":true,"timeZone":"Asia/Kolkata"},"body":"[~kihwal] Actually this is not the only block in hdfs. I took the metadata of part-m file which had issue and posted it here. The actual size of the /user/root/dir/out/part-m-05990 file is around 440 Kbytes. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vishnuganth","name":"vishnuganth","key":"vishnuganth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vishnu Ganth","active":true,"timeZone":"Asia/Kolkata"},"created":"2014-11-03T05:25:07.853+0000","updated":"2014-11-03T05:25:07.853+0000"}],"maxResults":8,"total":8,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-7299/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i21no7:"}}