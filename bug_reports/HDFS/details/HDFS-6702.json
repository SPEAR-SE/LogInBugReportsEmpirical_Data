{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12728120","self":"https://issues.apache.org/jira/rest/api/2/issue/12728120","key":"HDFS-6702","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12327181","id":"12327181","description":"2.6.0 release","name":"2.6.0","archived":false,"released":true,"releaseDate":"2014-11-18"}],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2014-07-20T01:32:03.061+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Tue Jul 22 16:33:39 UTC 2014","customfield_12310420":"406225","customfield_12312320":null,"customfield_12310222":"10002_*:*_1_*:*_298697409_*|*_1_*:*_1_*:*_60691367_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2014-07-22T07:46:45.620+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-6702/watchers","watchCount":5,"isWatching":false},"created":"2014-07-18T03:56:56.884+0000","customfield_12310192":null,"customfield_12310191":[{"self":"https://issues.apache.org/jira/rest/api/2/customFieldOption/10343","value":"Reviewed","id":"10343"}],"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"4.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[],"issuelinks":[{"id":"12405951","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12405951","type":{"id":"12310000","name":"Duplicate","inward":"is duplicated by","outward":"duplicates","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/12310000"},"inwardIssue":{"id":"12667785","key":"HDFS-5178","self":"https://issues.apache.org/jira/rest/api/2/issue/12667785","fields":{"summary":"DataTransferProtocol changes for supporting mutiple storages per DN","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/7","id":"7","description":"The sub-task of the issue","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype","name":"Sub-task","subtask":true,"avatarId":21146}}}},{"id":"12392227","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12392227","type":{"id":"12310000","name":"Duplicate","inward":"is duplicated by","outward":"duplicates","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/12310000"},"inwardIssue":{"id":"12674632","key":"HDFS-5391","self":"https://issues.apache.org/jira/rest/api/2/issue/12674632","fields":{"summary":"writeBlock should accept a target storage directory","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/7","id":"7","description":"The sub-task of the issue","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype","name":"Sub-task","subtask":true,"avatarId":21146}}}},{"id":"12391827","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12391827","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"12728294","key":"HDFS-6708","self":"https://issues.apache.org/jira/rest/api/2/issue/12728294","fields":{"summary":"StorageType should be encoded in the block token","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/7","id":"7","description":"The sub-task of the issue","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype","name":"Sub-task","subtask":true,"avatarId":21146}}}},{"id":"12391820","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12391820","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"12539644","key":"HDFS-2832","self":"https://issues.apache.org/jira/rest/api/2/issue/12539644","fields":{"summary":"Enable support for heterogeneous storages in HDFS - DN as a collection of storages","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/2","id":"2","description":"A new feature of the product, which has yet to be developed.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype","name":"New Feature","subtask":false,"avatarId":21141}}}},{"id":"12393072","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12393072","type":{"id":"12310040","name":"Required","inward":"is required by","outward":"requires","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/12310040"},"inwardIssue":{"id":"12722899","key":"HDFS-6584","self":"https://issues.apache.org/jira/rest/api/2/issue/12722899","fields":{"summary":"Support Archival Storage","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/2","id":"2","description":"A new feature of the product, which has yet to be developed.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype","name":"New Feature","subtask":false,"avatarId":21141}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2015-01-21T06:22:14.259+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12312927","id":"12312927","name":"datanode"},{"self":"https://issues.apache.org/jira/rest/api/2/component/12312928","id":"12312928","name":"hdfs-client"}],"timeoriginalestimate":null,"description":"When DFSClient asks NN for a new block (via addBlock), NN returns a LocatedBlock with storage type information.  However, DFSClient does not use StorageType to create blocks with DN.  As a result, the block replicas could possibly be created with a different storage type.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12656566","id":"12656566","filename":"h6702_20140719.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-07-18T20:43:55.406+0000","size":76478,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12656566/h6702_20140719.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12656796","id":"12656796","filename":"h6702_20140721.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-07-20T19:32:46.174+0000","size":78543,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12656796/h6702_20140721.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12656804","id":"12656804","filename":"h6702_20140721b.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-07-21T00:20:14.867+0000","size":78532,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12656804/h6702_20140721b.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12657065","id":"12657065","filename":"h6702_20140722.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-07-22T06:15:16.700+0000","size":79341,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12657065/h6702_20140722.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"406246","customfield_12312823":null,"summary":"DFSClient should create blocks using StorageType ","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12728120/comment/14066851","id":"14066851","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"body":"h6702_20140719.patch: passes storage types to DNs.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-07-18T20:41:33.479+0000","updated":"2014-07-18T20:41:33.479+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12728120/comment/14067754","id":"14067754","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12656566/h6702_20140719.patch\n  against trunk revision .\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:green}+1 tests included{color}.  The patch appears to include 10 new or modified test files.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:\n\n                  org.apache.hadoop.hdfs.TestSetrepIncreasing\n                  org.apache.hadoop.hdfs.TestModTime\n                  org.apache.hadoop.hdfs.security.TestDelegationToken\n                  org.apache.hadoop.hdfs.shortcircuit.TestShortCircuitLocalRead\n                  org.apache.hadoop.hdfs.TestParallelShortCircuitRead\n                  org.apache.hadoop.hdfs.TestDisableConnCache\n                  org.apache.hadoop.hdfs.TestConnCache\n                  org.apache.hadoop.hdfs.TestDFSClientRetries\n                  org.apache.hadoop.hdfs.TestSetrepDecreasing\n                  org.apache.hadoop.hdfs.server.datanode.TestDiskError\n                  org.apache.hadoop.hdfs.server.namenode.TestHostsFiles\n                  org.apache.hadoop.hdfs.server.datanode.TestTransferRbw\n                  org.apache.hadoop.hdfs.TestPread\n                  org.apache.hadoop.hdfs.TestFileStatus\n                  org.apache.hadoop.hdfs.server.datanode.TestBlockRecovery\n                  org.apache.hadoop.hdfs.TestReadWhileWriting\n                  org.apache.hadoop.hdfs.server.datanode.TestFsDatasetCache\n                  org.apache.hadoop.hdfs.server.blockmanagement.TestPendingInvalidateBlock\n                  org.apache.hadoop.hdfs.server.namenode.ha.TestQuotasWithHA\n                  org.apache.hadoop.hdfs.server.blockmanagement.TestBlockTokenWithDFS\n                  org.apache.hadoop.hdfs.TestBlocksScheduledCounter\n                  org.apache.hadoop.hdfs.protocol.datatransfer.sasl.TestSaslDataTransfer\n                  org.apache.hadoop.hdfs.server.datanode.TestCachingStrategy\n                  org.apache.hadoop.hdfs.web.TestWebHdfsWithMultipleNameNodes\n                  org.apache.hadoop.hdfs.server.datanode.TestBlockReplacement\n                  org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestInterDatanodeProtocol\n                  org.apache.hadoop.hdfs.server.namenode.ha.TestHAMetrics\n                  org.apache.hadoop.hdfs.server.blockmanagement.TestNodeCount\n                  org.apache.hadoop.hdfs.TestFileAppend\n                  org.apache.hadoop.hdfs.server.datanode.TestReadOnlySharedStorage\n                  org.apache.hadoop.hdfs.server.blockmanagement.TestBlocksWithNotEnoughRacks\n                  org.apache.hadoop.hdfs.TestParallelShortCircuitReadUnCached\n                  org.apache.hadoop.hdfs.server.datanode.TestHSync\n                  org.apache.hadoop.hdfs.security.TestDelegationTokenForProxyUser\n                  org.apache.hadoop.hdfs.TestBlockMissingException\n                  org.apache.hadoop.hdfs.web.TestWebHdfsFileSystemContract\n                  org.apache.hadoop.hdfs.TestAbandonBlock\n                  org.apache.hadoop.hdfs.server.namenode.TestSequentialBlockId\n                  org.apache.hadoop.hdfs.TestFileCreationClient\n                  org.apache.hadoop.hdfs.TestDFSMkdirs\n                  org.apache.hadoop.hdfs.TestFileAppendRestart\n                  org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyBlockManagement\n                  org.apache.hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA\n                  org.apache.hadoop.hdfs.TestBlockReaderLocalLegacy\n                  org.apache.hadoop.hdfs.TestWriteConfigurationToDFS\n                  org.apache.hadoop.hdfs.web.TestWebHDFS\n                  org.apache.hadoop.hdfs.TestReplication\n                  org.apache.hadoop.hdfs.TestFileConcurrentReader\n                  org.apache.hadoop.hdfs.TestClose\n                  org.apache.hadoop.hdfs.TestDFSRollback\n                  org.apache.hadoop.hdfs.server.datanode.TestBlockHasMultipleReplicasOnSameDN\n                  org.apache.hadoop.hdfs.TestFileAppend4\n                  org.apache.hadoop.hdfs.web.TestWebHDFSForHA\n                  org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestDatanodeRestart\n                  org.apache.hadoop.hdfs.TestSafeMode\n                  org.apache.hadoop.hdfs.TestDatanodeBlockScanner\n                  org.apache.hadoop.hdfs.TestDFSRename\n                  org.apache.hadoop.hdfs.TestSeekBug\n                  org.apache.hadoop.hdfs.server.namenode.web.resources.TestWebHdfsDataLocality\n                  org.apache.hadoop.hdfs.TestParallelRead\n                  org.apache.hadoop.hdfs.TestDFSUpgrade\n                  org.apache.hadoop.hdfs.server.blockmanagement.TestRBWBlockInvalidation\n                  org.apache.hadoop.hdfs.TestParallelShortCircuitReadNoChecksum\n                  org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration\n                  org.apache.hadoop.hdfs.TestDFSStorageStateRecovery\n                  org.apache.hadoop.hdfs.TestDecommission\n                  org.apache.hadoop.hdfs.TestCrcCorruption\n                  org.apache.hadoop.hdfs.server.namenode.TestINodeFile\n                  org.apache.hadoop.hdfs.TestFSOutputSummer\n                  org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover\n                  org.apache.hadoop.hdfs.TestFileLengthOnClusterRestart\n                  org.apache.hadoop.hdfs.TestSetTimes\n                  org.apache.hadoop.hdfs.TestHDFSFileSystemContract\n                  org.apache.hadoop.hdfs.TestDFSRemove\n                  org.apache.hadoop.hdfs.TestAppendDifferentChecksum\n                  org.apache.hadoop.hdfs.TestDFSFinalize\n                  org.apache.hadoop.hdfs.TestFileAppend2\n                  org.apache.hadoop.hdfs.server.namenode.ha.TestFailoverWithBlockTokensEnabled\n                  org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer\n                  org.apache.hadoop.hdfs.TestFsShellPermission\n                  org.apache.hadoop.hdfs.TestRestartDFS\n                  org.apache.hadoop.hdfs.TestFileAppend3\n                  org.apache.hadoop.hdfs.TestQuota\n                  org.apache.hadoop.hdfs.TestInjectionForSimulatedStorage\n                  org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs\n                  org.apache.hadoop.hdfs.TestClientBlockVerification\n                  org.apache.hadoop.hdfs.tools.offlineEditsViewer.TestOfflineEditsViewer\n                  org.apache.hadoop.hdfs.server.datanode.TestDataNodeMetrics\n                  org.apache.hadoop.hdfs.TestDFSClientFailover\n                  org.apache.hadoop.hdfs.server.namenode.TestSnapshotPathINodes\n                  org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyIsHot\n                  org.apache.hadoop.hdfs.TestGetBlocks\n                  org.apache.hadoop.hdfs.server.blockmanagement.TestOverReplicatedBlocks\n                  org.apache.hadoop.hdfs.server.namenode.TestAuditLogs\n                  org.apache.hadoop.hdfs.TestListFilesInFileContext\n                  org.apache.hadoop.hdfs.TestMultiThreadedHflush\n                  org.apache.hadoop.hdfs.server.blockmanagement.TestUnderReplicatedBlocks\n                  org.apache.hadoop.hdfs.TestDataTransferKeepalive\n                  org.apache.hadoop.hdfs.TestClientReportBadBlock\n                  org.apache.hadoop.hdfs.TestSmallBlock\n                  org.apache.hadoop.hdfs.TestHFlush\n                  org.apache.hadoop.hdfs.TestParallelUnixDomainRead\n                  org.apache.hadoop.hdfs.TestGetFileChecksum\n                  org.apache.hadoop.hdfs.shortcircuit.TestShortCircuitCache\n                  org.apache.hadoop.hdfs.server.datanode.TestDirectoryScanner\n                  org.apache.hadoop.hdfs.TestDFSClientExcludedNodes\n                  org.apache.hadoop.hdfs.server.datanode.TestNNHandlesBlockReportPerStorage\n                  org.apache.hadoop.hdfs.server.namenode.ha.TestPendingCorruptDnMessages\n                  org.apache.hadoop.hdfs.web.TestHttpsFileSystem\n                  org.apache.hadoop.hdfs.TestDFSStartupVersions\n                  org.apache.hadoop.hdfs.TestFileCreation\n                  org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode\n                  org.apache.hadoop.hdfs.TestMissingBlocksAlert\n                  org.apache.hadoop.hdfs.TestParallelShortCircuitLegacyRead\n                  org.apache.hadoop.hdfs.server.namenode.TestStartup\n                  org.apache.hadoop.hdfs.TestRead\n                  org.apache.hadoop.hdfs.server.namenode.TestDiskspaceQuotaUpdate\n                  org.apache.hadoop.hdfs.TestLocalDFS\n                  org.apache.hadoop.hdfs.TestDatanodeDeath\n                  org.apache.hadoop.hdfs.server.datanode.TestDeleteBlockPool\n                  org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting\n                  org.apache.hadoop.hdfs.server.datanode.TestNNHandlesCombinedBlockReport\n                  org.apache.hadoop.hdfs.TestBlockReaderFactory\n                  org.apache.hadoop.hdfs.TestDataTransferProtocol\n                  org.apache.hadoop.hdfs.TestDFSShell\n                  org.apache.hadoop.hdfs.TestListFilesInDFS\n                  org.apache.hadoop.hdfs.server.namenode.TestProcessCorruptBlocks\n                  org.apache.hadoop.hdfs.TestLeaseRecovery2\n                  org.apache.hadoop.hdfs.TestFileCorruption\n                  org.apache.hadoop.hdfs.TestHDFSTrash\n                  org.apache.hadoop.hdfs.server.datanode.TestMultipleNNDataBlockScanner\n                  org.apache.hadoop.hdfs.server.namenode.TestMetaSave\n                  org.apache.hadoop.hdfs.server.blockmanagement.TestPendingReplication\n                  org.apache.hadoop.hdfs.server.namenode.ha.TestHarFileSystemWithHA\n                  org.apache.hadoop.hdfs.server.datanode.TestIncrementalBrVariations\n                  org.apache.hadoop.hdfs.TestDistributedFileSystem\n                  org.apache.hadoop.hdfs.server.namenode.ha.TestHAAppend\n                  org.apache.hadoop.hdfs.server.namenode.TestBackupNode\n                  org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure\n                  org.apache.hadoop.hdfs.TestLargeBlock\n                  org.apache.hadoop.hdfs.server.namenode.ha.TestHAStateTransitions\n                  org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication\n                  org.apache.hadoop.hdfs.TestLease\n                  org.apache.hadoop.hdfs.server.datanode.TestDnRespectsBlockReportSplitThreshold\n                  org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencing\n                  org.apache.hadoop.hdfs.server.datanode.TestDataNodeRollingUpgrade\n                  org.apache.hadoop.hdfs.TestLeaseRecovery\n                  org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewerForAcl\n\n                                      The following test timeouts occurred in hadoop-hdfs-project/hadoop-hdfs:\n\norg.apache.hadoop.hdfs.TestBlockReaderLocal\n\n    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/7404//testReport/\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/7404//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2014-07-20T01:32:03.061+0000","updated":"2014-07-20T01:32:03.061+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12728120/comment/14068029","id":"14068029","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"body":"h6702_20140721.patch: fixes some bugs.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-07-20T19:32:46.178+0000","updated":"2014-07-20T19:32:46.178+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12728120/comment/14068067","id":"14068067","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12656796/h6702_20140721.patch\n  against trunk revision .\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:green}+1 tests included{color}.  The patch appears to include 10 new or modified test files.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:\n\n                  org.apache.hadoop.hdfs.server.datanode.TestDiskError\n\n    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/7406//testReport/\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/7406//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2014-07-20T22:35:36.804+0000","updated":"2014-07-20T22:35:36.804+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12728120/comment/14068085","id":"14068085","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"body":"h6702_20140721b.patch: fixes TestDiskError.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-07-21T00:20:14.871+0000","updated":"2014-07-21T00:20:14.871+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12728120/comment/14068149","id":"14068149","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:green}+1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12656804/h6702_20140721b.patch\n  against trunk revision .\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:green}+1 tests included{color}.  The patch appears to include 10 new or modified test files.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.\n\n    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/7407//testReport/\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/7407//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2014-07-21T03:16:05.361+0000","updated":"2014-07-21T03:16:05.361+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12728120/comment/14068456","id":"14068456","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinayrpet","name":"vinayrpet","key":"vinayrpet","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinayakumar B","active":true,"timeZone":"Asia/Kolkata"},"body":"Patch looks good \n\nOne nit.\n{code}\n+    final List<StorageTypeProto> protos = new ArrayList<StorageTypeProto>(\n+        types.length);\n+    for (int i = startIdx; i < types.length; ++i) {\n+      protos.add(convertStorageType(types[i]));\n+    }\n{code}\nHere, initialCapacity can be given as {{types.length-startIdx}}, otherwise extra allocation will happen for non-zero startIdx.\n\n+1 on addressing this","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinayrpet","name":"vinayrpet","key":"vinayrpet","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinayakumar B","active":true,"timeZone":"Asia/Kolkata"},"created":"2014-07-21T12:20:18.859+0000","updated":"2014-07-21T12:20:18.859+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12728120/comment/14068496","id":"14068496","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks Vinay.  I do have new ArrayList with types.length-startIdx in my previous patch (h6702_20140721.patch).  However, TestDiskError fails so that I change it to types.length.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-07-21T13:24:21.097+0000","updated":"2014-07-21T13:24:21.097+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12728120/comment/14069760","id":"14069760","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=arpitagarwal","name":"arpitagarwal","key":"arpitagarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arpit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi [~szetszwo],\n\n# For {{writeBlock}}, why do we pass both {{targetStorageTypes[0]}} and {{targetStorageTypes}}? Wouldn't it be sufficient to just pass targetStorageTypes? \n# DatanodeProtocol.proto: I got confused about {{BlockCommandProto}}. It has {{repeated StorageTypesProto targetStorageTypes}} which itself has repeated {{StorageTypeProto}} as member. Can we just make this {{repeated StorageTypeProto targetStorageTypes}} and remove the {{StorageTypesProto}} message?\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=arpitagarwal","name":"arpitagarwal","key":"arpitagarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arpit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-07-22T03:20:26.765+0000","updated":"2014-07-22T03:20:38.093+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12728120/comment/14069787","id":"14069787","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"body":"Arpit, thanks for taking a look.\n# targetStorageTypes is analogous to the targets parameter.  For the targets parameter, targets\\[0] is the first DN address which is used to create socket so that we don't have to (and the current code does not) pass targets\\[0] explicitly.  We have to specify the StorageType for the first DN.  There are two choices, \n#- (a) pass only one parameter targetStorageTypes\\[0..n-1] and use targetStorageTypes\\[0] for first DN, or\n#- (b) pass two parameters, storageType (=targetStorageTypes\\[0]) and targetStorageTypes\\[1..n-1].\nIf we choose (a) then the index of targets and targetStorageTypes won't be matched in the receiver side since targets\\[1..n-1] becomes targets\\[0..n-2] and targetStorageTypes\\[0..n-1] remains targetStorageTypes\\[0..n-1], i.e. targetStorageTypes\\[0] is for the first DN, targetStorageTypes\\[1] is for the second DN and so on but targets\\[0] is for the second DN, targets\\[1] is for the third DN and so on.\n# It is an two-dimensional array, which is similar to targetStorageUuids or targets in BlockCommandProto. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-07-22T04:10:20.605+0000","updated":"2014-07-22T04:10:20.605+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12728120/comment/14069809","id":"14069809","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=arpitagarwal","name":"arpitagarwal","key":"arpitagarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arpit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"body":"bq.  If we choose (a) then the index of targets and targetStorageTypes won't be matched in the receiver side since targets[1..n-1] becomes targets[0..n-2] and targetStorageTypes[0..n-1] remains targetStorageTypes[0..n-1], i.e. targetStorageTypes[0] is for the first DN, targetStorageTypes[1] is for the second DN and so on but targets[0] is for the second DN, targets[1] is for the third DN and so on.\nOkay I got it, this trick avoids special case code in {{writeBlock}}. Would you consider adding a short comment explaining this?\n\nbq. It is an two-dimensional array, which is similar to targetStorageUuids or targets in BlockCommandProto.\nGot it thanks.\n\n+1","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=arpitagarwal","name":"arpitagarwal","key":"arpitagarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arpit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-07-22T04:36:56.355+0000","updated":"2014-07-22T04:36:56.355+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12728120/comment/14069885","id":"14069885","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"body":"h6702_20140722.patch: revises the javadoc for writeBlock(..).","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-07-22T06:15:16.704+0000","updated":"2014-07-22T06:15:16.704+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12728120/comment/14069912","id":"14069912","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinayrpet","name":"vinayrpet","key":"vinayrpet","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinayakumar B","active":true,"timeZone":"Asia/Kolkata"},"body":"+1 for the latest javadoc updated patch.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinayrpet","name":"vinayrpet","key":"vinayrpet","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinayakumar B","active":true,"timeZone":"Asia/Kolkata"},"created":"2014-07-22T06:59:10.258+0000","updated":"2014-07-22T06:59:10.258+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12728120/comment/14069949","id":"14069949","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks, Vinay and Arpit for reviewing the patches.\n\nI have committed this.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-07-22T07:46:45.646+0000","updated":"2014-07-22T07:46:45.646+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12728120/comment/14069957","id":"14069957","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"FAILURE: Integrated in Hadoop-trunk-Commit #5933 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/5933/])\nHDFS-6702. Change DFSClient to pass the StorageType from the namenode to datanodes and change datanode to write block replicas using the specified storage type. (szetszwo: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1612493)\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/DataTransferProtocol.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/Receiver.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/Sender.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/balancer/Balancer.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BPOfferService.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/FsDatasetSpi.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsVolumeList.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/protocol/BlockCommand.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/proto/DatanodeProtocol.proto\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/proto/datatransfer.proto\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/proto/hdfs.proto\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/DFSTestUtil.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDataTransferProtocol.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/protocolPB/TestPBHelper.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/BlockReportTestBase.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/SimulatedFSDataset.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestBlockRecovery.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestBlockReplacement.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDiskError.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestSimulatedFSDataset.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/TestWriteToReplica.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2014-07-22T07:54:16.983+0000","updated":"2014-07-22T07:54:16.983+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12728120/comment/14070086","id":"14070086","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12657065/h6702_20140722.patch\n  against trunk revision .\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:green}+1 tests included{color}.  The patch appears to include 10 new or modified test files.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:\n\n                  org.apache.hadoop.hdfs.TestDFSUpgrade\n                  org.apache.hadoop.hdfs.TestDFSShell\n                  org.apache.hadoop.hdfs.TestHDFSServerPorts\n                  org.apache.hadoop.hdfs.TestDFSClientExcludedNodes\n\n    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/7420//testReport/\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/7420//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2014-07-22T10:17:03.816+0000","updated":"2014-07-22T10:17:03.816+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12728120/comment/14070124","id":"14070124","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"FAILURE: Integrated in Hadoop-Yarn-trunk #620 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/620/])\nHDFS-6702. Change DFSClient to pass the StorageType from the namenode to datanodes and change datanode to write block replicas using the specified storage type. (szetszwo: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1612493)\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/DataTransferProtocol.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/Receiver.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/Sender.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/balancer/Balancer.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BPOfferService.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/FsDatasetSpi.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsVolumeList.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/protocol/BlockCommand.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/proto/DatanodeProtocol.proto\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/proto/datatransfer.proto\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/proto/hdfs.proto\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/DFSTestUtil.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDataTransferProtocol.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/protocolPB/TestPBHelper.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/BlockReportTestBase.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/SimulatedFSDataset.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestBlockRecovery.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestBlockReplacement.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDiskError.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestSimulatedFSDataset.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/TestWriteToReplica.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2014-07-22T11:02:07.551+0000","updated":"2014-07-22T11:02:07.551+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12728120/comment/14070285","id":"14070285","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"FAILURE: Integrated in Hadoop-Hdfs-trunk #1812 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1812/])\nHDFS-6702. Change DFSClient to pass the StorageType from the namenode to datanodes and change datanode to write block replicas using the specified storage type. (szetszwo: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1612493)\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/DataTransferProtocol.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/Receiver.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/Sender.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/balancer/Balancer.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BPOfferService.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/FsDatasetSpi.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsVolumeList.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/protocol/BlockCommand.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/proto/DatanodeProtocol.proto\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/proto/datatransfer.proto\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/proto/hdfs.proto\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/DFSTestUtil.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDataTransferProtocol.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/protocolPB/TestPBHelper.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/BlockReportTestBase.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/SimulatedFSDataset.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestBlockRecovery.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestBlockReplacement.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDiskError.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestSimulatedFSDataset.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/TestWriteToReplica.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2014-07-22T14:00:08.240+0000","updated":"2014-07-22T14:00:08.240+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12728120/comment/14070357","id":"14070357","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"SUCCESS: Integrated in Hadoop-Mapreduce-trunk #1839 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1839/])\nHDFS-6702. Change DFSClient to pass the StorageType from the namenode to datanodes and change datanode to write block replicas using the specified storage type. (szetszwo: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1612493)\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSOutputStream.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/DataTransferProtocol.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/Receiver.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/Sender.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/balancer/Balancer.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BPOfferService.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/FsDatasetSpi.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsVolumeList.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/protocol/BlockCommand.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/proto/DatanodeProtocol.proto\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/proto/datatransfer.proto\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/proto/hdfs.proto\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/DFSTestUtil.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDataTransferProtocol.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/protocolPB/TestPBHelper.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/BlockReportTestBase.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/SimulatedFSDataset.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestBlockRecovery.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestBlockReplacement.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDiskError.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestSimulatedFSDataset.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/TestWriteToReplica.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2014-07-22T15:05:01.611+0000","updated":"2014-07-22T15:05:01.611+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12728120/comment/14070471","id":"14070471","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=arpitagarwal","name":"arpitagarwal","key":"arpitagarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arpit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks Nicholas!","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=arpitagarwal","name":"arpitagarwal","key":"arpitagarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arpit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-07-22T16:33:39.732+0000","updated":"2014-07-22T16:33:39.732+0000"}],"maxResults":20,"total":20,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-6702/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i1xwlr:"}}