{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"13090905","self":"https://issues.apache.org/jira/rest/api/2/issue/13090905","key":"HDFS-12222","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12335737","id":"12335737","description":"3.0.0-beta1 release","name":"3.0.0-beta1","archived":false,"released":true,"releaseDate":"2017-10-03"}],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2017-07-31T19:30:47.416+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Wed Sep 13 01:27:00 UTC 2017","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_3312413343_*|*_5_*:*_1_*:*_0_*|*_10002_*:*_1_*:*_673376193","customfield_12312321":null,"resolutiondate":"2017-09-13T00:35:57.976+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-12222/watchers","watchCount":8,"isWatching":false},"created":"2017-07-28T21:26:08.489+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":["hdfs-ec-3.0-nice-to-have"],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"6.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12335732","id":"12335732","description":"3.0.0-alpha1 release","name":"3.0.0-alpha1","archived":false,"released":true,"releaseDate":"2016-09-03"}],"issuelinks":[],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=HuafengWang","name":"HuafengWang","key":"huafengwang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Huafeng Wang","active":true,"timeZone":"Asia/Shanghai"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2017-09-13T01:27:00.515+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[],"timeoriginalestimate":null,"description":"HDFS applications query block location information to compute splits. One example of this is FileInputFormat:\n\nhttps://github.com/apache/hadoop/blob/d4015f8628dd973c7433639451a9acc3e741d2a2/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/FileInputFormat.java#L346\n\nYou see bits of code like this that calculate offsets as follows:\n\n{noformat}\n    long bytesInThisBlock = blkLocations[startIndex].getOffset() + \n                          blkLocations[startIndex].getLength() - offset;\n{noformat}\n\nEC confuses this since the block locations include parity block locations as well, which are not part of the logical file length. This messes up the offset calculation and thus topology/caching information too.\n\nApplications can figure out what's a parity block by reading the EC policy and then parsing the schema, but it'd be a lot better if we exposed this more generically in BlockLocation instead.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12335737","id":"12335737","description":"3.0.0-beta1 release","name":"3.0.0-beta1","archived":false,"released":true,"releaseDate":"2017-10-03"}],"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12882278","id":"12882278","filename":"HDFS-12222.001.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=HuafengWang","name":"HuafengWang","key":"huafengwang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Huafeng Wang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-08-17T07:12:09.650+0000","size":9390,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12882278/HDFS-12222.001.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12883059","id":"12883059","filename":"HDFS-12222.002.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=HuafengWang","name":"HuafengWang","key":"huafengwang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Huafeng Wang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-08-22T05:59:06.905+0000","size":4460,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12883059/HDFS-12222.002.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12885301","id":"12885301","filename":"HDFS-12222.003.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=HuafengWang","name":"HuafengWang","key":"huafengwang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Huafeng Wang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-09-05T05:32:02.112+0000","size":13479,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12885301/HDFS-12222.003.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12885764","id":"12885764","filename":"HDFS-12222.004.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=HuafengWang","name":"HuafengWang","key":"huafengwang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Huafeng Wang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-09-07T07:32:47.603+0000","size":31777,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12885764/HDFS-12222.004.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12885986","id":"12885986","filename":"HDFS-12222.005.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=HuafengWang","name":"HuafengWang","key":"huafengwang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Huafeng Wang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-09-08T03:04:19.393+0000","size":21856,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12885986/HDFS-12222.005.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12886588","id":"12886588","filename":"HDFS-12222.006.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=HuafengWang","name":"HuafengWang","key":"huafengwang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Huafeng Wang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-09-12T06:50:09.178+0000","size":23412,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12886588/HDFS-12222.006.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"Document and test BlockLocation for erasure-coded files","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=andrew.wang","name":"andrew.wang","key":"andrew.wang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=andrew.wang&avatarId=19230","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=andrew.wang&avatarId=19230","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=andrew.wang&avatarId=19230","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=andrew.wang&avatarId=19230"},"displayName":"Andrew Wang","active":true,"timeZone":"America/Los_Angeles"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=andrew.wang","name":"andrew.wang","key":"andrew.wang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=andrew.wang&avatarId=19230","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=andrew.wang&avatarId=19230","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=andrew.wang&avatarId=19230","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=andrew.wang&avatarId=19230"},"displayName":"Andrew Wang","active":true,"timeZone":"America/Los_Angeles"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/13090905/comment/16105720","id":"16105720","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=andrew.wang","name":"andrew.wang","key":"andrew.wang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=andrew.wang&avatarId=19230","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=andrew.wang&avatarId=19230","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=andrew.wang&avatarId=19230","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=andrew.wang&avatarId=19230"},"displayName":"Andrew Wang","active":true,"timeZone":"America/Los_Angeles"},"body":"Ping [~rkanter] since we discussed this offline.\n\nAlso, I see that FIF uses a lot of BlockLocation methods. I wonder what \"getOffset\" for instance really should return for parity blocks.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=andrew.wang","name":"andrew.wang","key":"andrew.wang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=andrew.wang&avatarId=19230","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=andrew.wang&avatarId=19230","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=andrew.wang&avatarId=19230","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=andrew.wang&avatarId=19230"},"displayName":"Andrew Wang","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-07-28T21:30:49.708+0000","updated":"2017-07-28T21:30:49.708+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13090905/comment/16107835","id":"16107835","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ajayydv","name":"ajayydv","key":"ajayydv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ajay Kumar","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi [~andrew.wang], For usages like FIF BlockLocation does it make more sense to expose parity blocks and data blocks via different functions in LocatedFileStatus? BlockLocation seems to be lower abstraction for FileInputFormat. \n\n{code} if (file instanceof LocatedFileStatus) {\n          blkLocations = ((LocatedFileStatus) file).getDataBlockLocations();\n        } else {\n          blkLocations = fs.getFileDataBlockLocations(file, 0, length);\n        }\n{code}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ajayydv","name":"ajayydv","key":"ajayydv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ajay Kumar","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-07-31T19:30:47.416+0000","updated":"2017-07-31T19:30:47.416+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13090905/comment/16108548","id":"16108548","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=drankye","name":"drankye","key":"drankye","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Kai Zheng","active":true,"timeZone":"Asia/Chongqing"},"body":"I understand that we need to avoid the confusion between erasure coded and replicated files when calculating splits for the format. If we want to expose more info like data blocks and parity blocks (or their locations), one question is what we can do with them? Note all the blocks or locations need to be used together to read the data.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=drankye","name":"drankye","key":"drankye","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Kai Zheng","active":true,"timeZone":"Asia/Chongqing"},"created":"2017-08-01T08:01:33.064+0000","updated":"2017-08-01T08:01:33.064+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13090905/comment/16109829","id":"16109829","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=andrew.wang","name":"andrew.wang","key":"andrew.wang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=andrew.wang&avatarId=19230","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=andrew.wang&avatarId=19230","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=andrew.wang&avatarId=19230","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=andrew.wang&avatarId=19230"},"displayName":"Andrew Wang","active":true,"timeZone":"America/Los_Angeles"},"body":"I like Ajay's idea, since it makes it very easy for current users to migrate their current code. One downside compared to an iterator is that it allocates another array of BlockLocation references, but since this array is small I think it's not a big deal.\n\n[~drankye] could you elaborate on your question? This new API would only be used by schedulers or other locality-aware apps.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=andrew.wang","name":"andrew.wang","key":"andrew.wang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=andrew.wang&avatarId=19230","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=andrew.wang&avatarId=19230","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=andrew.wang&avatarId=19230","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=andrew.wang&avatarId=19230"},"displayName":"Andrew Wang","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-08-01T21:35:30.503+0000","updated":"2017-08-01T21:35:30.503+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13090905/comment/16110180","id":"16110180","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=drankye","name":"drankye","key":"drankye","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Kai Zheng","active":true,"timeZone":"Asia/Chongqing"},"body":"bq. This new API would only be used by schedulers or other locality-aware apps.\nThis addressed my question, so the exposed info is useful. Thanks [~andrew.wang]!","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=drankye","name":"drankye","key":"drankye","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Kai Zheng","active":true,"timeZone":"Asia/Chongqing"},"created":"2017-08-02T02:48:16.480+0000","updated":"2017-08-02T02:48:16.480+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13090905/comment/16110440","id":"16110440","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=HuafengWang","name":"HuafengWang","key":"huafengwang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Huafeng Wang","active":true,"timeZone":"Asia/Shanghai"},"body":"Hi guys, I'd like to take this one.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=HuafengWang","name":"HuafengWang","key":"huafengwang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Huafeng Wang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-08-02T07:13:05.511+0000","updated":"2017-08-02T07:13:05.511+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13090905/comment/16119259","id":"16119259","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=alex.behm","name":"alex.behm","key":"alex.behm","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Alexander Behm","active":true,"timeZone":"Etc/UTC"},"body":"Impala also relies on the BlockLocation array returned from LocatedFileStatus.getBlockLocations() for scheduling. See for example HdfsScanNode#computeScanRangeLocations():\nhttps://github.com/apache/incubator-impala/blob/master/fe/src/main/java/org/apache/impala/planner/HdfsScanNode.java\n\nI'm certainly not an HDFS expert, but as a user I'd be happy with something like a BlockLocation#isParity() method or returning a special invalid value for BlockLocation#getOffset() for distinguishing between data and parity blocks. I'm also fine with [~ajayydv]'s proposal to separate the data and parity block APIs, but I wonder if we can leave the existing getBlockLocations() call and have it only return data blocks (without parity blocks) for maintaining API compatibility. In most cases, I don't think users should/will care about the parity blocks.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=alex.behm","name":"alex.behm","key":"alex.behm","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Alexander Behm","active":true,"timeZone":"Etc/UTC"},"created":"2017-08-09T00:51:06.850+0000","updated":"2017-08-09T00:51:06.850+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13090905/comment/16121223","id":"16121223","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=HuafengWang","name":"HuafengWang","key":"huafengwang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Huafeng Wang","active":true,"timeZone":"Asia/Shanghai"},"body":"I've checked the related code and found it is not easy to provide other functions to get parity or data blocks.\nThe problem is, LocatedFileStatus is a subclass of FileStatus, both located in the hadoop-common module, which does not have file related erasure coding policy information. Without that specific policy information, LocatedFileStatus has no idea which BlockLocation is actually a parity block. \n\nAfter discussed with Kai offline, one approach is to add an ECSchema into LocatedFileStatus so that we can determine which blocks are parity blocks if erasure coding is enabled. \nAny suggestions here? Thanks.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=HuafengWang","name":"HuafengWang","key":"huafengwang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Huafeng Wang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-08-10T08:00:51.533+0000","updated":"2017-08-10T08:00:51.533+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13090905/comment/16122607","id":"16122607","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=drankye","name":"drankye","key":"drankye","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Kai Zheng","active":true,"timeZone":"Asia/Chongqing"},"body":"I thought a little bit more about this, Huafeng. Could you help check if it works for you? Thanks!\n\nEven we use ECSchema info in hadoop common side codes, it's still tricky to use that info to parse for a erasure coded block locations in hadoop common side since we may need couple with HDFS internals.\n\nCould we have a hadoop common class like {{ErasureCodedBlockLocation}} which contain methods to get data/parity block locations plus cell size info and it can be passed into a new {{LocatedFileStatus}} constructor. The object of ErasureCodedBlockLocation can be constructed with parsed info in HDFS side.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=drankye","name":"drankye","key":"drankye","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Kai Zheng","active":true,"timeZone":"Asia/Chongqing"},"created":"2017-08-11T00:28:32.370+0000","updated":"2017-08-11T00:28:32.370+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13090905/comment/16122627","id":"16122627","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=HuafengWang","name":"HuafengWang","key":"huafengwang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Huafeng Wang","active":true,"timeZone":"Asia/Shanghai"},"body":"Hi [~drankye],  you're right. I think it's a better way and I'll give it a try.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=HuafengWang","name":"HuafengWang","key":"huafengwang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Huafeng Wang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-08-11T00:57:41.274+0000","updated":"2017-08-11T00:57:41.274+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13090905/comment/16130050","id":"16130050","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=HuafengWang","name":"HuafengWang","key":"huafengwang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Huafeng Wang","active":true,"timeZone":"Asia/Shanghai"},"body":"Hi guys, I just uploaded an initial patch which only sketches the basic idea. \nIn the current implementation, the LocatedFileStatus that FIF fetched is transformed from HdfsLocatedFileStatus if the underlying file system is HDFS. And the BlockLocation is actually a block group in the erasure coding case. \nIn my first patch, I added an ErasureCodedBlockLocation into LocatedFileStatus and this property will be set if HdfsLocatedFileStatus is erasure coded.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=HuafengWang","name":"HuafengWang","key":"huafengwang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Huafeng Wang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-08-17T07:30:17.051+0000","updated":"2017-08-17T07:30:17.051+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13090905/comment/16131022","id":"16131022","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=andrew.wang","name":"andrew.wang","key":"andrew.wang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=andrew.wang&avatarId=19230","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=andrew.wang&avatarId=19230","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=andrew.wang&avatarId=19230","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=andrew.wang&avatarId=19230"},"displayName":"Andrew Wang","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks for picking this up Huafeng!\n\nI liked Alex's proposal above to have the current public APIs for BlockLocation return just data blocks. Then rework the HDFS internals that need both data and parity blocks to call a new API. We might already have this separation in place, since the DFSClient uses the private-only LocatedBlock and HdfsFileStatus classes.\n\nThis sketch looks a bit different, but I think can be tweaked to fit. A couple review comments:\n\n* If we agree that FileSystem users likely don't care about the details of the EC schema or even the parity blocks, then we don't need the ErasureCodedBlockLocation class. Just change the makeQualifiedLocated and related to just return data blocks.\n* We need to be careful about strictly adding new methods when adding a new parameter, for compatibility.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=andrew.wang","name":"andrew.wang","key":"andrew.wang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=andrew.wang&avatarId=19230","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=andrew.wang&avatarId=19230","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=andrew.wang&avatarId=19230","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=andrew.wang&avatarId=19230"},"displayName":"Andrew Wang","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-08-17T19:10:16.195+0000","updated":"2017-08-17T19:10:16.195+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13090905/comment/16131912","id":"16131912","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=drankye","name":"drankye","key":"drankye","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Kai Zheng","active":true,"timeZone":"Asia/Chongqing"},"body":"Using the existing API to return data block locations ignoring parity ones and adding a new API (or adapting existing EC related API) to return something like ErasureCodedBlockLocation should work fine to me. Besides the data block locations info, {{cellSize}} is also important because without it, you won't be able to know how much to read for a cell ( I assume somebody may hack like, not using DFSClient API to read).","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=drankye","name":"drankye","key":"drankye","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Kai Zheng","active":true,"timeZone":"Asia/Chongqing"},"created":"2017-08-18T08:41:21.827+0000","updated":"2017-08-18T08:41:21.827+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13090905/comment/16133413","id":"16133413","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=andrew.wang","name":"andrew.wang","key":"andrew.wang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=andrew.wang&avatarId=19230","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=andrew.wang&avatarId=19230","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=andrew.wang&avatarId=19230","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=andrew.wang&avatarId=19230"},"displayName":"Andrew Wang","active":true,"timeZone":"America/Los_Angeles"},"body":"I'd hope that there aren't any clients circumventing DFSClient to read data :) AFAIK, Hadoop apps universally read through the Hadoop input streams.\n\nAlso, if someone is going below DFSClient to read, they can also get the cellSize from the LocatedBlock/HdfsFileStatus information. It's still being sent on the wire protocol, it just wouldn't be exposed via the public Java APIs.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=andrew.wang","name":"andrew.wang","key":"andrew.wang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=andrew.wang&avatarId=19230","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=andrew.wang&avatarId=19230","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=andrew.wang&avatarId=19230","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=andrew.wang&avatarId=19230"},"displayName":"Andrew Wang","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-08-18T18:26:22.405+0000","updated":"2017-08-18T18:26:22.405+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13090905/comment/16133699","id":"16133699","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=drankye","name":"drankye","key":"drankye","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Kai Zheng","active":true,"timeZone":"Asia/Chongqing"},"body":"bq. Also, if someone is going below DFSClient to read, they can also get the cellSize from the LocatedBlock/HdfsFileStatus information.\nYes, agree. It has to be that, since much more info would be needed to support that kind of hack and only HDFS specific API can provide.\n\nSo looks like what's exactly needed would be just having the existing API return all the data block locations in EC case instead of the replication locations. The location info can be used to support data processing scheduling, pretty enough and clean. Cool!","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=drankye","name":"drankye","key":"drankye","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Kai Zheng","active":true,"timeZone":"Asia/Chongqing"},"created":"2017-08-18T22:18:00.541+0000","updated":"2017-08-18T22:18:00.541+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13090905/comment/16136375","id":"16136375","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=HuafengWang","name":"HuafengWang","key":"huafengwang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Huafeng Wang","active":true,"timeZone":"Asia/Shanghai"},"body":"I just tweaked the patch according to your suggestions. Is it on the right way? \nAnd about the new API that returns both data and parity blocks, I tend to place this API in DFSClient and DistributedFileSystem, something like \n{code}\npublic ErasureCodedBlockLocation getECBlockLocation(Path p);\n{code}\n\nIs it a proper way to do that?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=HuafengWang","name":"HuafengWang","key":"huafengwang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Huafeng Wang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-08-22T06:19:43.377+0000","updated":"2017-08-22T06:19:43.377+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13090905/comment/16143291","id":"16143291","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=HuafengWang","name":"HuafengWang","key":"huafengwang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Huafeng Wang","active":true,"timeZone":"Asia/Shanghai"},"body":"Hi [~andrew.wang], any comment on my latest update?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=HuafengWang","name":"HuafengWang","key":"huafengwang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Huafeng Wang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-08-28T01:17:08.259+0000","updated":"2017-08-28T01:17:08.259+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13090905/comment/16149832","id":"16149832","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=andrew.wang","name":"andrew.wang","key":"andrew.wang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=andrew.wang&avatarId=19230","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=andrew.wang&avatarId=19230","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=andrew.wang&avatarId=19230","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=andrew.wang&avatarId=19230"},"displayName":"Andrew Wang","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi Huafeng, thanks for the rev, looks good. Please proceed with a full patch.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=andrew.wang","name":"andrew.wang","key":"andrew.wang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=andrew.wang&avatarId=19230","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=andrew.wang&avatarId=19230","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=andrew.wang&avatarId=19230","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=andrew.wang&avatarId=19230"},"displayName":"Andrew Wang","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-09-01T00:22:19.228+0000","updated":"2017-09-01T00:22:19.228+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13090905/comment/16153187","id":"16153187","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 29s{color} | {color:blue} Docker mode activated. {color} |\n|| || || || {color:brown} Prechecks {color} ||\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |\n|| || || || {color:brown} trunk Compile Tests {color} ||\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  1m 49s{color} | {color:blue} Maven dependency ordering for branch {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 15m  4s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 16m 33s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m 16s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  2m 32s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  4m  9s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 57s{color} | {color:green} trunk passed {color} |\n|| || || || {color:brown} Patch Compile Tests {color} ||\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 17s{color} | {color:blue} Maven dependency ordering for patch {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m 53s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 14m 18s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 14m 18s{color} | {color:green} the patch passed {color} |\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  2m 13s{color} | {color:orange} root: The patch generated 12 new + 225 unchanged - 1 fixed = 237 total (was 226) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  2m 26s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  4m 42s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 59s{color} | {color:green} the patch passed {color} |\n|| || || || {color:brown} Other Tests {color} ||\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  8m 30s{color} | {color:green} hadoop-common in the patch passed. {color} |\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  1m 28s{color} | {color:green} hadoop-hdfs-client in the patch passed. {color} |\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  2m 54s{color} | {color:green} hadoop-mapreduce-client-core in the patch passed. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 30s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black} 87m 40s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:71bbb86 |\n| JIRA Issue | HDFS-12222 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12885301/HDFS-12222.003.patch |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux 640e4ed9ab53 3.13.0-123-generic #172-Ubuntu SMP Mon Jun 26 18:04:35 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / ed162b7 |\n| Default Java | 1.8.0_144 |\n| findbugs | v3.1.0-RC1 |\n| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/20994/artifact/patchprocess/diff-checkstyle-root.txt |\n|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/20994/testReport/ |\n| modules | C: hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs-client hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core U: . |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/20994/console |\n| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2017-09-05T07:08:49.655+0000","updated":"2017-09-05T07:08:49.655+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13090905/comment/16154624","id":"16154624","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=andrew.wang","name":"andrew.wang","key":"andrew.wang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=andrew.wang&avatarId=19230","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=andrew.wang&avatarId=19230","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=andrew.wang&avatarId=19230","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=andrew.wang&avatarId=19230"},"displayName":"Andrew Wang","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi Huafeng, thanks for working on this! A few review comments:\n\n* Please fix checkstyles\n* Sorry I missed this from your last comment: I thought we didn't need the new getECBlockLocation method since normal users don't need to know about parity blocks. Can we remove DistributedFileSystem#getECBlockLocation and DFSClient#getECBlockLocation and the ECBlockLocation class?\n* Looks like some places where a user can get a BlockLocation will still include parity blocks, like getFileBlockLocation. Could you also check the rest of the FileSystem API? We should add test coverage for these APIs too: getFileBlockLocation, listFiles, listLocatedStatus, etc.\n* Also need to do the same changes for Hdfs.java for the FileContext API\n* Need javadoc / comments in HdfsLocatedFileStatus and wherever else we modify to explain the intent. It'd also be great to have an example of the expected format of BlockLocation[] for a replicated vs. EC file.\n* Could you verify that fsck -files -blocks -locations still returns parity blocks? We should add a unit test for this if there isn't one.\n* Also, could you add tests with a files of different sizes, e.g. bigger than one block group? It NPEs right now for me when I call listLocatedStatus in TestWriteReadStripe#testFileMoreThanABlockGroup1.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=andrew.wang","name":"andrew.wang","key":"andrew.wang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=andrew.wang&avatarId=19230","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=andrew.wang&avatarId=19230","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=andrew.wang&avatarId=19230","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=andrew.wang&avatarId=19230"},"displayName":"Andrew Wang","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-09-06T00:22:23.018+0000","updated":"2017-09-06T00:22:23.018+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13090905/comment/16156634","id":"16156634","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=HuafengWang","name":"HuafengWang","key":"huafengwang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Huafeng Wang","active":true,"timeZone":"Asia/Shanghai"},"body":"Hi [~andrew.wang], thanks for your review! I just uploaded a new patch. In this patch I mainly:\n* Removed the getECBlockLocation function and ECBlockLocation class.\n* Fixed {{getFileBlockLocation}} of DFSClient.\n* Add comments about {{getFileBlockLocation}}, {{listFiles}} and {{listLocatedStatus}} in {{FileSystem}}, {{DistributedFileSystem}} and {{FileContext}}\n* Add comments about {{makeQualifiedLocated}} in {{HdfsLocatedFileStatus}}\n* Add tests for {{DistributedFileSystem.getFileBlockLocation}}, {{DistributedFileSystem.listFiles}}, {{FileContext.getFileBlockLocation}} and {{FileContext.listFiles}} in case of ec with various file size.\n\nAnd about \n{quote}\nCould you verify that fsck -files -blocks -locations still returns parity blocks?\n{quote}\n\nI checked the output of {{fsck -files -blocks -locations}}, it does not have very detailed block location info of an erasure coded file. An output example of a 6+3 eraure coded file will be like \n{code}\n0. BP-417570284-10.239.160.132-1504687036886:blk_-9223372036854775792_1001 len=6291456 Live_repl=9  [blk_-9223372036854775792:DatanodeInfoWithStorage[127.0.0.1:54859,DS-09a24593-5cbc-444c-ad43-ab1b39c65887,DISK](LIVE), blk_-9223372036854775791:DatanodeInfoWithStorage[127.0.0.1:54863,DS-80d7a2bb-5acc-437c-936a-bd28314e2a8c,DISK](LIVE), blk_-9223372036854775790:DatanodeInfoWithStorage[127.0.0.1:54883,DS-05a880c7-0fa2-4683-a382-06ec7d975fd3,DISK](LIVE), blk_-9223372036854775789:DatanodeInfoWithStorage[127.0.0.1:54854,DS-8a5cf2da-1c7e-4942-b57c-8755ddb3cfcb,DISK](LIVE), blk_-9223372036854775788:DatanodeInfoWithStorage[127.0.0.1:54871,DS-95c64656-3131-413c-b400-0f14612b387d,DISK](LIVE), blk_-9223372036854775787:DatanodeInfoWithStorage[127.0.0.1:54867,DS-fbf6ea90-8829-44ce-8681-b5f53be726c1,DISK](STALE_BLOCK_CONTENT), blk_-9223372036854775786:DatanodeInfoWithStorage[127.0.0.1:54875,DS-d40bfede-c5c9-4cb0-8b5e-92ead1bbb4da,DISK](LIVE), blk_-9223372036854775785:DatanodeInfoWithStorage[127.0.0.1:54879,DS-c999124f-3d0e-4f6c-bd31-5f0fdff86fca,DISK](STALE_BLOCK_CONTENT), blk_-9223372036854775784:DatanodeInfoWithStorage[127.0.0.1:54850,DS-7ff8f0ed-b62a-40a9-8966-b16f71532712,DISK](LIVE)]\n{code} \n\nSo you mean we should also remove the parity blocks info?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=HuafengWang","name":"HuafengWang","key":"huafengwang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Huafeng Wang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-09-07T07:47:19.124+0000","updated":"2017-09-07T07:47:19.124+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13090905/comment/16156802","id":"16156802","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 19s{color} | {color:blue} Docker mode activated. {color} |\n|| || || || {color:brown} Prechecks {color} ||\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 3 new or modified test files. {color} |\n|| || || || {color:brown} trunk Compile Tests {color} ||\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 20s{color} | {color:blue} Maven dependency ordering for branch {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 15m 38s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 16m 36s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m  4s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  3m 21s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  5m 40s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m 34s{color} | {color:green} trunk passed {color} |\n|| || || || {color:brown} Patch Compile Tests {color} ||\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 15s{color} | {color:blue} Maven dependency ordering for patch {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  2m 26s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 10m 53s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 10m 53s{color} | {color:green} the patch passed {color} |\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  2m  9s{color} | {color:orange} root: The patch generated 6 new + 486 unchanged - 1 fixed = 492 total (was 487) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  3m 18s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  6m 12s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m 33s{color} | {color:green} the patch passed {color} |\n|| || || || {color:brown} Other Tests {color} ||\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  7m 36s{color} | {color:green} hadoop-common in the patch passed. {color} |\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  1m 22s{color} | {color:green} hadoop-hdfs-client in the patch passed. {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}101m 32s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  3m 32s{color} | {color:green} hadoop-mapreduce-client-core in the patch passed. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 36s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black}190m 28s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| Failed junit tests | hadoop.hdfs.server.namenode.TestReconstructStripedBlocks |\n|   | hadoop.hdfs.TestReadStripedFileWithMissingBlocks |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure160 |\n|   | hadoop.hdfs.TestClientProtocolForPipelineRecovery |\n|   | hadoop.hdfs.server.blockmanagement.TestReconstructStripedBlocksWithRackAwareness |\n|   | hadoop.hdfs.server.namenode.TestReencryptionWithKMS |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure170 |\n|   | hadoop.hdfs.server.blockmanagement.TestBlockManager |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure020 |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure090 |\n|   | hadoop.hdfs.TestLeaseRecoveryStriped |\n|   | hadoop.hdfs.TestReadStripedFileWithDNFailure |\n|   | hadoop.hdfs.TestErasureCodingPoliciesWithRandomECPolicy |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure150 |\n| Timed out junit tests | org.apache.hadoop.hdfs.TestWriteReadStripedFile |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:71bbb86 |\n| JIRA Issue | HDFS-12222 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12885764/HDFS-12222.004.patch |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux 513cbdc5b1f7 3.13.0-123-generic #172-Ubuntu SMP Mon Jun 26 18:04:35 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / b6e7d13 |\n| Default Java | 1.8.0_144 |\n| findbugs | v3.1.0-RC1 |\n| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/21035/artifact/patchprocess/diff-checkstyle-root.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/21035/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |\n|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/21035/testReport/ |\n| modules | C: hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs-client hadoop-hdfs-project/hadoop-hdfs hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core U: . |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/21035/console |\n| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2017-09-07T10:51:32.280+0000","updated":"2017-09-07T10:51:32.280+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13090905/comment/16157720","id":"16157720","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=andrew.wang","name":"andrew.wang","key":"andrew.wang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=andrew.wang&avatarId=19230","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=andrew.wang&avatarId=19230","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=andrew.wang&avatarId=19230","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=andrew.wang&avatarId=19230"},"displayName":"Andrew Wang","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi Huafeng, thanks for revving,\n\nI was most of the way through reviewing this patch, but decided to pull out a debugger to understand the current format. I might have mis-interpreted the format when I filed this bug, we might not need to change anything at all.\n\nThe BlockLocations are modeled right now as one location per block group. For an RS(3,2) file of length 4*BLOCK_SIZE+123, it'd look like:\n\n{noformat}\nBlockLocation(\n    offset: 0,\n    length: 3*BLOCK_SIZE, \n    hosts: {\"host1:9866\", \"host2:9866\", \"host3:9866\", \"host4:9866\", \"host5:9866\"})\nBlockLocation(\n    offset: 3*BLOCK_SIZE,\n    length: 123,\n    hosts: {\"host1:9866\", \"host4:9866\", \"host5:9866\"})\n{noformat}\n\nI think this is parsed fine by FileInputFormat and Impala and so on. It looks like a single really big block. We don't even need to remove the parity blocks. Impala at least has the idea of {{maxScanRangeLength}} so it can split really big blocks.\n\nHuafeng, what do you think? If you agree, we can still use this JIRA to add better Javadocs to explain what BlockLocation[] looks like for EC files, and also the test cases.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=andrew.wang","name":"andrew.wang","key":"andrew.wang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=andrew.wang&avatarId=19230","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=andrew.wang&avatarId=19230","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=andrew.wang&avatarId=19230","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=andrew.wang&avatarId=19230"},"displayName":"Andrew Wang","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-09-07T21:44:43.174+0000","updated":"2017-09-07T21:44:43.174+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13090905/comment/16158013","id":"16158013","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=HuafengWang","name":"HuafengWang","key":"huafengwang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Huafeng Wang","active":true,"timeZone":"Asia/Shanghai"},"body":"Hi Andrew, I agree with you. I'll update the patch soon.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=HuafengWang","name":"HuafengWang","key":"huafengwang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Huafeng Wang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-09-08T02:04:44.090+0000","updated":"2017-09-08T02:04:44.090+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13090905/comment/16162329","id":"16162329","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=andrew.wang","name":"andrew.wang","key":"andrew.wang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=andrew.wang&avatarId=19230","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=andrew.wang&avatarId=19230","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=andrew.wang&avatarId=19230","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=andrew.wang&avatarId=19230"},"displayName":"Andrew Wang","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi Huafeng, thanks for working on this, I took a look at the 005 patch, a few review comments:\n\n* I recommend moving the BlockLocation[] format example to FileSystem#getFileBlockLocations and FileContext#getFileBlockLocations, which are public APIs. Then, we can link to it from the other code locations.\n* Related, the javadoc links to TestDistributedFileSystemWithECFile don't work since prod code doesn't depend on test, recommend instead doing the above change and linking to the public method\n* Recommend adding a link to FileSystem#getFileBlockLocations to LocatedFileStatus#getBlockLocations.\n* Recommend adding a format explanation for a single BlockLocation (replicated and EC) to BlockLocation as well, along with the link to FileSystem and FileContext.\n\nRegarding this blurb:\n\n{code}\n   * In HDFS implementation, the BlockLocation of returned LocatedFileStatus\n   * will have different formats for replicated and erasure coded file. Please\n   * refer to HDFS for more details.\n{code}\n\nI'd prefer we drop this in most places, since this format should be compatible for downstreams, and it'll be well documented on the public API classes noted above.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=andrew.wang","name":"andrew.wang","key":"andrew.wang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=andrew.wang&avatarId=19230","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=andrew.wang&avatarId=19230","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=andrew.wang&avatarId=19230","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=andrew.wang&avatarId=19230"},"displayName":"Andrew Wang","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-09-12T01:27:56.521+0000","updated":"2017-09-12T01:27:56.521+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13090905/comment/16162765","id":"16162765","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 12s{color} | {color:blue} Docker mode activated. {color} |\n|| || || || {color:brown} Prechecks {color} ||\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 2 new or modified test files. {color} |\n|| || || || {color:brown} trunk Compile Tests {color} ||\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  1m 26s{color} | {color:blue} Maven dependency ordering for branch {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 14m 41s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 16m 54s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m 16s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  3m  8s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  5m 39s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m 15s{color} | {color:green} trunk passed {color} |\n|| || || || {color:brown} Patch Compile Tests {color} ||\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 18s{color} | {color:blue} Maven dependency ordering for patch {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  2m 21s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 13m 33s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 13m 33s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m 10s{color} | {color:green} root: The patch generated 0 new + 354 unchanged - 2 fixed = 354 total (was 356) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  2m 58s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  5m 53s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m 17s{color} | {color:green} the patch passed {color} |\n|| || || || {color:brown} Other Tests {color} ||\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}  8m 14s{color} | {color:red} hadoop-common in the patch failed. {color} |\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  1m 24s{color} | {color:green} hadoop-hdfs-client in the patch passed. {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}105m 52s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 29s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black}193m 26s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| Failed junit tests | hadoop.net.TestDNS |\n|   | hadoop.hdfs.TestReplaceDatanodeOnFailure |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure000 |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure100 |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure060 |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure210 |\n|   | hadoop.hdfs.TestReadStripedFileWithMissingBlocks |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure010 |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure130 |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure200 |\n|   | hadoop.hdfs.TestReconstructStripedFile |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure170 |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure040 |\n|   | hadoop.hdfs.TestClientProtocolForPipelineRecovery |\n|   | hadoop.hdfs.TestLeaseRecoveryStriped |\n|   | hadoop.hdfs.TestEncryptedTransfer |\n| Timed out junit tests | org.apache.hadoop.hdfs.TestWriteReadStripedFile |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:71bbb86 |\n| JIRA Issue | HDFS-12222 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12886588/HDFS-12222.006.patch |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux 682171c88b03 3.13.0-129-generic #178-Ubuntu SMP Fri Aug 11 12:48:20 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / e74d1be |\n| Default Java | 1.8.0_144 |\n| findbugs | v3.1.0-RC1 |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/21087/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/21087/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |\n|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/21087/testReport/ |\n| modules | C: hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs-client hadoop-hdfs-project/hadoop-hdfs U: . |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/21087/console |\n| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2017-09-12T10:14:36.057+0000","updated":"2017-09-12T10:14:36.057+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13090905/comment/16163947","id":"16163947","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=andrew.wang","name":"andrew.wang","key":"andrew.wang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=andrew.wang&avatarId=19230","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=andrew.wang&avatarId=19230","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=andrew.wang&avatarId=19230","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=andrew.wang&avatarId=19230"},"displayName":"Andrew Wang","active":true,"timeZone":"America/Los_Angeles"},"body":"+1 LGTM thanks for working on this Huafeng, will commit shortly.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=andrew.wang","name":"andrew.wang","key":"andrew.wang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=andrew.wang&avatarId=19230","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=andrew.wang&avatarId=19230","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=andrew.wang&avatarId=19230","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=andrew.wang&avatarId=19230"},"displayName":"Andrew Wang","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-09-13T00:35:14.038+0000","updated":"2017-09-13T00:35:14.038+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13090905/comment/16163948","id":"16163948","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=andrew.wang","name":"andrew.wang","key":"andrew.wang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=andrew.wang&avatarId=19230","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=andrew.wang&avatarId=19230","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=andrew.wang&avatarId=19230","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=andrew.wang&avatarId=19230"},"displayName":"Andrew Wang","active":true,"timeZone":"America/Los_Angeles"},"body":"Committed to trunk and branch-3.0, thanks for the contribution Huafeng!","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=andrew.wang","name":"andrew.wang","key":"andrew.wang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=andrew.wang&avatarId=19230","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=andrew.wang&avatarId=19230","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=andrew.wang&avatarId=19230","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=andrew.wang&avatarId=19230"},"displayName":"Andrew Wang","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-09-13T00:35:58.013+0000","updated":"2017-09-13T00:35:58.013+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13090905/comment/16163968","id":"16163968","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"SUCCESS: Integrated in Jenkins build Hadoop-trunk-Commit #12856 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/12856/])\nHDFS-12222. Document and test BlockLocation for erasure-coded files. (wang: rev f4b6267465d139bfdaf75e25761672eaf61d8a11)\n* (edit) hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FileContext.java\n* (edit) hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSClient.java\n* (edit) hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java\n* (edit) hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/BlockLocation.java\n* (edit) hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/AbstractFileSystem.java\n* (edit) hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocol/HdfsLocatedFileStatus.java\n* (add) hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDistributedFileSystemWithECFile.java\n* (edit) hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/LocatedFileStatus.java\n* (edit) hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FileSystem.java\n* (edit) hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDistributedFileSystem.java\n* (edit) hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/fs/Hdfs.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2017-09-13T00:52:16.769+0000","updated":"2017-09-13T00:52:16.769+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13090905/comment/16163998","id":"16163998","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=HuafengWang","name":"HuafengWang","key":"huafengwang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Huafeng Wang","active":true,"timeZone":"Asia/Shanghai"},"body":"Thanks [~andrew.wang] for your advice and help!","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=HuafengWang","name":"HuafengWang","key":"huafengwang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Huafeng Wang","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-09-13T01:27:00.515+0000","updated":"2017-09-13T01:27:00.515+0000"}],"maxResults":30,"total":30,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-12222/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i3i5lz:"}}