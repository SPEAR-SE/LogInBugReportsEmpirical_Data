{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12745402","self":"https://issues.apache.org/jira/rest/api/2/issue/12745402","key":"HDFS-7180","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12327181","id":"12327181","description":"2.6.0 release","name":"2.6.0","archived":false,"released":true,"releaseDate":"2014-11-18"}],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2014-10-16T23:14:24.634+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Thu Oct 30 17:53:00 UTC 2014","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":"10002_*:*_1_*:*_678624165_*|*_1_*:*_1_*:*_1635050966_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2014-10-28T21:48:19.488+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-7180/watchers","watchCount":6,"isWatching":false},"created":"2014-10-02T03:07:04.400+0000","customfield_12310192":null,"customfield_12310191":[{"self":"https://issues.apache.org/jira/rest/api/2/customFieldOption/10343","value":"Reviewed","id":"10343"}],"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/2","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/critical.svg","name":"Critical","id":"2"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"3.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12326264","id":"12326264","description":"2.5.0 release","name":"2.5.0","archived":false,"released":true,"releaseDate":"2014-08-11"}],"issuelinks":[{"id":"12399203","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12399203","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"12748961","key":"HDFS-7259","self":"https://issues.apache.org/jira/rest/api/2/issue/12748961","fields":{"summary":"Unresponseive NFS mount point due to deferred COMMIT response","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12399204","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12399204","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"12746807","key":"HDFS-7215","self":"https://issues.apache.org/jira/rest/api/2/issue/12746807","fields":{"summary":"Add JvmPauseMonitor to NFS gateway","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/4","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/minor.svg","name":"Minor","id":"4"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/4","id":"4","description":"An improvement or enhancement to an existing feature or task.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype","name":"Improvement","subtask":false,"avatarId":21140}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brandonli","name":"brandonli","key":"brandonli","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Brandon Li","active":true,"timeZone":"America/Los_Angeles"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2014-12-01T03:08:38.337+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12320727","id":"12320727","name":"nfs"}],"timeoriginalestimate":null,"description":"We are using Hadoop 2.5.0 (HDFS only) and start and mount the NFSv3 gateway on one node in the cluster to let users upload data with rsync.\n\nHowever, we find the NFSv3 daemon seems frequently get stuck while the HDFS seems working well. (hdfds dfs -ls and etc. works just well). The last stuck we found is after around 1 day running and several hundreds GBs of data uploaded.\n\nThe NFSv3 daemon is started on one node and on the same node the NFS is mounted.\n\nFrom the node where the NFS is mounted:\n\ndmsg shows like this:\n\n[1859245.368108] nfs: server localhost not responding, still trying\n[1859245.368111] nfs: server localhost not responding, still trying\n[1859245.368115] nfs: server localhost not responding, still trying\n[1859245.368119] nfs: server localhost not responding, still trying\n[1859245.368123] nfs: server localhost not responding, still trying\n[1859245.368127] nfs: server localhost not responding, still trying\n[1859245.368131] nfs: server localhost not responding, still trying\n[1859245.368135] nfs: server localhost not responding, still trying\n[1859245.368138] nfs: server localhost not responding, still trying\n[1859245.368142] nfs: server localhost not responding, still trying\n[1859245.368146] nfs: server localhost not responding, still trying\n[1859245.368150] nfs: server localhost not responding, still trying\n[1859245.368153] nfs: server localhost not responding, still trying\n\nThe mounted directory can not be `ls` and `df -hT` gets stuck too.\n\nThe latest lines from the nfs3 log in the hadoop logs directory:\n\n2014-10-02 05:43:20,452 INFO org.apache.hadoop.nfs.nfs3.IdUserGroup: Updated user map size: 35\n2014-10-02 05:43:20,461 INFO org.apache.hadoop.nfs.nfs3.IdUserGroup: Updated group map size: 54\n2014-10-02 05:44:40,374 INFO org.apache.hadoop.hdfs.nfs.nfs3.OpenFileCtx: Have to change stable write to unstable write:FILE_SYNC\n2014-10-02 05:44:40,732 INFO org.apache.hadoop.hdfs.nfs.nfs3.OpenFileCtx: Have to change stable write to unstable write:FILE_SYNC\n2014-10-02 05:46:06,535 INFO org.apache.hadoop.hdfs.nfs.nfs3.OpenFileCtx: Have to change stable write to unstable write:FILE_SYNC\n2014-10-02 05:46:26,075 INFO org.apache.hadoop.hdfs.nfs.nfs3.OpenFileCtx: Have to change stable write to unstable write:FILE_SYNC\n2014-10-02 05:47:56,420 INFO org.apache.hadoop.hdfs.nfs.nfs3.OpenFileCtx: Have to change stable write to unstable write:FILE_SYNC\n2014-10-02 05:48:56,477 INFO org.apache.hadoop.hdfs.nfs.nfs3.OpenFileCtx: Have to change stable write to unstable write:FILE_SYNC\n2014-10-02 05:51:46,750 INFO org.apache.hadoop.hdfs.nfs.nfs3.OpenFileCtx: Have to change stable write to unstable write:FILE_SYNC\n2014-10-02 05:53:23,809 INFO org.apache.hadoop.hdfs.nfs.nfs3.OpenFileCtx: Have to change stable write to unstable write:FILE_SYNC\n2014-10-02 05:53:24,508 INFO org.apache.hadoop.hdfs.nfs.nfs3.OpenFileCtx: Have to change stable write to unstable write:FILE_SYNC\n2014-10-02 05:55:57,334 INFO org.apache.hadoop.hdfs.nfs.nfs3.OpenFileCtx: Have to change stable write to unstable write:FILE_SYNC\n2014-10-02 05:57:07,428 INFO org.apache.hadoop.hdfs.nfs.nfs3.OpenFileCtx: Have to change stable write to unstable write:FILE_SYNC\n2014-10-02 05:58:32,609 INFO org.apache.hadoop.nfs.nfs3.IdUserGroup: Update cache now\n2014-10-02 05:58:32,610 INFO org.apache.hadoop.nfs.nfs3.IdUserGroup: Not doing static UID/GID mapping because '/etc/nfs.map' does not exist.\n2014-10-02 05:58:32,620 INFO org.apache.hadoop.nfs.nfs3.IdUserGroup: Updated user map size: 35\n2014-10-02 05:58:32,628 INFO org.apache.hadoop.nfs.nfs3.IdUserGroup: Updated group map size: 54\n2014-10-02 06:01:32,098 WARN org.apache.hadoop.hdfs.DFSClient: Slow ReadProcessor read fields took 60062ms (threshold=30000ms); ack: seqno: -2 status: SUCCESS status: ERROR downstreamAckTimeNanos: 0, targets: [10.0.3.172:50010, 10.0.3.176:50010]\n2014-10-02 06:01:32,099 WARN org.apache.hadoop.hdfs.DFSClient: DFSOutputStream ResponseProcessor exception  for block BP-1960069741-10.0.3.170-1410430543652:blk_1074363564_623643\njava.io.IOException: Bad response ERROR for block BP-1960069741-10.0.3.170-1410430543652:blk_1074363564_623643 from datanode 10.0.3.176:50010\n        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer$ResponseProcessor.run(DFSOutputStream.java:828)\n2014-10-02 06:07:00,368 WARN org.apache.hadoop.hdfs.DFSClient: Error Recovery for block BP-1960069741-10.0.3.170-1410430543652:blk_1074363564_623643 in pipeline 10.0.3.172:50010, 10.0.3.176:50010: bad datanode 10.0.3.176:50010\n\nThe logs seems suggest 10.0.3.176 is bad. However, from the `hdfs dfsadmin -report`, all nodes in the cluster seems working.\n\nAny help will be appreciated. Thanks in advance.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12676001","id":"12676001","filename":"HDFS-7180.001.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brandonli","name":"brandonli","key":"brandonli","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Brandon Li","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-10-21T01:17:47.790+0000","size":15998,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12676001/HDFS-7180.001.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12676390","id":"12676390","filename":"HDFS-7180.002.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brandonli","name":"brandonli","key":"brandonli","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Brandon Li","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-10-22T18:43:23.365+0000","size":16696,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12676390/HDFS-7180.002.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12676474","id":"12676474","filename":"HDFS-7180.003.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brandonli","name":"brandonli","key":"brandonli","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Brandon Li","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-10-22T23:45:41.613+0000","size":16756,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12676474/HDFS-7180.003.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"NFSv3 gateway frequently gets stuck due to GC","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ericzma","name":"ericzma","key":"ericzma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eric Zhiqiang Ma","active":true,"timeZone":"Asia/Hong_Kong"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ericzma","name":"ericzma","key":"ericzma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eric Zhiqiang Ma","active":true,"timeZone":"Asia/Hong_Kong"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":"Linux, Fedora 19 x86-64","customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12745402/comment/14174429","id":"14174429","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brandonli","name":"brandonli","key":"brandonli","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Brandon Li","active":true,"timeZone":"America/Los_Angeles"},"body":"Sorry for the late response. Thanks for filing the bug, [~ericzma].\nNFS gateway could be stuck in GC and thus the connection with DN timed out, which makes NFS gateway think the DN is bad. If this is the case, you can find lots of socket timeout exception in DN logs.\n\nOne of the cause of GC is the reordered writes arrive faster than the speed to dump them on local disk. In this case, NFS log should have nonSequentialWriteInMemory with a very big value (need the trace level to be DEBUG).\n\nI will upload a patch soon.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brandonli","name":"brandonli","key":"brandonli","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Brandon Li","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-10-16T23:14:24.634+0000","updated":"2014-10-16T23:14:24.634+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12745402/comment/14174706","id":"14174706","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ericzma","name":"ericzma","key":"ericzma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eric Zhiqiang Ma","active":true,"timeZone":"Asia/Hong_Kong"},"body":"~brandonli: Not at all and many thanks a lot for the analysis and confirmation!\n\nI checked the log on 10.0.3.176 and found the exception of socket timeout between 10.0.3.172 and 10.0.3.176 as follows.\n\n------------------------------\n2014-10-02 06:00:07,326 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1960069741-10.0.3.170-1410430543652:blk_1074363564_623643 src: /10.0.3.172:37334 dest: /10.0.3.176:\n50010\n2014-10-02 06:00:31,970 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Slow flushOrSync took 24097ms (threshold=300ms), isSync:true, flushTotalNanos=9424ns\n2014-10-02 06:01:32,093 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Exception for BP-1960069741-10.0.3.170-1410430543652:blk_1074363564_623643\njava.net.SocketTimeoutException: 60000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.0.3.176:50010 remote=/10.0.3.17\n2:37334]\n        at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)\n        at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)\n        at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)\n        at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)\n        at java.io.BufferedInputStream.read1(BufferedInputStream.java:286)\n        at java.io.BufferedInputStream.read(BufferedInputStream.java:345)\n        at java.io.DataInputStream.read(DataInputStream.java:149)\n        at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:192)\n        at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:213)\n        at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)\n        at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)\n        at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:453)\n        at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:734)\n        at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:741)\n        at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:124)\n        at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:71)\n        at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:234)\n        at java.lang.Thread.run(Thread.java:745)\n2014-10-02 06:01:32,093 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1960069741-10.0.3.170-1410430543652:blk_1074363564_623643, type=LAST_IN_PIPELINE, downstream\ns=0:[]: Thread is interrupted.\n2014-10-02 06:01:32,093 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1960069741-10.0.3.170-1410430543652:blk_1074363564_623643, type=LAST_IN_PIPELINE, downstream\ns=0:[] terminating\n2014-10-02 06:01:32,093 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: opWriteBlock BP-1960069741-10.0.3.170-1410430543652:blk_1074363564_623643 received exception java.net.SocketTime\noutException: 60000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.0.3.176:50010 remote=/10.0.3.172:37334]\n2014-10-02 06:01:32,093 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: dstore-176:50010:DataXceiver error processing WRITE_BLOCK operation  src: /10.0.3.172:37334 dst: /10.0.3.176:50\n010\njava.net.SocketTimeoutException: 60000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.0.3.176:50010 remote=/10.0.3.17\n2:37334]\n        at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)\n        at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)\n        at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)\n        at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)\n        at java.io.BufferedInputStream.read1(BufferedInputStream.java:286)\n        at java.io.BufferedInputStream.read(BufferedInputStream.java:345)\n        at java.io.DataInputStream.read(DataInputStream.java:149)\n        at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:192)\n        at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:213)\n        at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)\n        at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)\n        at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:453)\n        at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:734)\n        at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:741)\n        at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:124)\n        at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:71)\n        at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:234)\n        at java.lang.Thread.run(Thread.java:745)\n------------------------------\n\nOur trace level is INFO. Hence, I do not have information on the nonSequentialWriteInMemory.\n\nBTW: is it possible to disable the reordered writes or decrease its rate through configurations of the NFSv3 gateway or the NFS client?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ericzma","name":"ericzma","key":"ericzma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eric Zhiqiang Ma","active":true,"timeZone":"Asia/Hong_Kong"},"created":"2014-10-17T04:11:13.567+0000","updated":"2014-10-17T04:11:13.567+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12745402/comment/14175267","id":"14175267","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brandonli","name":"brandonli","key":"brandonli","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Brandon Li","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks for confirming the issue. The reordered write is an NFS client behavior, which we have no control. But we can throttle the data client data ingestion to gateway, which will be in the patch.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brandonli","name":"brandonli","key":"brandonli","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Brandon Li","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-10-17T17:19:43.444+0000","updated":"2014-10-17T17:19:43.444+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12745402/comment/14176314","id":"14176314","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ericzma","name":"ericzma","key":"ericzma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eric Zhiqiang Ma","active":true,"timeZone":"Asia/Hong_Kong"},"body":"Brandon Li: Thanks. It sounds great to me. I will be waiting for the patch and try it.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ericzma","name":"ericzma","key":"ericzma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eric Zhiqiang Ma","active":true,"timeZone":"Asia/Hong_Kong"},"created":"2014-10-19T13:45:16.301+0000","updated":"2014-10-19T13:45:16.301+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12745402/comment/14177825","id":"14177825","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12676001/HDFS-7180.001.patch\n  against trunk revision e90718f.\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.\n                        Please justify why no new tests are needed for this patch.\n                        Also please list what manual steps were performed to verify this patch.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs-nfs.\n\n    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/8466//testReport/\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/8466//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2014-10-21T01:55:31.774+0000","updated":"2014-10-21T01:55:31.774+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12745402/comment/14179349","id":"14179349","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jingzhao","name":"jingzhao","key":"jingzhao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jing Zhao","active":true,"timeZone":"America/Los_Angeles"},"body":"The patch looks good to me. One question is that if we let new incoming write wait for dumper, we need to make sure the waiting thread can finally get unblocked even if the dumper thread hits some issue. Currently it looks to me like if the dumper hits an exception then it may quit without calling notifyAll.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jingzhao","name":"jingzhao","key":"jingzhao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jing Zhao","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-10-21T23:55:03.053+0000","updated":"2014-10-21T23:55:03.053+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12745402/comment/14180305","id":"14180305","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brandonli","name":"brandonli","key":"brandonli","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Brandon Li","active":true,"timeZone":"America/Los_Angeles"},"body":"Nice catch, Jing.\nI've uploaded a new patch. It lets dumper notify waiting threads even when error happens. I also did some code cleanup.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brandonli","name":"brandonli","key":"brandonli","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Brandon Li","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-10-22T18:44:49.642+0000","updated":"2014-10-22T18:44:49.642+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12745402/comment/14180307","id":"14180307","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brandonli","name":"brandonli","key":"brandonli","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Brandon Li","active":true,"timeZone":"America/Los_Angeles"},"body":"The unit test seems tricky to add. I did some file uploading tests to see the pending non-sequencial writes were under control. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brandonli","name":"brandonli","key":"brandonli","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Brandon Li","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-10-22T18:46:21.736+0000","updated":"2014-10-22T18:46:21.736+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12745402/comment/14180382","id":"14180382","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12676390/HDFS-7180.002.patch\n  against trunk revision d67214f.\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.\n                        Please justify why no new tests are needed for this patch.\n                        Also please list what manual steps were performed to verify this patch.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:red}-1 findbugs{color}.  The patch appears to introduce 1 new Findbugs (version 2.0.3) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs-nfs.\n\n    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/8480//testReport/\nFindbugs warnings: https://builds.apache.org/job/PreCommit-HDFS-Build/8480//artifact/patchprocess/newPatchFindbugsWarningshadoop-hdfs-nfs.html\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/8480//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2014-10-22T19:25:25.564+0000","updated":"2014-10-22T19:25:25.564+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12745402/comment/14180744","id":"14180744","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brandonli","name":"brandonli","key":"brandonli","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Brandon Li","active":true,"timeZone":"America/Los_Angeles"},"body":"Uploaded a new patch to fix the findbugs warning.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brandonli","name":"brandonli","key":"brandonli","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Brandon Li","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-10-22T23:45:41.621+0000","updated":"2014-10-22T23:45:41.621+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12745402/comment/14180759","id":"14180759","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jingzhao","name":"jingzhao","key":"jingzhao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jing Zhao","active":true,"timeZone":"America/Los_Angeles"},"body":"+1 pending Jenkins","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jingzhao","name":"jingzhao","key":"jingzhao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jing Zhao","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-10-22T23:55:42.750+0000","updated":"2014-10-22T23:55:42.750+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12745402/comment/14180853","id":"14180853","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12676474/HDFS-7180.003.patch\n  against trunk revision 3b12fd6.\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.\n\n      {color:red}-1 javac{color}.  The applied patch generated 1269 javac compiler warnings (more than the trunk's current 1266 warnings).\n\n    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager:\n\n                  org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestCapacitySchedulerDynamicBehavior\n                  org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestCapacityScheduler\n\n    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/8487//testReport/\nJavac warnings: https://builds.apache.org/job/PreCommit-HDFS-Build/8487//artifact/patchprocess/diffJavacWarnings.txt\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/8487//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2014-10-23T01:06:04.603+0000","updated":"2014-10-23T01:06:04.603+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12745402/comment/14180990","id":"14180990","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brandonli","name":"brandonli","key":"brandonli","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Brandon Li","active":true,"timeZone":"America/Los_Angeles"},"body":"The javac warning and unit test failures are not introduced by this patch.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brandonli","name":"brandonli","key":"brandonli","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Brandon Li","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-10-23T04:13:06.269+0000","updated":"2014-10-23T04:13:06.269+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12745402/comment/14181009","id":"14181009","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brandonli","name":"brandonli","key":"brandonli","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Brandon Li","active":true,"timeZone":"America/Los_Angeles"},"body":"Thank you, Jing, for the review. I've committed the patch.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brandonli","name":"brandonli","key":"brandonli","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Brandon Li","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-10-23T04:28:02.732+0000","updated":"2014-10-23T04:28:02.732+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12745402/comment/14181010","id":"14181010","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"FAILURE: Integrated in Hadoop-trunk-Commit #6321 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/6321/])\nHDFS-7180. NFSv3 gateway frequently gets stuck due to GC. Contributed by Brandon Li (brandonli: rev d71d40a63d198991077d5babd70be5e9787a53f1)\n* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt\n* hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/WriteCtx.java\n* hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtxCache.java\n* hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/RpcProgramNfs3.java\n* hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java\n* hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/DFSClientCache.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2014-10-23T04:33:01.704+0000","updated":"2014-10-23T04:33:01.704+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12745402/comment/14181263","id":"14181263","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"SUCCESS: Integrated in Hadoop-Yarn-trunk #721 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/721/])\nHDFS-7180. NFSv3 gateway frequently gets stuck due to GC. Contributed by Brandon Li (brandonli: rev d71d40a63d198991077d5babd70be5e9787a53f1)\n* hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/DFSClientCache.java\n* hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtxCache.java\n* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt\n* hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java\n* hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/RpcProgramNfs3.java\n* hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/WriteCtx.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2014-10-23T11:49:55.784+0000","updated":"2014-10-23T11:49:55.784+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12745402/comment/14181389","id":"14181389","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"SUCCESS: Integrated in Hadoop-Hdfs-trunk #1910 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1910/])\nHDFS-7180. NFSv3 gateway frequently gets stuck due to GC. Contributed by Brandon Li (brandonli: rev d71d40a63d198991077d5babd70be5e9787a53f1)\n* hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/RpcProgramNfs3.java\n* hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtxCache.java\n* hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java\n* hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/DFSClientCache.java\n* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt\n* hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/WriteCtx.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2014-10-23T14:16:45.816+0000","updated":"2014-10-23T14:16:45.816+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12745402/comment/14181451","id":"14181451","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"FAILURE: Integrated in Hadoop-Mapreduce-trunk #1935 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1935/])\nHDFS-7180. NFSv3 gateway frequently gets stuck due to GC. Contributed by Brandon Li (brandonli: rev d71d40a63d198991077d5babd70be5e9787a53f1)\n* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt\n* hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtxCache.java\n* hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/DFSClientCache.java\n* hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/WriteCtx.java\n* hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java\n* hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/RpcProgramNfs3.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2014-10-23T15:14:04.905+0000","updated":"2014-10-23T15:14:04.905+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12745402/comment/14190032","id":"14190032","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ericzma","name":"ericzma","key":"ericzma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eric Zhiqiang Ma","active":true,"timeZone":"Asia/Hong_Kong"},"body":"NFSv3 gateway works well for us with the patch. No stucks found during uploading ~400GB data. Thanks, Brandon and all!","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ericzma","name":"ericzma","key":"ericzma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eric Zhiqiang Ma","active":true,"timeZone":"Asia/Hong_Kong"},"created":"2014-10-30T13:14:41.364+0000","updated":"2014-10-30T13:14:41.364+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12745402/comment/14190484","id":"14190484","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brandonli","name":"brandonli","key":"brandonli","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Brandon Li","active":true,"timeZone":"America/Los_Angeles"},"body":"Thank you, [~ericzma] for giving it a try!","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brandonli","name":"brandonli","key":"brandonli","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Brandon Li","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-10-30T17:53:00.715+0000","updated":"2014-10-30T17:53:00.715+0000"}],"maxResults":20,"total":20,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-7180/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i20pmv:"}}