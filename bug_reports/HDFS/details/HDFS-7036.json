{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12740318","self":"https://issues.apache.org/jira/rest/api/2/issue/12740318","key":"HDFS-7036","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":"2014-09-12T18:24:56.223+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Tue Mar 24 01:20:27 UTC 2015","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-7036/watchers","watchCount":8,"isWatching":false},"created":"2014-09-10T05:56:58.611+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":["BB2015-05-TBR"],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"1.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12327746","id":"12327746","description":"2.5.1 release","name":"2.5.1","archived":false,"released":true,"releaseDate":"2014-09-05"}],"issuelinks":[],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2015-05-06T03:28:07.973+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/10002","description":"A patch for this issue has been uploaded to JIRA by a contributor.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/document.png","name":"Patch Available","id":"10002","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/4","id":4,"key":"indeterminate","colorName":"yellow","name":"In Progress"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12319200","id":"12319200","name":"webhdfs","description":"WebHDFS: HTTP REST API for HDFS"}],"timeoriginalestimate":null,"description":"Issuing command\n{code}\n hadoop fs -lsr webhdfs://<insecureCluster>\n{code}\nat a secure cluster side fails with message \"Failed to get the token ...\", similar symptom as reported in HDFS-6776.\n\nIf the fix of HDFS-6776 is applied to only the secure cluster, doing \n{code}\ndistcp webhdfs://<insecureCluster> <secureCluster>\n{code}\nwould fail same way.\n\nBasically running any application in secure cluster to access insecure cluster via webhdfs would fail the same way, if the HDFS-6776 fix is not applied to the insecure cluster.\n\nThis could be quite some user pain. Filing this jira for a solution to make user's life easier.\n\nOne proposed solution was to add a msg-parsing mechanism in webhdfs, which is a bit hacky. The other proposed solution is to do the same kind of hack at application side, which means the same hack need to be applied in each application.\n\nThanks [~daryn], [~wheat9], [~jingzhao], [~tucu00] and [~atm] for the discussion in HDFS-6776.\n\n ","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12668367","id":"12668367","filename":"HDFS-7036.001.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-09-12T15:35:03.771+0000","size":2770,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12668367/HDFS-7036.001.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"HDFS-6776 fix requires to upgrade insecure cluster, which means quite some user pain","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12740318/comment/14129535","id":"14129535","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi [~wheat9] and [~jingzhao],\n\nThanks for the discussion in HDFS-6776. \n\nI described the two proposed solutions for addressing HDFS-7036 in the jira description. I think adding the msg-parsing hack in webhdfs seems to be the right approach so we don't have to put the similar hack in different applications. For example, even \"hadoop fs -lsr webhdfs://<insecureCluster>\" is broken for the same reason.\n\nThe argument against this approach was, the webhdfs has a large audience, thus could be an overkill. Would you please provide some more detail here? \n\nAssuming that we don't put the hack in webhdfs, would you please share some thoughts about the right solution?\n\nThanks a lot.\n \n\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-09-11T02:22:44.687+0000","updated":"2014-09-11T02:22:44.687+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12740318/comment/14131670","id":"14131670","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi [~wheat9] and [~jingzhao],\n\nI agree with [~tucu00] that this is a quite important thing to do to help user:\n{quote}\nIMO it will be a pita for users with multiple clusters the fact that we are not parsing the exception message. Please lets have a follow up JIRA for it.\n{quote}\n\nNot sure whether you have time to comment soon. To establish a base for further discussion, I uploaded the similar approach (rev 001 here) we proposed earlier in HDFS-6776. I'd really appreciate if you guys can comment and we can converge to a solution.\n\nBTW, since the IOException(\"Failed to get the token ..\" ) is now removed by HDFS-6776, I didn't introduce a string constant for that. The msg parsed by rev 001 is the sole occurence.\n\nThanks. \n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-09-12T15:44:41.344+0000","updated":"2014-09-12T15:44:41.344+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12740318/comment/14131875","id":"14131875","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12668367/HDFS-7036.001.patch\n  against trunk revision 78b0483.\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.\n                        Please justify why no new tests are needed for this patch.\n                        Also please list what manual steps were performed to verify this patch.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:\n\n                  org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover\n\n    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/8006//testReport/\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/8006//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2014-09-12T18:24:56.223+0000","updated":"2014-09-12T18:24:56.223+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12740318/comment/14144213","id":"14144213","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi [~wheat9] and [~jingzhao], \n\nIt has been quite a while since I created this jira as a follow-up of HDFS-6776, as we agreed in the discussion there. Would you please comment here?\n\nThanks a lot.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-09-23T02:29:08.769+0000","updated":"2014-09-23T02:29:08.769+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12740318/comment/14146861","id":"14146861","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wheat9","name":"wheat9","key":"wheat9","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Haohui Mai","active":true,"timeZone":"America/Los_Angeles"},"body":"My position has not changed since HDFS-6776. Just to recap:\n\n# This use case is so specific to distcp that it should be fixed distcp instead of the underlying filesystem implementation.\n# This is a hack for compatibility. There are many more users of {{WebHdfsFileSystem}} compared to distcp. It is more reasonable to contain the changes at higher layers (i.e. distcp) to avoid surprises to other applications.\n\nI understand that hacking {{WebHdfsFileSystem}} is an easy enough fix, I also understand that a hack might be needed either here or there, but parsing the exception message in {{WebHdfsFileSystem}} does not seem the right solution here.\n\nIf it turns out that this type of hack is unavoidable, I suggest doing it in distcp.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wheat9","name":"wheat9","key":"wheat9","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Haohui Mai","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-09-24T20:47:34.050+0000","updated":"2014-09-24T20:47:34.050+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12740318/comment/14146957","id":"14146957","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"HI [~wheat9], Thanks for your comments. \n\nWould you mind also comment on how we are going to deal with the similar failure of issuing\n{code}\nhadoop fs -ls <insecureCluster>\n{code}\nfrom secure cluster side? There is the possibility that other applications too. Given it's a hack, wonder if you would suggest to have the same hack to different places?\n\nWould you please give some *concrete* example about the potential damage it would cause if we have the hack in webhdfs? I think that would help the discussion most here.\n\nTo me, it's an easy and clean solution to have this hack in webhdfs, so all applications are taken care of by the solution; and it's going to be easy to take out this hack in the future when it's the time.\n\nOn the other hand, adding the hack in distcp and other applications, the solution in each application is going to be more complicated than the webhdfs one, and it has the potential to introduce more instability to the software than the potential damage I can see with the webhdfs solution. So the *concrete* example I hoped you could give can help the discussion here.\n\nThanks a lot.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-09-24T22:08:03.275+0000","updated":"2014-09-24T22:08:03.275+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12740318/comment/14146989","id":"14146989","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wheat9","name":"wheat9","key":"wheat9","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Haohui Mai","active":true,"timeZone":"America/Los_Angeles"},"body":"bq. ...adding the hack in distcp and other applications...\n\nCan you point out what the other applications are that need to access both secure and insecure cluster at the same time? To my best knowledge, distcp is the only use case. The title of this jira suggests it is focusing on distcp.\n\nIn contrast, YARN, MR and other applications that are built on top of them use {{WebHdfsFileSystem}} extensively.\n\nMy message has been consistent since HDFS-6776 -- the hack should be contained which result minimal damage in the codebase. I cannot +1 for the approach on hacking {{WebHdfsFileSystem}} just for this issue.\n\nIf you still don't get it, it might be helpful to go through the distcp code first.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wheat9","name":"wheat9","key":"wheat9","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Haohui Mai","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-09-24T22:34:41.268+0000","updated":"2014-09-24T22:34:41.268+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12740318/comment/14147038","id":"14147038","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi [~wheat9],\n\nOne example I described several times and in my previous comment is issuing {{hadoop fs -ls <insecureCluster>}} from secure cluster side. It's broken for the same reason. Do you suggest to hack the fsshell too or leave it as broken as is?  In addition, imagine user could write their own applications to access data in both secure and insecure cluster.\n\nWould you please provide some *concrete\" example of potential damage?\n\nThanks.\n\n\n\n\n\n\n\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-09-24T22:58:35.588+0000","updated":"2014-09-24T22:58:35.588+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12740318/comment/14148643","id":"14148643","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi [~wheat9],\n\nHope my answers yesterday addressed your questions. In case not, here is another attempt:\n{quote}\nCan you point out what the other applications are that need to access both secure and insecure cluster at the same time? To my best knowledge, distcp is the only use case. The title of this jira suggests it is focusing on distcp.\n{quote}\nEven though the goal of HDFS-6776 and this jira is to fix distcp, the real issue is that *webhdfs is broken* when accessing insecure cluster from secure cluster side, for the same reason. Distcp is just one use case. The fsshell example I gave in the jira description is another. If user has two clusters (secure and insecure), there is chance that user has the need to write applications that access data in a similar fashion.  Do you not agree that we should fix all these cases?\n\n{quote}\nMy message has been consistent since HDFS-6776 â€“ the hack should be contained which result minimal damage in the codebase. I cannot +1 for the approach on hacking WebHdfsFileSystem just for this issue.\n{quote}\nYes, I can see you said this in many comments. But would you please explain with *real* example about the damage of hacking in webhdfs? This is what I did not get from your earlier comments, and I have been asking for.\n\n{quote}\nIf you still don't get it, it might be helpful to go through the distcp code first.\n{quote}\nGiven that there is already  message parsing in webhdfs code (see HDFS-7026), and there is no complaint about it, there seems to be no real damage, except it's a bit hacky. \n\nGiven the simplicity of this solution I posted that fixed all the above mentioned cases, and no real damage, what I really don't get is, why go with the more complex solution (the complexity of fixing distcp, plus fsshell, any application that user might write with same need)?\n\nAfter all, it's just a hack that we try use to achieve better user experience, and  we will take out when it's the time. If we hack all over the places, to take the hack out would be costly too. \n\nEven if it's just for distcp, I think simplicity should be favored if there is no real damage.\n\nThanks.\n ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-09-26T02:35:11.787+0000","updated":"2014-09-26T02:35:11.787+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12740318/comment/14149228","id":"14149228","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Another point to emphasize, the *root cause* of the issue we try to solve in HDFS-6776 and HDFS-7036 is that *webhdfs is broken*. IMO, to fix the root cause, the solution would be in webhdfs, and fixing elsewhere would be like the widely heard old Chinese saying \"zhi4 biao1 bu2 zhi4 ben3\" (solve the symptom but not the root problem).\n\nIn summary, I favor fixing webhdfs for the following reasons:\n## fixing root cause\n## simplicity\n## no real damage\n\nThanks.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-09-26T14:41:51.924+0000","updated":"2014-09-26T14:41:51.924+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12740318/comment/14149283","id":"14149283","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"My understanding is that the main point of disagreement here is about whether there is real damage. I have been asking for *concrete* example of damage, which I don't see in any prior comments. I'd appreciate it if it's provided. Thanks.\n\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-09-26T15:20:16.015+0000","updated":"2014-09-26T15:20:16.015+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12740318/comment/14154356","id":"14154356","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi [~wheat9],\n\nAlthough I still think the right solution is to fix webhdfs because the root cause is that webhdfs is broken,  since we really had an disagreement here, I looked into how to fix in distcp you proposed.  Below is what I found. I would appreciate if you can tell if my analysis below makes sense to you.\n\nAs a refresher, below is the interesting part of the stack trace (reported in HDFS-6776) relevant to the discussion here.\n\n{code}\n\tat org.apache.hadoop.hdfs.web.WebHdfsFileSystem.run(WebHdfsFileSystem.java:440)\n\tat org.apache.hadoop.hdfs.web.WebHdfsFileSystem.listStatus(WebHdfsFileSystem.java:1018)\n\tat org.apache.hadoop.fs.Globber.listStatus(Globber.java:69)\n\tat org.apache.hadoop.fs.Globber.glob(Globber.java:217)\n\tat org.apache.hadoop.fs.FileSystem.globStatus(FileSystem.java:1623)\n\tat org.apache.hadoop.tools.GlobbedCopyListing.doBuildListing(GlobbedCopyListing.java:77)\n\tat org.apache.hadoop.tools.CopyListing.buildListing(CopyListing.java:81)\n\tat org.apache.hadoop.tools.DistCp.createInputFileListing(DistCp.java:342)\n\tat org.apache.hadoop.tools.DistCp.execute(DistCp.java:154)\n{code}\n\nTo fix in fistcp, we should look into the boundary portion between distcp and file system in the above stack trace:\n\n{code\n\tat org.apache.hadoop.tools.GlobbedCopyListing.doBuildListing(GlobbedCopyListing.java:77)\n\tat org.apache.hadoop.tools.CopyListing.buildListing(CopyListing.java:81)\n\tat org.apache.hadoop.tools.DistCp.createInputFileListing(DistCp.java:342)\n{code}\n\nThe boundary code in {{GlobbedCopyListing.doBuildListing}} is below \n{code}\n  for (Path p : options.getSourcePaths()) {\n      FileSystem fs = p.getFileSystem(getConf());\n      FileStatus[] inputs = fs.globStatus(p); <================this is where the exception is thrown\n\n      if(inputs != null && inputs.length > 0) {\n        for (FileStatus onePath: inputs) {\n          globbedPaths.add(onePath.getPath());\n        }\n      } else {\n        throw new InvalidInputException(p + \" doesn't exist\");        \n      }\n    }\n{code}\n\nI assume your proposed solution is to catch the exception here and do a hacked file listing using the {{p}} in the above code. However, this hack won't work for *wildcard* case:, e,g,:\n\n{code}\n hadoop  distcp webhdfs://<insecureCluster>/path/* webhdfs://<secureCluster>\n{code}\n\nWe won't be able to find what the wildcard will expand to, which is supposed to be got by {{FileStatus[] inputs = fs.globStatus(p);}}. Unless we hack into the file system.\n\nDid I misunderstand your approach? I'd appreciate if you could comment. Thanks in advance.\n\nBTW, You asked what applications other than distcp could apply in your last comment, I answered you with the \"hadoop fs -lsr\" example. Would you please confirm whether it addressed your  question? Do you think we should fix it too? Thanks.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-10-01T05:02:29.345+0000","updated":"2014-10-01T05:02:29.345+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12740318/comment/14376700","id":"14376700","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wheat9","name":"wheat9","key":"wheat9","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Haohui Mai","active":true,"timeZone":"America/Los_Angeles"},"body":"bq. I answered you with the \"hadoop fs -lsr\" example. Would you please confirm whether it addressed your question? Do you think we should fix it too? Thanks.\n\nFundamentally both distcp and ls are at the application layers. If you want to run ls in secure clusters to be able to list insecure clusters, then yes, it should be fixed. The problem is that whether it should be the default behavior, which is up to debate. I can see the values of both sides of the arguments. Practically it has not been a concern as {{ls}} only involves one cluster, and it is fairly easy to work around by overriding the configuration at the command line.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wheat9","name":"wheat9","key":"wheat9","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Haohui Mai","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-03-23T21:41:12.558+0000","updated":"2015-03-23T21:41:12.558+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12740318/comment/14377050","id":"14377050","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12668367/HDFS-7036.001.patch\n  against trunk revision 972f1f1.\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.\n                        Please justify why no new tests are needed for this patch.\n                        Also please list what manual steps were performed to verify this patch.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:\n\n                  org.apache.hadoop.tracing.TestTracing\n                  org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotReplication\n                  org.apache.hadoop.hdfs.server.namenode.TestFsck\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/10036//testReport/\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/10036//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2015-03-24T01:20:27.074+0000","updated":"2015-03-24T01:20:27.074+0000"}],"maxResults":14,"total":14,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-7036/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i1zv6v:"}}