{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12627382","self":"https://issues.apache.org/jira/rest/api/2/issue/12627382","key":"HDFS-4405","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/3","id":"3","description":"The problem is a duplicate of an existing issue.","name":"Duplicate"},"customfield_12312322":null,"customfield_12310220":"2013-01-14T08:26:33.427+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Thu Jan 17 07:40:51 UTC 2013","customfield_12310420":"304166","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_262188487_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2013-01-17T07:41:18.944+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-4405/watchers","watchCount":4,"isWatching":false},"created":"2013-01-14T06:51:30.499+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/1","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/blocker.svg","name":"Blocker","id":"1"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[],"issuelinks":[],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2013-01-17T07:41:18.970+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[],"timeoriginalestimate":null,"description":"test Environment: NN1,NN2,DN1,DN2,DN3\nmachine1:NN1,DN1\nmachine2:NN2,DN2\nmachine3:DN3\n\nmathine1 is down.\n\n2013-01-12 09:51:21,248 DEBUG ipc.Client (Client.java:setupIOstreams(562)) - Connecting to /160.161.0.155:8020\n2013-01-12 09:51:38,442 DEBUG ipc.Client (Client.java:close(932)) - closing ipc connection to vm2/160.161.0.155:8020: 10000 millis timeout while waiting for channel to be ready for connect. ch : java.nio.channels.SocketChannel[connection-pending remote=/160.161.0.155:8020]\njava.net.SocketTimeoutException: 10000 millis timeout while waiting for channel to be ready for connect. ch : java.nio.channels.SocketChannel[connection-pending remote=/160.161.0.155:8020]\n at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:213)\n at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:524)\n at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)\n at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:474)\n at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:568)\n at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:217)\n at org.apache.hadoop.ipc.Client.getConnection(Client.java:1286)\n at org.apache.hadoop.ipc.Client.call(Client.java:1156)\n at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:184)\n at $Proxy9.create(Unknown Source)\n at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:187)\n at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n at java.lang.reflect.Method.invoke(Method.java:597)\n at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:165)\n at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:84)\n at $Proxy10.create(Unknown Source)\n at org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:1261)\n at org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:1280)\n at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1128)\n at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1086)\n at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:232)\n at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:75)\n at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:806)\n at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:787)\n at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:715)\n at test.TestLease.main(TestLease.java:45)\n2013-01-12 09:51:38,443 DEBUG ipc.Client (Client.java:close(940)) - IPC Client (31594013) connection to /160.161.0.155:8020 from hdfs/hadoop@HADOOP.COM: closed\n2013-01-12 09:52:47,834 WARN  retry.RetryInvocationHandler (RetryInvocationHandler.java:invoke(95)) - Exception while invoking class org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create. Not retrying because the invoked method is not idempotent, and unable to determine whether it was invoked\njava.net.SocketTimeoutException: Call From szxy1x001833091/172.0.0.13 to vm2:8020 failed on socket timeout exception: java.net.SocketTimeoutException: 10000 millis timeout while waiting for channel to be ready for connect. ch : java.nio.channels.SocketChannel[connection-pending remote=/160.161.0.155:8020]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout\n at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:743)\n at org.apache.hadoop.ipc.Client.call(Client.java:1180)\n at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:184)\n at $Proxy9.create(Unknown Source)\n at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:187)\n at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n at java.lang.reflect.Method.invoke(Method.java:597)\n at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:165)\n at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:84)\n at $Proxy10.create(Unknown Source)\n at org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:1261)\n at org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:1280)\n at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1128)\n at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1086)\n at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:232)\n at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:75)\n at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:806)\n at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:787)\n at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:715)\n at test.TestLease.main(TestLease.java:45)\nCaused by: java.net.SocketTimeoutException: 10000 millis timeout while waiting for channel to be ready for connect. ch : java.nio.channels.SocketChannel[connection-pending remote=/160.161.0.155:8020]\n at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:213)\n at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:524)\n at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)\n at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:474)\n at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:568)\n at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:217)\n at org.apache.hadoop.ipc.Client.getConnection(Client.java:1286)\n at org.apache.hadoop.ipc.Client.call(Client.java:1156)\n ... 20 more\njava.net.SocketTimeoutException: Call From szxy1x001833091/172.0.0.13 to vm2:8020 failed on socket timeout exception: java.net.SocketTimeoutException: 10000 millis timeout while waiting for channel to be ready for connect. ch : java.nio.channels.SocketChannel[connection-pending remote=/160.161.0.155:8020]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout\n at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:743)\n at org.apache.hadoop.ipc.Client.call(Client.java:1180)\n at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:184)\n at $Proxy9.create(Unknown Source)\n at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:187)\n at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n at java.lang.reflect.Method.invoke(Method.java:597)\n at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:165)\n at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:84)\n at $Proxy10.create(Unknown Source)\n at org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:1261)\n at org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:1280)\n at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1128)\n at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1086)\n at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:232)\n at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:75)\n at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:806)\n at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:787)\n at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:715)\n at test.TestLease.main(TestLease.java:45)\nCaused by: java.net.SocketTimeoutException: 10000 millis timeout while waiting for channel to be ready for connect. ch : java.nio.channels.SocketChannel[connection-pending remote=/160.161.0.155:8020]\n at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:213)\n at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:524)\n at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)\n at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:474)\n at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:568)\n at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:217)\n at org.apache.hadoop.ipc.Client.getConnection(Client.java:1286)\n at org.apache.hadoop.ipc.Client.call(Client.java:1156)\n ... 20 more\n2013-01-12 09:54:52,269 DEBUG ipc.Client (Client.java:stop(1021)) - Stopping client\n","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"252186","customfield_12312823":null,"summary":"create file failure,when the machine of firse NameNod is down","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ewenpower","name":"ewenpower","key":"ewenpower","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liaowenrui","active":true,"timeZone":"Asia/Shanghai"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ewenpower","name":"ewenpower","key":"ewenpower","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liaowenrui","active":true,"timeZone":"Asia/Shanghai"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12627382/comment/13552504","id":"13552504","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"body":"I am not sure, how this is related to BK here. Please select the appropriate project.\nFor issue clarification, look at the API categorization in HDFS-2393, which are marked as idempotent.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-01-14T08:26:33.427+0000","updated":"2013-01-14T08:26:33.427+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12627382/comment/13552515","id":"13552515","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ewenpower","name":"ewenpower","key":"ewenpower","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liaowenrui","active":true,"timeZone":"Asia/Shanghai"},"body":"Uma,failure reason is that create file marked as not idempotent.\n\norg.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create. Not retrying because the invoked method is not idempotent, and unable to determine whether it was invoked\n\n\nhere is not related to BK.\n\nlog:\n\n013-01-12 09:52:47,834 WARN retry.RetryInvocationHandler (RetryInvocationHandler.java:invoke(95)) - Exception while invoking class org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create. Not retrying because the invoked method is not idempotent, and unable to determine whether it was invoked\n\nwhen client create file,the client will connect the first NameNode,but client don't connect to the first NameNode,because machine of first NameNode is shutdown.the create function mark as not idempotent,and create file op don't retry.so the create file op is failure. I think that when client don't connect to namenode,not idempotent will be retry. do you think,uma?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ewenpower","name":"ewenpower","key":"ewenpower","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liaowenrui","active":true,"timeZone":"Asia/Shanghai"},"created":"2013-01-14T08:47:10.742+0000","updated":"2013-01-14T08:47:10.742+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12627382/comment/13553408","id":"13553408","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ewenpower","name":"ewenpower","key":"ewenpower","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liaowenrui","active":true,"timeZone":"Asia/Shanghai"},"body":"this issue is hdfs issue.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ewenpower","name":"ewenpower","key":"ewenpower","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liaowenrui","active":true,"timeZone":"Asia/Shanghai"},"created":"2013-01-15T02:01:57.651+0000","updated":"2013-01-15T02:01:57.651+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12627382/comment/13553473","id":"13553473","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hustlmsp","name":"hustlmsp","key":"hustlmsp","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sijie Guo","active":true,"timeZone":"America/Los_Angeles"},"body":"[~ewenpower] if it was an hdfs issue, should it be moved to hdfs project?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hustlmsp","name":"hustlmsp","key":"hustlmsp","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sijie Guo","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-01-15T04:25:54.125+0000","updated":"2013-01-15T04:25:54.125+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12627382/comment/13553502","id":"13553502","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"body":"Create API did not mark as idempotent. That is working as per the design here. For your ref: HDFS-2393","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-01-15T05:24:58.416+0000","updated":"2013-01-15T05:24:58.416+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12627382/comment/13553505","id":"13553505","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"body":"Also look at the discussion in mailing list recently related this: [see|http://mail-archives.apache.org/mod_mbox/hadoop-user/201211.mbox/%3CCABbGW3w7nH+c5o_mOu7zp=+Acx-wtp4xXnv+YfZeN3C71v8ZCw@mail.gmail.com%3E]","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-01-15T05:29:53.120+0000","updated":"2013-01-15T05:29:53.120+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12627382/comment/13555954","id":"13555954","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"body":"Yes, you are right. Currently ConnectException only handled while connecting to NN. This is duplicate of HDFS-4404.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-01-17T07:40:51.806+0000","updated":"2013-01-17T07:40:51.806+0000"}],"maxResults":7,"total":7,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-4405/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i17juv:"}}