{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12994163","self":"https://issues.apache.org/jira/rest/api/2/issue/12994163","key":"HDFS-10714","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":"2016-08-02T14:41:13.645+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Mon Oct 03 21:47:41 UTC 2016","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-10714/watchers","watchCount":18,"isWatching":false},"created":"2016-08-02T04:11:34.602+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"1.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[],"issuelinks":[],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinayrpet","name":"vinayrpet","key":"vinayrpet","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinayakumar B","active":true,"timeZone":"Asia/Kolkata"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2017-03-01T10:24:39.080+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/10002","description":"A patch for this issue has been uploaded to JIRA by a contributor.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/document.png","name":"Patch Available","id":"10002","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/4","id":4,"key":"indeterminate","colorName":"yellow","name":"In Progress"}},"components":[],"timeoriginalestimate":null,"description":"We had come across one issue, where write is failed even 7 DN’s are available due to network fault at one datanode which is LAST_IN_PIPELINE. It will be similar to HDFS-6937 .\n\nScenario : (DN3 has N/W Fault and Min repl=2).\n\nWrite pipeline:\nDN1->DN2->DN3  => DN3 Gives ERROR_CHECKSUM ack. And so DN2 marked as bad\nDN1->DN4-> DN3 => DN3 Gives ERROR_CHECKSUM ack. And so DN4 is marked as bad\n….\nAnd so on ( all the times DN3 is LAST_IN_PIPELINE) ... Continued till no more datanodes to construct the pipeline.\n","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12827198","id":"12827198","filename":"HDFS-10714-01-draft.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinayrpet","name":"vinayrpet","key":"vinayrpet","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinayakumar B","active":true,"timeZone":"Asia/Kolkata"},"created":"2016-09-06T14:37:43.215+0000","size":19860,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12827198/HDFS-10714-01-draft.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"Issue in handling checksum errors in write pipeline when fault DN is LAST_IN_PIPELINE","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brahmareddy","name":"brahmareddy","key":"brahmareddy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=brahmareddy&avatarId=24624","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=brahmareddy&avatarId=24624","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=brahmareddy&avatarId=24624","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=brahmareddy&avatarId=24624"},"displayName":"Brahma Reddy Battula","active":true,"timeZone":"Asia/Kolkata"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brahmareddy","name":"brahmareddy","key":"brahmareddy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=brahmareddy&avatarId=24624","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=brahmareddy&avatarId=24624","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=brahmareddy&avatarId=24624","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=brahmareddy&avatarId=24624"},"displayName":"Brahma Reddy Battula","active":true,"timeZone":"Asia/Kolkata"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12994163/comment/15403322","id":"15403322","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brahmareddy","name":"brahmareddy","key":"brahmareddy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=brahmareddy&avatarId=24624","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=brahmareddy&avatarId=24624","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=brahmareddy&avatarId=24624","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=brahmareddy&avatarId=24624"},"displayName":"Brahma Reddy Battula","active":true,"timeZone":"Asia/Kolkata"},"body":"Thinking solutions like this.\n\n1) Remove both DNs in checksum error case..i.e DN2 and DN3\n\n2) Remove DN3  first and record DN2 as suspect node .. If it still fails with checksum error , then  DN2 can be removed as it's suspected during next pipeline\n\nI think, 2nd solution will be safe.. \n\nanythoughts on this...?  cc [~kanaka]/[~vinayrpet]","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brahmareddy","name":"brahmareddy","key":"brahmareddy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=brahmareddy&avatarId=24624","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=brahmareddy&avatarId=24624","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=brahmareddy&avatarId=24624","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=brahmareddy&avatarId=24624"},"displayName":"Brahma Reddy Battula","active":true,"timeZone":"Asia/Kolkata"},"created":"2016-08-02T04:26:24.059+0000","updated":"2016-08-02T04:26:24.059+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12994163/comment/15404103","id":"15404103","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"body":"Guessing who is faulty is complicated. Whatever works for a case can break other cases. It is not safe to remove the last guy, since it might be the only one that has valid data up to the ACKed bytes in certain cases. May be we should have the client examine datanodes individually before recreating a pipeline. \n- Have each datanode perform checksum validation up to the ACKed bytes (needs to be bytes-per-checksum aligned). \n- For identifying a bad node, directly write to N nodes for some number of packets. Exclude failed nodes and rebuild a pipeline.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"created":"2016-08-02T14:41:13.645+0000","updated":"2016-08-02T14:41:13.645+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12994163/comment/15467559","id":"15467559","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinayrpet","name":"vinayrpet","key":"vinayrpet","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinayakumar B","active":true,"timeZone":"Asia/Kolkata"},"body":"Here is the Initial approach, based on the #2 mentioned by [~brahmareddy].\n\n1. DN1->DN2->DN3 is the pipeline,\n2. DN3 will get ChecksumException, and Sends the CHECKSUM Error Ack upstream and shuts itself down.\n3. DN2 will receive the Ack, and before sending upstream, verifies its local replica's checksum.\n4. If DN2 also found checksum error, then possibly DN1 also would have error. So DN2 also marks itself CHECKSUM_ERROR, and sends the reply upstream and shuts itself down.\n\nSo in this way all DNs replicas will be verified before Ack reaches client.\n\nPlease review and give suggestions.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinayrpet","name":"vinayrpet","key":"vinayrpet","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinayakumar B","active":true,"timeZone":"Asia/Kolkata"},"created":"2016-09-06T14:36:36.838+0000","updated":"2016-09-06T14:36:36.838+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12994163/comment/15467787","id":"15467787","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 17s{color} | {color:blue} Docker mode activated. {color} |\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m  8s{color} | {color:blue} Maven dependency ordering for branch {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  8m 24s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m 41s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 33s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 42s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 29s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  3m 52s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 25s{color} | {color:green} trunk passed {color} |\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m  8s{color} | {color:blue} Maven dependency ordering for patch {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m 35s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m 44s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  1m 44s{color} | {color:green} the patch passed {color} |\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 33s{color} | {color:orange} hadoop-hdfs-project: The patch generated 5 new + 167 unchanged - 2 fixed = 172 total (was 169) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 32s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 23s{color} | {color:green} the patch passed {color} |\n| {color:red}-1{color} | {color:red} whitespace {color} | {color:red}  0m  0s{color} | {color:red} The patch has 4 line(s) that end in whitespace. Use git apply --whitespace=fix <<patch_file>>. Refer https://git-scm.com/docs/git-apply {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  4m  1s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 18s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  1m  2s{color} | {color:green} hadoop-hdfs-client in the patch passed. {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 60m  6s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 18s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black} 92m 42s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| Failed junit tests | hadoop.fs.viewfs.TestViewFsHdfs |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:9560f25 |\n| JIRA Issue | HDFS-10714 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12827198/HDFS-10714-01-draft.patch |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux b999d7a6cba6 3.13.0-92-generic #139-Ubuntu SMP Tue Jun 28 20:42:26 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / 62a9667 |\n| Default Java | 1.8.0_101 |\n| findbugs | v3.0.0 |\n| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/16645/artifact/patchprocess/diff-checkstyle-hadoop-hdfs-project.txt |\n| whitespace | https://builds.apache.org/job/PreCommit-HDFS-Build/16645/artifact/patchprocess/whitespace-eol.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/16645/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |\n|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/16645/testReport/ |\n| modules | C: hadoop-hdfs-project/hadoop-hdfs-client hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/16645/console |\n| Powered by | Apache Yetus 0.4.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2016-09-06T16:12:19.352+0000","updated":"2016-09-06T16:12:19.352+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12994163/comment/15469269","id":"15469269","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinayrpet","name":"vinayrpet","key":"vinayrpet","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinayakumar B","active":true,"timeZone":"Asia/Kolkata"},"body":"Current Patch contains some part of the HDFS-6937 patch.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinayrpet","name":"vinayrpet","key":"vinayrpet","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinayakumar B","active":true,"timeZone":"Asia/Kolkata"},"created":"2016-09-07T02:17:56.903+0000","updated":"2016-09-07T02:17:56.903+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12994163/comment/15471097","id":"15471097","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi [~brahmareddy] and [~vinayrpet], Thanks for working on this. \n\nWhen visiting this issue (per discussion in HDFS-6937),\n{quote}\nDN1->DN2->DN3 => DN3 Gives ERROR_CHECKSUM ack. And so DN2 marked as bad\n{quote}\n\nIn HDFS-6937 case, if DN3 gives ERROR_CHECKSUM error, DN3 will be replaced. But here DN2 got replaced. Would you please add some code snippet to explain how that happened? thanks.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-09-07T16:41:41.961+0000","updated":"2016-09-07T16:41:41.961+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12994163/comment/15494082","id":"15494082","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinayrpet","name":"vinayrpet","key":"vinayrpet","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinayakumar B","active":true,"timeZone":"Asia/Kolkata"},"body":"bq. In HDFS-6937 case, if DN3 gives ERROR_CHECKSUM error, DN3 will be replaced. But here DN2 got replaced. Would you please add some code snippet to explain how that happened? thanks.\nAt first DN3 only will be marked bad and replaced. And a reference will be kept DN2 as sender during previous checksum error. If checksum error found again in DN4 (which was replaced in place of DN3), then DN2 will be marked as BAD, provided DN2's local replica found valid in both times.\n\nHere is the code snippet.\n{code}\n+      int currentBad = badNodeIndex;\n+      /*\n+       * When the checksum error found during transfer of packets, finding out\n+       * the actual faulty node is tricky. So following below steps.\n+       * 1. First remove the node which reported CHECKSUM error as bad.\n+       *  and Keep track of it.\n+       * 2. If second time CHECKSUM error reported and sender is same as\n+       *  earlier, this time sender will be removed instead of the reporter.\n+       */\n+      if (checkSumError && badNodeIndex > 0) {\n+        if (prevChecksumErrorSenderNode != null) {\n+          // If same node involved with second checksum error, then its clear\n+          // that sender is the faulty node. \n+          if (prevChecksumErrorSenderNode.equals(nodes[badNodeIndex - 1])) {\n+            badNodeIndex = badNodeIndex - 1;\n+            errorState.setBadNodeIndex(badNodeIndex);\n+            prevChecksumErrorSenderNode = nodes[badNodeIndex - 1];\n+            LOG.warn(\"Bad node is changed to \" + nodes[badNodeIndex]\n+                + \" instead of \" + nodes[currentBad]\n+                + \" as this node caused checksum error in previous pipeline\");\n+          }\n+        } else {\n+          prevChecksumErrorSenderNode = nodes[badNodeIndex - 1];\n+          LOG.warn(\"Bad node is : \" + nodes[badNodeIndex]);\n+        }\n+      }\n{code}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinayrpet","name":"vinayrpet","key":"vinayrpet","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinayakumar B","active":true,"timeZone":"Asia/Kolkata"},"created":"2016-09-15T17:55:40.178+0000","updated":"2016-09-15T17:55:40.178+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12994163/comment/15541527","id":"15541527","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinayrpet","name":"vinayrpet","key":"vinayrpet","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinayakumar B","active":true,"timeZone":"Asia/Kolkata"},"body":"hi [~yzhangal],[~kihwal] \nWould selected approach looks fine to you?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinayrpet","name":"vinayrpet","key":"vinayrpet","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinayakumar B","active":true,"timeZone":"Asia/Kolkata"},"created":"2016-10-03T04:44:46.497+0000","updated":"2016-10-03T04:45:01.133+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12994163/comment/15542658","id":"15542658","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"body":"+1 on DN remembering what it did during a recovery and being more adaptive.\n\nUnconditionally removing DN3 first might not be a good idea, since this is the only one did checksum verification. The data on this node upto the ACKed bytes is very likely good (it still could have wrong data on disk). In majority of cases I have analyzed in the past, this would hurt than help. Sure it might be at fault, but seems too harsh to remove it first.  Perhaps instead of statically removing one node, DN should perform further diagnostics.  The client could try different node ordering in the pipeline before removing any node. We could also add a feature to tell all DNs in the pipeline to do checksum verification in the middle of a block write (is per packet switch possible?). If the errors from these propagate properly to the client, it will be able to make a more informed decision and avoid blaming a wrong node.\n\nOf course, this won't be perfect either. We also see checksum problems during dfs write stemming from faulty clients. The clients having OOM is the most common ones. These are irrecoverable. While we are at the subject of write pipelines, the transferBlock ops during replication is even worse since ACK is practically turned off. A node with a faulty NIC can do some damage there.  But that's outside the scope of this jira.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"created":"2016-10-03T15:22:40.946+0000","updated":"2016-10-03T15:22:40.946+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12994163/comment/15543529","id":"15543529","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi [~vinayrpet],\n\nThanks for your work here and sorry for the late reply. I agree with Kihwal's comment that \"Guessing who is faulty is complicated\".\n\nThe idea of the patch described at\nhttps://issues.apache.org/jira/browse/HDFS-10714?focusedCommentId=15467559&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-15467559\nseems to be a reasonable approach, but questions about the following scenarios:\n\nInitial pipeline DN1 -> DN2 -> DN3\n\nScenario 1. Detecting possibly network issue with DN2's output\n1.1 DN3 reported checksum error\n1.2 DN2 checked itself, and saw it's good\n1.3 Treat DN3 as bad, DN3 is replaced with DN4\n1.4 DN1 -> DN2 -> DN4\n1.5 DN4 reports checksum error, \n1.6 Treat DN2 as bad\nQuestion 1, do we allow DN3 and DN4 to be added back to be available DNs for later recovery? In theory we should.\n\nScenario 2. Detect data corruption at DN2 (this is like what's reported in HDFS-6937)\n2.1 DN3 reported checksum error\n2.2 DN2 checked itself, and saw it's bad, reports checksum error\n2.3 DN1 checked itself, and saw it's good, \n2.4 treat DN2 as bad\nQuestion 2, is this how it works? do we add back DN3 to be available for later recovery?\n\nScenario 3.\n3.1 DN3 reported checksum error\n3.2 DN2 checked itself, and saw it's bad\n3.3 DN1 checked itself, and saw it's bad\n3.4 treat DN1 as bad\nQuestion 3, is this how it works? and do we have DN2 and DN3 available for use by later recovery?\n\nThanks.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-10-03T21:47:41.304+0000","updated":"2016-10-03T21:47:41.304+0000"}],"maxResults":10,"total":10,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-10714/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i31s6v:"}}