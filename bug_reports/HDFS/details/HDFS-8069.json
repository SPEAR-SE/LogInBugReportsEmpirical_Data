{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12818679","self":"https://issues.apache.org/jira/rest/api/2/issue/12818679","key":"HDFS-8069","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":"2015-04-06T22:32:15.256+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Wed Apr 08 23:22:56 UTC 2015","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-8069/watchers","watchCount":10,"isWatching":false},"created":"2015-04-06T19:43:13.131+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/2","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/critical.svg","name":"Critical","id":"2"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12327584","id":"12327584","description":"2.7.0 release","name":"2.7.0","archived":false,"released":true,"releaseDate":"2015-04-20"}],"issuelinks":[{"id":"12420458","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12420458","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"inwardIssue":{"id":"12741125","key":"HDFS-7055","self":"https://issues.apache.org/jira/rest/api/2/issue/12741125","fields":{"summary":"Add tracing to DFSInputStream","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/7","id":"7","description":"The sub-task of the issue","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype","name":"Sub-task","subtask":true,"avatarId":21146}}}},{"id":"12420641","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12420641","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"inwardIssue":{"id":"12819158","key":"HDFS-8088","self":"https://issues.apache.org/jira/rest/api/2/issue/12819158","fields":{"summary":"Reduce the number of HTrace spans generated by HDFS reads","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/10002","description":"A patch for this issue has been uploaded to JIRA by a contributor.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/document.png","name":"Patch Available","id":"10002","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/4","id":4,"key":"indeterminate","colorName":"yellow","name":"In Progress"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/4","id":"4","description":"An improvement or enhancement to an existing feature or task.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype","name":"Improvement","subtask":false,"avatarId":21140}}}}],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2015-04-08T23:22:56.931+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12312928","id":"12312928","name":"hdfs-client"}],"timeoriginalestimate":null,"description":"I've been doing some testing of Accumulo with HDFS 2.7.0 and have noticed a serious performance impact when Accumulo registers itself as a SpanReceiver.\n\nThe context of the test which I noticed the impact is that an Accumulo process reads a series of updates from a write-ahead log. This is just reading a series of Writable objects from a file in HDFS. With tracing enabled, I waited for at least 10 minutes and the server still hadn't read a ~300MB file.\n\nDoing a poor-man's inspection via repeated thread dumps, I always see something like the following:\n\n{noformat}\n\"replication task 2\" daemon prio=10 tid=0x0000000002842800 nid=0x794d runnable [0x00007f6c7b1ec000]\n   java.lang.Thread.State: RUNNABLE\n        at java.util.concurrent.CopyOnWriteArrayList.iterator(CopyOnWriteArrayList.java:959)\n        at org.apache.htrace.Tracer.deliver(Tracer.java:80)\n        at org.apache.htrace.impl.MilliSpan.stop(MilliSpan.java:177)\n        - locked <0x000000077a770730> (a org.apache.htrace.impl.MilliSpan)\n        at org.apache.htrace.TraceScope.close(TraceScope.java:78)\n        at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:898)\n        - locked <0x000000079fa39a48> (a org.apache.hadoop.hdfs.DFSInputStream)\n        at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:697)\n        - locked <0x000000079fa39a48> (a org.apache.hadoop.hdfs.DFSInputStream)\n        at java.io.DataInputStream.readByte(DataInputStream.java:265)\n        at org.apache.hadoop.io.WritableUtils.readVLong(WritableUtils.java:308)\n        at org.apache.hadoop.io.WritableUtils.readVInt(WritableUtils.java:329)\n        at org.apache.accumulo.core.data.Mutation.readFields(Mutation.java:951)\n       ... more accumulo code omitted...\n{noformat}\n\nWhat I'm seeing here is that reading a single byte (in WritableUtils.readVLong) is causing a new Span creation and close (which includes a flush to the SpanReceiver). This results in an extreme amount of spans for {{DFSInputStream.byteArrayRead}} just for reading a file from HDFS -- over 700k spans for just reading a few hundred MB file.\n\nPerhaps there's something different we need to do for the SpanReceiver in Accumulo? I'm not entirely sure, but this was rather unexpected.\n\ncc/ [~cmccabe]","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"Tracing implementation on DFSInputStream seriously degrades performance","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=elserj","name":"elserj","key":"elserj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=elserj&avatarId=17258","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=elserj&avatarId=17258","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=elserj&avatarId=17258","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=elserj&avatarId=17258"},"displayName":"Josh Elser","active":true,"timeZone":"America/New_York"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=elserj","name":"elserj","key":"elserj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=elserj&avatarId=17258","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=elserj&avatarId=17258","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=elserj&avatarId=17258","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=elserj&avatarId=17258"},"displayName":"Josh Elser","active":true,"timeZone":"America/New_York"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12818679/comment/14482094","id":"14482094","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi [~elserj],\n\nI'm not familiar with the Accumulo span receiver.  Just off of the top of my head:\n\n1. Accumulo uses HDFS underneath.  When processing trace spans using Accumulo, are you creating more trace spans inside HDFS?  This will lead to a kind of infinite recursion.\n\n2. You should be tracing less than 1% of all requests.  We don't really support tracing 100% of all requests on a 300 MB file, or at least not without serious performance degradation.\n\nThere are ways to avoid issue #1.  The easiest way is to use htraced, a trace sink built specifically for the purpose of storing spans.  htraced is also developed inside the HTrace project rather than externally.  Issue #2 can be fixed by setting an appropriate sampler such as ProbabilitySampler.\n\nI do think we could potentially make the read pathway less \"chatty\" but that's somewhat of a separate issue.  No matter how few spans we create on the read pathway, you still will have problems with issue #1 and #2 if you have not configured correctly.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-04-06T22:32:15.256+0000","updated":"2015-04-06T22:32:41.506+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12818679/comment/14482120","id":"14482120","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"body":"I can think of a few ways to solve issue #1:\n\n1. Disable tracing in Hadoop, by setting {{hadoop.htrace.sampler}} to {{NeverSampler}}.  Needless to say, this will allow you to get tracing from Accumlo, which you have currently, but not Hadoop.  So it's not a regression but it won't give you additional functionality.\n\n2. Send the trace spans to a different Accumlo instance than the one you are tracing.  The different Accumlo instance can have tracing turned off (both Accumlo tracing and Hadoop tracing) and so avoid the amplification effect.\n\n3. Just use htraced.  We could add security to htraced if that is a concern.\n\nI wonder if we could simply have Accumlo use a shim API that we could later change over to call HTrace under the covers, once these issues have been worked out.  I'm a little concerned that we may want to change the HTrace API in the future and we might find that Accumlo has done some stuff we weren't expecting with it.  What do you think?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-04-06T22:47:54.197+0000","updated":"2015-04-06T22:48:16.493+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12818679/comment/14482224","id":"14482224","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=billie.rinaldi","name":"billie.rinaldi","key":"billie.rinaldi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=billie.rinaldi&avatarId=30233","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=billie.rinaldi&avatarId=30233","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=billie.rinaldi&avatarId=30233","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=billie.rinaldi&avatarId=30233"},"displayName":"Billie Rinaldi","active":true,"timeZone":"America/New_York"},"body":"We aren't tracing in the span collector.  We are only tracing one Accumulo operation, but it is a fairly complex operation.  So even if we traced this operation less often, we would still run into this issue.  I'm not sure I understand how the DFSInputStream tracing is supposed to be used.  Is it possible introduce sampling of DFSInputStream read operations within a current trace that has been enabled?  I'm also confused about why it would create a span for a single read operation, which is usually just pulling some bytes from an in-memory buffer (?), rather than only creating spans in the BlockReaders.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=billie.rinaldi","name":"billie.rinaldi","key":"billie.rinaldi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=billie.rinaldi&avatarId=30233","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=billie.rinaldi&avatarId=30233","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=billie.rinaldi&avatarId=30233","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=billie.rinaldi&avatarId=30233"},"displayName":"Billie Rinaldi","active":true,"timeZone":"America/New_York"},"created":"2015-04-06T23:50:48.462+0000","updated":"2015-04-06T23:50:48.462+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12818679/comment/14482261","id":"14482261","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=elserj","name":"elserj","key":"elserj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=elserj&avatarId=17258","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=elserj&avatarId=17258","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=elserj&avatarId=17258","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=elserj&avatarId=17258"},"displayName":"Josh Elser","active":true,"timeZone":"America/New_York"},"body":"Thanks for chiming in, [~billie.rinaldi]. I had been chatting with her about what I was seeing.\n\nI tried to break down what I see as the problem to the most trivial usecase, but perhaps I didn't do it well enough the first time. Take a class\n\n{code}\npublic class Foo implements Writable\n{code}\n\nI write some instances of this class to a file in HDFS, and then later read them back out again:\n\n{code}\nFSDataInputStream inputstream = filesystem.open(new Path(\"/my/file\"));\nfor (int i = 0; i < 100; i++) {\n  Foo myFoo = new Foo();\n  myFoo.readFields(inputstream);\n}\n{code}\n\nAs Billie said, the above is one step in a larger traced operation in Accumulo, but we *do* want to have this information from HDFS (e.g. is the time due to something wrong in Accumulo or HDFS, etc). It just struck me as extremely odd that something as (seemingly) simple as this would cause me such performance issues. Maybe the answer is \"don't do that\"? I just wanted to bring it up because it came across as very unexpected to me.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=elserj","name":"elserj","key":"elserj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=elserj&avatarId=17258","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=elserj&avatarId=17258","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=elserj&avatarId=17258","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=elserj&avatarId=17258"},"displayName":"Josh Elser","active":true,"timeZone":"America/New_York"},"created":"2015-04-07T00:12:39.840+0000","updated":"2015-04-07T00:12:39.840+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12818679/comment/14482274","id":"14482274","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=elserj","name":"elserj","key":"elserj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=elserj&avatarId=17258","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=elserj&avatarId=17258","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=elserj&avatarId=17258","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=elserj&avatarId=17258"},"displayName":"Josh Elser","active":true,"timeZone":"America/New_York"},"body":"With regards to your other points:\n\nComments to solutions on point 1:\n# As Billie said, we're not tracing the tracing code :). \n# A non-starter for me. We've had distributed tracing support built into Accumulo for years without issue. To suddenly inform users that they need to spin up a second cluster is a no-go.\n# If htraced had support for Accumulo as a backing store, I'd jump for joy. But, running one big-table application at a time is more than enough for me. Security isn't really relevant here -- there's more to Accumulo than just the security aspect. Kind of goes back to point 2: we have this support internally to Accumulo for some time. We really want to see it transparently go down through HDFS for the added insight.\n\nPoint 2:\nAgain, I think Billie got this already: this was caused by the tracing of a single operation. The traced operation in Accumulo read a file off of disk. Performance tanked due to excessive spans from one parent span.\n\nbq. I wonder if we could simply have Accumlo use a shim API that we could later change over to call HTrace under the covers, once these issues have been worked out. I'm a little concerned that we may want to change the HTrace API in the future and we might find that Accumlo has done some stuff we weren't expecting with it. What do you think?\n\nIt would certainly be much nicer to get rid of our tracer sink code and push it up into HTrace. Catching API changes early (instead of after a new HTrace version was released and Accumulo tried to use it) is ideal. Perhaps this is something we can start considering. The other side of the coin is that we could (will) be a good consumer that will try to hold you to some semblance of a stable API. Either way, a good discussion we can have over in HTrace rather than here :)","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=elserj","name":"elserj","key":"elserj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=elserj&avatarId=17258","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=elserj&avatarId=17258","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=elserj&avatarId=17258","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=elserj&avatarId=17258"},"displayName":"Josh Elser","active":true,"timeZone":"America/New_York"},"created":"2015-04-07T00:22:15.805+0000","updated":"2015-04-07T00:22:15.805+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12818679/comment/14482440","id":"14482440","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=iwasakims","name":"iwasakims","key":"iwasakims","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=iwasakims&avatarId=18289","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=iwasakims&avatarId=18289","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=iwasakims&avatarId=18289","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=iwasakims&avatarId=18289"},"displayName":"Masatake Iwasaki","active":true,"timeZone":"Asia/Tokyo"},"body":"bq. Is it possible introduce sampling of DFSInputStream read operations within a current trace that has been enabled?\n\nNo. There are some discussions in HADOOP-11758 and HTRACE-69.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=iwasakims","name":"iwasakims","key":"iwasakims","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=iwasakims&avatarId=18289","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=iwasakims&avatarId=18289","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=iwasakims&avatarId=18289","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=iwasakims&avatarId=18289"},"displayName":"Masatake Iwasaki","active":true,"timeZone":"Asia/Tokyo"},"created":"2015-04-07T02:18:11.252+0000","updated":"2015-04-07T02:18:11.252+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12818679/comment/14483286","id":"14483286","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=billie.rinaldi","name":"billie.rinaldi","key":"billie.rinaldi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=billie.rinaldi&avatarId=30233","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=billie.rinaldi&avatarId=30233","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=billie.rinaldi&avatarId=30233","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=billie.rinaldi&avatarId=30233"},"displayName":"Billie Rinaldi","active":true,"timeZone":"America/New_York"},"body":"From HTRACE-69:\nbq. If DFSInputStream#byteArrayRead is being too chatty, another option is to get rid of that trace span (and the ones on the BlockReader#read methods). We could just trace the functions which refill the buffers inside the BlockReader objects. That is the main operation that is time-consuming, so it might be more appropriate to do that anyway.\n\nI think this might be the case.  Creating spans for byte array reads of one byte or more effectively makes us unable to trace client operations if they happen to use DFSInputStream, which we are using to read walogs.  Operations involving Accumulo's RFiles seem to be in better shape since we are reading blocks from them.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=billie.rinaldi","name":"billie.rinaldi","key":"billie.rinaldi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=billie.rinaldi&avatarId=30233","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=billie.rinaldi&avatarId=30233","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=billie.rinaldi&avatarId=30233","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=billie.rinaldi&avatarId=30233"},"displayName":"Billie Rinaldi","active":true,"timeZone":"America/New_York"},"created":"2015-04-07T14:48:47.376+0000","updated":"2015-04-07T14:48:47.376+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12818679/comment/14484542","id":"14484542","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"body":"bq. Josh wrote: As Billie said, we're not tracing the tracing code .\n\nThanks for confirming this.  Just to double-check, can you confirm that you have {{hadoop.htrace.sampler}} set to nothing (the default).\n\nbq. Josh wrote: \\[a second cluster is\\] A non-starter for me. We've had distributed tracing support built into Accumulo for years without issue. To suddenly inform users that they need to spin up a second cluster is a no-go.\n\nUnderstood.  I think that the configuration you outlined, where {{hadoop.htrace.sampler}} is set to NeverSampler (or left unset) and all sampling happens at the level of Accumulo, should work.  We just need to fix the issues that we have currently.\n\nbq. Billie wrote: I think this might be the case \\[that HDFS tracing is too chatty\\]. Creating spans for byte array reads of one byte or more effectively makes us unable to trace client operations if they happen to use DFSInputStream, which we are using to read walogs. Operations involving Accumulo's RFiles seem to be in better shape since we are reading blocks from them.\n\nI am going to open an issue in HDFS to only trace the cases where we actually fill the buffer of the HDFS BlockReader.  I think that it's a reasonable tradeoff to make, given that filling the HDFS BlockReader buffer tends to be the main thing that delays readers from HDFS.  Just reading a byte from the in-memory buffer that already exists very seldom causes any delay, if ever.\n\nbq. Billie wrote: We are only tracing one Accumulo operation, but it is a fairly complex operation. So even if we traced this operation less often, we would still run into this issue\n\nIf the Accumlo operation is big enough, it may be necessary to split it into multiple HTrace spans.  For example, I think tracing an entire compaction would be too big.  We may have to experiment with this somewhat.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cmccabe","name":"cmccabe","key":"cmccabe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cmccabe&avatarId=29060","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cmccabe&avatarId=29060","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cmccabe&avatarId=29060","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cmccabe&avatarId=29060"},"displayName":"Colin P. McCabe","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-04-08T01:53:55.356+0000","updated":"2015-04-08T01:53:55.356+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12818679/comment/14486310","id":"14486310","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=elserj","name":"elserj","key":"elserj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=elserj&avatarId=17258","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=elserj&avatarId=17258","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=elserj&avatarId=17258","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=elserj&avatarId=17258"},"displayName":"Josh Elser","active":true,"timeZone":"America/New_York"},"body":"bq. Thanks for confirming this. Just to double-check, can you confirm that you have hadoop.htrace.sampler set to nothing (the default).\n\nSorry I took so long: Yes, I explicitly set {{hadoop.htrace.sampler}} to NeverSampler and re-ran the test with the same end result.\n\nbq. I am going to open an issue in HDFS to only trace the cases where we actually fill the buffer of the HDFS BlockReader. I think that it's a reasonable tradeoff to make, given that filling the HDFS BlockReader buffer tends to be the main thing that delays readers from HDFS. Just reading a byte from the in-memory buffer that already exists very seldom causes any delay, if ever.\n\nAgreed. Thanks for doing this.\n\nbq. If the Accumlo operation is big enough, it may be necessary to split it into multiple HTrace spans. For example, I think tracing an entire compaction would be too big. We may have to experiment with this somewhat.\n\nAgreed on experimentation. Personally, I'd love to be able to know \"is a compaction taking long because I'm waiting on HDFS?\", \"is there an inefficiency in how we read/write the bytes in Accumulo?\". I think a happy-medium just needs to be found.\n\nThanks again for your time with this.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=elserj","name":"elserj","key":"elserj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=elserj&avatarId=17258","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=elserj&avatarId=17258","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=elserj&avatarId=17258","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=elserj&avatarId=17258"},"displayName":"Josh Elser","active":true,"timeZone":"America/New_York"},"created":"2015-04-08T23:22:56.931+0000","updated":"2015-04-08T23:22:56.931+0000"}],"maxResults":9,"total":9,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-8069/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i2cv73:"}}