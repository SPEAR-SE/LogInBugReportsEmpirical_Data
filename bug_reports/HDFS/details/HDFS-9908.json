{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12947082","self":"https://issues.apache.org/jira/rest/api/2/issue/12947082","key":"HDFS-9908","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/2","id":"2","description":"The problem described is an issue which will never be fixed.","name":"Won't Fix"},"customfield_12312322":null,"customfield_12310220":"2016-03-22T19:32:40.418+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Tue May 31 15:19:07 UTC 2016","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_335419361_*|*_3_*:*_1_*:*_1208258279_*|*_5_*:*_1_*:*_0_*|*_10002_*:*_1_*:*_6041510272","customfield_12312321":null,"resolutiondate":"2016-05-31T15:19:07.164+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-9908/watchers","watchCount":7,"isWatching":false},"created":"2016-03-04T20:19:19.322+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"7.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12326264","id":"12326264","description":"2.5.0 release","name":"2.5.0","archived":false,"released":true,"releaseDate":"2014-08-11"}],"issuelinks":[{"id":"12461245","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12461245","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"12601173","key":"HADOOP-8640","self":"https://issues.apache.org/jira/rest/api/2/issue/12601173","fields":{"summary":"DU thread transient failures propagate to callers","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12459780","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12459780","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"inwardIssue":{"id":"12948145","key":"HDFS-9923","self":"https://issues.apache.org/jira/rest/api/2/issue/12948145","fields":{"summary":"Datanode disk failure handling is not consistent","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12477971","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12477971","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"inwardIssue":{"id":"12998307","key":"HDFS-10777","self":"https://issues.apache.org/jira/rest/api/2/issue/12998307","fields":{"summary":"DataNode should report&remove volume failures if DU cannot access files","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2016-08-18T20:50:48.867+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12312927","id":"12312927","name":"datanode"}],"timeoriginalestimate":null,"description":"DN may treat a disk scan failure exception as an NN handshake exception, and this can prevent a DN to join a cluster even if most of its disks are healthy.\n\nDuring NN handshake, DN initializes block pools. It will create a lock files per disk, and then scan the volumes. However, if the scanning throws exceptions due to disk failure, DN will think it's an exception because NN is inconsistent with the local storage (see {{DataNode#initBlockPool}}. As a result, it will attempt to reconnect to NN again.\n\nHowever, at this point, DN has not deleted its lock files on the disks. If it reconnects to NN again, it will think the same disks are already being used, and then it will fail handshake again because all disks can not be used (due to locking), and repeatedly. This will happen even if the DN has multiple disks, and only one of them fails. The DN will not be able to connect to NN despite just one failing disk. Note that it is possible to successfully create a lock file on a disk, and then has error scanning the disk.\n\nWe saw this on a CDH 5.3.3 cluster (which is based on Apache Hadoop 2.5.0, and we still see the same bug in 3.0.0 trunk branch). The root cause is that DN treats an internal error (single disk failure) as an external one (NN handshake failure) and we should fix it.\n\n{code:title=DataNode.java}\n/**\n   * One of the Block Pools has successfully connected to its NN.\n   * This initializes the local storage for that block pool,\n   * checks consistency of the NN's cluster ID, etc.\n   * \n   * If this is the first block pool to register, this also initializes\n   * the datanode-scoped storage.\n   * \n   * @param bpos Block pool offer service\n   * @throws IOException if the NN is inconsistent with the local storage.\n   */\n  void initBlockPool(BPOfferService bpos) throws IOException {\n    NamespaceInfo nsInfo = bpos.getNamespaceInfo();\n    if (nsInfo == null) {\n      throw new IOException(\"NamespaceInfo not found: Block pool \" + bpos\n          + \" should have retrieved namespace info before initBlockPool.\");\n    }\n    \n    setClusterId(nsInfo.clusterID, nsInfo.getBlockPoolID());\n\n    // Register the new block pool with the BP manager.\n    blockPoolManager.addBlockPool(bpos);\n    \n    // In the case that this is the first block pool to connect, initialize\n    // the dataset, block scanners, etc.\n    initStorage(nsInfo);\n\n    // Exclude failed disks before initializing the block pools to avoid startup\n    // failures.\n    checkDiskError();\n\n    data.addBlockPool(nsInfo.getBlockPoolID(), conf);  <----- this line throws disk error exception\n    blockScanner.enableBlockPoolId(bpos.getBlockPoolId());\n    initDirectoryScanner(conf);\n  }\n{code}\n\n{{FsVolumeList#addBlockPool}} is the source of exception.\n{code:title=FsVolumeList.java}\n  void addBlockPool(final String bpid, final Configuration conf) throws IOException {\n    long totalStartTime = Time.monotonicNow();\n    \n    final List<IOException> exceptions = Collections.synchronizedList(\n        new ArrayList<IOException>());\n    List<Thread> blockPoolAddingThreads = new ArrayList<Thread>();\n    for (final FsVolumeImpl v : volumes) {\n      Thread t = new Thread() {\n        public void run() {\n          try (FsVolumeReference ref = v.obtainReference()) {\n            FsDatasetImpl.LOG.info(\"Scanning block pool \" + bpid +\n                \" on volume \" + v + \"...\");\n            long startTime = Time.monotonicNow();\n            v.addBlockPool(bpid, conf);\n            long timeTaken = Time.monotonicNow() - startTime;\n            FsDatasetImpl.LOG.info(\"Time taken to scan block pool \" + bpid +\n                \" on \" + v + \": \" + timeTaken + \"ms\");\n          } catch (ClosedChannelException e) {\n            // ignore.\n          } catch (IOException ioe) {\n            FsDatasetImpl.LOG.info(\"Caught exception while scanning \" + v +\n                \". Will throw later.\", ioe);\n            exceptions.add(ioe);\n          }\n        }\n      };\n      blockPoolAddingThreads.add(t);\n      t.start();\n    }\n    for (Thread t : blockPoolAddingThreads) {\n      try {\n        t.join();\n      } catch (InterruptedException ie) {\n        throw new IOException(ie);\n      }\n    }\n    if (!exceptions.isEmpty()) {\n      throw exceptions.get(0); <----- here's the original of exception\n    }\n    \n    long totalTimeTaken = Time.monotonicNow() - totalStartTime;\n    FsDatasetImpl.LOG.info(\"Total time to scan all replicas for block pool \" +\n        bpid + \": \" + totalTimeTaken + \"ms\");\n  }\n{code}","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12792041","id":"12792041","filename":"HDFS-9908.001.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-03-08T17:29:18.945+0000","size":4222,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12792041/HDFS-9908.001.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12792108","id":"12792108","filename":"HDFS-9908.002.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-03-08T21:58:52.761+0000","size":10904,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12792108/HDFS-9908.002.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12794795","id":"12794795","filename":"HDFS-9908.003.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-03-22T17:07:04.742+0000","size":10924,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12794795/HDFS-9908.003.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12795234","id":"12795234","filename":"HDFS-9908.004.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-03-24T16:15:42.309+0000","size":14336,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12795234/HDFS-9908.004.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12795408","id":"12795408","filename":"HDFS-9908.005.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-03-25T12:28:23.524+0000","size":14564,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12795408/HDFS-9908.005.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12795636","id":"12795636","filename":"HDFS-9908.006.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-03-28T15:31:07.174+0000","size":15183,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12795636/HDFS-9908.006.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12796140","id":"12796140","filename":"HDFS-9908.007.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-03-30T19:17:05.307+0000","size":15183,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12796140/HDFS-9908.007.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"Datanode should tolerate disk scan failure during NN handshake","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":"CDH5.3.3","customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12947082/comment/15180534","id":"15180534","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"body":"For completeness, here's the related logs in DN:\n\n*DN connects to NN:*\n2016-02-18 02:20:37,949 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /10.107.162.126:50020\n2016-02-18 02:20:38,034 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: nameservice1\n2016-02-18 02:20:38,067 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: nameservice1\n2016-02-18 02:20:38,076 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to namenode1.weichiu.com/10.107.162.110:8022 starting to offer service\n2016-02-18 02:20:38,077 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to namenode2.weichiu.com10.107.162.120:8022 starting to offer service\n2016-02-18 02:20:38,085 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting\n2016-02-18 02:20:38,085 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting\n2016-02-18 02:20:39,211 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: namenode1.weichiu.com/10.107.162.110:8022. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)\n\n*Then DN does handshake, gets bpid from NN, and then analyze storage:*\n\n2016-02-18 02:20:53,512 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /data/1/dfs/dn/in_use.lock acquired by nodename 5124@namenode1.weichiu.com\n2016-02-18 02:20:53,563 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1018136951-49.4.167.110-1403564146510\n2016-02-18 02:20:53,563 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled\n2016-02-18 02:20:53,606 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.\n....\nall of the disks are successful\n\n*But one of them failed to scan:*\n\n2016-02-18 02:23:36,224 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Caught exception while scanning /data/8/dfs/dn/current.\nWill throw later.\nExitCodeException exitCode=1: du: cannot access `/data/8/dfs/dn/current/BP-1018136951-49.4.167.110-1403564146510/current/finalized/subdir228/subdir11/blk_\n1088686909': Input/output error\ndu: cannot access `/data/8/dfs/dn/current/BP-1018136951-49.4.167.110-1403564146510/current/finalized/subdir228/subdir11/blk_1088686909_14954023.meta': Inp\nut/output error\ndu: cannot access `/data/8/dfs/dn/current/BP-1018136951-49.4.167.110-1403564146510/current/finalized/subdir46/subdir69/blk_1093551560': Input/output error\ndu: cannot access `/data/8/dfs/dn/current/BP-1018136951-49.4.167.110-1403564146510/current/finalized/subdir46/subdir69/blk_1093551560_19818947.meta': Inpu\nt/output error\ndu: cannot access `/data/8/dfs/dn/current/BP-1018136951-49.4.167.110-1403564146510/current/finalized/subdir46/subdir116/blk_1093563577': Input/output erro\nr\ndu: cannot access `/data/8/dfs/dn/current/BP-1018136951-49.4.167.110-1403564146510/current/finalized/subdir46/subdir116/blk_1093563577_19830979.meta': Inp\nut/output error\ndu: cannot access `/data/8/dfs/dn/current/BP-1018136951-49.4.167.110-1403564146510/current/finalized/subdir46/subdir71/blk_1093552125': Input/output error\ndu: cannot access `/data/8/dfs/dn/current/BP-1018136951-49.4.167.110-1403564146510/current/finalized/subdir46/subdir71/blk_1093551897': Input/output error\ndu: cannot access `/data/8/dfs/dn/current/BP-1018136951-49.4.167.110-1403564146510/current/finalized/subdir46/subdir71/blk_1093551897_19819284.meta': Inpu\nt/output error\ndu: cannot access `/data/8/dfs/dn/current/BP-1018136951-49.4.167.110-1403564146510/current/finalized/subdir46/subdir71/blk_1093552003_19819390.meta': Inpu\nt/output error\ndu: cannot access `/data/8/dfs/dn/current/BP-1018136951-49.4.167.110-1403564146510/current/finalized/subdir46/subdir71/blk_1093552003': Input/output error\ndu: cannot access `/data/8/dfs/dn/current/BP-1018136951-49.4.167.110-1403564146510/current/finalized/subdir46/subdir71/blk_1093552125_19819512.meta': Inpu\nt/output error\ndu: cannot access `/data/8/dfs/dn/current/BP-1018136951-49.4.167.110-1403564146510/current/finalized/subdir46/subdir70/blk_1093551747': Input/output error\ndu: cannot access `/data/8/dfs/dn/current/BP-1018136951-49.4.167.110-1403564146510/current/finalized/subdir46/subdir70/blk_1093551747_19819134.meta': Inpu\nt/output error\ndu: cannot access `/data/8/dfs/dn/current/BP-1018136951-49.4.167.110-1403564146510/current/finalized/subdir46/subdir68/blk_1093551249_19818632.meta': Inpu\nt/output error\ndu: cannot access `/data/8/dfs/dn/current/BP-1018136951-49.4.167.110-1403564146510/current/finalized/subdir46/subdir68/blk_1093551249': Input/output error\n\n        at org.apache.hadoop.util.Shell.runCommand(Shell.java:538)\n        at org.apache.hadoop.util.Shell.run(Shell.java:455)\n        at org.apache.hadoop.fs.DU.run(DU.java:190)\n        at org.apache.hadoop.fs.DU.<init>(DU.java:70)\n        at org.apache.hadoop.fs.DU.<init>(DU.java:95)\n        at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice.<init>(BlockPoolSlice.java:116)\n        at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImpl.addBlockPool(FsVolumeImpl.java:284)\n        at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeList$2.run(FsVolumeList.java:247)\n\n*At this point, DN will attempt to handshake with NN again, only to find the disk is being used due to lock file:*\n\n2016-02-18 02:23:36,238 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory [DISK]file:/data/1/dfs/dn/ has already been used.\n2016-02-18 02:23:36,273 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1018136951-49.4.167.110-1403564146510\n2016-02-18 02:23:36,273 WARN org.apache.hadoop.hdfs.server.common.Storage: Failed to analyze storage directories for block pool BP-1018136951-49.4.167.110-1403564146510\njava.io.IOException: BlockPoolSliceStorage.recoverTransitionRead: attempt to load an used block storage: /data/1/dfs/dn/current/BP-1018136951-49.4.167.110-1403564146510\n        at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.loadBpStorageDirectories(BlockPoolSliceStorage.java:210)\n        at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.recoverTransitionRead(BlockPoolSliceStorage.java:242)\n        at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:391)\n        at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:472)\n        at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1322)\n        at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1292)\n        at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:320)\n        at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:225)\n        at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:862)\n        at java.lang.Thread.run(Thread.java:745)\n\n*Finally, it will think all disks are being used, and can't successfully perform the second handshake:*\n2016-02-18 02:23:36,558 FATAL org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool <registering> (Datanode Uuid unassigned) service to namenode1.weichiu.com/10.107.162.120:8022. Exiting.\njava.io.IOException: All specified directories are failed to load.\n        at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:473)\n        at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1322)\n        at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1292)\n        at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:320)\n        at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:225)\n        at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:862)\n        at java.lang.Thread.run(Thread.java:745)\n2016-02-18 02:23:36,559 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool ID needed, but service not yet registered with NN","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-03-04T21:02:59.157+0000","updated":"2016-03-04T21:02:59.157+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12947082/comment/15185308","id":"15185308","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"body":"Here I show a test case that demonstrates how it fails.\n\nSince it's hard to simulate a shell command error, I added a simulation flag in DU which throws a fake exception if the flag is true. This test case turns on the flag in order to trigger the exception, and with the flag turned on, the DN is unable to handshake successfully with NN, despite it is configured to tolerate 1 volume failure.\n\nPlease let me know if there are better ways to simulate a shell command error returned by du command.\n\nNext step, I'll catch the exception, and handle DU exceptions like {{BlockPoolSlice#checkDirs}}.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-03-08T17:29:18.952+0000","updated":"2016-03-08T17:29:18.952+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12947082/comment/15185913","id":"15185913","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"body":"Rev02:\nA quick and dirty fix for this issue. The new test case passed locally.\nWork in progress. Will need more efforts to make sure it works well in other scenarios.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-03-08T21:58:52.770+0000","updated":"2016-03-08T21:58:52.770+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12947082/comment/15206796","id":"15206796","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"body":"Rev03: be more conservative. Only remove those storage volume that returns \"Input/output error\". Many reasons can cause DU to return error, and the only thing I am more certain is Input/output error.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-03-22T17:07:04.756+0000","updated":"2016-03-22T17:07:04.756+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12947082/comment/15207106","id":"15207106","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=eddyxu","name":"eddyxu","key":"eddyxu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Lei (Eddy) Xu","active":true,"timeZone":"America/Los_Angeles"},"body":"Hey, [~jojochuang] Thanks for working on this.\n\n{code}\nif (true) {\n    throw new IOException(\"blah\");\n}\n{code}\n\nIt seems to only be your debug code?  Could you remove it from the patch.\n\n{code}\nif (!unhealthyDataDirs.isEmpty()) {\n   throw new DU.DiskUsageException(unhealthyDataDirs);\n}\n{code}\nI think that not all {{IOE}}s are DU related?  Throwing a {{DiskUsageException}} here might be confused.\n\nAbout {{handleDiskUsageError()}}, what if there are {{IOE}} that are not from DU? Should it throw these exceptions?\n\n{code}\n try {\n1545\t        // Remove all unhealthy volumes from DataNode.\n1546\t        removeVolumes(removalCandidates, false);\n1547\t      } catch (IOException e) {\n1548\t        LOG.warn(\"Error occurred when removing unhealthy storage dirs: \"\n1549\t            + e.getMessage(), e);\n1550\t      }\n{code}\n\nIf an {{IOE}} is thrown on this volume, is the metadata of the blocks on this volume still in memory? If so, can you add some comments.\n\n{code}\nimport org.apache.hadoop.fs.*;\n{code}\nPlease do not use wild card here. You can modify your IDE's preferences to prevent it.\n\n{code}\nprivate static boolean simulateDiskError;\n{code}\nIf possible, it'd be better to not use {{static}} member for tests. If there is anything happened before you reset the flag, other tests  will mistakenly see this flag as enabled.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=eddyxu","name":"eddyxu","key":"eddyxu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Lei (Eddy) Xu","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-03-22T19:32:40.418+0000","updated":"2016-03-22T19:32:40.418+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12947082/comment/15207329","id":"15207329","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 10s {color} | {color:blue} Docker mode activated. {color} |\n| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green} 0m 0s {color} | {color:green} The patch appears to include 1 new or modified test files. {color} |\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue} 0m 14s {color} | {color:blue} Maven dependency ordering for branch {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 6m 42s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 6m 1s {color} | {color:green} trunk passed with JDK v1.8.0_74 {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 6m 43s {color} | {color:green} trunk passed with JDK v1.7.0_95 {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 1m 6s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 46s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 27s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 3m 25s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 57s {color} | {color:green} trunk passed with JDK v1.8.0_74 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 2m 49s {color} | {color:green} trunk passed with JDK v1.7.0_95 {color} |\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue} 0m 13s {color} | {color:blue} Maven dependency ordering for patch {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 1m 27s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 6m 0s {color} | {color:green} the patch passed with JDK v1.8.0_74 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 6m 0s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 6m 40s {color} | {color:green} the patch passed with JDK v1.7.0_95 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 6m 40s {color} | {color:green} the patch passed {color} |\n| {color:red}-1{color} | {color:red} checkstyle {color} | {color:red} 1m 7s {color} | {color:red} root: patch generated 1 new + 214 unchanged - 0 fixed = 215 total (was 214) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 46s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 27s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green} 0m 0s {color} | {color:green} Patch has no whitespace issues. {color} |\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red} 1m 50s {color} | {color:red} hadoop-common-project/hadoop-common generated 13 new + 0 unchanged - 0 fixed = 13 total (was 0) {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 59s {color} | {color:green} the patch passed with JDK v1.8.0_74 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 2m 50s {color} | {color:green} the patch passed with JDK v1.7.0_95 {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 20m 57s {color} | {color:red} hadoop-common in the patch failed with JDK v1.8.0_74. {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 56m 27s {color} | {color:red} hadoop-hdfs in the patch failed with JDK v1.8.0_74. {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 7m 24s {color} | {color:red} hadoop-common in the patch failed with JDK v1.7.0_95. {color} |\n| {color:green}+1{color} | {color:green} unit {color} | {color:green} 55m 24s {color} | {color:green} hadoop-hdfs in the patch passed with JDK v1.7.0_95. {color} |\n| {color:red}-1{color} | {color:red} asflicense {color} | {color:red} 0m 26s {color} | {color:red} Patch generated 2 ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black} 199m 49s {color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| FindBugs | module:hadoop-common-project/hadoop-common |\n|  |  Dead store to emptyResults in org.apache.hadoop.security.LdapGroupsMapping.getGroups(String)  At LdapGroupsMapping.java:org.apache.hadoop.security.LdapGroupsMapping.getGroups(String)  At LdapGroupsMapping.java:[line 214] |\n|  |  Inconsistent synchronization of org.apache.hadoop.security.LdapGroupsMapping.bindPassword; locked 75% of time  Unsynchronized access at LdapGroupsMapping.java:75% of time  Unsynchronized access at LdapGroupsMapping.java:[line 323] |\n|  |  Inconsistent synchronization of org.apache.hadoop.security.LdapGroupsMapping.bindUser; locked 50% of time  Unsynchronized access at LdapGroupsMapping.java:50% of time  Unsynchronized access at LdapGroupsMapping.java:[line 322] |\n|  |  Inconsistent synchronization of org.apache.hadoop.security.LdapGroupsMapping.groupNameAttr; locked 66% of time  Unsynchronized access at LdapGroupsMapping.java:66% of time  Unsynchronized access at LdapGroupsMapping.java:[line 297] |\n|  |  Inconsistent synchronization of org.apache.hadoop.security.LdapGroupsMapping.groupSearchFilter; locked 50% of time  Unsynchronized access at LdapGroupsMapping.java:50% of time  Unsynchronized access at LdapGroupsMapping.java:[line 288] |\n|  |  Inconsistent synchronization of org.apache.hadoop.security.LdapGroupsMapping.isPosix; locked 50% of time  Unsynchronized access at LdapGroupsMapping.java:50% of time  Unsynchronized access at LdapGroupsMapping.java:[line 268] |\n|  |  Inconsistent synchronization of org.apache.hadoop.security.LdapGroupsMapping.keystore; locked 50% of time  Unsynchronized access at LdapGroupsMapping.java:50% of time  Unsynchronized access at LdapGroupsMapping.java:[line 318] |\n|  |  Inconsistent synchronization of org.apache.hadoop.security.LdapGroupsMapping.keystorePass; locked 75% of time  Unsynchronized access at LdapGroupsMapping.java:75% of time  Unsynchronized access at LdapGroupsMapping.java:[line 319] |\n|  |  Inconsistent synchronization of org.apache.hadoop.security.LdapGroupsMapping.ldapUrl; locked 75% of time  Unsynchronized access at LdapGroupsMapping.java:75% of time  Unsynchronized access at LdapGroupsMapping.java:[line 312] |\n|  |  Inconsistent synchronization of org.apache.hadoop.security.LdapGroupsMapping.posixGidAttr; locked 50% of time  Unsynchronized access at LdapGroupsMapping.java:50% of time  Unsynchronized access at LdapGroupsMapping.java:[line 271] |\n|  |  Inconsistent synchronization of org.apache.hadoop.security.LdapGroupsMapping.posixUidAttr; locked 66% of time  Unsynchronized access at LdapGroupsMapping.java:66% of time  Unsynchronized access at LdapGroupsMapping.java:[line 272] |\n|  |  Inconsistent synchronization of org.apache.hadoop.security.LdapGroupsMapping.useSsl; locked 50% of time  Unsynchronized access at LdapGroupsMapping.java:50% of time  Unsynchronized access at LdapGroupsMapping.java:[line 316] |\n|  |  Inconsistent synchronization of org.apache.hadoop.security.LdapGroupsMapping.userSearchFilter; locked 66% of time  Unsynchronized access at LdapGroupsMapping.java:66% of time  Unsynchronized access at LdapGroupsMapping.java:[line 258] |\n| JDK v1.8.0_74 Failed junit tests | hadoop.security.TestLdapGroupsMappingWithPosixGroup |\n|   | hadoop.net.TestDNS |\n|   | hadoop.security.TestLdapGroupsMapping |\n|   | hadoop.hdfs.shortcircuit.TestShortCircuitCache |\n|   | hadoop.hdfs.server.namenode.TestEditLog |\n|   | hadoop.hdfs.server.datanode.fsdataset.impl.TestLazyPersistReplicaRecovery |\n|   | hadoop.hdfs.TestFileAppend |\n| JDK v1.8.0_74 Timed out junit tests | org.apache.hadoop.util.TestNativeLibraryChecker |\n|   | org.apache.hadoop.http.TestHttpServerLifecycle |\n| JDK v1.7.0_95 Failed junit tests | hadoop.security.TestLdapGroupsMappingWithPosixGroup |\n|   | hadoop.security.TestLdapGroupsMapping |\n| JDK v1.7.0_95 Timed out junit tests | org.apache.hadoop.util.TestNativeLibraryChecker |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:fbe3e86 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12794795/HDFS-9908.003.patch |\n| JIRA Issue | HDFS-9908 |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux 5569b62de057 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / e7ed05e |\n| Default Java | 1.7.0_95 |\n| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_74 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_95 |\n| findbugs | v3.0.0 |\n| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/14895/artifact/patchprocess/diff-checkstyle-root.txt |\n| findbugs | https://builds.apache.org/job/PreCommit-HDFS-Build/14895/artifact/patchprocess/new-findbugs-hadoop-common-project_hadoop-common.html |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/14895/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.8.0_74.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/14895/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.8.0_74.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/14895/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.7.0_95.txt |\n| unit test logs |  https://builds.apache.org/job/PreCommit-HDFS-Build/14895/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.8.0_74.txt https://builds.apache.org/job/PreCommit-HDFS-Build/14895/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.8.0_74.txt https://builds.apache.org/job/PreCommit-HDFS-Build/14895/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.7.0_95.txt |\n| JDK v1.7.0_95  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/14895/testReport/ |\n| asflicense | https://builds.apache.org/job/PreCommit-HDFS-Build/14895/artifact/patchprocess/patch-asflicense-problems.txt |\n| modules | C:  hadoop-common-project/hadoop-common   hadoop-hdfs-project/hadoop-hdfs  U: . |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/14895/console |\n| Powered by | Apache Yetus 0.2.0   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2016-03-22T21:13:05.507+0000","updated":"2016-03-22T21:13:05.507+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12947082/comment/15210476","id":"15210476","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks for Eddy's comments:\nAttached rev04 to address Eddy's comments.\n\n{quote}\nI think that not all IOE}}s are DU related? Throwing a {{DiskUsageException here might be confused.\n{quote}\nWhat about if I change the exception name to AddBlockPoolException? It sounds more accurate to me.\n{quote}\nAbout handleDiskUsageError(), what if there are IOE that are not from DU? Should it throw these exceptions?\n{quote}\nThis is to keep the existing behavior: pop up exceptions to callers, whether or not they come from DU. The idea is  only process the exception when it happens to be during handshake, and to reduce the side effect to other callers of volume scanner. I am not sure if people prefer to keep the it as is, or do something differently.\n\n{quote}\nIf an IOE is thrown on this volume, is the metadata of the blocks on this volume still in memory? If so, can you add some comments.\n{quote}\nI'm not quite sure about this question. Do you mean the metadata of the blocks at NameNode? I think the answer is yes, because this is unrelated to NameNode. But a du input/output error can mean any files in the volume, and this includes the block, finalized, rbw and maybe others as well.\n\n{quote}\nIf possible, it'd be better to not use static member for tests. If there is anything happened before you reset the flag, other tests will mistakenly see this flag as enabled.\n{quote}\nI've updated the code to pass the test info in a Configuration object. Thanks a lot for the advice!","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-03-24T16:15:42.313+0000","updated":"2016-03-24T16:15:42.313+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12947082/comment/15210976","id":"15210976","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 21s {color} | {color:blue} Docker mode activated. {color} |\n| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green} 0m 0s {color} | {color:green} The patch appears to include 2 new or modified test files. {color} |\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue} 0m 20s {color} | {color:blue} Maven dependency ordering for branch {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 9m 33s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 12m 5s {color} | {color:green} trunk passed with JDK v1.8.0_74 {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 10m 9s {color} | {color:green} trunk passed with JDK v1.7.0_95 {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 1m 28s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 2m 33s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 42s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 4m 31s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 3m 5s {color} | {color:green} trunk passed with JDK v1.8.0_74 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 4m 8s {color} | {color:green} trunk passed with JDK v1.7.0_95 {color} |\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue} 0m 19s {color} | {color:blue} Maven dependency ordering for patch {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 2m 5s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 11m 45s {color} | {color:green} the patch passed with JDK v1.8.0_74 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 11m 45s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 10m 8s {color} | {color:green} the patch passed with JDK v1.7.0_95 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 10m 8s {color} | {color:green} the patch passed {color} |\n| {color:red}-1{color} | {color:red} checkstyle {color} | {color:red} 1m 29s {color} | {color:red} root: patch generated 10 new + 180 unchanged - 0 fixed = 190 total (was 180) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 2m 32s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 43s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green} 0m 0s {color} | {color:green} Patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 5m 15s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 3m 6s {color} | {color:green} the patch passed with JDK v1.8.0_74 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 4m 15s {color} | {color:green} the patch passed with JDK v1.7.0_95 {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 10m 40s {color} | {color:red} hadoop-common in the patch failed with JDK v1.8.0_74. {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 76m 47s {color} | {color:red} hadoop-hdfs in the patch failed with JDK v1.8.0_74. {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 10m 18s {color} | {color:red} hadoop-common in the patch failed with JDK v1.7.0_95. {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 75m 40s {color} | {color:red} hadoop-hdfs in the patch failed with JDK v1.7.0_95. {color} |\n| {color:red}-1{color} | {color:red} asflicense {color} | {color:red} 0m 49s {color} | {color:red} Patch generated 2 ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black} 266m 56s {color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| JDK v1.8.0_74 Failed junit tests | hadoop.ipc.TestRPCWaitForProxy |\n|   | hadoop.net.TestDNS |\n|   | hadoop.hdfs.shortcircuit.TestShortCircuitCache |\n|   | hadoop.hdfs.server.datanode.TestDirectoryScanner |\n|   | hadoop.hdfs.server.namenode.TestEditLog |\n|   | hadoop.hdfs.server.datanode.TestDataNodeUUID |\n|   | hadoop.hdfs.security.TestDelegationTokenForProxyUser |\n| JDK v1.8.0_74 Timed out junit tests | org.apache.hadoop.util.TestNativeLibraryChecker |\n|   | org.apache.hadoop.hdfs.TestFileAppend3 |\n|   | org.apache.hadoop.hdfs.server.balancer.TestBalancer |\n|   | org.apache.hadoop.hdfs.TestReadStripedFileWithDecoding |\n|   | org.apache.hadoop.hdfs.TestFileConcurrentReader |\n| JDK v1.7.0_95 Failed junit tests | hadoop.net.TestDNS |\n|   | hadoop.hdfs.server.datanode.TestDirectoryScanner |\n|   | hadoop.hdfs.server.namenode.TestNameNodeMetadataConsistency |\n|   | hadoop.hdfs.TestDistributedFileSystem |\n|   | hadoop.hdfs.security.TestDelegationTokenForProxyUser |\n|   | hadoop.hdfs.server.namenode.ha.TestDFSUpgradeWithHA |\n|   | hadoop.hdfs.server.namenode.TestNamenodeCapacityReport |\n|   | hadoop.hdfs.server.datanode.TestDataNodeHotSwapVolumes |\n|   | hadoop.hdfs.server.namenode.ha.TestBootstrapStandbyWithQJM |\n| JDK v1.7.0_95 Timed out junit tests | org.apache.hadoop.util.TestNativeLibraryChecker |\n|   | org.apache.hadoop.hdfs.TestDFSStorageStateRecovery |\n|   | org.apache.hadoop.hdfs.TestRestartDFS |\n|   | org.apache.hadoop.hdfs.TestRenameWhileOpen |\n|   | org.apache.hadoop.hdfs.TestDataTransferProtocol |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:fbe3e86 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12795234/HDFS-9908.004.patch |\n| JIRA Issue | HDFS-9908 |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux 19c5a0c40d13 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / b1394d6 |\n| Default Java | 1.7.0_95 |\n| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_74 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_95 |\n| findbugs | v3.0.0 |\n| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/14925/artifact/patchprocess/diff-checkstyle-root.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/14925/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.8.0_74.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/14925/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.8.0_74.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/14925/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.7.0_95.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/14925/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.7.0_95.txt |\n| unit test logs |  https://builds.apache.org/job/PreCommit-HDFS-Build/14925/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.8.0_74.txt https://builds.apache.org/job/PreCommit-HDFS-Build/14925/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.8.0_74.txt https://builds.apache.org/job/PreCommit-HDFS-Build/14925/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.7.0_95.txt https://builds.apache.org/job/PreCommit-HDFS-Build/14925/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.7.0_95.txt |\n| JDK v1.7.0_95  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/14925/testReport/ |\n| asflicense | https://builds.apache.org/job/PreCommit-HDFS-Build/14925/artifact/patchprocess/patch-asflicense-problems.txt |\n| modules | C:  hadoop-common-project/hadoop-common   hadoop-hdfs-project/hadoop-hdfs  U: . |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/14925/console |\n| Powered by | Apache Yetus 0.2.0   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2016-03-24T21:22:27.525+0000","updated":"2016-03-24T21:22:27.525+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12947082/comment/15211762","id":"15211762","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"body":"Rev05. Not very sure why there are test failures. These tests ran fine in my local environment. Attached a new patch to fix checkstyle warnings.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-03-25T12:28:23.529+0000","updated":"2016-03-25T12:28:23.529+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12947082/comment/15212194","id":"15212194","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 20s {color} | {color:blue} Docker mode activated. {color} |\n| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green} 0m 0s {color} | {color:green} The patch appears to include 2 new or modified test files. {color} |\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue} 0m 21s {color} | {color:blue} Maven dependency ordering for branch {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 9m 39s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 11m 58s {color} | {color:green} trunk passed with JDK v1.8.0_74 {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 10m 15s {color} | {color:green} trunk passed with JDK v1.7.0_95 {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 1m 28s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 2m 32s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 44s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 4m 38s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 3m 4s {color} | {color:green} trunk passed with JDK v1.8.0_74 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 4m 13s {color} | {color:green} trunk passed with JDK v1.7.0_95 {color} |\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue} 0m 19s {color} | {color:blue} Maven dependency ordering for patch {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 2m 2s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 11m 46s {color} | {color:green} the patch passed with JDK v1.8.0_74 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 11m 46s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 10m 9s {color} | {color:green} the patch passed with JDK v1.7.0_95 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 10m 9s {color} | {color:green} the patch passed {color} |\n| {color:red}-1{color} | {color:red} checkstyle {color} | {color:red} 1m 30s {color} | {color:red} root: patch generated 1 new + 180 unchanged - 0 fixed = 181 total (was 180) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 2m 31s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 41s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green} 0m 0s {color} | {color:green} Patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 5m 11s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 3m 8s {color} | {color:green} the patch passed with JDK v1.8.0_74 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 4m 8s {color} | {color:green} the patch passed with JDK v1.7.0_95 {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 10m 39s {color} | {color:red} hadoop-common in the patch failed with JDK v1.8.0_74. {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 78m 16s {color} | {color:red} hadoop-hdfs in the patch failed with JDK v1.8.0_74. {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 10m 31s {color} | {color:red} hadoop-common in the patch failed with JDK v1.7.0_95. {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 93m 16s {color} | {color:red} hadoop-hdfs in the patch failed with JDK v1.7.0_95. {color} |\n| {color:red}-1{color} | {color:red} asflicense {color} | {color:red} 0m 38s {color} | {color:red} Patch generated 2 ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black} 286m 6s {color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| JDK v1.8.0_74 Failed junit tests | hadoop.ipc.TestRPCWaitForProxy |\n|   | hadoop.fs.shell.find.TestIname |\n|   | hadoop.fs.shell.find.TestPrint0 |\n|   | hadoop.fs.shell.find.TestName |\n|   | hadoop.hdfs.server.datanode.TestDirectoryScanner |\n|   | hadoop.hdfs.server.namenode.TestEditLog |\n|   | hadoop.hdfs.server.datanode.TestDataNodeUUID |\n|   | hadoop.hdfs.server.datanode.TestDataNodeMultipleRegistrations |\n|   | hadoop.hdfs.security.TestDelegationTokenForProxyUser |\n|   | hadoop.hdfs.TestFileAppend |\n|   | hadoop.hdfs.TestBlockStoragePolicy |\n| JDK v1.8.0_74 Timed out junit tests | org.apache.hadoop.util.TestNativeLibraryChecker |\n|   | org.apache.hadoop.hdfs.TestFileAppend3 |\n|   | org.apache.hadoop.hdfs.server.balancer.TestBalancer |\n|   | org.apache.hadoop.hdfs.TestReadStripedFileWithDecoding |\n|   | org.apache.hadoop.hdfs.TestFileConcurrentReader |\n| JDK v1.7.0_95 Failed junit tests | hadoop.hdfs.server.datanode.TestDirectoryScanner |\n|   | hadoop.hdfs.server.namenode.ha.TestHAAppend |\n|   | hadoop.hdfs.qjournal.TestSecureNNWithQJM |\n| JDK v1.7.0_95 Timed out junit tests | org.apache.hadoop.util.TestNativeLibraryChecker |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:fbe3e86 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12795408/HDFS-9908.005.patch |\n| JIRA Issue | HDFS-9908 |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux 9f10555000e7 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / 2c268cc |\n| Default Java | 1.7.0_95 |\n| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_74 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_95 |\n| findbugs | v3.0.0 |\n| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/14940/artifact/patchprocess/diff-checkstyle-root.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/14940/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.8.0_74.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/14940/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.8.0_74.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/14940/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.7.0_95.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/14940/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.7.0_95.txt |\n| unit test logs |  https://builds.apache.org/job/PreCommit-HDFS-Build/14940/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.8.0_74.txt https://builds.apache.org/job/PreCommit-HDFS-Build/14940/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.8.0_74.txt https://builds.apache.org/job/PreCommit-HDFS-Build/14940/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.7.0_95.txt https://builds.apache.org/job/PreCommit-HDFS-Build/14940/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.7.0_95.txt |\n| JDK v1.7.0_95  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/14940/testReport/ |\n| asflicense | https://builds.apache.org/job/PreCommit-HDFS-Build/14940/artifact/patchprocess/patch-asflicense-problems.txt |\n| modules | C:  hadoop-common-project/hadoop-common   hadoop-hdfs-project/hadoop-hdfs  U: . |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/14940/console |\n| Powered by | Apache Yetus 0.2.0   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2016-03-25T18:16:36.001+0000","updated":"2016-03-25T18:16:36.001+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12947082/comment/15212469","id":"15212469","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=eddyxu","name":"eddyxu","key":"eddyxu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Lei (Eddy) Xu","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks a lot for updating the patch, [~jojochuang].\n\nOne qq in {{handleAddBlockError()}}, should we throw the {{IOE}} if {{removeCandidates.size() < unhealthyDataDirs.size()}}.\n\nThe rest LTGM.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=eddyxu","name":"eddyxu","key":"eddyxu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Lei (Eddy) Xu","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-03-25T21:56:00.691+0000","updated":"2016-03-25T21:56:00.691+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12947082/comment/15214323","id":"15214323","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"body":"[~eddyxu] thanks for the comments.\nIf we throw the IOE in that case, that means other disk corruption error might also fail NN handshake. (there are a few places in {{BlockPoolSlice#(constructor)}} where it throw IOException if it fails to create directories.\n\nOn the other hand, I think it would be inappropriate to ignore these failures. If we do not have a consistent failure tolerance mechanism in place, I agree throwing an IOException seems to be a slightly better approach.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-03-28T15:28:12.574+0000","updated":"2016-03-28T15:28:12.574+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12947082/comment/15214328","id":"15214328","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"body":"Rev06: rethrow exception if any of the IOE caught in {{FsVolumeList#addBlockPool}} is not a du input/utput error, making sure that any potentially important error is exposed, rather than ignored.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-03-28T15:31:07.178+0000","updated":"2016-03-28T15:31:07.178+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12947082/comment/15218640","id":"15218640","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"body":"Post the patch again. For some reason precommit validation was not triggered. v06 and v07 are the same.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-03-30T19:17:05.312+0000","updated":"2016-03-30T19:17:05.312+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12947082/comment/15219013","id":"15219013","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 17s {color} | {color:blue} Docker mode activated. {color} |\n| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green} 0m 0s {color} | {color:green} The patch appears to include 2 new or modified test files. {color} |\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue} 0m 15s {color} | {color:blue} Maven dependency ordering for branch {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 6m 54s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 6m 3s {color} | {color:green} trunk passed with JDK v1.8.0_74 {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 6m 53s {color} | {color:green} trunk passed with JDK v1.7.0_95 {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 1m 6s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 46s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 28s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 3m 28s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 59s {color} | {color:green} trunk passed with JDK v1.8.0_74 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 2m 49s {color} | {color:green} trunk passed with JDK v1.7.0_95 {color} |\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue} 0m 15s {color} | {color:blue} Maven dependency ordering for patch {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 1m 27s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 5m 37s {color} | {color:green} the patch passed with JDK v1.8.0_74 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 5m 37s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 6m 36s {color} | {color:green} the patch passed with JDK v1.7.0_95 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 6m 36s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 1m 5s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 46s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 29s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green} 0m 0s {color} | {color:green} Patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 3m 57s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 59s {color} | {color:green} the patch passed with JDK v1.8.0_74 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 2m 55s {color} | {color:green} the patch passed with JDK v1.7.0_95 {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 6m 48s {color} | {color:red} hadoop-common in the patch failed with JDK v1.8.0_74. {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 69m 16s {color} | {color:red} hadoop-hdfs in the patch failed with JDK v1.8.0_74. {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 6m 53s {color} | {color:red} hadoop-common in the patch failed with JDK v1.7.0_95. {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 72m 8s {color} | {color:red} hadoop-hdfs in the patch failed with JDK v1.7.0_95. {color} |\n| {color:red}-1{color} | {color:red} asflicense {color} | {color:red} 0m 27s {color} | {color:red} Patch generated 3 ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black} 215m 5s {color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| JDK v1.8.0_74 Failed junit tests | hadoop.hdfs.server.datanode.TestDataNodeMetrics |\n|   | hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot |\n|   | hadoop.hdfs.TestDFSUpgradeFromImage |\n| JDK v1.8.0_74 Timed out junit tests | org.apache.hadoop.util.TestNativeLibraryChecker |\n| JDK v1.7.0_95 Failed junit tests | hadoop.hdfs.TestHFlush |\n|   | hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot |\n| JDK v1.7.0_95 Timed out junit tests | org.apache.hadoop.util.TestNativeLibraryChecker |\n|   | org.apache.hadoop.hdfs.TestLeaseRecovery2 |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:fbe3e86 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12796140/HDFS-9908.007.patch |\n| JIRA Issue | HDFS-9908 |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux 2df70faf93fc 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / 09d63d5 |\n| Default Java | 1.7.0_95 |\n| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_74 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_95 |\n| findbugs | v3.0.0 |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/15005/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.8.0_74.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/15005/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.8.0_74.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/15005/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.7.0_95.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/15005/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.7.0_95.txt |\n| unit test logs |  https://builds.apache.org/job/PreCommit-HDFS-Build/15005/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.8.0_74.txt https://builds.apache.org/job/PreCommit-HDFS-Build/15005/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.8.0_74.txt https://builds.apache.org/job/PreCommit-HDFS-Build/15005/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.7.0_95.txt https://builds.apache.org/job/PreCommit-HDFS-Build/15005/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.7.0_95.txt |\n| JDK v1.7.0_95  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/15005/testReport/ |\n| asflicense | https://builds.apache.org/job/PreCommit-HDFS-Build/15005/artifact/patchprocess/patch-asflicense-problems.txt |\n| modules | C:  hadoop-common-project/hadoop-common   hadoop-hdfs-project/hadoop-hdfs  U: . |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/15005/console |\n| Powered by | Apache Yetus 0.2.0   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2016-03-30T22:56:37.555+0000","updated":"2016-03-30T22:56:37.555+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12947082/comment/15281774","id":"15281774","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"body":"Need to rebase due to HADOOP-12973.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-05-12T17:19:07.710+0000","updated":"2016-05-12T17:19:07.710+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12947082/comment/15292208","id":"15292208","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"body":"Interestingly, after HADOOP-12973, the exception thrown by du will be caught and logged. That is to say, NN handshake will not be disrupt by this exception.\n\n{code}\n@Override\n  protected synchronized void refresh() {\n    if (duShell == null) {\n      duShell = new DUShell();\n    }\n    try {\n      duShell.startRefresh();\n    } catch (IOException ioe) {\n      LOG.warn(\"Could not get disk usage information\", ioe);\n    }\n  }\n{code}\n\nHiding a potential disk error in the log may not be the best option, IMO.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-05-19T21:44:55.245+0000","updated":"2016-05-19T21:44:55.245+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12947082/comment/15307900","id":"15307900","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"body":"This patch no longer applies after the DU refactoring.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-05-31T15:19:07.206+0000","updated":"2016-05-31T15:19:07.206+0000"}],"maxResults":18,"total":18,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-9908/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i2u6bj:"}}