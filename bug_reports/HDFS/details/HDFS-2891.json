{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12541178","self":"https://issues.apache.org/jira/rest/api/2/issue/12541178","key":"HDFS-2891","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":"2012-04-01T09:24:34.622+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Sun Apr 01 12:02:27 UTC 2012","customfield_12310420":"226530","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-2891/watchers","watchCount":7,"isWatching":false},"created":"2012-02-04T09:23:54.676+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12317959","id":"12317959","description":"1.1.0 release","name":"1.1.0","archived":false,"released":true,"releaseDate":"2012-10-13"}],"issuelinks":[],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2012-04-01T12:02:27.484+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12312927","id":"12312927","name":"datanode"},{"self":"https://issues.apache.org/jira/rest/api/2/component/12312928","id":"12312928","name":"hdfs-client"}],"timeoriginalestimate":null,"description":"In one of my clusters, observed this situation.\nThis issue looks to be due to time out in ResponseProcesser at client side, it is marking first DataNode as bad.\nThis happens in 20.2 version. This can be there in branch-1 as well and will check for trunk.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"114022","customfield_12312823":null,"summary":"Some times first DataNode detected as bad when we power off for the second DataNode.","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12541178/comment/13200372","id":"13200372","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"body":"\nMore info:\n\nThis happens when we test with Hbase.\nRun the HDFS and HBase cluster normally, and Suddenly Power-off the mid Datanode from the pipeline.\nThen Clinet was getting following exception.\n\n{noformat}\n[2012-01-31 11:15:42,596] [WARN ] [ResponseProcessor for block blk_1327946241860_1109] [org.apache.hadoop.hdfs.DFSClient 3287] DFSOutputStream ResponseProcessor exception for block blk_1327946241860_1109java.net.SocketTimeoutException: 69000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/XXX:59179 remote=/FIRST_DATANODE_IP:10010]\n\tat org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:167)\n\tat org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:155)\n\tat org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:128)\n\tat java.io.DataInputStream.readFully(DataInputStream.java:178)\n\tat java.io.DataInputStream.readLong(DataInputStream.java:399)\n\tat org.apache.hadoop.hdfs.protocol.DataTransferProtocol$PipelineAck.readFields(DataTransferProtocol.java:131)\n\tat org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$ResponseProcessor.run(DFSClient.java:3240)\n{noformat}\n\nAfter that client closed the connection and first Datanode was getting EOFException and interrupted the threads.\n\n{noformat}\n[2012-01-31 11:15:42,597] [INFO ] [org.apache.hadoop.hdfs.server.datanode.DataXceiver@3e909a58] [org.apache.hadoop.hdfs.server.datanode.DataNode 816] Exception in receiveBlock for block blk_1327946241860_1109\njava.io.EOFException: while trying to read 31744 bytes\n\tat org.apache.hadoop.hdfs.server.datanode.BlockReceiver.readToBuf(BlockReceiver.java:352)\n\tat org.apache.hadoop.hdfs.server.datanode.BlockReceiver.readNextPacket(BlockReceiver.java:399)\n\tat org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:611)\n\tat org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:781)\n\tat org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:514)\n\tat org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:138)\n\tat java.lang.Thread.run(Thread.java:662)\n[2012-01-31 11:15:42,598] [INFO ] [PacketResponder 2 for Block blk_1327946241860_1109] [org.apache.hadoop.hdfs.server.datanode.DataNode 1123] PacketResponder blk_1327946241860_1109 2 : Thread is interrupted.\n[2012-01-31 11:15:42,598] [INFO ] [PacketResponder 2 for Block blk_1327946241860_1109] [org.apache.hadoop.hdfs.server.datanode.DataNode 1194] PacketResponder 2 for block blk_1327946241860_1109 terminating\n{noformat}\n\nFinally Client is marking this first DataNode as bad.\n\n{noformat}\n[2012-01-31 11:15:42,597] [WARN ] [DataStreamer for file /hbase/.logs/DDB01,20020,1327946260020/DDB01%3A20020.1327978683479 block blk_1327946241860_1109] [org.apache.hadoop.hdfs.DFSClient 3326] Error Recovery for block blk_1327946241860_1109 bad datanode[0] FIRST_DATANODE_IP:10010\n[2012-01-31 11:15:42,597] [WARN ] [DataStreamer for file /hbase/.logs/DDB01,20020,1327946260020/DDB01%3A20020.1327978683479 block blk_1327946241860_1109] [org.apache.hadoop.hdfs.DFSClient 3380] Error Recovery for block blk_1327946241860_1109 in pipeline FIRST_DATANODE_IP:10010, SECOND_DATANODE_IP:10010, THIRD_DATANODE_IP:10010: bad datanode FIRST_DATANODE_IP:10010\n[2012-01-31 11:15:46,607] [INFO ] [DataStreamer for file /hbase/.logs/DDB01,20020,1327946260020/DDB01%3A20020.1327978683479 block blk_1327946241860_1109] [org.apache.hadoop.ipc.Client 514] Retrying connect to server: /SECOND_DATANODE_IP:10020. Already tried 0 time(s).\n{noformat}\n\nInfact first datanode is healthy, but unportunately due to this timeouts clinet detected first datanode as bad. Then immediately it is trying with the second datanode( by choosing it as primary node).\n\nIdeally first Datanode should get first timeout because he will wait only 66000ms for ack response from second datanode(power off DN). Here clients waits for 69000ms. But for some reason Client is getting first time out exception that firstDatanode. So, first DN marked as bad instaed of second one.\n\nImpact is, Clinet again tries for the second datanode and obiously will fail again.It will 6 times unnecessarily it will retry. \n\n{noformat}\n2012-01-31 11:19:58,565] [WARN ] [DataStreamer for file /hbase/.logs/DDB01,20020,1327946260020/DDB01%3A20020.1327978683479 block blk_1327946241860_1109] [org.apache.hadoop.hdfs.DFSClient 3426] Error Recovery for block blk_1327946241860_1109 failed  because recovery from primary datanode SECOND_DATANODE_IP:10010 failed 6 times.  Pipeline was FIRST_DATANODE_IP:10010, SECOND_DATANODE_IP:10010, THIRD_DATANODE_IP:10010. Marking primary datanode as bad.\n{noformat}\n\nFinally it will end up in writing only one replica in third DataNode. But here we have two nodes healthy. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"created":"2012-02-04T09:58:33.830+0000","updated":"2012-02-04T09:58:33.830+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12541178/comment/13200373","id":"13200373","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"body":"Note: this is not happening very regularly.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"created":"2012-02-04T10:00:23.753+0000","updated":"2012-02-04T10:00:23.753+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12541178/comment/13243686","id":"13243686","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chaku88","name":"chaku88","key":"chaku88","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"chackaravarthy","active":true,"timeZone":"Asia/Kolkata"},"body":"Hi Uma,\n\nThis problem exists in branch-1.0 also.\n\n*This can happen in the following scenario :*\n{quote}\n1. consider the pipeline as [ DN1 -> DN2 -> DN3 ]\n2. create one file and get the stream.\n3. write some bytes using that stream and call sync.\n4. keep the stream open.\n5. Now unplug network / power-off / ethernet down in DN2 machine.\n{quote}\n\n*The explanation is as follows :*\n\n*Consider the case, when the caller is not writing any data and dataStreamer & ResponseProcessor threads are running And also DN2 machine ethernet down:*\n\n{quote}\n\t1. At *time t1* , ResponseProcessor will start reading the ack from DN1 [timeOut is 69 secs ]\n\n\t2. But in the DN1 , packetResponder not yet started reading the ack. It will be waiting on ackQueue until one packet arrives.\n\n\t3. After time *t1+34.5* secs only, dataStreamer will stream the HEART_BEAT packet to DN1. [if there is no data packet, DataStreamer will send HEART_BEAT packet after waiting for half of the timeout value]\n\n\t4. Then only, DataXceiver will receive the packet and will put it in ackQueue in DN side.\n\n\t5. At *time t2* , Once the ackQueue is enqueued, the packetResponder will start reading the ack from DN2. [timeOut is 66 secs]\n\n\t6. As DN2 machine ethernet is down, packetResponder in DN1 is not getting the reply.\n\n\t7. But packetResponder will get timeOut only after *t2+66* secs.\n\n\t8. Hence ResponseProcessor is getting socketTimeOutException earlier than PacketResponder.\n\n{quote}\n\n\t\t*t2 - t1 >= 34.5 secs*   [if its greater than 3 secs itself, the reported scenario can happen]\n\n\tSo, DFSClient is getting SocketTimeOutException before DN1.\n\tHence DFSClient is detecting DN1 as bad datanode [which is up] and not detecting DN2 as bad datanode [which is down]\n\n\n*Reason :*\n\nIn DataNode, the PacketResponder will start reading the ack only when it receives one packet [either data or heartbeat packet]\nBut In DFSClient, the ResponseProcessor will start reading the ack before sending packet.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chaku88","name":"chaku88","key":"chaku88","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"chackaravarthy","active":true,"timeZone":"Asia/Kolkata"},"created":"2012-04-01T09:24:34.622+0000","updated":"2012-04-01T09:24:34.622+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12541178/comment/13243703","id":"13243703","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi Chackara,\n\n Thanks a lot for working on this issue.\nSeems to be valid scenario. Do you want to upload a patch for this issue?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"created":"2012-04-01T12:02:27.420+0000","updated":"2012-04-01T12:02:27.420+0000"}],"maxResults":4,"total":4,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-2891/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i0jvfj:"}}