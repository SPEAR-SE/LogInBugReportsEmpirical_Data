{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"13097703","self":"https://issues.apache.org/jira/rest/api/2/issue/13097703","key":"HDFS-12357","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12334218","id":"12334218","description":"2.9.0 release","name":"2.9.0","archived":false,"released":true,"releaseDate":"2017-11-17"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12335737","id":"12335737","description":"3.0.0-beta1 release","name":"3.0.0-beta1","archived":false,"released":true,"releaseDate":"2017-10-03"}],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2017-08-28T08:27:35.364+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Fri Sep 08 00:46:19 UTC 2017","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_208169776_*|*_5_*:*_1_*:*_0_*|*_10002_*:*_1_*:*_917860160","customfield_12312321":null,"resolutiondate":"2017-09-07T21:27:54.614+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-12357/watchers","watchCount":7,"isWatching":false},"created":"2017-08-25T20:40:44.760+0000","customfield_12310192":null,"customfield_12310191":[{"self":"https://issues.apache.org/jira/rest/api/2/customFieldOption/10343","value":"Reviewed","id":"10343"}],"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"9.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[],"issuelinks":[{"id":"12512979","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12512979","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"13094298","key":"HDFS-12294","self":"https://issues.apache.org/jira/rest/api/2/issue/13094298","fields":{"summary":"Let distcp to bypass external attribute provider when calling getFileStatus etc at source cluster","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/4","id":"4","description":"An improvement or enhancement to an existing feature or task.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype","name":"Improvement","subtask":false,"avatarId":21140}}}},{"id":"12513245","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12513245","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"inwardIssue":{"id":"13090315","key":"HDFS-12202","self":"https://issues.apache.org/jira/rest/api/2/issue/13090315","fields":{"summary":"Provide new set of FileSystem API to bypass external attribute provider","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/2","id":"2","description":"A new feature of the product, which has yet to be developed.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype","name":"New Feature","subtask":false,"avatarId":21141}}}},{"id":"12514244","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12514244","type":{"id":"12310050","name":"Regression","inward":"is broken by","outward":"breaks","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/12310050"},"outwardIssue":{"id":"13100604","key":"HDFS-12404","self":"https://issues.apache.org/jira/rest/api/2/issue/13100604","fields":{"summary":"Rename hdfs config authorization.provider.bypass.users to attributes.provider.bypass.users","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2017-09-08T16:15:09.445+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[],"timeoriginalestimate":null,"description":"This is a third proposal to solve the problem described in HDFS-12202.\n\nThe problem is, when we do distcp from one cluster to another (or within the same cluster), in addition to copying file data, we copy the metadata from source to target. If external attribute provider is enabled, the metadata may be read from the provider, thus provider data read from source may be saved to target HDFS. \n\nWe want to avoid saving metadata from external provider to HDFS, so we want to bypass external provider when doing the distcp (or hadoop fs -cp) operation.\n\nTwo alternative approaches were proposed earlier, one in HDFS-12202, the other in HDFS-12294. The proposal here is the third one.\n\nThe idea is, we introduce a new config, that specifies a special user (or a list of users), and let NN bypass external provider when the current user is a special user.\n\nIf we run applications as the special user that need data from external attribute provider, then it won't work. So the constraint on this approach is, the special users here should not run applications that need data from external provider.\n\nThanks [~asuresh] for proposing this idea and [~chris.douglas], [~daryn], [~manojg] for the discussions in the other jiras. \n\nI'm creating this one to discuss further.\n\n\n","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12884001","id":"12884001","filename":"HDFS-12357.001.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-08-28T06:30:01.057+0000","size":9007,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12884001/HDFS-12357.001.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12885085","id":"12885085","filename":"HDFS-12357.001a.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-09-02T14:41:42.435+0000","size":9854,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12885085/HDFS-12357.001a.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12885094","id":"12885094","filename":"HDFS-12357.001b.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-09-02T18:05:53.773+0000","size":9836,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12885094/HDFS-12357.001b.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12884998","id":"12884998","filename":"HDFS-12357.002.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-09-01T18:45:09.504+0000","size":13319,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12884998/HDFS-12357.002.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12885031","id":"12885031","filename":"HDFS-12357.003.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-09-01T22:53:51.475+0000","size":12646,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12885031/HDFS-12357.003.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12885032","id":"12885032","filename":"HDFS-12357.004.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-09-01T22:56:42.097+0000","size":12041,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12885032/HDFS-12357.004.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12885045","id":"12885045","filename":"HDFS-12357.005.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-09-02T01:27:14.298+0000","size":13604,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12885045/HDFS-12357.005.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12885507","id":"12885507","filename":"HDFS-12357.006.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-09-06T02:58:01.203+0000","size":10206,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12885507/HDFS-12357.006.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12885747","id":"12885747","filename":"HDFS-12357.007.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-09-07T05:32:31.919+0000","size":13889,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12885747/HDFS-12357.007.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"Let NameNode to bypass external attribute provider for special user","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/13097703/comment/16143421","id":"16143421","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi [~asuresh], [~chris.douglas], [~daryn], [~manojg] and other folks who are interested,\n\nPosted a draft patch for further discussion.  If you could review and comment, it would be very much appreciated.\n\nThanks.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-08-28T06:32:25.262+0000","updated":"2017-08-28T06:32:25.262+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13097703/comment/16143514","id":"16143514","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 16s{color} | {color:blue} Docker mode activated. {color} |\n|| || || || {color:brown} Prechecks {color} ||\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |\n|| || || || {color:brown} trunk Compile Tests {color} ||\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 13m 59s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 47s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 43s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 53s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 41s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 40s{color} | {color:green} trunk passed {color} |\n|| || || || {color:brown} Patch Compile Tests {color} ||\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 48s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 44s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 44s{color} | {color:green} the patch passed {color} |\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 39s{color} | {color:orange} hadoop-hdfs-project/hadoop-hdfs: The patch generated 5 new + 465 unchanged - 0 fixed = 470 total (was 465) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 50s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  1s{color} | {color:green} The patch has no ill-formed XML file. {color} |\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  1m 48s{color} | {color:red} hadoop-hdfs-project/hadoop-hdfs generated 1 new + 0 unchanged - 0 fixed = 1 total (was 0) {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 37s{color} | {color:green} the patch passed {color} |\n|| || || || {color:brown} Other Tests {color} ||\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 90m 41s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 18s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black}116m 40s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| FindBugs | module:hadoop-hdfs-project/hadoop-hdfs |\n|  |  Write to static field org.apache.hadoop.hdfs.server.namenode.FSDirectory.usersToBypassExtAttrProvider from instance method new org.apache.hadoop.hdfs.server.namenode.FSDirectory(FSNamesystem, Configuration)  At FSDirectory.java:from instance method new org.apache.hadoop.hdfs.server.namenode.FSDirectory(FSNamesystem, Configuration)  At FSDirectory.java:[line 371] |\n| Failed junit tests | hadoop.hdfs.TestLeaseRecoveryStriped |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure150 |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure110 |\n|   | hadoop.hdfs.TestDFSStripedInputStreamWithRandomECPolicy |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure180 |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure010 |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure |\n|   | hadoop.hdfs.TestReadStripedFileWithDecoding |\n|   | hadoop.tools.TestHdfsConfigFields |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure020 |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure100 |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure210 |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure050 |\n|   | hadoop.hdfs.TestReconstructStripedFile |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure070 |\n| Timed out junit tests | org.apache.hadoop.hdfs.TestWriteReadStripedFile |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:14b5c93 |\n| JIRA Issue | HDFS-12357 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12884001/HDFS-12357.001.patch |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  xml  |\n| uname | Linux 8006479782a2 3.13.0-117-generic #164-Ubuntu SMP Fri Apr 7 11:05:26 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / ae7abad |\n| Default Java | 1.8.0_144 |\n| findbugs | v3.1.0-RC1 |\n| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/20890/artifact/patchprocess/diff-checkstyle-hadoop-hdfs-project_hadoop-hdfs.txt |\n| findbugs | https://builds.apache.org/job/PreCommit-HDFS-Build/20890/artifact/patchprocess/new-findbugs-hadoop-hdfs-project_hadoop-hdfs.html |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/20890/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |\n|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/20890/testReport/ |\n| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/20890/console |\n| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2017-08-28T08:27:35.364+0000","updated":"2017-08-28T08:27:35.364+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13097703/comment/16146393","id":"16146393","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=atm","name":"atm","key":"atm","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=atm&avatarId=14136","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=atm&avatarId=14136","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=atm&avatarId=14136","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=atm&avatarId=14136"},"displayName":"Aaron T. Myers","active":true,"timeZone":"America/Los_Angeles"},"body":"Took a quick look at the patch, not thorough. One thing jumped out at me on a cursory inspection - why make {{usersToBypassExtAttrProvider}} static? Probably won't cause any problems, but also doesn't seem necessary, and could potentially confuse the situation, e.g. in a unit test with multiple NNs.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=atm","name":"atm","key":"atm","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=atm&avatarId=14136","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=atm&avatarId=14136","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=atm&avatarId=14136","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=atm&avatarId=14136"},"displayName":"Aaron T. Myers","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-08-30T00:22:26.359+0000","updated":"2017-08-30T00:22:26.359+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13097703/comment/16147258","id":"16147258","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=daryn","name":"daryn","key":"daryn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Daryn Sharp","active":true,"timeZone":"America/Chicago"},"body":"Should this perhaps be implemented in the external attribute provider itself?  Instead of an all or nothing approach, it will grant the provider fine-grain authorization control over combinations of users and paths to expose \"real\" attrs.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=daryn","name":"daryn","key":"daryn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Daryn Sharp","active":true,"timeZone":"America/Chicago"},"created":"2017-08-30T13:55:56.410+0000","updated":"2017-08-30T13:55:56.410+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13097703/comment/16148062","id":"16148062","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=manojg","name":"manojg","key":"manojg","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Manoj Govindassamy","active":true,"timeZone":"America/Los_Angeles"},"body":"[~yzhangal],\n  Here is one other jira on the similar lines - HDFS-12203 - INodeAttributesProvider#getAttributes() support for default/passthrough mode.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=manojg","name":"manojg","key":"manojg","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Manoj Govindassamy","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-08-30T21:10:36.483+0000","updated":"2017-08-30T21:10:36.483+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13097703/comment/16148139","id":"16148139","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks you all for the review and comments!\n\n[~atm]: good point, will remove the static. Thanks.\n\n[~daryn], thanks for your comments, some thoughts:\n1. Based on user/path to decide what attributes to reveal is indeed more refined. However, it adds complexity. And every provider has to provide an implementation. Wonder if you can provide an example we want to decide things based on user/path combination?\n2. Currently I use NameNode.getRemoteUser() to tell which user it is. If we put this bypass logic into Provider, the provider need to know what the current user is. we either have to change the API of provider, or add some new methods in parallel, to pass the user information. \n\n[~manojg], talking about SnapshotDiff to bypass provider, the caller need to tell the provider to do that, thus new API is needed. Right? thanks.\n\nLook forward to your further thoughts and comments!\n\nThanks a lot.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-08-30T22:16:47.785+0000","updated":"2017-08-31T01:14:11.160+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13097703/comment/16149912","id":"16149912","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi [~atm], [~daryn] [~manojg], any comments/thoughts on my previous reply?\n\nHi [~asuresh] and [~chris.douglas], would appreciate if you guys could take a look at the patch too.\n\nThanks a lot.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-09-01T01:56:59.657+0000","updated":"2017-09-01T01:56:59.657+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13097703/comment/16149947","id":"16149947","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"body":"Sorry to be dense, but why can't this live in the external attribute provider? {{NameNode::getRemoteUser}} is not only public, it's a 2-line method calling stable APIs. Given:\n{code:java}\n  INodeAttributes getAttributes(INodesInPath iip)\n      throws FileNotFoundException {\n    INode node = FSDirectory.resolveLastINode(iip);\n    int snapshot = iip.getPathSnapshotId();\n    INodeAttributes nodeAttrs = node.getSnapshotINode(snapshot);\n    if (attributeProvider != null) {\n      // permission checking sends the full components array including the\n      // first empty component for the root.  however file status\n      // related calls are expected to strip out the root component according\n      // to TestINodeAttributeProvider.\n      byte[][] components = iip.getPathComponents();\n      components = Arrays.copyOfRange(components, 1, components.length);\n      nodeAttrs = attributeProvider.getAttributes(components, nodeAttrs);\n    }\n    return nodeAttrs;\n  }\n{code}\ncan't {{attributeProvider}} return the formal {{nodeAttrs}} unmodified after performing the same logic as {{NameNode::getRemoteUser}}?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-09-01T02:44:41.704+0000","updated":"2017-09-01T02:44:41.704+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13097703/comment/16150819","id":"16150819","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"HI [~chris.douglas],\n\nThanks a lot for your comment.\n\nSome thoughts:\n\n- I assumed that the external attribute provider is not expected to have knowledge of NameNode, is this not the case? \n- I agree that if we call NameNode.getRemoteUser in external provider, we can implement the same logic in the provider. However, that means all different providers (sentry, ranger etc) need to be fixed accordingly, otherwise we will get unexpected result. Is this what we want to do?\n- The problem here is to decide whether to consult ext provider based on user, not based on user/path combination. So it seems more clear to let NN to decide whether to consult ext provider. If we let the provider to decide, and if there is bug in the provider, we will get unexpected result.\n- Operation-wise, to change all provider's implementation and update clusters is more expensive. \n\nWhat do you think about these points?\n\nThanks.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-09-01T16:52:01.322+0000","updated":"2017-09-01T16:52:01.322+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13097703/comment/16150890","id":"16150890","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"body":"bq. we can implement the same logic in the provider. However, that means all different providers (sentry, ranger etc) need to be fixed accordingly\nWould a filter implementation wrapping the configured, external attribute provider suffice?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-09-01T17:36:45.374+0000","updated":"2017-09-01T17:36:45.374+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13097703/comment/16150921","id":"16150921","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=manojg","name":"manojg","key":"manojg","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Manoj Govindassamy","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks for working on this [~yzhangal]. Thanks [~chris.douglas] for your review and comments.\n\nI believe the motive here is to strictly not return any of external provider attributes for certain users. Tools like distcp can listFileStatus() as this special user to get plain/standalone hdfs attributes which can then be _safely_ copied to a remote hdfs. We might not want tools like DistCp to copy external attributes to HDFS. \n\nNow, this knob/control for returning external attributes can either be given to HDFS or the external provider. While having all the logics about returning the right set of attributes at a single place, like the provider does sound like very good idea, there is still a gap in the design. If I understand the problem rightly, here the choice need to be given to HDFS whether to contact external attributes provider or return the local default provider, so as to be totally sure that right set of attributes are returned. May be this guarantee is not established if the control is placed at the external provider. \n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=manojg","name":"manojg","key":"manojg","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Manoj Govindassamy","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-09-01T17:50:32.544+0000","updated":"2017-09-01T17:50:32.544+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13097703/comment/16151009","id":"16151009","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"body":"Example moving this to a filter provider, no integration/tests, including a test verifying that the filter overrides all the methods of {{INodeAttributeProvider}}. Would this work?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-09-01T18:46:26.360+0000","updated":"2017-09-01T18:46:26.360+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13097703/comment/16151047","id":"16151047","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks [~chris.douglas] and [~manojg].\n\nSorry for a lengthy reply here:\n\n{quote}\nWould a filter implementation wrapping the configured, external attribute provider suffice?\n{quote}\nThe current patch implements this logic (like an inlined version of the wrapper class in C++ world). If we put this logic to the wrapper class, I can see some issues:\n\n1. the wrapper need to create two provider objects, one is the default (HDFS), the other is the external provider, and switch between these two. However, in the existing code, I don't see the default provider object is always created. See 2.a below.\n\nThe default value of the following config is empty, which means no default provider will be created.\n{code}\n<property>\n  <name>dfs.namenode.inode.attributes.provider.class</name>\n  <value></value>\n  <description>\n    Name of class to use for delegating HDFS authorization.\n  </description>\n</property>\n{code}\nNot sure whether we should have the default provider configured here.\n\n2. currently there are two places to decide whether to consult external attribute provider\n2.a.\n{code}\n  INodeAttributes getAttributes(INodesInPath iip)\n      throws FileNotFoundException {\n    INode node = FSDirectory.resolveLastINode(iip);\n    int snapshot = iip.getPathSnapshotId();\n    INodeAttributes nodeAttrs = node.getSnapshotINode(snapshot);\n    if (attributeProvider != null) {\n      // permission checking sends the full components array including the\n      // first empty component for the root.  however file status\n      // related calls are expected to strip out the root component according\n      // to TestINodeAttributeProvider.\n      byte[][] components = iip.getPathComponents();\n      components = Arrays.copyOfRange(components, 1, components.length);\n      nodeAttrs = attributeProvider.getAttributes(components, nodeAttrs);\n    }\n    return nodeAttrs;\n  }\n{code}\nwe already got the attributes from HDFS, then we decide to whether to overwrite it with provider's data. The easiest way is to check if the user is a special user, then we don't ask for provider's data at all. If we do this in a wrapper class, we always have to get some attributes, which maybe from HDFS or not. It's not a clear implementation and may incur runtime cost.\n\n2.b\n{code}\n @VisibleForTesting\n  FSPermissionChecker getPermissionChecker(String fsOwner, String superGroup,\n      UserGroupInformation ugi) throws AccessControlException {\n    return new FSPermissionChecker(\n        fsOwner, superGroup, ugi, attributeProvider);\n  }\n{code}\nHere we need to pass either a null or the external attributeProvider configured to permission checker. if we include this logic to the external provider, we need have an API in this wrapper class, to return the external provicer or null, and pass it to the \"attributeProvider\" parameter in the above code. like\n{code}\n    return new FSPermissionChecker(\n        fsOwner, superGroup, ugi, attributeProvider.getRealAttributeProvider());\n{code}\nWe need to add this getRealAttibuteProvider() API to the base provider class, which is a bit weird because this API is only meaning ful in the wrapper layer. And changing the provider API is what we try to avoid here.\n\nThoughts?\n\nThanks.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-09-01T19:26:09.775+0000","updated":"2017-09-01T21:36:08.596+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13097703/comment/16151121","id":"16151121","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 17s{color} | {color:blue} Docker mode activated. {color} |\n|| || || || {color:brown} Prechecks {color} ||\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |\n|| || || || {color:brown} trunk Compile Tests {color} ||\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 17m 17s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m  8s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 53s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 15s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 17s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 51s{color} | {color:green} trunk passed {color} |\n|| || || || {color:brown} Patch Compile Tests {color} ||\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m  4s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m  1s{color} | {color:green} the patch passed {color} |\n| {color:red}-1{color} | {color:red} javac {color} | {color:red}  1m  1s{color} | {color:red} hadoop-hdfs-project_hadoop-hdfs generated 4 new + 411 unchanged - 0 fixed = 415 total (was 411) {color} |\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 46s{color} | {color:orange} hadoop-hdfs-project/hadoop-hdfs: The patch generated 5 new + 466 unchanged - 0 fixed = 471 total (was 466) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  2s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  2s{color} | {color:green} The patch has no ill-formed XML file. {color} |\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  1m 50s{color} | {color:red} hadoop-hdfs-project/hadoop-hdfs generated 1 new + 0 unchanged - 0 fixed = 1 total (was 0) {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 38s{color} | {color:green} the patch passed {color} |\n|| || || || {color:brown} Other Tests {color} ||\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 83m  5s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 29s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black}115m 20s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| FindBugs | module:hadoop-hdfs-project/hadoop-hdfs |\n|  |  Write to static field org.apache.hadoop.hdfs.server.namenode.FSDirectory.usersToBypassExtAttrProvider from instance method new org.apache.hadoop.hdfs.server.namenode.FSDirectory(FSNamesystem, Configuration)  At FSDirectory.java:from instance method new org.apache.hadoop.hdfs.server.namenode.FSDirectory(FSNamesystem, Configuration)  At FSDirectory.java:[line 371] |\n| Failed junit tests | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure100 |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure130 |\n|   | hadoop.hdfs.tools.TestDFSAdminWithHA |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure050 |\n|   | hadoop.hdfs.tools.TestDebugAdmin |\n|   | hadoop.hdfs.server.namenode.ha.TestPipelinesFailover |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure090 |\n|   | hadoop.hdfs.TestLeaseRecoveryStriped |\n|   | hadoop.hdfs.server.namenode.ha.TestPendingCorruptDnMessages |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure200 |\n|   | hadoop.hdfs.TestReadStripedFileWithDecoding |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure150 |\n|   | hadoop.hdfs.TestDistributedFileSystem |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure030 |\n| Timed out junit tests | org.apache.hadoop.hdfs.TestDFSStripedInputStreamWithRandomECPolicy |\n|   | org.apache.hadoop.hdfs.TestWriteReadStripedFile |\n|   | org.apache.hadoop.hdfs.server.mover.TestStorageMover |\n|   | org.apache.hadoop.hdfs.server.balancer.TestBalancer |\n|   | org.apache.hadoop.hdfs.server.mover.TestMover |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:71bbb86 |\n| JIRA Issue | HDFS-12357 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12884998/HDFS-12357.002.patch |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  xml  |\n| uname | Linux 0dfc2a1f80e2 3.13.0-123-generic #172-Ubuntu SMP Mon Jun 26 18:04:35 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / 063b6d0 |\n| Default Java | 1.8.0_144 |\n| findbugs | v3.1.0-RC1 |\n| javac | https://builds.apache.org/job/PreCommit-HDFS-Build/20970/artifact/patchprocess/diff-compile-javac-hadoop-hdfs-project_hadoop-hdfs.txt |\n| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/20970/artifact/patchprocess/diff-checkstyle-hadoop-hdfs-project_hadoop-hdfs.txt |\n| findbugs | https://builds.apache.org/job/PreCommit-HDFS-Build/20970/artifact/patchprocess/new-findbugs-hadoop-hdfs-project_hadoop-hdfs.html |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/20970/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |\n|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/20970/testReport/ |\n| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/20970/console |\n| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2017-09-01T20:46:37.835+0000","updated":"2017-09-01T20:46:37.835+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13097703/comment/16151189","id":"16151189","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"HI [~chris.douglas],\n\nSorry I did not see your latest comment and even updated a revised patch when I made the earlier comments. Thanks much for doing that. \n\nIt seems my last comments still applies. My comments are largely about the integration, which is the key part that you did not address in the example patch. If you'd like, would you please take a look?\n\nThanks.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-09-01T21:34:56.417+0000","updated":"2017-09-01T21:34:56.417+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13097703/comment/16151239","id":"16151239","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"body":"bq. 1. the wrapper need to create two provider objects, one is the default (HDFS), the other is the external provider, and switch between these two. However, in the existing code, I don't see the default provider object is always created\nSure, but if no external attribute provider is created, then the wrapper doesn't need to be created. What is the problem?\n\nbq. 2a. \\[...]  The easiest way is to check if the user is a special user, then we don't ask for provider's data at all. If we do this in a wrapper class, we always have to get some attributes, which maybe from HDFS or not. \\[...]\nAs in the v001 version, this is avoided.\n\nbq. 2b. Here we need to pass either a null or the external attributeProvider configured to permission checker. if we include this logic to the external provider, we need have an API in this wrapper class, to return the external provicer or null\nUnless this is invoked in a separate thread, doesn't the same logic apply? If the provider is configured then it's invoked by {{FSPermissionChecker}}, if it's a filtered user then it doesn't consult the external attribute provider.\n\nbq. My comments are largely about the integration, which is the key part that you did not address in the example patch. If you'd like, would you please take a look?\nI'll take a second pass, but I don't intend to take over the patch...","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-09-01T22:23:12.099+0000","updated":"2017-09-01T22:23:12.099+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13097703/comment/16151246","id":"16151246","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"body":"I wasn't sure if {{INodeAttributeProvider::getExternalAccessControlEnforcer}} should have respected the user list, but from {{FSPermissionChecker::getAccessControlEnforcer}}:\n{code:java}\n  private AccessControlEnforcer getAccessControlEnforcer() {\n    return (attributeProvider != null)\n        ? attributeProvider.getExternalAccessControlEnforcer(this) : this;\n  }\n{code}\nIt looks like v001 should check {{isBypassUser}} and return the default if it matches, exactly like the other methods. Are there other cases that this needs to cover?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-09-01T22:33:03.884+0000","updated":"2017-09-01T22:33:03.884+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13097703/comment/16151264","id":"16151264","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"body":"Missed a dead store","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-09-01T22:57:02.362+0000","updated":"2017-09-01T22:57:02.362+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13097703/comment/16151272","id":"16151272","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi [~chris.douglas],\n\nIn patch rev1, I passed null to attributeProvider in getPermissionChecker when it's a bypass user (2.b of my earlier comments),  so the external provider is bypassed and we don't need to check {{isBypassUser}} in {{private AccessControlEnforcer getAccessControlEnforcer()}} you asked.\n\nI think my rev1 covered all. But it's possible I missed something.\n\nThanks.\n \n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-09-01T23:08:55.372+0000","updated":"2017-09-01T23:08:55.372+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13097703/comment/16151280","id":"16151280","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"body":"v002 assumed that enforcement should always delegate to the provider, unlike v001 and v004 (which should be equivalent). I'm not familiar with how {{INodeAttributeProvider}} is used in practice, so I'll defer to you on the correct semantics.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-09-01T23:17:50.881+0000","updated":"2017-09-01T23:17:50.881+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13097703/comment/16151290","id":"16151290","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"{quote}\nAs in the v001 version, this is avoided.\n{quote}\nNot really. In the following code, \n\nwe get HDFS attributes first by {{INodeAttributes nodeAttrs = node.getSnapshotINode(snapshot);}}. Then we get the external provider attribute if needed.\n\nIn v001, for special user, it's not needed to get external provider attribute, thus we don't call {{nodeAttrs = attributeProvider.getAttributes(components, nodeAttrs);}}; \n\nHowever, in the wrapper solution, we will go into the {{if (attributeProvider != null) {}} block and call it. If the {{attributeProvider.getAttributes}} decides to bypass external provider, it's going to do the same thing as  {{INodeAttributes nodeAttrs = node.getSnapshotINode(snapshot);}} to get the HDFS version attribute. So we get the HDFS attribute twice.In v001, we only get it once.\n\n{code}\n INodeAttributes getAttributes(INodesInPath iip)\n      throws FileNotFoundException {\n    INode node = FSDirectory.resolveLastINode(iip);\n    int snapshot = iip.getPathSnapshotId();\n    INodeAttributes nodeAttrs = node.getSnapshotINode(snapshot);\n    if (attributeProvider != null) {\n      // permission checking sends the full components array including the\n      // first empty component for the root.  however file status\n      // related calls are expected to strip out the root component according\n      // to TestINodeAttributeProvider.\n      byte[][] components = iip.getPathComponents();\n      components = Arrays.copyOfRange(components, 1, components.length);\n      nodeAttrs = attributeProvider.getAttributes(components, nodeAttrs);\n    }\n    return nodeAttrs;\n  }\n{code}\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-09-01T23:24:47.132+0000","updated":"2017-09-01T23:24:47.132+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13097703/comment/16151304","id":"16151304","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"body":"The inner provider is not invoked. {{attributeProvider.getAttributes(components, nodeAttrs)}} checks for the user, and returns {{nodeAttrs}}.\n\nIf {{iip.getPathComponents()}} and the copy is a significant cost- which would be bad news for external attribute providers generally- then this could still be pushed down a level, out of {{FSDirectory}}.\n\nI don't see why this is a significant difference.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-09-01T23:37:54.118+0000","updated":"2017-09-01T23:37:54.118+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13097703/comment/16151306","id":"16151306","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Hm, I saw that you do this\n{code}\n  @Override\n  public INodeAttributes getAttributes(\n      String[] pathElements, INodeAttributes inode) {\n    return isBypassUser()\n        ? inode\n        : provider.getAttributes(pathElements, inode);\n  }\n{code}\nthat is, you did not try to get the HDFS attributes again, instead, you returned the attributes passed from caller.\n\nHowever, \n{code}\n      byte[][] components = iip.getPathComponents();\n      components = Arrays.copyOfRange(components, 1, components.length);\n{code}\nthe above code is avoided in v001, but it's unavoidable in wrapper implementation, even though {{components}} will not be used when it's bypass user. So this is a waste.\n\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-09-01T23:40:07.910+0000","updated":"2017-09-01T23:40:07.910+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13097703/comment/16151315","id":"16151315","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"HI [~chris.douglas],\n\nWould you please revisit my comment 2.b? \n\nIn order to do the wrapper implementation,  we either need to add a new API to the provider base class, such that it returns the real provider based on whether it's bypass user, or add a new API to say whether it's bypass user, and let the following method to call this API:\n{code}\n private AccessControlEnforcer getAccessControlEnforcer() {\n    return (attributeProvider != null)\n        ? attributeProvider.getExternalAccessControlEnforcer(this) : this;\n  }\n{code}\nAdding this new API is an integration issue to me.\n\nThanks.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-09-01T23:55:34.110+0000","updated":"2017-09-01T23:55:34.110+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13097703/comment/16151325","id":"16151325","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Ah, I overlooked the code here you added in the new class\n{code}\n @Override\n  public AccessControlEnforcer getExternalAccessControlEnforcer(\n      AccessControlEnforcer defaultEnforcer) {\n    return isBypassUser()\n        ? defaultEnforcer\n        : provider.getExternalAccessControlEnforcer(defaultEnforcer);\n  }\n{code}\nso, that actually addressed comment 2.b.\n\nThanks.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-09-02T00:09:36.606+0000","updated":"2017-09-02T00:09:36.606+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13097703/comment/16151344","id":"16151344","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=manojg","name":"manojg","key":"manojg","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Manoj Govindassamy","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks for the patch [~chris.douglas]. Having {{UserFilterINodeAttributeProvider}} seems like a cleaner approach. Is it possible to examine the {{bypassUser}} config and skip the wrapper {{UserFilterINodeAttributeProvider}} if the user list is empty. Most of the times, the bypass user list is going to empty and we can totally skip the wrapper if so. \n\n{noformat}\n205\t  void setINodeAttributeProvider(\n206\t      INodeAttributeProvider provider, Configuration conf) {\n207\t    attributeProvider = null == provider\n208\t        ? null\n209\t        : new UserFilterINodeAttributeProvider(provider, conf);\n207\t  }\t210\t\n{noformat}\n\n[~yzhangal], I don't see the problem with {{getAccessControlEnforcer}}. But as you pointed out, if we can avoid duplicate of components, it would be great. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=manojg","name":"manojg","key":"manojg","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Manoj Govindassamy","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-09-02T00:37:04.702+0000","updated":"2017-09-02T00:37:04.702+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13097703/comment/16151345","id":"16151345","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi [~chris.douglas],\n\nWith v004, the only concern is now \n\nhttps://issues.apache.org/jira/browse/HDFS-12357?focusedCommentId=16151306&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-16151306\n\nIf we can avoid {{components = Arrays.copyOfRange(components, 1, components.length);}}, that will be great. Because this happens to every {{getAttributes}} call which can be avoided when it's the bypass user.\n\nThanks.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-09-02T00:37:53.886+0000","updated":"2017-09-02T00:37:53.886+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13097703/comment/16151361","id":"16151361","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 22s{color} | {color:blue} Docker mode activated. {color} |\n|| || || || {color:brown} Prechecks {color} ||\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |\n|| || || || {color:brown} trunk Compile Tests {color} ||\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 15m 46s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 53s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 49s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 57s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 47s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 43s{color} | {color:green} trunk passed {color} |\n|| || || || {color:brown} Patch Compile Tests {color} ||\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 56s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 56s{color} | {color:green} the patch passed {color} |\n| {color:red}-1{color} | {color:red} javac {color} | {color:red}  0m 56s{color} | {color:red} hadoop-hdfs-project_hadoop-hdfs generated 4 new + 411 unchanged - 0 fixed = 415 total (was 411) {color} |\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 47s{color} | {color:orange} hadoop-hdfs-project/hadoop-hdfs: The patch generated 4 new + 643 unchanged - 0 fixed = 647 total (was 643) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 57s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  2s{color} | {color:green} The patch has no ill-formed XML file. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 57s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 42s{color} | {color:green} the patch passed {color} |\n|| || || || {color:brown} Other Tests {color} ||\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}118m 42s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 22s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black}148m 22s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| Failed junit tests | hadoop.hdfs.server.blockmanagement.TestBlockTokenWithDFSStriped |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure140 |\n|   | hadoop.tools.TestHdfsConfigFields |\n|   | hadoop.hdfs.TestReconstructStripedFile |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure010 |\n|   | hadoop.hdfs.TestClientProtocolForPipelineRecovery |\n|   | hadoop.hdfs.TestLeaseRecoveryStriped |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailureWithRandomECPolicy |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure150 |\n|   | hadoop.hdfs.server.namenode.TestNameNodeMetadataConsistency |\n|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure |\n|   | hadoop.hdfs.TestSafeMode |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure190 |\n|   | hadoop.hdfs.TestEncryptedTransfer |\n| Timed out junit tests | org.apache.hadoop.hdfs.TestWriteReadStripedFile |\n|   | org.apache.hadoop.hdfs.TestReadStripedFileWithDecoding |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:71bbb86 |\n| JIRA Issue | HDFS-12357 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12885032/HDFS-12357.004.patch |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  xml  |\n| uname | Linux 671cd6c01249 3.13.0-123-generic #172-Ubuntu SMP Mon Jun 26 18:04:35 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / 7996eca |\n| Default Java | 1.8.0_144 |\n| findbugs | v3.1.0-RC1 |\n| javac | https://builds.apache.org/job/PreCommit-HDFS-Build/20974/artifact/patchprocess/diff-compile-javac-hadoop-hdfs-project_hadoop-hdfs.txt |\n| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/20974/artifact/patchprocess/diff-checkstyle-hadoop-hdfs-project_hadoop-hdfs.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/20974/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |\n|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/20974/testReport/ |\n| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/20974/console |\n| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2017-09-02T01:29:39.427+0000","updated":"2017-09-02T01:29:39.427+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13097703/comment/16151362","id":"16151362","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"HI [~chris.douglas],\n\nI uploaded rev005 to avoid the {{components = Arrays.copyOfRange(components, 1, components.length);}} overhead.\n\nBasically I added a new API (package scope)  {{boolean isBypassUser() {}} to {{INodeAttributeProvider}} class, and have a default implementation of returning false. Then let {{UserFilterINodeAttributeProvider}} version to override it. Then do the following\n{code}\n    if (attributeProvider != null &&\n        !attributeProvider.isBypassUser()) {\n      // permission checking sends the full components array including the\n      // first empty component for the root.  however file status\n      // related calls are expected to strip out the root component according\n      // to TestINodeAttributeProvider.\n      byte[][] components = iip.getPathComponents();\n      components = Arrays.copyOfRange(components, 1, components.length);\n      nodeAttrs = attributeProvider.getAttributes(components, nodeAttrs);\n    }\n    return nodeAttrs;\n    ......\n{code}\nsimilar to the logic as in v001. \n\nSo here is a trade-off between not exposing the isBypassUser API and suffer the cost overhead, vs exposing it and save the cost.\n\nWonder what you think?\n\nThanks.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-09-02T01:35:19.493+0000","updated":"2017-09-02T01:35:19.493+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13097703/comment/16151396","id":"16151396","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 13s{color} | {color:blue} Docker mode activated. {color} |\n|| || || || {color:brown} Prechecks {color} ||\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |\n|| || || || {color:brown} trunk Compile Tests {color} ||\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 13m 47s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 49s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 44s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 53s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 41s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 41s{color} | {color:green} trunk passed {color} |\n|| || || || {color:brown} Patch Compile Tests {color} ||\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 48s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 45s{color} | {color:green} the patch passed {color} |\n| {color:red}-1{color} | {color:red} javac {color} | {color:red}  0m 45s{color} | {color:red} hadoop-hdfs-project_hadoop-hdfs generated 4 new + 411 unchanged - 0 fixed = 415 total (was 411) {color} |\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 41s{color} | {color:orange} hadoop-hdfs-project/hadoop-hdfs: The patch generated 4 new + 647 unchanged - 0 fixed = 651 total (was 647) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 50s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  2s{color} | {color:green} The patch has no ill-formed XML file. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 44s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 38s{color} | {color:green} the patch passed {color} |\n|| || || || {color:brown} Other Tests {color} ||\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 89m 57s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 17s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black}115m 49s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| Failed junit tests | hadoop.hdfs.TestHFlush |\n|   | hadoop.hdfs.TestLeaseRecoveryStriped |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure180 |\n|   | hadoop.hdfs.TestClientProtocolForPipelineRecovery |\n|   | hadoop.tools.TestHdfsConfigFields |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure150 |\n| Timed out junit tests | org.apache.hadoop.hdfs.TestLeaseRecovery2 |\n|   | org.apache.hadoop.hdfs.TestWriteReadStripedFile |\n|   | org.apache.hadoop.hdfs.TestReadStripedFileWithDecoding |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:71bbb86 |\n| JIRA Issue | HDFS-12357 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12885045/HDFS-12357.005.patch |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  xml  |\n| uname | Linux b864616b7569 3.13.0-119-generic #166-Ubuntu SMP Wed May 3 12:18:55 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / 7996eca |\n| Default Java | 1.8.0_144 |\n| findbugs | v3.1.0-RC1 |\n| javac | https://builds.apache.org/job/PreCommit-HDFS-Build/20976/artifact/patchprocess/diff-compile-javac-hadoop-hdfs-project_hadoop-hdfs.txt |\n| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/20976/artifact/patchprocess/diff-checkstyle-hadoop-hdfs-project_hadoop-hdfs.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/20976/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |\n|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/20976/testReport/ |\n| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/20976/console |\n| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2017-09-02T03:26:58.889+0000","updated":"2017-09-02T03:26:58.889+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13097703/comment/16151448","id":"16151448","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"HI [~manojg],\n\n{quote}\nHaving UserFilterINodeAttributeProvider seems like a cleaner approach. Is it possible to examine the bypassUser config and skip the wrapper UserFilterINodeAttributeProvider if the user list is empty. Most of the times, the bypass user list is going to empty and we can totally skip the wrapper if so.\n{quote}\nThanks for the good point here, sorry too many updates today I missed the above one again.\n\nIf we move the code of loading conf and checking isBypassUse to {{FSDirectory}} class  (like done in v001), we could  skip the wrapper when the bypassUser is empty. However, even when bypassUser is not empty, it's only one of two users, the wrapper is still created when many other users are not in the list. Any further thought?\n\nHi [~chris.douglas],\n\nLooking at the change I did in rev5 again, it saved the extra cost of {{components = Arrays.copyOfRange(components, 1, components.length);}}, but it introduced another extra cost: {{isBypassUser()}} is called twice. One at\n{code}\n    if (attributeProvider != null &&\n        !attributeProvider.isBypassUser()) {\n{code}\nThe other at the trapper implementation\n{code}\nnodeAttrs = attributeProvider.getAttributes(components, nodeAttrs);\n{code} \n\nafter the first one is checked and found to be a non bypassUser, the second one checks again. And this extra call happens to most users unfortunately.  Seems not easy to avoid both extra costs with the wrapper approach.\n\nv001 implementation does't have either of these extra costs. But certainly the wrapper class is a better abstraction.  I can go with either approach if agreed, and we can certainly keep improving the solution.\n\nThanks a lot.\n\n\n\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-09-02T08:34:31.964+0000","updated":"2017-09-02T08:34:31.964+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13097703/comment/16151528","id":"16151528","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi [~chris.douglas],\n\nThanks a lot for the good discussion yesterday!\n\nWe favor wrapper solution for the better abstraction design. But due to the extra checking I described in my last comment, I did a revised version 001a on top of v001 for reference. Mainly introduced a new method and calls to it at needed places:\n\n{code}\n  private INodeAttributeProvider getUserFilteredAttributeProvider(\n      UserGroupInformation ugi) {\n    if (ugi == null) {\n      return attributeProvider;\n    }\n    if (attributeProvider == null ||\n        isUserBypassingExtAttrProvider(ugi.getUserName())) {\n      return null;\n    }\n    return attributeProvider;\n  }\n{code}\n\nCould you please take a look at both 005 and 001a? Either one would work for us, and we can keep improving the solution.\n\nThanks a lot.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-09-02T15:21:32.707+0000","updated":"2017-09-02T15:21:32.707+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13097703/comment/16151547","id":"16151547","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 14s{color} | {color:blue} Docker mode activated. {color} |\n|| || || || {color:brown} Prechecks {color} ||\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |\n|| || || || {color:brown} trunk Compile Tests {color} ||\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 14m 21s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 48s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 42s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 53s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 42s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 40s{color} | {color:green} trunk passed {color} |\n|| || || || {color:brown} Patch Compile Tests {color} ||\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 48s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 48s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 48s{color} | {color:green} the patch passed {color} |\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 39s{color} | {color:orange} hadoop-hdfs-project/hadoop-hdfs: The patch generated 5 new + 466 unchanged - 0 fixed = 471 total (was 466) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 50s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  1s{color} | {color:green} The patch has no ill-formed XML file. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 45s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 38s{color} | {color:green} the patch passed {color} |\n|| || || || {color:brown} Other Tests {color} ||\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 88m 43s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 16s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black}115m  7s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| Failed junit tests | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure080 |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailureWithRandomECPolicy |\n|   | hadoop.hdfs.qjournal.server.TestJournalNodeSync |\n|   | hadoop.hdfs.TestLeaseRecoveryStriped |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure090 |\n|   | hadoop.hdfs.TestAclsEndToEnd |\n|   | hadoop.tools.TestHdfsConfigFields |\n|   | hadoop.hdfs.TestPipelines |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure070 |\n| Timed out junit tests | org.apache.hadoop.hdfs.TestWriteReadStripedFile |\n|   | org.apache.hadoop.hdfs.TestReadStripedFileWithDecoding |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:71bbb86 |\n| JIRA Issue | HDFS-12357 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12885085/HDFS-12357.001a.patch |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  xml  |\n| uname | Linux dd60d533f99e 3.13.0-119-generic #166-Ubuntu SMP Wed May 3 12:18:55 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / 275980b |\n| Default Java | 1.8.0_144 |\n| findbugs | v3.1.0-RC1 |\n| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/20977/artifact/patchprocess/diff-checkstyle-hadoop-hdfs-project_hadoop-hdfs.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/20977/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |\n|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/20977/testReport/ |\n| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/20977/console |\n| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2017-09-02T17:26:01.764+0000","updated":"2017-09-02T17:26:01.764+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13097703/comment/16151556","id":"16151556","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Renamed a method and uploaded 001b.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-09-02T18:06:21.774+0000","updated":"2017-09-02T18:06:21.774+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13097703/comment/16151577","id":"16151577","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 14s{color} | {color:blue} Docker mode activated. {color} |\n|| || || || {color:brown} Prechecks {color} ||\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |\n|| || || || {color:brown} trunk Compile Tests {color} ||\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 13m 47s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 49s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 42s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 54s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 40s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 40s{color} | {color:green} trunk passed {color} |\n|| || || || {color:brown} Patch Compile Tests {color} ||\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 48s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 47s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 47s{color} | {color:green} the patch passed {color} |\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 39s{color} | {color:orange} hadoop-hdfs-project/hadoop-hdfs: The patch generated 5 new + 466 unchanged - 0 fixed = 471 total (was 466) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 51s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  1s{color} | {color:green} The patch has no ill-formed XML file. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 45s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 38s{color} | {color:green} the patch passed {color} |\n|| || || || {color:brown} Other Tests {color} ||\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 88m  0s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 16s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black}113m 48s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| Failed junit tests | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure130 |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure080 |\n|   | hadoop.hdfs.TestReadStripedFileWithDecoding |\n|   | hadoop.hdfs.TestLeaseRecoveryStriped |\n|   | hadoop.hdfs.server.datanode.TestDirectoryScanner |\n|   | hadoop.tools.TestHdfsConfigFields |\n|   | hadoop.hdfs.TestPipelines |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure000 |\n|   | hadoop.hdfs.TestListFilesInFileContext |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure070 |\n| Timed out junit tests | org.apache.hadoop.hdfs.TestWriteReadStripedFile |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:71bbb86 |\n| JIRA Issue | HDFS-12357 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12885094/HDFS-12357.001b.patch |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  xml  |\n| uname | Linux 3b184b55560f 3.13.0-119-generic #166-Ubuntu SMP Wed May 3 12:18:55 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / 275980b |\n| Default Java | 1.8.0_144 |\n| findbugs | v3.1.0-RC1 |\n| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/20979/artifact/patchprocess/diff-checkstyle-hadoop-hdfs-project_hadoop-hdfs.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/20979/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |\n|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/20979/testReport/ |\n| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/20979/console |\n| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2017-09-02T20:04:46.917+0000","updated":"2017-09-02T20:04:46.917+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13097703/comment/16151587","id":"16151587","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"body":"bq. if we can avoid duplicate of components, it would be great.\nAre there any clusters that benefit from this optimization? The fraction of calls for distcp jobs, in clusters with an external attribute provider configured, run by a particular user is unlikely to be significant. This cost is currently incurred by _every_ call with an external attribute provider. Again, if this cost is significant, then it should be optimized across external attribute providers (moving this logic into {{INodeAttributeProvider}}).\n\nThe approach in v001\\* is difficult to extend. For example, if another developer were to add a config knob that bypassed particular paths, then it would have to work around the logic in {{FSDirectory}}.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-09-02T20:47:41.918+0000","updated":"2017-09-02T20:47:41.918+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13097703/comment/16154337","id":"16154337","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"body":"Had offline discussions with [~yzhangal]. We tried a version that would bypass not only the path component logic, but also add more generic filtering (by {{INodesInPath}} and {{NodeAttributes}}). Unfortunately, the API is not always invoked in contexts where this information is freely available.\n\nInternally, the NameNode relies on null values for the {{INodeAttributeProvider}} and {{AccessControlEnforcer}}; it constructs some intermediate data to satisfy the plugin APIs. To extend v004/v005 to also avoid these costs would not be as straightforward as the invocation in {{FSDirectory}}. Fixing this across all providers- by pushing these conditions ahead of the call- is a more significant refactor with implications for existing implementations. [~yzhangal] cited experience in the field, where copying jobs cause NN failover. We don't have specific data implicating the costs we're avoiding here, but the more general solution has no willing implementors, so we can press forward with v001b.\n\nSomeone more familiar with external attribute providers should [verify|https://issues.apache.org/jira/browse/HDFS-12357?focusedCommentId=16151280&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-16151280] the bypass of {{AccessControlEnforcer}} for the configured users.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-09-05T21:23:58.981+0000","updated":"2017-09-05T21:23:58.981+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13097703/comment/16154520","id":"16154520","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Many thanks [~chris.douglas] for the offline discussions! \n\nGood summary! I can create a jira for more general solution, we can work on the jira when there is a new use case coming up, such as filtering by path or by the combination of user/path. I think the new solution can be stacked on top of the fix of this jira.\n\nI checked with folks around and we agreed that for the dedicated user we can bypass external provider when doing permission checking. This means the permission checking will be using HDFS metadata.  Welcome to comment If other folks have any.\n\nThanks again!\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-09-05T23:00:45.853+0000","updated":"2017-09-05T23:00:45.853+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13097703/comment/16154605","id":"16154605","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=manojg","name":"manojg","key":"manojg","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Manoj Govindassamy","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks for working on this [~yzhangal]. Thanks [~chris.douglas] for the valuable comments and the alternative proposals. Much appreciated.\n\nMy review comments for HDFS-12357.001b.patch.\n\n1. {{FSDirectory.java}}\n-- {{getUserFilteredAttributeProvider}} -- line 401 to 407 can be simplified in a single if block\n{noformat}\nif (ugi == null || isUserBypassingExtAttrProvider(ugi.getUserName()) {\n   return null;\n}\n{noformat}\n\n-- {{initUsersToBypassExtProvider()}} : an user list like \"a, b, \" can trip the code to add a null object to the {{usersToBypassExtAttrProvider}}. Probably we want to verify the trimmed user before adding it to the bypass list.\n\n2. {{hdfs-default.xml}}\n-- \"..for whom the external attributes provider will be bypassed\" - This config description can have more details like what bypass would mean for the user operations. Is that only for permission checking or other operations etc.,\n\n3. {{TestINodeAttributeProvider}}\n-- Can you please add one non-bypassed user \"u4\" to the test list of users in line 239? Basically a true negative case.\n-- Check style issues\n\n4. Probably the patch can be renamed to HDFS-12357.006.patch so that any new reviewers looking at this jira can go straight to the latest patch instead of suffix versions in the older patch.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=manojg","name":"manojg","key":"manojg","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Manoj Govindassamy","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-09-06T00:09:11.334+0000","updated":"2017-09-06T00:09:11.334+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13097703/comment/16154736","id":"16154736","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks for the review [~manojg], good catches.\n\nI uploaded rev6 to address all, except the third one, since we already have the test for it right before the test I added.\n\nWould you please take another look? Thanks.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-09-06T02:59:46.715+0000","updated":"2017-09-06T02:59:46.715+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13097703/comment/16155802","id":"16155802","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 15s{color} | {color:blue} Docker mode activated. {color} |\n|| || || || {color:brown} Prechecks {color} ||\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |\n|| || || || {color:brown} trunk Compile Tests {color} ||\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 15m 50s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 58s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 46s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  3s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 56s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 44s{color} | {color:green} trunk passed {color} |\n|| || || || {color:brown} Patch Compile Tests {color} ||\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 59s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 57s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 57s{color} | {color:green} the patch passed {color} |\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 44s{color} | {color:orange} hadoop-hdfs-project/hadoop-hdfs: The patch generated 4 new + 466 unchanged - 0 fixed = 470 total (was 466) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  1s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  1s{color} | {color:green} The patch has no ill-formed XML file. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m  5s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 43s{color} | {color:green} the patch passed {color} |\n|| || || || {color:brown} Other Tests {color} ||\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 98m 29s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 17s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black}128m 19s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| Failed junit tests | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure060 |\n|   | hadoop.tools.TestHdfsConfigFields |\n|   | hadoop.hdfs.TestFileAppendRestart |\n|   | hadoop.hdfs.tools.TestDFSAdminWithHA |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure180 |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure050 |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure110 |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure190 |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure210 |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure070 |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure020 |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure090 |\n|   | hadoop.hdfs.TestLeaseRecoveryStriped |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure120 |\n|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure150 |\n|   | hadoop.hdfs.TestReconstructStripedFile |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure030 |\n| Timed out junit tests | org.apache.hadoop.hdfs.TestWriteReadStripedFile |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:71bbb86 |\n| JIRA Issue | HDFS-12357 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12885507/HDFS-12357.006.patch |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  xml  |\n| uname | Linux 704820cea650 3.13.0-123-generic #172-Ubuntu SMP Mon Jun 26 18:04:35 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / 1f3bc63 |\n| Default Java | 1.8.0_144 |\n| findbugs | v3.1.0-RC1 |\n| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/21022/artifact/patchprocess/diff-checkstyle-hadoop-hdfs-project_hadoop-hdfs.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/21022/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |\n|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/21022/testReport/ |\n| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/21022/console |\n| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2017-09-06T18:02:59.815+0000","updated":"2017-09-06T18:02:59.815+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13097703/comment/16155925","id":"16155925","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=manojg","name":"manojg","key":"manojg","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Manoj Govindassamy","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks for working on the patch revision [~yzhangal]. Overall looks good to me. +1. few nits.\n\n1. {{FSDirectory.java#initUsersToBypassExtProvider}}\n{noformat}\n373\t    List<String> bpUserList = new ArrayList<String>();\n374\t    for(int i = 0; i < bypassUsers.length; i++) {\n375\t      String tmp = bypassUsers[i].trim();\n376\t      if (!tmp.isEmpty()) {\n377\t        bpUserList.add(tmp);\n378\t      }\n379\t    }\n380\t    if (bpUserList.size() > 0) {\n381\t      usersToBypassExtAttrProvider = new HashSet<String>();\n382\t      for(String user : bpUserList) {\n383\t        LOG.info(\"Add user \" + user + \" to the list that will bypass external\"\n384\t            + \" attribute provider.\");\n385\t        usersToBypassExtAttrProvider.add(user.trim());\n386\t      }\n387\t    }\n{noformat}\n\nThe above 2 for loops can be simplified to 1 loop. Checking for trim and adding to _usersToBypassExtAttrProvider_ can be done in the same block.\n\n2. {{TestINodeAttributeProvider}}\n{noformat}\n240\t    String[] bypassUsers = {\"u2\", \"u3\"};\n{noformat}\n* Can we please add \"u4\" also this list? yes, since this user is not in the bypass list the getFileStatus is going to differ from other users. Adding this non bypass user will make the test complete.\n* And, it would be great if we can verify the base hdfs permission instead of assuming the same with the CALLED map contents.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=manojg","name":"manojg","key":"manojg","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Manoj Govindassamy","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-09-06T19:40:09.383+0000","updated":"2017-09-06T20:13:46.855+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13097703/comment/16156498","id":"16156498","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks [~manojg] for the review.\n\nUploaded rev7 to address all except for \"u4\", which is already covered by a pre-existing case as I stated earlier. Good point to check permission in addition to checking CALLED map in test, added that.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-09-07T05:36:13.399+0000","updated":"2017-09-07T05:36:13.399+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13097703/comment/16156615","id":"16156615","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=manojg","name":"manojg","key":"manojg","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Manoj Govindassamy","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks for the patch revision [~yzhangal]. LGTM, +1. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=manojg","name":"manojg","key":"manojg","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Manoj Govindassamy","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-09-07T07:29:07.481+0000","updated":"2017-09-07T07:29:07.481+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13097703/comment/16156654","id":"16156654","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 31s{color} | {color:blue} Docker mode activated. {color} |\n|| || || || {color:brown} Prechecks {color} ||\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |\n|| || || || {color:brown} trunk Compile Tests {color} ||\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 15m 13s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 50s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 45s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  0s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 52s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 45s{color} | {color:green} trunk passed {color} |\n|| || || || {color:brown} Patch Compile Tests {color} ||\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 56s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 49s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 49s{color} | {color:green} the patch passed {color} |\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 44s{color} | {color:orange} hadoop-hdfs-project/hadoop-hdfs: The patch generated 3 new + 466 unchanged - 0 fixed = 469 total (was 466) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 59s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  3s{color} | {color:green} The patch has no ill-formed XML file. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m  0s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 42s{color} | {color:green} the patch passed {color} |\n|| || || || {color:brown} Other Tests {color} ||\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}118m 51s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 16s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black}147m 51s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| Failed junit tests | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure200 |\n|   | hadoop.tools.TestHdfsConfigFields |\n|   | hadoop.hdfs.TestClientProtocolForPipelineRecovery |\n|   | hadoop.hdfs.TestLeaseRecoveryStriped |\n|   | hadoop.hdfs.server.namenode.TestReencryptionWithKMS |\n|   | hadoop.hdfs.server.namenode.ha.TestPipelinesFailover |\n|   | hadoop.hdfs.server.namenode.TestDecommissioningStatus |\n|   | hadoop.hdfs.TestReplaceDatanodeOnFailure |\n| Timed out junit tests | org.apache.hadoop.hdfs.TestWriteReadStripedFile |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:71bbb86 |\n| JIRA Issue | HDFS-12357 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12885747/HDFS-12357.007.patch |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  xml  |\n| uname | Linux 514a3507bf4c 3.13.0-123-generic #172-Ubuntu SMP Mon Jun 26 18:04:35 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / b6e7d13 |\n| Default Java | 1.8.0_144 |\n| findbugs | v3.1.0-RC1 |\n| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/21033/artifact/patchprocess/diff-checkstyle-hadoop-hdfs-project_hadoop-hdfs.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/21033/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |\n|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/21033/testReport/ |\n| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/21033/console |\n| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2017-09-07T08:09:14.606+0000","updated":"2017-09-07T08:09:14.606+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13097703/comment/16157353","id":"16157353","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"body":"Many thanks to [~asuresh], [~chris.douglas], [~daryn], [~manojg] and [~atm] for the discussion and review. \n\nI committed to trunk, branch-3.0 and branch-2.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yzhangal","name":"yzhangal","key":"yzhangal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yongjun Zhang","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-09-07T18:01:27.273+0000","updated":"2017-09-07T18:01:27.273+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13097703/comment/16157706","id":"16157706","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"SUCCESS: Integrated in Jenkins build Hadoop-trunk-Commit #12811 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/12811/])\nHDFS-12357. Let NameNode to bypass external attribute provider for (yzhang: rev d77ed238a911fc85d6f4bbce606cac7ec44f557f)\n* (edit) hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java\n* (edit) hadoop-hdfs-project/hadoop-hdfs/src/main/resources/hdfs-default.xml\n* (edit) hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestINodeAttributeProvider.java\n* (edit) hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSConfigKeys.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2017-09-07T21:34:39.069+0000","updated":"2017-09-07T21:34:39.069+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13097703/comment/16157942","id":"16157942","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=manojg","name":"manojg","key":"manojg","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Manoj Govindassamy","active":true,"timeZone":"America/Los_Angeles"},"body":"hdfs-default.xml is missing the right config param and the fix is available in HDFS-12404. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=manojg","name":"manojg","key":"manojg","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Manoj Govindassamy","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-09-08T00:46:19.536+0000","updated":"2017-09-08T00:46:19.536+0000"}],"maxResults":48,"total":48,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-12357/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i3jb1r:"}}