{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12467159","self":"https://issues.apache.org/jira/rest/api/2/issue/12467159","key":"HDFS-1227","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/3","id":"3","description":"The problem is a duplicate of an existing issue.","name":"Duplicate"},"customfield_12312322":null,"customfield_12310220":"2010-06-17T05:12:36.597+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Fri Sep 10 06:50:52 UTC 2010","customfield_12310420":"15917","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_520502438_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2010-06-23T04:53:20.680+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-1227/watchers","watchCount":2,"isWatching":false},"created":"2010-06-17T04:18:18.242+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12315103","id":"12315103","description":"Append/sync support for Hadoop 0.20","name":"0.20-append","archived":true,"released":false}],"issuelinks":[],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2010-09-10T06:50:52.769+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12312927","id":"12312927","name":"datanode"}],"timeoriginalestimate":null,"description":"- Summary: client append is not atomic, hence, it is possible that\nwhen retrying during append, there is an exception in updateBlock\nindicating unmatched file length, making append failed.\n \n- Setup:\n+ # available datanodes = 3\n+ # disks / datanode = 1\n+ # failures = 1\n+ failure type = bad disk\n+ When/where failure happens = (see below)\n+ This bug is non-deterministic, to reproduce it, add a sufficient sleep before out.write() in BlockReceiver.receivePacket() in dn1 and dn2 but not dn3\n \n- Details:\n Suppose client appends 16 bytes to block X which has length 16 bytes at dn1, dn2, dn3.\nDn1 is primary. The pipeline is dn3-dn2-dn1. recoverBlock succeeds.\nClient starts sending data to the dn3 - the first datanode in pipeline.\ndn3 forwards the packet to downstream datanodes, and starts writing\ndata to its disk. Suppose there is an exception in dn3 when writing to disk.\nClient gets the exception, it starts the recovery code by calling dn1.recoverBlock() again.\ndn1 in turn calls dn2.getMetadataInfo() and dn1.getMetaDataInfo() to build the syncList.\nSuppose at the time getMetadataInfo() is called at both datanodes (dn1 and dn2),\nthe previous packet (which is sent from dn3) has not come to disk yet.\nHence, the block Info given by getMetaDataInfo contains the length of 16 bytes.\nBut after that, the packet \"comes\" to disk, making the block file length now becomes 32 bytes.\nUsing the syncList (with contains block info with length 16 byte), dn1 calls updateBlock at\ndn2 and dn1, which will failed, because the length of new block info (given by updateBlock,\nwhich is 16 byte) does not match with its actual length on disk (which is 32 byte)\n \nNote that this bug is non-deterministic. Its depends on the thread interleaving\nat datanodes.\n\nThis bug was found by our Failure Testing Service framework:\nhttp://www.eecs.berkeley.edu/Pubs/TechRpts/2010/EECS-2010-98.html\nFor questions, please email us: Thanh Do (thanhdo@cs.wisc.edu) and \nHaryadi Gunawi (haryadi@eecs.berkeley.edu)\n\n","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"113402","customfield_12312823":null,"summary":"UpdateBlock fails due to unmatched file length","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=thanhdo","name":"thanhdo","key":"thanhdo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=thanhdo&avatarId=22565","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=thanhdo&avatarId=22565","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=thanhdo&avatarId=22565","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=thanhdo&avatarId=22565"},"displayName":"Thanh Do","active":true,"timeZone":"Etc/UTC"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=thanhdo","name":"thanhdo","key":"thanhdo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=thanhdo&avatarId=22565","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=thanhdo&avatarId=22565","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=thanhdo&avatarId=22565","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=thanhdo&avatarId=22565"},"displayName":"Thanh Do","active":true,"timeZone":"Etc/UTC"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12467159/comment/12879662","id":"12879662","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"Believe this is addressed by HDFS-1186 in the 20-append branch","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2010-06-17T05:12:36.597+0000","updated":"2010-06-17T05:12:36.597+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12467159/comment/12881543","id":"12881543","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"Going to resolve this as invalid. If you can reproduce after HDFS-1186 is committed, or provide a unit test, we can reopen.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2010-06-23T04:53:20.652+0000","updated":"2010-06-23T04:53:20.652+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12467159/comment/12888893","id":"12888893","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=thanhdo","name":"thanhdo","key":"thanhdo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=thanhdo&avatarId=22565","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=thanhdo&avatarId=22565","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=thanhdo&avatarId=22565","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=thanhdo&avatarId=22565"},"displayName":"Thanh Do","active":true,"timeZone":"Etc/UTC"},"body":"In the append-branch, I saw the \"unmatched file length exception happens\", but then the client retries RecoverBlock, hence, tolerates this","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=thanhdo","name":"thanhdo","key":"thanhdo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=thanhdo&avatarId=22565","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=thanhdo&avatarId=22565","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=thanhdo&avatarId=22565","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=thanhdo&avatarId=22565"},"displayName":"Thanh Do","active":true,"timeZone":"Etc/UTC"},"created":"2010-07-15T19:24:46.574+0000","updated":"2010-07-15T19:24:46.574+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12467159/comment/12889302","id":"12889302","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=thanhdo","name":"thanhdo","key":"thanhdo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=thanhdo&avatarId=22565","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=thanhdo&avatarId=22565","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=thanhdo&avatarId=22565","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=thanhdo&avatarId=22565"},"displayName":"Thanh Do","active":true,"timeZone":"Etc/UTC"},"body":"when startBlockRecovery is called, the writer thread is interrupted. But the effect/changes that this write made to disk (if any) is still there, right?\nHence this exception still happens (after HDFS-1186 is committed).","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=thanhdo","name":"thanhdo","key":"thanhdo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=thanhdo&avatarId=22565","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=thanhdo&avatarId=22565","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=thanhdo&avatarId=22565","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=thanhdo&avatarId=22565"},"displayName":"Thanh Do","active":true,"timeZone":"Etc/UTC"},"created":"2010-07-16T20:17:21.350+0000","updated":"2010-07-16T20:17:21.350+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12467159/comment/12892588","id":"12892588","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"Hi Thanh. Since the writer is interrupted before getting the recovery info, it will return the new length, with the effect of the write, like you said. But when the synchronized length is calculated, it's taken as the minimum of the lengths (ie the length at DN1), which is what we want.\n\nDid you test this against the append branch with HDFS-1186 applied on top? (Note that 1186 has not yet been committed to the branch)","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2010-07-27T01:09:50.706+0000","updated":"2010-07-27T01:09:50.706+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12467159/comment/12907909","id":"12907909","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"body":">Dn1 is primary. The pipeline is dn3-dn2-dn1. recoverBlock succeeds.\n>Client starts sending data to the dn3 - the first datanode in pipeline.\n\nI am slightly confused by the above. The first datanode in the write pipeline is typically the primary datanode. If the client is writing to d1, d1 is forwarding it to d2 and d2 is forwarding it to d3, then the primary is d1, isn't it?\n\nAlso, this bug should already be solved in the append-0.20 branch.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"created":"2010-09-10T06:50:52.736+0000","updated":"2010-09-10T06:50:52.736+0000"}],"maxResults":6,"total":6,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-1227/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i0jrlr:"}}