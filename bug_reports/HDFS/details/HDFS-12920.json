{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"13124542","self":"https://issues.apache.org/jira/rest/api/2/issue/13124542","key":"HDFS-12920","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":"2017-12-13T01:23:37.961+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Sat Dec 16 01:54:10 UTC 2017","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-12920/watchers","watchCount":11,"isWatching":false},"created":"2017-12-13T00:58:36.784+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/1","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/blocker.svg","name":"Blocker","id":"1"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[],"issuelinks":[{"id":"12542338","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12542338","type":{"id":"12310000","name":"Duplicate","inward":"is duplicated by","outward":"duplicates","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/12310000"},"outwardIssue":{"id":"13182612","key":"HDFS-13889","self":"https://issues.apache.org/jira/rest/api/2/issue/13182612","fields":{"summary":"The hadoop3.x client have compatible problem with hadoop2.x cluster","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/2","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/critical.svg","name":"Critical","id":"2"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/4","id":"4","description":"An improvement or enhancement to an existing feature or task.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype","name":"Improvement","subtask":false,"avatarId":21140}}}},{"id":"12522140","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12522140","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"13120060","key":"HADOOP-15059","self":"https://issues.apache.org/jira/rest/api/2/issue/13120060","fields":{"summary":"3.0 deployment cannot work with old version MR tar ball which breaks rolling upgrade","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/1","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/blocker.svg","name":"Blocker","id":"1"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12522139","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12522139","type":{"id":"12310050","name":"Regression","inward":"is broken by","outward":"breaks","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/12310050"},"inwardIssue":{"id":"13003420","key":"HDFS-10845","self":"https://issues.apache.org/jira/rest/api/2/issue/13003420","fields":{"summary":"Change defaults in hdfs-site.xml to match timeunit type","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/4","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/minor.svg","name":"Minor","id":"4"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/7","id":"7","description":"The sub-task of the issue","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype","name":"Sub-task","subtask":true,"avatarId":21146}}}}],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2018-09-04T13:21:40.189+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12329603","id":"12329603","name":"hdfs"}],"timeoriginalestimate":null,"description":"After HADOOP-15059 get resolved. I tried to deploy 2.9.0 tar ball with 3.0.0 RC1, and run the job with following errors:\r\n{noformat}\r\n2017-12-12 13:29:06,824 INFO [main] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.mapreduce.v2.app.MRAppMaster failed in state INITED; cause: org.apache.hadoop.yarn.exceptions.YarnRuntimeException: java.lang.NumberFormatException: For input string: \"30s\"\r\norg.apache.hadoop.yarn.exceptions.YarnRuntimeException: java.lang.NumberFormatException: For input string: \"30s\"\r\n\tat org.apache.hadoop.mapreduce.v2.app.MRAppMaster$2.call(MRAppMaster.java:542)\r\n\tat org.apache.hadoop.mapreduce.v2.app.MRAppMaster$2.call(MRAppMaster.java:522)\r\n\tat org.apache.hadoop.mapreduce.v2.app.MRAppMaster.callWithJobClassLoader(MRAppMaster.java:1764)\r\n\tat org.apache.hadoop.mapreduce.v2.app.MRAppMaster.createOutputCommitter(MRAppMaster.java:522)\r\n\tat org.apache.hadoop.mapreduce.v2.app.MRAppMaster.serviceInit(MRAppMaster.java:308)\r\n\tat org.apache.hadoop.service.AbstractService.init(AbstractService.java:164)\r\n\tat org.apache.hadoop.mapreduce.v2.app.MRAppMaster$5.run(MRAppMaster.java:1722)\r\n\tat java.security.AccessController.doPrivileged(Native Method)\r\n\tat javax.security.auth.Subject.doAs(Subject.java:422)\r\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1886)\r\n\tat org.apache.hadoop.mapreduce.v2.app.MRAppMaster.initAndStartAppMaster(MRAppMaster.java:1719)\r\n\tat org.apache.hadoop.mapreduce.v2.app.MRAppMaster.main(MRAppMaster.java:1650)\r\n{noformat}\r\nThis is because HDFS-10845, we are adding time unit to hdfs-default.xml but it cannot be recognized by old version MR jars. \r\nThis break our rolling upgrade story, so should mark as blocker.\r\nA quick workaround is to add values in hdfs-site.xml with removing all time unit. But the right way may be to revert HDFS-10845 (and get rid of noisy warnings).","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12342732","id":"12342732","description":"3.0.2 release","name":"3.0.2","archived":false,"released":true,"releaseDate":"2018-04-21"}],"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"HDFS default value change (with adding time unit) breaks old version MR tarball work with new version (3.0) of hadoop","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=djp","name":"djp","key":"djp","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=djp&avatarId=16954","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=djp&avatarId=16954","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=djp&avatarId=16954","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=djp&avatarId=16954"},"displayName":"Junping Du","active":true,"timeZone":"Asia/Shanghai"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=djp","name":"djp","key":"djp","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=djp&avatarId=16954","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=djp&avatarId=16954","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=djp&avatarId=16954","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=djp&avatarId=16954"},"displayName":"Junping Du","active":true,"timeZone":"Asia/Shanghai"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/13124542/comment/16288568","id":"16288568","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=djp","name":"djp","key":"djp","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=djp&avatarId=16954","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=djp&avatarId=16954","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=djp&avatarId=16954","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=djp&avatarId=16954"},"displayName":"Junping Du","active":true,"timeZone":"Asia/Shanghai"},"body":"CC [~andrew.wang], [~linyiqun], [~chris.douglas].","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=djp","name":"djp","key":"djp","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=djp&avatarId=16954","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=djp&avatarId=16954","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=djp&avatarId=16954","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=djp&avatarId=16954"},"displayName":"Junping Du","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-12-13T01:15:17.094+0000","updated":"2017-12-13T01:15:17.094+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13124542/comment/16288574","id":"16288574","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=andrew.wang","name":"andrew.wang","key":"andrew.wang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=andrew.wang&avatarId=19230","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=andrew.wang&avatarId=19230","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=andrew.wang&avatarId=19230","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=andrew.wang&avatarId=19230"},"displayName":"Andrew Wang","active":true,"timeZone":"America/Los_Angeles"},"body":"Particularly since there's a workaround, let's bump this to 3.0.1.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=andrew.wang","name":"andrew.wang","key":"andrew.wang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=andrew.wang&avatarId=19230","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=andrew.wang&avatarId=19230","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=andrew.wang&avatarId=19230","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=andrew.wang&avatarId=19230"},"displayName":"Andrew Wang","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-12-13T01:23:37.961+0000","updated":"2017-12-13T01:23:37.961+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13124542/comment/16288638","id":"16288638","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=linyiqun","name":"linyiqun","key":"linyiqun","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=linyiqun&avatarId=25258","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=linyiqun&avatarId=25258","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=linyiqun&avatarId=25258","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=linyiqun&avatarId=25258"},"displayName":"Yiqun Lin","active":true,"timeZone":"Asia/Shanghai"},"body":"Hi  [~djp], thanks for reporting this.\r\nbq. A quick workaround is to add values in hdfs-site.xml with removing all time unit. But the right way may be to revert HDFS-10845 (and get rid of noisy warnings).\r\nI think we don't need to removing all time unit values in hdfs-default file. HDFS configurations support time unit suffix was implemented in HDFS-9847. That change was only committed in trunk not include branch-2. So the new settings with time unit suffix are only making sense in 3.x.x versions. So the right way should be to revert HDFS-10845 and get rid of noisy warnings as you suggested.\r\nIf we are all agreed on on this way, I will attach the patch to make this changed.\r\nThanks.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=linyiqun","name":"linyiqun","key":"linyiqun","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=linyiqun&avatarId=25258","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=linyiqun&avatarId=25258","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=linyiqun&avatarId=25258","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=linyiqun&avatarId=25258"},"displayName":"Yiqun Lin","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-12-13T02:49:03.445+0000","updated":"2017-12-13T02:49:03.445+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13124542/comment/16288641","id":"16288641","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"body":"/cc [~arpitagarwal]\r\n\r\nIf we're not going to [change the config properties|https://issues.apache.org/jira/browse/HDFS-9847?focusedCommentId=15211227&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-15211227], and the client needs to load 3.x config files during rolling upgrades, then this isn't worth the hassle.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-12-13T02:52:18.606+0000","updated":"2017-12-13T02:52:18.606+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13124542/comment/16288948","id":"16288948","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=djp","name":"djp","key":"djp","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=djp&avatarId=16954","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=djp&avatarId=16954","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=djp&avatarId=16954","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=djp&avatarId=16954"},"displayName":"Junping Du","active":true,"timeZone":"Asia/Shanghai"},"body":"bq. So the right way should be to revert HDFS-10845 and get rid of noisy warnings as you suggested. If we are all agreed on on this way, I will attach the patch to make this changed.\r\nThanks [~linyiqun] for quick response. I am +1 on ongoing this way.\r\n\r\nbq. If we're not going to change the config properties, the client needs to load 3.x config files during rolling upgrades, then this isn't worth the hassle.\r\nActually, it could be a serious issue for old client (provided by MR tarball via distributed cache) to work with new 3.x config which include incompatible default value. Old client cannot recognize the new value for the known property (end up with \"s\", etc.) and throw exception to end the job which means app cannot run successful during upgrade from 2.9 to 3.0.0.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=djp","name":"djp","key":"djp","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=djp&avatarId=16954","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=djp&avatarId=16954","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=djp&avatarId=16954","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=djp&avatarId=16954"},"displayName":"Junping Du","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-12-13T09:24:36.217+0000","updated":"2017-12-13T09:24:36.217+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13124542/comment/16289960","id":"16289960","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"body":"I understand the issue, Junping. An alternative to reverting the change is to deprecate the old property and create a new one that understands time units, as was raised in that JIRA. If specifying units breaks rolling upgrades, then what is the point of adding units, ever?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-12-13T21:40:05.111+0000","updated":"2017-12-13T21:40:05.111+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13124542/comment/16291005","id":"16291005","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jlowe","name":"jlowe","key":"jlowe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jason Lowe","active":true,"timeZone":"America/Chicago"},"body":"This only occurs if the job submitter is using 3.x jars and the submitted job is using 2.x jars.  If the job submitter is using the same jars as the code then this does not happen, since the values copied from hdfs-default.xml into job.xml as part of job submission are compatible with the parsing code.\r\n\r\nSo another workaround is to have at least two tarballs on HDFS, one that uses 3.x and one that uses 2.x.  The 3.x site configs request the 3.x tarball and the 2.x site configs request the 2.x tarball.  When the job submitter client upgrades to use 3.x jars, it can also upgrade to 3.x configs to start running the job with 3.x as well.\r\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jlowe","name":"jlowe","key":"jlowe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jason Lowe","active":true,"timeZone":"America/Chicago"},"created":"2017-12-14T15:31:06.666+0000","updated":"2017-12-14T15:31:06.666+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13124542/comment/16293424","id":"16293424","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=arpitagarwal","name":"arpitagarwal","key":"arpitagarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arpit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"body":"[~djp], does presence of any unit-suffixed values in the config file cause this failure?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=arpitagarwal","name":"arpitagarwal","key":"arpitagarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arpit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-12-15T23:54:20.488+0000","updated":"2017-12-15T23:54:20.488+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13124542/comment/16293555","id":"16293555","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=djp","name":"djp","key":"djp","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=djp&avatarId=16954","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=djp&avatarId=16954","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=djp&avatarId=16954","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=djp&avatarId=16954"},"displayName":"Junping Du","active":true,"timeZone":"Asia/Shanghai"},"body":"bq. An alternative to reverting the change is to deprecate the old property and create a new one that understands time units, as was raised in that JIRA. If specifying units breaks rolling upgrades, then what is the point of adding units, ever?\r\nThat is also a possible approach. We can either keep the default value for existing properties or start to using new properties and deprecated previous properties.\r\n\r\nbq. So another workaround is to have at least two tarballs on HDFS, one that uses 3.x and one that uses 2.x. The 3.x site configs request the 3.x tarball and the 2.x site configs request the 2.x tarball. When the job submitter client upgrades to use 3.x jars, it can also upgrade to 3.x configs to start running the job with 3.x as well.\r\nAs we discussed offline, if we explicitly packaging these configs into tarball, then we may not hitting this issue as different version tar ball and configuration will match each other in the end. However, some users may not follow this practice before and after. Also, managing configurations in different places (cluster setup, MR tar ball, job submission, etc.) is also complicated. May be it is more easier to fix issue here instead of tarball configuration?\r\n\r\nbq. Junping Du, does presence of any unit-suffixed values in the config file cause this failure?\r\nHi [~arpitagarwal], the unit-suffixed values is by default (in hdfs-default.xml) now in 3.x. Job submit against old version MR tar ball will load new default values provided by new hadoop deployment which will get stuck with exception I put above.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=djp","name":"djp","key":"djp","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=djp&avatarId=16954","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=djp&avatarId=16954","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=djp&avatarId=16954","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=djp&avatarId=16954"},"displayName":"Junping Du","active":true,"timeZone":"Asia/Shanghai"},"created":"2017-12-16T01:54:10.152+0000","updated":"2017-12-16T01:54:10.152+0000"}],"maxResults":9,"total":9,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-12920/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i3nu27:"}}