{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12895745","self":"https://issues.apache.org/jira/rest/api/2/issue/12895745","key":"HDFS-9126","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/6","id":"6","description":"The problem isn't valid and it can't be fixed.","name":"Invalid"},"customfield_12312322":null,"customfield_12310220":"2015-09-23T16:04:49.284+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Wed Sep 20 21:24:17 UTC 2017","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_62938162780_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2017-09-20T21:24:17.376+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-9126/watchers","watchCount":6,"isWatching":false},"created":"2015-09-23T10:34:54.683+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/2","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/critical.svg","name":"Critical","id":"2"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12327181","id":"12327181","description":"2.6.0 release","name":"2.6.0","archived":false,"released":true,"releaseDate":"2014-11-18"}],"issuelinks":[],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2017-09-20T21:24:35.971+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12312926","id":"12312926","name":"namenode"}],"timeoriginalestimate":null,"description":"In our product Hadoop cluster,when active namenode begin download/transfer \nfsimage from standby namenode.some times zkfc monitor health of NameNode socket timeout,zkfs judge active namenode status SERVICE_NOT_RESPONDING ,happen hadoop namenode ha failover,fence old active namenode.\n\nzkfc logs:\n2015-09-24 11:44:44,739 WARN org.apache.hadoop.ha.HealthMonitor: Transport-level exception trying to monitor health of NameNode at hostname1/192.168.10.11:8020: Call From hostname1/192.168.10.11 to hostname1:8020 failed on socket timeout exception: java.net.SocketTimeoutException: 45000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/192.168.10.11:22614 remote=hostname1/192.168.10.11:8020]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout\n2015-09-24 11:44:44,740 INFO org.apache.hadoop.ha.HealthMonitor: Entering state SERVICE_NOT_RESPONDING\n2015-09-24 11:44:44,740 INFO org.apache.hadoop.ha.ZKFailoverController: Local service NameNode at hostname1/192.168.10.11:8020 entered state: SERVICE_NOT_RESPONDING\n2015-09-24 11:44:44,740 INFO org.apache.hadoop.ha.ZKFailoverController: Quitting master election for NameNode at hostname1/192.168.10.11:8020 and marking that fencing is necessary\n2015-09-24 11:44:44,740 INFO org.apache.hadoop.ha.ActiveStandbyElector: Yielding from election\n2015-09-24 11:44:44,761 INFO org.apache.zookeeper.ZooKeeper: Session: 0x54d81348fe503e3 closed\n2015-09-24 11:44:44,761 WARN org.apache.hadoop.ha.ActiveStandbyElector: Ignoring stale result from old client with sessionId 0x54d81348fe503e3\n2015-09-24 11:44:44,764 INFO org.apache.zookeeper.ClientCnxn: EventThread shut down\n\nnamenode logs:\n2015-09-24 11:43:34,074 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.10.12\n2015-09-24 11:43:34,074 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs\n2015-09-24 11:43:34,075 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 2317430129\n2015-09-24 11:43:34,253 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 272988 Total time for transactions(ms): 5502 Number of transactions batched in Syncs: 146274 Number of syncs: 32375 SyncTimes(ms): 274465 319599\n2015-09-24 11:43:46,005 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds\n2015-09-24 11:44:21,054 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: PendingReplicationMonitor timed out blk_1185804191_112164210\n2015-09-24 11:44:36,076 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /software/data/hadoop-data/hdfs/namenode/current/edits_inprogress_0000000002317430129 -> /software/data/hadoop-data/hdfs/namenode/current/edits_0000000002317430129-0000000002317703116\n2015-09-24 11:44:36,077 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 2317703117\n2015-09-24 11:45:38,008 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 1 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 61585\n2015-09-24 11:45:38,009 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 222.88s at 63510.29 KB/s\n2015-09-24 11:45:38,009 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000002317430128 size 14495092105 bytes.\n2015-09-24 11:45:38,416 WARN org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Remote journal 192.168.10.13:8485 failed to write txns 2317703117-2317703117. Will try to write to this JN again after the next log roll.\norg.apache.hadoop.ipc.RemoteException(java.io.IOException): IPC's epoch 44 is less than the last promised epoch 45\n        at org.apache.hadoop.hdfs.qjournal.server.Journal.checkRequest(Journal.java:414)\n        at org.apache.hadoop.hdfs.qjournal.server.Journal.checkWriteRequest(Journal.java:442)\n        at org.apache.hadoop.hdfs.qjournal.server.Journal.journal(Journal.java:342)\n        at org.apache.hadoop.hdfs.qjournal.server.JournalNodeRpcServer.journal(JournalNodeRpcServer.java:148)\n        at org.apache.hadoop.hdfs.qjournal.protocolPB.QJournalProtocolServerSideTranslatorPB.journal(QJournalProtocolServerSideTranslatorPB.java:158)\n        at org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$QJournalProtocolService$2.callBlockingMethod(QJournalProtocolProtos.java:25421)\n        at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)\n        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)\n        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2039)\n        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2035)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:415)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)\n        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2033)\n        at org.apache.hadoop.ipc.Client.call(Client.java:1468)\n        at org.apache.hadoop.ipc.Client.call(Client.java:1399)\n        at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)\n        at com.sun.proxy.$Proxy9.journal(Unknown Source)\n        at org.apache.hadoop.hdfs.qjournal.protocolPB.QJournalProtocolTranslatorPB.journal(QJournalProtocolTranslatorPB.java:167)\n        at org.apache.hadoop.hdfs.qjournal.client.IPCLoggerChannel$7.call(IPCLoggerChannel.java:385)\n        at org.apache.hadoop.hdfs.qjournal.client.IPCLoggerChannel$7.call(IPCLoggerChannel.java:378)\n        at java.util.concurrent.FutureTask.run(FutureTask.java:262)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n        at java.lang.Thread.run(Thread.java:745)\n\t\t\n#Similar log like above \n\n2015-09-24 11:45:38,418 WARN org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Aborting QuorumOutputStream starting at txid 2317703117\n2015-09-24 11:45:38,505 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 1\n2015-09-24 11:45:38,549 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG:\n/************************************************************\nSHUTDOWN_MSG: Shutting down NameNode at hostname1/192.168.10.11\n","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"namenode crash in fsimage download/transfer","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=zengyongping","name":"zengyongping","key":"zengyongping","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"zengyongping","active":true,"timeZone":"Etc/UTC"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=zengyongping","name":"zengyongping","key":"zengyongping","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"zengyongping","active":true,"timeZone":"Etc/UTC"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":"OS:Centos 6.5(final)\nApache Hadoop:2.6.0\nnamenode ha base 5 journalnodes","customfield_12313520":null,"customfield_12311020":null,"duedate":"2015-09-23","customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12895745/comment/14904724","id":"14904724","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=nijel","name":"nijel","key":"nijel","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"nijel","active":true,"timeZone":"Etc/UTC"},"body":"[~pingley]\nCan you attach the logs or the error messages  for more clarity  ?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=nijel","name":"nijel","key":"nijel","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"nijel","active":true,"timeZone":"Etc/UTC"},"created":"2015-09-23T16:04:49.284+0000","updated":"2015-09-23T16:04:49.284+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12895745/comment/14905891","id":"14905891","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=zengyongping","name":"zengyongping","key":"zengyongping","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"zengyongping","active":true,"timeZone":"Etc/UTC"},"body":"hi,I attach some logs,can you help me fix the probrom? thank you.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=zengyongping","name":"zengyongping","key":"zengyongping","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"zengyongping","active":true,"timeZone":"Etc/UTC"},"created":"2015-09-24T06:31:11.678+0000","updated":"2015-09-24T06:31:11.678+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12895745/comment/15180393","id":"15180393","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brian.spallholtz%40gmail.com","name":"brian.spallholtz@gmail.com","key":"brian.spallholtz@gmail.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Brian P Spallholtz","active":true,"timeZone":"Etc/UTC"},"body":"Any resolution to this? ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brian.spallholtz%40gmail.com","name":"brian.spallholtz@gmail.com","key":"brian.spallholtz@gmail.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Brian P Spallholtz","active":true,"timeZone":"Etc/UTC"},"created":"2016-03-04T19:11:07.954+0000","updated":"2016-03-04T19:11:07.954+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12895745/comment/16083601","id":"16083601","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=liemlin","name":"liemlin","key":"liemlin","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"linhaiqiang","active":true,"timeZone":"Etc/UTC"},"body":"We have already encounter simliar issue. As logs shown, an unexpected 45 sec timeout occured when active namenode's corresponding healthMonitor was checking namenode's health(health check request emited at 2017-07-06 17:22:12). The timeout makes healthMonitor believes active namenode had failed, and thus closed zk client to quit leader election. However, we did not find any exception in namenode's log and gc log. A more wired thing is that namenode's ends logging at 2017-07-06 17:20:37.\n\nAfter analysing the source code, the scenario is shown below:\n1. when activce namenode' corresponding healthMonitor is checking NN's health, a 45 secends timeout makes state switched to SERVICE_NOT_RESPONDING.\n2. Active NN quits leader election. zkClinet close connection and, thus, temporary lock znode on zk is deleted.\n3. standby NN gain the leadership from zk in order to switch itself to new active NN.\n4. To prevent 'Split-Brain', before switching to active state, standby NN sends rpc request to switch current active NN' state to standby.\n5. If this rpc request fails, standby NN tries to kill target NN jvm via ssh. This is the exactly same to our case.\n6. After killing target NN successfully, standby NN switchs itself to activce.\n\nThough we have understood the scenario, what happend in previous active NN is still unknown. Sadly, Jstack trace can be found no longer since jvm is killed by standby nn. Does anyone understand or have similar prolem? Thanks for sharing in advance.\n\nnamenode log\n2017-07-06 17:20:25,944 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 192.168.74.160:50010 is added to blk_8181385931_7145837309{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-8b015249-3dfc-46d6-b575-a5217dd3e40e:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-a88850be-de4f-4cf8-b6ec-10c8116c4226:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-09006ca0-3bd0-41a2-b4b9-90a28682031b:NORMAL|RBW]]} size 0\n2017-07-06 17:20:25,945 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 192.168.8.230:50010 is added to blk_8181385931_7145837309{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-8b015249-3dfc-46d6-b575-a5217dd3e40e:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-a88850be-de4f-4cf8-b6ec-10c8116c4226:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-09006ca0-3bd0-41a2-b4b9-90a28682031b:NORMAL|RBW]]} size 0\n2017-07-06 17:20:25,945 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 192.168.74.79:50010 is added to blk_8181385931_7145837309{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-8b015249-3dfc-46d6-b575-a5217dd3e40e:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-a88850be-de4f-4cf8-b6ec-10c8116c4226:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-09006ca0-3bd0-41a2-b4b9-90a28682031b:NORMAL|RBW]]} size 0\n2017-07-06 17:20:25,945 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hive-mobdss/hive_2017-07-06_17-19-52_775_5225473556650420863-1/_task_tmp.-ext-10003/_tmp.000000_0 is closed by DFSClient_attempt_1482378778761_39818303_m_000000_0_1289941958_1\n2017-07-06 17:20:25,946 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hbase/data/ns_spider/p_site_product/2a79796e1be609fc26ecf1ab58f5aac9/.tmp/733c7b7008594135ae6fcb540f0ca4d5 is closed by DFSClient_hb_rs_slave557-prd3.hadoop.com,60020,1498730232536_-2089669913_35\n2017-07-06 17:20:26,667 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/mobdss/.staging/job_1482378778761_39818325/job_1482378778761_39818325_1.jhist for DFSClient_NONMAPREDUCE_-907911548_1\n2017-07-06 17:20:30,826 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/yyadmin/.staging/job_1482378778761_39818328/job_1482378778761_39818328_1.jhist for DFSClient_NONMAPREDUCE_-1343712942_1\n2017-07-06 17:20:32,051 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/yyadmin/.staging/job_1482378778761_39818327/job_1482378778761_39818327_1.jhist for DFSClient_NONMAPREDUCE_-904958265_1\n2017-07-06 17:20:33,722 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/yyadmin/.staging/job_1482378778761_39818341/job_1482378778761_39818341_1.jhist for DFSClient_NONMAPREDUCE_1250585342_1\n2017-07-06 17:20:37,402 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds\n\n\nzkfc log\n2017-07-06 17:22:12,264 WARN org.apache.hadoop.ha.HealthMonitor: Transport-level exception trying to monitor health of Na\nmeNode at hostname1/hostname1:8020: Call From hostname1/hostname1 to namenode1-pr\nd3.hadoop.com:8020 failed on socket timeout exception: java.net.SocketTimeoutException: 45000 millis timeout while wait\ning for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/hostname1:25190 remote=name\nnode1-prd3.hadoop.com/hostname1:8020]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout\n2017-07-06 17:22:12,265 INFO org.apache.hadoop.ha.HealthMonitor: Entering state SERVICE_NOT_RESPONDING\n2017-07-06 17:22:12,265 INFO org.apache.hadoop.ha.ZKFailoverController: Local service NameNode at namenode1-prd3.hadoop\n.com/hostname1:8020 entered state: SERVICE_NOT_RESPONDING\n2017-07-06 17:22:12,265 INFO org.apache.hadoop.ha.ZKFailoverController: Quitting master election for NameNode at namenode\n1-prd3.hadoop.com/hostname1:8020 and marking that fencing is necessary\n2017-07-06 17:22:12,265 INFO org.apache.hadoop.ha.ActiveStandbyElector: Yielding from election\n2017-07-06 17:22:12,269 INFO org.apache.zookeeper.ZooKeeper: Session: 0x350703139e63a4d closed\n2017-07-06 17:22:12,269 WARN org.apache.hadoop.ha.ActiveStandbyElector: Ignoring stale result from old client with sessio\nnId 0x350703139e63a4d\n2017-07-06 17:22:12,270 INFO org.apache.zookeeper.ClientCnxn: EventThread shut down\n2017-07-06 17:22:19,020 WARN org.apache.hadoop.ha.HealthMonitor: Transport-level exception trying to monitor health of Na\nmeNode at hostname1/hostname1:8020: Failed on local exception: java.io.EOFException; Host Details : l\nocal host is: \"hostname1/hostname1\"; destination host is: \"hostname1\":8020; \n2017-07-06 17:22:21,022 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hostname1/hostname1:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=1, sleepTime=1000 MIL\nLISECONDS)\n2017-07-06 17:22:21,023 WARN org.apache.hadoop.ha.HealthMonitor: Transport-level exception trying to monitor health of Na\nmeNode at hostname1/hostname1:8020: Call From hostname1/hostname1 to namenode1-pr\nd3.hadoop.com:8020 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:\n  http://wiki.apache.org/hadoop/ConnectionRefused\n  \n\njournal log\n2017-07-06 17:22:18,906 INFO org.apache.hadoop.hdfs.qjournal.server.Journal: Scanning storage FileJournalManager(root=/home/bigdata/hadoop/journal/hadoop1)\n2017-07-06 17:22:19,022 INFO org.apache.hadoop.hdfs.qjournal.server.Journal: Latest log is EditLogFile(file=/home/bigdata/hadoop/journal/hadoop1/current/edits_inprogress_0000000054649908467,first=0000000054649908467,last=0000000054650023722,inProgress=true,hasCorruptHeader=false)\n2017-07-06 17:22:19,194 INFO org.apache.hadoop.hdfs.qjournal.server.Journal: getSegmentInfo(54649908467): EditLogFile(file=/home/bigdata/hadoop/journal/hadoop1/current/edits_inprogress_0000000054649908467,first=0000000054649908467,last=0000000054650023722,inProgress=true,hasCorruptHeader=false) -> startTxId: 54649908467 endTxId: 54650023722 isInProgress: true\n2017-07-06 17:22:19,195 INFO org.apache.hadoop.hdfs.qjournal.server.Journal: Prepared recovery for segment 54649908467: segmentState { startTxId: 54649908467 endTxId: 54650023722 isInProgress: true } lastWriterEpoch: 23 lastCommittedTxId: 54650023721\n2017-07-06 17:22:19,316 INFO org.apache.hadoop.hdfs.qjournal.server.Journal: getSegmentInfo(54649908467): EditLogFile(file=/home/bigdata/hadoop/journal/hadoop1/current/edits_inprogress_0000000054649908467,first=0000000054649908467,last=0000000054650023722,inProgress=true,hasCorruptHeader=false) -> startTxId: 54649908467 endTxId: 54650023722 isInProgress: true\n2017-07-06 17:22:19,316 INFO org.apache.hadoop.hdfs.qjournal.server.Journal: Skipping download of log startTxId: 54649908467 endTxId: 54650023722 isInProgress: true: already have up-to-date logs\n2017-07-06 17:22:19,317 INFO org.apache.hadoop.hdfs.qjournal.server.Journal: Accepted recovery for segment 54649908467: segmentState { startTxId: 54649908467 endTxId: 54650023722 isInProgress: true } acceptedInEpoch: 24\n2017-07-06 17:22:19,340 INFO org.apache.hadoop.hdfs.qjournal.server.Journal: Validating log segment /home/bigdata/hadoop/journal/hadoop1/current/edits_inprogress_0000000054649908467 about to be finalized\n2017-07-06 17:22:19,421 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/bigdata/hadoop/journal/hadoop1/current/edits_inprogress_0000000054649908467 -> /home/bigdata/hadoop/journal/hadoop1/current/edits_0000000054649908467-0000000054650023722\n2017-07-06 17:22:59,927 INFO org.apache.hadoop.hdfs.qjournal.server.Journal: Updating lastWriterEpoch from 23 to 24 for client /hostname2\n\n\ngc log\n2017-07-06T17:18:05.519+0800: 36901803.972: [GC2017-07-06T17:18:05.521+0800: 36901803.975: [ParNew: 7064064K->67185K(8738176K), 0.2323100 secs] 51648481K->44652702K(82138496K), 0.2362590 secs] [Times: user=2.64 sys=0.03, real=0.23 secs] \n2017-07-06T17:18:18.967+0800: 36901817.421: [GC2017-07-06T17:18:18.970+0800: 36901817.423: [ParNew: 7057777K->79674K(8738176K), 0.1799340 secs] 51643294K->44666348K(82138496K), 0.1840240 secs] [Times: user=2.84 sys=0.00, real=0.19 secs] \n2017-07-06T17:18:38.142+0800: 36901836.596: [GC2017-07-06T17:18:38.145+0800: 36901836.598: [ParNew: 7070266K->55166K(8738176K), 0.1605790 secs] 51656940K->44643432K(82138496K), 0.1637720 secs] [Times: user=2.64 sys=0.00, real=0.17 secs] \n2017-07-06T17:18:52.320+0800: 36901850.773: [GC2017-07-06T17:18:52.322+0800: 36901850.776: [ParNew: 7045758K->62376K(8738176K), 0.1141060 secs] 51634024K->44652240K(82138496K), 0.1179480 secs] [Times: user=1.56 sys=0.01, real=0.12 secs] \n2017-07-06T17:19:04.957+0800: 36901863.411: [GC2017-07-06T17:19:04.960+0800: 36901863.414: [ParNew: 7052968K->63039K(8738176K), 0.1575490 secs] 51642832K->44653620K(82138496K), 0.1620030 secs] [Times: user=2.04 sys=0.01, real=0.17 secs] \n2017-07-06T17:19:19.620+0800: 36901878.073: [GC2017-07-06T17:19:19.622+0800: 36901878.075: [ParNew: 7053631K->61205K(8738176K), 0.1163170 secs] 51644212K->44652939K(82138496K), 0.1204990 secs] [Times: user=1.82 sys=0.02, real=0.13 secs] \n2017-07-06T17:19:37.739+0800: 36901896.192: [GC2017-07-06T17:19:37.741+0800: 36901896.195: [ParNew: 7051797K->60432K(8738176K), 0.1181070 secs] 51643531K->44653501K(82138496K), 0.1213480 secs] [Times: user=1.89 sys=0.00, real=0.12 secs] \n2017-07-06T17:19:52.404+0800: 36901910.857: [GC2017-07-06T17:19:52.406+0800: 36901910.860: [ParNew: 7051024K->65565K(8738176K), 0.1908720 secs] 51644093K->44660271K(82138496K), 0.1942620 secs] [Times: user=2.71 sys=0.00, real=0.20 secs] \n2017-07-06T17:20:07.543+0800: 36901925.997: [GC2017-07-06T17:20:07.545+0800: 36901925.999: [ParNew: 7056157K->67362K(8738176K), 0.1630430 secs] 51650863K->44662989K(82138496K), 0.1662440 secs] [Times: user=2.35 sys=0.02, real=0.17 secs] \n2017-07-06T17:20:22.728+0800: 36901941.181: [GC2017-07-06T17:20:22.730+0800: 36901941.184: [ParNew: 7057662K->84616K(8738176K), 0.2662860 secs] 51653290K->44681927K(82138496K), 0.2696280 secs] [Times: user=4.49 sys=0.00, real=0.27 secs]","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=liemlin","name":"liemlin","key":"liemlin","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"linhaiqiang","active":true,"timeZone":"Etc/UTC"},"created":"2017-07-12T07:47:19.194+0000","updated":"2017-07-12T07:47:19.194+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12895745/comment/16173853","id":"16173853","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=arpitagarwal","name":"arpitagarwal","key":"arpitagarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arpit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"body":"Hard to say what was causing this issue. The user/dev list is a better place to bring this up.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=arpitagarwal","name":"arpitagarwal","key":"arpitagarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arpit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-09-20T21:24:17.444+0000","updated":"2017-09-20T21:24:17.444+0000"}],"maxResults":5,"total":5,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-9126/votes","votes":2,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i2lgav:"}}