{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"13174733","self":"https://issues.apache.org/jira/rest/api/2/issue/13174733","key":"HDFS-13768","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":"2018-09-01T08:34:21.747+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Tue Sep 04 08:17:34 UTC 2018","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-13768/watchers","watchCount":8,"isWatching":false},"created":"2018-07-26T05:38:24.564+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"1.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12341434","id":"12341434","description":"3.1.0 release","name":"3.1.0","archived":false,"released":true,"releaseDate":"2018-04-06"}],"issuelinks":[],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=RANith","name":"RANith","key":"ranith","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10432"},"displayName":"Ranith Sardar","active":true,"timeZone":"Asia/Kolkata"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2018-09-04T08:18:01.346+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/10002","description":"A patch for this issue has been uploaded to JIRA by a contributor.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/document.png","name":"Patch Available","id":"10002","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/4","id":4,"key":"indeterminate","colorName":"yellow","name":"In Progress"}},"components":[],"timeoriginalestimate":null,"description":"We find DN starting so slowly when rolling upgrade our cluster. When we restart DNs, the DNs start so slowly and not register to NN immediately. And this cause a lots of following error:\r\n{noformat}\r\nDataXceiver error processing WRITE_BLOCK operation  src: /xx.xx.xx.xx:64360 dst: /xx.xx.xx.xx:50010\r\njava.io.IOException: Not ready to serve the block pool, BP-1508644862-xx.xx.xx.xx-1493781183457.\r\n        at org.apache.hadoop.hdfs.server.datanode.DataXceiver.checkAndWaitForBP(DataXceiver.java:1290)\r\n        at org.apache.hadoop.hdfs.server.datanode.DataXceiver.checkAccess(DataXceiver.java:1298)\r\n        at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:630)\r\n        at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:169)\r\n        at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:106)\r\n        at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:246)\r\n        at java.lang.Thread.run(Thread.java:745)\r\n{noformat}\r\n\r\nLooking into the logic of DN startup, it will do the initial block pool operation before the registration. And during initializing block pool operation, we found the adding replicas to volume map is the most expensive operation.  Related log:\r\n{noformat}\r\n2018-07-26 10:46:23,771 INFO [Thread-105] org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1508644862-xx.xx.xx.xx-1493781183457 on volume /home/hard_disk/1/dfs/dn/current: 242722ms\r\n2018-07-26 10:46:26,231 INFO [Thread-109] org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1508644862-xx.xx.xx.xx-1493781183457 on volume /home/hard_disk/5/dfs/dn/current: 245182ms\r\n2018-07-26 10:46:32,146 INFO [Thread-112] org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1508644862-xx.xx.xx.xx-1493781183457 on volume /home/hard_disk/8/dfs/dn/current: 251097ms\r\n2018-07-26 10:47:08,283 INFO [Thread-106] org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1508644862-xx.xx.xx.xx-1493781183457 on volume /home/hard_disk/2/dfs/dn/current: 287235ms\r\n{noformat}\r\n\r\nCurrently DN uses independent thread to scan and add replica for each volume, but we still need to wait the slowest thread to finish its work. So the main problem here is that we could make the thread to run faster.\r\n\r\nThe jstack we get when DN blocking in the adding replica:\r\n{noformat}\r\n\"Thread-113\" #419 daemon prio=5 os_prio=0 tid=0x00007f40879ff000 nid=0x145da runnable [0x00007f4043a38000]\r\n   java.lang.Thread.State: RUNNABLE\r\n\tat java.io.UnixFileSystem.list(Native Method)\r\n\tat java.io.File.list(File.java:1122)\r\n\tat java.io.File.listFiles(File.java:1207)\r\n\tat org.apache.hadoop.fs.FileUtil.listFiles(FileUtil.java:1165)\r\n\tat org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice.addToReplicasMap(BlockPoolSlice.java:445)\r\n\tat org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice.addToReplicasMap(BlockPoolSlice.java:448)\r\n\tat org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice.addToReplicasMap(BlockPoolSlice.java:448)\r\n\tat org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice.getVolumeMap(BlockPoolSlice.java:342)\r\n\tat org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImpl.getVolumeMap(FsVolumeImpl.java:864)\r\n\tat org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeList$1.run(FsVolumeList.java:191)\r\n{noformat}\r\n\r\nOne improvement maybe we can use ForkJoinPool to do this recursive task, rather than a sync way. This will be a great improvement because it can greatly speed up recovery process.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12341705","id":"12341705","description":"2.10.0 release","name":"2.10.0","archived":false,"released":false},{"self":"https://issues.apache.org/jira/rest/api/2/version/12342772","id":"12342772","description":"","name":"3.2.0","archived":false,"released":false},{"self":"https://issues.apache.org/jira/rest/api/2/version/12343763","id":"12343763","description":"3.1.2 release","name":"3.1.2","archived":false,"released":false}],"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12937996","id":"12937996","filename":"HDFS-13768.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=RANith","name":"RANith","key":"ranith","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10432"},"displayName":"Ranith Sardar","active":true,"timeZone":"Asia/Kolkata"},"created":"2018-09-01T08:00:11.178+0000","size":4552,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12937996/HDFS-13768.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":" Adding replicas to volume map makes DataNode start slowly ","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=linyiqun","name":"linyiqun","key":"linyiqun","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=linyiqun&avatarId=25258","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=linyiqun&avatarId=25258","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=linyiqun&avatarId=25258","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=linyiqun&avatarId=25258"},"displayName":"Yiqun Lin","active":true,"timeZone":"Asia/Shanghai"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=linyiqun","name":"linyiqun","key":"linyiqun","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=linyiqun&avatarId=25258","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=linyiqun&avatarId=25258","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=linyiqun&avatarId=25258","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=linyiqun&avatarId=25258"},"displayName":"Yiqun Lin","active":true,"timeZone":"Asia/Shanghai"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/13174733/comment/16599573","id":"16599573","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=RANith","name":"RANith","key":"ranith","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10432"},"displayName":"Ranith Sardar","active":true,"timeZone":"Asia/Kolkata"},"body":"According to code structure, each thread of volumes will call getVolumeMap and add replicas under the given directory to the volume map is recursive call. As we can see, thread result will be in hold until all thread completes their performances. For recursive call in addToReplicasMap() method, will take more time for more sub-dirs (depended).\r\n\r\n*Solutions:*\r\n * Declare a common ForkJoinPool in BlockPoolSlice.\r\n * Considering all call for addToReplicasMap() as a single task. Submitting them to common ForkJoinPool.\r\n * forkpoolSize is considered as half of core size, because processor will busy with other works.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=RANith","name":"RANith","key":"ranith","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10432"},"displayName":"Ranith Sardar","active":true,"timeZone":"Asia/Kolkata"},"created":"2018-09-01T08:34:21.747+0000","updated":"2018-09-01T08:34:21.747+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13174733/comment/16601796","id":"16601796","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 24s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |\r\n|| || || || {color:brown} trunk Compile Tests {color} ||\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 19m 46s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 57s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 51s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  5s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 13m  5s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 57s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 49s{color} | {color:green} trunk passed {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m  1s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 54s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 54s{color} | {color:green} the patch passed {color} |\r\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 47s{color} | {color:orange} hadoop-hdfs-project/hadoop-hdfs: The patch generated 12 new + 16 unchanged - 0 fixed = 28 total (was 16) {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 59s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 12m 15s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 58s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 45s{color} | {color:green} the patch passed {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 96m 53s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 31s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black}154m 40s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Reason || Tests ||\r\n| Failed junit tests | hadoop.hdfs.TestDFSUpgradeFromImage |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailureWithRandomECPolicy |\r\n|   | hadoop.hdfs.TestPersistBlocks |\r\n|   | hadoop.hdfs.TestDatanodeStartupFixesLegacyStorageIDs |\r\n|   | hadoop.hdfs.server.datanode.TestDataNodeRollingUpgrade |\r\n|   | hadoop.hdfs.TestDatanodeLayoutUpgrade |\r\n|   | hadoop.hdfs.server.datanode.TestDataNodeHotSwapVolumes |\r\n|   | hadoop.hdfs.server.datanode.TestDeleteBlockPool |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:ba1ab08 |\r\n| JIRA Issue | HDFS-13768 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12937996/HDFS-13768.patch |\r\n| Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |\r\n| uname | Linux 439cf7342730 3.13.0-153-generic #203-Ubuntu SMP Thu Jun 14 08:52:28 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | /testptch/patchprocess/precommit/personality/provided.sh |\r\n| git revision | trunk / ff036e4 |\r\n| maven | version: Apache Maven 3.3.9 |\r\n| Default Java | 1.8.0_181 |\r\n| findbugs | v3.1.0-RC1 |\r\n| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/24937/artifact/out/diff-checkstyle-hadoop-hdfs-project_hadoop-hdfs.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/24937/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |\r\n|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/24937/testReport/ |\r\n| Max. process+thread count | 2973 (vs. ulimit of 10000) |\r\n| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |\r\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/24937/console |\r\n| Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2018-09-03T06:15:13.629+0000","updated":"2018-09-03T06:15:13.629+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13174733/comment/16602728","id":"16602728","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=surendrasingh","name":"surendrasingh","key":"surendrasingh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=surendrasingh&avatarId=30759","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=surendrasingh&avatarId=30759","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=surendrasingh&avatarId=30759","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=surendrasingh&avatarId=30759"},"displayName":"Surendra Singh Lilhore","active":true,"timeZone":"Etc/UTC"},"body":"Thanks [~RANith] for patch.\r\n\r\nSome review comment \r\n\r\n1. You can start you first task in BlockPoolSlice#getVolumeMap() and then BlockPoolSlice#addToReplicasMap() can submit the sub task when item is directory.\r\n{code:java}\r\n    if (!success) {\r\n      // add finalized replicas\r\n      addToReplicasMap(volumeMap, finalizedDir, lazyWriteReplicaMap, true);\r\n      // add rbw replicas\r\n      addToReplicasMap(volumeMap, rbwDir, lazyWriteReplicaMap, false);\r\n    }\r\n{code}\r\nThis can be changed to\r\n{code:java}\r\n     if (!success) {\r\n       // add finalized replicas\r\n      AddReplicaProcessor task = new AddReplicaProcessor(volumeMap,\r\n          finalizedDir, lazyWriteReplicaMap, true);\r\n      forkJoinPool.invoke(task);\r\n       // add rbw replicas\r\n      task = new AddReplicaProcessor(volumeMap, rbwDir, lazyWriteReplicaMap,\r\n          false);\r\n      forkJoinPool.invoke(task);\r\n     }\r\n{code}\r\n2. You used {{forkJoinPool.invoke()}} in BlockPoolSlice#addToReplicasMap(). It will wait till the task is finished. You need to use here {{task.fork()}}.\r\n{code:java}\r\n+        forkJoinPool.invoke(new AddReplicaProcessor(volumeMap, file,\r\n+            lazyWriteReplicaMap, isFinalized));\r\n{code}\r\ninstead of this use\r\n{code:java}\r\n+            AddReplicaProcessor task = new AddReplicaProcessor(volumeMap, file,\r\n+                lazyWriteReplicaMap, isFinalized);\r\n+            task.fork();\r\n{code}\r\n3. line 78, you shutdown the {{forkJoinPool}}. This may be by mistake. Pls check once.\r\n{code:java}\r\n+      forkJoinPool.shutdown();\r\n{code}\r\n4. What if the exception occur's in {{AddReplicaProcessor}} ?, you need to report it back to the next level.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=surendrasingh","name":"surendrasingh","key":"surendrasingh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=surendrasingh&avatarId=30759","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=surendrasingh&avatarId=30759","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=surendrasingh&avatarId=30759","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=surendrasingh&avatarId=30759"},"displayName":"Surendra Singh Lilhore","active":true,"timeZone":"Etc/UTC"},"created":"2018-09-04T08:17:34.351+0000","updated":"2018-09-04T08:18:01.339+0000"}],"maxResults":3,"total":3,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-13768/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i3wbzr:"}}