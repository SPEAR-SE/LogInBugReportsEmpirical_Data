{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12408551","self":"https://issues.apache.org/jira/rest/api/2/issue/12408551","key":"HDFS-142","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12315103","id":"12315103","description":"Append/sync support for Hadoop 0.20","name":"0.20-append","archived":true,"released":false},{"self":"https://issues.apache.org/jira/rest/api/2/version/12316392","id":"12316392","description":"Merge append/sync support with security","name":"0.20.205.0","archived":false,"released":true,"releaseDate":"2011-10-06"}],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2008-11-15T01:04:01.161+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Wed Oct 19 00:26:07 UTC 2011","customfield_12310420":"16725","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_50016903388_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2010-06-16T22:30:26.295+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-142/watchers","watchCount":8,"isWatching":false},"created":"2008-11-15T00:55:22.907+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/1","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/blocker.svg","name":"Blocker","id":"1"},"labels":[],"customfield_12312333":null,"customfield_12310230":"hbase","customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"25.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12315103","id":"12315103","description":"Append/sync support for Hadoop 0.20","name":"0.20-append","archived":true,"released":false}],"issuelinks":[{"id":"12322900","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12322900","type":{"id":"12310010","name":"Incorporates","inward":"is part of","outward":"incorporates","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/12310010"},"outwardIssue":{"id":"12411972","key":"HADOOP-4997","self":"https://issues.apache.org/jira/rest/api/2/issue/12411972","fields":{"summary":"workaround for tmp file handling on DataNodes in 0.18 (HADOOP-4663)","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/1","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/blocker.svg","name":"Blocker","id":"1"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12322878","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12322878","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"12411898","key":"HDFS-57","self":"https://issues.apache.org/jira/rest/api/2/issue/12411898","fields":{"summary":"A Datanode's datadir could have lots of blocks in the top-level directory","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12322457","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12322457","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"12408955","key":"HADOOP-4702","self":"https://issues.apache.org/jira/rest/api/2/issue/12408955","fields":{"summary":"Failed block replication leaves an incomplete block in receiver's tmp data directory","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/1","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/blocker.svg","name":"Blocker","id":"1"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12322625","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12322625","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"12410301","key":"HADOOP-4810","self":"https://issues.apache.org/jira/rest/api/2/issue/12410301","fields":{"summary":"Data lost at cluster startup time","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/1","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/blocker.svg","name":"Blocker","id":"1"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12324741","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12324741","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"12423724","key":"HDFS-29","self":"https://issues.apache.org/jira/rest/api/2/issue/12423724","fields":{"summary":"In Datanode, update block may fail due to length inconsistency","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12332360","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12332360","type":{"id":"10001","name":"dependent","inward":"is depended upon by","outward":"depends upon","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10001"},"outwardIssue":{"id":"12396337","key":"HDFS-101","self":"https://issues.apache.org/jira/rest/api/2/issue/12396337","fields":{"summary":"DFS write pipeline : DFSClient sometimes does not detect second datanode failure ","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/1","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/blocker.svg","name":"Blocker","id":"1"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12332362","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12332362","type":{"id":"10001","name":"dependent","inward":"is depended upon by","outward":"depends upon","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10001"},"outwardIssue":{"id":"12441999","key":"HDFS-793","self":"https://issues.apache.org/jira/rest/api/2/issue/12441999","fields":{"summary":"DataNode should first receive the whole packet ack message before it constructs and sends its own ack message for the packet","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/1","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/blocker.svg","name":"Blocker","id":"1"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12330881","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12330881","type":{"id":"10001","name":"dependent","inward":"is depended upon by","outward":"depends upon","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10001"},"outwardIssue":{"id":"12456712","key":"HDFS-988","self":"https://issues.apache.org/jira/rest/api/2/issue/12456712","fields":{"summary":"saveNamespace race can corrupt the edits log","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/1","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/blocker.svg","name":"Blocker","id":"1"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12331885","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12331885","type":{"id":"10001","name":"dependent","inward":"is depended upon by","outward":"depends upon","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10001"},"outwardIssue":{"id":"12435178","key":"HDFS-606","self":"https://issues.apache.org/jira/rest/api/2/issue/12435178","fields":{"summary":"ConcurrentModificationException in invalidateCorruptReplicas()","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12332361","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12332361","type":{"id":"10001","name":"dependent","inward":"is depended upon by","outward":"depends upon","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10001"},"outwardIssue":{"id":"12443029","key":"HDFS-826","self":"https://issues.apache.org/jira/rest/api/2/issue/12443029","fields":{"summary":"Allow a mechanism for an application to detect that datanode(s)  have died in the write pipeline","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/4","id":"4","description":"An improvement or enhancement to an existing feature or task.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype","name":"Improvement","subtask":false,"avatarId":21140}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2013-05-02T02:29:32.820+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[],"timeoriginalestimate":null,"description":"Before 0.18, when Datanode restarts, it deletes files under data-dir/tmp  directory since these files are not valid anymore. But in 0.18 it moves these files to normal directory incorrectly making them valid blocks. One of the following would work :\n\n- remove the tmp files during upgrade, or\n- if the files under /tmp are in pre-18 format (i.e. no generation), delete them.\n\nCurrently effect of this bug is that, these files end up failing block verification and eventually get deleted. But cause incorrect over-replication at the namenode before that.\n\nAlso it looks like our policy regd treating files under tmp needs to be defined better. Right now there are probably one or two more bugs with it. Dhruba, please file them if you rememeber.\n","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12444438","id":"12444438","filename":"appendFile-recheck-lease.txt","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2010-05-13T23:34:19.817+0000","size":6103,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12444438/appendFile-recheck-lease.txt"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12399438","id":"12399438","filename":"appendQuestions.txt","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"created":"2009-02-04T09:09:38.989+0000","size":8100,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12399438/appendQuestions.txt"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12397355","id":"12397355","filename":"deleteTmp_0.18.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"created":"2009-01-07T23:49:23.630+0000","size":1720,"mimeType":"text/x-diff","content":"https://issues.apache.org/jira/secure/attachment/12397355/deleteTmp_0.18.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12394276","id":"12394276","filename":"deleteTmp.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"created":"2008-11-19T20:04:23.276+0000","size":5802,"mimeType":"text/x-diff","content":"https://issues.apache.org/jira/secure/attachment/12394276/deleteTmp.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12397237","id":"12397237","filename":"deleteTmp2.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"created":"2009-01-06T22:43:23.613+0000","size":13575,"mimeType":"text/x-diff","content":"https://issues.apache.org/jira/secure/attachment/12397237/deleteTmp2.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12438903","id":"12438903","filename":"deleteTmp5_20.txt","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"created":"2010-03-16T07:10:20.469+0000","size":33185,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12438903/deleteTmp5_20.txt"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12438876","id":"12438876","filename":"deleteTmp5_20.txt","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"created":"2010-03-15T23:37:24.298+0000","size":35669,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12438876/deleteTmp5_20.txt"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12444625","id":"12444625","filename":"dont-recover-rwr-when-rbw-available.txt","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2010-05-17T00:19:01.744+0000","size":24901,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12444625/dont-recover-rwr-when-rbw-available.txt"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12397947","id":"12397947","filename":"handleTmp1.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"created":"2009-01-15T07:12:11.601+0000","size":9224,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12397947/handleTmp1.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12439399","id":"12439399","filename":"HDFS-142_20.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=nspiegelberg","name":"nspiegelberg","key":"nspiegelberg","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Nicolas Spiegelberg","active":true,"timeZone":"America/Los_Angeles"},"created":"2010-03-21T07:33:25.323+0000","size":55447,"mimeType":"text/x-diff","content":"https://issues.apache.org/jira/secure/attachment/12439399/HDFS-142_20.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12446645","id":"12446645","filename":"HDFS-142_20-append2.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=nspiegelberg","name":"nspiegelberg","key":"nspiegelberg","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Nicolas Spiegelberg","active":true,"timeZone":"America/Los_Angeles"},"created":"2010-06-08T23:55:52.079+0000","size":86288,"mimeType":"text/x-diff","content":"https://issues.apache.org/jira/secure/attachment/12446645/HDFS-142_20-append2.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12492791","id":"12492791","filename":"HDFS-142.20-security.1.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jnp","name":"jnp","key":"jnp","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jitendra Nath Pandey","active":true,"timeZone":"Etc/UTC"},"created":"2011-09-02T18:59:59.707+0000","size":90228,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12492791/HDFS-142.20-security.1.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12492805","id":"12492805","filename":"HDFS-142.20-security.2.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jnp","name":"jnp","key":"jnp","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jitendra Nath Pandey","active":true,"timeZone":"Etc/UTC"},"created":"2011-09-02T20:32:29.568+0000","size":91484,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12492805/HDFS-142.20-security.2.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12443011","id":"12443011","filename":"hdfs-142-commitBlockSynchronization-unknown-datanode.txt","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2010-04-27T22:11:12.863+0000","size":1913,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12443011/hdfs-142-commitBlockSynchronization-unknown-datanode.txt"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12442490","id":"12442490","filename":"HDFS-142-deaddn-fix.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=nspiegelberg","name":"nspiegelberg","key":"nspiegelberg","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Nicolas Spiegelberg","active":true,"timeZone":"America/Los_Angeles"},"created":"2010-04-21T23:15:33.802+0000","size":3321,"mimeType":"text/x-diff","content":"https://issues.apache.org/jira/secure/attachment/12442490/HDFS-142-deaddn-fix.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12442916","id":"12442916","filename":"HDFS-142-finalize-fix.txt","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rash37","name":"rash37","key":"rash37","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"sam rash","active":true,"timeZone":"America/Los_Angeles"},"created":"2010-04-27T01:27:21.671+0000","size":7058,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12442916/HDFS-142-finalize-fix.txt"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12439424","id":"12439424","filename":"hdfs-142-minidfs-fix-from-409.txt","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2010-03-21T23:00:28.170+0000","size":2182,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12439424/hdfs-142-minidfs-fix-from-409.txt"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12440085","id":"12440085","filename":"HDFS-142-multiple-blocks-datanode-exception.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=karthik.ranga","name":"karthik.ranga","key":"karthik.ranga","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Karthik Ranganathan","active":true,"timeZone":"America/Los_Angeles"},"created":"2010-03-29T18:04:41.251+0000","size":3465,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12440085/HDFS-142-multiple-blocks-datanode-exception.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12443682","id":"12443682","filename":"hdfs-142-recovery-reassignment-and-bbw-cleanup.txt","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2010-05-05T05:57:32.313+0000","size":19119,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12443682/hdfs-142-recovery-reassignment-and-bbw-cleanup.txt"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12443012","id":"12443012","filename":"hdfs-142-testcases.txt","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2010-04-27T22:11:12.947+0000","size":8499,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12443012/hdfs-142-testcases.txt"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12443733","id":"12443733","filename":"hdfs-142-testleaserecovery-fix.txt","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2010-05-05T16:55:53.553+0000","size":4783,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12443733/hdfs-142-testleaserecovery-fix.txt"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12444435","id":"12444435","filename":"recentInvalidateSets-assertion-fix.txt","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2010-05-13T22:48:11.893+0000","size":1352,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12444435/recentInvalidateSets-assertion-fix.txt"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12446519","id":"12446519","filename":"recover-rbw-v2.txt","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2010-06-07T20:33:38.122+0000","size":27171,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12446519/recover-rbw-v2.txt"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12442399","id":"12442399","filename":"testfileappend4-deaddn.txt","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2010-04-21T06:04:33.987+0000","size":2195,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12442399/testfileappend4-deaddn.txt"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12444373","id":"12444373","filename":"validateBlockMetaData-synchronized.txt","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2010-05-13T01:59:43.246+0000","size":911,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12444373/validateBlockMetaData-synchronized.txt"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"14240","customfield_12312823":null,"summary":"In 0.20, move blocks being written into a blocksBeingWritten directory","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12647779","id":"12647779","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"body":"I would probably take the first approach of deleting the tmp files during the upgrade. Related JIRAs are HADOOP-3677 and HADOOP-2656","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"created":"2008-11-15T01:04:01.161+0000","updated":"2008-11-15T01:04:01.161+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12647803","id":"12647803","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"body":"recoverTransitionRead invokes doUpgrade(). I plan to put in a check in doUpgrade() to remove the tmp directories from all storage directories. It is not very elegant, because doUpgrade() now needs to know that each storage dir contains a \"tmp\" directory, if anybody has any other suggestion for code layout, please let me know.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"created":"2008-11-15T07:41:06.087+0000","updated":"2008-11-15T07:41:06.087+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12647888","id":"12647888","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"body":"Why not simply delete the block files that are not in 'genstamp' format? This does not depend on upgrade at all. This is how DN handles assigning default generation number initially.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-11-15T18:23:03.506+0000","updated":"2008-11-15T18:23:03.506+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12648264","id":"12648264","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"body":"Actualy, on second thoughts, this does not seem to be a bug. For example, let's say that we have a cluster that is running 0.20 release of hadoop. When you restart a datanode, all files in the \"tmp\" directory need to be moved to the real block directory. The reason being that a FileSystem.sync() call demands that data once written to the datanode should persist. Thus, the problem you are seeing is not related to cluster upgrade.\n\nâ‰¥these files end up failing block verification and eventually get deleted. But cause incorrect over-replication at the namenode before that.\n\nMaybe we should try to improve the situation here. Is it possible to put the blocks that got moved from \"tmp\" to the real block directory at the head of the block-to-verify list so that their CRC validation occur first? \n\nAnother optimization (that i do not particularly like) is that the client can tell the datanode if the client has invoked FileSystem.sync(). The Datanode can persist this information. At datanode startup time, the Datanode moves only those blocks that were marked as \"synced\" earlier.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"created":"2008-11-17T19:23:24.363+0000","updated":"2008-11-17T19:23:24.363+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12648271","id":"12648271","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"body":"Dhruba, these files are invalid at least on 0.17,  and should not used next restart, no?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-11-17T19:28:40.968+0000","updated":"2008-11-17T19:28:40.968+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12648279","id":"12648279","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"body":"Block verification failure was actually a fortunate side effect that detected this bug. It is not a fix.  Marking invalid blocks valid looks to me like a real data corruption and should not be allowed at all.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-11-17T19:35:09.858+0000","updated":"2008-11-17T19:35:09.858+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12648295","id":"12648295","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"body":"Yeah, I agree. In the general case, the generation stamp incompability will cause these invalid blocks to get deleted. But the 0.18 upgrade allocates a generation stamp of 0 for all old blocks. This is a bug that should be fixed. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"created":"2008-11-17T19:59:04.825+0000","updated":"2008-11-17T19:59:04.825+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12649147","id":"12649147","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"body":"Here is the first version of the patch. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"created":"2008-11-19T20:04:23.302+0000","updated":"2008-11-19T20:04:23.302+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12649157","id":"12649157","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"body":"Some description of what the patch does would be helpful for review.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-11-19T20:27:05.310+0000","updated":"2008-11-19T20:27:05.310+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12649170","id":"12649170","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"body":"When a Datanode restarts, it attempts to move all file from the \"tmp\" directory to the block directory. \n\nWhat this patch does: If a file does not have a generation stamp associated with it, then it is not moved. The generation stamp is extracted form the corresponding metafile. The metafile could be in the tmp directory itself or it could already be in the block directory.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"created":"2008-11-19T21:38:25.062+0000","updated":"2008-11-19T21:38:25.062+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12650078","id":"12650078","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"body":"Hi Raghu, do you have any feedback on the patch I posted earlier? Thanks","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"created":"2008-11-23T23:19:24.527+0000","updated":"2008-11-23T23:19:24.527+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12650706","id":"12650706","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"body":"I will review this today. Did you get a chance to file the bug on rest of the issues related to files under tmp directory? Could you link that bug to this one? I think these are serious issues since these are essentially data corruptions.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-11-25T19:57:33.213+0000","updated":"2008-11-25T19:57:33.213+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12650871","id":"12650871","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"body":"The other bug is HADOOP-4702.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"created":"2008-11-26T06:19:40.117+0000","updated":"2008-11-26T06:19:40.117+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12650875","id":"12650875","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"body":"hmm.. these are all side effects of the basic problem :  Datanode does not know which files under /tmp are good and which are not. Before 0.18, all the files were bad. \n\nMy preference would to fix this problem (in addition to HADOOP-4702), since it affects other things. There is another case where after an error, lease recovery succeeds one hour later on the datanode since DN thinks its temporary files are good.. resulting an another corrupt block. There could be more.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-11-26T06:48:48.615+0000","updated":"2008-11-26T06:48:48.615+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12650877","id":"12650877","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"body":"I agree that we need to solve HADOOP-4702. \n\n>here is another case ease recovery succeeds one hour later on the datanode since DN thinks its temporary files are good.. resulting an another corrupt block.\n\nCan you pl explain this scenario in greater detail? If the client encountered an error and exited, then the write was never completed. How did it create a corrupt block?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"created":"2008-11-26T06:56:01.105+0000","updated":"2008-11-26T06:56:01.105+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12651094","id":"12651094","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"body":"\nNicholas has more details on the problem and thinks HADOOP-3574 would fix it. But I am not sure this approach of fixing each of the side effects as they are detected is a good one.\n\nIt looks very error prone and wrong for datanode to not know which files under tmp are invalid since 0.18. do you not see that as a real problem?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-11-26T18:41:39.566+0000","updated":"2008-11-26T18:41:39.566+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12651101","id":"12651101","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi Raghu, I did not following this issue close enough.  Why \"datanode to not know which files under tmp are invalid since 0.18\"?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-11-26T18:48:44.438+0000","updated":"2008-11-26T18:48:44.438+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12651105","id":"12651105","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"body":"> Why \"datanode to not know which files under tmp are invalid since 0.18\"? \nIt just does not. Thats why it moves them to normal directory (this jira and HADOOP-4702), and incorrectly 'recovers' (HADOOP-3574) etc. \n\nWhy? Because it does not have anything to distinguish between valid and invalid. Note that before 0.18 everything there is invalid.. Since you guys implemented it, it is better for you to explain :-), I guess.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-11-26T18:59:05.686+0000","updated":"2008-11-26T18:59:05.686+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12652485","id":"12652485","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"body":"Regd the patch : \n\n- Did you test the patch?\n- It looks like it still moves meta files to data directory (removes the actual block file).\n- Not sure why we check datanode's data directory for metadata file.. even if it exists, it would mostly be in some sub directory under datadir.\n     -- Related to the above : from the logic it looks like this might leave more than one metadata file in ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-12-02T20:07:22.755+0000","updated":"2008-12-02T20:07:22.755+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12659907","id":"12659907","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"body":"Thanks Raghu. I will restart work on this one.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"created":"2008-12-30T19:47:11.311+0000","updated":"2008-12-30T19:47:11.311+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12661364","id":"12661364","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"body":"When a datanode receives a replication request, it starts the block in a separate directory. These blocks will be cleaned up when the datanode restarts. The general algorithm is as follows:\n\n1. When a datanode receives a block from a client, it starts the block in datadir/tmp directory.\n2. When a datanode receives a block as part of a replication request, it starts the block in datadir//tmp_replication directory\n3. When a block is finalised, it moves from any of the above two temporary directories to its final location.\n4. When a datanode restarts, it moves all the blocks from datadir/tmp directory to their final location. These blocsk were part of writes by clients and the client-namenode-genstamp protocol will ensure that the most-uptodate replicas of the block will be maintained.\n4. When a datanode restarts, the blocks in datadir/tmp_replication directory are removed. No recovery is needed for these blocks.\n\nThe question that remains is what do we need to do for blocks that are moved as part of rebalancer? I think the blocks that rebalancer moves should go into tmp_replication as well. \n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"created":"2009-01-06T22:43:23.653+0000","updated":"2009-01-06T22:43:23.653+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12661673","id":"12661673","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"body":"A few comments :\n\n-  since only the blocks that were part of writes could be valid, it it better to create them in \"tmp_valid\" or \"tmp_writes\" directory?\n- The rest of the blocks in tmp will be deleted automatically. This fixes the rebalancer issue as well. We can not leave any possible corruptions.\n\n- It is very crucial that any files left over should not cause corruption that we have already seen. \n    -- Simpler and better alternative for 0.18.3 might be to just say sync() is not supported and remove everything under tmp (same as 0.17).\n    -- This way it gives more time this jira to make sure there are no cases where it could cause corruption. \n\n- The patch move all the files to top level directory. But datanode data directories are organized to limit each directory to 64 blocks and 64 subdirectories. The current policy violates that. Overtime datanodes could end up having very large number of files in top level directory.\n   -- But this is not very important to fix in 0.18.. but it should be fixed in 0.19 or another line. A seperate jira might help.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-01-07T19:32:39.664+0000","updated":"2009-01-07T19:32:39.664+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12661690","id":"12661690","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"body":"Creating multiple \"tmp\" directories seems to be an indication of the design flaw.\nThe question is why do we need to place the blocks that will be recovered to the main storage no matter what in a temporary directory instead of storing them in the main storage from the very beginning?\nAlso, I don't see any \"proof of correctness\" here. How do we know this will not lead to the same or other problems the way the initial code did?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-01-07T20:14:43.280+0000","updated":"2009-01-07T20:14:43.280+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12661698","id":"12661698","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"body":"When a client is writing to a block on the datanode, it is good to create it in the \"tmp\" directory instead of the real block directory. This means that the datanode has a record that these blocks are not yet finalized and might need some recovery. In the typical case, existence of a block in the \"tmp\" directory means that the block is not yet confirmed to the namenode. In the current code, it is the client that actually triggers the recovery. \n\nLike Raghu proposed, it might be a good idea to name the original \"tmp\" directory as \"tmp_writes\". In fact, the blocks here are not temporary any more. It can be named as \"blocks_inflight_dir\" or something like that. However, if we change it now, won't we need an upgrade  that can handle the case when the \"tmp\" directory existed?\n\n@Raghu: if we disable \"sync\" on 0.18.3, that will be an API incompatiblity from 0.18.2. Is that acceptable?\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"created":"2009-01-07T20:37:09.898+0000","updated":"2009-01-07T20:37:09.898+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12661700","id":"12661700","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"body":"> @Raghu: if we disable \"sync\" on 0.18.3, that will be an API incompatiblity from 0.18.2. Is that acceptable?\n\nI think that is ok. Of course we don't want to such a thing often but I am pretty sure most users would agree better to safe w.r.t data. At Y! no one is advised to use sync() and we are running with such a fix.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-01-07T20:43:08.200+0000","updated":"2009-01-07T20:43:08.200+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12661732","id":"12661732","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"body":"> In fact, the blocks here are not temporary any more.\n\nThis is the key. They are not temporary so why do we keep them in tmp directory? Why DNs cannot report them to the name-node? It is just a matter of reporting the right length, right?\n\n> disable \"sync\" on 0.18.3, will be an API incompatiblity from 0.18.2.\n\nThis is not incompatibility. The feature does not work correctly in 0.18.2 and it will still not work correctly in 0.18.3 with the advantage of not causing all the problems.\nI think removing everything under tmp as Raghu proposes is the right solution for 0.18.3.\nWe should talk about the \"real\" fix in terms of 0.19 and up. This seems to be a consensus among colleagues around me.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-01-07T21:57:01.367+0000","updated":"2009-01-07T21:57:01.367+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12661738","id":"12661738","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"body":"The namenode always discards replicas that are smaller in size than other replicas. It always keeps the largest-size replica as the valid one. So, can this bug affect data integrity? ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"created":"2009-01-07T22:16:01.803+0000","updated":"2009-01-07T22:16:01.803+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12661742","id":"12661742","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"body":"I will make a patch for 0.18 as Raghu/Konstantin suggested that disables the sync API. Will port it shortly.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"created":"2009-01-07T22:17:24.621+0000","updated":"2009-01-07T22:17:24.621+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12661782","id":"12661782","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"body":"Patch for 0.18. It throws an exception from the fsync() call and deletes all blocks from the \"tmp\" directory of the datadir. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"created":"2009-01-07T23:49:23.661+0000","updated":"2009-01-07T23:49:23.661+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12661788","id":"12661788","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"body":"+1 from me for 0.18.3 fix. We might need to disable one or two unit tests.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-01-08T00:04:52.815+0000","updated":"2009-01-08T00:04:52.815+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12661791","id":"12661791","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"body":"Yes, some unit tests have to be disabled for 0.18.\n\ni am still worried that the fix for 0.18.3 causes an API change. Maybe hbase has  to use it. Although I made the patch for 0.18, I am -1 for putting it into the general 018 release.  I can put in config variables to disable \"fsync\" if needed.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"created":"2009-01-08T00:14:55.811+0000","updated":"2009-01-08T00:14:55.811+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12661802","id":"12661802","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"body":"If you don't throw an exception from fsync() then there is now api change. In this case fsync() will work if data-nodes/clients don't fail it's just some sync-ed data may not survive cluster restarts. So hbase people will be able to write there programs with fsync(), but it will be guaranteed to work when they upgrade to newer versions where this issue is going to be fixed.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-01-08T01:09:47.363+0000","updated":"2009-01-08T01:09:47.363+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12661809","id":"12661809","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"body":"May be it makes sense to create a separate jira for the fix for 0.18.3 so that we could close it when its done and continue the discussion about the real fix here. Or vice versa.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-01-08T01:37:44.617+0000","updated":"2009-01-08T01:37:44.617+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12662104","id":"12662104","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"body":"filed HADOOP-4997 for temporary work around. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-01-08T20:22:33.842+0000","updated":"2009-01-08T20:22:33.842+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12662146","id":"12662146","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley","name":"owen.omalley","key":"owen.omalley","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=29697","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=29697","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=owen.omalley&avatarId=29697","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=owen.omalley&avatarId=29697"},"displayName":"Owen O'Malley","active":true,"timeZone":"America/Los_Angeles"},"body":"For 0.18.3, we absolutely can *not* throw on fsync. It would be much better to silently do nothing. There are too many applications where throwing would break them.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley","name":"owen.omalley","key":"owen.omalley","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=29697","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=29697","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=owen.omalley&avatarId=29697","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=owen.omalley&avatarId=29697"},"displayName":"Owen O'Malley","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-01-08T22:20:48.241+0000","updated":"2009-01-08T22:20:48.241+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12662154","id":"12662154","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"body":"\nMicheal Stack from HBase confirmed that HBase on 0.18 does not use sync.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-01-08T22:47:03.640+0000","updated":"2009-01-08T22:47:03.640+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12663042","id":"12663042","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"body":"Now that the 0.18.3 issues are handled by HADOOP-4997, let's discuss what we need to do for 0.19 and above. I propose that blocks that are created by client-writes be created in the \"tmp\" directory whereas blocks created by replcation requests be created in tmp_replication directory. On datanode restarts,  the blocks in the \"tmp\" directory are reclaimed whereas the blocks in tmp_replication directory are discarded.\n\nThe reason I propose to start client-generated blocks in the \"tmp\" directory (instead of the real block directory) is because these blocks are not yet confirmed to the namenode. They are still being written and ideally should not be included in any block report(s). ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"created":"2009-01-12T18:44:51.025+0000","updated":"2009-01-12T18:44:51.025+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12663850","id":"12663850","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"body":"I had an offline discussion with Sanjay, Rob Chansler, Nicholas and partly with Konstantin. Here is the summary:\n\nThis JIRA will go into 0.19. (For 0.18.3, the equivalent work will be done via HADOOP-4997).\n\nThe proposal is that blocks that are created by client-writes be created in the \"blocks_being_written\" directory whereas blocks created by replication requests be created in \"blocks_being_replicated\" directory. On datanode restarts, the blocks in the \"tmp\" directory and \"blocks_being_replicated\" directory are deleted whereas the blocks in \"blocks_being_written\" directory are recovered and promoted to the real block directory.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"created":"2009-01-14T18:52:31.246+0000","updated":"2009-01-14T18:52:31.246+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12663891","id":"12663891","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"body":"I think the proposed approach does not solve the problem.\nIt improves in a sense current state but does not eliminate the problem completely.\n\nThe idea of promoting blocks from \"tmp\" to the real storage is necessary to support sync(). We are trying to cover the following sequence of events:\n# a client starts writing to a block and says sync();\n# the data-node does the write and the sync() and then fails;\n# the data-node restarts and the sync-ed block should appear as a valid block on this node, because the semantic of sync demands the sync-ed data to survive failures of clients, data-nodes and the name-node.\n\nIt seams natural to promote blocks from tmp to the real storage during startup, but this caused problems because together with the sync-ed blocks the data-node also promotes all other potentially incomplete blocks from the tmp.\n\nOne source of incomplete blocks in tmp is the internal block replication initiated by the name-node but not completed on the data-node due to a failure. \n\n(I) The proposal is to divide tmp into 2 directories \n\"blocks_being_replicated\" and \"blocks_being_written\". This excludes partially replicated \nblocks from being promoted to the real storage during data-node restarts.\n\nBut this does not cover another source of incomplete blocks, which is the regular block writing by a client. It also can fail, remain incomplete, and will be promoted to the main storage during data-node restart.\nThe question is why do we not care about these blocks? \nWhy they cannot cause the same problems as the ones that are being replicated?\n\nSuppose I do not use sync-s. The incomplete blocks will still be promoted to the real storage, will be reported to the name-node and the name-node will have to process them and finally remove most of them. Isn't it a degradation in performance.\n\n(II) I'd rather consider dividing into two directories one having \"transient\" and another having \"persistent\" blocks. The transient blocks should be removed during startup, and persistent should be promoted into the real storage. Once sync-ed a block should be moved into the persistent directory.\n\n(III) Another variation is to promote sync-ed (persistent) blocks directly to the main storage. The problem here is to deal with blockReceived and blockReports, which I feel can be solved.\n\n(IV) Yet another approach is to keep the storage structure unchanged and write each sync-ed (finalized) portions of the block into main storage by appending that portion to the real block file. This will require an extra disk io for merging files (instead of renaming) but will let us discard everything that is in tmp as we do now.\n\nWhat we are trying to do with the directories is to assign properties to the block replicas and make them survive crashes. Previously there were just 2 properties final and transient. So we had 2 directories: tmp and main. Now we need a third property, which says the block is persistent but not finalized yet. So we tend to introduce yet another directory. I think this is too straightforward, because there is plenty of other approaches to implement boolean properties on entities.\nWhy we are not considering them?\n\nAlso worth noting this issue directly affects appends, because a replica being appended is first copied to the tmp directory and then treated as described above.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-01-14T21:23:29.663+0000","updated":"2009-01-14T21:23:29.663+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12663958","id":"12663958","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"body":"I think the issue that Konstantin is raising is based on the assumption that data that is not \"synced\" by a client *should not* appear in a file. This assumption is not true as specified in the design document for Appends. The guarantee is that data that is written prior to a \"sync\" call will be seen by all new readers of the file.\n\nJust like in any UNIX-y systems, data that is not \"sync\" can still be seen by other concurrent readers. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"created":"2009-01-15T01:02:38.264+0000","updated":"2009-01-15T01:02:38.264+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12664023","id":"12664023","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"body":"This patch creates all blocks that are part of client write request to be stored in blocksBeingWritten directory. Blocsk that are part of replication requests and created in blocksBeingReplicated directory. \n\nA datanode restarts removes all blocks from the \"tmp\" and blocksBeingReplicated directory and moves all blocks from the blocksBeingWritten directory into the real block directory.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"created":"2009-01-15T07:12:11.664+0000","updated":"2009-01-15T07:12:11.664+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12664338","id":"12664338","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"body":"I think the assumption Dhruba is making about my motivation is not true.\nThe problem is that the proposed *solution does not work*. \nAnd I said that in the first line of that long comment above.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-01-16T00:11:40.249+0000","updated":"2009-01-16T00:11:40.249+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12664640","id":"12664640","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"body":"Hi Konstantin, can you pl explain (sorry I was not able to understand it from your description even after reading it many many times) why the proposed solution and patch does not work?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"created":"2009-01-16T19:27:55.603+0000","updated":"2009-01-16T19:27:55.603+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12664701","id":"12664701","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chansler","name":"chansler","key":"chansler","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Robert Chansler","active":true,"timeZone":"America/Los_Angeles"},"body":"Large consensus (Dhruba, Nicholas, Sanjay, Konstantin, Rob) that this is not appropriate for 18.3. Hadoop:4997 will substitute for this in 18.3.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chansler","name":"chansler","key":"chansler","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Robert Chansler","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-01-16T22:09:06.877+0000","updated":"2009-01-16T22:09:06.877+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12665224","id":"12665224","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi Dhruba. There were several issues (we actually had a data loss) caused by promoting blocks from tmp to main storage. One of them is HADOOP-4702, which was probably when you were on vacation.\nThe problem was that partial blocks were promoted to the main storage even though they were transient.\nI am arguing that your solution does not eliminate this condition. blocksBeingWritten can still contain transient blocks and they will still be promoted to the main storage. A simple example is when you write a block (without using sync()) and the DN fails in the middle leaving an incomplete (transient) block in blocksBeingWritten directory. This block will be moved to the main storage upon DN restart although it should be treated exactly as the blocks in blocksBeingReplicated directory are, because neither the block nor a part of it was ever finalized.\nDoes it make more sense?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-01-19T20:54:49.558+0000","updated":"2009-01-19T20:54:49.558+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12665356","id":"12665356","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"body":"In the \"append world\" (i.e 0.19), the semantics that we provide is that data written by a writer may be seen by other readers even if the writer has not invoked \"sync\". HDFS makes every effort (within reasonable cost limits) to persist data that is written to a file. Moreover, the \"append\" protocol uses the generation stamp of the block to accurately determine stale blocks, thus it is safe to promote blocks from the \"blocksBeingWritten\" directory to the real block directory.\n\nThe data corruption you have seen occured because the generation-stamp-update-procotol is not triggered during a block transfer request. This patch correctly handles block-trasfer-requests and should prevent the data corruption issue from occuring.\n\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"created":"2009-01-20T07:52:23.542+0000","updated":"2009-01-20T07:52:23.542+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12665493","id":"12665493","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"body":"\n> The data corruption you have seen occured because the generation-stamp-update-procotol is not triggered \n> during a block transfer request. This patch correctly handles block-trasfer-requests and should prevent the data \n> corruption issue from occuring.\n\nMany different types of data corruption occurred recently with 0.18.. mainly because of combination of bugs. \n\nThe corruptions caused by  the issue in this jira has little to do with generation stamp for transfers. Primary cause is this :\n\n# DN promotes all files created in 0.17  from /tmp directory that it should never have done.\n# When it moved the files it did not generate a gen stamp for metadata files.\n# DN reports those blocks as valid to NN.\n# Later DN marks these files as corrupt since there is no metadata.\n\nThe above is one of the biggest source of corruptions. There were various other bugs that contributed, many of these were fixed in 0.18.3. \n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-01-20T18:22:49.230+0000","updated":"2009-01-20T18:22:49.230+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12665542","id":"12665542","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"body":"Append or not if we want files be visible by other clients there should be a logic which reads files in the tmp directory. And this is not related to promoting incomplete files. We do not have guarantees for the data to survive crashes if it has not been sync-ed even if another client has seen it.\n\n> the \"append\" protocol uses the generation stamp to accurately determine stale blocks\n> it is safe to promote blocks from the \"blocksBeingWritten\" directory\n\nIf the protocol worked correctly it would be safe to promote any incomplete blocks including those in blocksBeingReplicated but it wasn't.\n\nI would rather not promote unsynced files because\n# it turned to be error-prone\n# it adds performance overhead, when sync or append is not used.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-01-20T20:20:42.816+0000","updated":"2009-01-20T20:20:42.816+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12665744","id":"12665744","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"body":"The append design explicitly states that the system should make every effort to persist data written to a file even is sync is not invoked. \"sync\" has some cost associated with it, and an application might not want to incur the cost at every write, but t would definitely like HDFS to make the best effort to persist that data it has written.\n\n> it turned to be error-prone\n\nThe design is not error prone, it was the implementation that had some shortcomings. In particular, blocks that are part of replication requests should not have been promoted. This is fixed by this patch. If you are aware of other bugs in this area that can cause problems, it would be really nice if you can list it out or create a unit test to trigger that bug. I understand that the \"append\" protocol is complex, but when implemented correctly should be fool-proof.\n\n\n>it adds performance overhead, when sync or append is not used.\n\nare you concerned that renaming the block file from the blocksBeingWritten directory to the main block directory adds overhead to the write-pipeline? ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"created":"2009-01-21T07:24:22.899+0000","updated":"2009-01-21T07:24:22.899+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12665950","id":"12665950","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"body":"> The append design explicitly states that the system should make every effort to persist data\n\nThis is listed under section \"The non-goals of this design are:\"\nWhich design are we talking about anyway? The document attached to 1700 is 8 months behind the patch.\n\n> In particular, blocks that are part of replication requests should not have been promoted.\n\nWhy? What makes them different from incomplete blocks that are a part of client creates? Same blocks.\n\n> it adds performance overhead, when sync or append is not used.\n\nI am concerned that incomplete blocks will be promoted, then sent (reported) to the name-node, then processed there and finally most of them will be removed. It's the name-node overhead which is a concern not the data-node.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-01-21T20:11:01.359+0000","updated":"2009-01-21T20:11:01.359+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12666358","id":"12666358","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"body":"> Which design are we talking about anyway? The document attached to 1700 is 8 months behind the patch.\n\nThe design document for Appends is still a valid document. It is true that the patch took a long time to develop.\n\n> I am concerned that incomplete blocks will be promoted, then sent (reported) to the name-node, then processed there and finally most of them will be removed. It's the name-node overhead which is a concern not the data-node.\n\nOk, so it is not about correctness, but rather a performance question. I will run some tests on how much this can add to performance overhead. Will report my findings soon. The reason I like promoting blocks to the real directory (only when the datanode crashes) is because this is data that an application has written and I would rather save it than delete it. From my viewpoint, the system should make every effort to persist this data, rather than saying that \"ok, you did not invoke sync, so you lose your data\". (I remember a discussion with Sameer saying that it would be nice to have every new block allocation at the namenode  be persisted, and persisting the block list at the namenode is useless if the datanode anyways deletes blocks that were not closed).","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"created":"2009-01-23T00:09:46.239+0000","updated":"2009-01-23T00:09:46.239+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12666379","id":"12666379","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"body":"> Ok, so it is not about correctness, but rather a performance question.\n\nIt is about both. You did not answer my questions.\nMy point is that if the processing was correct than incomplete blocks whether they are generated by clients or during block replication would be handled correctly, but they were not.\nSo fixing the problem for a part of them (those generated during replication) will not solve the problem completely because the client generated incomplete blocks are still there.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-01-23T01:20:05.609+0000","updated":"2009-01-23T01:20:05.609+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12667953","id":"12667953","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"body":">will not solve the problem completely because the client generated incomplete blocks are still there\n\n@Konstantin: it appears that you feel that applying this patch might still leave a hole. I am unable to visualize a scenario where this could cause a bug. I think the generation-stamp-protocol is adequate. I would really appreciate it if you can write a unit test that can demonstrate this bug (on trunk + the patch associated with this JIRA).","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"created":"2009-01-28T07:24:35.148+0000","updated":"2009-01-28T07:24:35.148+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12668127","id":"12668127","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hairong","name":"hairong","key":"hairong","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hairong Kuang","active":true,"timeZone":"Etc/UTC"},"body":"Is it possible that DataNode leaves the blocks under tmp untouched at the startup time? Instead it leaves those blocks for the lease recovery process to prompt them. When a DataNode starts up, it reads blocks under tmp and put them to OngoingCreates data structure. It then reports them to NN. If NN sees a tmp block that is not the last block of an under-construction file, mark it as corrupt; Otherwise, this is really an under construction block and NN adds it to the targets set of the file. Later when the file's lease expires, NN will close the file and those blocks will be finalized.\n\nThe idea is to start DataNode from the same state when it was down. Prompting blocks at the startup time provides a possibility of polluting dfs data. \n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hairong","name":"hairong","key":"hairong","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hairong Kuang","active":true,"timeZone":"Etc/UTC"},"created":"2009-01-28T19:41:36.726+0000","updated":"2009-01-28T19:41:36.726+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12668137","id":"12668137","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"body":"[See related comment here|https://issues.apache.org/jira/browse/HADOOP-5027#action_12668136]","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shv","name":"shv","key":"shv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Konstantin Shvachko","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-01-28T20:13:23.036+0000","updated":"2009-01-28T20:13:23.036+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12668156","id":"12668156","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"body":"@Hairong: Your proposal should mostly work.\n\nBut, I still do not understand the problem that can result while promoting blocks from \"blocksBeingWritten\" directory when datanode restarts. The generation-stamp-protocol takes care of distinguishing bad replicas from good replicas. \n\nThe design is that the NN block report processing (i.e. addStoredBlock) should completely ignore blocks that are under construction.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"created":"2009-01-28T20:54:02.228+0000","updated":"2009-01-28T20:54:02.228+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12668171","id":"12668171","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hairong","name":"hairong","key":"hairong","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hairong Kuang","active":true,"timeZone":"Etc/UTC"},"body":"I do believe that the generation-stamp-protocol should work. But I do not like the idea of prompting blocks under the tmp directory. Blocks under tmp are under-construction. Blindly finalizing them explicitly introduces polluted blocks to the system and it completely depends on NN to clean them up. This design seems to me not clean. Any minor error on the NN side might cost a lot. Bugs like HADOOP-4810 caused Yahoo to lose quite amount of data and introduced problems like HADOOP-4692 and other problems that we could not identify the cause yet. I think it would be nice that DataNodes do not introduce pollution in the first place.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hairong","name":"hairong","key":"hairong","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hairong Kuang","active":true,"timeZone":"Etc/UTC"},"created":"2009-01-28T21:32:34.397+0000","updated":"2009-01-28T21:32:34.397+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12668177","id":"12668177","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"body":"@Dhruba, could you check if following analysis of a possible corruption correct? :\n\nSay a block is being written and gen stamp is consistent across all three datanodes (common case) :\n\n * Say block sizes after a cluster restart are : x+5, x+10, and x+15 (on three datanode respectively). But this does not mean checksum file is correct since DataNode could be killed any time even OS could restart. \n * When datanodes join the cluster, blocks on D1 and D2 will be deleted since they are smaller than block on D3. Later block on D3 will be reported as corrupt since Checksums don't match. This is hard corruption. \n * Note what we will lose any data on the block that was synced earlier.  \n\n> I am unable to visualize a scenario where this could cause a bug. \n\nIt does not imply it is correct. The most important job of HDFS is keep the data intact. It should take priority over new features or scheduled. IMHO The current approach of _\"it is correct until proven wrong\"_ does not really suit for critical parts. For e.g. couple of months back there were no known corruption issues.. but we later saw many such issues. \n\nI am not saying we can prove everything. But we should be conservative and do only what is already known to be correct. In this case, the block files are valid only until the last sync.. so truncating to last sync (or to some known to be good length) is better.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-01-28T21:55:32.122+0000","updated":"2009-01-28T21:55:32.122+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12668188","id":"12668188","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"body":"Hairong, I understand your point of view.  A bug in the generation-stamp protocol could cause data corruption.\n\nThe alternative is to not promote blocks to the main storage when the datanode restarts. In this case, the data that was written by the client to that datanode is lost. This is data written by an application, and it would be nice if HDFS can make every effort to recover this data instead of deleting it. This is true with most other file systems. For example, if an application writes some data to an ext3 file and then dies before closing/fsync it, the OS/FS does not delete the data that was cached in the OS pages. It makes every effort to persist it. If we can have similar semantics for HDFS, it will be a more powerful system, isn't it? An HDFS application that does not issue a \"fsync\", cannot rely on the fact that all the data it has written will be persisted, but as long as HDFS makes a good effort to keep all the data, that will be nice, isn't it? \n\nSo, this issue all boils down to the tradeoff of having a \"file system that never persists data unless the writer explicitly invoked a fsync\"  verses  \"complexity of the namenode thereby introducing buggy code\". \n\nI can vote for one application that we run inhouse that would definitely like the behaviour where HDFS makes every effort to persist data (rather than invoking sync frequently). HBase can use this feature too (in the future) to recover HBase transactions that lie beyond the sync point (good to have, not a hard requirement).\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"created":"2009-01-28T22:13:33.197+0000","updated":"2009-01-28T22:13:33.197+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12668196","id":"12668196","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"body":"@Raghu. In your test case, the NN knows that the file is under construction. addStoredBlock() as well as a block report should not touch this block at all. The existence of a lease record implies that the NN has relinquished control of this file to the writer/datanode pair. Hence, the NN cannot make any decisions (corrupt block? replciate block?) etc for this block. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"created":"2009-01-28T22:23:57.572+0000","updated":"2009-01-28T22:23:57.572+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12668198","id":"12668198","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"body":"> In your test case, the NN knows that the file is under construction.\n\nAssuming client is also restarted, when does the lease expire? Does the corruption happen after the expiry?\n\nthanks.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-01-28T22:28:07.795+0000","updated":"2009-01-28T22:28:07.795+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12668200","id":"12668200","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hairong","name":"hairong","key":"hairong","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hairong Kuang","active":true,"timeZone":"Etc/UTC"},"body":"Dhruba, for the idea that I proposed, we still preserve the data under tmp. Block finalization is delayed until its file's lease is expired. NN will initiate lease recovery and close the file. Also the proposal tries to restore data structures both at NN and DN side when dfs was down. So any synced data should be available to any reader if they were available to a reader before dfs was down. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hairong","name":"hairong","key":"hairong","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hairong Kuang","active":true,"timeZone":"Etc/UTC"},"created":"2009-01-28T22:36:27.629+0000","updated":"2009-01-28T22:36:27.629+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12668203","id":"12668203","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"body":"@Raghu: The hard-limit-lease-timeout is currently one hour. The NN will start lease recovery after 1 hour. The lease recovery process locates the right replicas (with the same size) bumps up the generation stamp on all these datanode(s), and persists the new block id (that has the new generation stamp) into the Inode. Since the inode map now has a new block id (because of the change in gen stamp), all old replicas that have the old generation stamp do not belong to any inode. If such a old block checks in with the NN via a block report, it will get deleted. Does it sound right?\n\n@Hairong: I get your proposal. I am starting to like it a lot!\n>When a DataNode starts up, it reads blocks under tmp and put them to OngoingCreates data structure\nDo we really need to do this? Even if we leave the blocks in the tmp directory, it will be ok isn't it? A block report won't contain this block. But how does it matter because the NN-blockreport-processing will always ignore the last block of a file that is under construction. Now, when lease recovery occurs, this block could move from the tmp directory to the real block directory.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"created":"2009-01-28T22:48:06.722+0000","updated":"2009-01-28T22:48:06.722+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12668204","id":"12668204","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"body":"Hairong's proposal:\n\nDataNode leaves the blocks under tmp untouched at the startup time. Instead it leaves those blocks for the lease recovery process to prompt them. When a DataNode starts up, it reads blocks under tmp and put them to OngoingCreates data structure. A block  report does not contain this block, but it is ok. The NN block report processing always ignores the last block of a file under construction.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"created":"2009-01-28T22:50:22.566+0000","updated":"2009-01-28T22:50:22.566+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12668208","id":"12668208","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"body":"bq. @Raghu: The hard-limit-lease-timeout is currently one hour. The NN will start lease recovery after 1 hour. The lease recovery process locates the right replicas (with the same size) bumps up the generation stamp on all these datanode(s), and persists the new block id (that has the new generation stamp) into the Inode. Since the inode map now has a new block id (because of the change in gen stamp), all old replicas that have the old generation stamp do not belong to any inode. If such a old block checks in with the NN via a block report, it will get deleted. Does it sound right? \n\nFrom the scenario I outlined above, will it work? All the blocks have same gen-stamp and have (slightly) different lengths. For the given scenario above, could you tell how it ends up with a valid block? Sorry you might have already answered in above comment.. but I could not easily see it.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-01-28T22:55:33.757+0000","updated":"2009-01-28T22:55:33.757+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12668209","id":"12668209","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"body":"> If such a old block checks in with the NN via a block report, it will get deleted. Does it sound right? \nSo we do lose that block. Isn't that a problem?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-01-28T22:58:16.567+0000","updated":"2009-01-28T22:58:16.567+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12668218","id":"12668218","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"body":"> From the scenario I outlined above, will it work? All the blocks have same gen-stamp and have (slightly) different lengths. For the given scenario above, could you tell how it ends up with a valid block?\n\nThis is the core of the generation-stamp recovery logic. The primary datanode contacts each of the datanode(s) in the pipeline and retrieves the generation stamp and the length of each of the replicas. It picks as valid only those replicas that equals or exceeds the generation stamp stored in the NN. For each of these \"valid\" replicas, it picks only those replica(s) that have the smallest size. These are the \"real valid\" replicas of the block. The other replicas can be deleted. \n\nThe primary datanode then stamps all those \"valid\" replicas with a new generation stamp and updates the namenode inode list with this new generation stamp for this block.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"created":"2009-01-28T23:16:36.107+0000","updated":"2009-01-28T23:16:36.107+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12668232","id":"12668232","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"body":"> The primary datanode then stamps all those \"valid\" replicas with a new generation stamp and updates the namenode inode list with this new generation stamp for this block.\n\nThanks that is useful. I am still trying deduce whether you are implying there will be a corruption or a valid replica.\n\nAs I see it, in this case there will be one replica with 'x+5' bytes with the new gen-stamp. But given that checksum does not match (no sync to native filesystem is done, all three datanodes are killed while they are in wrte() system call), looks like we end up with corruption.. right? I am missing something?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-01-28T23:28:58.975+0000","updated":"2009-01-28T23:28:58.975+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12668255","id":"12668255","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"body":"An offline discussion with Raghu resulted in this proposal (slight modification to Hairong's proposal):\n\nThe Datanode, on startup, verifies the length of each block in the \"blocksBeingWrtitten\" directory with their corresponding meta files lengths (and truncates block file if necessary to match meta file). It inserts these blocks in ongoingCreates.It then leaves those blocks for the lease recovery process to prompt them.  A block report does not contain this block, but it is ok. The NN block report processing always ignores the last block of a file under construction. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"created":"2009-01-29T00:16:21.191+0000","updated":"2009-01-29T00:16:48.124+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12668258","id":"12668258","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hairong","name":"hairong","key":"hairong","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hairong Kuang","active":true,"timeZone":"Etc/UTC"},"body":"This sounds good to me. In addition, DN still needs to report NN all blocks in the tmp directory and NN either instructs DN to delete a report tmp block if it is not under construction or adds it to the target set of the file inode it belongs to. I assume that NN does not persist \"targets\" of an under construction file.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hairong","name":"hairong","key":"hairong","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hairong Kuang","active":true,"timeZone":"Etc/UTC"},"created":"2009-01-29T00:24:11.905+0000","updated":"2009-01-29T00:24:11.905+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12668266","id":"12668266","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"body":"An offline discussion with Hairong resulted in detecting that a special purpose block report (for blocks in blocksBeingWritten directory) needs to be sent by the datanode at start-up time. The Namenode has to process this report specially: it should not insert these blocks into blocksMap, instead it should update the targets of the last blocks for filesUnderConstruction.\n\nGiven the \"special\" needs of the above, I think it is better if we promote the blocks from \"blocksBingWriten\" directory to the main directory (after matching/truncating sizes of block files and their crc files) into the main data directory. \n\nSo, I propose that we do the following:\nAt start-up, the DN matches the blocks in the \"blocksBeingWritten\" directory with their meta files. If the size do not match, then the datafile is truncated to match the length described by the CRCs in the metafile. This ensures that this block is likely to be a valid one. Then, these blocks are promoted to the main block directory. (The generation-stamp-protocol will detect inconsistent replicas during lease recovery)","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"created":"2009-01-29T01:00:45.647+0000","updated":"2009-01-29T01:00:45.647+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12668637","id":"12668637","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hairong","name":"hairong","key":"hairong","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hairong Kuang","active":true,"timeZone":"Etc/UTC"},"body":"I still feel very uncomfortable about prompting blocks under \"blocksBeingWritten\". Basically this changes the state of these blocks. DataNode does not know that these blocks are being written any more. In the most recent patch to HADOOP-4692, depending on the state of blocks, block replication takes different behavior. It may wrongly delete on-disk block if its length does not match the NN recorded length if a being written block is prompted to be a permanent block.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hairong","name":"hairong","key":"hairong","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hairong Kuang","active":true,"timeZone":"Etc/UTC"},"created":"2009-01-29T22:15:27.567+0000","updated":"2009-01-29T22:15:27.567+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12669096","id":"12669096","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sanjay.radia","name":"sanjay.radia","key":"sanjay.radia","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sanjay Radia","active":true,"timeZone":"America/Los_Angeles"},"body":"I really like Hirong's suggestion ( https://issues.apache.org/jira/browse/HADOOP-4663?focusedCommentId=12668127#action_12668127) to  *keep* the DN tmp blocks as ongoingCreates and send the special BR to the NN. This is symmetric to the  inodes-under-construction and lease recovery of the NN.\n\n\nThe main issue I had with the older approaches was the inconsistency:\n*   we added a notion of  Tmp because we didn't want to send these block as part of a BR to the NN,\n*  but if the DN restarted all block in tmp are moved to main directory and included in  the BR anyway. \n\nHairong's suggestion keeps the semantics of tmp the same across reboots of DN.\nThis is  very clean even though it adds additional code and a new \"block under cons\" BR.\nFurthermore it allows us to verify that these blocks match those under construction on the NN side. \nOur past attempts at sync/append and at fixing this bug have  been unsuccessful because I think we were trying to\nbe too clever. \n\nThe problem I have with Dhruba's suggestion is that it retains the inconsistency I mention above and somehow appears \nto be trying to avoid the special BR. If on a reboot , the DN\nmoves some blocks from tmp to main (after doing the validations Dhruba suggested), why have them in tmp in the first place?\n\nOne could consider not sending this special BR at all ever. This does not work because  the blocks in tmp may not \nevery get cleaned in some circumstances, For example,  if  a NN is restarted from \nan older fsimage, the tmp files in the DNs will never be removed. \n\nSo +1 for Hairong's suggestion.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sanjay.radia","name":"sanjay.radia","key":"sanjay.radia","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sanjay Radia","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-01-31T00:26:17.066+0000","updated":"2009-01-31T00:26:17.066+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12669101","id":"12669101","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"body":"I have been thinking of Hairong's suggestion as well. I agree that it makes sense for the blocks inside \"blocksBeingWritten\" directory to not be auto-promoted, but instead make lease recovery promote them on demand. The only problem I had with this approach is that a \"special\" block report is needed. \n\nWhat if we have a block report always have two counters up front? the first counter will list the number of normal blocks in the block report. the second counter will have the number of blocks in the block report that are being picked up from the \"blocksBeingWritten\" directory? The NN, while processing a block report, will first look at the first counter and process those many blocks from the block report as usual. Then it will look at the second counter and will special-process those many blocks from the block report. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"created":"2009-01-31T00:38:40.611+0000","updated":"2009-01-31T00:38:40.611+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12670284","id":"12670284","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"body":"This document appendQuestions.txt attempts to answer some questions related to the \"Append\" feature for HDFS.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"created":"2009-02-04T09:09:39.051+0000","updated":"2009-02-04T09:09:39.051+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12672769","id":"12672769","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=nidaley","name":"nidaley","key":"nidaley","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Nigel Daley","active":true,"timeZone":"Etc/UTC"},"body":"As discussed on core-dev@ (http://www.nabble.com/Hadoop-0.19.1-td21739202.html) we will disable append in 0.19.1.  Moving these append related issues to 0.19.2.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=nidaley","name":"nidaley","key":"nidaley","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Nigel Daley","active":true,"timeZone":"Etc/UTC"},"created":"2009-02-11T20:59:28.987+0000","updated":"2009-02-11T20:59:28.987+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12674490","id":"12674490","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"body":"An offline discussion with Hairong, Sanjay, Rob Chansler, Raghu and Konstantin resulted in these observations. 'bbw\" refers to \"blocksBeingWritten\" directory.\n\n1. leave blocks in bbw directory even when data restarts. only when the block is finalized (when user closes the block or lease recovery occurs), does the block move to the real block directory.\n2. first block report (following a datanode registration) sends all blocks (including blocks in bbw)\n3. the block report processing on namenode  ignores blocks that are under construction\n4. lease recovery should verify crc of block before they get promoted from bbw to real block directory\n5. When lease recovery ocurs, the datanode should terminate writer-threads before returning length of block\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"created":"2009-02-18T06:51:50.027+0000","updated":"2009-02-18T06:51:50.027+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12835069","id":"12835069","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"body":"This patch is needed to make Hbase work correctly on Hadoop 0.20.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"created":"2010-02-18T00:17:59.490+0000","updated":"2010-02-18T00:17:59.490+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12845600","id":"12845600","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"body":"Patch for hadoop 0.20 release.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"created":"2010-03-15T23:37:24.331+0000","updated":"2010-03-15T23:37:24.331+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12845749","id":"12845749","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"body":"This patch passes all unit tests.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"created":"2010-03-16T07:10:20.547+0000","updated":"2010-03-16T07:10:20.547+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12846193","id":"12846193","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stack","name":"stack","key":"stack","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"stack","active":true,"timeZone":"America/Los_Angeles"},"body":"Disclaimer: I'm not up on the background to this patch but taking a look anyways.\n\nPatch looks good.  I like the TestAppend4 addition.\n\nDo you want to leave xxxtestAppendWithReplication and xxxtestAppendSyncHalfBlock in there and the commented out code?\n\nShould \"+        DataNode.LOG.info(\"XXX createTmpFile failed for file \" + f + \" Block \" + b);\" be logged at WARN level?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stack","name":"stack","key":"stack","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"stack","active":true,"timeZone":"America/Los_Angeles"},"created":"2010-03-16T22:53:27.147+0000","updated":"2010-03-16T22:53:27.147+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12846247","id":"12846247","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=nspiegelberg","name":"nspiegelberg","key":"nspiegelberg","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Nicolas Spiegelberg","active":true,"timeZone":"America/Los_Angeles"},"body":"Although related to HDFS-142, TestAppend4 is an ongoing suite of unit tests we're trying to tailor to the HBase use case.  TestAppend4 is currently revealing other bugs, so some of the code is commented out.  We're working on fixing the other bugs and will update the Test file when we fix them.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=nspiegelberg","name":"nspiegelberg","key":"nspiegelberg","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Nicolas Spiegelberg","active":true,"timeZone":"America/Los_Angeles"},"created":"2010-03-17T01:31:50.589+0000","updated":"2010-03-17T01:31:50.589+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12846271","id":"12846271","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stack","name":"stack","key":"stack","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"stack","active":true,"timeZone":"America/Los_Angeles"},"body":"@Nicolas Sounds good.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stack","name":"stack","key":"stack","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"stack","active":true,"timeZone":"America/Los_Angeles"},"created":"2010-03-17T02:55:44.310+0000","updated":"2010-03-17T02:55:44.310+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12847871","id":"12847871","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=nspiegelberg","name":"nspiegelberg","key":"nspiegelberg","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Nicolas Spiegelberg","active":true,"timeZone":"America/Los_Angeles"},"body":"In many of the TestFileAppend4 tests, we need to sequentially shutdown datanodes in a cluster.  As each datanode is killed, the DFSClient sees it's pipeline dying and signals a recoverBlock.  T o avoid having the namenode bump the sequence number of an open file on recoverBlock, we need to put it in safe mode.  HDFS-988 fixes a number of bugs, including recoverBlock, where the namenode will modify the file even though it is in safemode.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=nspiegelberg","name":"nspiegelberg","key":"nspiegelberg","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Nicolas Spiegelberg","active":true,"timeZone":"America/Los_Angeles"},"created":"2010-03-21T03:23:14.792+0000","updated":"2010-03-21T03:23:14.792+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12847895","id":"12847895","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=nspiegelberg","name":"nspiegelberg","key":"nspiegelberg","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Nicolas Spiegelberg","active":true,"timeZone":"America/Los_Angeles"},"body":"Add checksum check of last chunk on restart.  Added TestFileAppend4 to test HDFS-200 + HDFS-142.  Passes all tests.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=nspiegelberg","name":"nspiegelberg","key":"nspiegelberg","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Nicolas Spiegelberg","active":true,"timeZone":"America/Los_Angeles"},"created":"2010-03-21T07:33:25.329+0000","updated":"2010-03-21T07:33:25.329+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12848000","id":"12848000","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"Hi Nicolas. I needed to add this fix to MiniDFSCluster (backported from part of HDFS-409) for the tests to pass. Otherwise, sometimes the MiniDFS cluster wouldn't have received heartbeats from all of its DNs, and the replication factor would be too low.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2010-03-21T23:00:28.807+0000","updated":"2010-03-21T23:00:28.807+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12851028","id":"12851028","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=karthik.ranga","name":"karthik.ranga","key":"karthik.ranga","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Karthik Ranganathan","active":true,"timeZone":"America/Los_Angeles"},"body":"Hey guys,\n\nIf we had 2 or more files in the blocks being written directory, the data node would not be able to start up - because the code tries to add the BlockAndFile objects to a TreeSet internally, but the block and file object does not implement a comparable. The first addition goes through as the TreeSet does not have to compare anything. The data node dies on restart with the following exception:\n\n2010-03-23 15:50:23,152 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: java.lang.ClassCastException: org.apache.hadoop.hdfs.server.datanode.FSDataset$BlockAndFile cannot be cast to java.lang.Comparable\n        at java.util.TreeMap.put(TreeMap.java:542)\n        at java.util.TreeSet.add(TreeSet.java:238)\n        at org.apache.hadoop.hdfs.server.datanode.FSDataset$FSDir.getBlockAndFileInfo(FSDataset.java:247)\n        at org.apache.hadoop.hdfs.server.datanode.FSDataset$FSVolume.recoverBlocksBeingWritten(FSDataset.java:539)\n        at org.apache.hadoop.hdfs.server.datanode.FSDataset$FSVolume.<init>(FSDataset.java:381)\n        at org.apache.hadoop.hdfs.server.datanode.FSDataset.<init>(FSDataset.java:895)\n        at org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:305)\n        at org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:219)\n        at org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:1337)\n        at org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:1292)\n        at org.apache.hadoop.hdfs.server.datanode.DataNode.createDataNode(DataNode.java:1300)\n        at org.apache.hadoop.hdfs.server.datanode.DataNode.main(DataNode.java:1422)\n\nThis patch makes the BlockAndFile class implement Comparable, and a unit test (thanks Nick) that verifies this case.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=karthik.ranga","name":"karthik.ranga","key":"karthik.ranga","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Karthik Ranganathan","active":true,"timeZone":"America/Los_Angeles"},"created":"2010-03-29T18:04:41.379+0000","updated":"2010-03-29T18:04:41.379+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12859221","id":"12859221","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"I found a bug in the append code where it doesn't work properly with the following sequence:\n- open a file for write\n- write some data\n- close it\n- the DN with the lowest name dies, but not yet marked dead on the NN\n- a client calls append() to try to recover the lease (not knowing that the file isn't currently under construction)\n\nIn this case, the client ends up thinking it has opened the file for append, and there's a new lease on the NN side, but on the client side it's in an error state where close() will throw IOE (and not close the new lease).\n\nAttaching a new case for TestFileAppend4 for this situation.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2010-04-21T06:04:34.045+0000","updated":"2010-04-21T06:04:34.045+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12859223","id":"12859223","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"Renaming JIRA to reflect the actual scope of this issue in the branch-20 sync work","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2010-04-21T06:07:42.469+0000","updated":"2010-04-21T06:07:42.469+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12859576","id":"12859576","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=nspiegelberg","name":"nspiegelberg","key":"nspiegelberg","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Nicolas Spiegelberg","active":true,"timeZone":"America/Los_Angeles"},"body":"Added patch to fix Todd's deaddn problem.  The main problem: DFSOutputStream called processDatanodeError() but then ignored the return value.  This meant that any slew of pipeline creation exceptions would be ignored and the client would think that append() passed.  Good catch!","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=nspiegelberg","name":"nspiegelberg","key":"nspiegelberg","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Nicolas Spiegelberg","active":true,"timeZone":"America/Los_Angeles"},"created":"2010-04-21T23:15:33.878+0000","updated":"2010-04-21T23:15:33.878+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12861197","id":"12861197","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rash37","name":"rash37","key":"rash37","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"sam rash","active":true,"timeZone":"America/Los_Angeles"},"body":"fixes issue with lease recovery failing on blocks that are already finalized\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rash37","name":"rash37","key":"rash37","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"sam rash","active":true,"timeZone":"America/Los_Angeles"},"created":"2010-04-27T01:27:21.731+0000","updated":"2010-04-27T01:27:21.731+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12861582","id":"12861582","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"Uploading two more patches for 0.20 append:\n - hdfs-142-commitBlockSynchronization-unknown-datanode.txt fixes a case where FSN.getDatanode was throwing an UnregisteredDatanodeException since one of the original recovery targets had departed the cluster (in this case been replaced by a new DN with the same storage but a different port). This exception was causing the commitBlockSynchronization to fail after removing the old block from blocksMap but before putting in the new one, making both old and new blocks inaccessible, and causing any further nextGenerationStamp calls to fail.\n- hdfs-142-testcases.txt includes two new test cases:\n-- testRecoverFinalizedBlock stops a writer just before it calls completeFile() and then has another client recover the file\n-- testDatanodeFailsToCommit() injects an IOE when the DN calls commitBlockSynchronization for the first time, to make sure that the retry succeeds even though updateBlocks() was already called during the first synchronization attempt.\n-- These tests pass after applying Sam's patch to fix refinalization of a finalized block.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2010-04-27T22:11:13.018+0000","updated":"2010-04-27T22:11:13.018+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12864176","id":"12864176","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"Attaching a patch with two more fixes:\n\n- If a block is received that is a part of a file that no longer exists, remove it.  \n  This prevents blocks from getting orphaned in the blocksBeingWritten directory forever\n\n- File recovery happens after reassigning lease to an NN_Recovery client\n    This also includes safeguards and tests to ensure that straggling commitBlockSynchronization\n    calls cannot incorrectly overwrite the last block of a file with an old generation stamp\n    or a different block ID.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2010-05-05T05:57:32.395+0000","updated":"2010-05-05T05:57:32.395+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12864381","id":"12864381","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"The last patch seems to break TestLeaseRecovery, since that test abuses updateBlock() to truncate a block for testing purposes. I'll post an update soon.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2010-05-05T16:03:54.392+0000","updated":"2010-05-05T16:03:54.392+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12864400","id":"12864400","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"Here's a fix for TestLeaseRecovery so that it passes even with the new safeguards in FSDataset.updateBlock","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2010-05-05T16:55:53.688+0000","updated":"2010-05-05T16:55:53.688+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12864633","id":"12864633","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rash37","name":"rash37","key":"rash37","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"sam rash","active":true,"timeZone":"America/Los_Angeles"},"body":"todd :  one question about the latest 2 patches.  Is clientName access from multiple threads via setClientName/getClientName ?\nif so, shouldn't it be volatile?\n\n (I think that object, INodeFileUnderConstruction can be accessed from other threads, in particular if the NN starts recovery, sets it, and another RPC thread tries to handle a close or sync call)\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rash37","name":"rash37","key":"rash37","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"sam rash","active":true,"timeZone":"America/Los_Angeles"},"created":"2010-05-06T03:20:30.649+0000","updated":"2010-05-06T03:20:30.649+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12864636","id":"12864636","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"It's accessed from multiple threads, but those threads are always synchronized on the FSNamesystem lock anyway - none of the lease-related stuff has any actual concurrency. Marking it volatile wouldn't cause any harm, but I think we assume pretty much everywhere that the leases aren't mucked with without holding the coarse grain lock.\n\nBTW, on an unrelated note, I found that TestNodeCount times out due to the MiniDFSCluster changes imported by HDFS-409 - will upload a fix for that here soon.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2010-05-06T03:33:52.598+0000","updated":"2010-05-06T03:33:52.598+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12866391","id":"12866391","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"Posted a patch to HDFS-606 which is important to not lose replicas (TestFileAppend2 was failing occasionally for me with this CME)","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2010-05-11T23:51:01.873+0000","updated":"2010-05-11T23:51:01.873+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12866940","id":"12866940","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"Had a test failure of TestFileAppend2 today with:\n\n   [junit] 2010-05-12 12:20:46,249 WARN  protocol.InterDatanodeProtocol (DataNode.java:recoverBlock(1537)) - Failed to getBlockMetaDataInfo for block (=blk_7206139570868165957_1054) from datanode (=127.0.0.1:42179)\n    [junit] java.io.IOException: Block blk_7206139570868165957_1054 does not exist in volumeMap.\n    [junit]     at org.apache.hadoop.hdfs.server.datanode.FSDataset.validateBlockMetadata(FSDataset.java:1250)\n    [junit]     at org.apache.hadoop.hdfs.server.datanode.DataNode.getBlockMetaDataInfo(DataNode.java:1425)\n    [junit]     at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:1521)\n    [junit]     at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:1616)\n\nThis failure was actually on our vanilla 0.20 Hudson, not on the append branch.\n\nIn investigating this I noticed that validateBlockMetadata is not marked synchronized in FSDataset, and thus accesses the volumeMap HashMap in an unsynchronized matter. If this races with eg a rehash of the hashmap, it can give false non-existence.\n\nDoesn't seem to be a problem in trunk append (this function is gone)","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2010-05-13T01:55:34.149+0000","updated":"2010-05-13T01:55:34.149+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12867146","id":"12867146","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rash37","name":"rash37","key":"rash37","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"sam rash","active":true,"timeZone":"America/Los_Angeles"},"body":"this reminds me--in the test I posted on hdfs-1057, I had two tests that fail doing concurrent reads and appends.  The tests actually fail w/o the concurrent read patch.  I haven't had time to look into it.  You can run the tests in TestFileConcurrentReader.  I can file a sep jira for this as well, but it seems append-related.\n\n\n  // fails due to issue w/append, disable \n  public void _testUnfinishedBlockCRCErrorTransferToAppend() throws IOException {\n    runTestUnfinishedBlockCRCError(true, SyncType.APPEND, DEFAULT_WRITE_SIZE);\n }\n\n  // fails due to issue w/append, disable \n  public void _testUnfinishedBlockCRCErrorNormalTransferAppend() \n    throws IOException {\n    runTestUnfinishedBlockCRCError(false, SyncType.APPEND, DEFAULT_WRITE_SIZE);\n  }\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rash37","name":"rash37","key":"rash37","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"sam rash","active":true,"timeZone":"America/Los_Angeles"},"created":"2010-05-13T14:32:00.901+0000","updated":"2010-05-13T14:32:00.901+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12867296","id":"12867296","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"Small fix for another test failure exposed by TestFileAppend2.testComplexAppend (when run with java assertions enabled). When we removed blocks from recentInvalidateSets, we didn't remove the collections when they became empty, which triggered an assertion at the top of DatanodeDescriptor.addBlocksToBeInvalidated\n\n(this is not an issue in trunk, trunk has this same fix)","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2010-05-13T22:48:11.948+0000","updated":"2010-05-13T22:48:11.948+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12867311","id":"12867311","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"appendFile() is made up of two synchronized blocks, and there is no re-check of the file existence (or lease) when entering the second one. Uploading a test case and fix.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2010-05-13T23:34:19.893+0000","updated":"2010-05-13T23:34:19.893+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12868057","id":"12868057","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"Attached patch treats replicas recovered during DN startup as possibly truncated, and thus recovers those replicas from still-running DNs only if such replicas are available. (included test case explains this better)","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2010-05-17T00:19:01.886+0000","updated":"2010-05-17T00:19:01.886+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12876402","id":"12876402","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"New version of the dont-recover-rbw patch (this is what I've been testing against)","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2010-06-07T20:33:38.205+0000","updated":"2010-06-07T20:33:38.205+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12876403","id":"12876403","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=nspiegelberg","name":"nspiegelberg","key":"nspiegelberg","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Nicolas Spiegelberg","active":true,"timeZone":"America/Los_Angeles"},"body":"TestFileAppend4 tests depend on a number of JIRAs already being applied.  Explicitly specifying them so it's easier to add this to 0.20-append branch.\n\nHDFS-826 : Uses to determine which DNs to kill and which are still valid.\nHDFS-101 : For when we try killing DNs further in the pipeline\nHDFS-793 : Because we verify data size after all DNs have sent an ACK\nHDFS-988 : Fix safemode.  Before, only the last DN has the highest seqnum on test cluster restart.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=nspiegelberg","name":"nspiegelberg","key":"nspiegelberg","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Nicolas Spiegelberg","active":true,"timeZone":"America/Los_Angeles"},"created":"2010-06-07T20:33:58.154+0000","updated":"2010-06-07T20:33:58.154+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12876876","id":"12876876","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=nspiegelberg","name":"nspiegelberg","key":"nspiegelberg","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Nicolas Spiegelberg","active":true,"timeZone":"America/Los_Angeles"},"body":"Patch for 0.20-append branch.  Starts with HDFS-142_20.patch and includes all patches up to appendFile-recheck-lease.txt.  Had trouble adding the relatively-new recover-rbw-v2.txt, so left that for Todd.  Assumes that the 0.20-append patches in HDFS-826, HDFS-988, & HDFS-101 have been applied previously.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=nspiegelberg","name":"nspiegelberg","key":"nspiegelberg","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Nicolas Spiegelberg","active":true,"timeZone":"America/Los_Angeles"},"created":"2010-06-08T23:55:52.169+0000","updated":"2010-06-08T23:55:52.169+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/12879555","id":"12879555","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"body":"I have committed this. Thanks Sam, Nicolas and Todd.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"created":"2010-06-16T22:30:26.260+0000","updated":"2010-06-16T22:30:26.260+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/13096210","id":"13096210","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jnp","name":"jnp","key":"jnp","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jitendra Nath Pandey","active":true,"timeZone":"Etc/UTC"},"body":"Patch for 20-security branch uploaded.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jnp","name":"jnp","key":"jnp","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jitendra Nath Pandey","active":true,"timeZone":"Etc/UTC"},"created":"2011-09-02T18:59:59.733+0000","updated":"2011-09-02T18:59:59.733+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/13096275","id":"13096275","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sureshms","name":"sureshms","key":"sureshms","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10450","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10450","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10450","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10450"},"displayName":"Suresh Srinivas","active":true,"timeZone":"America/Los_Angeles"},"body":"Can you please add a banner to TestFileAppend4.java","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sureshms","name":"sureshms","key":"sureshms","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10450","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10450","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10450","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10450"},"displayName":"Suresh Srinivas","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-09-02T20:22:10.648+0000","updated":"2011-09-02T20:22:10.648+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/13096280","id":"13096280","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jnp","name":"jnp","key":"jnp","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jitendra Nath Pandey","active":true,"timeZone":"Etc/UTC"},"body":"Added Apache License header.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jnp","name":"jnp","key":"jnp","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jitendra Nath Pandey","active":true,"timeZone":"Etc/UTC"},"created":"2011-09-02T20:32:29.622+0000","updated":"2011-09-02T20:32:29.622+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/13096328","id":"13096328","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sureshms","name":"sureshms","key":"sureshms","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10450","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10450","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10450","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10450"},"displayName":"Suresh Srinivas","active":true,"timeZone":"America/Los_Angeles"},"body":"+1 for the patch.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sureshms","name":"sureshms","key":"sureshms","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10450","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10450","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10450","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10450"},"displayName":"Suresh Srinivas","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-09-02T21:36:39.265+0000","updated":"2011-09-02T21:36:39.265+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/13096333","id":"13096333","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sureshms","name":"sureshms","key":"sureshms","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10450","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10450","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10450","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10450"},"displayName":"Suresh Srinivas","active":true,"timeZone":"America/Los_Angeles"},"body":"I committed the patch 0.20-security","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sureshms","name":"sureshms","key":"sureshms","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10450","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10450","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10450","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10450"},"displayName":"Suresh Srinivas","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-09-02T21:38:35.792+0000","updated":"2011-09-02T21:38:35.792+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12408551/comment/13130220","id":"13130220","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mattf","name":"mattf","key":"mattf","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Matt Foley","active":true,"timeZone":"America/Los_Angeles"},"body":"Closed upon release of 0.20.205.0","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mattf","name":"mattf","key":"mattf","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Matt Foley","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-10-19T00:26:07.018+0000","updated":"2011-10-19T00:26:07.018+0000"}],"maxResults":113,"total":113,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-142/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i02smv:"}}