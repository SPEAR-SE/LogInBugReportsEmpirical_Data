{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12402839","self":"https://issues.apache.org/jira/rest/api/2/issue/12402839","key":"HDFS-45","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/8","id":"8","description":"The described issue is not actually a problem - it is as designed.","name":"Not A Problem"},"customfield_12312322":null,"customfield_12310220":"2008-08-22T06:48:45.057+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Fri Jul 18 22:19:36 UTC 2014","customfield_12310420":"16881","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_186338465681_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2014-07-18T22:19:36.342+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-45/watchers","watchCount":2,"isWatching":false},"created":"2008-08-22T05:38:30.884+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[],"issuelinks":[],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2014-07-18T22:19:36.515+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[],"timeoriginalestimate":null,"description":"I started a hadoop cluster, built with the (latest) trunk  and tried doing _dfs -put_ with the (dfs) clients from the (older/stale) trunk. The client went ahead and tried to upload the data onto the cluster and failed with the following error\n{noformat}\n-bash-3.00$ ./bin/hadoop dfs -put file file\n08/08/22 05:11:06 INFO hdfs.DFSClient: Exception in createBlockOutputStream java.io.IOException: Could not read from stream\n08/08/22 05:11:06 INFO hdfs.DFSClient: Abandoning block blk_5748330682182803489_1002\n08/08/22 05:11:12 INFO hdfs.DFSClient: Exception in createBlockOutputStream java.io.IOException: Could not read from stream\n08/08/22 05:11:12 INFO hdfs.DFSClient: Abandoning block blk_7482082538144151768_1002\n08/08/22 05:11:18 INFO hdfs.DFSClient: Exception in createBlockOutputStream java.io.IOException: Could not read from stream\n08/08/22 05:11:18 INFO hdfs.DFSClient: Abandoning block blk_-3132217232090937466_1002\n08/08/22 05:11:24 INFO hdfs.DFSClient: Exception in createBlockOutputStream java.io.IOException: Could not read from stream\n08/08/22 05:11:24 INFO hdfs.DFSClient: Abandoning block blk_-6473055472384366978_1002\n08/08/22 05:11:30 WARN hdfs.DFSClient: DataStreamer Exception: java.io.IOException: Unable to create new block.\n        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.nextBlockOutputStream(DFSClient.java:2504)\n        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.access$2000(DFSClient.java:1810)\n        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:1990)\n\nput: Filesystem closed\n{noformat}\n\nIt would be better if somehow the client detects that its not *made* for this master and softly/simply bail out.\n----\nNote that I *did not* do it on purpose but forgot to replace the older installation with the newer one.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"108012","customfield_12312823":null,"summary":"DFS client should throw version mismatch errors in case of a changed functionality","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=amar_kamat","name":"amar_kamat","key":"amar_kamat","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Amar Kamat","active":true,"timeZone":"Etc/UTC"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=amar_kamat","name":"amar_kamat","key":"amar_kamat","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Amar Kamat","active":true,"timeZone":"Etc/UTC"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12402839/comment/12624596","id":"12624596","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"body":"If there is a protocol mismatch between client and server, then dfs will bail out. In your case, it is possible that the protcol versionnumber was not bumped up when the new feature was introduced.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dhruba","name":"dhruba","key":"dhruba","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=dhruba&avatarId=30636","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dhruba&avatarId=30636","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dhruba&avatarId=30636","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dhruba&avatarId=30636"},"displayName":"dhruba borthakur","active":true,"timeZone":"America/Tijuana"},"created":"2008-08-22T06:48:45.057+0000","updated":"2008-08-22T06:48:45.057+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12402839/comment/12624612","id":"12624612","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=amar_kamat","name":"amar_kamat","key":"amar_kamat","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Amar Kamat","active":true,"timeZone":"Etc/UTC"},"body":"I think even the build version should be checked if bumping the protocol version for every related issue is not feasible.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=amar_kamat","name":"amar_kamat","key":"amar_kamat","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Amar Kamat","active":true,"timeZone":"Etc/UTC"},"created":"2008-08-22T07:51:32.371+0000","updated":"2008-08-22T07:51:32.371+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12402839/comment/14066985","id":"14066985","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=aw","name":"aw","key":"aw","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=aw&avatarId=23681","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=aw&avatarId=23681","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=aw&avatarId=23681","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=aw&avatarId=23681"},"displayName":"Allen Wittenauer","active":true,"timeZone":"America/Tijuana"},"body":"This is no longer necessary with protobuf rpc.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=aw","name":"aw","key":"aw","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=aw&avatarId=23681","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=aw&avatarId=23681","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=aw&avatarId=23681","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=aw&avatarId=23681"},"displayName":"Allen Wittenauer","active":true,"timeZone":"America/Tijuana"},"created":"2014-07-18T22:19:36.471+0000","updated":"2014-07-18T22:19:36.471+0000"}],"maxResults":3,"total":3,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-45/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i0iucv:"}}