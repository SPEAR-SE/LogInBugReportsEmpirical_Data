{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12552440","self":"https://issues.apache.org/jira/rest/api/2/issue/12552440","key":"HDFS-3318","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12320052","id":"12320052","description":"0.23.3","name":"0.23.3","archived":false,"released":true,"releaseDate":"2012-09-20"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12322472","id":"12322472","description":"2.0.2-alpha release","name":"2.0.2-alpha","archived":false,"released":true,"releaseDate":"2012-10-09"}],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2012-04-24T23:06:36.991+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Mon Jul 16 22:33:55 UTC 2012","customfield_12310420":"236663","customfield_12312320":null,"customfield_12310222":"10002_*:*_1_*:*_77076068_*|*_1_*:*_1_*:*_602048_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2012-04-25T19:26:47.705+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-3318/watchers","watchCount":9,"isWatching":false},"created":"2012-04-24T21:52:09.704+0000","customfield_12310192":null,"customfield_12310191":[{"self":"https://issues.apache.org/jira/rest/api/2/customFieldOption/10342","value":"Incompatible change","id":"10342"},{"self":"https://issues.apache.org/jira/rest/api/2/customFieldOption/10343","value":"Reviewed","id":"10343"}],"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/1","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/blocker.svg","name":"Blocker","id":"1"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"2.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12320052","id":"12320052","description":"0.23.3","name":"0.23.3","archived":false,"released":true,"releaseDate":"2012-09-20"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12320353","id":"12320353","description":"hadoop-2.0.0-alpha release","name":"2.0.0-alpha","archived":false,"released":true,"releaseDate":"2012-05-23"}],"issuelinks":[{"id":"12355351","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12355351","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"12548520","key":"HDFS-3166","self":"https://issues.apache.org/jira/rest/api/2/issue/12548520","fields":{"summary":"Hftp connections do not have a timeout","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/2","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/critical.svg","name":"Critical","id":"2"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12355174","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12355174","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"12461316","key":"HDFS-1085","self":"https://issues.apache.org/jira/rest/api/2/issue/12461316","fields":{"summary":"hftp read  failing silently","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12367683","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12367683","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"inwardIssue":{"id":"12643423","key":"HDFS-4715","self":"https://issues.apache.org/jira/rest/api/2/issue/12643423","fields":{"summary":"Backport HDFS-3577 and other related WebHDFS issue to branch-1","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12355173","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12355173","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"inwardIssue":{"id":"12599005","key":"HDFS-3671","self":"https://issues.apache.org/jira/rest/api/2/issue/12599005","fields":{"summary":"ByteRangeInputStream shouldn't require the content length header be present","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/10002","description":"A patch for this issue has been uploaded to JIRA by a contributor.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/document.png","name":"Patch Available","id":"10002","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/4","id":4,"key":"indeterminate","colorName":"yellow","name":"In Progress"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/2","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/critical.svg","name":"Critical","id":"2"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12355251","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12355251","type":{"id":"12310050","name":"Regression","inward":"is broken by","outward":"breaks","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/12310050"},"outwardIssue":{"id":"12596327","key":"HDFS-3577","self":"https://issues.apache.org/jira/rest/api/2/issue/12596327","fields":{"summary":"WebHdfsFileSystem can not read files larger than 24KB","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/1","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/blocker.svg","name":"Blocker","id":"1"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=daryn","name":"daryn","key":"daryn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Daryn Sharp","active":true,"timeZone":"America/Chicago"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2015-03-10T04:35:22.265+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12312928","id":"12312928","name":"hdfs-client"}],"timeoriginalestimate":null,"description":"Hftp transfers >2GB hang after the transfer is complete.  The problem appears to be caused by java internally using an int for the content length.  When it overflows 2GB, it won't check the bounds of the reads on the input stream.  The client continues reading after all data is received, and the client blocks until the server times out the connection -- _many_ minutes later.  In conjunction with hftp timeouts, all transfers >2G fail with a read timeout.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12320052","id":"12320052","description":"0.23.3","name":"0.23.3","archived":false,"released":true,"releaseDate":"2012-09-20"}],"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12524067","id":"12524067","filename":"HDFS-3318.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=daryn","name":"daryn","key":"daryn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Daryn Sharp","active":true,"timeZone":"America/Chicago"},"created":"2012-04-24T22:02:03.850+0000","size":2406,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12524067/HDFS-3318.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12524289","id":"12524289","filename":"HDFS-3318-1.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=daryn","name":"daryn","key":"daryn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Daryn Sharp","active":true,"timeZone":"America/Chicago"},"created":"2012-04-25T15:19:04.713+0000","size":3128,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12524289/HDFS-3318-1.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"44365","customfield_12312823":null,"summary":"Hftp hangs on transfers >2GB","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=daryn","name":"daryn","key":"daryn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Daryn Sharp","active":true,"timeZone":"America/Chicago"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=daryn","name":"daryn","key":"daryn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Daryn Sharp","active":true,"timeZone":"America/Chicago"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12552440/comment/13261067","id":"13261067","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=daryn","name":"daryn","key":"daryn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Daryn Sharp","active":true,"timeZone":"America/Chicago"},"body":"Wrap the url's input stream in a stream bounded with a {{long}} based on content length.\n\nAdd impl to pass through the other 2 {{read}} methods to the bounded stream.  This yields a ~1.4X improvement in transfer times.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=daryn","name":"daryn","key":"daryn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Daryn Sharp","active":true,"timeZone":"America/Chicago"},"created":"2012-04-24T22:02:03.870+0000","updated":"2012-04-24T22:02:03.870+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12552440/comment/13261092","id":"13261092","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=daryn","name":"daryn","key":"daryn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Daryn Sharp","active":true,"timeZone":"America/Chicago"},"body":"Patch does not include tests due to the infeasibility of testing the transfer time/success of a 2GB+ file.  It's been manually tested with large customer files that are currently failing to copy.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=daryn","name":"daryn","key":"daryn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Daryn Sharp","active":true,"timeZone":"America/Chicago"},"created":"2012-04-24T22:28:03.668+0000","updated":"2012-04-24T22:28:03.668+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12552440/comment/13261116","id":"13261116","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"body":"Before introduction of the client-side timeout in hftp, server-side would timeout in 200 seconds, which is the jetty keepalive timeout. Currently when the client-side times out, which is smaller than 200 seconds, hftp client thinks transfer has failed since it does not detect the end of transfer based on the content length header. This doesn't seem to happen when the file size is < 2GB.  HttpURLConnection.getContentLength() returns an int (max: 2^32-1) and it might be internally keeping track of progress as long as content-length is < 2GB.\n\nAs a side effect of the fix, it will shed 200 seconds off transfer times for files bigger than 2GB (for pre hftp client timeout), since it will no longer wait for the server side to close the connection.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"created":"2012-04-24T23:06:36.991+0000","updated":"2012-04-24T23:06:36.991+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12552440/comment/13261141","id":"13261141","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"-1 overall.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12524067/HDFS-3318.patch\n  against trunk revision .\n\n    +1 @author.  The patch does not contain any @author tags.\n\n    -1 tests included.  The patch doesn't appear to include any new or modified tests.\n                        Please justify why no new tests are needed for this patch.\n                        Also please list what manual steps were performed to verify this patch.\n\n    +1 javadoc.  The javadoc tool did not generate any warning messages.\n\n    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.\n\n    +1 eclipse:eclipse.  The patch built with eclipse:eclipse.\n\n    +1 findbugs.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.\n\n    +1 release audit.  The applied patch does not increase the total number of release audit warnings.\n\n    -1 core tests.  The patch failed these unit tests:\n                  org.apache.hadoop.hdfs.web.TestOffsetUrlInputStream\n                  org.apache.hadoop.fs.TestUrlStreamHandler\n                  org.apache.hadoop.hdfs.TestByteRangeInputStream\n\n    +1 contrib tests.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/2324//testReport/\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/2324//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2012-04-24T23:32:22.517+0000","updated":"2012-04-24T23:32:22.517+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12552440/comment/13261645","id":"13261645","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi Daryn,\n\nCan streamLength > 2^31 ? Would in then be bounded by that higher number and still cause issues? \n\nWhy are you Overriding \n{noformat}\n  @Override\n  public int read(byte[] b) throws IOException {\n    return read(b, 0, b.length);\n  }\n{noformat}\n\nWouldn't the original implementation be picked up from InputStream which has exactly the same code? I tested with this short program and it prints exactly what Michael Jackson used to say he is.\n\n{noformat}\nclass A {\n  public void printA() {\n    System.out.println(\"A\");\n    printC();\n  }\n  public void printC() {\n    System.out.println(\"C\");\n  }\n}\n\nclass B extends A {\n  @Override\n  public void printC() {\n    System.out.println(\"D\");\n  }\n  \n  public void printB() {\n    System.out.println(\"B\");\n    printA();\n  }\n}\n\npublic class TestJAVA {\n  public static void main(String arg[]) {\n    B b = new B();\n    b.printB();\n  }\n}\n{noformat}\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"created":"2012-04-25T13:46:26.535+0000","updated":"2012-04-25T13:46:26.535+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12552440/comment/13261677","id":"13261677","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=daryn","name":"daryn","key":"daryn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Daryn Sharp","active":true,"timeZone":"America/Chicago"},"body":"I doubt the per-read buffer is going to be >2GB for at least 5-10 years.  By that time, I think java will have fixed the issue. :)","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=daryn","name":"daryn","key":"daryn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Daryn Sharp","active":true,"timeZone":"America/Chicago"},"created":"2012-04-25T14:35:06.050+0000","updated":"2012-04-25T14:35:06.050+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12552440/comment/13261684","id":"13261684","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=revans2","name":"revans2","key":"revans2","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Robert Joseph Evans","active":true,"timeZone":"America/Chicago"},"body":"I looked at the patch and it looks good to me.  I agree with Ravi that we do not need to override read(byte[] b).  I am a +1 (non-binding) on this.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=revans2","name":"revans2","key":"revans2","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Robert Joseph Evans","active":true,"timeZone":"America/Chicago"},"created":"2012-04-25T14:50:10.331+0000","updated":"2012-04-25T14:50:10.331+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12552440/comment/13261708","id":"13261708","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=daryn","name":"daryn","key":"daryn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Daryn Sharp","active":true,"timeZone":"America/Chicago"},"body":"Removed {{read(byte[])}} and fixed related tests.\n\nAnother jira broke {{TestUrlStreamHandler}}.  Somehow there are no more {{fs.$scheme.impl}} keys in the conf.  There are only {{fs.AbstractFileSystem.$scheme.impl}} keys.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=daryn","name":"daryn","key":"daryn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Daryn Sharp","active":true,"timeZone":"America/Chicago"},"created":"2012-04-25T15:19:04.802+0000","updated":"2012-04-25T15:19:04.802+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12552440/comment/13261784","id":"13261784","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"-1 overall.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12524289/HDFS-3318-1.patch\n  against trunk revision .\n\n    +1 @author.  The patch does not contain any @author tags.\n\n    +1 tests included.  The patch appears to include 1 new or modified test files.\n\n    +1 javadoc.  The javadoc tool did not generate any warning messages.\n\n    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.\n\n    +1 eclipse:eclipse.  The patch built with eclipse:eclipse.\n\n    +1 findbugs.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.\n\n    +1 release audit.  The applied patch does not increase the total number of release audit warnings.\n\n    -1 core tests.  The patch failed these unit tests:\n                  org.apache.hadoop.fs.TestUrlStreamHandler\n\n    +1 contrib tests.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/2328//testReport/\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/2328//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2012-04-25T16:30:34.851+0000","updated":"2012-04-25T16:30:34.851+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12552440/comment/13261806","id":"13261806","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"body":"Talked offline with Daryn. He has a way of removing any of my doubts :) Thanks Daryn! +1","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"created":"2012-04-25T16:58:57.556+0000","updated":"2012-04-25T16:58:57.556+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12552440/comment/13261902","id":"13261902","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=atm","name":"atm","key":"atm","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=atm&avatarId=14136","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=atm&avatarId=14136","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=atm&avatarId=14136","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=atm&avatarId=14136"},"displayName":"Aaron T. Myers","active":true,"timeZone":"America/Los_Angeles"},"body":"I think the patch largely looks good. I'm confused, however, by the change of how \"filelength\" is determined. \n\nIt changed from this:\n{code}\nfinal String cl = connection.getHeaderField(StreamFile.CONTENT_LENGTH);\nfilelength = (cl == null) ? -1 : Long.parseLong(cl);\n{code}\nTo this:\n{code}\nfinal String cl = connection.getHeaderField(StreamFile.CONTENT_LENGTH);\n...\nfinal long streamlength = Long.parseLong(cl);\nfilelength = startPos + streamlength;\n{code}\n\nWhy does the filelength now begin at startPos? That change seems unrelated to this issue. Or am I missing something?\n\n+1 once this question is addressed.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=atm","name":"atm","key":"atm","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=atm&avatarId=14136","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=atm&avatarId=14136","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=atm&avatarId=14136","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=atm&avatarId=14136"},"displayName":"Aaron T. Myers","active":true,"timeZone":"America/Los_Angeles"},"created":"2012-04-25T18:31:27.895+0000","updated":"2012-04-25T18:31:27.895+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12552440/comment/13261956","id":"13261956","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"body":"I think the previous filelength works only if startPos is zero.  It is a bug.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2012-04-25T19:04:38.413+0000","updated":"2012-04-25T19:04:38.413+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12552440/comment/13261970","id":"13261970","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=daryn","name":"daryn","key":"daryn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Daryn Sharp","active":true,"timeZone":"America/Chicago"},"body":"bq. Why does the filelength now begin at startPos?\n\nIt's another bug related to successfully reading the stream that I didn't fully fix, but fixed \"enough\".  When EOF is encountered, it checks {noformat}if (currentPos < filelength) { EOFException } {noformat} to decide if there was a premature EOF.  {{currentPos}} and {{filelength}} are *not relative* to {{startPos}}, thus it's not valid to compare the current pos to the stream length.\n\nEx. I have 128 bytes.  I seek 100 bytes into it.  The remaining content-length is 28.  My file length is not 28 bytes!  I read more 10 bytes and the connection unexpectedly closes.  The broken premature EOF condition fails to detect the fault because (110 < 28) is false.  The correct check is (110 < 100+28).\n\n{noformat}\n      filelength\n------------------------\n       ^----------------\nstartPos  content-length\n{noformat}\n\nI can file a separate jira for this 1-line fix if you'd like.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=daryn","name":"daryn","key":"daryn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Daryn Sharp","active":true,"timeZone":"America/Chicago"},"created":"2012-04-25T19:20:19.037+0000","updated":"2012-04-25T19:20:19.037+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12552440/comment/13261978","id":"13261978","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"body":"I have committed this.  Thanks, Daryn!","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2012-04-25T19:26:47.740+0000","updated":"2012-04-25T19:26:47.740+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12552440/comment/13261984","id":"13261984","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=atm","name":"atm","key":"atm","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=atm&avatarId=14136","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=atm&avatarId=14136","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=atm&avatarId=14136","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=atm&avatarId=14136"},"displayName":"Aaron T. Myers","active":true,"timeZone":"America/Los_Angeles"},"body":"Works for me. Just wanted to make sure it wasn't inadvertent.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=atm","name":"atm","key":"atm","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=atm&avatarId=14136","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=atm&avatarId=14136","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=atm&avatarId=14136","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=atm&avatarId=14136"},"displayName":"Aaron T. Myers","active":true,"timeZone":"America/Los_Angeles"},"created":"2012-04-25T19:33:19.996+0000","updated":"2012-04-25T19:33:19.996+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12552440/comment/13261995","id":"13261995","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"Integrated in Hadoop-Common-trunk-Commit #2131 (See [https://builds.apache.org/job/Hadoop-Common-trunk-Commit/2131/])\n    HDFS-3318. Use BoundedInputStream in ByteRangeInputStream, otherwise, it hangs on transfers >2 GB.  Contributed by Daryn Sharp (Revision 1330500)\n\n     Result = SUCCESS\nszetszwo : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1330500\nFiles : \n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/ByteRangeInputStream.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestByteRangeInputStream.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2012-04-25T19:45:14.079+0000","updated":"2012-04-25T19:45:14.079+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12552440/comment/13261997","id":"13261997","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"Integrated in Hadoop-Mapreduce-trunk-Commit #2147 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk-Commit/2147/])\n    HDFS-3318. Use BoundedInputStream in ByteRangeInputStream, otherwise, it hangs on transfers >2 GB.  Contributed by Daryn Sharp (Revision 1330500)\n\n     Result = SUCCESS\nszetszwo : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1330500\nFiles : \n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/ByteRangeInputStream.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestByteRangeInputStream.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2012-04-25T19:48:36.671+0000","updated":"2012-04-25T19:48:36.671+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12552440/comment/13262000","id":"13262000","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"Integrated in Hadoop-Hdfs-trunk-Commit #2205 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk-Commit/2205/])\n    HDFS-3318. Use BoundedInputStream in ByteRangeInputStream, otherwise, it hangs on transfers >2 GB.  Contributed by Daryn Sharp (Revision 1330500)\n\n     Result = SUCCESS\nszetszwo : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1330500\nFiles : \n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/ByteRangeInputStream.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestByteRangeInputStream.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2012-04-25T19:49:38.991+0000","updated":"2012-04-25T19:49:38.991+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12552440/comment/13262569","id":"13262569","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"Integrated in Hadoop-Hdfs-0.23-Build #239 (See [https://builds.apache.org/job/Hadoop-Hdfs-0.23-Build/239/])\n    svn merge -c 1330500 from trunk for HDFS-3318. Use BoundedInputStream in ByteRangeInputStream, otherwise, it hangs on transfers >2 GB. (Revision 1330504)\n\n     Result = UNSTABLE\nszetszwo : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1330504\nFiles : \n* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs\n* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt\n* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/main/java\n* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/ByteRangeInputStream.java\n* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestByteRangeInputStream.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2012-04-26T12:40:18.981+0000","updated":"2012-04-26T12:40:18.981+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12552440/comment/13262603","id":"13262603","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"Integrated in Hadoop-Hdfs-trunk #1026 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1026/])\n    HDFS-3318. Use BoundedInputStream in ByteRangeInputStream, otherwise, it hangs on transfers >2 GB.  Contributed by Daryn Sharp (Revision 1330500)\n\n     Result = FAILURE\nszetszwo : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1330500\nFiles : \n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/ByteRangeInputStream.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestByteRangeInputStream.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2012-04-26T13:12:19.829+0000","updated":"2012-04-26T13:12:19.829+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12552440/comment/13262617","id":"13262617","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"Integrated in Hadoop-Mapreduce-trunk #1061 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1061/])\n    HDFS-3318. Use BoundedInputStream in ByteRangeInputStream, otherwise, it hangs on transfers >2 GB.  Contributed by Daryn Sharp (Revision 1330500)\n\n     Result = FAILURE\nszetszwo : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1330500\nFiles : \n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/ByteRangeInputStream.java\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestByteRangeInputStream.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2012-04-26T13:23:17.141+0000","updated":"2012-04-26T13:23:17.141+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12552440/comment/13414866","id":"13414866","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"body":"Is this also a problem in branch-1?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2012-07-16T06:02:43.007+0000","updated":"2012-07-16T06:02:43.007+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12552440/comment/13415140","id":"13415140","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=revans2","name":"revans2","key":"revans2","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Robert Joseph Evans","active":true,"timeZone":"America/Chicago"},"body":"Yes this probably also impacts branch-1.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=revans2","name":"revans2","key":"revans2","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Robert Joseph Evans","active":true,"timeZone":"America/Chicago"},"created":"2012-07-16T14:06:49.963+0000","updated":"2012-07-16T14:06:49.963+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12552440/comment/13415172","id":"13415172","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=daryn","name":"daryn","key":"daryn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Daryn Sharp","active":true,"timeZone":"America/Chicago"},"body":"Yes, on branch-1, >2GB transfers incur a 200s penalty after transfer is complete.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=daryn","name":"daryn","key":"daryn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Daryn Sharp","active":true,"timeZone":"America/Chicago"},"created":"2012-07-16T14:30:58.563+0000","updated":"2012-07-16T14:30:58.563+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12552440/comment/13415447","id":"13415447","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=eli","name":"eli","key":"eli","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eli Collins","active":true,"timeZone":"America/Los_Angeles"},"body":"Marking this as an incompatible change as the following code broke distcp from 0.20.2 and 0.21 releases. The code below requires the content length header be present however that field wasn't introduced in trunk until 22 (by HDFS-1085), it came into branch-1 via the YDH merge. Filed HDFS-3671 to fix this.\n\n{code}\n-      filelength = (cl == null) ? -1 : Long.parseLong(cl);\n-      in = connection.getInputStream();\n+      if (cl == null) {\n+        throw new IOException(StreamFile.CONTENT_LENGTH+\" header is missing\");\n+      }\n{code}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=eli","name":"eli","key":"eli","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eli Collins","active":true,"timeZone":"America/Los_Angeles"},"created":"2012-07-16T17:54:05.901+0000","updated":"2012-07-16T17:54:05.901+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12552440/comment/13415733","id":"13415733","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"body":"The Content-Length check will be removed by HDFS-3577.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2012-07-16T22:33:55.864+0000","updated":"2012-07-16T22:33:55.864+0000"}],"maxResults":26,"total":26,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-3318/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i07yjz:"}}