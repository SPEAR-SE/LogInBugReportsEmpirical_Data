{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"13007487","self":"https://issues.apache.org/jira/rest/api/2/issue/13007487","key":"HDFS-10902","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":null,"customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Mon Sep 26 14:26:52 UTC 2016","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-10902/watchers","watchCount":12,"isWatching":false},"created":"2016-09-26T06:21:05.482+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/2","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/critical.svg","name":"Critical","id":"2"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[],"issuelinks":[],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinayrpet","name":"vinayrpet","key":"vinayrpet","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinayakumar B","active":true,"timeZone":"Asia/Kolkata"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2016-09-26T14:26:52.146+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12320525","id":"12320525","name":"qjm","description":"Quorum Journal Manager"}],"timeoriginalestimate":null,"description":"In one of our cluster faced an issue, where NameNode restart failed due to a stale/failed txn available in one JN but not others. \n\nScenario is:\n1. Full cluster restart\n2. startLogSegment Txn(195222) synced in Only one JN but failed to others, because they were shutting down. Only editlog file was created but txn was not synced in others, so after restart they were marked as empty.\n3. Cluster restarted. During failover, this new logSegment missed the recovery because this JN was slow in responding to this call.\n4. Other JNs recover was successfull, as there was no in-progress files.\n5. editlog.openForWrite() detected that (195222) was already available, and failed the failover.\n\nSame steps repeated until that stale editlog in JN was manually deleted.\n\nSince QJM is a quorum of JNs, txn is considered successfull, if its written min quorum. Otherwise it will be failed.\nSo, same case should be applied while selecting streams for reading also.\nStale/failed txns available in only less JNs should not be considered for reading.\n\nHDFS-10519, does similar work to consider 'durable' txns based on 'committedTxnId'. But updating 'committedTxnId' for every flush with one more RPC seems tobe problematic to performance.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"QJM should not consider stale/failed txn available in any one of JNs.","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinayrpet","name":"vinayrpet","key":"vinayrpet","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinayakumar B","active":true,"timeZone":"Asia/Kolkata"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinayrpet","name":"vinayrpet","key":"vinayrpet","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinayakumar B","active":true,"timeZone":"Asia/Kolkata"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/13007487/comment/15522200","id":"15522200","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinayrpet","name":"vinayrpet","key":"vinayrpet","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinayakumar B","active":true,"timeZone":"Asia/Kolkata"},"body":"\nAnalysis\n------------\n1. startLogSegment success in JN1 and failed in JN2,JN3\n{noformat}\n\t2016-09-21 21:34:13,807 FATAL org.apache.hadoop.hdfs.server.namenode.FSEditLog: Error: flush failed for required journal (JournalAndStream(mgr=QJM to [192.167.100.47:8485, 192.167.100.49:8485, 192.167.100.51:8485], stream=QuorumOutputStream starting at txid 195222))\n\torg.apache.hadoop.hdfs.qjournal.client.QuorumException: Got too many exceptions to achieve quorum size 2/3. 1 successful responses:\n\t192.167.100.49:8485: null [success]\n\t2 exceptions thrown:\n\t192.167.100.51:8485: Call From oraclec1h3-iscsi/192.167.100.49 to oraclec1h2-iscsi:8485 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused\n\t192.167.100.47:8485: Call From oraclec1h3-iscsi/192.167.100.49 to oraclec1h1-iscsi:8485 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused\n\t\tat org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)\n\t\tat org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:223)\n\t\tat org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:142)\n\t\tat org.apache.hadoop.hdfs.qjournal.client.QuorumOutputStream.flushAndSync(QuorumOutputStream.java:107)\n\t\tat org.apache.hadoop.hdfs.server.namenode.EditLogOutputStream.flush(EditLogOutputStream.java:113)\n\t\tat org.apache.hadoop.hdfs.server.namenode.EditLogOutputStream.flush(EditLogOutputStream.java:107)\n\t\tat org.apache.hadoop.hdfs.server.namenode.JournalSet$JournalSetOutputStream$8.apply(JournalSet.java:533)\n\t\tat org.apache.hadoop.hdfs.server.namenode.JournalSet.mapJournalsAndReportErrors(JournalSet.java:393)\n\t\tat org.apache.hadoop.hdfs.server.namenode.JournalSet.access$100(JournalSet.java:57)\n\t\tat org.apache.hadoop.hdfs.server.namenode.JournalSet$JournalSetOutputStream.flush(JournalSet.java:529)\n\t\tat org.apache.hadoop.hdfs.server.namenode.FSEditLog.logSync(FSEditLog.java:648)\n\t\tat org.apache.hadoop.hdfs.server.namenode.FSEditLog.startLogSegment(FSEditLog.java:1268)\n\t\tat org.apache.hadoop.hdfs.server.namenode.FSEditLog.openForWrite(FSEditLog.java:323)\n\t\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startActiveServices(FSNamesystem.java:1123)\n\t\tat org.apache.hadoop.hdfs.server.namenode.NameNode$NameNodeHAContext.startActiveServices(NameNode.java:1869)\n\t\tat org.apache.hadoop.hdfs.server.namenode.ha.ActiveState.enterState(ActiveState.java:61)\n\t\tat org.apache.hadoop.hdfs.server.namenode.ha.HAState.setStateInternal(HAState.java:64)\n\t\tat org.apache.hadoop.hdfs.server.namenode.ha.StandbyState.setState(StandbyState.java:49)\n\t\tat org.apache.hadoop.hdfs.server.namenode.NameNode.transitionToActive(NameNode.java:1735)\n\t\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.transitionToActive(NameNodeRpcServer.java:1634)\n\t\tat org.apache.hadoop.ha.protocolPB.HAServiceProtocolServerSideTranslatorPB.transitionToActive(HAServiceProtocolServerSideTranslatorPB.java:107)\n\t\tat org.apache.hadoop.ha.proto.HAServiceProtocolProtos$HAServiceProtocolService$2.callBlockingMethod(HAServiceProtocolProtos.java:4460)\n\t\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)\n\t\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:973)\n\t\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2143)\n\t\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2139)\n\t\tat java.security.AccessController.doPrivileged(Native Method)\n\t\tat javax.security.auth.Subject.doAs(Subject.java:422)\n\t\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1710)\n\t\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2137)\n\t2016-09-21 21:34:13,807 WARN org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Aborting QuorumOutputStream starting at txid 195222\n{noformat}\n2. Next \"recoverUnclosedJournal\" streams is not finalizing in JN1, because JN1's response is coming as last. So its not considered.\n{noformat}\t\n\t2016-09-21 21:40:00,339 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Beginning recovery of unclosed segment starting at txid 195029\n\t2016-09-21 21:40:00,380 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Recovery prepare phase complete. Responses:\n\t192.167.100.47:8485: segmentState { startTxId: 195029 endTxId: 195221 isInProgress: false } lastWriterEpoch: 15 lastCommittedTxId: 195221\n\t192.167.100.51:8485: segmentState { startTxId: 195029 endTxId: 195221 isInProgress: false } lastWriterEpoch: 15 lastCommittedTxId: 195221\n\t2016-09-21 21:40:00,381 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Using longest log: 192.167.100.47:8485=segmentState {\n\t  startTxId: 195029\n\t  endTxId: 195221\n\t  isInProgress: false\n\t}\n\tlastWriterEpoch: 15\n\tlastCommittedTxId: 195221\n{noformat}\n3. While catching up, 195222 was not considered as that was not finalized in JN1.\n\n4. While trying to create the next logSegment, NameNode is finding the same stream available in JN1, so creation failed\n{noformat}\n\t2016-09-21 21:40:00,463 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: Error encountered requiring NN shutdown. Shutting down immediately.\n\tjava.lang.IllegalStateException: Cannot start writing at txid 195222 when there is a stream available for read: org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@1d5067d4\n\t\tat org.apache.hadoop.hdfs.server.namenode.FSEditLog.openForWrite(FSEditLog.java:320)\n\t\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startActiveServices(FSNamesystem.java:1123)\n\t\tat org.apache.hadoop.hdfs.server.namenode.NameNode$NameNodeHAContext.startActiveServices(NameNode.java:1869)\n\t\tat org.apache.hadoop.hdfs.server.namenode.ha.ActiveState.enterState(ActiveState.java:61)\n\t\tat org.apache.hadoop.hdfs.server.namenode.ha.HAState.setStateInternal(HAState.java:64)\n{noformat}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinayrpet","name":"vinayrpet","key":"vinayrpet","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinayakumar B","active":true,"timeZone":"Asia/Kolkata"},"created":"2016-09-26T06:22:26.477+0000","updated":"2016-09-26T06:22:26.477+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13007487/comment/15522464","id":"15522464","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinayrpet","name":"vinayrpet","key":"vinayrpet","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinayakumar B","active":true,"timeZone":"Asia/Kolkata"},"body":"One possible solution could be as below:\n\n1. From all available JNs we can come to know that what is the last readable txn available in each JN.\n2. We can select the *minimum lastReadable txn*, which is matching in min quorum JNs, as max Txn to consider as valid.\n3. If there is any mismatch between lastReadableTxn in available JNs and there is no quorum matching, then read can be failed as stale txns should not be considered.\n\n[~andrew.wang], [~kihwal], [~umamaheswararao], [~szetszwo], please provide your opinions on this, as this seems to be critical to decide valid txns.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinayrpet","name":"vinayrpet","key":"vinayrpet","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinayakumar B","active":true,"timeZone":"Asia/Kolkata"},"created":"2016-09-26T08:34:47.362+0000","updated":"2016-09-26T08:34:47.362+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13007487/comment/15523219","id":"15523219","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinayrpet","name":"vinayrpet","key":"vinayrpet","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinayakumar B","active":true,"timeZone":"Asia/Kolkata"},"body":"Below are some more logs related to recoverUnFinalizedSegments during failover.\n\n1. Active NameNode logs\n{noformat}\n2016-09-21 21:40:00,291 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state\n2016-09-21 21:40:00,301 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Starting recovery process for unclosed journal segments...\n2016-09-21 21:40:00,339 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Successfully started new epoch 16\n2016-09-21 21:40:00,339 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Beginning recovery of unclosed segment starting at txid 195029\n2016-09-21 21:40:00,380 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Recovery prepare phase complete. Responses:\n192.167.100.47:8485: segmentState { startTxId: 195029 endTxId: 195221 isInProgress: false } lastWriterEpoch: 15 lastCommittedTxId: 195221\n192.167.100.51:8485: segmentState { startTxId: 195029 endTxId: 195221 isInProgress: false } lastWriterEpoch: 15 lastCommittedTxId: 195221\n2016-09-21 21:40:00,381 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Using longest log: 192.167.100.47:8485=segmentState {\n  startTxId: 195029\n  endTxId: 195221\n  isInProgress: false\n}\nlastWriterEpoch: 15\nlastCommittedTxId: 195221\n.\n.\n.\n2016-09-21 21:40:00,424 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Catching up to latest edits from old active before taking over writer role in edits logs\n.\n.\n.\n2016-09-21 21:40:00,435 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Will take over writing edit logs at txnid 195222\n2016-09-21 21:40:00,463 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: Error encountered requiring NN shutdown. Shutting down immediately.\njava.lang.IllegalStateException: Cannot start writing at txid 195222 when there is a stream available for read: org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@1d5067d4\n\tat org.apache.hadoop.hdfs.server.namenode.FSEditLog.openForWrite(FSEditLog.java:320)\n\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startActiveServices(FSNamesystem.java:1123)\n{noformat}\n\n2. From JN with stale txn: 192.167.100.49:8485\n{noformat}\n2016-09-21 21:40:00,424 INFO org.apache.hadoop.hdfs.qjournal.server.Journal: Updating lastPromisedEpoch from 15 to 16 for client /192.167.100.49\n2016-09-21 21:40:00,428 INFO org.apache.hadoop.hdfs.qjournal.server.Journal: Scanning storage FileJournalManager(root=/opt/carbondata/HACluster/install/hadoop/journalnode/journalDir/hacluster)\n2016-09-21 21:40:00,433 INFO org.apache.hadoop.hdfs.qjournal.server.Journal: Latest log is EditLogFile(file=/opt/carbondata/HACluster/install/hadoop/journalnode/journalDir/hacluster/current/edits_inprogress_0000000000000195222,first=0000000000000195222,last=0000000000000195222,inProgress=true,hasCorruptHeader=false)\n2016-09-21 21:40:00,460 INFO org.apache.hadoop.hdfs.qjournal.server.Journal: getSegmentInfo(195029): EditLogFile(file=/opt/carbondata/HACluster/install/hadoop/journalnode/journalDir/hacluster/current/edits_0000000000000195029-0000000000000195221,first=0000000000000195029,last=0000000000000195221,inProgress=false,hasCorruptHeader=false) -> startTxId: 195029 endTxId: 195221 isInProgress: false\n2016-09-21 21:40:00,461 INFO org.apache.hadoop.hdfs.qjournal.server.Journal: Prepared recovery for segment 195029: segmentState { startTxId: 195029 endTxId: 195221 isInProgress: false } lastWriterEpoch: 15 lastCommittedTxId: 195221\n2016-09-21 21:40:00,470 INFO org.apache.hadoop.hdfs.qjournal.server.Journal: getSegmentInfo(195029): EditLogFile(file=/opt/carbondata/HACluster/install/hadoop/journalnode/journalDir/hacluster/current/edits_0000000000000195029-0000000000000195221,first=0000000000000195029,last=0000000000000195221,inProgress=false,hasCorruptHeader=false) -> startTxId: 195029 endTxId: 195221 isInProgress: false\n2016-09-21 21:40:00,470 INFO org.apache.hadoop.hdfs.qjournal.server.Journal: Skipping download of log startTxId: 195029 endTxId: 195221 isInProgress: false: already have up-to-date logs\n2016-09-21 21:40:00,472 INFO org.apache.hadoop.hdfs.qjournal.server.Journal: Accepted recovery for segment 195029: segmentState { startTxId: 195029 endTxId: 195221 isInProgress: false } acceptedInEpoch: 16\n{noformat}\n\n3. JN 192.167.100.47:8485\n{noformat}\n2016-09-21 21:40:15,874 INFO org.apache.hadoop.hdfs.qjournal.server.Journal: Updating lastPromisedEpoch from 15 to 16 for client /192.167.100.49\n2016-09-21 21:40:15,877 INFO org.apache.hadoop.hdfs.qjournal.server.Journal: Scanning storage FileJournalManager(root=/opt/carbondata/HACluster/install/hadoop/journalnode/journalDir/hacluster)\n2016-09-21 21:40:15,881 INFO org.apache.hadoop.hdfs.qjournal.server.Journal: Latest log is EditLogFile(file=/opt/carbondata/HACluster/install/hadoop/journalnode/journalDir/hacluster/current/edits_0000000000000195029-0000000000000195221,first=0000000000000195029,last=0000000000000195221,inProgress=false,hasCorruptHeader=false)\n2016-09-21 21:40:15,908 INFO org.apache.hadoop.hdfs.qjournal.server.Journal: getSegmentInfo(195029): EditLogFile(file=/opt/carbondata/HACluster/install/hadoop/journalnode/journalDir/hacluster/current/edits_0000000000000195029-0000000000000195221,first=0000000000000195029,last=0000000000000195221,inProgress=false,hasCorruptHeader=false) -> startTxId: 195029 endTxId: 195221 isInProgress: false\n2016-09-21 21:40:15,909 INFO org.apache.hadoop.hdfs.qjournal.server.Journal: Prepared recovery for segment 195029: segmentState { startTxId: 195029 endTxId: 195221 isInProgress: false } lastWriterEpoch: 15 lastCommittedTxId: 195221\n2016-09-21 21:40:15,939 INFO org.apache.hadoop.hdfs.qjournal.server.Journal: getSegmentInfo(195029): EditLogFile(file=/opt/carbondata/HACluster/install/hadoop/journalnode/journalDir/hacluster/current/edits_0000000000000195029-0000000000000195221,first=0000000000000195029,last=0000000000000195221,inProgress=false,hasCorruptHeader=false) -> startTxId: 195029 endTxId: 195221 isInProgress: false\n2016-09-21 21:40:15,939 INFO org.apache.hadoop.hdfs.qjournal.server.Journal: Skipping download of log startTxId: 195029 endTxId: 195221 isInProgress: false: already have up-to-date logs\n2016-09-21 21:40:15,941 INFO org.apache.hadoop.hdfs.qjournal.server.Journal: Accepted recovery for segment 195029: segmentState { startTxId: 195029 endTxId: 195221 isInProgress: false } acceptedInEpoch: 16\n{noformat}\n\n4. JN 192.167.100.51:8485\n{noformat}\n2016-09-21 21:40:33,523 INFO org.apache.hadoop.hdfs.qjournal.server.Journal: Updating lastPromisedEpoch from 15 to 16 for client /192.167.100.49\n2016-09-21 21:40:33,526 INFO org.apache.hadoop.hdfs.qjournal.server.Journal: Scanning storage FileJournalManager(root=/opt/carbondata/HACluster/install/hadoop/journalnode/journalDir/hacluster)\n2016-09-21 21:40:33,530 INFO org.apache.hadoop.hdfs.qjournal.server.Journal: Latest log is EditLogFile(file=/opt/carbondata/HACluster/install/hadoop/journalnode/journalDir/hacluster/current/edits_0000000000000195029-0000000000000195221,first=0000000000000195029,last=0000000000000195221,inProgress=false,hasCorruptHeader=false)\n2016-09-21 21:40:33,547 INFO org.apache.hadoop.hdfs.qjournal.server.Journal: getSegmentInfo(195029): EditLogFile(file=/opt/carbondata/HACluster/install/hadoop/journalnode/journalDir/hacluster/current/edits_0000000000000195029-0000000000000195221,first=0000000000000195029,last=0000000000000195221,inProgress=false,hasCorruptHeader=false) -> startTxId: 195029 endTxId: 195221 isInProgress: false\n2016-09-21 21:40:33,548 INFO org.apache.hadoop.hdfs.qjournal.server.Journal: Prepared recovery for segment 195029: segmentState { startTxId: 195029 endTxId: 195221 isInProgress: false } lastWriterEpoch: 15 lastCommittedTxId: 195221\n2016-09-21 21:40:33,581 INFO org.apache.hadoop.hdfs.qjournal.server.Journal: getSegmentInfo(195029): EditLogFile(file=/opt/carbondata/HACluster/install/hadoop/journalnode/journalDir/hacluster/current/edits_0000000000000195029-0000000000000195221,first=0000000000000195029,last=0000000000000195221,inProgress=false,hasCorruptHeader=false) -> startTxId: 195029 endTxId: 195221 isInProgress: false\n2016-09-21 21:40:33,582 INFO org.apache.hadoop.hdfs.qjournal.server.Journal: Skipping download of log startTxId: 195029 endTxId: 195221 isInProgress: false: already have up-to-date logs\n2016-09-21 21:40:33,583 INFO org.apache.hadoop.hdfs.qjournal.server.Journal: Accepted recovery for segment 195029: segmentState { startTxId: 195029 endTxId: 195221 isInProgress: false } acceptedInEpoch: 16\n{noformat}\n\nFrom above logs its clear that, JN with highest txn(stale) was not participated in recovery. But during fseditLog.openForWrite(), selectInputStreams() it responded, so starrLogSegment() failed.\n\n*So Another possible solution could be:*\n1. During recovery, discard all segments which are more than requested segment to recover.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinayrpet","name":"vinayrpet","key":"vinayrpet","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinayakumar B","active":true,"timeZone":"Asia/Kolkata"},"created":"2016-09-26T14:26:52.146+0000","updated":"2016-09-26T14:26:52.146+0000"}],"maxResults":3,"total":3,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-10902/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i342bj:"}}