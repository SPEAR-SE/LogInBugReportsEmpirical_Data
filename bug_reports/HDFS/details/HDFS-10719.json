{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12994617","self":"https://issues.apache.org/jira/rest/api/2/issue/12994617","key":"HDFS-10719","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/3","id":"3","description":"The problem is a duplicate of an existing issue.","name":"Duplicate"},"customfield_12312322":null,"customfield_12310220":"2016-08-03T17:29:26.888+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Wed Aug 31 12:00:56 UTC 2016","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_827493_*|*_5_*:*_1_*:*_0_*|*_10002_*:*_1_*:*_2409182306","customfield_12312321":null,"resolutiondate":"2016-08-31T12:59:03.645+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-10719/watchers","watchCount":4,"isWatching":false},"created":"2016-08-03T15:32:15.616+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":["patch"],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"4.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12331979","id":"12331979","description":"2.7.1 release","name":"2.7.1","archived":false,"released":true,"releaseDate":"2015-07-06"}],"issuelinks":[{"id":"12479169","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12479169","type":{"id":"12310000","name":"Duplicate","inward":"is duplicated by","outward":"duplicates","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/12310000"},"inwardIssue":{"id":"12616736","key":"HDFS-4210","self":"https://issues.apache.org/jira/rest/api/2/issue/12616736","fields":{"summary":"Throw helpful exception when DNS entry for JournalNode cannot be resolved","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/5","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/trivial.svg","name":"Trivial","id":"5"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kpalanisamy","name":"kpalanisamy","key":"kpalanisamy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kpalanisamy&avatarId=36559","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kpalanisamy&avatarId=36559","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kpalanisamy&avatarId=36559","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kpalanisamy&avatarId=36559"},"displayName":"Karthik Palanisamy","active":true,"timeZone":"Etc/UTC"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2016-08-31T12:59:05.272+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12319803","id":"12319803","name":"journal-node","description":"Journal Node for the QJM"},{"self":"https://issues.apache.org/jira/rest/api/2/component/12312926","id":"12312926","name":"namenode"}],"timeoriginalestimate":null,"description":"2016-08-03 02:53:53,760 ERROR namenode.NameNode (NameNode.java:main(1712)) - Failed to start namenode.\njava.lang.IllegalArgumentException: Unable to construct journal, qjournal://xxxx1:8485;xxxx2:8485;xxxx3:8485/shva\n        at org.apache.hadoop.hdfs.server.namenode.FSEditLog.createJournal(FSEditLog.java:1637)\n        at org.apache.hadoop.hdfs.server.namenode.FSEditLog.initJournals(FSEditLog.java:282)\n        at org.apache.hadoop.hdfs.server.namenode.FSEditLog.initSharedJournalsForRead(FSEditLog.java:260)\n        at org.apache.hadoop.hdfs.server.namenode.FSImage.initEditLog(FSImage.java:789)\n        at org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:634)\n        at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:294)\n        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:983)\n        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:688)\n        at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:662)\n        at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:726)\n        at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:951)\n        at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:935)\n        at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1641)\n        at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1707)\nCaused by: java.lang.reflect.InvocationTargetException\n        at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n        at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n        at java.lang.reflect.Constructor.newInstance(Constructor.java:422)\n        at org.apache.hadoop.hdfs.server.namenode.FSEditLog.createJournal(FSEditLog.java:1635)\n        ... 13 more\nCaused by: java.lang.NullPointerException\n        at org.apache.hadoop.hdfs.qjournal.client.IPCLoggerChannelMetrics.getName(IPCLoggerChannelMetrics.java:107)\n        at org.apache.hadoop.hdfs.qjournal.client.IPCLoggerChannelMetrics.create(IPCLoggerChannelMetrics.java:91)\n        at org.apache.hadoop.hdfs.qjournal.client.IPCLoggerChannel.<init>(IPCLoggerChannel.java:178)\n        at org.apache.hadoop.hdfs.qjournal.client.IPCLoggerChannel$1.createLogger(IPCLoggerChannel.java:156)\n        at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.createLoggers(QuorumJournalManager.java:367)\n        at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.createLoggers(QuorumJournalManager.java:149)\n        at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.<init>(QuorumJournalManager.java:116)\n        at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.<init>(QuorumJournalManager.java:105)\n        ... 18 more\n2016-08-03 02:53:53,765 INFO  util.ExitUtil (ExitUtil.java:terminate(124)) - Exiting with status 1\n2016-08-03 02:53:53,768 INFO  namenode.NameNode (LogAdapter.java:info(47)) - SHUTDOWN_MSG:\n\n*and the failover is not successful*\n\nI have attached the patch, It allows the Namenode to start if the majority of the Quorums are resolvable.\nthrows warning if the quorum is unresolvable.\nthrows Unknown host exception if the majority of the journals are unresolvable.\n\n","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12821855","id":"12821855","filename":"HDFS-10719-1.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kpalanisamy","name":"kpalanisamy","key":"kpalanisamy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kpalanisamy&avatarId=36559","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kpalanisamy&avatarId=36559","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kpalanisamy&avatarId=36559","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kpalanisamy&avatarId=36559"},"displayName":"Karthik Palanisamy","active":true,"timeZone":"Etc/UTC"},"created":"2016-08-03T15:40:54.706+0000","size":2065,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12821855/HDFS-10719-1.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12822130","id":"12822130","filename":"HDFS-10719-2.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kpalanisamy","name":"kpalanisamy","key":"kpalanisamy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kpalanisamy&avatarId=36559","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kpalanisamy&avatarId=36559","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kpalanisamy&avatarId=36559","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kpalanisamy&avatarId=36559"},"displayName":"Karthik Palanisamy","active":true,"timeZone":"Etc/UTC"},"created":"2016-08-04T18:20:31.011+0000","size":1973,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12822130/HDFS-10719-2.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12824853","id":"12824853","filename":"HDFS-10719-3.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kpalanisamy","name":"kpalanisamy","key":"kpalanisamy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kpalanisamy&avatarId=36559","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kpalanisamy&avatarId=36559","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kpalanisamy&avatarId=36559","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kpalanisamy&avatarId=36559"},"displayName":"Karthik Palanisamy","active":true,"timeZone":"Etc/UTC"},"created":"2016-08-22T14:50:36.597+0000","size":1746,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12824853/HDFS-10719-3.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12825040","id":"12825040","filename":"HDFS-10719-4.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kpalanisamy","name":"kpalanisamy","key":"kpalanisamy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kpalanisamy&avatarId=36559","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kpalanisamy&avatarId=36559","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kpalanisamy&avatarId=36559","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kpalanisamy&avatarId=36559"},"displayName":"Karthik Palanisamy","active":true,"timeZone":"Etc/UTC"},"created":"2016-08-23T12:37:05.129+0000","size":1470,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12825040/HDFS-10719-4.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"In HA, Namenode is failed to start If any of the Quorum hostname is unresolved.","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kpalanisamy","name":"kpalanisamy","key":"kpalanisamy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kpalanisamy&avatarId=36559","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kpalanisamy&avatarId=36559","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kpalanisamy&avatarId=36559","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kpalanisamy&avatarId=36559"},"displayName":"Karthik Palanisamy","active":true,"timeZone":"Etc/UTC"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kpalanisamy","name":"kpalanisamy","key":"kpalanisamy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kpalanisamy&avatarId=36559","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kpalanisamy&avatarId=36559","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kpalanisamy&avatarId=36559","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kpalanisamy&avatarId=36559"},"displayName":"Karthik Palanisamy","active":true,"timeZone":"Etc/UTC"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":"HDP-2.4","customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":[{"self":"https://issues.apache.org/jira/rest/api/2/customFieldOption/10430","value":"Patch","id":"10430"}],"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12994617/comment/15406268","id":"15406268","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 16s{color} | {color:blue} Docker mode activated. {color} |\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  8m 45s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m  1s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 41s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  6s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 18s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 52s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 59s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 48s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 42s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 42s{color} | {color:green} the patch passed {color} |\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 23s{color} | {color:orange} hadoop-hdfs-project/hadoop-hdfs: The patch generated 28 new + 14 unchanged - 0 fixed = 42 total (was 14) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 50s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m  9s{color} | {color:green} the patch passed {color} |\n| {color:red}-1{color} | {color:red} whitespace {color} | {color:red}  0m  0s{color} | {color:red} The patch 19 line(s) with tabs. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 47s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 53s{color} | {color:green} the patch passed {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 78m 37s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 23s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black}100m 43s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| Failed junit tests | hadoop.hdfs.server.datanode.TestFsDatasetCache |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:9560f25 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12821855/HDFS-10719-1.patch |\n| JIRA Issue | HDFS-10719 |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux 785ba208c8e5 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / 2d82276 |\n| Default Java | 1.8.0_101 |\n| findbugs | v3.0.0 |\n| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/16308/artifact/patchprocess/diff-checkstyle-hadoop-hdfs-project_hadoop-hdfs.txt |\n| whitespace | https://builds.apache.org/job/PreCommit-HDFS-Build/16308/artifact/patchprocess/whitespace-tabs.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/16308/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |\n|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/16308/testReport/ |\n| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/16308/console |\n| Powered by | Apache Yetus 0.4.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2016-08-03T17:29:26.888+0000","updated":"2016-08-03T17:29:26.888+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12994617/comment/15408202","id":"15408202","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kpalanisamy","name":"kpalanisamy","key":"kpalanisamy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kpalanisamy&avatarId=36559","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kpalanisamy&avatarId=36559","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kpalanisamy&avatarId=36559","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kpalanisamy&avatarId=36559"},"displayName":"Karthik Palanisamy","active":true,"timeZone":"Etc/UTC"},"body":"The duplicate case has been created with the different tag Hadoop Common HADOOP-13468.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kpalanisamy","name":"kpalanisamy","key":"kpalanisamy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kpalanisamy&avatarId=36559","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kpalanisamy&avatarId=36559","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kpalanisamy&avatarId=36559","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kpalanisamy&avatarId=36559"},"displayName":"Karthik Palanisamy","active":true,"timeZone":"Etc/UTC"},"created":"2016-08-04T17:50:03.657+0000","updated":"2016-08-04T18:18:32.965+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12994617/comment/15408424","id":"15408424","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 11s{color} | {color:blue} Docker mode activated. {color} |\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  8m 15s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 56s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 29s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  1s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 13s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m  3s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 59s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 54s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 51s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 51s{color} | {color:green} the patch passed {color} |\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 27s{color} | {color:orange} hadoop-hdfs-project/hadoop-hdfs: The patch generated 19 new + 13 unchanged - 0 fixed = 32 total (was 13) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 56s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 11s{color} | {color:green} the patch passed {color} |\n| {color:red}-1{color} | {color:red} whitespace {color} | {color:red}  0m  0s{color} | {color:red} The patch has 2 line(s) that end in whitespace. Use git apply --whitespace=fix <<patch_file>>. Refer https://git-scm.com/docs/git-apply {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m  0s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 59s{color} | {color:green} the patch passed {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 58m 48s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 20s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black} 80m 56s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| Failed junit tests | hadoop.tracing.TestTracing |\n|   | hadoop.hdfs.server.blockmanagement.TestComputeInvalidateWork |\n|   | hadoop.security.TestRefreshUserMappings |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:9560f25 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12822130/HDFS-10719-2.patch |\n| JIRA Issue | HDFS-10719 |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux effea6a25399 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / b8ca84a |\n| Default Java | 1.8.0_101 |\n| findbugs | v3.0.0 |\n| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/16322/artifact/patchprocess/diff-checkstyle-hadoop-hdfs-project_hadoop-hdfs.txt |\n| whitespace | https://builds.apache.org/job/PreCommit-HDFS-Build/16322/artifact/patchprocess/whitespace-eol.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/16322/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |\n|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/16322/testReport/ |\n| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/16322/console |\n| Powered by | Apache Yetus 0.4.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2016-08-04T20:18:27.616+0000","updated":"2016-08-04T20:18:27.616+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12994617/comment/15431140","id":"15431140","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 19s{color} | {color:blue} Docker mode activated. {color} |\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  8m 41s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 54s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 30s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 10s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 17s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m  5s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m  2s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m  0s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 59s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 59s{color} | {color:green} the patch passed {color} |\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 27s{color} | {color:orange} hadoop-hdfs-project/hadoop-hdfs: The patch generated 3 new + 14 unchanged - 0 fixed = 17 total (was 14) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 58s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 10s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 49s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 54s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} unit {color} | {color:green} 76m 54s{color} | {color:green} hadoop-hdfs in the patch passed. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 19s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black} 99m 45s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:9560f25 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12824853/HDFS-10719-3.patch |\n| JIRA Issue | HDFS-10719 |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux 96163359e55b 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / 115ecb5 |\n| Default Java | 1.8.0_101 |\n| findbugs | v3.0.0 |\n| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/16498/artifact/patchprocess/diff-checkstyle-hadoop-hdfs-project_hadoop-hdfs.txt |\n|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/16498/testReport/ |\n| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/16498/console |\n| Powered by | Apache Yetus 0.4.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2016-08-22T16:38:26.091+0000","updated":"2016-08-22T16:38:26.091+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12994617/comment/15432716","id":"15432716","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kpalanisamy","name":"kpalanisamy","key":"kpalanisamy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kpalanisamy&avatarId=36559","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kpalanisamy&avatarId=36559","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kpalanisamy&avatarId=36559","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kpalanisamy&avatarId=36559"},"displayName":"Karthik Palanisamy","active":true,"timeZone":"Etc/UTC"},"body":"I simplify the fix here by throwing UnknownHostException instead NullPointer exception, also pointing hostname from URI which is unresolved.\n\n*Without fix*\n\n{panel}\n2016-08-23 11:54:19,780 ERROR namenode.NameNode (NameNode.java:main(1712)) - Failed to start namenode.\njava.lang.IllegalArgumentException: Unable to construct journal, qjournal://kart2402.xxx.com:8485;kart2401.xxx.com:8485;kart2403.xxx.com:8485/karthik\n       \tat org.apache.hadoop.hdfs.server.namenode.FSEditLog.createJournal(FSEditLog.java:1637)\n       \tat org.apache.hadoop.hdfs.server.namenode.FSEditLog.initJournals(FSEditLog.java:282)\n       \tat org.apache.hadoop.hdfs.server.namenode.FSEditLog.initSharedJournalsForRead(FSEditLog.java:260)\n       \tat org.apache.hadoop.hdfs.server.namenode.FSImage.initEditLog(FSImage.java:789)\n       \tat org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:634)\n       \tat org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:294)\n       \tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:983)\n       \tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:688)\n       \tat org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:662)\n       \tat org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:722)\n       \tat org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:951)\n       \tat org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:935)\n       \tat org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1641)\n       \tat org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1707)\nCaused by: java.lang.reflect.InvocationTargetException\n       \tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n       \tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n       \tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n       \tat java.lang.reflect.Constructor.newInstance(Constructor.java:422)\n       \tat org.apache.hadoop.hdfs.server.namenode.FSEditLog.createJournal(FSEditLog.java:1635)\n       \t... 13 more\nCaused by: java.lang.NullPointerException\n       \tat org.apache.hadoop.hdfs.qjournal.client.IPCLoggerChannelMetrics.getName(IPCLoggerChannelMetrics.java:107)\n       \tat org.apache.hadoop.hdfs.qjournal.client.IPCLoggerChannelMetrics.create(IPCLoggerChannelMetrics.java:91)\n       \tat org.apache.hadoop.hdfs.qjournal.client.IPCLoggerChannel.<init>(IPCLoggerChannel.java:178)\n       \tat org.apache.hadoop.hdfs.qjournal.client.IPCLoggerChannel$1.createLogger(IPCLoggerChannel.java:156)\n       \tat org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.createLoggers(QuorumJournalManager.java:367)\n       \tat org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.createLoggers(QuorumJournalManager.java:149)\n       \tat org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.<init>(QuorumJournalManager.java:116)\n       \tat org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.<init>(QuorumJournalManager.java:105)\n       \t... 18 more\n{panel}\n\n\n*With fix*\n\n{panel}\n2016-08-23 12:03:02,621 ERROR namenode.NameNode (NameNode.java:main(1712)) - Failed to start namenode.\njava.lang.IllegalArgumentException: Unable to construct journal, qjournal://kart2402.xxx.com:8485;kart2401.xxx.com:8485;kart2403.xxx.com:8485/karthik\n       \tat org.apache.hadoop.hdfs.server.namenode.FSEditLog.createJournal(FSEditLog.java:1637)\n       \tat org.apache.hadoop.hdfs.server.namenode.FSEditLog.initJournals(FSEditLog.java:282)\n       \tat org.apache.hadoop.hdfs.server.namenode.FSEditLog.initSharedJournalsForRead(FSEditLog.java:260)\n       \tat org.apache.hadoop.hdfs.server.namenode.FSImage.initEditLog(FSImage.java:789)\n       \tat org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:634)\n       \tat org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:294)\n       \tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:983)\n       \tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:688)\n       \tat org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:662)\n       \tat org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:722)\n       \tat org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:951)\n       \tat org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:935)\n       \tat org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1641)\n       \tat org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1707)\nCaused by: java.lang.reflect.InvocationTargetException\n       \tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n       \tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n       \tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n       \tat java.lang.reflect.Constructor.newInstance(Constructor.java:422)\n       \tat org.apache.hadoop.hdfs.server.namenode.FSEditLog.createJournal(FSEditLog.java:1635)\n       \t... 13 more\nCaused by: java.net.UnknownHostException: [kart2403.xxx.com:8485]\n       \tat org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.getLoggerAddresses(QuorumJournalManager.java:404)\n       \tat org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.createLoggers(QuorumJournalManager.java:367)\n       \tat org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.createLoggers(QuorumJournalManager.java:152)\n       \tat org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.<init>(QuorumJournalManager.java:119)\n       \tat org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.<init>(QuorumJournalManager.java:108)\n       \t... 18 more\n{panel}\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kpalanisamy","name":"kpalanisamy","key":"kpalanisamy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kpalanisamy&avatarId=36559","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kpalanisamy&avatarId=36559","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kpalanisamy&avatarId=36559","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kpalanisamy&avatarId=36559"},"displayName":"Karthik Palanisamy","active":true,"timeZone":"Etc/UTC"},"created":"2016-08-23T12:41:57.438+0000","updated":"2016-08-23T12:41:57.438+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12994617/comment/15432866","id":"15432866","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 21s{color} | {color:blue} Docker mode activated. {color} |\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  7m 23s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 47s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 26s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 53s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 13s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 45s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 55s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 47s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 45s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 45s{color} | {color:green} the patch passed {color} |\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 24s{color} | {color:orange} hadoop-hdfs-project/hadoop-hdfs: The patch generated 3 new + 14 unchanged - 0 fixed = 17 total (was 14) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 48s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 10s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 48s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 57s{color} | {color:green} the patch passed {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 77m 55s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 20s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black} 98m  0s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| Failed junit tests | hadoop.hdfs.server.namenode.snapshot.TestSnapshotFileLength |\n|   | hadoop.hdfs.web.TestWebHDFS |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:9560f25 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12824853/HDFS-10719-3.patch |\n| JIRA Issue | HDFS-10719 |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux bf430ba7ac44 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / f0efea4 |\n| Default Java | 1.8.0_101 |\n| findbugs | v3.0.0 |\n| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/16510/artifact/patchprocess/diff-checkstyle-hadoop-hdfs-project_hadoop-hdfs.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/16510/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |\n|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/16510/testReport/ |\n| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/16510/console |\n| Powered by | Apache Yetus 0.4.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2016-08-23T14:16:38.625+0000","updated":"2016-08-23T14:16:38.625+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12994617/comment/15452044","id":"15452044","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=arpitagarwal","name":"arpitagarwal","key":"arpitagarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arpit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"body":"Looks like a similar fix was made by HDFS-4210 recently. Karthik, you can probably resolve this as a duplicate of HDFS-4210.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=arpitagarwal","name":"arpitagarwal","key":"arpitagarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arpit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-08-31T12:00:56.536+0000","updated":"2016-08-31T12:00:56.536+0000"}],"maxResults":7,"total":7,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-10719/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i31uzj:"}}