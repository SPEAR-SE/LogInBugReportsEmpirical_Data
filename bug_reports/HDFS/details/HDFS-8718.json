{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12843138","self":"https://issues.apache.org/jira/rest/api/2/issue/12843138","key":"HDFS-8718","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/3","id":"3","description":"The problem is a duplicate of an existing issue.","name":"Duplicate"},"customfield_12312322":null,"customfield_12310220":"2015-07-07T16:25:24.301+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Thu Aug 09 16:42:05 UTC 2018","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_97573072033_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2018-08-09T16:42:05.035+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-8718/watchers","watchCount":14,"isWatching":false},"created":"2015-07-07T09:04:13.081+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12327584","id":"12327584","description":"2.7.0 release","name":"2.7.0","archived":false,"released":true,"releaseDate":"2015-04-20"}],"issuelinks":[{"id":"12540687","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12540687","type":{"id":"12310000","name":"Duplicate","inward":"is duplicated by","outward":"duplicates","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/12310000"},"outwardIssue":{"id":"12972299","key":"HDFS-10453","self":"https://issues.apache.org/jira/rest/api/2/issue/12972299","fields":{"summary":"ReplicationMonitor thread could stuck for long time due to the race between replication and delete of same file in a large cluster.","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}}],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2018-08-09T16:49:56.685+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[],"timeoriginalestimate":null,"description":"Decommission a datanode from hadoop, and hdfs can calculate the correct number of  blocks to be replicated from web-ui. \n{code}\nDecomissioning\nNode\tLast contact\tUnder replicated blocks\tBlocks with no live replicas\tUnder Replicated Blocks \nIn files under construction\nTS-BHTEST-03:50010 (172.22.49.3:50010)\t\t25641\t0\t0\n{code}\n\nFrom NN's log, the work of block replicating cannot be enforced due to inconsistent expected storage type.\n\n{code}\nNode /default/rack_02/172.22.49.5:50010 [\n  Storage [DISK]DS-3915533b-4ae4-4806-bf83caf1446f1e2f:NORMAL:172.22.49.5:50010 is not chosen since storage types do not match, where the required storage type is ARCHIVE.\n  Storage [DISK]DS-3e54c331-3eaf-4447-b5e4-9bf91bc71b17:NORMAL:172.22.49.5:50010 is not chosen since storage types do not match, where the required storage type is ARCHIVE.\n  Storage [DISK]DS-d44fa611-aa73-4415-a2de-7e73c9c5ea68:NORMAL:172.22.49.5:50010 is not chosen since storage types do not match, where the required storage type is ARCHIVE.\n  Storage [DISK]DS-cebbf410-06a0-4171-a9bd-d0db55dad6d3:NORMAL:172.22.49.5:50010 is not chosen since storage types do not match, where the required storage type is ARCHIVE.\n  Storage [DISK]DS-4c50b1c7-eaad-4858-b476-99dec17d68b5:NORMAL:172.22.49.5:50010 is not chosen since storage types do not match, where the required storage type is ARCHIVE.\n  Storage [DISK]DS-f6cf9123-4125-4234-8e21-34b12170e576:NORMAL:172.22.49.5:50010 is not chosen since storage types do not match, where the required storage type is ARCHIVE.\n  Storage [DISK]DS-7601b634-1761-45cc-9ffd-73ee8687c2a7:NORMAL:172.22.49.5:50010 is not chosen since storage types do not match, where the required storage type is ARCHIVE.\n  Storage [DISK]DS-1d4b91ab-fe2f-4d5f-bd0a-57e9a0714654:NORMAL:172.22.49.5:50010 is not chosen since storage types do not match, where the required storage type is ARCHIVE.\n  Storage [DISK]DS-cd2279cf-9c5a-4380-8c41-7681fa688eaf:NORMAL:172.22.49.5:50010 is not chosen since storage types do not match, where the required storage type is ARCHIVE.\n  Storage [DISK]DS-630c734f-334a-466d-9649-4818d6e91181:NORMAL:172.22.49.5:50010 is not chosen since storage types do not match, where the required storage type is ARCHIVE.\n  Storage [DISK]DS-31cd0d68-5f7c-4a0a-91e6-afa53c4df820:NORMAL:172.22.49.5:50010 is not chosen since storage types do not match, where the required storage type is ARCHIVE.\n]\n2015-07-07 16:00:22,032 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but onl\ny 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK, ARCHIVE], removed=[DISK], policy=BlockStoragePolicy{HOT:7,\n storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})\n2015-07-07 16:00:22,032 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in n\need of 1 to reach 3 (unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[],\n replicationFallbacks=[ARCHIVE]}, newBlock=false) All required storage types are unavailable:  unavailableStorages=[DISK, ARCHIVE], storageP\nolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}\n{code}\n\nWe have upgraded the hadoop cluster from 2.5 to 2.7.0 previously. I believe the feature of ARCHIVE STORAGE has been enforced, but how about the block's storage type after upgrading?\n\nThe default BlockStoragePolicy is hot, and I guess those blocks do not have the correct information bit of BlockStoragePolicy, so it cannot be handled well.\nAfter I shutdown the datanode, the under-replicated blocks can be asked to copy. So the workaround is to shutdown the datanode. \n\nCould anyone take a look at the issue? ","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"Block replicating cannot work after upgrading to 2.7 ","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jiangbinglover","name":"jiangbinglover","key":"jiangbinglover","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Bing Jiang","active":true,"timeZone":"Asia/Hong_Kong"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jiangbinglover","name":"jiangbinglover","key":"jiangbinglover","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Bing Jiang","active":true,"timeZone":"Asia/Hong_Kong"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12843138/comment/14616936","id":"14616936","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=arpitagarwal","name":"arpitagarwal","key":"arpitagarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arpit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi [~jianbginglover], do you have ARCHIVE storage policy configured on any files/directories? Also are any of your DataNodes configured with ARCHIVE storage?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=arpitagarwal","name":"arpitagarwal","key":"arpitagarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arpit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-07-07T16:25:24.301+0000","updated":"2015-07-07T16:25:24.301+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12843138/comment/14617750","id":"14617750","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jiangbinglover","name":"jiangbinglover","key":"jiangbinglover","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Bing Jiang","active":true,"timeZone":"Asia/Hong_Kong"},"body":"No, I have upgraded from 2.5. I have not done any modification on hdfs-site.xml. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jiangbinglover","name":"jiangbinglover","key":"jiangbinglover","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Bing Jiang","active":true,"timeZone":"Asia/Hong_Kong"},"created":"2015-07-08T00:48:48.924+0000","updated":"2015-07-08T00:48:48.924+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12843138/comment/14618740","id":"14618740","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kanaka","name":"kanaka","key":"kanaka","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kanaka&avatarId=24828","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kanaka&avatarId=24828","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kanaka&avatarId=24828","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kanaka&avatarId=24828"},"displayName":"Kanaka Kumar Avvaru","active":true,"timeZone":"Asia/Kolkata"},"body":"Hi [~jianbginglover], \n\nI think this log must be preceded with some other log message which looks like \n{code} Failed to place enough replicas, still in need of X to reach Y (unavailableStorages=[DISK, ARCHIVE] , storagePolicy={HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true/false) {code}\n\nIf possible please share NN logs with may give clue on root cause.\n\nAlso, please confirm both the machines {{172.22.49.3 and 172.22.49.5}} are in same rack or not","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kanaka","name":"kanaka","key":"kanaka","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kanaka&avatarId=24828","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kanaka&avatarId=24828","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kanaka&avatarId=24828","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kanaka&avatarId=24828"},"displayName":"Kanaka Kumar Avvaru","active":true,"timeZone":"Asia/Kolkata"},"created":"2015-07-08T15:01:42.548+0000","updated":"2015-07-08T15:01:42.548+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12843138/comment/14619778","id":"14619778","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jiangbinglover","name":"jiangbinglover","key":"jiangbinglover","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Bing Jiang","active":true,"timeZone":"Asia/Hong_Kong"},"body":"[~kanaka] \n\nYou are right. The two nodes are not in the same rack, and actually 172.22.49.3 has been configured in one rack without any other nodes.\n{code}\n===========\n\nbh@TS-BHTEST-01 hadoop $ hdfs dfsadmin -printTopology\nRack: /default/rack_02\n   172.22.49.2:50010 (TS-BHTEST-02)\n   172.22.49.4:50010 (TS-BHTEST-04)\n   172.22.49.5:50010 (TS-BHTEST-05)\n   172.22.49.6:50010 (TS-BHTEST-06)\n   172.22.49.7:50010 (TS-BHTEST-07)\n\nRack: /default/rack_03\n   172.22.49.3:50010 (TS-BHTEST-03)\n\n{code}\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jiangbinglover","name":"jiangbinglover","key":"jiangbinglover","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Bing Jiang","active":true,"timeZone":"Asia/Hong_Kong"},"created":"2015-07-09T02:53:19.466+0000","updated":"2015-07-09T02:53:19.466+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12843138/comment/14619826","id":"14619826","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jiangbinglover","name":"jiangbinglover","key":"jiangbinglover","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Bing Jiang","active":true,"timeZone":"Asia/Hong_Kong"},"body":"Meanwhile, there are some DEBUG logs:\n{code}\n2015-07-09 11:33:05,406 DEBUG org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to choose from local rack (location = /default/rack_03), retry with the rack of the next replica (location = /default/rack_02)\norg.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy$NotEnoughReplicasException: \n        at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRandom(BlockPlacementPolicyDefault.java:690)\n        at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRandom(BlockPlacementPolicyDefault.java:605)\n        at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseLocalRack(BlockPlacementPolicyDefault.java:511)\n        at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:362)\n        at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:213)\n        at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:110)\n        at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$ReplicationWork.chooseTargets(BlockManager.java:3718)\n        at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$ReplicationWork.access$200(BlockManager.java:3683)\n        at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.computeReplicationWorkForBlocks(BlockManager.java:1407)\n        at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.computeReplicationWork(BlockManager.java:1313)\n        at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.computeDatanodeWork(BlockManager.java:3654)\n        at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$ReplicationMonitor.run(BlockManager.java:3606)\n        at java.lang.Thread.run(Thread.java:745)\n{code}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jiangbinglover","name":"jiangbinglover","key":"jiangbinglover","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Bing Jiang","active":true,"timeZone":"Asia/Hong_Kong"},"created":"2015-07-09T03:35:10.919+0000","updated":"2015-07-09T03:35:10.919+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12843138/comment/15268067","id":"15268067","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hexiaoqiao","name":"hexiaoqiao","key":"hexiaoqiao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hexiaoqiao&avatarId=26980","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hexiaoqiao&avatarId=26980","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hexiaoqiao&avatarId=26980","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hexiaoqiao&avatarId=26980"},"displayName":"He Xiaoqiao","active":true,"timeZone":"Asia/Shanghai"},"body":"i met the same problem after upgraded the cluster to 2.7.1, and never config ARCHIVE storage policy.\n\n{code:xml}\n2016-04-19 10:20:48,083 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 7 to reach 10 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy\n...\n2016-04-19 10:21:17,184 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 7 to reach 10 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy\n2016-04-19 10:21:17,184 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 7 but only 0 storage types can be selected (replication=10, selected=[], unavailable=[DISK, ARCHIVE], removed=[DISK, DISK, DISK, DISK, DISK, DISK, DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})\n2016-04-19 10:21:17,184 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 7 to reach 10 (unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) All required storage types are unavailable:  unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}\n{code}\n\nabove NN log is all about ReplicationMonitor process one {{ReplicationWork}}, it depicts that {{ReplicationWork}} can not choose any proper targets which StorageType should be DISK although traverse all DN of the Cluster. then {{DISK}} is added to {{unavailableStorages}}, the next loop {{ARCHIVE}} is added to {{unavailableStorages}} because there is no ARCHIVE storage. After that throw NotEnoughReplicasException.\n\nThe core Question is *WHY it can NOT choose any proper datanode as target in {{ReplicationWork}} successfully, even if there are thousand DNs in the cluster*.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hexiaoqiao","name":"hexiaoqiao","key":"hexiaoqiao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hexiaoqiao&avatarId=26980","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hexiaoqiao&avatarId=26980","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hexiaoqiao&avatarId=26980","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hexiaoqiao&avatarId=26980"},"displayName":"He Xiaoqiao","active":true,"timeZone":"Asia/Shanghai"},"created":"2016-05-03T04:18:31.168+0000","updated":"2016-05-03T04:18:31.168+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12843138/comment/15303438","id":"15303438","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hexiaoqiao","name":"hexiaoqiao","key":"hexiaoqiao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hexiaoqiao&avatarId=26980","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hexiaoqiao&avatarId=26980","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hexiaoqiao&avatarId=26980","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hexiaoqiao&avatarId=26980"},"displayName":"He Xiaoqiao","active":true,"timeZone":"Asia/Shanghai"},"body":"hi [~jianbginglover] and [~kanaka], ReplicationMonitor stuck for long time since *Global Lock*, and this caused block replicating could not work as expected. I create new issue [HDFS-10453|https://issues.apache.org/jira/browse/HDFS-10453] to describe this problem in detail and upload patch with solution.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hexiaoqiao","name":"hexiaoqiao","key":"hexiaoqiao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hexiaoqiao&avatarId=26980","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hexiaoqiao&avatarId=26980","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hexiaoqiao&avatarId=26980","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hexiaoqiao&avatarId=26980"},"displayName":"He Xiaoqiao","active":true,"timeZone":"Asia/Shanghai"},"created":"2016-05-27T04:03:09.805+0000","updated":"2016-05-27T04:03:09.805+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12843138/comment/15745858","id":"15745858","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wutaklon%40amazon.com","name":"wutaklon@amazon.com","key":"wutaklon@amazon.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10443","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10443","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10443","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10443"},"displayName":"Taklon Stephen Wu","active":true,"timeZone":"Etc/UTC"},"body":"+1","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=wutaklon%40amazon.com","name":"wutaklon@amazon.com","key":"wutaklon@amazon.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10443","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10443","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10443","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10443"},"displayName":"Taklon Stephen Wu","active":true,"timeZone":"Etc/UTC"},"created":"2016-12-13T18:31:58.581+0000","updated":"2016-12-13T18:31:58.581+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12843138/comment/16575112","id":"16575112","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks [~hexiaoqiao] for identifying the duplicates and [~jiangbinglover] for reporting this issue.\r\n\r\nI'll go ahead and close this Jira as a dup of HDFS-10453.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"created":"2018-08-09T16:42:05.086+0000","updated":"2018-08-09T16:42:05.086+0000"}],"maxResults":9,"total":9,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-8718/votes","votes":1,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i2gxhj:"}}