{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12896356","self":"https://issues.apache.org/jira/rest/api/2/issue/12896356","key":"HDFS-9143","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/3","id":"3","description":"The problem is a duplicate of an existing issue.","name":"Duplicate"},"customfield_12312322":null,"customfield_12310220":null,"customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Fri Sep 25 09:26:51 UTC 2015","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_254941723_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2015-09-28T07:45:53.335+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-9143/watchers","watchCount":8,"isWatching":false},"created":"2015-09-25T08:56:51.684+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/4","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/minor.svg","name":"Minor","id":"4"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12326143","id":"12326143","description":"2.4.0 release","name":"2.4.0","archived":false,"released":true,"releaseDate":"2014-04-07"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12327181","id":"12327181","description":"2.6.0 release","name":"2.6.0","archived":false,"released":true,"releaseDate":"2014-11-18"}],"issuelinks":[{"id":"12443226","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12443226","type":{"id":"12310000","name":"Duplicate","inward":"is duplicated by","outward":"duplicates","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/12310000"},"outwardIssue":{"id":"12730227","key":"HDFS-6763","self":"https://issues.apache.org/jira/rest/api/2/issue/12730227","fields":{"summary":"Initialize file system-wide quota once on transitioning to active","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}}],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2015-09-28T07:45:53.359+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12312926","id":"12312926","name":"namenode"}],"timeoriginalestimate":null,"description":"I have seen many logs from datanodes in our cluster reporting socket timeout when sending heartbeat or blockReceivedAndDeleted to Standby NameNode, but it never happen to Active NameNode.  \nAt first, i thought it maybe caused by Editlog Tailer fetch Editlog too much making full gc, but after i watched the gc log, it is not. So i investigate the code path and log, find it only take very few seconds for the SNN to fetch the journal and merge it. But when you open the webpage of SNN during merge processing, it can not response  like stop the world time of full GC, but there is no gc at that time. So i jstack SNN for some time, and finding all the time consumed by updateCountForQuota method in FSImage.  \nThe updateCountForQuota is called ervry time when loadEdits, it update the count of each directory with quota in the namespace from ROOT, besides it hold the write lock of FSImage, so every time when SNN merge the edit from JN, it is always making the stop world.  \nI don't think it is necessary for SNN to updateCountForQuota everytime when tail the edit, when trasition to Active, it call updateCountForQuota and never missing any quota data.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"updateCountForQuota method during EditlogTailer loadEdit can make SNN timeout very often ","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jiangyu1211","name":"jiangyu1211","key":"jiangyu1211","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"jiangyu","active":true,"timeZone":"Asia/Shanghai"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jiangyu1211","name":"jiangyu1211","key":"jiangyu1211","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"jiangyu","active":true,"timeZone":"Asia/Shanghai"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12896356/comment/14907825","id":"14907825","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jiangyu1211","name":"jiangyu1211","key":"jiangyu1211","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"jiangyu","active":true,"timeZone":"Asia/Shanghai"},"body":"Here is the log from DataNode:\njava.net.SocketTimeoutException: Call From snn/10.39.5.22 to 10.39.5.42:8020 failed on socket timeout exception: java.net.SocketTimeoutException: 60000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.39.5.22:57698 remote=10.39.5.42/10.39.5.42:8020]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout\n        at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n        at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)\n        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n        at java.lang.reflect.Constructor.newInstance(Constructor.java:526)\n        at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)\n        at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:749)\n        at org.apache.hadoop.ipc.Client.call(Client.java:1414)\n        at org.apache.hadoop.ipc.Client.call(Client.java:1363)\n        at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)\n        at com.sun.proxy.$Proxy14.blockReceivedAndDeleted(Unknown Source)\n        at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:606)\n        at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:190)\n        at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:103)\n        at com.sun.proxy.$Proxy14.blockReceivedAndDeleted(Unknown Source)\n        at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.blockReceivedAndDeleted(DatanodeProtocolClientSideTranslatorPB.java:263)\n        at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.reportReceivedDeletedBlocks(BPServiceActor.java:307)\n        at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:711)\n        at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:839)\n        at java.lang.Thread.run(Thread.java:745)\nCaused by: java.net.SocketTimeoutException: 60000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.39.5.22:57698 remote=10.39.5.42/10.39.5.42:8020]\n        at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)\n        at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)\n        at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)\n        at java.io.FilterInputStream.read(FilterInputStream.java:133)\n        at java.io.FilterInputStream.read(FilterInputStream.java:133)\n        at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:510)\n        at java.io.BufferedInputStream.fill(BufferedInputStream.java:235)\n        at java.io.BufferedInputStream.read(BufferedInputStream.java:254)\n        at java.io.DataInputStream.readInt(DataInputStream.java:387)\n        at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1054)\n        at org.apache.hadoop.ipc.Client$Connection.run(Client.java:949)","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jiangyu1211","name":"jiangyu1211","key":"jiangyu1211","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"jiangyu","active":true,"timeZone":"Asia/Shanghai"},"created":"2015-09-25T08:58:27.684+0000","updated":"2015-09-25T08:58:27.684+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12896356/comment/14907829","id":"14907829","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jiangyu1211","name":"jiangyu1211","key":"jiangyu1211","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"jiangyu","active":true,"timeZone":"Asia/Shanghai"},"body":"Here is the log from SNN:\n2015-09-25 12:08:21,289 WARN org.apache.hadoop.ipc.Server: IPC Server handler 118 on 8020, call org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol.blockReceivedAndDeleted from 10.39.7.50:35587 Call#1454030 Retry#0: output error\n2015-09-25 12:08:21,289 WARN org.apache.hadoop.ipc.Server: IPC Server handler 74 on 8020, call org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol.blockReceivedAndDeleted from 10.39.5.22:57698 Call#2825473 Retry#0: output error\n2015-09-25 12:08:21,288 WARN org.apache.hadoop.ipc.Server: IPC Server handler 91 on 8020, call org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol.blockReceivedAndDeleted from 10.39.5.27:48523 Call#1297974 Retry#0: output error\n2015-09-25 12:08:21,288 WARN org.apache.hadoop.ipc.Server: IPC Server handler 50 on 8020, call org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol.blockReceivedAndDeleted from 10.39.5.28:47496 Call#1325076 Retry#0: output error\n\nI also log the time of updateCountForQuota:\n2015-09-25 03:14:13,951 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://10.39.5.41:8480/getJournal?jid=ns1&segmentTxId=205812193&storageInfo=-56%3A358820969%3A0%3ACID-1561e550-a7b9-4886-8a9a-cc2328b82912&ugi=hadoop, http://10.39.5.42:8480/getJournal?jid=ns1&segmentTxId=205812193&storageInfo=-56%3A358820969%3A0%3ACID-1561e550-a7b9-4886-8a9a-cc2328b82912&ugi=hadoop of size 221412 edits # 2403 loaded in 0 seconds\n2015-09-25 03:14:50,657 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Update count time :36706\n2015-09-25 03:14:50,657 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Loaded 2403 edits starting from txid 205812192","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jiangyu1211","name":"jiangyu1211","key":"jiangyu1211","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"jiangyu","active":true,"timeZone":"Asia/Shanghai"},"created":"2015-09-25T09:00:40.322+0000","updated":"2015-09-25T09:00:40.322+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12896356/comment/14907833","id":"14907833","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jiangyu1211","name":"jiangyu1211","key":"jiangyu1211","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"jiangyu","active":true,"timeZone":"Asia/Shanghai"},"body":"It is easy to reproduce it,  you can use a mapreduce program to make dir , when you make over one hundred million dirs, you can finding this situation every time. I only use 20 datanodes to test it.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jiangyu1211","name":"jiangyu1211","key":"jiangyu1211","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"jiangyu","active":true,"timeZone":"Asia/Shanghai"},"created":"2015-09-25T09:04:06.548+0000","updated":"2015-09-25T09:04:06.548+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12896356/comment/14907851","id":"14907851","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jiangyu1211","name":"jiangyu1211","key":"jiangyu1211","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"jiangyu","active":true,"timeZone":"Asia/Shanghai"},"body":"The updateCountForQuota method hold the write lock  of FSNamesystem, not FSImage, my mistake.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jiangyu1211","name":"jiangyu1211","key":"jiangyu1211","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"jiangyu","active":true,"timeZone":"Asia/Shanghai"},"created":"2015-09-25T09:26:51.682+0000","updated":"2015-09-25T09:26:51.682+0000"}],"maxResults":4,"total":4,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-9143/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i2lk27:"}}