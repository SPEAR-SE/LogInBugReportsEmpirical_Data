{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"13028217","self":"https://issues.apache.org/jira/rest/api/2/issue/13028217","key":"HDFS-11246","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":"2016-12-14T22:14:57.153+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Tue Nov 28 18:54:52 UTC 2017","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-11246/watchers","watchCount":11,"isWatching":false},"created":"2016-12-14T22:05:59.588+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"5.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12333995","id":"12333995","description":"2.7.3 release","name":"2.7.3","archived":false,"released":true,"releaseDate":"2016-08-25"}],"issuelinks":[],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kshukla","name":"kshukla","key":"kshukla","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=34050","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34050","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34050","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34050"},"displayName":"Kuhu Shukla","active":true,"timeZone":"Etc/UTC"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2017-11-28T18:54:52.401+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/10002","description":"A patch for this issue has been uploaded to JIRA by a contributor.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/document.png","name":"Patch Available","id":"10002","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/4","id":4,"key":"indeterminate","colorName":"yellow","name":"In Progress"}},"components":[],"timeoriginalestimate":null,"description":"{code}\n    readLock();\n    boolean success = true;\n    ContentSummary cs;\n    try {\n      checkOperation(OperationCategory.READ);\n      cs = FSDirStatAndListingOp.getContentSummary(dir, src);\n    } catch (AccessControlException ace) {\n      success = false;\n      logAuditEvent(success, operationName, src);\n      throw ace;\n    } finally {\n      readUnlock(operationName);\n    }\n{code}\n\nIt would be nice to have audit logging outside the lock esp. in scenarios where applications hammer a given operation several times. ","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12877677","id":"12877677","filename":"HDFS-11246.001.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kshukla","name":"kshukla","key":"kshukla","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=34050","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34050","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34050","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34050"},"displayName":"Kuhu Shukla","active":true,"timeZone":"Etc/UTC"},"created":"2017-07-17T21:14:07.494+0000","size":39114,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12877677/HDFS-11246.001.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12877827","id":"12877827","filename":"HDFS-11246.002.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kshukla","name":"kshukla","key":"kshukla","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=34050","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34050","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34050","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34050"},"displayName":"Kuhu Shukla","active":true,"timeZone":"Etc/UTC"},"created":"2017-07-18T16:03:40.257+0000","size":39157,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12877827/HDFS-11246.002.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12892402","id":"12892402","filename":"HDFS-11246.003.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kshukla","name":"kshukla","key":"kshukla","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=34050","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34050","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34050","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34050"},"displayName":"Kuhu Shukla","active":true,"timeZone":"Etc/UTC"},"created":"2017-10-16T15:56:26.039+0000","size":44591,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12892402/HDFS-11246.003.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12895950","id":"12895950","filename":"HDFS-11246.004.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kshukla","name":"kshukla","key":"kshukla","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=34050","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34050","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34050","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34050"},"displayName":"Kuhu Shukla","active":true,"timeZone":"Etc/UTC"},"created":"2017-11-03T19:17:56.382+0000","size":53720,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12895950/HDFS-11246.004.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12899635","id":"12899635","filename":"HDFS-11246.005.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kshukla","name":"kshukla","key":"kshukla","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=34050","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34050","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34050","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34050"},"displayName":"Kuhu Shukla","active":true,"timeZone":"Etc/UTC"},"created":"2017-11-28T15:37:09.723+0000","size":53628,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12899635/HDFS-11246.005.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"FSNameSystem#logAuditEvent should be called outside the read or write locks","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kshukla","name":"kshukla","key":"kshukla","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=34050","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34050","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34050","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34050"},"displayName":"Kuhu Shukla","active":true,"timeZone":"Etc/UTC"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kshukla","name":"kshukla","key":"kshukla","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=34050","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34050","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34050","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34050"},"displayName":"Kuhu Shukla","active":true,"timeZone":"Etc/UTC"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/13028217/comment/15749667","id":"15749667","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=liuml07","name":"liuml07","key":"liuml07","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=liuml07&avatarId=29203","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=liuml07&avatarId=29203","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=liuml07&avatarId=29203","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=liuml07&avatarId=29203"},"displayName":"Mingliang Liu","active":true,"timeZone":"America/Los_Angeles"},"body":"audit log can be async; anyway logging out of locks is nice to have.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=liuml07","name":"liuml07","key":"liuml07","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=liuml07&avatarId=29203","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=liuml07&avatarId=29203","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=liuml07&avatarId=29203","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=liuml07&avatarId=29203"},"displayName":"Mingliang Liu","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-12-14T22:14:57.153+0000","updated":"2016-12-14T22:14:57.153+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13028217/comment/15750073","id":"15750073","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=linyiqun","name":"linyiqun","key":"linyiqun","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=linyiqun&avatarId=25258","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=linyiqun&avatarId=25258","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=linyiqun&avatarId=25258","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=linyiqun&avatarId=25258"},"displayName":"Yiqun Lin","active":true,"timeZone":"Asia/Shanghai"},"body":"+1 for the idea. I see we can move {{logAuditEvent(success, operationName, src)}} into finally block so that can both cover the normal and exception scenarios.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=linyiqun","name":"linyiqun","key":"linyiqun","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=linyiqun&avatarId=25258","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=linyiqun&avatarId=25258","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=linyiqun&avatarId=25258","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=linyiqun&avatarId=25258"},"displayName":"Yiqun Lin","active":true,"timeZone":"Asia/Shanghai"},"created":"2016-12-15T01:49:04.080+0000","updated":"2016-12-15T01:49:04.080+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13028217/comment/15751533","id":"15751533","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kshukla","name":"kshukla","key":"kshukla","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=34050","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34050","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34050","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34050"},"displayName":"Kuhu Shukla","active":true,"timeZone":"Etc/UTC"},"body":"Thanks a lot [~linyiqun]. \nbq.  I see we can move logAuditEvent(success, operationName, src) into finally block \nThat would mean we log for IOExceptions and others as well with allowed=false, which should ideally only be when we see an AccessControlException. This was a bug fixed thru HDFS-9395. We can still have the call in the finally block while making sure we don't log unconditionally.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kshukla","name":"kshukla","key":"kshukla","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=34050","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34050","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34050","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34050"},"displayName":"Kuhu Shukla","active":true,"timeZone":"Etc/UTC"},"created":"2016-12-15T14:38:55.684+0000","updated":"2016-12-15T14:38:55.684+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13028217/comment/15751535","id":"15751535","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kshukla","name":"kshukla","key":"kshukla","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=34050","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34050","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34050","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34050"},"displayName":"Kuhu Shukla","active":true,"timeZone":"Etc/UTC"},"body":"bq. audit log can be async\nThat is interesting. Will get back to you with more questions on that after some thought. Thanks!","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kshukla","name":"kshukla","key":"kshukla","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=34050","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34050","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34050","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34050"},"displayName":"Kuhu Shukla","active":true,"timeZone":"Etc/UTC"},"created":"2016-12-15T14:39:30.498+0000","updated":"2016-12-15T14:39:30.498+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13028217/comment/16090579","id":"16090579","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kshukla","name":"kshukla","key":"kshukla","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=34050","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34050","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34050","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34050"},"displayName":"Kuhu Shukla","active":true,"timeZone":"Etc/UTC"},"body":"First cut of the patch which adds a try-finally block to unlock before audit logging. Appreciate any comments/review on the approach while I work on the unit test (not included in this version  of the patch). Thanks a lot!","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kshukla","name":"kshukla","key":"kshukla","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=34050","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34050","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34050","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34050"},"displayName":"Kuhu Shukla","active":true,"timeZone":"Etc/UTC"},"created":"2017-07-17T21:15:26.602+0000","updated":"2017-07-17T21:15:26.602+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13028217/comment/16090764","id":"16090764","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 21s{color} | {color:blue} Docker mode activated. {color} |\n|| || || || {color:brown} Prechecks {color} ||\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |\n|| || || || {color:brown} trunk Compile Tests {color} ||\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 14m 35s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 57s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 39s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 56s{color} | {color:green} trunk passed {color} |\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  1m 57s{color} | {color:red} hadoop-hdfs-project/hadoop-hdfs in trunk has 10 extant Findbugs warnings. {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 41s{color} | {color:green} trunk passed {color} |\n|| || || || {color:brown} Patch Compile Tests {color} ||\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 52s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m  1s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  1m  1s{color} | {color:green} the patch passed {color} |\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 37s{color} | {color:orange} hadoop-hdfs-project/hadoop-hdfs: The patch generated 5 new + 178 unchanged - 0 fixed = 183 total (was 178) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 58s{color} | {color:green} the patch passed {color} |\n| {color:red}-1{color} | {color:red} whitespace {color} | {color:red}  0m  0s{color} | {color:red} The patch has 1 line(s) that end in whitespace. Use git apply --whitespace=fix <<patch_file>>. Refer https://git-scm.com/docs/git-apply {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 58s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 39s{color} | {color:green} the patch passed {color} |\n|| || || || {color:brown} Other Tests {color} ||\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 74m 22s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 24s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black}102m 24s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| Failed junit tests | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting |\n|   | hadoop.hdfs.server.namenode.TestNamenodeCapacityReport |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:14b5c93 |\n| JIRA Issue | HDFS-11246 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12877677/HDFS-11246.001.patch |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux d30db9898444 3.13.0-116-generic #163-Ubuntu SMP Fri Mar 31 14:13:22 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / 5b00792 |\n| Default Java | 1.8.0_131 |\n| findbugs | v3.1.0-RC1 |\n| findbugs | https://builds.apache.org/job/PreCommit-HDFS-Build/20316/artifact/patchprocess/branch-findbugs-hadoop-hdfs-project_hadoop-hdfs-warnings.html |\n| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/20316/artifact/patchprocess/diff-checkstyle-hadoop-hdfs-project_hadoop-hdfs.txt |\n| whitespace | https://builds.apache.org/job/PreCommit-HDFS-Build/20316/artifact/patchprocess/whitespace-eol.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/20316/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |\n|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/20316/testReport/ |\n| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/20316/console |\n| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2017-07-17T23:00:59.962+0000","updated":"2017-07-17T23:00:59.962+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13028217/comment/16091717","id":"16091717","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=daryn","name":"daryn","key":"daryn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Daryn Sharp","active":true,"timeZone":"America/Chicago"},"body":"bq. audit log can be async; anyway logging out of locks is nice to have.\n\nFYI, logging outside the lock is far more than nice to have. I added the async edit logging but it's not enough.\n\nThe process of building the audit log line is not cheap and log4j still suffers from synchronized contention before it drops the log messages into the async appender's queue.  Logging a spam of write ops that fail with ACE, while holding the write lock, is a non-trivial drag on performance.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=daryn","name":"daryn","key":"daryn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Daryn Sharp","active":true,"timeZone":"America/Chicago"},"created":"2017-07-18T15:32:30.369+0000","updated":"2017-07-18T15:32:30.369+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13028217/comment/16091759","id":"16091759","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kshukla","name":"kshukla","key":"kshukla","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=34050","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34050","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34050","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34050"},"displayName":"Kuhu Shukla","active":true,"timeZone":"Etc/UTC"},"body":"Fixed checkstyle and whitespace issues. Findbugs warnings are unrelated to the patch. Same goes for the test failures. [~daryn], [~liuml07], [~linyiqun], request for review/comments on the patch. Thanks a lot!","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kshukla","name":"kshukla","key":"kshukla","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=34050","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34050","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34050","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34050"},"displayName":"Kuhu Shukla","active":true,"timeZone":"Etc/UTC"},"created":"2017-07-18T16:04:34.455+0000","updated":"2017-07-18T16:05:35.695+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13028217/comment/16091868","id":"16091868","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 15s{color} | {color:blue} Docker mode activated. {color} |\n|| || || || {color:brown} Prechecks {color} ||\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |\n|| || || || {color:brown} trunk Compile Tests {color} ||\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 13m  4s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 47s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 38s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 53s{color} | {color:green} trunk passed {color} |\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  1m 39s{color} | {color:red} hadoop-hdfs-project/hadoop-hdfs in trunk has 10 extant Findbugs warnings. {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 41s{color} | {color:green} trunk passed {color} |\n|| || || || {color:brown} Patch Compile Tests {color} ||\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 48s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 45s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 45s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 34s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 51s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 44s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 37s{color} | {color:green} the patch passed {color} |\n|| || || || {color:brown} Other Tests {color} ||\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 63m 40s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 20s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black} 88m 34s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| Failed junit tests | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure150 |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:14b5c93 |\n| JIRA Issue | HDFS-11246 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12877827/HDFS-11246.002.patch |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux 9a640506bf05 3.13.0-119-generic #166-Ubuntu SMP Wed May 3 12:18:55 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / 0b7afc0 |\n| Default Java | 1.8.0_131 |\n| findbugs | v3.1.0-RC1 |\n| findbugs | https://builds.apache.org/job/PreCommit-HDFS-Build/20326/artifact/patchprocess/branch-findbugs-hadoop-hdfs-project_hadoop-hdfs-warnings.html |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/20326/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |\n|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/20326/testReport/ |\n| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/20326/console |\n| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2017-07-18T17:37:07.494+0000","updated":"2017-07-18T17:37:07.494+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13028217/comment/16093132","id":"16093132","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brahmareddy","name":"brahmareddy","key":"brahmareddy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=brahmareddy&avatarId=24624","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=brahmareddy&avatarId=24624","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=brahmareddy&avatarId=24624","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=brahmareddy&avatarId=24624"},"displayName":"Brahma Reddy Battula","active":true,"timeZone":"Asia/Kolkata"},"body":"[~kshukla] thanks for working on this.\n\nbq.That would mean we log for IOExceptions and others as well with allowed=false, which should ideally only be when we see an AccessControlException. This was a bug fixed thru HDFS-9395. We can still have the call in the finally block while making sure we don't log unconditionally.\n\n Instead of double try-finally blocks can we  log in finally block based on some boolean condition like below such that it can be logged only on ACE..?\n\n*Option 1:*\n{code}\n       final String operationName = \"setOwner\";\n-    FileStatus auditStat;\n+    boolean logAudit = false;\n+    boolean allow = true;\n+    FileStatus auditStat=null;\n     checkOperation(OperationCategory.WRITE);\n     writeLock();\n     try {\n       checkOperation(OperationCategory.WRITE);\n       checkNameNodeSafeMode(\"Cannot set owner for \" + src);\n       auditStat = FSDirAttrOp.setOwner(dir, src, username, group);\n+      logAudit = true;\n     } catch (AccessControlException e) {\n-      logAuditEvent(false, operationName, src);\n+      logAudit = true;\n+      allow = false;\n+\n       throw e;\n     } finally {\n       writeUnlock(operationName);\n+      if(logAudit)\n+        logAuditEvent(allow, operationName, src, null, auditStat);\n     }\n     getEditLog().logSync();\n-    logAuditEvent(true, operationName, src, null, auditStat);\n{code}\n*Option 2:*\n{code}\n+  public enum AuditCheck {\n+    SUCCESS, FAILURE, NONE\n+  }\n   /**\n    * Set owner for an existing file.\n    * @throws IOException\n@@ -1807,21 +1810,25 @@ void setPermission(String src, FsPermission permission) throws IOException {\n   void setOwner(String src, String username, String group)\n       throws IOException {\n     final String operationName = \"setOwner\";\n-    FileStatus auditStat;\n+    AuditCheck auditCheck = AuditCheck.NONE;\n+    FileStatus auditStat = null;\n     checkOperation(OperationCategory.WRITE);\n     writeLock();\n     try {\n       checkOperation(OperationCategory.WRITE);\n       checkNameNodeSafeMode(\"Cannot set owner for \" + src);\n       auditStat = FSDirAttrOp.setOwner(dir, src, username, group);\n+      auditCheck = AuditCheck.SUCCESS;\n     } catch (AccessControlException e) {\n-      logAuditEvent(false, operationName, src);\n+      auditCheck = AuditCheck.FAILURE;\n       throw e;\n     } finally {\n       writeUnlock(operationName);\n+      if (auditCheck != AuditCheck.NONE)\n+        logAuditEvent(auditCheck == AuditCheck.SUCCESS, operationName, src,\n+            null, auditStat);\n     }\n     getEditLog().logSync();\n-    logAuditEvent(true, operationName, src, null, auditStat);\n{code}\n\nI prefer *option-2.*","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brahmareddy","name":"brahmareddy","key":"brahmareddy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=brahmareddy&avatarId=24624","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=brahmareddy&avatarId=24624","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=brahmareddy&avatarId=24624","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=brahmareddy&avatarId=24624"},"displayName":"Brahma Reddy Battula","active":true,"timeZone":"Asia/Kolkata"},"created":"2017-07-19T14:07:32.137+0000","updated":"2017-07-19T14:09:31.861+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13028217/comment/16093317","id":"16093317","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kshukla","name":"kshukla","key":"kshukla","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=34050","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34050","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34050","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34050"},"displayName":"Kuhu Shukla","active":true,"timeZone":"Etc/UTC"},"body":"Thanks [~brahmareddy] for the review! Will update patch with option-2 approach soon.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kshukla","name":"kshukla","key":"kshukla","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=34050","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34050","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34050","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34050"},"displayName":"Kuhu Shukla","active":true,"timeZone":"Etc/UTC"},"created":"2017-07-19T15:57:24.332+0000","updated":"2017-07-19T15:57:24.332+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13028217/comment/16093843","id":"16093843","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=daryn","name":"daryn","key":"daryn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Daryn Sharp","active":true,"timeZone":"America/Chicago"},"body":"I'm not sure I like either of the the suggestions because it re-orders the audit logging and edit log syncing.  On a semantic level, one might expect the audit log to only include durable edits.  It may be confusing to see audits for edits lost in a crash.\n\nMore importantly logging before syncing is likely to increase the odds of less txns batched per sync.  Log4j synchronization can be a real bottleneck, even with the async appender support I added.\n\nThe double try feels a bit odd but it seems like a clean change that doesn't cause edit/audit reordering.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=daryn","name":"daryn","key":"daryn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Daryn Sharp","active":true,"timeZone":"America/Chicago"},"created":"2017-07-19T21:45:06.950+0000","updated":"2017-07-19T21:45:06.950+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13028217/comment/16094611","id":"16094611","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brahmareddy","name":"brahmareddy","key":"brahmareddy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=brahmareddy&avatarId=24624","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=brahmareddy&avatarId=24624","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=brahmareddy&avatarId=24624","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=brahmareddy&avatarId=24624"},"displayName":"Brahma Reddy Battula","active":true,"timeZone":"Asia/Kolkata"},"body":"[~daryn] Thanks for insight on this.Yes, you are correct.\nbq.The double try feels a bit odd but it seems like a clean change that doesn't cause edit/audit reordering.\nAgree with you.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brahmareddy","name":"brahmareddy","key":"brahmareddy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=brahmareddy&avatarId=24624","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=brahmareddy&avatarId=24624","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=brahmareddy&avatarId=24624","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=brahmareddy&avatarId=24624"},"displayName":"Brahma Reddy Battula","active":true,"timeZone":"Asia/Kolkata"},"created":"2017-07-20T12:30:28.541+0000","updated":"2017-07-20T12:30:28.541+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13028217/comment/16094879","id":"16094879","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kshukla","name":"kshukla","key":"kshukla","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=34050","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34050","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34050","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34050"},"displayName":"Kuhu Shukla","active":true,"timeZone":"Etc/UTC"},"body":"Thank you [~daryn], [~brahmareddy] for your comments. Request you to share some review comments on the current patch given that we want to go ahead with the double try-block approach. Appreciate it!","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kshukla","name":"kshukla","key":"kshukla","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=34050","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34050","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34050","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34050"},"displayName":"Kuhu Shukla","active":true,"timeZone":"Etc/UTC"},"created":"2017-07-20T16:00:00.499+0000","updated":"2017-07-20T16:00:00.499+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13028217/comment/16206109","id":"16206109","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kshukla","name":"kshukla","key":"kshukla","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=34050","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34050","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34050","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34050"},"displayName":"Kuhu Shukla","active":true,"timeZone":"Etc/UTC"},"body":"Rebased patch.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kshukla","name":"kshukla","key":"kshukla","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=34050","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34050","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34050","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34050"},"displayName":"Kuhu Shukla","active":true,"timeZone":"Etc/UTC"},"created":"2017-10-16T16:05:27.357+0000","updated":"2017-10-16T16:05:27.357+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13028217/comment/16206537","id":"16206537","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 19m 41s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |\r\n|| || || || {color:brown} trunk Compile Tests {color} ||\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 14m 50s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 55s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 42s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  3s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 10m 54s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m  6s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 53s{color} | {color:green} trunk passed {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m  2s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 52s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 52s{color} | {color:green} the patch passed {color} |\r\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 39s{color} | {color:orange} hadoop-hdfs-project/hadoop-hdfs: The patch generated 3 new + 171 unchanged - 3 fixed = 174 total (was 174) {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  0s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 10m 10s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 12s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 51s{color} | {color:green} the patch passed {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}175m 50s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 59s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black}244m 21s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Reason || Tests ||\r\n| Failed junit tests | hadoop.hdfs.server.namenode.TestAuditLogs |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure140 |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure200 |\r\n|   | hadoop.hdfs.tools.TestDFSAdminWithHA |\r\n|   | hadoop.cli.TestHDFSCLI |\r\n|   | hadoop.hdfs.server.namenode.TestNameNodeXAttr |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure070 |\r\n|   | hadoop.hdfs.TestHDFSFileSystemContract |\r\n|   | hadoop.hdfs.security.TestDelegationTokenForProxyUser |\r\n|   | hadoop.hdfs.TestDistributedFileSystem |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure010 |\r\n|   | hadoop.fs.TestSymlinkHdfsFileSystem |\r\n|   | hadoop.fs.TestSymlinkHdfsFileContext |\r\n|   | hadoop.hdfs.web.TestWebHDFSAcl |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure100 |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure110 |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure090 |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure060 |\r\n|   | hadoop.hdfs.TestMissingBlocksAlert |\r\n|   | hadoop.fs.TestGlobPaths |\r\n|   | hadoop.hdfs.server.namenode.TestFileContextXAttr |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure210 |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure160 |\r\n|   | hadoop.hdfs.TestSecureEncryptionZoneWithKMS |\r\n|   | hadoop.hdfs.server.federation.router.TestRouterRpc |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure120 |\r\n|   | hadoop.hdfs.TestDFSPermission |\r\n|   | hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA |\r\n|   | hadoop.hdfs.server.namenode.snapshot.TestDisallowModifyROSnapshot |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure040 |\r\n|   | hadoop.hdfs.server.namenode.TestParallelImageWrite |\r\n|   | hadoop.fs.TestFcHdfsPermission |\r\n|   | hadoop.hdfs.server.namenode.TestAuditLoggerWithCommands |\r\n|   | hadoop.hdfs.server.namenode.snapshot.TestSnapshotDeletion |\r\n|   | hadoop.hdfs.TestReadStripedFileWithMissingBlocks |\r\n|   | hadoop.hdfs.server.blockmanagement.TestBlockStatsMXBean |\r\n|   | hadoop.hdfs.server.federation.router.TestRouterRpcMultiDestination |\r\n|   | hadoop.hdfs.server.namenode.TestFSImageWithSnapshot |\r\n|   | hadoop.hdfs.tools.offlineEditsViewer.TestOfflineEditsViewer |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure020 |\r\n|   | hadoop.hdfs.server.namenode.snapshot.TestSnapshot |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure180 |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure030 |\r\n|   | hadoop.hdfs.TestEncryptionZones |\r\n|   | hadoop.hdfs.web.TestWebHDFSXAttr |\r\n|   | hadoop.hdfs.TestDFSInotifyEventInputStream |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure150 |\r\n|   | hadoop.hdfs.TestRestartDFS |\r\n|   | hadoop.hdfs.server.namenode.TestFileContextAcl |\r\n|   | hadoop.hdfs.server.namenode.TestINodeFile |\r\n|   | hadoop.security.TestPermission |\r\n|   | hadoop.hdfs.server.namenode.ha.TestFailureToReadEdits |\r\n|   | hadoop.hdfs.TestAclsEndToEnd |\r\n|   | hadoop.hdfs.TestFsShellPermission |\r\n|   | hadoop.hdfs.TestSafeMode |\r\n|   | hadoop.hdfs.server.namenode.TestNameNodeAcl |\r\n|   | hadoop.hdfs.TestDFSShell |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure050 |\r\n|   | hadoop.hdfs.server.namenode.TestNamenodeRetryCache |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure190 |\r\n|   | hadoop.hdfs.server.blockmanagement.TestUnderReplicatedBlocks |\r\n| Timed out junit tests | org.apache.hadoop.hdfs.TestFileChecksum |\r\n|   | org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData |\r\n|   | org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker |  Image:yetus/hadoop:0de40f0 |\r\n| JIRA Issue | HDFS-11246 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12892402/HDFS-11246.003.patch |\r\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |\r\n| uname | Linux 3b70e86735a5 3.13.0-123-generic #172-Ubuntu SMP Mon Jun 26 18:04:35 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\r\n| git revision | trunk / 9fcc3a1 |\r\n| Default Java | 1.8.0_144 |\r\n| findbugs | v3.1.0-RC1 |\r\n| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/21714/artifact/patchprocess/diff-checkstyle-hadoop-hdfs-project_hadoop-hdfs.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/21714/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |\r\n|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/21714/testReport/ |\r\n| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |\r\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/21714/console |\r\n| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2017-10-16T20:15:17.648+0000","updated":"2017-10-16T20:15:17.648+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13028217/comment/16219052","id":"16219052","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=daryn","name":"daryn","key":"daryn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Daryn Sharp","active":true,"timeZone":"America/Chicago"},"body":"I'd move the initial locking inside the try.  Ie. The basic change is essentially adding a try that catches ACE around the existing code.  Minor, it looks like there's a few places that now unnecessarily use a success boolean.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=daryn","name":"daryn","key":"daryn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Daryn Sharp","active":true,"timeZone":"America/Chicago"},"created":"2017-10-25T16:51:24.245+0000","updated":"2017-10-25T16:51:24.245+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13028217/comment/16238209","id":"16238209","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kshukla","name":"kshukla","key":"kshukla","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=34050","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34050","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34050","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34050"},"displayName":"Kuhu Shukla","active":true,"timeZone":"Etc/UTC"},"body":"Revised patch addressing comments from Daryn.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kshukla","name":"kshukla","key":"kshukla","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=34050","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34050","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34050","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34050"},"displayName":"Kuhu Shukla","active":true,"timeZone":"Etc/UTC"},"created":"2017-11-03T19:18:16.701+0000","updated":"2017-11-03T19:18:16.701+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13028217/comment/16238387","id":"16238387","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 21s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |\r\n|| || || || {color:brown} trunk Compile Tests {color} ||\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 14m 58s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 46s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 33s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 51s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green}  9m 58s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 43s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 49s{color} | {color:green} trunk passed {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 52s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 46s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 46s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 34s{color} | {color:green} hadoop-hdfs-project/hadoop-hdfs: The patch generated 0 new + 170 unchanged - 3 fixed = 170 total (was 173) {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 53s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green}  9m 58s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 53s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 43s{color} | {color:green} the patch passed {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 43m  1s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |\r\n| {color:red}-1{color} | {color:red} asflicense {color} | {color:red}  0m 24s{color} | {color:red} The patch generated 176 ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black} 88m 54s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Reason || Tests ||\r\n| Unreaped Processes | hadoop-hdfs:8 |\r\n| Failed junit tests | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure070 |\r\n|   | hadoop.hdfs.TestHdfsAdmin |\r\n|   | hadoop.hdfs.TestDFSStripedInputStreamWithRandomECPolicy |\r\n|   | hadoop.hdfs.TestErasureCodingMultipleRacks |\r\n|   | hadoop.hdfs.TestEncryptionZonesWithKMS |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailureWithRandomECPolicy |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithRandomECPolicy |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure020 |\r\n|   | hadoop.hdfs.TestFileConcurrentReader |\r\n|   | hadoop.hdfs.TestRestartDFS |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure080 |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure100 |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:5b98639 |\r\n| JIRA Issue | HDFS-11246 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12895950/HDFS-11246.004.patch |\r\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |\r\n| uname | Linux 687b323b42af 4.4.0-43-generic #63-Ubuntu SMP Wed Oct 12 13:48:03 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | /testptch/patchprocess/precommit/personality/provided.sh |\r\n| git revision | trunk / 299d382 |\r\n| maven | version: Apache Maven 3.3.9 |\r\n| Default Java | 1.8.0_131 |\r\n| findbugs | v3.1.0-RC1 |\r\n| Unreaped Processes Log | https://builds.apache.org/job/PreCommit-HDFS-Build/21948/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs-reaper.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/21948/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |\r\n|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/21948/testReport/ |\r\n| asflicense | https://builds.apache.org/job/PreCommit-HDFS-Build/21948/artifact/out/patch-asflicense-problems.txt |\r\n| Max. process+thread count | 3212 (vs. ulimit of 5000) |\r\n| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |\r\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/21948/console |\r\n| Powered by | Apache Yetus 0.7.0-SNAPSHOT   http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2017-11-03T21:11:25.540+0000","updated":"2017-11-03T21:11:25.540+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13028217/comment/16246067","id":"16246067","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kshukla","name":"kshukla","key":"kshukla","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=34050","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34050","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34050","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34050"},"displayName":"Kuhu Shukla","active":true,"timeZone":"Etc/UTC"},"body":"Most test failures are due to OOM causing no new thread creations to go through. Other warnings can be ignored as well. Request for review comments on whether this seems reasonable [~daryn]. Thanks a lot! ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kshukla","name":"kshukla","key":"kshukla","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=34050","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34050","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34050","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34050"},"displayName":"Kuhu Shukla","active":true,"timeZone":"Etc/UTC"},"created":"2017-11-09T17:07:36.946+0000","updated":"2017-11-09T17:07:36.946+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13028217/comment/16268923","id":"16268923","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=daryn","name":"daryn","key":"daryn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Daryn Sharp","active":true,"timeZone":"America/Chicago"},"body":"Coming back to this patch, had a recent incident with user flooding ops generating ACE in the lock.\r\n\r\nIn my earlier comment, I meant the pattern used to be \"lock - try - finally unlock\".  The prior patches used \"lock - try - try\", whereas I wanted \"try - lock - try\" to match the prior pattern, not \"try - try - lock\" in the latest patch.  This very important in the event the locking call fails because the inner finally will cause an unbalanced unlock.  The fsn lock is no longer trivial and could be prone to a runtime exception or OOM, hence the resource (lock) should be acquired outside the inner try.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=daryn","name":"daryn","key":"daryn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Daryn Sharp","active":true,"timeZone":"America/Chicago"},"created":"2017-11-28T15:31:39.929+0000","updated":"2017-11-28T15:31:39.929+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13028217/comment/16268933","id":"16268933","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kshukla","name":"kshukla","key":"kshukla","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=34050","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34050","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34050","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34050"},"displayName":"Kuhu Shukla","active":true,"timeZone":"Etc/UTC"},"body":"Updated patch after talking to Daryn offline about what the locking should look like.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kshukla","name":"kshukla","key":"kshukla","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=34050","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34050","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34050","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34050"},"displayName":"Kuhu Shukla","active":true,"timeZone":"Etc/UTC"},"created":"2017-11-28T15:37:28.674+0000","updated":"2017-11-28T15:37:28.674+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13028217/comment/16269171","id":"16269171","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=genericqa","name":"genericqa","key":"genericqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=genericqa&avatarId=33630","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=genericqa&avatarId=33630","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=genericqa&avatarId=33630","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=genericqa&avatarId=33630"},"displayName":"genericqa","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 10m  4s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |\r\n|| || || || {color:brown} trunk Compile Tests {color} ||\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 16m 39s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 51s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 40s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 57s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 11m 16s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 51s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 49s{color} | {color:green} trunk passed {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 55s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 50s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 50s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 36s{color} | {color:green} hadoop-hdfs-project/hadoop-hdfs: The patch generated 0 new + 170 unchanged - 3 fixed = 170 total (was 173) {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 53s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 10m 48s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 53s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 48s{color} | {color:green} the patch passed {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 83m 54s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 24s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black}144m  3s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Reason || Tests ||\r\n| Failed junit tests | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting |\r\n|   | hadoop.fs.TestUnbuffer |\r\n|   | hadoop.hdfs.qjournal.server.TestJournalNodeSync |\r\n|   | hadoop.hdfs.server.datanode.TestDirectoryScanner |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:5b98639 |\r\n| JIRA Issue | HDFS-11246 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12899635/HDFS-11246.005.patch |\r\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |\r\n| uname | Linux f5f51ac9d6e9 3.13.0-135-generic #184-Ubuntu SMP Wed Oct 18 11:55:51 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | /testptch/patchprocess/precommit/personality/provided.sh |\r\n| git revision | trunk / 641ba5c |\r\n| maven | version: Apache Maven 3.3.9 |\r\n| Default Java | 1.8.0_151 |\r\n| findbugs | v3.1.0-RC1 |\r\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/22210/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |\r\n|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/22210/testReport/ |\r\n| Max. process+thread count | 3878 (vs. ulimit of 5000) |\r\n| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |\r\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/22210/console |\r\n| Powered by | Apache Yetus 0.7.0-SNAPSHOT   http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=genericqa","name":"genericqa","key":"genericqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=genericqa&avatarId=33630","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=genericqa&avatarId=33630","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=genericqa&avatarId=33630","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=genericqa&avatarId=33630"},"displayName":"genericqa","active":true,"timeZone":"Etc/UTC"},"created":"2017-11-28T18:05:03.890+0000","updated":"2017-11-28T18:05:03.890+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13028217/comment/16269265","id":"16269265","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kshukla","name":"kshukla","key":"kshukla","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=34050","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34050","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34050","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34050"},"displayName":"Kuhu Shukla","active":true,"timeZone":"Etc/UTC"},"body":"Test failures are unrelated. [~daryn], request for review/comments. Thanks a lot!","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kshukla","name":"kshukla","key":"kshukla","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=34050","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34050","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34050","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34050"},"displayName":"Kuhu Shukla","active":true,"timeZone":"Etc/UTC"},"created":"2017-11-28T18:54:52.401+0000","updated":"2017-11-28T18:54:52.401+0000"}],"maxResults":24,"total":24,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-11246/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i37m2n:"}}