{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12437828","self":"https://issues.apache.org/jira/rest/api/2/issue/12437828","key":"HDFS-693","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/8","id":"8","description":"The described issue is not actually a problem - it is as designed.","name":"Not A Problem"},"customfield_12312322":null,"customfield_12310220":"2010-06-04T15:23:54.087+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Wed Oct 24 14:44:42 UTC 2012","customfield_12310420":"16469","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_95761264453_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2012-10-24T14:44:42.012+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-693/watchers","watchCount":17,"isWatching":false},"created":"2009-10-12T06:23:37.596+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"1.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12314048","id":"12314048","description":"","name":"0.20.1","archived":false,"released":true,"releaseDate":"2009-09-01"}],"issuelinks":[{"id":"12342221","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12342221","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"12440593","key":"HDFS-770","self":"https://issues.apache.org/jira/rest/api/2/issue/12440593","fields":{"summary":"SocketTimeoutException: timeout while waiting for channel to be ready for read","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}}],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2012-10-24T14:44:42.047+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12312927","id":"12312927","name":"datanode"}],"timeoriginalestimate":null,"description":"To exclude the case of network problem, I found the count of  dataXceiver is about 30.  Also, I could see the output of netstate -a | grep 50075 has many TIME_WAIT status when this happened.\n\npartial log in attachment. \n\n","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12421843","id":"12421843","filename":"HDFS-693.log","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dongtalk%40gmail.com","name":"dongtalk@gmail.com","key":"dongtalk@gmail.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yajun Dong","active":true,"timeZone":"Etc/UTC"},"created":"2009-10-12T06:29:40.674+0000","size":8550,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12421843/HDFS-693.log"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"62331","customfield_12312823":null,"summary":"java.net.SocketTimeoutException: 480000 millis timeout while waiting for channel to be ready for write exceptions were cast when trying to read file via StreamFile.","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dongtalk%40gmail.com","name":"dongtalk@gmail.com","key":"dongtalk@gmail.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yajun Dong","active":true,"timeZone":"Etc/UTC"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dongtalk%40gmail.com","name":"dongtalk@gmail.com","key":"dongtalk@gmail.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yajun Dong","active":true,"timeZone":"Etc/UTC"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12437828/comment/12764589","id":"12764589","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dongtalk%40gmail.com","name":"dongtalk@gmail.com","key":"dongtalk@gmail.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yajun Dong","active":true,"timeZone":"Etc/UTC"},"body":"Furthermore, the exception in DataNode I see :\n\n2009-10-12 09:43:47,261 INFO dfs.DFSClient: Could not obtain block blk_3304550638094049753 from any node: java.io.IOException: No live nodes contain current block","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dongtalk%40gmail.com","name":"dongtalk@gmail.com","key":"dongtalk@gmail.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yajun Dong","active":true,"timeZone":"Etc/UTC"},"created":"2009-10-12T07:34:54.775+0000","updated":"2009-10-12T07:34:54.775+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12437828/comment/12764591","id":"12764591","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dongtalk%40gmail.com","name":"dongtalk@gmail.com","key":"dongtalk@gmail.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yajun Dong","active":true,"timeZone":"Etc/UTC"},"body":"Furthermore, the exceptions in DataNode i see :\n\n2009-10-12 09:43:47,261INFO dfs.DFSClient: Could not obtain block blk_3304550638094049753 from any node: java.io.IOException: No live nodes contain current block","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dongtalk%40gmail.com","name":"dongtalk@gmail.com","key":"dongtalk@gmail.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yajun Dong","active":true,"timeZone":"Etc/UTC"},"created":"2009-10-12T07:36:58.188+0000","updated":"2009-10-12T07:36:58.188+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12437828/comment/12875630","id":"12875630","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=whitingj","name":"whitingj","key":"whitingj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jeff Whiting","active":true,"timeZone":"Etc/UTC"},"body":"For what it is worth I've been seeing the same problem on 0.20.2.  Specifically the java.net.SocketTimeoutException: 480000 millis timeout while waiting for channel to be ready for write. ch error.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=whitingj","name":"whitingj","key":"whitingj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jeff Whiting","active":true,"timeZone":"Etc/UTC"},"created":"2010-06-04T15:23:54.087+0000","updated":"2010-06-04T15:23:54.087+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12437828/comment/12884957","id":"12884957","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brahmareddy","name":"brahmareddy","key":"brahmareddy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=brahmareddy&avatarId=24624","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=brahmareddy&avatarId=24624","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=brahmareddy&avatarId=24624","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=brahmareddy&avatarId=24624"},"displayName":"Brahma Reddy Battula","active":true,"timeZone":"Asia/Kolkata"},"body":"I am using the 20.1 version,I am getting following  exception\n\nERROR org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(192.168.3.26:50010, storageID=DS-2095362429-192.168.3.26-50010-1244004238916, infoPort=50075, ipcPort=50020):DataXceiver\njava.net.SocketTimeoutException:  *{color:red}660000 millis{color}8  timeout while waiting for channel to be ready for write. ch : java.nio.channels.SocketChannel[connected local=/192.168.3.26:50010 remote=/192.168.3.26:34243]","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brahmareddy","name":"brahmareddy","key":"brahmareddy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=brahmareddy&avatarId=24624","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=brahmareddy&avatarId=24624","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=brahmareddy&avatarId=24624","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=brahmareddy&avatarId=24624"},"displayName":"Brahma Reddy Battula","active":true,"timeZone":"Asia/Kolkata"},"created":"2010-07-03T18:20:55.693+0000","updated":"2010-07-03T18:20:55.693+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12437828/comment/12886083","id":"12886083","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cycle23","name":"cycle23","key":"cycle23","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Cody Saunders","active":true,"timeZone":"Etc/UTC"},"body":"I have also seen this, and believe it may go back to Java + Timezone issues. I found a possibly related thread:\n\nhttp://mail-archives.apache.org/mod_mbox/hadoop-hdfs-user/201004.mbox/%3C670102.35052.qm@web52303.mail.re2.yahoo.com%3E\n\nWith summary:\n\n\" stu@ubuntu-namenode:~/testtime$ java testDateTime \ndate: Thu Apr 22 11:37:32 PST 2010\nstu@ubuntu-namenode:~/testtime$ date\nThu Apr 22 12:37:34 PDT 2010\nstu@ubuntu-namenode:~/testtime$ cat /etc/timezone \nAmerica/Los_Angeles\n\nbut then says:\n\nstu@ubuntu-hadoop-1:~/testtime$ java testDateTime\ndate: Thu Apr 22 12:38:11 PDT 2010\nstu@ubuntu-hadoop-1:~/testtime$ date\nThu Apr 22 12:38:12 PDT 2010\nstu@ubuntu-hadoop-1:~/testtime$ cat /etc/timezone \nAmerica/Los_Angeles\"\n\n\n....It looks like this person is saying that testDateTime sometimes works exactly right and other times does not... We can probably get around it by using \"TZ\" in the environment for Java, which is what I'm trying currently. So far, haven't seen more 480s timeouts.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cycle23","name":"cycle23","key":"cycle23","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Cody Saunders","active":true,"timeZone":"Etc/UTC"},"created":"2010-07-07T21:04:36.116+0000","updated":"2010-07-07T21:04:36.116+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12437828/comment/12886090","id":"12886090","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cycle23","name":"cycle23","key":"cycle23","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Cody Saunders","active":true,"timeZone":"Etc/UTC"},"body":"Followup, even though I set TZ, I still get 480s timeouts in datanodes. Here's a sample, where it appears only 3ms actually pass before it complains:\n\n2010-07-07 13:56:57,865 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.200.207:50010, dest: /192.168.200.207:44915, bytes: 264192, op: HDFS_READ, cliID: DFSClient_1293902555, srvID: DS-7579347-192.168.200.207-50010-1278476587314, blockid: blk_-3262154426456719253_1840\n\n2010-07-07 13:56:57,868 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(192.168.200.207:50010, storageID=DS-7579347-192.168.200.207-50010-1278476587314, infoPort=50075, ipcPort=50020):Got exception while serving blk_-3262154426456719253_1840 to /192.168.200.207:\njava.net.SocketTimeoutException: 480000 millis timeout while waiting for channel to be ready for write. ch : java.nio.channels.SocketChannel[connected local=/192.168.200.207:50010 remote=/192.168.200.207:44915]\n    at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:246)\n    at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:159)\n    at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:198)\n    at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendChunks(BlockSender.java:313)\n    at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:400)\n    at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:180)\n    at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:95)\n    at java.lang.Thread.run(Thread.java:619)\n\nI am using hadoop 0.20.2 and hbase 0.20.4.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cycle23","name":"cycle23","key":"cycle23","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Cody Saunders","active":true,"timeZone":"Etc/UTC"},"created":"2010-07-07T21:25:32.560+0000","updated":"2010-07-07T21:25:32.560+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12437828/comment/12886166","id":"12886166","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cycle23","name":"cycle23","key":"cycle23","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Cody Saunders","active":true,"timeZone":"Etc/UTC"},"body":"Last thing to say, setting the dfs.socket.write.timeout to 0 is so far the best workaround I've discovered. I may try other values to see if I can find the upper limit, but if it is near an hour, starts to seem like timezone jumps. I'm using java 1.6.0_16. Could it be the hadoop call or the java call is relying on uninit var to decide if daylight savings hour...?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cycle23","name":"cycle23","key":"cycle23","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Cody Saunders","active":true,"timeZone":"Etc/UTC"},"created":"2010-07-08T00:38:13.216+0000","updated":"2010-07-08T00:38:13.216+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12437828/comment/12886167","id":"12886167","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cycle23","name":"cycle23","key":"cycle23","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Cody Saunders","active":true,"timeZone":"Etc/UTC"},"body":"Sorry, I meant to say dfs.datanode.socket.write.timeout","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cycle23","name":"cycle23","key":"cycle23","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Cody Saunders","active":true,"timeZone":"Etc/UTC"},"created":"2010-07-08T00:39:23.196+0000","updated":"2010-07-08T00:39:23.196+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12437828/comment/12886235","id":"12886235","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cycle23","name":"cycle23","key":"cycle23","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Cody Saunders","active":true,"timeZone":"Etc/UTC"},"body":"Not sure how directly this is related, but since there's so much suggestions out there to use dfs.datanode.socket.write.timeout = 0, it sort of blows up in this line of code:\n\nlong writeTimeout = HdfsConstants.WRITE_TIMEOUT_EXTENSION * nodes.length +\n                            datanodeWriteTimeout;\n\nfrom:\n\nhadoop-0.20.2/src/hdfs/org/apache/hadoop/hdfs/DFSClient.java\n\n\"datanodeWriteTimeout\" is -ZERO- due to the desire to have infinite write timeouts, and per much advice on the web.. however, this particular line renders that useless since it adds it to the constant (5000) * # nodes (in this case, \"2\" were involved.. replication maybe).\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cycle23","name":"cycle23","key":"cycle23","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Cody Saunders","active":true,"timeZone":"Etc/UTC"},"created":"2010-07-08T04:56:03.353+0000","updated":"2010-07-08T04:56:03.353+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12437828/comment/12894627","id":"12894627","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cycle23","name":"cycle23","key":"cycle23","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Cody Saunders","active":true,"timeZone":"Etc/UTC"},"body":"I just wanted to re-iterate the above statement about the portions of code where the value is added in with the WRITE_TIMEOUT_EXTENSION constant * number of nodes...\n\nIf using '0' to get around write timeout problems is a bad practice or not is probably the first question. If so, is it documented somewhere? If not, then logic like I've pointed out above would break the idea of using \"infinite\" wait. \n\nI ran into timeout conditions this time starting with exception:\n50010-1267539292546, infoPort=50075, ipcPort=50020):Exception writing block blk_3120944928137673159_2109400 to mirror 192.168.130.94:50010\njava.net.SocketException: Broken pipe\n    at java.net.SocketOutputStream.socketWrite0(Native Method)\n    at java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:92)\n    at java.net.SocketOutputStream.write(SocketOutputStream.java:136)\n    at java.io.BufferedOutputStream.write(BufferedOutputStream.java:105)\n    at java.io.DataOutputStream.write(DataOutputStream.java:90)\n    at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:401)\n    at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:524)\n    at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:357)\n    at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:103)\n    at java.lang.Thread.run(Thread.java:619)\n\n\nWhen I look at\nBlockReceiver.java:401\n\nI see it goes back to mirrorOut, defined before the call to receiveBlock in dataXceiver, as:\n\n(line 285)          mirrorOut = new DataOutputStream(\n             new BufferedOutputStream(\n                         NetUtils.getOutputStream(mirrorSock, writeTimeout),\n                         SMALL_BUFFER_SIZE));\n\nwith writeTimeout from line 280:\n\n int writeTimeout = datanode.socketWriteTimeout +\n                             (HdfsConstants.WRITE_TIMEOUT_EXTENSION * numTargets);\n\n\nI have avoided almost every timeout but occasional read-side timeouts in my very slow VM environment by setting dfs.datanode.socket.write.timeout to something like 1000000, but had not yet tried this in production, where it is still zero, and I received the timeout complaint.\n\nAt the time I was writing 1M records per hour from about 8 different clients of hbase.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cycle23","name":"cycle23","key":"cycle23","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Cody Saunders","active":true,"timeZone":"Etc/UTC"},"created":"2010-08-02T18:07:49.750+0000","updated":"2010-08-02T18:07:49.750+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12437828/comment/12902449","id":"12902449","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dmusatov","name":"dmusatov","key":"dmusatov","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Dmitry Musatov","active":true,"timeZone":"Etc/UTC"},"body":"Setting dfs.datanode.socket.write.timeout to zero decreases actual timeout both for DFS Client and Server, but for Server it also switches from NIO to Regular socket implementation.\nProoflink: http://svn.apache.org/viewvc/hadoop/common/tags/release-0.20.2/src/hdfs/org/apache/hadoop/hdfs/server/datanode/DataNode.java?revision=916569&view=markup\nLines (250,251),(307,308),(403-407) or search for socketWriteTimeout","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dmusatov","name":"dmusatov","key":"dmusatov","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Dmitry Musatov","active":true,"timeZone":"Etc/UTC"},"created":"2010-08-25T14:03:57.400+0000","updated":"2010-08-25T14:03:57.400+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12437828/comment/13001979","id":"13001979","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"body":"In our observation this issue came in long run with huge no of blocks in Data Nodes . every hour Data Nodes are sending their blocks report to the Name Node. If number of blocks in Data Node are huge (3 Data Nodes with 2GB RAM, Scribe server is sending logs at 5000records/s , 4 scribe clients , block size is 64MB ) then it requires good amount of time to scan all the blocks. This block scanning causes lot of IO operations. At this time if any write request comes , then it will take long time for it to get a free io channel on the Data Node. Because of this during the blcock scan time a Data Node may not be able to acknowledge the client requests causing timeouts   on the client sockets.\n If DN1 send the data to DN2 for replication and at that time DN2 is doing the block scanning. Since DN2 is busy, it may not be able to send the ack to DN1 on time. So here timeouts can happen. \n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-03-03T12:51:13.961+0000","updated":"2011-03-03T12:51:13.961+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12437828/comment/13227534","id":"13227534","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=inder","name":"inder","key":"inder","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Inder SIngh","active":true,"timeZone":"Etc/UTC"},"body":"Folks,\n\nWhat's the recommendation here. Does increasing the timeout resolve this? Does it have any other side effects.We are hitting the same on medium size cluster ~60 nodes.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=inder","name":"inder","key":"inder","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Inder SIngh","active":true,"timeZone":"Etc/UTC"},"created":"2012-03-12T13:58:10.939+0000","updated":"2012-03-12T13:58:10.939+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12437828/comment/13483279","id":"13483279","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=qwertymaniac","name":"qwertymaniac","key":"qwertymaniac","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=qwertymaniac&avatarId=16780","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=qwertymaniac&avatarId=16780","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=qwertymaniac&avatarId=16780","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=qwertymaniac&avatarId=16780"},"displayName":"Harsh J","active":true,"timeZone":"Asia/Kolkata"},"body":"This issue has gone stale - resolving. The timeouts result from a variety of operations (i.e. actual timeouts due to the client disappearing - tasks getting killed, etc., hitting transceiver limits, etc.) - not due to a bug in HDFS. Or at least, not anymore.\n\nResolving as Not A Problem. Please file a new ticket if you are seeing unwanted timeouts on healthy clients/environments/configuration.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=qwertymaniac","name":"qwertymaniac","key":"qwertymaniac","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=qwertymaniac&avatarId=16780","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=qwertymaniac&avatarId=16780","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=qwertymaniac&avatarId=16780","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=qwertymaniac&avatarId=16780"},"displayName":"Harsh J","active":true,"timeZone":"Asia/Kolkata"},"created":"2012-10-24T14:44:42.026+0000","updated":"2012-10-24T14:44:42.026+0000"}],"maxResults":14,"total":14,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-693/votes","votes":5,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i0b1cn:"}}