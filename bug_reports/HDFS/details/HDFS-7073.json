{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12741891","self":"https://issues.apache.org/jira/rest/api/2/issue/12741891","key":"HDFS-7073","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12327181","id":"12327181","description":"2.6.0 release","name":"2.6.0","archived":false,"released":true,"releaseDate":"2014-11-18"}],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2014-09-16T22:07:22.720+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Sat Sep 20 22:33:58 UTC 2014","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":"10002_*:*_2_*:*_181201355_*|*_1_*:*_2_*:*_114327920_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2014-09-20T05:17:08.555+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-7073/watchers","watchCount":8,"isWatching":false},"created":"2014-09-16T19:11:39.331+0000","customfield_12310192":null,"customfield_12310191":[{"self":"https://issues.apache.org/jira/rest/api/2/customFieldOption/10343","value":"Reviewed","id":"10343"}],"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"3.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[],"issuelinks":[{"id":"12396962","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12396962","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"12540302","key":"HDFS-2856","self":"https://issues.apache.org/jira/rest/api/2/issue/12540302","fields":{"summary":"Fix block protocol so that Datanodes don't require root or jsvc","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/4","id":"4","description":"An improvement or enhancement to an existing feature or task.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype","name":"Improvement","subtask":false,"avatarId":21140}}}},{"id":"12397303","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12397303","type":{"id":"12310050","name":"Regression","inward":"is broken by","outward":"breaks","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/12310050"},"outwardIssue":{"id":"12742981","key":"HDFS-7107","self":"https://issues.apache.org/jira/rest/api/2/issue/12742981","fields":{"summary":"Avoid Findbugs warning for synchronization on AbstractNNFailoverProxyProvider#fallbackToSimpleAuth.","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/5","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/trivial.svg","name":"Trivial","id":"5"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2014-12-01T03:10:03.984+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12312927","id":"12312927","name":"datanode"},{"self":"https://issues.apache.org/jira/rest/api/2/component/12312928","id":"12312928","name":"hdfs-client"},{"self":"https://issues.apache.org/jira/rest/api/2/component/12313400","id":"12313400","name":"security"}],"timeoriginalestimate":null,"description":"HDFS-2856 implemented general SASL support on DataTransferProtocol.  Part of that work also included a fallback mode in case the remote cluster is running under a different configuration without SASL.  I've discovered a few edge case configurations that this did not support:\n\n* Cluster is unsecured, but has block access tokens enabled.  This is not something I've seen done in practice, but I've heard historically it has been allowed.  The HDFS-2856 code relied on seeing an empty block access token to trigger fallback, and this doesn't work if the unsecured cluster actually is using block access tokens.\n* The DataNode has an unpublicized testing configuration property that could be used to skip the privileged port check.  However, the HDFS-2856 code is still enforcing requirement of SASL when the ports are not privileged, so this would force existing configurations to make changes to activate SASL.\n\nThis patch will restore the old behavior so that these edge case configurations will continue to work the same way.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12327181","id":"12327181","description":"2.6.0 release","name":"2.6.0","archived":false,"released":true,"releaseDate":"2014-11-18"}],"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12669155","id":"12669155","filename":"HDFS-7073.1.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-09-16T19:20:31.977+0000","size":18012,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12669155/HDFS-7073.1.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12669935","id":"12669935","filename":"HDFS-7073.2.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-09-19T06:41:18.027+0000","size":62543,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12669935/HDFS-7073.2.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12670029","id":"12670029","filename":"HDFS-7073.3.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-09-19T16:36:59.646+0000","size":60595,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12670029/HDFS-7073.3.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"Allow falling back to a non-SASL connection on DataTransferProtocol in several edge cases.","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12741891/comment/14136026","id":"14136026","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"body":"I'm attaching the patch.  Summary:\n# {{SaslDataTransferClient/Server}}: Remove checks that had been enforcing requirement of SASL configuration.  This had been too strict to support use of {{ignore.secure.ports.for.testing}}.  Additionally, the client piece has new logic to support fallback when the cluster is unsecured but using block access tokens.  I think this is an unusual configuration, so I expect this code path would be executed only very rarely.\n# {{DFSOutputStream}}: The new client fallback logic also needed some coordination at this layer.  If the client attempts a connection with SASL to a non-SASL DataNode, then the DataNode closes the socket after rejecting the unexpected message.  The coordination here in the {{DFSOutputStream}} reconnect loop ensures that we get another chance with an open socket.\n# {{DataNode}}: There had been some mishandling in {{checkSecureConfig}} around checking the {{dfs.data.tranfser.protection}} property.  It's defined in hdfs-default.xml, so it always comes in with empty string as the default (not null).  I changed some of this logic to check for empty string instead of null.\n# {{TestSaslDataTransfer}}: Tests have been updated for better coverage of {{DateNode#checkSecureConfig}}.  I also took the opportunity to apply a timeout.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-09-16T19:20:31.982+0000","updated":"2014-09-16T19:20:31.982+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12741891/comment/14136332","id":"14136332","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12669155/HDFS-7073.1.patch\n  against trunk revision 8e5d671.\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:\n\n                  org.apache.hadoop.hdfs.web.TestWebHDFS\n                  org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover\n\n    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/8039//testReport/\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/8039//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2014-09-16T22:07:22.720+0000","updated":"2014-09-16T22:07:22.720+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12741891/comment/14136436","id":"14136436","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"body":"The test failures are unrelated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-09-16T23:00:45.611+0000","updated":"2014-09-16T23:00:45.611+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12741891/comment/14136766","id":"14136766","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jnp","name":"jnp","key":"jnp","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jitendra Nath Pandey","active":true,"timeZone":"Etc/UTC"},"body":"# We should be able to catch {{SaslDataTransferFallbackException}} instead of specifically checking the instance type.\n# In {{SaslDataTransferClient}} and {{SaslDataTransferServer}}, I think it would be more precise if we specifically check for 'ignore.secure.ports.for.testing'. \n\nOverall, the patch looks good to me.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jnp","name":"jnp","key":"jnp","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jitendra Nath Pandey","active":true,"timeZone":"Etc/UTC"},"created":"2014-09-17T04:35:44.923+0000","updated":"2014-09-17T04:35:44.923+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12741891/comment/14137711","id":"14137711","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"body":"[~jnp], thank you for taking a look.\n\nRegarding the instanceof check, I don't see a way to avoid it.  There is a lot of existing logic in the catch clause checking for specific exception types and doing special handling.  When fallback fails, we need to be able to drive the original exception into this handling logic to preserve the existing error handling behavior.  Some of this logic controls the outer loop too ({{break}} vs. {{continue}}), so it's not logic that's trivial to refactor behind a reusable method.  Maybe this whole code path would benefit from a larger clean-up refactoring, but that would be too much to fold into this patch now.\n\nRegarding checking {{ignore.secure.ports.for.testing}}, we can't make that change in the client.  {{ignore.secure.ports.for.testing}} has been a server-side property used by the DataNode only.  It's possible that the client would be running with different config files than the DataNode.  If an existing deployment defined {{ignore.secure.ports.for.testing}} in the DataNode configs, but not the client configs, then this wouldn't work.\n\nOn the server side, I'm unclear on exactly what we'd do with a check of {{ignore.secure.ports.for.testing}}.  If we do {{} else if (ignoreSecurePortsForTesting) {}}, then we'd still need a catch-all {{else}} block for when both {{dfs.data.transfer.protection}} and {{ignore.secure.ports.for.testing}} are off.  I suppose the only thing we can do there is to try a no-SASL connection, which is identical to the handling of the current patch.  Maybe it's actually clearer to leave the patch as is?\n\nLet me know your thoughts.  Thanks again!","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-09-17T18:35:26.526+0000","updated":"2014-09-17T18:35:26.526+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12741891/comment/14137762","id":"14137762","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jnp","name":"jnp","key":"jnp","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jitendra Nath Pandey","active":true,"timeZone":"Etc/UTC"},"body":"bq. ... Maybe this whole code path would benefit from a larger clean-up refactoring, but that would be too much to fold into this patch now.\nI agree, that much of refactoring will be beyond this patch's scope. I am ok to leave it as it is.\n\nbq. ... catch-all else block\nThe catch all else block should just throw an exception on the server side. If security is on, ports are not secured, and dfs.data.transfer.protection, ignore.secure.ports.for.testing are also off then we shouldn't allow a connection.\n  I agree to leave it as it is on the client side.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jnp","name":"jnp","key":"jnp","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jitendra Nath Pandey","active":true,"timeZone":"Etc/UTC"},"created":"2014-09-17T19:06:28.702+0000","updated":"2014-09-17T19:06:28.702+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12741891/comment/14138634","id":"14138634","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hitliuyi","name":"hitliuyi","key":"hitliuyi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yi Liu","active":true,"timeZone":"Asia/Shanghai"},"body":"Hi [~cnauroth], nice work.\n\n{quote}\nDataNode: There had been some mishandling in checkSecureConfig around checking the dfs.data.tranfser.protection property. It's defined in hdfs-default.xml, so it always comes in with empty string as the default (not null). I changed some of this logic to check for empty string instead of null.\n{quote}\nThat's great for this fix too, otherwise if cluster is security enabled and we still can start DN listened on an unprivileged port (> 1024) even {{dfs.data.transfer.protection}} is empty.\n\n{quote}\nCluster is unsecured, but has block access tokens enabled. This is not something I've seen done in practice, but I've heard historically it has been allowed. The HDFS-2856 code relied on seeing an empty block access token to trigger fallback, and this doesn't work if the unsecured cluster actually is using block access tokens.\n{quote}\n\nIn the patch, fallback for writeblock is handled, but fallback for readblock is not handled. \nThe test case for this scenario is hard to write because {{UserGroupInformation#isSecurityEnabled()}} is static, so we can't configure client secured but server unsecured.\nBut I just have this environment and test this scenario, I configured: server(unsecured and block access tokens enabled), client (secure enabled, block access tokens enabled and fallback enabled). I see write file is successful, but *read file failed*.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hitliuyi","name":"hitliuyi","key":"hitliuyi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yi Liu","active":true,"timeZone":"Asia/Shanghai"},"created":"2014-09-18T07:22:00.509+0000","updated":"2014-09-18T07:22:00.509+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12741891/comment/14138639","id":"14138639","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hitliuyi","name":"hitliuyi","key":"hitliuyi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yi Liu","active":true,"timeZone":"Asia/Shanghai"},"body":"For the first comment, I want to add: even though follow-on sasl handshake would failed, but the error log user see is not explicit. So it's pretty good of the fix for *not* let DN start successful on unprivileged port if {{dfs.data.transfer.protection}} is empty.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hitliuyi","name":"hitliuyi","key":"hitliuyi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yi Liu","active":true,"timeZone":"Asia/Shanghai"},"created":"2014-09-18T07:29:42.818+0000","updated":"2014-09-18T07:29:42.818+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12741891/comment/14138694","id":"14138694","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hitliuyi","name":"hitliuyi","key":"hitliuyi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yi Liu","active":true,"timeZone":"Asia/Shanghai"},"body":"One security issue I can think is: If we allow this type of fallback, as discussed in HDFS-2856 about the attack vector, a malicious task can easily listen on the DN's port after it dies and steal the block access token. So we'd better not allow the fallback?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hitliuyi","name":"hitliuyi","key":"hitliuyi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yi Liu","active":true,"timeZone":"Asia/Shanghai"},"created":"2014-09-18T08:39:57.078+0000","updated":"2014-09-18T08:39:57.078+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12741891/comment/14139272","id":"14139272","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"body":"bq. In the patch, fallback for writeblock is handled, but fallback for readblock is not handled. \n\nYes, I spotted the same thing in my testing yesterday and chose to cancel the patch to make it clear that it's not ready.  I'm working on a new patch.  Thank you for your testing too.\n\nbq. The test case for this scenario is hard to write because UserGroupInformation#isSecurityEnabled() is static...\n\nYes, agreed.  Unfortunately, until we refactor some of the static stuff inside {{UserGroupInformation}}, it's going to be impossible to put tests covering these kinds of cross-cluster scenarios directly into the source tree.  We're having to rely on external system tests to cover this.  Last time I looked at refactoring {{UserGroupInformation}}, it looked like it was going to be a big effort, and possibly backwards-incompatible.\n\nbq. If we allow this type of fallback, as discussed in HDFS-2856 about the attack vector, a malicious task can easily listen on the DN's port after it dies and steal the block access token.  So we'd better not allow the fallback?\n\nThanks, great catch.  The difficulty here is that {{ipc.client.fallback-to-simple-auth-allowed}} controls fallback globally regardless of which cluster the client is connecting to.  One of the big use cases motivating fallback is distcp between a secure cluster and a non-secure cluster.  In that scenario, setting {{ipc.client.fallback-to-simple-auth-allowed}} could accidentally trigger fallback during communication with the secured cluster, when we really only want it for the unsecured cluster.\n\nI'm going to explore an alternative implementation that detects if fallback actually occurred during the corresponding NameNode interaction before the DataTransferProtocol call.  This would tell us unambiguously if the remote DataNode was unsecured.  Doing this would require some additional plumbing at the RPC layer.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-09-18T18:14:28.892+0000","updated":"2014-09-18T18:14:28.892+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12741891/comment/14139816","id":"14139816","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hitliuyi","name":"hitliuyi","key":"hitliuyi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yi Liu","active":true,"timeZone":"Asia/Shanghai"},"body":"Thanks Chris.\n{quote}\nOne of the big use cases motivating fallback is distcp between a secure cluster and a non-secure cluster. In that scenario, setting ipc.client.fallback-to-simple-auth-allowed could accidentally trigger fallback during communication with the secured cluster, when we really only want it for the unsecured cluster.\n{quote}\nAgree. \n\nAt least in this JIRA we can fix the checking for {{dfs.data.transfer.protection}}, and for the fallback, we can continue in a new JIRA?\n{quote}\nI'm going to explore an alternative implementation that detects if fallback actually occurred during the corresponding NameNode interaction before the DataTransferProtocol call. This would tell us unambiguously if the remote DataNode was unsecured. Doing this would require some additional plumbing at the RPC layer.\n{quote}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hitliuyi","name":"hitliuyi","key":"hitliuyi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yi Liu","active":true,"timeZone":"Asia/Shanghai"},"created":"2014-09-19T01:02:04.081+0000","updated":"2014-09-19T01:02:04.081+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12741891/comment/14140090","id":"14140090","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"body":"I'm attaching patch v2.  This takes a different approach.  We detect if the NameNode interaction falls back to simple auth.  If so, then we know we need to skip SASL for DataTransferProtocol too.\n\nIt's a bigger patch than v1, mostly due to mechanical method signature changes.  I needed to plumb through the various RPC client and proxy layers to pull back out a flag indicating if fallback to simple auth occurred.\n\nIn addition to the new tests and existing tests changed in the patch, I also manually tested file write and read from a client running secure configuration to a cluster running unsecure configuration.\n\nJitendra and Yi, how does this look?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-09-19T06:41:18.034+0000","updated":"2014-09-19T06:41:18.034+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12741891/comment/14140261","id":"14140261","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12669935/HDFS-7073.2.patch\n  against trunk revision 6fe5c6b.\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:green}+1 tests included{color}.  The patch appears to include 4 new or modified test files.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:red}-1 findbugs{color}.  The patch appears to introduce 1 new Findbugs (version 2.0.3) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs:\n\n                  org.apache.hadoop.hdfs.server.mover.TestStorageMover\n                  org.apache.hadoop.hdfs.TestEncryptionZonesWithKMS\n                  org.apache.hadoop.hdfs.web.TestWebHdfsFileSystemContract\n                  org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover\n\n    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/8104//testReport/\nFindbugs warnings: https://builds.apache.org/job/PreCommit-HDFS-Build/8104//artifact/PreCommit-HADOOP-Build-patchprocess/newPatchFindbugsWarningshadoop-hdfs.html\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/8104//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2014-09-19T09:53:47.844+0000","updated":"2014-09-19T09:53:47.844+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12741891/comment/14140447","id":"14140447","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hitliuyi","name":"hitliuyi","key":"hitliuyi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yi Liu","active":true,"timeZone":"Asia/Shanghai"},"body":"Chris, thanks for quick update for this bulk of work.\n\nThe new approach is good. Agree that if the NameNode interaction falls back to simple auth then we skip SASL for DataTransferProtocol too, that makes sense. This can also protect from in secured cluster and fallback allowed, malicious task listens on the DN's port and steal the block access token. Also in this way, we don't need fallback exception to trigger retry as in the patch.\n\n\n\nThe new patch looks good to me, only few comments:\n\n*1.* I think we may not need to pass {{fallbackToSimpleAuth}} for each call. Since we do authentication for each connection, {{fallbackToSimpleAuth}} could be as a variable of connection, then in _ProtobufRpcEngine_ and other rpc engine, we can get _fallbackToSimpleAuth_ through the connection. Then the logic looks more straight and clear?\n\n*2.* I see there are two {{TODO}} for HA case in NameNodeProxies.java.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hitliuyi","name":"hitliuyi","key":"hitliuyi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yi Liu","active":true,"timeZone":"Asia/Shanghai"},"created":"2014-09-19T13:11:43.483+0000","updated":"2014-09-19T13:11:43.483+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12741891/comment/14140833","id":"14140833","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"body":"Thank you for looking again, Yi.  Here is patch v3.  This stops tracking the flag per {{Call}} instance.  I don't think we can make the flag a member of {{Connection}}.  Because of the {{ClientCache}} and the internal pooling of {{Connection}} instances, there could be a risk that one {{DFSClient}} instance shuts down, then another {{DFSClient}} instance connects to the same cluster, and it ends up pulling a pooled {{Connection}} that still contains the flag connected to the old {{DFSClient}}.  It's definitely a good simplification though to take your suggestion of not tracking it as a member of {{Call}}.  We can just pass it through to {{setupIOstreams}}.\n\nThanks also for catching the leftover TODOs.  These were already done in the prior patch by the code changes in {{AbstractNNFailoverProxyProvider}}, so I removed the comments.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-09-19T16:36:59.652+0000","updated":"2014-09-19T16:36:59.652+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12741891/comment/14141078","id":"14141078","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12670029/HDFS-7073.3.patch\n  against trunk revision 25fd69a.\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:green}+1 tests included{color}.  The patch appears to include 3 new or modified test files.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:red}-1 findbugs{color}.  The patch appears to introduce 1 new Findbugs (version 2.0.3) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs:\n\n                  org.apache.hadoop.crypto.random.TestOsSecureRandom\n                  org.apache.hadoop.ha.TestZKFailoverControllerStress\n                  org.apache.hadoop.hdfs.server.namenode.snapshot.TestUpdatePipelineWithSnapshots\n                  org.apache.hadoop.fs.TestUrlStreamHandler\n                  org.apache.hadoop.hdfs.server.namenode.TestFileLimit\n                  org.apache.hadoop.hdfs.TestParallelShortCircuitRead\n                  org.apache.hadoop.hdfs.server.namenode.TestEditLogAutoroll\n                  org.apache.hadoop.TestRefreshCallQueue\n                  org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyCheckpoints\n                  org.apache.hadoop.cli.TestCryptoAdminCLI\n                  org.apache.hadoop.hdfs.TestSetrepDecreasing\n                  org.apache.hadoop.hdfs.server.datanode.TestDiskError\n                  org.apache.hadoop.fs.viewfs.TestViewFsWithAcls\n                  org.apache.hadoop.hdfs.server.datanode.TestDataNodeHotSwapVolumes\n                  org.apache.hadoop.hdfs.server.namenode.TestFSEditLogLoader\n                  org.apache.hadoop.hdfs.server.namenode.TestHostsFiles\n                  org.apache.hadoop.hdfs.server.datanode.TestTransferRbw\n                  org.apache.hadoop.fs.contract.hdfs.TestHDFSContractDelete\n                  org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl\n                  org.apache.hadoop.fs.TestFcHdfsSetUMask\n                  org.apache.hadoop.hdfs.server.namenode.TestDeleteRace\n                  org.apache.hadoop.hdfs.server.namenode.TestFSDirectory\n                  org.apache.hadoop.hdfs.server.namenode.TestLeaseManager\n                  org.apache.hadoop.fs.contract.hdfs.TestHDFSContractOpen\n                  org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotListing\n                  org.apache.hadoop.hdfs.server.datanode.TestStorageReport\n                  org.apache.hadoop.hdfs.server.datanode.TestBlockRecovery\n                  org.apache.hadoop.hdfs.TestReadWhileWriting\n                  org.apache.hadoop.fs.contract.hdfs.TestHDFSContractMkdir\n                  org.apache.hadoop.fs.contract.hdfs.TestHDFSContractAppend\n                  org.apache.hadoop.hdfs.server.datanode.TestFsDatasetCache\n                  org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestRbwSpaceReservation\n                  org.apache.hadoop.hdfs.server.blockmanagement.TestPendingInvalidateBlock\n                  org.apache.hadoop.hdfs.server.namenode.ha.TestQuotasWithHA\n                  org.apache.hadoop.hdfs.server.namenode.ha.TestGetGroupsWithHA\n                  org.apache.hadoop.hdfs.server.namenode.TestSecondaryWebUi\n                  org.apache.hadoop.hdfs.server.namenode.TestAuditLogger\n                  org.apache.hadoop.hdfs.server.blockmanagement.TestBlockTokenWithDFS\n                  org.apache.hadoop.hdfs.TestWriteBlockGetsBlockLengthHint\n                  org.apache.hadoop.hdfs.server.namenode.TestHDFSConcat\n                  org.apache.hadoop.hdfs.server.datanode.TestCachingStrategy\n                  org.apache.hadoop.hdfs.server.namenode.TestAddBlockRetry\n                  org.apache.hadoop.fs.TestSymlinkHdfsFileSystem\n                  org.apache.hadoop.fs.viewfs.TestViewFsDefaultValue\n                  org.apache.hadoop.fs.TestSymlinkHdfsFileContext\n                  org.apache.hadoop.hdfs.TestClientProtocolForPipelineRecovery\n                  org.apache.hadoop.hdfs.TestFSInputChecker\n                  org.apache.hadoop.hdfs.server.namenode.ha.TestBootstrapStandby\n                  org.apache.hadoop.hdfs.server.datanode.TestDataNodeInitStorage\n                  org.apache.hadoop.hdfs.server.mover.TestStorageMover\n                  org.apache.hadoop.hdfs.server.datanode.TestBlockReplacement\n                  org.apache.hadoop.hdfs.server.blockmanagement.TestHeartbeatHandling\n                  org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestInterDatanodeProtocol\n                  org.apache.hadoop.cli.TestAclCLI\n                  org.apache.hadoop.hdfs.server.namenode.ha.TestHAMetrics\n                  org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotBlocksMap\n                  org.apache.hadoop.hdfs.server.blockmanagement.TestNodeCount\n                  org.apache.hadoop.hdfs.tools.TestDFSHAAdminMiniCluster\n                  org.apache.hadoop.hdfs.server.datanode.TestReadOnlySharedStorage\n                  org.apache.hadoop.hdfs.TestEncryptedTransfer\n                  org.apache.hadoop.hdfs.server.blockmanagement.TestBlocksWithNotEnoughRacks\n                  org.apache.hadoop.hdfs.server.namenode.TestNNStorageRetentionFunctional\n                  org.apache.hadoop.hdfs.server.datanode.TestHSync\n                  org.apache.hadoop.hdfs.server.namenode.TestNameNodeRpcServer\n                  org.apache.hadoop.fs.contract.hdfs.TestHDFSContractSeek\n                  org.apache.hadoop.hdfs.web.TestWebHdfsFileSystemContract\n                  org.apache.hadoop.hdfs.server.namenode.TestFileContextXAttr\n                  org.apache.hadoop.hdfs.TestAbandonBlock\n                  org.apache.hadoop.hdfs.server.namenode.TestAclConfigFlag\n                  org.apache.hadoop.hdfs.server.namenode.TestSequentialBlockId\n                  org.apache.hadoop.hdfs.TestFileCreationClient\n                  org.apache.hadoop.hdfs.server.namenode.TestFSImageWithXAttr\n                  org.apache.hadoop.hdfs.server.namenode.metrics.TestNameNodeMetrics\n                  org.apache.hadoop.hdfs.server.namenode.snapshot.TestXAttrWithSnapshot\n                  org.apache.hadoop.hdfs.server.namenode.TestFSImageWithAcl\n                  org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyBlockManagement\n                  org.apache.hadoop.hdfs.tools.TestDFSAdminWithHA\n                  org.apache.hadoop.hdfs.TestDFSShellGenericOptions\n                  org.apache.hadoop.tracing.TestTracing\n                  org.apache.hadoop.hdfs.server.namenode.TestListCorruptFileBlocks\n                  org.apache.hadoop.hdfs.server.namenode.ha.TestFailureOfSharedDir\n                  org.apache.hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA\n                  org.apache.hadoop.hdfs.server.datanode.TestDataNodeMultipleRegistrations\n                  org.apache.hadoop.hdfs.server.namenode.TestParallelImageWrite\n                  org.apache.hadoop.hdfs.server.namenode.snapshot.TestAclWithSnapshot\n                  org.apache.hadoop.hdfs.TestFileConcurrentReader\n                  org.apache.hadoop.hdfs.server.namenode.TestNameNodeResourceChecker\n                  org.apache.hadoop.hdfs.server.namenode.TestGenericJournalConf\n                  org.apache.hadoop.fs.viewfs.TestViewFsWithXAttrs\n                  org.apache.hadoop.hdfs.TestClose\n                  org.apache.hadoop.hdfs.server.datanode.TestDataNodeExit\n                  org.apache.hadoop.hdfs.server.namenode.TestEditLogJournalFailures\n                  org.apache.hadoop.hdfs.TestPersistBlocks\n                  org.apache.hadoop.hdfs.TestDatanodeReport\n                  org.apache.hadoop.tools.TestJMXGet\n                  org.apache.hadoop.hdfs.server.namenode.TestNameNodeMXBean\n                  org.apache.hadoop.hdfs.server.datanode.TestBlockHasMultipleReplicasOnSameDN\n                  org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotDiffReport\n                  org.apache.hadoop.fs.contract.hdfs.TestHDFSContractCreate\n                  org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestDatanodeRestart\n                  org.apache.hadoop.hdfs.server.namenode.TestCreateEditsLog\n                  org.apache.hadoop.hdfs.server.namenode.TestFSNamesystemMBean\n                  org.apache.hadoop.hdfs.TestWriteRead\n                  org.apache.hadoop.hdfs.server.balancer.TestBalancerWithMultipleNameNodes\n                  org.apache.hadoop.hdfs.TestBalancerBandwidth\n                  org.apache.hadoop.hdfs.server.datanode.TestFsDatasetCacheRevocation\n                  org.apache.hadoop.fs.TestEnhancedByteBufferAccess\n                  org.apache.hadoop.fs.TestFcHdfsPermission\n                  org.apache.hadoop.hdfs.server.namenode.TestEditLogRace\n                  org.apache.hadoop.security.TestRefreshUserMappings\n                  org.apache.hadoop.hdfs.server.namenode.TestAllowFormat\n                  org.apache.hadoop.fs.viewfs.TestViewFsHdfs\n                  org.apache.hadoop.hdfs.TestDFSRename\n                  org.apache.hadoop.hdfs.TestIsMethodSupported\n                  org.apache.hadoop.fs.TestResolveHdfsSymlink\n                  org.apache.hadoop.hdfs.server.namenode.metrics.TestNNMetricFilesInGetListingOps\n                  org.apache.hadoop.hdfs.server.namenode.web.resources.TestWebHdfsDataLocality\n                  org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestWriteToReplica\n                  org.apache.hadoop.tracing.TestTracingShortCircuitLocalRead\n                  org.apache.hadoop.hdfs.server.namenode.TestDecommissioningStatus\n                  org.apache.hadoop.hdfs.server.namenode.snapshot.TestCheckpointsWithSnapshots\n                  org.apache.hadoop.hdfs.server.blockmanagement.TestRBWBlockInvalidation\n                  org.apache.hadoop.hdfs.TestParallelShortCircuitReadNoChecksum\n                  org.apache.hadoop.hdfs.server.namenode.ha.TestEditLogTailer\n                  org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration\n                  org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotMetrics\n                  org.apache.hadoop.hdfs.TestDecommission\n                  org.apache.hadoop.hdfs.server.namenode.TestINodeFile\n                  org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover\n                  org.apache.hadoop.hdfs.server.balancer.TestBalancerWithEncryptedTransfer\n                  org.apache.hadoop.hdfs.server.namenode.TestNamenodeRetryCache\n                  org.apache.hadoop.hdfs.server.namenode.ha.TestDelegationTokensWithHA\n                  org.apache.hadoop.hdfs.server.balancer.TestBalancer\n                  org.apache.hadoop.fs.TestFcHdfsCreateMkdir\n                  org.apache.hadoop.hdfs.TestAppendDifferentChecksum\n                  org.apache.hadoop.hdfs.server.blockmanagement.TestReplicationPolicy\n                  org.apache.hadoop.hdfs.server.namenode.ha.TestNNHealthCheck\n                  org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotReplication\n                  org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotNameWithInvalidCharacters\n                  org.apache.hadoop.hdfs.server.namenode.ha.TestBootstrapStandbyWithQJM\n                  org.apache.hadoop.hdfs.server.namenode.TestBlockUnderConstruction\n                  org.apache.hadoop.hdfs.server.mover.TestMover\n                  org.apache.hadoop.hdfs.server.namenode.TestDeadDatanode\n                  org.apache.hadoop.hdfs.server.blockmanagement.TestComputeInvalidateWork\n                  org.apache.hadoop.hdfs.server.namenode.TestNameNodeRetryCacheMetrics\n                  org.apache.hadoop.hdfs.TestDFSFinalize\n                  org.apache.hadoop.hdfs.server.namenode.TestCacheDirectives\n                  org.apache.hadoop.hdfs.TestFileAppend2\n                  org.apache.hadoop.hdfs.server.namenode.ha.TestInitializeSharedEdits\n                  org.apache.hadoop.hdfs.server.datanode.TestIncrementalBlockReports\n                  org.apache.hadoop.hdfs.server.namenode.ha.TestFailoverWithBlockTokensEnabled\n                  org.apache.hadoop.hdfs.server.namenode.TestStorageRestore\n                  org.apache.hadoop.hdfs.server.namenode.TestEditLog\n                  org.apache.hadoop.fs.viewfs.TestViewFileSystemWithXAttrs\n                  org.apache.hadoop.hdfs.server.namenode.ha.TestHAFsck\n                  org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAcls\n                  org.apache.hadoop.hdfs.server.namenode.TestXAttrConfigFlag\n                  org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer\n                  org.apache.hadoop.hdfs.TestFsShellPermission\n                  org.apache.hadoop.hdfs.TestFileAppend3\n                  org.apache.hadoop.hdfs.server.namenode.snapshot.TestINodeFileUnderConstructionWithSnapshot\n                  org.apache.hadoop.hdfs.TestQuota\n                  org.apache.hadoop.hdfs.server.namenode.snapshot.TestDisallowModifyROSnapshot\n                  org.apache.hadoop.hdfs.server.balancer.TestBalancerWithHANameNodes\n                  org.apache.hadoop.hdfs.server.namenode.TestNameNodeRespectsBindHostKeys\n                  org.apache.hadoop.hdfs.server.datanode.TestDataNodeMXBean\n                  org.apache.hadoop.hdfs.tools.offlineEditsViewer.TestOfflineEditsViewer\n                  org.apache.hadoop.hdfs.server.blockmanagement.TestBlockManager\n                  org.apache.hadoop.hdfs.server.datanode.TestDataNodeMetrics\n                  org.apache.hadoop.hdfs.server.namenode.TestSnapshotPathINodes\n                  org.apache.hadoop.hdfs.server.namenode.ha.TestStateTransitionFailure\n                  org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyIsHot\n                  org.apache.hadoop.security.TestPermission\n                  org.apache.hadoop.hdfs.server.balancer.TestBalancerWithNodeGroup\n                  org.apache.hadoop.fs.contract.hdfs.TestHDFSContractConcat\n                  org.apache.hadoop.hdfs.server.namenode.TestLargeDirectoryDelete\n                  org.apache.hadoop.hdfs.server.namenode.ha.TestDFSZKFailoverController\n                  org.apache.hadoop.hdfs.server.blockmanagement.TestOverReplicatedBlocks\n                  org.apache.hadoop.hdfs.server.namenode.TestFsck\n                  org.apache.hadoop.hdfs.server.namenode.TestAuditLogs\n                  org.apache.hadoop.hdfs.server.namenode.snapshot.TestNestedSnapshots\n                  org.apache.hadoop.hdfs.server.namenode.TestSecondaryNameNodeUpgrade\n                  org.apache.hadoop.hdfs.server.blockmanagement.TestUnderReplicatedBlocks\n                  org.apache.hadoop.security.TestPermissionSymlinks\n                  org.apache.hadoop.net.TestNetworkTopology\n                  org.apache.hadoop.fs.contract.hdfs.TestHDFSContractRootDirectory\n                  org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot\n                  org.apache.hadoop.hdfs.TestParallelUnixDomainRead\n                  org.apache.hadoop.cli.TestXAttrCLI\n                  org.apache.hadoop.hdfs.server.namenode.TestNameEditsConfigs\n                  org.apache.hadoop.hdfs.TestEncryptionZonesWithHA\n                  org.apache.hadoop.hdfs.server.datanode.TestRefreshNamenodes\n                  org.apache.hadoop.hdfs.TestFileCreationEmpty\n                  org.apache.hadoop.hdfs.server.namenode.ha.TestDFSUpgradeWithHA\n                  org.apache.hadoop.fs.contract.hdfs.TestHDFSContractRename\n                  org.apache.hadoop.hdfs.server.namenode.TestSecurityTokenEditLog\n                  org.apache.hadoop.hdfs.server.datanode.TestDirectoryScanner\n                  org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotFileLength\n                  org.apache.hadoop.hdfs.server.datanode.TestNNHandlesBlockReportPerStorage\n                  org.apache.hadoop.fs.permission.TestStickyBit\n                  org.apache.hadoop.hdfs.server.namenode.ha.TestPendingCorruptDnMessages\n                  org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotDeletion\n                  org.apache.hadoop.hdfs.TestFileCreation\n                  org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode\n                  org.apache.hadoop.hdfs.TestMissingBlocksAlert\n                  org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshot\n                  org.apache.hadoop.fs.viewfs.TestViewFileSystemAtHdfsRoot\n                  org.apache.hadoop.hdfs.server.namenode.TestTransferFsImage\n                  org.apache.hadoop.hdfs.server.namenode.TestStartup\n                  org.apache.hadoop.hdfs.server.namenode.TestNameNodeRecovery\n                  org.apache.hadoop.hdfs.TestRead\n                  org.apache.hadoop.hdfs.server.namenode.ha.TestEditLogsDuringFailover\n                  org.apache.hadoop.hdfs.server.namenode.TestDiskspaceQuotaUpdate\n                  org.apache.hadoop.hdfs.server.datanode.TestDeleteBlockPool\n                  org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting\n                  org.apache.hadoop.hdfs.server.datanode.TestNNHandlesCombinedBlockReport\n                  org.apache.hadoop.hdfs.server.namenode.ha.TestXAttrsWithHA\n                  org.apache.hadoop.hdfs.TestBlockReaderFactory\n                  org.apache.hadoop.hdfs.server.namenode.TestFSImageWithSnapshot\n                  org.apache.hadoop.hdfs.TestPipelines\n                  org.apache.hadoop.fs.loadGenerator.TestLoadGenerator\n                  org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotRename\n                  org.apache.hadoop.cli.TestCacheAdminCLI\n                  org.apache.hadoop.hdfs.server.namenode.TestProcessCorruptBlocks\n                  org.apache.hadoop.hdfs.TestFileCorruption\n                  org.apache.hadoop.hdfs.server.namenode.TestMetadataVersionOutput\n                  org.apache.hadoop.hdfs.server.namenode.TestNamenodeCapacityReport\n                  org.apache.hadoop.hdfs.server.namenode.ha.TestLossyRetryInvocationHandler\n                  org.apache.hadoop.fs.TestHDFSFileContextMainOperations\n                  org.apache.hadoop.hdfs.server.namenode.TestSaveNamespace\n                  org.apache.hadoop.hdfs.server.datanode.TestMultipleNNDataBlockScanner\n                  org.apache.hadoop.fs.TestGlobPaths\n                  org.apache.hadoop.fs.viewfs.TestViewFsFileStatusHdfs\n                  org.apache.hadoop.hdfs.server.namenode.TestMetaSave\n                  org.apache.hadoop.hdfs.server.namenode.TestCheckPointForSecurityTokens\n                  org.apache.hadoop.hdfs.server.blockmanagement.TestPendingReplication\n                  org.apache.hadoop.hdfs.server.namenode.ha.TestHarFileSystemWithHA\n                  org.apache.hadoop.fs.viewfs.TestViewFsAtHdfsRoot\n                  org.apache.hadoop.TestGenericRefresh\n                  org.apache.hadoop.hdfs.server.datanode.TestIncrementalBrVariations\n                  org.apache.hadoop.hdfs.server.balancer.TestBalancerWithSaslDataTransfer\n                  org.apache.hadoop.hdfs.server.namenode.ha.TestHAAppend\n                  org.apache.hadoop.hdfs.tools.TestGetGroups\n                  org.apache.hadoop.hdfs.server.namenode.TestBackupNode\n                  org.apache.hadoop.hdfs.server.namenode.TestNameNodeAcl\n                  org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure\n                  org.apache.hadoop.fs.shell.TestHdfsTextCommand\n                  org.apache.hadoop.hdfs.TestLargeBlock\n                  org.apache.hadoop.cli.TestHDFSCLI\n                  org.apache.hadoop.hdfs.TestReplaceDatanodeOnFailure\n                  org.apache.hadoop.hdfs.server.namenode.TestFavoredNodesEndToEnd\n                  org.apache.hadoop.fs.TestSymlinkHdfsDisable\n                  org.apache.hadoop.hdfs.server.namenode.ha.TestHAStateTransitions\n                  org.apache.hadoop.hdfs.server.namenode.TestFSImage\n                  org.apache.hadoop.fs.viewfs.TestViewFileSystemHdfs\n                  org.apache.hadoop.hdfs.server.namenode.TestAddBlock\n                  org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencingWithReplication\n                  org.apache.hadoop.hdfs.server.namenode.ha.TestFailureToReadEdits\n                  org.apache.hadoop.hdfs.TestDFSInotifyEventInputStream\n                  org.apache.hadoop.hdfs.server.namenode.snapshot.TestRenameWithSnapshots\n                  org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshottableDirListing\n                  org.apache.hadoop.hdfs.TestLease\n                  org.apache.hadoop.hdfs.server.namenode.snapshot.TestSetQuotaWithSnapshot\n                  org.apache.hadoop.hdfs.server.namenode.TestNameNodeXAttr\n                  org.apache.hadoop.hdfs.server.datanode.TestDnRespectsBlockReportSplitThreshold\n                  org.apache.hadoop.hdfs.server.namenode.TestCheckpoint\n                  org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotStatsMXBean\n                  org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencing\n                  org.apache.hadoop.hdfs.server.datanode.TestDataNodeRollingUpgrade\n                  org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewerForAcl\n\n    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/8108//testReport/\nFindbugs warnings: https://builds.apache.org/job/PreCommit-HDFS-Build/8108//artifact/PreCommit-HADOOP-Build-patchprocess/newPatchFindbugsWarningshadoop-hdfs.html\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/8108//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2014-09-19T18:49:03.458+0000","updated":"2014-09-19T18:49:03.458+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12741891/comment/14141133","id":"14141133","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"body":"Well, all the things broke in that test run.  :-)  This is clearly a pre-commit build problem.  The failures are caused by {{NoSuchMethodError}}.  I'm starting to think that pre-commit builds are colliding with each other on the Jenkins host's local Maven repository.  If you have a hadoop-hdfs change dependent on a hadoop-common change, then I suspect there is a race condition that can cause your build to pull a hadoop-common.jar that was built for some other patch.  I've triggered a fresh build.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-09-19T19:25:09.849+0000","updated":"2014-09-19T19:25:09.849+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12741891/comment/14141277","id":"14141277","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=arpitagarwal","name":"arpitagarwal","key":"arpitagarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arpit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"body":"I am running into the same issue with HDFS-6581.\n\nIt may be more than just a race condition, I've run the build overnight when no other Jenkins builds were in progress and hit the same failure.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=arpitagarwal","name":"arpitagarwal","key":"arpitagarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arpit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-09-19T20:57:09.068+0000","updated":"2014-09-19T20:57:09.068+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12741891/comment/14141481","id":"14141481","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12670029/HDFS-7073.3.patch\n  against trunk revision 9f03a7c.\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:green}+1 tests included{color}.  The patch appears to include 3 new or modified test files.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:red}-1 findbugs{color}.  The patch appears to introduce 1 new Findbugs (version 2.0.3) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs:\n\n                  org.apache.hadoop.crypto.random.TestOsSecureRandom\n                  org.apache.hadoop.hdfs.server.mover.TestStorageMover\n                  org.apache.hadoop.hdfs.web.TestWebHdfsFileSystemContract\n                  org.apache.hadoop.hdfs.qjournal.server.TestJournalNode\n                  org.apache.hadoop.hdfs.TestEncryptionZonesWithKMS\n                  org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover\n\n    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/8114//testReport/\nFindbugs warnings: https://builds.apache.org/job/PreCommit-HDFS-Build/8114//artifact/PreCommit-HADOOP-Build-patchprocess/newPatchFindbugsWarningshadoop-hdfs.html\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/8114//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2014-09-19T22:46:39.159+0000","updated":"2014-09-19T22:46:39.159+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12741891/comment/14141513","id":"14141513","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"body":"The test failures are unrelated and documented elsewhere.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-09-19T23:08:30.796+0000","updated":"2014-09-19T23:08:30.796+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12741891/comment/14141592","id":"14141592","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hitliuyi","name":"hitliuyi","key":"hitliuyi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yi Liu","active":true,"timeZone":"Asia/Shanghai"},"body":"Thanks Chris, about {{ClientCache}}, you are right, I missed that.\nThe patch is OK for me, +1 (non-binding).","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hitliuyi","name":"hitliuyi","key":"hitliuyi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Yi Liu","active":true,"timeZone":"Asia/Shanghai"},"created":"2014-09-20T00:12:06.177+0000","updated":"2014-09-20T00:12:06.177+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12741891/comment/14141621","id":"14141621","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jnp","name":"jnp","key":"jnp","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jitendra Nath Pandey","active":true,"timeZone":"Etc/UTC"},"body":"+1","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jnp","name":"jnp","key":"jnp","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jitendra Nath Pandey","active":true,"timeZone":"Etc/UTC"},"created":"2014-09-20T00:48:11.199+0000","updated":"2014-09-20T00:48:11.199+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12741891/comment/14141758","id":"14141758","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"body":"I committed this to trunk and branch-2.  Jitendra and Yi, thanks very much for the very helpful code reviews.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-09-20T05:17:08.589+0000","updated":"2014-09-20T05:17:08.589+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12741891/comment/14141934","id":"14141934","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"SUCCESS: Integrated in Hadoop-Yarn-trunk #686 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/686/])\nHDFS-7073. Allow falling back to a non-SASL connection on DataTransferProtocol in several edge cases. Contributed by Chris Nauroth. (cnauroth: rev f85cc14eb49a46e81d2edcdc1ffe4d0852f193a5)\n* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/RPC.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DNConf.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/balancer/NameNodeConnector.java\n* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/sasl/SaslDataTransferClient.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestRetryCacheWithHA.java\n* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/WritableRpcEngine.java\n* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/ProtobufRpcEngine.java\n* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/ipc/TestRPC.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSConfigKeys.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/HAUtil.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NamenodeFsck.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/balancer/Dispatcher.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/ha/ConfiguredFailoverProxyProvider.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/ha/AbstractNNFailoverProxyProvider.java\n* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Client.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSClient.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/NameNodeProxies.java\n* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/RpcEngine.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/sasl/SaslDataTransferServer.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/protocol/datatransfer/sasl/TestSaslDataTransfer.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2014-09-20T11:33:49.551+0000","updated":"2014-09-20T11:33:49.551+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12741891/comment/14141976","id":"14141976","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"FAILURE: Integrated in Hadoop-Hdfs-trunk #1877 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1877/])\nHDFS-7073. Allow falling back to a non-SASL connection on DataTransferProtocol in several edge cases. Contributed by Chris Nauroth. (cnauroth: rev f85cc14eb49a46e81d2edcdc1ffe4d0852f193a5)\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DNConf.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSConfigKeys.java\n* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Client.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/sasl/SaslDataTransferClient.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestRetryCacheWithHA.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/HAUtil.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/sasl/SaslDataTransferServer.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/balancer/Dispatcher.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSClient.java\n* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/ha/AbstractNNFailoverProxyProvider.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/balancer/NameNodeConnector.java\n* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/RpcEngine.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/NameNodeProxies.java\n* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/ProtobufRpcEngine.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/protocol/datatransfer/sasl/TestSaslDataTransfer.java\n* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/ipc/TestRPC.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NamenodeFsck.java\n* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/WritableRpcEngine.java\n* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/RPC.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/ha/ConfiguredFailoverProxyProvider.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2014-09-20T13:52:13.358+0000","updated":"2014-09-20T13:52:13.358+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12741891/comment/14142070","id":"14142070","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"FAILURE: Integrated in Hadoop-Mapreduce-trunk #1902 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1902/])\nHDFS-7073. Allow falling back to a non-SASL connection on DataTransferProtocol in several edge cases. Contributed by Chris Nauroth. (cnauroth: rev f85cc14eb49a46e81d2edcdc1ffe4d0852f193a5)\n* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/RpcEngine.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/protocol/datatransfer/sasl/TestSaslDataTransfer.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/ha/ConfiguredFailoverProxyProvider.java\n* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/ipc/TestRPC.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSConfigKeys.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/balancer/NameNodeConnector.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/sasl/SaslDataTransferServer.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/HAUtil.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NamenodeFsck.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/NameNodeProxies.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java\n* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/RPC.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/sasl/SaslDataTransferClient.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/balancer/Dispatcher.java\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestRetryCacheWithHA.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DNConf.java\n* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/WritableRpcEngine.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSClient.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/ha/AbstractNNFailoverProxyProvider.java\n* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/ProtobufRpcEngine.java\n* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Client.java\n* hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2014-09-20T16:02:18.850+0000","updated":"2014-09-20T16:02:18.850+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12741891/comment/14142219","id":"14142219","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"body":"I missed a Findbugs warning in this patch.  I just submitted a subsequent patch on HDFS-7107 to fix this.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cnauroth","name":"cnauroth","key":"cnauroth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=cnauroth&avatarId=11432","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=cnauroth&avatarId=11432","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=cnauroth&avatarId=11432","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=cnauroth&avatarId=11432"},"displayName":"Chris Nauroth","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-09-20T22:33:58.543+0000","updated":"2014-09-20T22:33:58.543+0000"}],"maxResults":27,"total":27,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-7073/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i2046v:"}}