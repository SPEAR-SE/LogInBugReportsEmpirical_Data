{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"13071553","self":"https://issues.apache.org/jira/rest/api/2/issue/13071553","key":"HDFS-11817","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12334218","id":"12334218","description":"2.9.0 release","name":"2.9.0","archived":false,"released":true,"releaseDate":"2017-11-17"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12339179","id":"12339179","name":"3.0.0-alpha4","archived":false,"released":true,"releaseDate":"2017-07-07"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12340353","id":"12340353","name":"2.8.2","archived":false,"released":true,"releaseDate":"2017-10-24"}],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2017-05-18T19:38:50.355+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Tue Apr 24 20:51:19 UTC 2018","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_633955831_*|*_5_*:*_1_*:*_0_*|*_10002_*:*_1_*:*_518513348","customfield_12312321":null,"resolutiondate":"2017-05-25T22:37:41.157+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-11817/watchers","watchCount":12,"isWatching":false},"created":"2017-05-12T14:29:52.036+0000","customfield_12310192":null,"customfield_12310191":[{"self":"https://issues.apache.org/jira/rest/api/2/customFieldOption/10343","value":"Reviewed","id":"10343"}],"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/2","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/critical.svg","name":"Critical","id":"2"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"6.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12329057","id":"12329057","description":"2.8.0 release","name":"2.8.0","archived":false,"released":true,"releaseDate":"2017-03-22"}],"issuelinks":[{"id":"12533859","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12533859","type":{"id":"12310000","name":"Duplicate","inward":"is duplicated by","outward":"duplicates","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/12310000"},"inwardIssue":{"id":"12830008","key":"HDFS-8406","self":"https://issues.apache.org/jira/rest/api/2/issue/12830008","fields":{"summary":"Lease recovery continually failed","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12532150","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12532150","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"inwardIssue":{"id":"13153825","key":"HDFS-13486","self":"https://issues.apache.org/jira/rest/api/2/issue/13153825","fields":{"summary":"Backport HDFS-11817 (A faulty node can cause a lease leak and NPE on accessing data) to branch-2.7","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2018-05-12T06:42:19.131+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[],"timeoriginalestimate":null,"description":"When the namenode performs a lease recovery for a failed write, the {{commitBlockSynchronization()}} will fail, if none of the new target has sent a received-IBR.  At this point, the data is inaccessible, as the namenode will throw a {{NullPointerException}} upon {{getBlockLocations()}}.\n\nThe lease recovery will be retried in about an hour by the namenode. If the nodes are faulty (usually when there is only one new target), they may not block report until this point. If this happens, lease recovery throws an {{AlreadyBeingCreatedException}}, which causes LeaseManager to simply remove the lease without  finalizing the inode.  \n\nThis results in an inconsistent lease state. The inode stays under-construction, but no more lease recovery is attempted. A manual lease recovery is also not allowed. \n","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12339198","id":"12339198","name":"2.8.1","archived":false,"released":true,"releaseDate":"2017-06-08"}],"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12868777","id":"12868777","filename":"hdfs-11817_supplement.txt","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"created":"2017-05-18T14:39:55.201+0000","size":6772,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12868777/hdfs-11817_supplement.txt"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12919880","id":"12919880","filename":"HDFS-11817.branch-2.7.001.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"created":"2018-04-19T20:12:32.852+0000","size":15608,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12919880/HDFS-11817.branch-2.7.001.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12869068","id":"12869068","filename":"HDFS-11817.branch-2.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"created":"2017-05-19T22:35:39.909+0000","size":17117,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12869068/HDFS-11817.branch-2.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12869949","id":"12869949","filename":"HDFS-11817.v2.branch-2.8.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"created":"2017-05-25T22:40:19.683+0000","size":16344,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12869949/HDFS-11817.v2.branch-2.8.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12869358","id":"12869358","filename":"HDFS-11817.v2.branch-2.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"created":"2017-05-22T22:54:27.177+0000","size":15944,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12869358/HDFS-11817.v2.branch-2.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12869359","id":"12869359","filename":"HDFS-11817.v2.trunk.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"created":"2017-05-22T22:54:27.184+0000","size":13335,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12869359/HDFS-11817.v2.trunk.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"A faulty node can cause a lease leak and NPE on accessing data","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/13071553/comment/16010646","id":"16010646","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"body":"There are two possible immediate fixes that can be implemented.\n- Allow {{commitBlockSynchronization()}} to complete even if a received-IBR is not received (I.e. last block not in COMPLETE state). This is equivalent of allowing closing without the last block being COMPETE.\n- Do not allow {{LeaseManager}} to blindly remove the lease on a lease recovery failure and leave the inode in under-construction state. \n\nThey are all simple changes that will prevent the issues from happening.  However, I haven't been able to root cause how and where NPE is happening.  It is from calling {{getBlockLocations()}}, but so far I have not been able to reproduce it.  I will find other means to RC it.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"created":"2017-05-15T14:58:13.527+0000","updated":"2017-05-15T14:58:13.527+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13071553/comment/16014703","id":"16014703","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"body":"*Details of the NPE:*\nThe JVM did produce a stacktrace on the very first occurance of the NPE. Subsequent ones were missing a stack trace.\n\nThe NPE is caused by {{commitBlockSynchronization()}} containing a dead node in the new targets.  Since block recoveries are issued based on {{BlockUnderConstructionFeature.replicas}} (aka expected locations), which is not updated on node death, block recovery can include dead nodes.  When {{commitBlockSynchronization()}} is called, the expected locations is also updated. (In fact, the whole BlockUnderConstructionFeature is swapped)  Each expected location is populated by searching for datanode storage using the storage ID string passed in {{commitBlockSynchronization()}}.   If the node is dead, the look up returns null.\n\n(Clarification on dead node: the faulty node did try to come back at times and that actually made the situation worse. On re-registration, the existing storages are removed from the datanode descriptor. If it cannot heatbeat for some reason, storage lookup using a storage ID will return null)\n\nIf {{getBlockLocation()}} is called after this, {{newLocatedBlock()}} is called with the expected locations, not with the locations in the blocks map, since it is still under-construction. This calls {{DatanodeStorageInfo.toDatanodeInfos()}}, which blows up, as it tries to call {{getDatanodeDescriptor()}} of the null storage object.\n\n*Proposed solution to the NPE issue:*\nWe can have {{commitBlockSynchronization()}} check for valid storage ID before updating data structures.  Even if no valid storage ID is found, we can't fail the operation. One or more node did finalize the block, whether they are dead or alive at this moment. It is like a missing block case.  We can go ahead and commit the block without the dead node/storage and also allow closing of the file, just like {{completeFile()}}.\n\nOn closing of the file, {{checkReplication()}} is called and in our example, this will cause the last block (still in committed state) to be reported as missing.  If the dead node comes back, it will include the finalized replica in the block report and that will cause the block to be completed and missing block to be cleared.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"created":"2017-05-17T20:23:03.481+0000","updated":"2017-05-18T20:24:41.231+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13071553/comment/16014712","id":"16014712","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"body":"*Summary:*\n The observation of the incident resulted in discovery of three flaws.\n\n1) A block recovery can involve dead nodes and it can lead to a corruption of a data structure, which causes NPE.\n2) If a block cannot be completed, {{commitBlockSynchronization()}} will fail, since it requires all blocks to be complete, unlike regular file closings.\n3) If a block has experienced 2) and remains committed (not complete), next lease recovery will result in a lease state corruption. (Removed from LeaseManager, but INode stays under-construction)\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"created":"2017-05-17T20:30:16.103+0000","updated":"2017-05-17T20:30:16.103+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13071553/comment/16015850","id":"16015850","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"body":"Attaching supplemental information including stack traces.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"created":"2017-05-18T14:39:55.207+0000","updated":"2017-05-18T14:39:55.207+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13071553/comment/16016330","id":"16016330","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks for your investigation Kihwal! I am seeing something similar on 2.7.3. A block is holding up decommissioning because recovery failed. (The strace below is from the time when the cluster was 2.7.2) . DN2 and DN3 are no longer part of the cluster. DN1 is the node held up for decomissioning. I checked that the block and meta file indeed are in the finalized directory.\n{code}\n2016-09-19 09:02:25,837 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: recoverBlocks FAILED: RecoveringBlock{BP-<someid>:blk_1094097355_20357090; getBlockSize()=0; corrupt=false; offset=-1; locs=[DatanodeInfoWithStorage[<DN1>:50010,null,null], DatanodeInfoWithStorage[<DN2>:50010,null,null], DatanodeInfoWithStorage[<DN3>:50010,null,null]]}\norg.apache.hadoop.ipc.RemoteException(java.lang.IllegalStateException): Failed to finalize INodeFile <filename> since blocks[0] is non-complete, where blocks=[blk_1094097355_20552508{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=0, replicas=[ReplicaUC[[DISK]DS-03bed13e-5cdd-4207-91b6-abd83f9eb7d3:NORMAL:<DN1>:50010|RBW]]}].\n        at com.google.common.base.Preconditions.checkState(Preconditions.java:172)\n        at org.apache.hadoop.hdfs.server.namenode.INodeFile.assertAllBlocksComplete(INodeFile.java:222)\n        at org.apache.hadoop.hdfs.server.namenode.INodeFile.toCompleteFile(INodeFile.java:209)\n        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.finalizeINodeFileUnderConstruction(FSNamesystem.java:4218)\n        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.closeFileCommitBlocks(FSNamesystem.java:4457)\n        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.commitBlockSynchronization(FSNamesystem.java:4419)\n        at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.commitBlockSynchronization(NameNodeRpcServer.java:837)\n        at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolServerSideTranslatorPB.commitBlockSynchronization(DatanodeProtocolServerSideTranslatorPB.java:291)\n        at org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$DatanodeProtocolService$2.callBlockingMethod(DatanodeProtocolProtos.java:28768)\n        at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)\n        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:969)\n        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)\n        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:415)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1679)\n        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)\n\n        at org.apache.hadoop.ipc.Client.call(Client.java:1475)\n        at org.apache.hadoop.ipc.Client.call(Client.java:1412)\n        at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)\n        at com.sun.proxy.$Proxy16.commitBlockSynchronization(Unknown Source)\n        at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.commitBlockSynchronization(DatanodeProtocolClientSideTranslatorPB.java:312)\n        at org.apache.hadoop.hdfs.server.datanode.DataNode.syncBlock(DataNode.java:2780)\n        at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:2642)\n        at org.apache.hadoop.hdfs.server.datanode.DataNode.access$400(DataNode.java:243)\n        at org.apache.hadoop.hdfs.server.datanode.DataNode$5.run(DataNode.java:2519)\n        at java.lang.Thread.run(Thread.java:744)\n{code}\n\nI am not sure what purpose failing {{commitBlockSyncronization()}} in this case fulfills, so I would be agreeable to your proposed solution\nbq. We can have commitBlockSynchronization() check for valid storage ID before updating data structures. Even if no valid storage ID is found, we can't fail the operation","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-05-18T19:38:50.355+0000","updated":"2017-05-18T19:38:50.355+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13071553/comment/16016420","id":"16016420","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"body":"Hi, [~raviprak]. We've seen what you described above. It is not directly related to this jira, but I think we had an internal fix for this. Just a couple of days ago, we were talking about pushing the fix to Apache. Please do file a jira and let me know.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"created":"2017-05-18T20:29:38.828+0000","updated":"2017-05-18T20:29:38.828+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13071553/comment/16016472","id":"16016472","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks Kihwal! I've filed https://issues.apache.org/jira/browse/HDFS-11852 . ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=raviprak","name":"raviprak","key":"raviprak","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=raviprak&avatarId=10113","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=raviprak&avatarId=10113","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=raviprak&avatarId=10113","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=raviprak&avatarId=10113"},"displayName":"Ravi Prakash","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-05-18T21:13:36.818+0000","updated":"2017-05-18T21:13:36.818+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13071553/comment/16018136","id":"16018136","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"body":"I started the patch for branch-2.8 and branch-2.  The trunk version is not ready yet, but want to run the branch-2 version through precommit before the weekend.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"created":"2017-05-19T22:35:39.915+0000","updated":"2017-05-19T22:35:39.915+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13071553/comment/16018224","id":"16018224","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 18s{color} | {color:blue} Docker mode activated. {color} |\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 3 new or modified test files. {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  7m  8s{color} | {color:green} branch-2 passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 48s{color} | {color:green} branch-2 passed with JDK v1.8.0_131 {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 46s{color} | {color:green} branch-2 passed with JDK v1.7.0_131 {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 33s{color} | {color:green} branch-2 passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 56s{color} | {color:green} branch-2 passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 15s{color} | {color:green} branch-2 passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m  8s{color} | {color:green} branch-2 passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 41s{color} | {color:green} branch-2 passed with JDK v1.8.0_131 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m  2s{color} | {color:green} branch-2 passed with JDK v1.7.0_131 {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 49s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 41s{color} | {color:green} the patch passed with JDK v1.8.0_131 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 41s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 44s{color} | {color:green} the patch passed with JDK v1.7.0_131 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 44s{color} | {color:green} the patch passed {color} |\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 29s{color} | {color:orange} hadoop-hdfs-project/hadoop-hdfs: The patch generated 7 new + 272 unchanged - 5 fixed = 279 total (was 277) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 51s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 14s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 17s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 38s{color} | {color:green} the patch passed with JDK v1.8.0_131 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m  1s{color} | {color:green} the patch passed with JDK v1.7.0_131 {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 56m 20s{color} | {color:red} hadoop-hdfs in the patch failed with JDK v1.7.0_131. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 22s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black}138m 58s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| JDK v1.8.0_131 Failed junit tests | hadoop.hdfs.server.namenode.TestLeaseManager |\n|   | hadoop.hdfs.server.balancer.TestBalancerRPCDelay |\n|   | hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA |\n| JDK v1.8.0_131 Timed out junit tests | org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting |\n| JDK v1.7.0_131 Failed junit tests | hadoop.hdfs.server.namenode.TestLeaseManager |\n|   | hadoop.hdfs.server.blockmanagement.TestReplicationPolicyWithUpgradeDomain |\n|   | hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA |\n| JDK v1.7.0_131 Timed out junit tests | org.apache.hadoop.hdfs.server.blockmanagement.TestBlockStatsMXBean |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:8515d35 |\n| JIRA Issue | HDFS-11817 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12869068/HDFS-11817.branch-2.patch |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux 0657e96c7c2d 3.13.0-107-generic #154-Ubuntu SMP Tue Dec 20 09:57:27 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | branch-2 / 2719cc0 |\n| Default Java | 1.7.0_131 |\n| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_131 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_131 |\n| findbugs | v3.0.0 |\n| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/19520/artifact/patchprocess/diff-checkstyle-hadoop-hdfs-project_hadoop-hdfs.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/19520/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.7.0_131.txt |\n| JDK v1.7.0_131  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/19520/testReport/ |\n| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/19520/console |\n| Powered by | Apache Yetus 0.5.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2017-05-20T01:14:13.872+0000","updated":"2017-05-20T01:14:13.872+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13071553/comment/16019886","id":"16019886","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"body":"Two test failures are real.\n{noformat}\nTestRetryCacheWithHA#testCheckLease\nTestLeaseManager#testCheckLease\n{noformat}\n\n{{TestLeaseManager}} was failing because I made failed lease recoveries to be retried. In the new patch, I made it give up and remove the lease if an IOException is thrown because of a bad path.  For all other cases, it is correct to retry, since they are likely transient conditions.\n\n{{TestRetryCacheWithHA}} was failing because the test passed fake storage IDs to {{updatePipeline()}}, despite it has the real storage IDs available. Updated the test.\n\nI will upload the trunk version shortly with these changes.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"created":"2017-05-22T17:38:30.658+0000","updated":"2017-05-22T17:38:30.658+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13071553/comment/16020252","id":"16020252","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"body":"In trunk, there already is a logic to weed out null StorageInfo before putting one to the expected locations. This was done by as part of HDFS-9040. It too had TestRetryCacheWithHA failed, so it was also fixed as part of HDFS-9040, although I believe my fix is better. As it is a EC-related change, the JIRA cannot be applied to branch-2.   I will back-port the relevant portion in my patch, so that trunk and branch-2/2.8 stays more in sync.  The trunk version of my patch will contain the test case (HDFS-9040 did not add a new test case for this) and the lease manager fix.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"created":"2017-05-22T21:45:32.050+0000","updated":"2017-05-22T21:45:32.050+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13071553/comment/16020510","id":"16020510","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  1m 13s{color} | {color:blue} Docker mode activated. {color} |\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 3 new or modified test files. {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 14m 22s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 50s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 40s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 53s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 16s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 43s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 44s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 51s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 47s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 47s{color} | {color:green} the patch passed {color} |\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 36s{color} | {color:orange} hadoop-hdfs-project/hadoop-hdfs: The patch generated 7 new + 271 unchanged - 4 fixed = 278 total (was 275) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 59s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 12s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 57s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 40s{color} | {color:green} the patch passed {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 72m 11s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 24s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black}100m 47s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| Failed junit tests | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure |\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure080 |\n|   | hadoop.hdfs.TestDFSRSDefault10x4StripedOutputStreamWithFailure |\n|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:14b5c93 |\n| JIRA Issue | HDFS-11817 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12869359/HDFS-11817.v2.trunk.patch |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux f5667cdf52bd 3.13.0-107-generic #154-Ubuntu SMP Tue Dec 20 09:57:27 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / 8e0f83e |\n| Default Java | 1.8.0_131 |\n| findbugs | v3.1.0-RC1 |\n| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/19549/artifact/patchprocess/diff-checkstyle-hadoop-hdfs-project_hadoop-hdfs.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/19549/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |\n|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/19549/testReport/ |\n| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/19549/console |\n| Powered by | Apache Yetus 0.5.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2017-05-23T01:12:39.521+0000","updated":"2017-05-23T01:12:39.521+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13071553/comment/16025471","id":"16025471","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=daryn","name":"daryn","key":"daryn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Daryn Sharp","active":true,"timeZone":"America/Chicago"},"body":"+1 I would be nice if this recovery code was cleaned up someday, but this definitely fixes the perma-UC files and NPEs.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=daryn","name":"daryn","key":"daryn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Daryn Sharp","active":true,"timeZone":"America/Chicago"},"created":"2017-05-25T22:12:57.960+0000","updated":"2017-05-25T22:12:57.960+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13071553/comment/16025494","id":"16025494","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"body":"Thanks for the review, Daryn.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"created":"2017-05-25T22:37:41.198+0000","updated":"2017-05-25T22:37:41.198+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13071553/comment/16025499","id":"16025499","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"body":"Attaching what's committed to 2.8 as reference.  The cherry-pick from branch-2 was clean, but had to update one method call in the test, since the containing class has been changed.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"created":"2017-05-25T22:40:19.689+0000","updated":"2017-05-25T22:40:19.689+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13071553/comment/16025525","id":"16025525","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"SUCCESS: Integrated in Jenkins build Hadoop-trunk-Commit #11785 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/11785/])\nHDFS-11817. A faulty node can cause a lease leak and NPE on accessing (kihwal: rev 2b5ad48762587abbcd8bdb50d0ae98f8080d926c)\n* (edit) hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirTruncateOp.java\n* (edit) hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java\n* (edit) hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestBlockUnderConstructionFeature.java\n* (edit) hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestBlockUnderConstruction.java\n* (edit) hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java\n* (edit) hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockUnderConstructionFeature.java\n* (edit) hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestCommitBlockSynchronization.java\n* (edit) hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/LeaseManager.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2017-05-25T23:03:50.678+0000","updated":"2017-05-25T23:03:50.678+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13071553/comment/16128995","id":"16128995","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brahmareddy","name":"brahmareddy","key":"brahmareddy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=brahmareddy&avatarId=24624","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=brahmareddy&avatarId=24624","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=brahmareddy&avatarId=24624","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=brahmareddy&avatarId=24624"},"displayName":"Brahma Reddy Battula","active":true,"timeZone":"Asia/Kolkata"},"body":"I feel, this can be merged to {{branch-2.7}} as well.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brahmareddy","name":"brahmareddy","key":"brahmareddy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=brahmareddy&avatarId=24624","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=brahmareddy&avatarId=24624","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=brahmareddy&avatarId=24624","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=brahmareddy&avatarId=24624"},"displayName":"Brahma Reddy Battula","active":true,"timeZone":"Asia/Kolkata"},"created":"2017-08-16T16:02:17.564+0000","updated":"2017-08-16T16:02:17.564+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13071553/comment/16129868","id":"16129868","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinayrpet","name":"vinayrpet","key":"vinayrpet","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinayakumar B","active":true,"timeZone":"Asia/Kolkata"},"body":"bq. I feel, this can be merged to branch-2.7 as well.\n+1","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinayrpet","name":"vinayrpet","key":"vinayrpet","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinayakumar B","active":true,"timeZone":"Asia/Kolkata"},"created":"2017-08-17T04:12:36.940+0000","updated":"2017-08-17T04:12:36.940+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13071553/comment/16444708","id":"16444708","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"body":"I'm trying to backport this to branch-2.7.\r\n\r\nThere are quite a few conflicts, but the biggest change compared to the branch-2.8 patch is\r\n{code:java|title=BlockInfoContiguousUnderConstruction#addReplicaIfNotPresent}\r\nvoid addReplicaIfNotPresent(DatanodeStorageInfo storage,\r\n                     Block block,\r\n                     ReplicaState rState) {\r\n    Iterator<ReplicaUnderConstruction> it = replicas.iterator();\r\n    while (it.hasNext()) {\r\n{code}\r\nbecause branch-2.7 does not have HDFS-8928. Without the change, replicas could be null and tests fails with NPE.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"created":"2018-04-19T20:12:53.992+0000","updated":"2018-04-19T20:12:53.992+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13071553/comment/16444720","id":"16444720","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"body":"I filed HDFS-13486 to initiate the backport effort. Since the change is non-trivial, I'd like to have a dedicated Jira to get code reviewed and to validate with tests.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"created":"2018-04-19T20:17:27.854+0000","updated":"2018-04-19T20:17:27.854+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13071553/comment/16450793","id":"16450793","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"SUCCESS: Integrated in Jenkins build Hadoop-trunk-Commit #14057 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/14057/])\nHDFS-11817. A faulty node can cause a lease leak and NPE on accessing (xyao: rev 0dbcd01de54b68142e0e54b2c948eff0c3fdada6)\n* (edit) hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirTruncateOp.java\n* (edit) hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java\n* (edit) hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestCommitBlockSynchronization.java\n* (edit) hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockUnderConstructionFeature.java\n* (edit) hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestBlockUnderConstruction.java\n* (edit) hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestBlockUnderConstructionFeature.java\n* (edit) hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/LeaseManager.java\n* (edit) hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2018-04-24T20:51:19.409+0000","updated":"2018-04-24T20:51:19.409+0000"}],"maxResults":21,"total":21,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-11817/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i3ewh3:"}}