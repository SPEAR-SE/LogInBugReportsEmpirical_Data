{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"13140341","self":"https://issues.apache.org/jira/rest/api/2/issue/13140341","key":"HDFS-13179","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":"2018-03-12T20:10:21.272+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Mon Mar 26 09:02:10 UTC 2018","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-13179/watchers","watchCount":7,"isWatching":false},"created":"2018-02-22T22:32:48.061+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/2","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/critical.svg","name":"Critical","id":"2"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"1.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12341433","id":"12341433","description":"3.0.0 GA release","name":"3.0.0","archived":false,"released":true,"releaseDate":"2017-12-13"}],"issuelinks":[],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2018-03-27T02:50:53.227+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12327021","id":"12327021","name":"fs"}],"timeoriginalestimate":null,"description":"The error caused by TimeoutException because the test is waiting to ensure that the file is replicated to DISK storage but the replication can't be finished to DISK during the 30s timeout in ensureFileReplicasOnStorageType(), but the file is still on RAM_DISK - so there is no data loss.\r\n\r\nAdding the following to TestLazyPersistReplicaRecovery.java:56 essentially fixes the flakiness. \r\n{code:java}\r\n    try {\r\n      ensureFileReplicasOnStorageType(path1, DEFAULT);\r\n    }catch (TimeoutException t){\r\n      LOG.warn(\"We got \\\"\" + t.getMessage() + \"\\\" so trying to find data on RAM_DISK\");\r\n      ensureFileReplicasOnStorageType(path1, RAM_DISK);\r\n    }\r\n  }\r\n{code}\r\n\r\nSome thoughts:\r\n* Successful and failed tests run similar to the point when datanode restarts. Restart line is the following in the log: LazyPersistTestCase - Restarting the DataNode\r\n* There is a line which only occurs in the failed test: *addStoredBlock: Redundant addStoredBlock request received for blk_1073741825_1001 on node 127.0.0.1:49455 size 5242880*\r\n* This redundant request at BlockManager#addStoredBlock could be the main reason for the test fail. Something wrong with the gen stamp? Corrupt replicas? \r\n\r\n=============================\r\n\r\nCurrent fail ratio based on my test of TestLazyPersistReplicaRecovery: \r\n1000 runs, 34 failures (3.4% fail)\r\n\r\nFailure rate analysis:\r\nTestLazyPersistReplicaRecovery.testDnRestartWithSavedReplicas: 3.4%\r\n\r\n33 failures caused by: {noformat}\r\njava.util.concurrent.TimeoutException: Timed out waiting for condition. Thread diagnostics: Timestamp: 2018-01-05 11:50:34,964 \"IPC Server handler 6 on 39589\" \r\n{noformat}\r\n\r\n1 failure caused by: {noformat}\r\njava.net.BindException: Problem binding to [localhost:56729] java.net.BindException: Address already in use; For more details see: http://wiki.apache.org/hadoop/BindException at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestLazyPersistReplicaRecovery.testDnRestartWithSavedReplicas(TestLazyPersistReplicaRecovery.java:49) Caused by: java.net.BindException: Address already in use at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestLazyPersistReplicaRecovery.testDnRestartWithSavedReplicas(TestLazyPersistReplicaRecovery.java:49)\r\n{noformat}\r\n\r\n=============================\r\n\r\nExample stacktrace:\r\n{noformat}\r\nTimed out waiting for condition. Thread diagnostics:\r\nTimestamp: 2017-11-01 10:36:49,499\r\n\"Thread-1\" prio=5 tid=13 runnable\r\njava.lang.Thread.State: RUNNABLE\r\nat java.lang.Thread.dumpThreads(Native Method)\r\nat java.lang.Thread.getAllStackTraces(Thread.java:1610)\r\nat org.apache.hadoop.test.TimedOutTestsListener.buildThreadDump(TimedOutTestsListener.java:87)\r\nat org.apache.hadoop.test.TimedOutTestsListener.buildThreadDiagnosticString(TimedOutTestsListener.java:73)\r\nat org.apache.hadoop.test.GenericTestUtils.waitFor(GenericTestUtils.java:369)\r\nat org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.LazyPersistTestCase.ensureFileReplicasOnStorageType(LazyPersistTestCase.java:140)\r\nat org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestLazyPersistReplicaRecovery.testDnRestartWithSavedReplicas(TestLazyPersistReplicaRecovery.java:54)\r\nat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\nat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\nat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\nat java.lang.reflect.Method.invoke(Method.java:498)\r\n...\r\n{noformat}","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12914205","id":"12914205","filename":"test runs.zip","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gabor.bota","name":"gabor.bota","key":"gabor.bota","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=gabor.bota&avatarId=33034","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=gabor.bota&avatarId=33034","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=gabor.bota&avatarId=33034","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=gabor.bota&avatarId=33034"},"displayName":"Gabor Bota","active":true,"timeZone":"Europe/Budapest"},"created":"2018-03-13T03:03:27.406+0000","size":53040,"mimeType":"application/zip","content":"https://issues.apache.org/jira/secure/attachment/12914205/test+runs.zip"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"TestLazyPersistReplicaRecovery#testDnRestartWithSavedReplicas fails intermittently","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gabor.bota","name":"gabor.bota","key":"gabor.bota","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=gabor.bota&avatarId=33034","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=gabor.bota&avatarId=33034","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=gabor.bota&avatarId=33034","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=gabor.bota&avatarId=33034"},"displayName":"Gabor Bota","active":true,"timeZone":"Europe/Budapest"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gabor.bota","name":"gabor.bota","key":"gabor.bota","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=gabor.bota&avatarId=33034","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=gabor.bota&avatarId=33034","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=gabor.bota&avatarId=33034","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=gabor.bota&avatarId=33034"},"displayName":"Gabor Bota","active":true,"timeZone":"Europe/Budapest"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/13140341/comment/16395805","id":"16395805","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bharatviswa","name":"bharatviswa","key":"bharatviswa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Bharat Viswanadham","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi [~gabor.bota]\r\n\r\nIf we do that, then the replica is not propagated to disk and the test case purpose of checking whether it is moved to disk or not is checked, if we add such a code right? Let me know If I am missing something here?\r\n\r\ntestDnRestartWithSavedReplicas will not be tested. So, I am thinking can we iterate for more than 30 seconds and check the test case behavior?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bharatviswa","name":"bharatviswa","key":"bharatviswa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Bharat Viswanadham","active":true,"timeZone":"America/Los_Angeles"},"created":"2018-03-12T20:10:21.272+0000","updated":"2018-03-12T20:10:21.272+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13140341/comment/16395838","id":"16395838","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gabor.bota","name":"gabor.bota","key":"gabor.bota","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=gabor.bota&avatarId=33034","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=gabor.bota&avatarId=33034","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=gabor.bota&avatarId=33034","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=gabor.bota&avatarId=33034"},"displayName":"Gabor Bota","active":true,"timeZone":"Europe/Budapest"},"body":"[~bharatviswa] if you are speaking about increasing the timeout, it won't fix the issue. Once the {noformat} addStoredBlock: Redundant addStoredBlock request received... {noformat} happens the test will fail. \r\nDo you maybe know what can cause the redundant request, and how to prevent it?\r\n ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gabor.bota","name":"gabor.bota","key":"gabor.bota","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=gabor.bota&avatarId=33034","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=gabor.bota&avatarId=33034","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=gabor.bota&avatarId=33034","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=gabor.bota&avatarId=33034"},"displayName":"Gabor Bota","active":true,"timeZone":"Europe/Budapest"},"created":"2018-03-12T20:38:52.228+0000","updated":"2018-03-12T20:39:04.300+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13140341/comment/16395888","id":"16395888","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=elgoiri","name":"elgoiri","key":"elgoiri","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Íñigo Goiri","active":true,"timeZone":"Etc/UTC"},"body":"FWIW, not completely related but TestLazyPersistReplicaRecovery cannot even start in Windows:\r\n{code}\r\n[ERROR] testDnRestartWithSavedReplicas(org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestLazyPersistReplicaRecovery)  Time elapsed: 2.804 s  <<< ERROR!\r\n1450: Insufficient system resources exist to complete the requested service.\r\n\r\n        at org.apache.hadoop.io.nativeio.NativeIO$Windows.extendWorkingSetSize(Native Method)\r\n        at org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1373)\r\n        at org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:497)\r\n        at org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2769)\r\n        at org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2677)\r\n        at org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1643)\r\n        at org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:885)\r\n        at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:497)\r\n        at org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:456)\r\n        at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.LazyPersistTestCase.startUpCluster(LazyPersistTestCase.java:315)\r\n        at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.LazyPersistTestCase$ClusterWithRamDiskBuilder.build(LazyPersistTestCase.java:414)\r\n        at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestLazyPersistReplicaRecovery.testDnRestartWithSavedReplicas(TestLazyPersistReplicaRecovery.java:36)\r\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n        at java.lang.reflect.Method.invoke(Method.java:498)\r\n        at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)\r\n        at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)\r\n        at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)\r\n        at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)\r\n        at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)\r\n        at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)\r\n{code}\r\nProbably this should be a separate JIRA though.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=elgoiri","name":"elgoiri","key":"elgoiri","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Íñigo Goiri","active":true,"timeZone":"Etc/UTC"},"created":"2018-03-12T21:00:12.609+0000","updated":"2018-03-12T21:00:12.609+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13140341/comment/16396092","id":"16396092","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bharatviswa","name":"bharatviswa","key":"bharatviswa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Bharat Viswanadham","active":true,"timeZone":"America/Los_Angeles"},"body":"[~gabor.bota]\r\n\r\nThis will happen, when the trigger block report is called, the block report sent block storage is still RAM_DISK, it is not DISK, then we get the Redundant addStoredBlock request. I mean, when we process the IBR (the block reported storage is still RAM_DISK).\r\n\r\n \r\n\r\nI am not completely sure why this block not moved to disk, might be the RamDiskReplicaTracker scheduled for move, but not yet completed, and it has restarted datanode. So, this might be happening.\r\n\r\n \r\n\r\nIf you have a complete log of that run by chance, that will help to find the actual cause. As I am not able to repeat this issue.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bharatviswa","name":"bharatviswa","key":"bharatviswa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Bharat Viswanadham","active":true,"timeZone":"America/Los_Angeles"},"created":"2018-03-12T21:43:33.106+0000","updated":"2018-03-12T21:47:11.467+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13140341/comment/16396469","id":"16396469","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gabor.bota","name":"gabor.bota","key":"gabor.bota","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=gabor.bota&avatarId=33034","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=gabor.bota&avatarId=33034","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=gabor.bota&avatarId=33034","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=gabor.bota&avatarId=33034"},"displayName":"Gabor Bota","active":true,"timeZone":"Europe/Budapest"},"body":"I've uploaded the successful and the failed test logs with some additional logging included.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gabor.bota","name":"gabor.bota","key":"gabor.bota","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=gabor.bota&avatarId=33034","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=gabor.bota&avatarId=33034","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=gabor.bota&avatarId=33034","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=gabor.bota&avatarId=33034"},"displayName":"Gabor Bota","active":true,"timeZone":"Europe/Budapest"},"created":"2018-03-13T03:04:35.326+0000","updated":"2018-03-13T03:04:35.326+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13140341/comment/16413600","id":"16413600","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=liaoyuxiangqin","name":"liaoyuxiangqin","key":"liaoyuxiangqin","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liaoyuxiangqin","active":true,"timeZone":"Etc/UTC"},"body":"[~gabor.bota] [~bharatviswa] [~elgoiri] [~xiaochen]. I think the failed reason is the correct replica recovered from lazypersist was replaced by incorrect replica read from cache when restart datanode. The comparative analysis  the successful and the failed test logs  as follows:\r\n{quote}success:\r\n 15:05:43,550 INFO BlockPoolSlice - Successfully read replica from cache file : /tmp/run_tha_testU50PcZ/target/test/data/dfs/data/data1/current/BP-1756767659-172.17.0.1-1517497537101/current/replicas\r\n 15:05:43,568 INFO FsDatasetImpl - Recovered 1 replicas from /tmp/run_tha_testU50PcZ/target/test/data/dfs/data/data2/current/BP-1756767659-172.17.0.1-1517497537101/current/lazypersist\r\n{quote}\r\n{quote}failed:\r\n 15:07:17,309 INFO FsDatasetImpl - Recovered 1 replicas from /tmp/run_tha_testvb5u64/target/test/data/dfs/data/data2/current/BP-381858266-172.17.0.1-1517497631100/current/lazypersist\r\n 15:07:17,310 INFO FsDatasetImpl - Time to add replicas to map for block pool BP-381858266-172.17.0.1-1517497631100 on volume /tmp/run_tha_testvb5u64/target/test/data/dfs/data/data2: 2ms\r\n 15:07:17,311 INFO BlockPoolSlice - Successfully read replica from cache file : /tmp/run_tha_testvb5u64/target/test/data/dfs/data/data1/current/BP-381858266-172.17.0.1-1517497631100/current/replicas\r\n{quote}\r\nFrom above test logs we can find that the read replica from cache file execute in the front of recover replaca from lazypersist when success, but the execute sequence is in opposite when failed.The reason lead to this issue is block pool getAllVolumesMap() async by dispatch thread per volume when datanode restart, and the thread process speed may different in every time, so cannot guarantee which vloume finish first.\r\n\r\nAt last I have a question about What is the effect of cache file? And I think the transient Storage not need to write replica to cache file when shutdown volume.\r\n Thinks!","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=liaoyuxiangqin","name":"liaoyuxiangqin","key":"liaoyuxiangqin","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"liaoyuxiangqin","active":true,"timeZone":"Etc/UTC"},"created":"2018-03-26T09:02:10.057+0000","updated":"2018-03-27T02:50:53.222+0000"}],"maxResults":6,"total":6,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-13179/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i3qhv3:"}}