{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12945635","self":"https://issues.apache.org/jira/rest/api/2/issue/12945635","key":"HDFS-9874","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12329057","id":"12329057","description":"2.8.0 release","name":"2.8.0","archived":false,"released":true,"releaseDate":"2017-03-22"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12333995","id":"12333995","description":"2.7.3 release","name":"2.7.3","archived":false,"released":true,"releaseDate":"2016-08-25"},{"self":"https://issues.apache.org/jira/rest/api/2/version/12335732","id":"12335732","description":"3.0.0-alpha1 release","name":"3.0.0-alpha1","archived":false,"released":true,"releaseDate":"2016-09-03"}],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2016-03-03T19:19:59.171+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Thu Aug 25 23:00:25 UTC 2016","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":"1_*:*_3_*:*_239406079_*|*_5_*:*_1_*:*_0_*|*_10002_*:*_3_*:*_1292162215","customfield_12312321":null,"resolutiondate":"2016-03-18T15:41:35.513+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-9874/watchers","watchCount":16,"isWatching":false},"created":"2016-02-29T22:15:27.291+0000","customfield_12310192":null,"customfield_12310191":[{"self":"https://issues.apache.org/jira/rest/api/2/customFieldOption/10343","value":"Reviewed","id":"10343"}],"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/2","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/critical.svg","name":"Critical","id":"2"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"3.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12327584","id":"12327584","description":"2.7.0 release","name":"2.7.0","archived":false,"released":true,"releaseDate":"2015-04-20"}],"issuelinks":[{"id":"12474390","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12474390","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"inwardIssue":{"id":"12988219","key":"HDFS-10605","self":"https://issues.apache.org/jira/rest/api/2/issue/12988219","fields":{"summary":"Can not synchronized call method of object and Mockito.spy(object), So UT:testRemoveVolumeBeingWritten passed but maybe deadlock online","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/10002","description":"A patch for this issue has been uploaded to JIRA by a contributor.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/document.png","name":"Patch Available","id":"10002","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/4","id":4,"key":"indeterminate","colorName":"yellow","name":"In Progress"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/4","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/minor.svg","name":"Minor","id":"4"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12462806","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12462806","type":{"id":"12310050","name":"Regression","inward":"is broken by","outward":"breaks","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/12310050"},"inwardIssue":{"id":"12956174","key":"HDFS-10260","self":"https://issues.apache.org/jira/rest/api/2/issue/12956174","fields":{"summary":"TestFsDatasetImpl#testCleanShutdownOfVolume often fails","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shahrs87","name":"shahrs87","key":"shahrs87","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rushabh S Shah","active":true,"timeZone":"Etc/UTC"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2016-12-01T23:20:39.834+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12312927","id":"12312927","name":"datanode"}],"timeoriginalestimate":null,"description":"One of the failed volume shutdown took 3 days to complete.\nBelow are the relevant datanode logs while shutting down a volume (due to disk failure)\n\n{noformat}\n2016-02-21 10:12:55,333 [Thread-49277] WARN impl.FsDatasetImpl: Removing failed volume volumeA/current: \norg.apache.hadoop.util.DiskChecker$DiskErrorException: Directory is not writable: volumeA/current/BP-1788428031-nnIp-1351700107344/current/finalized\n        at org.apache.hadoop.util.DiskChecker.checkAccessByFileMethods(DiskChecker.java:194)\n        at org.apache.hadoop.util.DiskChecker.checkDirAccess(DiskChecker.java:174)\n        at org.apache.hadoop.util.DiskChecker.checkDir(DiskChecker.java:108)\n        at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice.checkDirs(BlockPoolSlice.java:308)\n        at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImpl.checkDirs(FsVolumeImpl.java:786)\n        at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeList.checkDirs(FsVolumeList.java:242)\n        at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.checkDataDir(FsDatasetImpl.java:2011)\n        at org.apache.hadoop.hdfs.server.datanode.DataNode.checkDiskError(DataNode.java:3145)\n        at org.apache.hadoop.hdfs.server.datanode.DataNode.access$800(DataNode.java:243)\n        at org.apache.hadoop.hdfs.server.datanode.DataNode$7.run(DataNode.java:3178)\n        at java.lang.Thread.run(Thread.java:745)\n2016-02-21 10:12:55,334 [Thread-49277] INFO datanode.BlockScanner: Removing scanner for volume volumeA (StorageID DS-cd2ea223-bab3-4361-a567-5f3f27a5dd23)\n2016-02-21 10:12:55,334 [VolumeScannerThread(volumeA)] INFO datanode.VolumeScanner: VolumeScanner(volumeA, DS-cd2ea223-bab3-4361-a567-5f3f27a5dd23) exiting.\n2016-02-21 10:12:55,335 [VolumeScannerThread(volumeA)] WARN datanode.VolumeScanner: VolumeScanner(volumeA, DS-cd2ea223-bab3-4361-a567-5f3f27a5dd23): error saving org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImpl$BlockIteratorImpl@4169ad8b.\njava.io.FileNotFoundException: volumeA/current/BP-1788428031-nnIp-1351700107344/scanner.cursor.tmp (Read-only file system)\n        at java.io.FileOutputStream.open(Native Method)\n        at java.io.FileOutputStream.<init>(FileOutputStream.java:213)\n        at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImpl$BlockIteratorImpl.save(FsVolumeImpl.java:669)\n        at org.apache.hadoop.hdfs.server.datanode.VolumeScanner.saveBlockIterator(VolumeScanner.java:314)\n        at org.apache.hadoop.hdfs.server.datanode.VolumeScanner.run(VolumeScanner.java:633)\n\n2016-02-24 16:05:53,285 [Thread-49277] WARN impl.FsDatasetImpl: Failed to delete old dfsUsed file in volumeA/current/BP-1788428031-nnIp-1351700107344/current\n2016-02-24 16:05:53,286 [Thread-49277] WARN impl.FsDatasetImpl: Failed to write dfsUsed to volumeA/current/BP-1788428031-nnIp-1351700107344/current/dfsUsed\njava.io.FileNotFoundException: volumeA/current/BP-1788428031-nnIp-1351700107344/current/dfsUsed (Read-only file system)\n\t\tat java.io.FileOutputStream.open(Native Method)\n\t\tat java.io.FileOutputStream.<init>(FileOutputStream.java:213)\n\t\tat java.io.FileOutputStream.<init>(FileOutputStream.java:162)\n\t\tat org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice.saveDfsUsed(BlockPoolSlice.java:247)\n\t\tat org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice.shutdown(BlockPoolSlice.java:698)\n\t\tat org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImpl.shutdown(FsVolumeImpl.java:815)\n\t\tat org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeList.removeVolume(FsVolumeList.java:328)\n\t\tat org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeList.checkDirs(FsVolumeList.java:250)\n\t\tat org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.checkDataDir(FsDatasetImpl.java:2011)\n\t\tat org.apache.hadoop.hdfs.server.datanode.DataNode.checkDiskError(DataNode.java:3145)\n\t\tat org.apache.hadoop.hdfs.server.datanode.DataNode.access$800(DataNode.java:243)\n\t\tat org.apache.hadoop.hdfs.server.datanode.DataNode$7.run(DataNode.java:3178)\n\t\tat java.lang.Thread.run(Thread.java:745)\n\n2016-02-24 16:05:53,286 [Thread-49277] INFO impl.FsDatasetImpl: Removed volume: volumeA/current\n2016-02-24 16:05:53,286 [Thread-49277] WARN impl.FsDatasetImpl: Completed checkDirs. Found 1 failure volumes.\n2016-02-24 16:05:53,286 [Thread-49277] INFO datanode.DataNode: Deactivating volumes (clear failure=false): volumeA\n2016-02-24 16:05:53,286 [Thread-49277] INFO impl.FsDatasetImpl: Removing volumeA from FsDataset.\n2016-02-24 16:05:53,342 [Thread-49277] INFO common.Storage: Removing block level storage: volumeA/current/BP-1788428031-nnIp-1351700107344\n2016-02-24 16:05:53,345 [Thread-49277] WARN datanode.DataNode: DataNode.handleDiskError: Keep Running: true\n{noformat} \n\nThe datanode waits for the reference count to become zero before shutting down the volume.\n{code:title=FsVolumeImpl.java|borderStyle=solid}\nwhile (this.reference.getReferenceCount() > 0) {\n     if (FsDatasetImpl.LOG.isDebugEnabled()) {\n       FsDatasetImpl.LOG.debug(String.format(\n           \"The reference count for %s is %d, wait to be 0.\",\n           this, reference.getReferenceCount()));\n     }\n     try {\n       Thread.sleep(SLEEP_MILLIS);\n     } catch (InterruptedException e) {\n       throw new IOException(e);\n     }\n   }\n{code}\n\nJust before datanode logged the following line, \n{noformat} \n2016-02-24 16:05:53,285 [Thread-49277] WARN impl.FsDatasetImpl: Failed to delete old dfsUsed file in volumeA/current/BP-1788428031-nnIp-1351700107344/current\n{noformat}\nI saw the following stack trace\n{noformat}\n2016-02-24 16:05:53,017 [DataXceiver for client DFSClient_NONMAPREDUCE_1651663681_1 at /upStreamDNIp:55710 [Receiving block BP-1788428031-nnIp-1351700107344:blk_7059462432_1109832821906]] INFO datanode.DataNode: Exception for BP-1788428031-nnIp-1351700107344:blk_7059462432_1109832909736\njava.io.IOException: Premature EOF from inputStream\n        at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:201)\n        at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:213)\n        at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)\n        at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)\n        at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:501)\n        at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:895)\n        at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:801)\n        at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:137)\n        at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:74)\n        at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:253)\n        at java.lang.Thread.run(Thread.java:745)\n2016-02-24 16:05:53,018 [PacketResponder: BP-1788428031-nnIp-1351700107344:blk_7059462432_1109832909736, type=LAST_IN_PIPELINE, downstreams=0:[]] INFO datanode.DataNode: PacketResponder: BP-1788428031-nnIp-1351700107344:blk_7059462432_1109832909736, type=LAST_IN_PIPELINE, downstreams=0:[]: Thread is interrupted.\n2016-02-24 16:05:53,018 [PacketResponder: BP-1788428031-nnIp-1351700107344:blk_7059462432_1109832909736, type=LAST_IN_PIPELINE, downstreams=0:[]] INFO datanode.DataNode: PacketResponder: BP-1788428031-nnIp-1351700107344:blk_7059462432_1109832909736, type=LAST_IN_PIPELINE, downstreams=0:[] terminating\n2016-02-24 16:05:53,018 [DataXceiver for client DFSClient_NONMAPREDUCE_1651663681_1 at /upStreamDNIp:55710 [Receiving block BP-1788428031-nnIp-1351700107344:blk_7059462432_1109832821906]] INFO datanode.DataNode: opWriteBlock BP-1788428031-nnIp-1351700107344:blk_7059462432_1109832909736 received exception java.io.IOException: Prematur\ne EOF from inputStream\n2016-02-24 16:05:53,018 [DataXceiver for client DFSClient_NONMAPREDUCE_1651663681_1 at /upStreamDNIp:55710 [Receiving block BP-1788428031-nnIp-1351700107344:blk_7059462432_1109832821906]] ERROR datanode.DataNode: thisDNName:1004:DataXceiver error processing WRITE_BLOCK operation  src: /upStreamDNIp:55710 dst: /thisDNIp\n:1004\njava.io.IOException: Premature EOF from inputStream\n        at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:201)\n        at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:213)\n        at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)\n        at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)\n        at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:501)\n        at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:895)\n        at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:801)\n        at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:137)\n        at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:74)\n        at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:253)\n        at java.lang.Thread.run(Thread.java:745)\n\n{noformat}\n\n\nOn tracking the block blk_7059462432_1109832821906, I see that the block was created on 2016-02-17 15:06:28,256\n{noformat}\n2016-02-17 15:06:28,928 [DataXceiver for client DFSClient_NONMAPREDUCE_1651663681_1 at /upStreamDNIp:55590 [Receiving block BP-1788428031-nnIp-1351700107344:blk_7059462432_1109832821906]] INFO datanode.DataNode: Receiving BP-1788428031-nnIp-1351700107344:blk_7059462432_1109832821906 src: /upStreamDNIp:55590 dest: /thisDNIp:1004\n{noformat}\n\n\nThe job which created this file was running for more than 7 days and the client eventually failed to renew the delegation token so the lease manager failed to renew lease for this file.\nOnce commitBlockSynchronization kicked in, it tried to recover the block and eventually the DataXceiver thread died decrementing the reference count.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12329057","id":"12329057","description":"2.8.0 release","name":"2.8.0","archived":false,"released":true,"releaseDate":"2017-03-22"}],"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12791200","id":"12791200","filename":"HDFS-9874-trunk.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shahrs87","name":"shahrs87","key":"shahrs87","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rushabh S Shah","active":true,"timeZone":"Etc/UTC"},"created":"2016-03-03T16:37:30.513+0000","size":5785,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12791200/HDFS-9874-trunk.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12792352","id":"12792352","filename":"HDFS-9874-trunk-1.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shahrs87","name":"shahrs87","key":"shahrs87","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rushabh S Shah","active":true,"timeZone":"Etc/UTC"},"created":"2016-03-09T21:43:49.450+0000","size":7422,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12792352/HDFS-9874-trunk-1.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12792577","id":"12792577","filename":"HDFS-9874-trunk-2.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shahrs87","name":"shahrs87","key":"shahrs87","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rushabh S Shah","active":true,"timeZone":"Etc/UTC"},"created":"2016-03-10T20:20:38.931+0000","size":7432,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12792577/HDFS-9874-trunk-2.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"Long living DataXceiver threads cause volume shutdown to block.","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shahrs87","name":"shahrs87","key":"shahrs87","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rushabh S Shah","active":true,"timeZone":"Etc/UTC"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shahrs87","name":"shahrs87","key":"shahrs87","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rushabh S Shah","active":true,"timeZone":"Etc/UTC"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12945635/comment/15178073","id":"15178073","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shahrs87","name":"shahrs87","key":"shahrs87","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rushabh S Shah","active":true,"timeZone":"Etc/UTC"},"body":"This patch goes through the volume map and stops the writer thread if the replica object is an instance of ReplicaInPipeline.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shahrs87","name":"shahrs87","key":"shahrs87","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rushabh S Shah","active":true,"timeZone":"Etc/UTC"},"created":"2016-03-03T16:38:50.295+0000","updated":"2016-03-03T16:38:50.295+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12945635/comment/15178418","id":"15178418","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 11s {color} | {color:blue} Docker mode activated. {color} |\n| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green} 0m 0s {color} | {color:green} The patch appears to include 1 new or modified test files. {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 7m 35s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 0m 44s {color} | {color:green} trunk passed with JDK v1.8.0_72 {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 0m 45s {color} | {color:green} trunk passed with JDK v1.7.0_95 {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 24s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 0m 55s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 14s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 2m 11s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 13s {color} | {color:green} trunk passed with JDK v1.8.0_72 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 53s {color} | {color:green} trunk passed with JDK v1.7.0_95 {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 0m 50s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 0m 42s {color} | {color:green} the patch passed with JDK v1.8.0_72 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 0m 42s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 0m 43s {color} | {color:green} the patch passed with JDK v1.7.0_95 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 0m 43s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 20s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 0m 54s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 12s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green} 0m 0s {color} | {color:green} Patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 2m 25s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 10s {color} | {color:green} the patch passed with JDK v1.8.0_72 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 56s {color} | {color:green} the patch passed with JDK v1.7.0_95 {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 65m 57s {color} | {color:red} hadoop-hdfs in the patch failed with JDK v1.8.0_72. {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 57m 28s {color} | {color:red} hadoop-hdfs in the patch failed with JDK v1.7.0_95. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green} 0m 22s {color} | {color:green} Patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black} 151m 20s {color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| JDK v1.8.0_72 Failed junit tests | hadoop.hdfs.server.namenode.TestNamenodeCapacityReport |\n|   | hadoop.hdfs.shortcircuit.TestShortCircuitCache |\n| JDK v1.7.0_95 Failed junit tests | hadoop.hdfs.server.namenode.TestEditLog |\n|   | hadoop.hdfs.server.datanode.TestFsDatasetCache |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:0ca8df7 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12791200/HDFS-9874-trunk.patch |\n| JIRA Issue | HDFS-9874 |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux bf00281a78f7 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / 0a9f00a |\n| Default Java | 1.7.0_95 |\n| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_72 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_95 |\n| findbugs | v3.0.0 |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/14705/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.8.0_72.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/14705/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.7.0_95.txt |\n| unit test logs |  https://builds.apache.org/job/PreCommit-HDFS-Build/14705/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.8.0_72.txt https://builds.apache.org/job/PreCommit-HDFS-Build/14705/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.7.0_95.txt |\n| JDK v1.7.0_95  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/14705/testReport/ |\n| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/14705/console |\n| Powered by | Apache Yetus 0.3.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2016-03-03T19:19:59.171+0000","updated":"2016-03-03T19:19:59.171+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12945635/comment/15178578","id":"15178578","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shahrs87","name":"shahrs87","key":"shahrs87","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rushabh S Shah","active":true,"timeZone":"Etc/UTC"},"body":"I ran all the failed tests on jdk7 (jdk1.7.0_71) and jdk8 (jdk1.8.0_45).\nNone of the tests failed on my machine.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shahrs87","name":"shahrs87","key":"shahrs87","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rushabh S Shah","active":true,"timeZone":"Etc/UTC"},"created":"2016-03-03T20:40:01.193+0000","updated":"2016-03-03T20:40:01.193+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12945635/comment/15183159","id":"15183159","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=daryn","name":"daryn","key":"daryn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Daryn Sharp","active":true,"timeZone":"America/Chicago"},"body":"The synchronization on {{FSDatasetImpl#stopAllDataxceiverThreads}} is a bit concerning.  Stopping xceiver threads uses a default timeout of 1min.  That's a long time for the DN to block if threads don't exit immediately.\n\nThe iteration of replicas might not be safe.  The correct locking model isn't immediately clear but  {{ReplicaMap#replicas}} has the comment which other code doesn't appear to follow:\n{noformat}\n  /**\n   * Get a collection of the replicas for given block pool\n   * This method is <b>not synchronized</b>. It needs to be synchronized\n   * externally using the mutex, both for getting the replicas\n   * values from the map and iterating over it. Mutex can be accessed using\n   * {@link #getMutext()} method.\n{noformat}\n\nMight need to consider forcibly decrementing the ref and interrupting with no timeout.\n\nFor the test, I'd assert the volume actually has a non-zero ref count before trying to interrupt.  Instead of triggering an async check and sleeping, which inevitable creates flaky race conditions, the disk check should be invoked non-async.  Should verify that the client stream fails after the volume is failed.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=daryn","name":"daryn","key":"daryn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Daryn Sharp","active":true,"timeZone":"America/Chicago"},"created":"2016-03-07T15:49:51.595+0000","updated":"2016-03-07T15:49:51.595+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12945635/comment/15188099","id":"15188099","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shahrs87","name":"shahrs87","key":"shahrs87","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rushabh S Shah","active":true,"timeZone":"Etc/UTC"},"body":"Cancelling the patch to address Daryn's comment.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shahrs87","name":"shahrs87","key":"shahrs87","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rushabh S Shah","active":true,"timeZone":"Etc/UTC"},"created":"2016-03-09T21:42:40.826+0000","updated":"2016-03-09T21:42:40.826+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12945635/comment/15188111","id":"15188111","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shahrs87","name":"shahrs87","key":"shahrs87","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rushabh S Shah","active":true,"timeZone":"Etc/UTC"},"body":"Thanks Daryn for the valuable comments.\n{quote}\nThe synchronization on FSDatasetImpl#stopAllDataxceiverThreads is a bit concerning. Stopping xceiver threads uses a default timeout of 1min. That's a long time for the DN to block if threads don't exit immediately.\n{quote}\nAddressed the issue by interrupting the BlockReceiver thread.\n\n{quote}\nThe iteration of replicas might not be safe. The correct locking model isn't immediately clear but ReplicaMap#replicas has the comment which other code doesn't appear to follow:\n{quote}\nSince all the calls to ReplicaMap#replicas are synchronized on FsDatasetImpl class, I did the same way.\n\n{quote}\nFor the test, I'd assert the volume actually has a non-zero ref count before trying to interrupt. Instead of triggering an async check and sleeping, which inevitable creates flaky race conditions, the disk check should be invoked non-async. Should verify that the client stream fails after the volume is failed.\n{quote}\nThat's a good suggestion to write good test cases. Thanks a lot.\nAddressed all the comments in this section.\nPlease review the revised patch.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shahrs87","name":"shahrs87","key":"shahrs87","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rushabh S Shah","active":true,"timeZone":"Etc/UTC"},"created":"2016-03-09T21:48:10.073+0000","updated":"2016-03-09T21:48:10.073+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12945635/comment/15188508","id":"15188508","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 12s {color} | {color:blue} Docker mode activated. {color} |\n| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green} 0m 0s {color} | {color:green} The patch appears to include 1 new or modified test files. {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 9m 35s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 0m 52s {color} | {color:green} trunk passed with JDK v1.8.0_74 {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 0m 41s {color} | {color:green} trunk passed with JDK v1.7.0_95 {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 21s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 0m 54s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 13s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 2m 2s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 26s {color} | {color:green} trunk passed with JDK v1.8.0_74 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 2m 13s {color} | {color:green} trunk passed with JDK v1.7.0_95 {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 0m 56s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 0m 57s {color} | {color:green} the patch passed with JDK v1.8.0_74 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 0m 57s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 1m 5s {color} | {color:green} the patch passed with JDK v1.7.0_95 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 1m 5s {color} | {color:green} the patch passed {color} |\n| {color:red}-1{color} | {color:red} checkstyle {color} | {color:red} 0m 30s {color} | {color:red} hadoop-hdfs-project/hadoop-hdfs: patch generated 1 new + 145 unchanged - 0 fixed = 146 total (was 145) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 21s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 19s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green} 0m 0s {color} | {color:green} Patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 3m 12s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 31s {color} | {color:green} the patch passed with JDK v1.8.0_74 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 2m 25s {color} | {color:green} the patch passed with JDK v1.7.0_95 {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 75m 15s {color} | {color:red} hadoop-hdfs in the patch failed with JDK v1.8.0_74. {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 70m 24s {color} | {color:red} hadoop-hdfs in the patch failed with JDK v1.7.0_95. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green} 0m 26s {color} | {color:green} Patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black} 180m 17s {color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| JDK v1.8.0_74 Failed junit tests | hadoop.hdfs.server.datanode.TestTriggerBlockReport |\n|   | hadoop.hdfs.server.namenode.TestEditLog |\n|   | hadoop.hdfs.TestFileAppend |\n|   | hadoop.hdfs.server.namenode.ha.TestDFSUpgradeWithHA |\n|   | hadoop.hdfs.server.namenode.TestNamenodeCapacityReport |\n| JDK v1.7.0_95 Failed junit tests | hadoop.hdfs.server.namenode.TestEditLog |\n|   | hadoop.hdfs.TestDFSUpgradeFromImage |\n|   | hadoop.metrics2.sink.TestRollingFileSystemSinkWithSecureHdfs |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:0ca8df7 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12792352/HDFS-9874-trunk-1.patch |\n| JIRA Issue | HDFS-9874 |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux ee85e8c1fa27 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / 2e040d3 |\n| Default Java | 1.7.0_95 |\n| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_74 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_95 |\n| findbugs | v3.0.0 |\n| checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/14764/artifact/patchprocess/diff-checkstyle-hadoop-hdfs-project_hadoop-hdfs.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/14764/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.8.0_74.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/14764/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.7.0_95.txt |\n| unit test logs |  https://builds.apache.org/job/PreCommit-HDFS-Build/14764/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.8.0_74.txt https://builds.apache.org/job/PreCommit-HDFS-Build/14764/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.7.0_95.txt |\n| JDK v1.7.0_95  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/14764/testReport/ |\n| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/14764/console |\n| Powered by | Apache Yetus 0.2.0   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2016-03-10T02:08:15.854+0000","updated":"2016-03-10T02:08:15.854+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12945635/comment/15189877","id":"15189877","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shahrs87","name":"shahrs87","key":"shahrs87","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rushabh S Shah","active":true,"timeZone":"Etc/UTC"},"body":"Cancelling the patch to address checkstyle warning.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shahrs87","name":"shahrs87","key":"shahrs87","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rushabh S Shah","active":true,"timeZone":"Etc/UTC"},"created":"2016-03-10T20:20:02.375+0000","updated":"2016-03-10T20:20:02.375+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12945635/comment/15189882","id":"15189882","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shahrs87","name":"shahrs87","key":"shahrs87","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rushabh S Shah","active":true,"timeZone":"Etc/UTC"},"body":"Fixed checkstyle warning.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shahrs87","name":"shahrs87","key":"shahrs87","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rushabh S Shah","active":true,"timeZone":"Etc/UTC"},"created":"2016-03-10T20:20:38.935+0000","updated":"2016-03-10T20:20:38.935+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12945635/comment/15189884","id":"15189884","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shahrs87","name":"shahrs87","key":"shahrs87","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rushabh S Shah","active":true,"timeZone":"Etc/UTC"},"body":"Ran all the failed tests on both jdk7 and jdk8.\nAll of them passed.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shahrs87","name":"shahrs87","key":"shahrs87","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rushabh S Shah","active":true,"timeZone":"Etc/UTC"},"created":"2016-03-10T20:21:16.199+0000","updated":"2016-03-10T20:21:16.199+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12945635/comment/15190243","id":"15190243","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 10s {color} | {color:blue} Docker mode activated. {color} |\n| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green} 0m 0s {color} | {color:green} The patch appears to include 1 new or modified test files. {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 6m 33s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 0m 40s {color} | {color:green} trunk passed with JDK v1.8.0_74 {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 0m 41s {color} | {color:green} trunk passed with JDK v1.7.0_95 {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 22s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 0m 51s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 13s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 1m 54s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 6s {color} | {color:green} trunk passed with JDK v1.8.0_74 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 46s {color} | {color:green} trunk passed with JDK v1.7.0_95 {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 0m 47s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 0m 36s {color} | {color:green} the patch passed with JDK v1.8.0_74 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 0m 36s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 0m 38s {color} | {color:green} the patch passed with JDK v1.7.0_95 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 0m 38s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 20s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 0m 48s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 11s {color} | {color:green} the patch passed {color} |\n| {color:red}-1{color} | {color:red} whitespace {color} | {color:red} 0m 0s {color} | {color:red} The patch has 1 line(s) that end in whitespace. Use git apply --whitespace=fix. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 2m 10s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 5s {color} | {color:green} the patch passed with JDK v1.8.0_74 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 44s {color} | {color:green} the patch passed with JDK v1.7.0_95 {color} |\n| {color:green}+1{color} | {color:green} unit {color} | {color:green} 54m 40s {color} | {color:green} hadoop-hdfs in the patch passed with JDK v1.8.0_74. {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 53m 23s {color} | {color:red} hadoop-hdfs in the patch failed with JDK v1.7.0_95. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green} 0m 20s {color} | {color:green} Patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black} 133m 4s {color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| JDK v1.7.0_95 Failed junit tests | hadoop.hdfs.TestHFlush |\n|   | hadoop.hdfs.server.namenode.ha.TestDFSUpgradeWithHA |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:0ca8df7 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12792577/HDFS-9874-trunk-2.patch |\n| JIRA Issue | HDFS-9874 |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux 761ed470b5bb 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / 79961ec |\n| Default Java | 1.7.0_95 |\n| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_74 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_95 |\n| findbugs | v3.0.0 |\n| whitespace | https://builds.apache.org/job/PreCommit-HDFS-Build/14783/artifact/patchprocess/whitespace-eol.txt |\n| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/14783/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.7.0_95.txt |\n| unit test logs |  https://builds.apache.org/job/PreCommit-HDFS-Build/14783/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.7.0_95.txt |\n| JDK v1.7.0_95  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/14783/testReport/ |\n| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/14783/console |\n| Powered by | Apache Yetus 0.2.0   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2016-03-11T00:42:43.375+0000","updated":"2016-03-11T00:42:43.375+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12945635/comment/15201604","id":"15201604","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"body":"This patch will kick out writers even for \"graceful\" removals. But when a drive is remove, we probably don't want long-living writers to block the maintenance.  So I think it is still acceptable.\n+1 the patch looks good.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"created":"2016-03-18T15:12:19.984+0000","updated":"2016-03-18T15:12:19.984+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12945635/comment/15201656","id":"15201656","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"body":"Committed to trunk through branch-2.7. Thanks for analyzing and fixing the issue, [~shahrs87].","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kihwal","name":"kihwal","key":"kihwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=kihwal&avatarId=34594","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kihwal&avatarId=34594","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kihwal&avatarId=34594","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kihwal&avatarId=34594"},"displayName":"Kihwal Lee","active":true,"timeZone":"America/Chicago"},"created":"2016-03-18T15:41:35.545+0000","updated":"2016-03-18T15:41:35.545+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12945635/comment/15201875","id":"15201875","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"FAILURE: Integrated in Hadoop-trunk-Commit #9474 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/9474/])\nHDFS-9874. Long living DataXceiver threads cause volume shutdown to (kihwal: rev 63c966a3fbeb675959fc4101e65de9f57aecd17d)\n* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/TestFsDatasetImpl.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsVolumeImpl.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java\n* hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/ReplicaInPipeline.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2016-03-18T17:59:47.120+0000","updated":"2016-03-18T17:59:47.120+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12945635/comment/15201923","id":"15201923","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shahrs87","name":"shahrs87","key":"shahrs87","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rushabh S Shah","active":true,"timeZone":"Etc/UTC"},"body":"Thanks [~kihwal] for reviews and committing and [~daryn] for excellent reviews.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shahrs87","name":"shahrs87","key":"shahrs87","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rushabh S Shah","active":true,"timeZone":"Etc/UTC"},"created":"2016-03-18T18:24:58.680+0000","updated":"2016-03-18T18:24:58.680+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12945635/comment/15204980","id":"15204980","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"body":"It seems this patch is buggy.\n\nIn a precommit job, this test threw NPE:\nhttps://builds.apache.org/job/PreCommit-HDFS-Build/14881/testReport/org.apache.hadoop.hdfs.server.datanode.fsdataset.impl/TestFsDatasetImpl/testCleanShutdownOfVolume/\n\nException in thread \"DataNode: [[[DISK]file:/testptch/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/3/dfs/data/data1/, [DISK]file:/testptch/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/3/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:39740\" java.lang.NullPointerException\n\tat org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockReports(FsDatasetImpl.java:1714)\n\tat org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.shutdownBlockPool(FsDatasetImpl.java:2591)\n\tat org.apache.hadoop.hdfs.server.datanode.DataNode.shutdownBlockPool(DataNode.java:1479)\n\tat org.apache.hadoop.hdfs.server.datanode.BPOfferService.shutdownActor(BPOfferService.java:411)\n\tat org.apache.hadoop.hdfs.server.datanode.BPServiceActor.cleanUp(BPServiceActor.java:494)\n\tat org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:749)\n\tat java.lang.Thread.run(Thread.java:745)\n\nAnd the precommit record shows it has been failing continuously for 3 times.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-03-21T19:56:24.454+0000","updated":"2016-03-21T19:56:24.454+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12945635/comment/15204987","id":"15204987","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shahrs87","name":"shahrs87","key":"shahrs87","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rushabh S Shah","active":true,"timeZone":"Etc/UTC"},"body":"[~jojochuang]: Thanks for reporting. Taking a look now.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shahrs87","name":"shahrs87","key":"shahrs87","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rushabh S Shah","active":true,"timeZone":"Etc/UTC"},"created":"2016-03-21T19:59:19.787+0000","updated":"2016-03-21T19:59:19.787+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12945635/comment/15205092","id":"15205092","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shahrs87","name":"shahrs87","key":"shahrs87","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rushabh S Shah","active":true,"timeZone":"Etc/UTC"},"body":"The NPE is expected.\n{quote}\n at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockReports(FsDatasetImpl.java:1714)\nat org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.shutdownBlockPool(FsDatasetImpl.java:2591)\nat org.apache.hadoop.hdfs.server.datanode.DataNode.shutdownBlockPool(DataNode.java:1479)\nat org.apache.hadoop.hdfs.server.datanode.BPOfferService.shutdownActor(BPOfferService.java:411)\n{quote}\nThis is getting called while shutting down the cluster.\nThis is expected since I have triggered only a part of checkDiskError thread.\n\n{code:title=DataNode.java|borderStyle=solid}\n private void checkDiskError() {\n    Set<File> unhealthyDataDirs = data.checkDataDir();\n    if (unhealthyDataDirs != null && !unhealthyDataDirs.isEmpty()) {\n      try {\n        // Remove all unhealthy volumes from DataNode.\n        removeVolumes(unhealthyDataDirs, false);\n      } catch (IOException e) { \n        LOG.warn(\"Error occurred when removing unhealthy storage dirs: \"\n            + e.getMessage(), e);\n      }    \n      StringBuilder sb = new StringBuilder(\"DataNode failed volumes:\");\n      for (File dataDir : unhealthyDataDirs) {\n        sb.append(dataDir.getAbsolutePath() + \";\");\n      }    \n      handleDiskError(sb.toString());\n    }    \n  }\n{code}\n\nI have only called the first line of the above function in the test case since I don't want the test case to wait for DataNode#checkDiskErrorInterval (which is 5 secs if defualt).\nThat's why it will not execute  removeVolumes(unhealthyDataDirs, false)\nTherefore the NPE.\n\nI am not able to reproduce the test case failing on my local machine on jdk 7 and jdk8.\n[~jojochuang]: Does it fail on your machine ?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shahrs87","name":"shahrs87","key":"shahrs87","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rushabh S Shah","active":true,"timeZone":"Etc/UTC"},"created":"2016-03-21T20:46:01.963+0000","updated":"2016-03-21T20:46:01.963+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12945635/comment/15205137","id":"15205137","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks for looking into it. Maybe the NPE is unrelated.\nI'm not able to fail the test, it could be an intermittent flaky test.\nBut in anyway, it would be great if you could improve the test diagnostics using {{GenericTestUtils#assertExceptionContains}}. This utility method prints the stack trace if the exception message doesn't match the expected value.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-03-21T21:04:51.193+0000","updated":"2016-03-21T21:04:51.193+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12945635/comment/15205591","id":"15205591","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shahrs87","name":"shahrs87","key":"shahrs87","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rushabh S Shah","active":true,"timeZone":"Etc/UTC"},"body":"Sure. Will update the patch shortly.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=shahrs87","name":"shahrs87","key":"shahrs87","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rushabh S Shah","active":true,"timeZone":"Etc/UTC"},"created":"2016-03-22T01:34:46.993+0000","updated":"2016-03-22T01:34:46.993+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12945635/comment/15438012","id":"15438012","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinodkv","name":"vinodkv","key":"vinodkv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinod Kumar Vavilapalli","active":true,"timeZone":"America/Los_Angeles"},"body":"Closing the JIRA as part of 2.7.3 release.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinodkv","name":"vinodkv","key":"vinodkv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinod Kumar Vavilapalli","active":true,"timeZone":"America/Los_Angeles"},"created":"2016-08-25T23:00:25.595+0000","updated":"2016-08-25T23:00:25.595+0000"}],"maxResults":21,"total":21,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-9874/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i2txxj:"}}