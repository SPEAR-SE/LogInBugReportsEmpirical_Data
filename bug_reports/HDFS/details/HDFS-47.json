{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12389638","self":"https://issues.apache.org/jira/rest/api/2/issue/12389638","key":"HDFS-47","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/8","id":"8","description":"The described issue is not actually a problem - it is as designed.","name":"Not A Problem"},"customfield_12312322":null,"customfield_12310220":"2008-02-27T01:51:22.674+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Thu Dec 29 14:55:31 UTC 2011","customfield_12310420":"16879","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_121095321867_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2011-12-29T14:55:31.528+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-47/watchers","watchCount":5,"isWatching":false},"created":"2008-02-27T01:20:09.730+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[],"issuelinks":[],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2011-12-29T14:55:31.592+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[],"timeoriginalestimate":null,"description":"We see more dead datanodes than in previous releases. The common exception is found in the out file:\n\nException in thread \"org.apache.hadoop.dfs.DataBlockScanner@18166e5\" java.lang.OutOfMemoryError: Java heap space\nException in thread \"DataNode: [dfs.data.dir-value]\" java.lang.OutOfMemoryError: Java heap space\n\n","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"107820","customfield_12312823":null,"summary":"dead datanodes because of OutOfMemoryError","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ckunz","name":"ckunz","key":"ckunz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Christian Kunz","active":true,"timeZone":"Etc/UTC"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ckunz","name":"ckunz","key":"ckunz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Christian Kunz","active":true,"timeZone":"Etc/UTC"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12389638/comment/12572757","id":"12572757","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"body":"One easy improvement: The class of DataNode.childSockets should be Set, instead Map.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=szetszwo","name":"szetszwo","key":"szetszwo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=szetszwo&avatarId=23156","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=szetszwo&avatarId=23156","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=szetszwo&avatarId=23156","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=szetszwo&avatarId=23156"},"displayName":"Tsz Wo Nicholas Sze","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-02-27T01:51:22.674+0000","updated":"2008-02-27T04:23:56.773+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12389638/comment/12572765","id":"12572765","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ckunz","name":"ckunz","key":"ckunz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Christian Kunz","active":true,"timeZone":"Etc/UTC"},"body":"I found a couple of datanodes with a different exception (still OutOfMemoryError):\n\nin the out file:\nException in thread \"org.apache.hadoop.dfs.DataNode$DataXceiver@9d54d\" java.lang.OutOfMemoryError: Java heap space\n\nin the log file:\n2008-02-26 23:01:12,810 ERROR org.apache.hadoop.dfs.DataNode: xxx.xxx.xxx.101:50010:DataXceiver: java.lang.OutOfMemoryError: Java heap space\n        at java.io.BufferedInputStream.<init>(BufferedInputStream.java:178)\n        at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:919)\n        at java.lang.Thread.run(Thread.java:619)\nor\n\n2008-02-27 01:30:20,703 ERROR org.apache.hadoop.dfs.DataNode: xxx.xxx.xxx.136:50010:DataXceiver: java.lang.OutOfMemoryError: Java heap space\n        at java.io.BufferedInputStream.<init>(BufferedInputStream.java:178)\n        at org.apache.hadoop.dfs.DataNode$BlockSender.<init>(DataNode.java:1521)\n        at org.apache.hadoop.dfs.DataNode$DataXceiver.readBlock(DataNode.java:992)\n        at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:930)\n        at java.lang.Thread.run(Thread.java:619)\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ckunz","name":"ckunz","key":"ckunz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Christian Kunz","active":true,"timeZone":"Etc/UTC"},"created":"2008-02-27T03:22:52.722+0000","updated":"2008-02-27T03:22:52.722+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12389638/comment/12572790","id":"12572790","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"body":"Edit : typos\n\nI looked at one of these dead datanodes. OutOfMemoryErros seems to be an independent problem.  These errors (there are multiple of them) are in .out file without timestamps. On this node, .out was modified at 01:39 and log file shows DataNode seems to have functioned normally for some more time. \n\nThe datanode seems to stuck because one of its threads is stuck forever waiting for 'df' to return while holding a central lock (FSDataset). And there is a zombied df process on the machine. The offending stacktrace : \n\n{noformat}\n\n\"org.apache.hadoop.dfs.DataNode$DataXceiver@dc08c3\" daemon prio=10 tid=0xae45e800 nid=0x2f3d in Object.wait() [0x8cafe000..0x8caff030]\n   java.lang.Thread.State: WAITING (on object monitor)\n        at java.lang.Object.wait(Native Method)\n        - waiting on <0xed78c5f8> (a java.lang.UNIXProcess$Gate)\n        at java.lang.Object.wait(Object.java:485)\n        at java.lang.UNIXProcess$Gate.waitForExit(UNIXProcess.java:64)\n        - locked <0xed78c5f8> (a java.lang.UNIXProcess$Gate)\n        at java.lang.UNIXProcess.<init>(UNIXProcess.java:145)\n        at java.lang.ProcessImpl.start(ProcessImpl.java:65)\n        at java.lang.ProcessBuilder.start(ProcessBuilder.java:452)\n        at org.apache.hadoop.util.Shell.runCommand(Shell.java:115)\n        at org.apache.hadoop.util.Shell.run(Shell.java:100)\n        at org.apache.hadoop.fs.DF.getCapacity(DF.java:63)\n        at org.apache.hadoop.dfs.FSDataset$FSVolume.getCapacity(FSDataset.java:307)\n        at org.apache.hadoop.dfs.FSDataset$FSVolume.getAvailable(FSDataset.java:311)\n        at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:393)\n        - locked <0xb6551838> (a org.apache.hadoop.dfs.FSDataset$FSVolumeSet)\n        at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:657)\n        - locked <0xb6551838> (a org.apache.hadoop.dfs.FSDataset$FSVolumeSet)\n        - locked <0xb653aec8> (a org.apache.hadoop.dfs.FSDataset)\n        at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:1983)\n        at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1074)\n        at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:938)\n        at java.lang.Thread.run(Thread.java:619)\n{noformat}\n\nWe also need to find why there are mutlipel OutOfMemoryError. My guess is that some of the normally functioning datanodes will have these as well.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-02-27T04:57:28.763+0000","updated":"2008-02-27T04:59:16.057+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12389638/comment/12572810","id":"12572810","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"body":"The ProcessBuilder getting stuck is also mostly caused by DataNode running out of memory, because both the datanodes have \"Exception in thread \"process reaper\" java.lang.OutOfMemoryError: Java heap space\".  \"process reaper\" looks like a thread in Java Process implementation. So I guess running out memory is the main issue.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-02-27T07:16:39.761+0000","updated":"2008-02-27T07:16:39.761+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12389638/comment/12573023","id":"12573023","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"body":"Koji and I looked at one of the datanodes. Attached jmap-histo.txt is the output of 'jmap -histo'. The top entry takes pretty much all the memory :\n\n{noformat}\nnum   #instances    #bytes  class name\n--------------------------------------\n  1:     25039   918792056  [B\n  2:     38666     4910272  [C\n  3:     23620     2674272  <constMethodKlass>\n  4:     23620     1893912  <methodKlass>\n  5:     38347     1549664  <symbolKlass>\n{noformat}\n\nDoes \"[B\" refer to byte arrays? Any ideas about how get anymore info out of this process are welcome.\n\nEDIT : Please ignore this one, I guess we need to run 'jmap -histo:live\", which shows much more sober picture.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-02-27T19:00:04.014+0000","updated":"2008-02-27T19:09:01.809+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12389638/comment/12573389","id":"12573389","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"body":"Recall that running out of file handles can also throw OutOfMemoryError, as well as a few other conditions.  How much memory is the process actually using?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-02-28T18:17:35.873+0000","updated":"2008-02-28T18:17:35.873+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12389638/comment/12573397","id":"12573397","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"body":"DataNode is allowed 1000MB (-Xmx). Top shows virtual memory of around 1.2-1.3 GB resident is around 50-150MB. I am thinking of running a temporary patch that prints some stats when any thread catches OutOfMemoryException, and probably block so that we can inspect the process further.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-02-28T18:44:08.420+0000","updated":"2008-02-28T18:44:08.420+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12389638/comment/12573496","id":"12573496","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"body":"Christian,\n\nWhat is the read and write pattern like? How fast do clients read? For e.g. on one of the normal datanodes, there are around 500 connections to DataNode and it is pretty much idle. These connections need around 200MB active memory. So another DataNode only needs a few times more connections to run out of memory.\n\nEdit: Most of these are writing new blocks.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-02-28T22:35:02.418+0000","updated":"2008-02-28T23:19:30.304+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12389638/comment/12573510","id":"12573510","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"body":"Regd buffers, for readers, HADOOP-2578 will remove one out of 3 BUFFER_SIZE buffer. We should file another jira to use a smaller buffer size for crc file. Then we will have only one large buffer per reader. Similarly while writing data.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-02-28T23:14:11.926+0000","updated":"2008-02-28T23:14:11.926+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12389638/comment/12573523","id":"12573523","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ckunz","name":"ckunz","key":"ckunz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Christian Kunz","active":true,"timeZone":"Etc/UTC"},"body":"Every map application streams through about 40-60 DFS files and writes directly to 2 DFS files (besides sending data to map-reduce framework). None of the maps accesses the same data.\n\nEvery reduce application writes to about 70 DFS files.\n\nKeep in mind, that the datanodes ran out of memory already during the map phase.\n\nThis access pattern did not change for a while now. But we started to see datanodes running out of memory with about nightly build #810.\n\nI am surprised about the high number of connections. Are some of them stale?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ckunz","name":"ckunz","key":"ckunz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Christian Kunz","active":true,"timeZone":"Etc/UTC"},"created":"2008-02-28T23:56:58.808+0000","updated":"2008-02-28T23:56:58.808+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12389638/comment/12573526","id":"12573526","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ckunz","name":"ckunz","key":"ckunz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Christian Kunz","active":true,"timeZone":"Etc/UTC"},"body":"Concerning read speed of map applications, a back-on-the-envelope calculation comes up with an estimate of 0.5-1 MB/s per map application.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ckunz","name":"ckunz","key":"ckunz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Christian Kunz","active":true,"timeZone":"Etc/UTC"},"created":"2008-02-29T00:13:56.204+0000","updated":"2008-02-29T00:13:56.204+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12389638/comment/12573530","id":"12573530","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ckunz","name":"ckunz","key":"ckunz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Christian Kunz","active":true,"timeZone":"Etc/UTC"},"body":"Raghu, do you think that the relatively slow reading speed per block poses a problem to the datanodes?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ckunz","name":"ckunz","key":"ckunz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Christian Kunz","active":true,"timeZone":"Etc/UTC"},"created":"2008-02-29T00:26:55.160+0000","updated":"2008-02-29T00:26:55.160+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12389638/comment/12573541","id":"12573541","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"body":"\nSlow reads are same problem as before. It hasn't changed in terms of buffering.\n\nBut slow writes have bigger penalty in terms of buffer space used. Before 16, it didn't matter how slow client wrote, DFSClient cached full block on its local disk and streamed the whole block quickly to DataNode. In 16, client has connections open pretty much as long as the output stream is open. For each client connection, 2 datanodes have 4 buffers and the last datanode has 3 buffers. Each of these buffers is of the size io.file.buffer.size. This might explain why you are seeing more OutOfMemory errors now.\n\nWe still need to find out about number of connections open. We could expect some of the datanodes to have multiple times the average load. \n\nMost of the time, these errors are caught by DataNode data transfer threads, we could print all the stack traces or some equally useful info once every few minutes of these exceptions to log. The stacktrace shows how many reads and writes are going on. Let me know if I should prepare patch.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-02-29T01:05:25.586+0000","updated":"2008-02-29T01:05:25.586+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12389638/comment/12573548","id":"12573548","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ckunz","name":"ckunz","key":"ckunz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Christian Kunz","active":true,"timeZone":"Etc/UTC"},"body":"I am not completely convinced that the change in writing explains the problem, because:\n\n1) since the time the reduce phase of the job started, we did not get any more dead datanodes (but they happened more frequently during the map phase)\n2) we saw dead datanodes with nightly build #810 (my impression is that that release still wrote to local disk)\n\nBut I would be happy to restart a couple of datanodes with a new patch.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ckunz","name":"ckunz","key":"ckunz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Christian Kunz","active":true,"timeZone":"Etc/UTC"},"created":"2008-02-29T01:24:16.115+0000","updated":"2008-02-29T01:29:54.255+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12389638/comment/12573551","id":"12573551","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"body":"> (my impression is that that release still wrote to local disk)\n0.16. does not write to local disk. Local Disk write was remove quite some time back. But it had removed some buffers on  DataNode. HADOOP-2768 went into svn revision 618349 and you are running 618351. \nEdit: HADOOP-2768 brought buffering back to how it was before the local disk was removed. But this buffer has bigger penalty for slow writes.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-02-29T01:33:35.866+0000","updated":"2008-02-29T01:38:18.451+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12389638/comment/12573555","id":"12573555","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ckunz","name":"ckunz","key":"ckunz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Christian Kunz","active":true,"timeZone":"Etc/UTC"},"body":"#810 release was a trunk release from Jan 4, running on a different cluster. Because we did not experience HADOOP-2883 with that release, I assumed that it did not write directly to DFS. Am I wrong?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ckunz","name":"ckunz","key":"ckunz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Christian Kunz","active":true,"timeZone":"Etc/UTC"},"created":"2008-02-29T01:52:53.086+0000","updated":"2008-02-29T01:52:53.086+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12389638/comment/12573556","id":"12573556","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"body":"\nWhat % of datanodes do you think logged OutOfMemory exception even once? If avg load at any time was able to cause this problem then we would see a large portion of datanodes to have this exception in their logs. I grepped on a few random datanodes and I could not seen any in last few days. Simon shows number of active reads and writes. We could check datanodes that have high numbers there.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-02-29T01:54:43.595+0000","updated":"2008-02-29T01:54:43.595+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12389638/comment/12573558","id":"12573558","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"body":"> #810 release was a trunk release from Jan 4, running on a different cluster. Because we did not experience HADOOP-2883 with that release, I assumed that it did not write directly to DFS. Am I wrong?\n\nRight. HADOOP-1707 went in on Jan 17th. What is relation to this Jira? All the logs and times mentioned here are around Feb 19-24th or so.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-02-29T02:00:29.359+0000","updated":"2008-02-29T02:00:29.359+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12389638/comment/12573578","id":"12573578","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ckunz","name":"ckunz","key":"ckunz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Christian Kunz","active":true,"timeZone":"Etc/UTC"},"body":"When we ran into the same problem with #810 a month ago on a different cluster it was not clear to us whether we should report it immediately because it was a trunk release and it might have been just a transient problem. We wanted to wait for a stable release and check whether it stlil happens.\n\nBTW, I checked the logs:\nAround 2% of datanodes had OutOfMemoryError exceptions. By itself, it would probably be not much of a problem, but it happened that some of the datanodes went out within a short time of period such that we lossed a few blocks.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ckunz","name":"ckunz","key":"ckunz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Christian Kunz","active":true,"timeZone":"Etc/UTC"},"created":"2008-02-29T03:44:14.987+0000","updated":"2008-02-29T03:44:14.987+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12389638/comment/12573896","id":"12573896","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks Christian. 2% is bad enough :). We need to find out if this is caused just by large number of client connections or some other bug that gets triggered.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rangadi","name":"rangadi","key":"rangadi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Raghu Angadi","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-02-29T18:52:32.853+0000","updated":"2008-02-29T18:52:32.853+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12389638/comment/13177213","id":"13177213","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=qwertymaniac","name":"qwertymaniac","key":"qwertymaniac","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=qwertymaniac&avatarId=16780","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=qwertymaniac&avatarId=16780","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=qwertymaniac&avatarId=16780","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=qwertymaniac&avatarId=16780"},"displayName":"Harsh J","active":true,"timeZone":"Asia/Kolkata"},"body":"This has gone stale. FWIW, haven't seen DNs go OOM on its own in recent years. Probably a leak that was fixed?\n\nResolving as Not a Problem (anymore).","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=qwertymaniac","name":"qwertymaniac","key":"qwertymaniac","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=qwertymaniac&avatarId=16780","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=qwertymaniac&avatarId=16780","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=qwertymaniac&avatarId=16780","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=qwertymaniac&avatarId=16780"},"displayName":"Harsh J","active":true,"timeZone":"Asia/Kolkata"},"created":"2011-12-29T14:55:31.569+0000","updated":"2011-12-29T14:55:31.569+0000"}],"maxResults":21,"total":21,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-47/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i0it67:"}}