{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12596562","self":"https://issues.apache.org/jira/rest/api/2/issue/12596562","key":"HDFS-3584","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310942","id":"12310942","key":"HDFS","name":"Hadoop HDFS","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/3","id":"3","description":"The problem is a duplicate of an existing issue.","name":"Duplicate"},"customfield_12312322":null,"customfield_12310220":"2012-07-02T11:51:57.789+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Tue Aug 21 22:39:43 UTC 2018","customfield_12310420":"257185","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_193680920137_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2018-08-21T22:39:43.029+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-3584/watchers","watchCount":21,"isWatching":false},"created":"2012-07-02T06:24:22.949+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12320353","id":"12320353","description":"hadoop-2.0.0-alpha release","name":"2.0.0-alpha","archived":false,"released":true,"releaseDate":"2012-05-23"}],"issuelinks":[{"id":"12467218","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12467218","type":{"id":"12310000","name":"Duplicate","inward":"is duplicated by","outward":"duplicates","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/12310000"},"inwardIssue":{"id":"12954883","key":"HDFS-10240","self":"https://issues.apache.org/jira/rest/api/2/issue/12954883","fields":{"summary":"Race between close/recoverLease leads to missing block","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}}],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2018-08-21T22:39:43.075+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12312926","id":"12312926","name":"namenode"}],"timeoriginalestimate":null,"description":"Scenario:\n========= \n1. There are 2 clients cli1 and cli2 cli1 write a file F1 and not closed\n2. The cli2 will call append on unclosed file and triggers a leaserecovery\n3. Cli1 is closed\n4. Lease recovery is completed and with updated GS in DN and got BlockReport since there is a mismatch in GS the block got corrupted\n5. Now we got a CommitBlockSync this will also fail since the File is already closed by cli1 and state in NN is Finalized\n","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"114249","customfield_12312823":null,"summary":"Blocks are getting marked as corrupt with append operation under high load.","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brahmareddy","name":"brahmareddy","key":"brahmareddy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=brahmareddy&avatarId=24624","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=brahmareddy&avatarId=24624","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=brahmareddy&avatarId=24624","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=brahmareddy&avatarId=24624"},"displayName":"Brahma Reddy Battula","active":true,"timeZone":"Asia/Kolkata"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brahmareddy","name":"brahmareddy","key":"brahmareddy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=brahmareddy&avatarId=24624","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=brahmareddy&avatarId=24624","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=brahmareddy&avatarId=24624","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=brahmareddy&avatarId=24624"},"displayName":"Brahma Reddy Battula","active":true,"timeZone":"Asia/Kolkata"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12596562/comment/13404905","id":"13404905","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brahmareddy","name":"brahmareddy","key":"brahmareddy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=brahmareddy&avatarId=24624","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=brahmareddy&avatarId=24624","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=brahmareddy&avatarId=24624","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=brahmareddy&avatarId=24624"},"displayName":"Brahma Reddy Battula","active":true,"timeZone":"Asia/Kolkata"},"body":"*please check following log for blk_-7909104799008701972* \n\n{noformat}\n2012-06-25 13:48:59,603 INFO org.apache.hadoop.hdfs.StateChange: BLOCK NameSystem.addToCorruptReplicasMap: blk_-7909104799008701972 added as corrupt on ****DN1:50010 by /****DN1 because block is COMPLETE and reported genstamp 96470 does not match genstamp in block map 96309\n2012-06-25 13:48:59,604 DEBUG org.apache.hadoop.hdfs.StateChange: UnderReplicationBlocks.update blk_-7909104799008701972_96309 curReplicas 2 curExpectedReplicas 3 oldReplicas 3 oldExpectedReplicas  3 curPri  2 oldPri  3\n2012-06-25 13:48:59,604 DEBUG org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.UnderReplicationBlock.update:blk_-7909104799008701972_96309 has only 2 replicas and needs 3 replicas so is added to neededReplications at priority level 2\n2012-06-25 13:48:59,604 DEBUG org.apache.hadoop.hdfs.StateChange: BLOCK* block RECEIVED_BLOCK: blk_-7909104799008701972_96470 is received from DatanodeRegistration(****DN1, storageID=DS-1986831640-****DN1-50010-1340363042399, infoPort=50075, ipcPort=50020, storageInfo=lv=-40;cid=CID-fdfc6cef-05b1-4900-b5f9-cc275dfd343c;nsid=415242063;c=0)\n2012-06-25 13:48:59,607 DEBUG org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Reported block blk_-7909104799008701972_96470 on ****DN2:50010 size 524288 replicaState = FINALIZED\n2012-06-25 13:48:59,608 INFO org.apache.hadoop.hdfs.StateChange: BLOCK NameSystem.addToCorruptReplicasMap: blk_-7909104799008701972 added as corrupt on ****DN2:50010 by /****DN2 because block is COMPLETE and reported genstamp 96470 does not match genstamp in block map 96309\n2012-06-25 13:48:59,608 DEBUG org.apache.hadoop.hdfs.StateChange: UnderReplicationBlocks.update blk_-7909104799008701972_96309 curReplicas 1 curExpectedReplicas 3 oldReplicas 2 oldExpectedReplicas  3 curPri  0 oldPri  2\n2012-06-25 13:48:59,609 DEBUG org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.UnderReplicationBlock.remove: Removing block blk_-7909104799008701972_96309 from priority queue 2\n2012-06-25 13:48:59,609 DEBUG org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.UnderReplicationBlock.update:blk_-7909104799008701972_96309 has only 1 replicas and needs 3 replicas so is added to neededReplications at priority level 0\n2012-06-25 13:48:59,610 DEBUG org.apache.hadoop.hdfs.StateChange: BLOCK* block RECEIVED_BLOCK: blk_-7909104799008701972_96470 is received from DatanodeRegistration(****DN2, storageID=DS-485536663-****DN2-50010-1340362102909, infoPort=50075, ipcPort=50020, storageInfo=lv=-40;cid=CID-fdfc6cef-05b1-4900-b5f9-cc275dfd343c;nsid=415242063;c=0)\n2012-06-25 13:48:59,678 DEBUG org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Reported block blk_-7909104799008701972_96470 on ****DN3:50010 size 524288 replicaState = FINALIZED\n2012-06-25 13:48:59,679 INFO org.apache.hadoop.hdfs.StateChange: BLOCK NameSystem.addToCorruptReplicasMap: blk_-7909104799008701972 added as corrupt on ****DN3:50010 by /****DN3 because block is COMPLETE and reported genstamp 96470 does not match genstamp in block map 96309\n2012-06-25 13:48:59,681 DEBUG org.apache.hadoop.hdfs.StateChange: UnderReplicationBlocks.update blk_-7909104799008701972_96309 curReplicas 0 curExpectedReplicas 3 oldReplicas 1 oldExpectedReplicas  3 curPri  4 oldPri  0\n2012-06-25 13:48:59,681 DEBUG org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.UnderReplicationBlock.remove: Removing block blk_-7909104799008701972_96309 from priority queue 0\n2012-06-25 13:48:59,682 DEBUG org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.UnderReplicationBlock.update:blk_-7909104799008701972_96309 has only 0 replicas and needs 3 replicas so is added to neededReplications at priority level 4\n2012-06-25 13:48:59,682 DEBUG org.apache.hadoop.hdfs.StateChange: BLOCK* block RECEIVED_BLOCK: blk_-7909104799008701972_96470 is received from DatanodeRegistration(****DN3, storageID=DS-598160968-****DN3-50010-1340382093938, infoPort=50075, ipcPort=50020, storageInfo=lv=-40;cid=CID-fdfc6cef-05b1-4900-b5f9-cc275dfd343c;nsid=415242063;c=0)\n2012-06-25 13:48:59,683 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: commitBlockSynchronization(lastblock=BP-1988075715-****DN1-1340361925673:blk_-7909104799008701972_96309, newgenerationstamp=96470, newlength=524288, newtargets=[****DN1:50010, ****DN2:50010, ****DN3:50010], closeFile=true, deleteBlock=false)\n2012-06-25 13:48:59,683 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:root (auth:SIMPLE) cause:java.io.IOException: Unexpected block (=BP-1988075715-****DN1-1340361925673:blk_-7909104799008701972_96309) since the file (=append_1654216706419640) is not under construction\n2012-06-25 13:48:59,685 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 8020, call org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol.commitBlockSynchronization from ****DN1:15704: error: java.io.IOException: Unexpected block (=BP-1988075715-****DN1-1340361925673:blk_-7909104799008701972_96309) since the file (=append_1654216706419640) is not under construction\njava.io.IOException: Unexpected block (=BP-1988075715-****DN1-1340361925673:blk_-7909104799008701972_96309) since the file (=append_1654216706419640) is not under construction\n2012-06-25 13:49:00,413 DEBUG org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Block blk_-7909104799008701972_96309 cannot be repl from any node\n{noformat}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=brahmareddy","name":"brahmareddy","key":"brahmareddy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=brahmareddy&avatarId=24624","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=brahmareddy&avatarId=24624","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=brahmareddy&avatarId=24624","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=brahmareddy&avatarId=24624"},"displayName":"Brahma Reddy Battula","active":true,"timeZone":"Asia/Kolkata"},"created":"2012-07-02T06:30:07.878+0000","updated":"2012-07-02T06:30:07.878+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12596562/comment/13405025","id":"13405025","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=amithdk","name":"amithdk","key":"amithdk","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"amith","active":true,"timeZone":"Asia/Kolkata"},"body":"Here I can see client1 are not able to get the lease renewed with in soft limit period and client2 try to trigger lease recovery\nI can see this from the exception @ client\n\nClient log\n{noformat}\n2012-06-28 19:40:56,452 INFO  hdfs.TestHDFSAPI (TestHDFSAPI.java:writeFile(168)) - Writing File with client DFS[DFSClient[clientName=DFSClient_clientIDD36655341694508_139393306_1, ugi=B00902108 (auth:SIMPLE)]] File = /home/test/writefile_36673810701636\n2012-06-28 19:41:04,619 INFO  hdfs.TestHDFSAPI (TestHDFSAPI.java:writeFile(179)) - Creating File with client DFS[DFSClient[clientName=DFSClient_clientIDD36655341694508_139393306_1, ugi=B00902108 (auth:SIMPLE)]] File = /home/test/writefile_36673810701636\n2012-06-28 19:42:28,004 INFO  hdfs.TestHDFSAPI (TestHDFSAPI.java:writeFile(186)) - Closing File with client DFS[DFSClient[clientName=DFSClient_clientIDD36655341694508_139393306_1, ugi=B00902108 (auth:SIMPLE)]] File = /home/test/writefile_36673810701636 file size= 524288\n2012-06-28 19:42:32,680 INFO  hdfs.TestHDFSAPI (TestHDFSAPI.java:appendFile(76)) - Going Append File with client DFS[DFSClient[clientName=DFSClient_clientIDD36661058974201_139393306_1, ugi=B00902108 (auth:SIMPLE)]]File = /home/test/writefile_36673810701636file size= 524288\norg.apache.hadoop.hdfs.protocol.RecoveryInProgressException: Failed to close file /home/test/writefile_36673810701636. Lease recovery is in progress. Try again later.\n{noformat}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=amithdk","name":"amithdk","key":"amithdk","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"amith","active":true,"timeZone":"Asia/Kolkata"},"created":"2012-07-02T11:51:57.789+0000","updated":"2012-07-02T11:51:57.789+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12596562/comment/13405043","id":"13405043","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks Brahma and Amith for digging into it.\n\nSeems like a bug.\nWe are triggering the recovery from append on leaseExpired check, that means that we are trusting that, older client might have gone down. So, there is no renewal from clients and soft limit expired. And append call is triggering the recovery himself and throwing the exception to user, saying file not yet closed try again later. Here we are renewing the lease now from append call itself.\n\n{code}\n if (lease.expiredSoftLimit()) {\n          LOG.info(\"startFile: recover lease \" + lease + \", src=\" + src +\n              \" from client \" + pendingFile.getClientName());\n          boolean isClosed = internalReleaseLease(lease, src, null, lease.expiredSoftLimit());\n          if(!isClosed)\n            throw new RecoveryInProgressException(\n                \"Failed to close file \" + src +\n                \". Lease recovery is in progress. Try again later.\");\n        }\n{code}\n\nand in internalReleaseLease:\n\n{code}\n    case UNDER_RECOVERY:\n      final BlockInfoUnderConstruction uc = (BlockInfoUnderConstruction)lastBlock;\n      // setup the last block locations from the blockManager if not known\n      if (uc.getNumExpectedLocations() == 0) {\n        uc.setExpectedLocations(blockManager.getNodes(lastBlock));\n      }\n      // start recovery of the last block for this file\n      long blockRecoveryId = nextGenerationStamp();\n      lease = reassignLease(lease, src, recoveryLeaseHolder, pendingFile);\n      uc.initializeBlockRecovery(blockRecoveryId);\n      leaseManager.renewLease(lease);\n{code}\n\nHere block recovery will happen in background in primary DN and will be returned.\n\nBut unfortunately now close call came from the old client and file got closed. Seems like this happend under high load.\nBut block ids already bumped in DNs and will rejected as file closed with older genstamps at NN side.\ncommitBlockSynchronization also failing due to this reason.\n\nI think we need to block the older clients to close the file at this stage?\n\nwhat if append call takes the new lease ownership and removes the older client lease?\n\nclose call anyway checking the lease expiration.\n\n{code}\n try {\n      pendingFile = checkLease(src, holder);\n    } catch (LeaseExpiredException lee) {\n      INodeFile file = dir.getFileINode(src);\n      if (file != null && !file.isUnderConstruction()) {\n        // This could be a retry RPC - i.e the client tried to close\n        // the file, but missed the RPC response. Thus, it is trying\n        // again to close the file. If the file still exists and\n        // the client's view of the last block matches the actual\n        // last block, then we'll treat it as a successful close.\n        // See HDFS-3031.\n        Block realLastBlock = file.getLastBlock();\n        if (Block.matchingIdAndGenStamp(last, realLastBlock)) {\n          NameNode.stateChangeLog.info(\"DIR* NameSystem.completeFile: \" +\n              \"received request from \" + holder + \" to complete file \" + src +\n              \" which is already closed. But, it appears to be an RPC \" +\n              \"retry. Returning success.\");\n          return true;\n        }\n      }\n      throw lee;\n    }\n{code}\nI am not sure , I am missing some thing here.\nwould greatly appreciate your suggestions on this.\n  ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"created":"2012-07-02T12:47:51.686+0000","updated":"2012-07-02T12:47:51.686+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12596562/comment/13407665","id":"13407665","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi All,\n\nDo you have any comments on this issue?\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"created":"2012-07-06T02:49:11.343+0000","updated":"2012-07-06T02:49:11.343+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12596562/comment/13411801","id":"13411801","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"body":"Todd, could you please comment on this, for further discussion if you have time?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=umamaheswararao","name":"umamaheswararao","key":"umamaheswararao","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Uma Maheswara Rao G","active":true,"timeZone":"America/Los_Angeles"},"created":"2012-07-11T18:12:30.521+0000","updated":"2012-07-11T18:12:30.521+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12596562/comment/15312138","id":"15312138","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=qwertymaniac","name":"qwertymaniac","key":"qwertymaniac","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=qwertymaniac&avatarId=16780","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=qwertymaniac&avatarId=16780","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=qwertymaniac&avatarId=16780","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=qwertymaniac&avatarId=16780"},"displayName":"Harsh J","active":true,"timeZone":"Asia/Kolkata"},"body":"HDFS-10240 appears to report a similar issue.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=qwertymaniac","name":"qwertymaniac","key":"qwertymaniac","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=qwertymaniac&avatarId=16780","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=qwertymaniac&avatarId=16780","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=qwertymaniac&avatarId=16780","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=qwertymaniac&avatarId=16780"},"displayName":"Harsh J","active":true,"timeZone":"Asia/Kolkata"},"created":"2016-06-02T11:00:03.993+0000","updated":"2016-06-02T11:00:03.993+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12596562/comment/16553493","id":"16553493","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"body":"This is definitely the same as HDFS-10240, and it is reproducible even with one client thread.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"created":"2018-07-23T22:38:54.129+0000","updated":"2018-07-23T22:38:54.129+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12596562/comment/16553637","id":"16553637","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"body":"bq. I think we need to block the older clients to close the file at this stage?\r\nMy take is that once recoverLease() or whatever calls that starts lease recovery reaches NameNode, NN should reject follow-up close()/recoverLease() calls until it is able to recover the lease. If the lease recovery doesn't complete, you just can't safely assume the file can be closed (e.g. file doesn't have sufficient number of replicas)\r\n\r\nbq. what if append call takes the new lease ownership and removes the older client lease?\r\nMeaning append takes over lease without a lease recovery, so it doesn't bump up GS? That doesn't sounds right to me.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"created":"2018-07-24T00:51:25.607+0000","updated":"2018-07-24T00:51:25.607+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12596562/comment/16588098","id":"16588098","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=elgoiri","name":"elgoiri","key":"elgoiri","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Íñigo Goiri","active":true,"timeZone":"Etc/UTC"},"body":"Can we close this one once HDFS-10240 is committed?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=elgoiri","name":"elgoiri","key":"elgoiri","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Íñigo Goiri","active":true,"timeZone":"Etc/UTC"},"created":"2018-08-21T22:33:43.034+0000","updated":"2018-08-21T22:33:43.034+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12596562/comment/16588103","id":"16588103","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"body":"Close this one. Thanks for reminder [~elgoiri]","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jojochuang","name":"jojochuang","key":"jojochuang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=jojochuang&avatarId=25508","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jojochuang&avatarId=25508","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jojochuang&avatarId=25508","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jojochuang&avatarId=25508"},"displayName":"Wei-Chiu Chuang","active":true,"timeZone":"America/Los_Angeles"},"created":"2018-08-21T22:39:43.070+0000","updated":"2018-08-21T22:39:43.070+0000"}],"maxResults":10,"total":10,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/HDFS-3584/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i0jwtz:"}}