{
    "expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields",
    "fields": {
        "aggregateprogress": {
            "progress": 0,
            "total": 0
        },
        "aggregatetimeestimate": null,
        "aggregatetimeoriginalestimate": null,
        "aggregatetimespent": null,
        "assignee": null,
        "components": [],
        "created": "2014-10-28T07:44:53.000+0000",
        "creator": {
            "active": true,
            "avatarUrls": {
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452",
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
            },
            "displayName": "Vishnu Ganth",
            "key": "vishnuganth",
            "name": "vishnuganth",
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=vishnuganth",
            "timeZone": "Asia/Kolkata"
        },
        "customfield_10010": null,
        "customfield_12310191": null,
        "customfield_12310192": null,
        "customfield_12310220": "2014-10-28T08:37:29.310+0000",
        "customfield_12310222": null,
        "customfield_12310230": null,
        "customfield_12310250": null,
        "customfield_12310290": null,
        "customfield_12310291": null,
        "customfield_12310300": null,
        "customfield_12310310": "0.0",
        "customfield_12310320": null,
        "customfield_12310420": "9223372036854775807",
        "customfield_12310920": "9223372036854775807",
        "customfield_12310921": null,
        "customfield_12311020": null,
        "customfield_12311024": null,
        "customfield_12311120": null,
        "customfield_12311820": "0|i21no7:",
        "customfield_12312022": null,
        "customfield_12312023": null,
        "customfield_12312024": null,
        "customfield_12312026": null,
        "customfield_12312220": null,
        "customfield_12312320": null,
        "customfield_12312321": null,
        "customfield_12312322": null,
        "customfield_12312323": null,
        "customfield_12312324": null,
        "customfield_12312325": null,
        "customfield_12312326": null,
        "customfield_12312327": null,
        "customfield_12312328": null,
        "customfield_12312329": null,
        "customfield_12312330": null,
        "customfield_12312331": null,
        "customfield_12312332": null,
        "customfield_12312333": null,
        "customfield_12312334": null,
        "customfield_12312335": null,
        "customfield_12312336": null,
        "customfield_12312337": null,
        "customfield_12312338": null,
        "customfield_12312339": null,
        "customfield_12312340": null,
        "customfield_12312341": null,
        "customfield_12312520": null,
        "customfield_12312521": "Mon Nov 03 05:25:07 UTC 2014",
        "customfield_12312720": null,
        "customfield_12312823": null,
        "customfield_12312920": null,
        "customfield_12312921": null,
        "customfield_12312923": null,
        "customfield_12313422": "false",
        "customfield_12313520": null,
        "description": "Hadoop Namenode is getting failed because of some unexpected value of block size in fsimage.\n\nStack trace:\n{code}\n2014-10-27 16:22:12,107 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: \n/************************************************************\nSTARTUP_MSG: Starting NameNode\nSTARTUP_MSG:   host = <mastermachine-hostname>/<ip>\nSTARTUP_MSG:   args = []\nSTARTUP_MSG:   version = 2.0.0-cdh4.4.0\nSTARTUP_MSG:   classpath = /var/run/cloudera-scm-agent/process/12726-hdfs-NAMENODE:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/hue-plugins-2.5.0-cdh4.4.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/activation-1.1.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/jetty-6.1.26.cloudera.2.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/jersey-core-1.8.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/jackson-xc-1.8.8.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/jasper-compiler-5.5.23.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/guava-11.0.2.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/commons-collections-3.2.1.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/paranamer-2.3.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/commons-net-3.1.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/xz-1.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/commons-beanutils-core-1.8.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/commons-cli-1.2.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/jetty-util-6.1.26.cloudera.2.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/zookeeper-3.4.5-cdh4.4.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/jackson-mapper-asl-1.8.8.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/jackson-jaxrs-1.8.8.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/slf4j-api-1.6.1.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/stax-api-1.0.1.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/snappy-java-1.0.4.1.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/jline-0.9.94.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/commons-beanutils-1.7.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/jsp-api-2.1.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/jsr305-1.3.9.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/commons-logging-1.1.1.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/commons-digester-1.8.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/xmlenc-0.52.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/jackson-core-asl-1.8.8.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/log4j-1.2.17.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/slf4j-log4j12-1.6.1.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/jersey-server-1.8.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/servlet-api-2.5.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/jettison-1.1.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/commons-httpclient-3.1.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/commons-math-2.1.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/jets3t-0.6.1.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/commons-el-1.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/avro-1.7.4.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/commons-codec-1.4.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/commons-lang-2.5.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/jersey-json-1.8.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/kfs-0.3.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/jasper-runtime-5.5.23.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/commons-configuration-1.6.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/junit-4.8.2.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/mockito-all-1.8.5.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/commons-io-2.1.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/protobuf-java-2.4.0a.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/jsch-0.1.42.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/commons-compress-1.4.1.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/jaxb-api-2.2.2.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/jaxb-impl-2.2.3-1.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/lib/asm-3.2.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/.//hadoop-common.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/.//hadoop-annotations.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/.//hive-serdes-1.0-SNAPSHOT.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/.//hadoop-annotations-2.0.0-cdh4.4.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/.//hadoop-common-2.0.0-cdh4.4.0-tests.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/.//hadoop-auth.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/.//hadoop-auth-2.0.0-cdh4.4.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop/.//hadoop-common-2.0.0-cdh4.4.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-hdfs/./:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-hdfs/lib/jetty-6.1.26.cloudera.2.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-hdfs/lib/jersey-core-1.8.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-hdfs/lib/guava-11.0.2.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-hdfs/lib/commons-cli-1.2.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-hdfs/lib/jetty-util-6.1.26.cloudera.2.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-hdfs/lib/zookeeper-3.4.5-cdh4.4.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-hdfs/lib/jackson-mapper-asl-1.8.8.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-hdfs/lib/jline-0.9.94.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-hdfs/lib/jsp-api-2.1.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-hdfs/lib/jsr305-1.3.9.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-hdfs/lib/commons-logging-1.1.1.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-hdfs/lib/xmlenc-0.52.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-hdfs/lib/jackson-core-asl-1.8.8.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-hdfs/lib/log4j-1.2.17.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-hdfs/lib/jersey-server-1.8.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-hdfs/lib/servlet-api-2.5.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-hdfs/lib/commons-daemon-1.0.3.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-hdfs/lib/commons-el-1.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-hdfs/lib/commons-codec-1.4.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-hdfs/lib/commons-lang-2.5.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-hdfs/lib/jasper-runtime-5.5.23.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-hdfs/lib/commons-io-2.1.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-hdfs/lib/protobuf-java-2.4.0a.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-hdfs/lib/asm-3.2.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-hdfs/.//hadoop-hdfs.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-hdfs/.//hadoop-hdfs-2.0.0-cdh4.4.0-tests.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-hdfs/.//hadoop-hdfs-2.0.0-cdh4.4.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/lib/javax.inject-1.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/lib/jersey-core-1.8.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/lib/paranamer-2.3.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/lib/netty-3.2.4.Final.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/lib/xz-1.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/lib/jackson-mapper-asl-1.8.8.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/lib/snappy-java-1.0.4.1.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/lib/jackson-core-asl-1.8.8.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/lib/log4j-1.2.17.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/lib/jersey-server-1.8.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/lib/jersey-guice-1.8.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/lib/avro-1.7.4.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/lib/guice-3.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/lib/aopalliance-1.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/lib/guice-servlet-3.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/lib/commons-io-2.1.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/lib/protobuf-java-2.4.0a.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/lib/commons-compress-1.4.1.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/lib/asm-3.2.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/.//hadoop-yarn-server-tests-2.0.0-cdh4.4.0-tests.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/.//hadoop-yarn-applications-distributedshell-2.0.0-cdh4.4.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/.//hadoop-yarn-server-web-proxy.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher-2.0.0-cdh4.4.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/.//hadoop-yarn-server-nodemanager-2.0.0-cdh4.4.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/.//hadoop-yarn-server-resourcemanager.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/.//hadoop-yarn-site.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/.//hadoop-yarn-common.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/.//hadoop-yarn-site-2.0.0-cdh4.4.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/.//hadoop-yarn-server-tests-2.0.0-cdh4.4.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/.//hadoop-yarn-client.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/.//hadoop-yarn-server-resourcemanager-2.0.0-cdh4.4.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/.//hadoop-yarn-server-web-proxy-2.0.0-cdh4.4.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/.//hadoop-yarn-server-tests.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/.//hadoop-yarn-client-2.0.0-cdh4.4.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/.//hadoop-yarn-server-common-2.0.0-cdh4.4.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/.//hadoop-yarn-applications-distributedshell.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/.//hadoop-yarn-common-2.0.0-cdh4.4.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/.//hadoop-yarn-api.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/.//hadoop-yarn-server-nodemanager.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/.//hadoop-yarn-api-2.0.0-cdh4.4.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-yarn/.//hadoop-yarn-server-common.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/lib/javax.inject-1.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/lib/jersey-core-1.8.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/lib/paranamer-2.3.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/lib/netty-3.2.4.Final.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/lib/xz-1.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/lib/jackson-mapper-asl-1.8.8.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/lib/jackson-core-asl-1.8.8.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/lib/log4j-1.2.17.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/lib/jersey-server-1.8.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/lib/jersey-guice-1.8.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/lib/avro-1.7.4.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/lib/guice-3.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/lib/aopalliance-1.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/lib/guice-servlet-3.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/lib/commons-io-2.1.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/lib/protobuf-java-2.4.0a.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/lib/commons-compress-1.4.1.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/lib/asm-3.2.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/.//hadoop-streaming.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-2.0.0-cdh4.4.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/.//hadoop-distcp.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/.//hadoop-archives.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/.//hadoop-archives-2.0.0-cdh4.4.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/.//hadoop-gridmix-2.0.0-cdh4.4.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-common-2.0.0-cdh4.4.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/.//hadoop-datajoin.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/.//hadoop-rumen.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/.//hadoop-distcp-2.0.0-cdh4.4.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/.//hadoop-extras-2.0.0-cdh4.4.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins-2.0.0-cdh4.4.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/.//hadoop-rumen-2.0.0-cdh4.4.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-core.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/.//hadoop-streaming-2.0.0-cdh4.4.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-app.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle-2.0.0-cdh4.4.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/.//hadoop-mapreduce-examples-2.0.0-cdh4.4.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/.//hadoop-mapreduce-examples.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/.//hadoop-gridmix.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-2.0.0-cdh4.4.0-tests.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-core-2.0.0-cdh4.4.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-2.0.0-cdh4.4.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-app-2.0.0-cdh4.4.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/.//hadoop-datajoin-2.0.0-cdh4.4.0.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-common.jar:/opt/cloudera/parcels/CDH-4.4.0-1.cdh4.4.0.p0.39/lib/hadoop-mapreduce/.//hadoop-extras.jar:/usr/share/cmf/lib/plugins/event-publish-4.7.2-shaded.jar:/usr/share/cmf/lib/plugins/navigator-plugin-4.7.2-shaded.jar:/usr/share/cmf/lib/plugins/tt-instrumentation-4.7.2.jar\nSTARTUP_MSG:   build = file:///data/1/jenkins/workspace/generic-package-rhel64-6-0/topdir/BUILD/hadoop-2.0.0-cdh4.4.0/src/hadoop-common-project/hadoop-common -r c0eba6cd38c984557e96a16ccd7356b7de835e79; compiled by 'jenkins' on Tue Sep  3 19:33:17 PDT 2013\nSTARTUP_MSG:   java = 1.7.0_45\n************************************************************/\n2014-10-27 16:22:12,129 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]\n2014-10-27 16:22:12,695 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties\n2014-10-27 16:22:12,725 INFO org.apache.hadoop.metrics2.impl.MetricsSinkAdapter: Sink ganglia started\n2014-10-27 16:22:12,823 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).\n2014-10-27 16:22:12,823 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started\n2014-10-27 16:22:13,114 INFO org.apache.hadoop.util.HostsFileReader: Adding <IP1> to the list of included hosts from /var/run/cloudera-scm-agent/process/12726-hdfs-NAMENODE/dfs_hosts_allow.txt\n2014-10-27 16:22:13,114 INFO org.apache.hadoop.util.HostsFileReader: Adding <IP2> to the list of included hosts from /var/run/cloudera-scm-agent/process/12726-hdfs-NAMENODE/dfs_hosts_allow.txt\n2014-10-27 16:22:13,114 INFO org.apache.hadoop.util.HostsFileReader: Adding <IP3> to the list of included hosts from /var/run/cloudera-scm-agent/process/12726-hdfs-NAMENODE/dfs_hosts_allow.txt\n2014-10-27 16:22:13,114 INFO org.apache.hadoop.util.HostsFileReader: Adding <IP4> to the list of included hosts from /var/run/cloudera-scm-agent/process/12726-hdfs-NAMENODE/dfs_hosts_allow.txt\n2014-10-27 16:22:13,114 INFO org.apache.hadoop.util.HostsFileReader: Adding <IP5> to the list of included hosts from /var/run/cloudera-scm-agent/process/12726-hdfs-NAMENODE/dfs_hosts_allow.txt\n2014-10-27 16:22:13,114 INFO org.apache.hadoop.util.HostsFileReader: Adding <IP6> to the list of included hosts from /var/run/cloudera-scm-agent/process/12726-hdfs-NAMENODE/dfs_hosts_allow.txt\n2014-10-27 16:22:13,115 INFO org.apache.hadoop.util.HostsFileReader: Adding <IP7> to the list of included hosts from /var/run/cloudera-scm-agent/process/12726-hdfs-NAMENODE/dfs_hosts_allow.txt\n2014-10-27 16:22:13,115 INFO org.apache.hadoop.util.HostsFileReader: Adding <IP8> to the list of included hosts from /var/run/cloudera-scm-agent/process/12726-hdfs-NAMENODE/dfs_hosts_allow.txt\n2014-10-27 16:22:13,116 INFO org.apache.hadoop.hdfs.server.namenode.HostFileManager: read includes:\nHostSet(\n\t<IP1>->Entry{<IP1>, port=0, ipAddress=<IP1>}\n\t<IP2>->Entry{<IP2>, port=0, ipAddress=<IP2>}\n\t<IP3>->Entry{<IP3>, port=0, ipAddress=<IP3>}\n\t<IP4>->Entry{<IP4>, port=0, ipAddress=<IP4>}\n\t<IP5>->Entry{<IP5>, port=0, ipAddress=<IP5>}\n\t<IP6>->Entry{<IP6>, port=0, ipAddress=<IP6>}\n\t<IP7>->Entry{<IP7>, port=0, ipAddress=<IP7>}\n\t<IP8>->Entry{<IP8>, port=0, ipAddress=<IP8>}\n)\n2014-10-27 16:22:13,116 INFO org.apache.hadoop.hdfs.server.namenode.HostFileManager: read excludes:\nHostSet(\n)\n2014-10-27 16:22:13,144 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000\n2014-10-27 16:22:13,186 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false\n2014-10-27 16:22:13,187 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 3\n2014-10-27 16:22:13,187 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512\n2014-10-27 16:22:13,187 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1\n2014-10-27 16:22:13,187 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2\n2014-10-27 16:22:13,187 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = true\n2014-10-27 16:22:13,187 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000\n2014-10-27 16:22:13,187 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false\n2014-10-27 16:22:13,187 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000\n2014-10-27 16:22:13,192 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdfs (auth:SIMPLE)\n2014-10-27 16:22:13,192 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup\n2014-10-27 16:22:13,192 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true\n2014-10-27 16:22:13,193 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false\n2014-10-27 16:22:13,197 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true\n2014-10-27 16:22:13,421 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times\n2014-10-27 16:22:13,422 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033\n2014-10-27 16:22:13,423 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0\n2014-10-27 16:22:13,423 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000\n2014-10-27 16:22:13,675 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /opt1/dfs/nn/in_use.lock acquired by nodename 13026@<mastermachine-hostname>\n2014-10-27 16:22:14,134 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /data/dfs/nn/in_use.lock acquired by nodename 13026@<mastermachine-hostname>\n2014-10-27 16:22:14,268 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /opt2/dfs/nn/in_use.lock acquired by nodename 13026@<mastermachine-hostname>\n2014-10-27 16:22:14,361 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /opt1/dfs/nn/current\n2014-10-27 16:22:14,440 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /data/dfs/nn/current\n2014-10-27 16:22:14,475 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /opt2/dfs/nn/current\n2014-10-27 16:22:14,854 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loading image file /opt1/dfs/nn/current/fsimage_0000000000023479779 using no compression\n2014-10-27 16:22:14,854 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Number of files = 247160\n2014-10-27 16:22:16,428 ERROR org.apache.hadoop.hdfs.server.namenode.FSImage: Failed to load image from FSImageFile(file=/opt1/dfs/nn/current/fsimage_0000000000023479779, cpktTxId=0000000000023479779)\njava.io.IOException: Unexpected block size: -1945969516689645797\n\tat org.apache.hadoop.hdfs.protocol.Block.readHelper(Block.java:187)\n\tat org.apache.hadoop.hdfs.protocol.Block.readFields(Block.java:173)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImageFormat$Loader.loadINode(FSImageFormat.java:379)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImageFormat$Loader.loadDirectory(FSImageFormat.java:310)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImageFormat$Loader.loadLocalNameINodes(FSImageFormat.java:283)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImageFormat$Loader.load(FSImageFormat.java:224)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:786)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:775)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImageFile(FSImage.java:677)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:647)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:274)\n\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:639)\n\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:476)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:403)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:437)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:613)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:598)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1169)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1233)\n2014-10-27 16:22:16,442 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loading image file /data/dfs/nn/current/fsimage_0000000000023479779 using no compression\n2014-10-27 16:22:16,442 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Number of files = 247160\n2014-10-27 16:22:16,945 ERROR org.apache.hadoop.hdfs.server.namenode.FSImage: Failed to load image from FSImageFile(file=/data/dfs/nn/current/fsimage_0000000000023479779, cpktTxId=0000000000023479779)\njava.io.IOException: Unexpected block size: -1945969516689645797\n\tat org.apache.hadoop.hdfs.protocol.Block.readHelper(Block.java:187)\n\tat org.apache.hadoop.hdfs.protocol.Block.readFields(Block.java:173)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImageFormat$Loader.loadINode(FSImageFormat.java:379)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImageFormat$Loader.loadDirectory(FSImageFormat.java:310)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImageFormat$Loader.loadLocalNameINodes(FSImageFormat.java:283)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImageFormat$Loader.load(FSImageFormat.java:224)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:786)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:775)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImageFile(FSImage.java:677)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:647)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:274)\n\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:639)\n\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:476)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:403)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:437)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:613)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:598)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1169)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1233)\n2014-10-27 16:22:16,949 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loading image file /opt2/dfs/nn/current/fsimage_0000000000023479779 using no compression\n2014-10-27 16:22:16,949 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Number of files = 247160\n2014-10-27 16:22:17,407 ERROR org.apache.hadoop.hdfs.server.namenode.FSImage: Failed to load image from FSImageFile(file=/opt2/dfs/nn/current/fsimage_0000000000023479779, cpktTxId=0000000000023479779)\njava.io.IOException: Unexpected block size: -1945969516689645797\n\tat org.apache.hadoop.hdfs.protocol.Block.readHelper(Block.java:187)\n\tat org.apache.hadoop.hdfs.protocol.Block.readFields(Block.java:173)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImageFormat$Loader.loadINode(FSImageFormat.java:379)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImageFormat$Loader.loadDirectory(FSImageFormat.java:310)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImageFormat$Loader.loadLocalNameINodes(FSImageFormat.java:283)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImageFormat$Loader.load(FSImageFormat.java:224)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:786)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:775)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImageFile(FSImage.java:677)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:647)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:274)\n\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:639)\n\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:476)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:403)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:437)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:613)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:598)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1169)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1233)\n2014-10-27 16:22:17,410 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping NameNode metrics system...\n2014-10-27 16:22:17,411 INFO org.apache.hadoop.metrics2.impl.MetricsSinkAdapter: ganglia thread interrupted.\n2014-10-27 16:22:17,411 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system stopped.\n2014-10-27 16:22:17,411 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system shutdown complete.\n2014-10-27 16:22:17,411 FATAL org.apache.hadoop.hdfs.server.namenode.NameNode: Exception in namenode join\njava.io.IOException: Failed to load an FSImage file!\n\tat org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:658)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:274)\n\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:639)\n\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:476)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:403)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:437)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:613)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:598)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1169)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1233)\n2014-10-27 16:22:17,413 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 1\n2014-10-27 16:22:17,415 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: \n/************************************************************\nSHUTDOWN_MSG: Shutting down NameNode at <mastermachine-hostname>/<IP>\n************************************************************/\n{code}",
        "duedate": null,
        "environment": null,
        "fixVersions": [],
        "issuelinks": [],
        "issuetype": {
            "avatarId": 21133,
            "description": "A problem which impairs or prevents the functions of the product.",
            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
            "id": "1",
            "name": "Bug",
            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
            "subtask": false
        },
        "labels": [],
        "lastViewed": null,
        "priority": {
            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
            "id": "3",
            "name": "Major",
            "self": "https://issues.apache.org/jira/rest/api/2/priority/3"
        },
        "progress": {
            "progress": 0,
            "total": 0
        },
        "project": {
            "avatarUrls": {
                "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310942&avatarId=10094",
                "24x24": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310942&avatarId=10094",
                "32x32": "https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310942&avatarId=10094",
                "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12310942&avatarId=10094"
            },
            "id": "12310942",
            "key": "HDFS",
            "name": "Hadoop HDFS",
            "projectCategory": {
                "description": "Scalable Distributed Computing",
                "id": "10292",
                "name": "Hadoop",
                "self": "https://issues.apache.org/jira/rest/api/2/projectCategory/10292"
            },
            "self": "https://issues.apache.org/jira/rest/api/2/project/12310942"
        },
        "reporter": {
            "active": true,
            "avatarUrls": {
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452",
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
            },
            "displayName": "Vishnu Ganth",
            "key": "vishnuganth",
            "name": "vishnuganth",
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=vishnuganth",
            "timeZone": "Asia/Kolkata"
        },
        "resolution": null,
        "resolutiondate": null,
        "status": {
            "description": "The issue is open and ready for the assignee to start work on it.",
            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/open.png",
            "id": "1",
            "name": "Open",
            "self": "https://issues.apache.org/jira/rest/api/2/status/1",
            "statusCategory": {
                "colorName": "blue-gray",
                "id": 2,
                "key": "new",
                "name": "To Do",
                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/2"
            }
        },
        "subtasks": [],
        "summary": "Hadoop Namenode failing because of negative value in fsimage",
        "timeestimate": null,
        "timeoriginalestimate": null,
        "timespent": null,
        "updated": "2014-11-03T05:25:07.000+0000",
        "versions": [{
            "archived": false,
            "description": "hadoop-2.0.0-alpha release",
            "id": "12320353",
            "name": "2.0.0-alpha",
            "releaseDate": "2012-05-23",
            "released": true,
            "self": "https://issues.apache.org/jira/rest/api/2/version/12320353"
        }],
        "votes": {
            "hasVoted": false,
            "self": "https://issues.apache.org/jira/rest/api/2/issue/HDFS-7299/votes",
            "votes": 0
        },
        "watches": {
            "isWatching": false,
            "self": "https://issues.apache.org/jira/rest/api/2/issue/HDFS-7299/watchers",
            "watchCount": 6
        },
        "workratio": -1
    },
    "id": "12751016",
    "key": "HDFS-7299",
    "self": "https://issues.apache.org/jira/rest/api/2/issue/12751016"
}