{
    "expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields",
    "fields": {
        "aggregateprogress": {
            "progress": 0,
            "total": 0
        },
        "aggregatetimeestimate": null,
        "aggregatetimeoriginalestimate": null,
        "aggregatetimespent": null,
        "assignee": {
            "active": true,
            "avatarUrls": {
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452",
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
            },
            "displayName": "Jason Lowe",
            "key": "jlowe",
            "name": "jlowe",
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=jlowe",
            "timeZone": "America/Chicago"
        },
        "components": [
            {
                "id": "12312905",
                "name": "contrib/streaming",
                "self": "https://issues.apache.org/jira/rest/api/2/component/12312905"
            },
            {
                "description": "MR-279: Map Reduce Next.",
                "id": "12314301",
                "name": "mrv2",
                "self": "https://issues.apache.org/jira/rest/api/2/component/12314301"
            }
        ],
        "created": "2012-02-02T18:04:23.000+0000",
        "creator": {
            "active": true,
            "avatarUrls": {
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452",
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
            },
            "displayName": "Jason Lowe",
            "key": "jlowe",
            "name": "jlowe",
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=jlowe",
            "timeZone": "America/Chicago"
        },
        "customfield_10010": null,
        "customfield_12310191": null,
        "customfield_12310192": null,
        "customfield_12310220": "2012-02-03T23:57:56.140+0000",
        "customfield_12310222": "10002_*:*_2_*:*_2083626557_*|*_1_*:*_2_*:*_161747838_*|*_5_*:*_1_*:*_0",
        "customfield_12310230": null,
        "customfield_12310250": null,
        "customfield_12310290": null,
        "customfield_12310291": null,
        "customfield_12310300": null,
        "customfield_12310310": "1.0",
        "customfield_12310320": [{
            "archived": false,
            "description": "0.23.1 - Performance release",
            "id": "12318883",
            "name": "0.23.1",
            "releaseDate": "2012-02-17",
            "released": true,
            "self": "https://issues.apache.org/jira/rest/api/2/version/12318883"
        }],
        "customfield_12310420": "226315",
        "customfield_12310920": "51631",
        "customfield_12310921": null,
        "customfield_12311020": null,
        "customfield_12311024": null,
        "customfield_12311120": null,
        "customfield_12311820": "0|i097ef:",
        "customfield_12312022": null,
        "customfield_12312023": null,
        "customfield_12312024": null,
        "customfield_12312026": null,
        "customfield_12312220": null,
        "customfield_12312320": null,
        "customfield_12312321": null,
        "customfield_12312322": null,
        "customfield_12312323": null,
        "customfield_12312324": null,
        "customfield_12312325": null,
        "customfield_12312326": null,
        "customfield_12312327": null,
        "customfield_12312328": null,
        "customfield_12312329": null,
        "customfield_12312330": null,
        "customfield_12312331": null,
        "customfield_12312332": null,
        "customfield_12312333": null,
        "customfield_12312334": null,
        "customfield_12312335": null,
        "customfield_12312336": null,
        "customfield_12312337": null,
        "customfield_12312338": null,
        "customfield_12312339": null,
        "customfield_12312340": null,
        "customfield_12312341": null,
        "customfield_12312520": null,
        "customfield_12312521": "Wed Apr 12 19:57:48 UTC 2017",
        "customfield_12312720": null,
        "customfield_12312823": null,
        "customfield_12312920": null,
        "customfield_12312921": null,
        "customfield_12312923": null,
        "customfield_12313422": "false",
        "customfield_12313520": null,
        "description": "If a streaming job doesn't consume all of its input then the job can be marked successful even though the job's output is truncated.\n\nHere's a simple setup that can exhibit the problem.  Note that the job output will most likely be truncated compared to the same job run with a zero-length input file.\n\n{code}\n$ hdfs dfs -cat in\nfoo\n$ yarn jar ./share/hadoop/tools/lib/hadoop-streaming-0.24.0-SNAPSHOT.jar -Dmapred.map.tasks=1 -Dmapred.reduce.tasks=1 -mapper /bin/env -reducer NONE -input in -output out\n{code}\n\nExamining the map task log shows this:\n\n{code:title=Excerpt from map task stdout log}\n2012-02-02 11:27:25,054 WARN [main] org.apache.hadoop.streaming.PipeMapRed: java.io.IOException: Broken pipe\n2012-02-02 11:27:25,054 INFO [main] org.apache.hadoop.streaming.PipeMapRed: mapRedFinished\n2012-02-02 11:27:25,056 WARN [Thread-12] org.apache.hadoop.streaming.PipeMapRed: java.io.IOException: Bad file descriptor\n2012-02-02 11:27:25,124 INFO [main] org.apache.hadoop.mapred.Task: Task:attempt_1328203555769_0001_m_000000_0 is done. And is in the process of commiting\n2012-02-02 11:27:25,127 WARN [Thread-11] org.apache.hadoop.streaming.PipeMapRed: java.io.IOException: DFSOutputStream is closed\n2012-02-02 11:27:25,199 INFO [main] org.apache.hadoop.mapred.Task: Task attempt_1328203555769_0001_m_000000_0 is allowed to commit now\n2012-02-02 11:27:25,225 INFO [main] org.apache.hadoop.mapred.FileOutputCommitter: Saved output of task 'attempt_1328203555769_0001_m_000000_0' to hdfs://localhost:9000/user/somebody/out/_temporary/1\n2012-02-02 11:27:27,834 INFO [main] org.apache.hadoop.mapred.Task: Task 'attempt_1328203555769_0001_m_000000_0' done.\n{code}\n\nIn PipeMapRed.mapRedFinished() we can see it will eat IOExceptions and return without waiting for the output threads or throwing a runtime exception to fail the job.  Net result is that the DFS streams could be shutdown too early if the output threads are still busy and we could lose job output.\n\nFixing this brings up the bigger question of what *should* happen when a streaming job doesn't consume all of its input.  Should we have grabbed all of the output from the job and still marked it successful or should we have failed the job?  If the former then we need to fix some other places in the code as well, since feeding a much larger input file (e.g.: 600K) to the same sample streaming job results in the job failing with the exception below.  It wouldn't be consistent to fail the job that doesn't consume a lot of input but pass the job that leaves just a few leftovers.\n\n{code}\n2012-02-02 10:29:37,220 INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1270)) - Running job: job_1328200108174_0001\n2012-02-02 10:29:44,354 INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1291)) - Job job_1328200108174_0001 running in uber mode : false\n2012-02-02 10:29:44,355 INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1298)) -  map 0% reduce 0%\n2012-02-02 10:29:46,394 INFO  mapreduce.Job (Job.java:printTaskEvents(1386)) - Task Id : attempt_1328200108174_0001_m_000000_0, Status : FAILED\nError: java.io.IOException: Broken pipe\n\tat java.io.FileOutputStream.writeBytes(Native Method)\n\tat java.io.FileOutputStream.write(FileOutputStream.java:282)\n\tat java.io.BufferedOutputStream.write(BufferedOutputStream.java:105)\n\tat java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)\n\tat java.io.BufferedOutputStream.write(BufferedOutputStream.java:109)\n\tat java.io.DataOutputStream.write(DataOutputStream.java:90)\n\tat org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)\n\tat org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)\n\tat org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)\n\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)\n\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:394)\n\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:329)\n\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:147)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:396)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1177)\n\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:142)\n{code}\n\nAssuming the job returns a successful exit code, I think we should allow the job to complete successfully even though it doesn't consume all of its inputs.  Part of the reasoning is that there's already this comment in PipeMapper.java that implies we desire that behavior:\n\n{code:title=PipeMapper.java}\n        // terminate with success:\n        // swallow input records although the stream processor failed/closed\n{code}",
        "duedate": null,
        "environment": null,
        "fixVersions": [{
            "archived": true,
            "description": "0.23.2",
            "id": "12319851",
            "name": "0.23.2",
            "released": false,
            "self": "https://issues.apache.org/jira/rest/api/2/version/12319851"
        }],
        "issuelinks": [],
        "issuetype": {
            "avatarId": 21133,
            "description": "A problem which impairs or prevents the functions of the product.",
            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
            "id": "1",
            "name": "Bug",
            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
            "subtask": false
        },
        "labels": [],
        "lastViewed": null,
        "priority": {
            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
            "id": "3",
            "name": "Major",
            "self": "https://issues.apache.org/jira/rest/api/2/priority/3"
        },
        "progress": {
            "progress": 0,
            "total": 0
        },
        "project": {
            "avatarUrls": {
                "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310941&avatarId=10096",
                "24x24": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310941&avatarId=10096",
                "32x32": "https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310941&avatarId=10096",
                "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12310941&avatarId=10096"
            },
            "id": "12310941",
            "key": "MAPREDUCE",
            "name": "Hadoop Map/Reduce",
            "projectCategory": {
                "description": "Scalable Distributed Computing",
                "id": "10292",
                "name": "Hadoop",
                "self": "https://issues.apache.org/jira/rest/api/2/projectCategory/10292"
            },
            "self": "https://issues.apache.org/jira/rest/api/2/project/12310941"
        },
        "reporter": {
            "active": true,
            "avatarUrls": {
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452",
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
            },
            "displayName": "Jason Lowe",
            "key": "jlowe",
            "name": "jlowe",
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=jlowe",
            "timeZone": "America/Chicago"
        },
        "resolution": {
            "description": "A fix for this issue is checked into the tree and tested.",
            "id": "1",
            "name": "Fixed",
            "self": "https://issues.apache.org/jira/rest/api/2/resolution/1"
        },
        "resolutiondate": "2012-02-28T17:47:17.000+0000",
        "status": {
            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
            "id": "5",
            "name": "Resolved",
            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
            "statusCategory": {
                "colorName": "green",
                "id": 3,
                "key": "done",
                "name": "Done",
                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3"
            }
        },
        "subtasks": [],
        "summary": "Broken pipe on streaming job can lead to truncated output for a successful job",
        "timeestimate": null,
        "timeoriginalestimate": null,
        "timespent": null,
        "updated": "2017-04-12T19:57:48.000+0000",
        "versions": [
            {
                "archived": false,
                "description": "0.23.1 - Performance release",
                "id": "12318883",
                "name": "0.23.1",
                "releaseDate": "2012-02-17",
                "released": true,
                "self": "https://issues.apache.org/jira/rest/api/2/version/12318883"
            },
            {
                "archived": false,
                "description": "hadoop-2.0.0-alpha release",
                "id": "12320354",
                "name": "2.0.0-alpha",
                "releaseDate": "2012-05-23",
                "released": true,
                "self": "https://issues.apache.org/jira/rest/api/2/version/12320354"
            }
        ],
        "votes": {
            "hasVoted": false,
            "self": "https://issues.apache.org/jira/rest/api/2/issue/MAPREDUCE-3790/votes",
            "votes": 0
        },
        "watches": {
            "isWatching": false,
            "self": "https://issues.apache.org/jira/rest/api/2/issue/MAPREDUCE-3790/watchers",
            "watchCount": 7
        },
        "workratio": -1
    },
    "id": "12540962",
    "key": "MAPREDUCE-3790",
    "self": "https://issues.apache.org/jira/rest/api/2/issue/12540962"
}