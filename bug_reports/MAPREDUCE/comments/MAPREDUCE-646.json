[Another option might be to increase its replication, no?, Yes. Increasing replication is another solution. But since we dont know the number of parallel maps that can run, setting replication to a fixed value like 10 may not be enough for some cases and also can become overhead on namenode. So distributed cache could be better ?, Distributed cache would give every mapper a full copy of the file, but each only reads a portion of the file, so I think increased replication is more appropriate than the distributed cache.

We can find the number of map slots with JobClient#getClusterStatus().getMaxMapTasks().  We might set the replication to the square root of that.  This should not overload the namenode worse than any other job.
, In general, I think the size of this file distcp_src_files would not consume many hdfs blocks space.

WIth thousands of nodes in cluster(say 4000), even sqrt of getMaxMapTasks() would be 89(i.e. sqrt(8000)), which is a big number for replication. Is that still OK fornamenode's perf with many distcp jobs running parallelly, each creating this file with this many replicas ?
, > Is that still OK fornamenode's perf ?

This should not be a problem for the namenode.  It would be best to write the file first with normal replication, then increase its replication, to avoid an overly-long HDFS write pipeline.

The rationale for sqrt is that a two-stage fanout is done: first from the original to the replicas, then from the replicas to the maps.  Sqrt(maps) uses approximately the same fanout factor at each stage, minimizing the number of datanode clients (the presumed bottleneck here)., Attaching patch for increasing the replication of _distcp_src_files to sqrt(maxMapsOnCluster).

Please review and provide your comments., Doug,   Would it be better if distcp sets dfs.client.max.block.acquire.failures to sqrt(maxMapsOnCluster) as DFSClient.DFSInputStream.chooseDataNode() compares number of failures with this config property(default value of 3) ? But we need that only for this file _distcp_src_files., > Would it be better if distcp sets dfs.client.max.block.acquire.failures to sqrt(maxMapsOnCluster)

The hope is that by increasing the replication there won't be many failures: it shouldn't have to try every replica.  So 3 should probably still be fine, I think., Some comments on the patch:
 - FSShell should not be used to increase replication, rather just call FileSystem#setReplication().
 - The replication should be set immediately after the file is closed, so that it has a chance to get replicated while duplicates are checked before the job is submitted.

, Attaching patch with suggested changes., The replication number should also depend on the number of maps (see DistCp.setMapCount(..)).  It does not make sense to set replication to 89 if there are only 10 maps., Thanks Nicholas for pointing it out.

Attached new patch with the suggested change., +1 patch looks good.  Not sure if it is easy to add a unit test., Looks difficult to check the replication of this file from testcase as we need to check the replication while the distcp job is running.
Manually tested with log message that display the replication factor of this file after setReplication() is done for different values by changing the code of testMapCount() in TestCopyFiles., I also think that it is not easy to create new unit tests for this.  Manual tests are good enough.  Could you run test-patch and the unit tests, and then post the results?, ant test-patch gave

     [exec] -1 overall.
     [exec]
     [exec]     +1 @author.  The patch does not contain any @author tags.
     [exec]
     [exec]     -1 tests included.  The patch doesn't appear to include any new or modified tests.
     [exec]                         Please justify why no tests are needed for this patch.
     [exec]
     [exec]     +1 javadoc.  The javadoc tool did not generate any warning messages.
     [exec]
     [exec]     +1 javac.  The applied patch does not increase the total number of javac compiler warnings.
     [exec]
     [exec]     +1 findbugs.  The patch does not introduce any new Findbugs warnings.
     [exec]
     [exec]     +1 Eclipse classpath. The patch retains Eclipse classpath integrity.
     [exec]
     [exec]     +1 release audit.  The applied patch does not increase the total number of release audit warnings.


Unit tests passed on my linux machine., I have committed this.  Thanks, Ravi!, Integrated in Hadoop-Mapreduce-trunk #15 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-Mapreduce-trunk/15/])
    ]