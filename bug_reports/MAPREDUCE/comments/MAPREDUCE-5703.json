[The problem is likely being that while JHS is copying the history file, but the files are not successfully written and JHS certainly doesn't have the info about the job. And the JobClient is querying the JHS about the job after it gets known from RM that the job is finished. Since the job doesn't exist in JHS, it throws NPE. But only restarting one DN shouldn't affect so much, only if this is the only DN in the cluster., @Jian

Yes , the issue was caused due to write failure at the DN and i had only one data node. Thanks for review., We have a cluster with 3 data nodes, but due to some reason, the job history was not persisted successfully as shown in the AM log.

-------------------------------------------------------------LOG----------------------------------------------------------------------
 ERROR [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Error writing History Event: org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent@1f2cfc93
java.io.IOException: All datanodes 10.253.21.212:9200 are bad. Aborting...
        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1140)
        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:936)
        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:491)
----------------------------------------------------------------------------------------------------------------------------------------

As a result, the job failed and threw NPE. The bad thing is the job was marked as failed even though the job actually finished successfully. 

This means this NPE could happen frequently if the cluster size is not big and it is not an edge case. 

The method GetTaskAttemptCompletionEventsResponse() fetched a Job by calling verifyAndGetJob(), but it never checked if job was null or not, which was the root cause of this issue.

    public GetTaskAttemptCompletionEventsResponse
        getTaskAttemptCompletionEvents(
            GetTaskAttemptCompletionEventsRequest request) throws IOException {
      JobId jobId = request.getJobId();
      int fromEventId = request.getFromEventId();
      int maxEvents = request.getMaxEvents();

      Job job = verifyAndGetJob(jobId);
      GetTaskAttemptCompletionEventsResponse response = recordFactory.newRecordInstance(GetTaskAttemptCompletionEventsResponse.class);
      response.addAllCompletionEvents(Arrays.asList(job.getTaskAttemptCompletionEvents(fromEventId, maxEvents)));
      return response;
    }

Since people may face this problem often for a small cluster, what would be the best way to fix this issue then? Do retry when save the job to HDFS? Or something else?

, Hi Jian He, could you please response to this jira? We have seen this issue couple times in our production clusters. You could give us a hint on what would be the best way to resolve this issue and then we can work on a fix for this. Thanks in advance.
, I have run into the same problem many times before.
 - The reason why AM would fail writing the history-file is because it goes out of good nodes to write to. The reports on this JIRA (1 node cluster, 3 nodes cluster) point to this.
 - The reason why RM says it succeeded, but JHS cannot say so is the same as that of MAPREDUCE-5547.

Closing as dup. Please revert back if you disagree.]