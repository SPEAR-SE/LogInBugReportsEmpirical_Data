[HADOOP-6467 has fixed this., I am hitting similar issue.

I am using a HAR jar given by Mahadev separately with a 20.100 cluster


Caused by: java.lang.IllegalArgumentException: Offset 0 is outside of file (0..-1)
        at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getBlockIndex(FileInputFormat.java:301)
        at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:260)
        at org.apache.hadoop.zebra.mapreduce.TableInputFormat.getRowSplits(TableInputFormat.java:829)
        at org.apache.hadoop.zebra.mapreduce.TableInputFormat.getSplits(TableInputFormat.java:1033)
        at org.apache.hadoop.zebra.mapreduce.TableInputFormat.getSplits(TableInputFormat.java:966)
        at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:258)
        ... 14 more

, @Nicholas: HADOOP-6467 didn't fix that because the FileBlockLocations object it reported didn't have any information about the file. Some input formats rely on that info to calculate the splits and that's what triggered the error. Initially Paul (reporter) solved the problem by creating a virtual single block for the FileBlockLocations with correct info for the file (I think the important ones were block size and offset), and returning it. Paul's patch missed unit tests and I think that's why he didn't upload it.

Later, Dmytro proposed a better solution in which he actually reported the right block locations based on the part file. He created MAPREDUCE-1752 to discuss that. His patch will probably fix this JIRA as well., Thanks for the info, Rodrigo., Seems that MAPREDUCE-1752 fixed this.  Please feel free to reopen this if it is still a problem.]