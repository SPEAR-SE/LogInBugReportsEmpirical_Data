[Some more info about the epoll fd:

[todd@XXXX ~]$ ls -l /proc/17218/fd/157
lrwx------. 1 todd todd 64 Mar 15 21:56 /proc/17218/fd/157 -> socket:[3219051144]
[todd@XXXX ~]$ cat /proc/17218/fdinfo/157
pos:    0
flags:  02
[todd@XXXX ~]$ lsof -p 17218 | grep ' 157'
java    17218 todd  157u  unix 0xffff8800abb36380        0t0 3219051144 socket
, Googling around, looks like it's related to http://jira.codehaus.org/browse/JETTY-937. I added a comment to that JIRA.  (this was experienced with Jetty 6.1.26, Java 6u24), This doesn't seem to be jetty problem per se. More like a bug in nio. I see it a lot lately in the rpc layer. Lots of different use cases with the same result:
{code}
java.lang.Thread.State: RUNNABLE
	at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
	at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:215)
	at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:65)
	at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:69)
	- locked <0x00002aaab3dd8760> (a sun.nio.ch.Util$1)
	- locked <0x00002aaab3dd83a0> (a java.util.Collections$UnmodifiableSet)
	- locked <0x00002aaab3dd82e8> (a sun.nio.ch.EPollSelectorImpl)
	at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:80){code}
If anybody found a work around please share., Though on the surface they appear different, I think this is also caused by the same underlying JVM bug as MAPREDUCE-2389. The JVM bug in question causes a spurious dup2() call which overwrites an open fd. In this case, it's overwriting the epoll fd. In the case of MAPREDUCE-2389, it's overwriting an fd corresponding to a spill record, Konstantin: downgrading to Jetty 6.1.14 seems to be an effective workaround. Unfortunately it opens you up to some XSS security holes, but in some clusters that might be preferable :), Hi:
On my cluster, one TT also stuck. It's not responding to any HTTP connections 

1> the thread stack info:

"1989360587@qtp-1863318328-0 - Acceptor0 SelectChannelConnector@0.0.0.0:10060" prio=10 tid=0x00007fb9fc2a6800 nid=0x612e runnable [0x00007fba0015b000]
   java.lang.Thread.State: RUNNABLE
	at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
	at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:210)
	at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:65)
	at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:69)
	- locked <0x00007fba14758c70> (a sun.nio.ch.Util$1)
	- locked <0x00007fba14758c58> (a java.util.Collections$UnmodifiableSet)
	- locked <0x00007fba124d8aa8> (a sun.nio.ch.EPollSelectorImpl)
	at sun.nio.ch.SelectorImpl.selectNow(SelectorImpl.java:88)
	at org.mortbay.io.nio.SelectorManager$SelectSet.doSelect(SelectorManager.java:652)
	at org.mortbay.io.nio.SelectorManager.doSelect(SelectorManager.java:192)
	at org.mortbay.jetty.nio.SelectChannelConnector.accept(SelectChannelConnector.java:124)
	at org.mortbay.jetty.AbstractConnector$Acceptor.run(AbstractConnector.java:708)
	at org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:582)

2> I use netstat cmd to check the 50060 port state, and find 83 connections are on CLOSE_WAIT or SYN_RECV state.
tcp        0      0 172.16.4.7:50060        172.16.4.6:52526        SYN_RECV    
tcp        0      0 172.16.4.7:50060        172.16.4.3:41380        SYN_RECV    
tcp        0      0 172.16.4.7:50060        172.16.4.5:41908        SYN_RECV    
tcp        0      0 172.16.4.7:50060        172.16.4.6:52495        SYN_RECV    
tcp        0      0 172.16.4.7:50060        172.16.4.8:39167        SYN_RECV    
tcp        0      0 172.16.4.7:50060        172.16.4.8:38799        SYN_RECV    
tcp        0      0 172.16.4.7:50060        172.16.4.6:52416        SYN_RECV    
tcp        0      0 172.16.4.7:50060        172.16.4.6:47010        SYN_RECV    
tcp        0      0 172.16.4.7:50060        172.16.4.5:42449        SYN_RECV    
tcp        0      0 172.16.4.7:50060        172.16.4.2:50107        SYN_RECV    
tcp        0      0 172.16.4.7:50060        172.16.4.6:52558        SYN_RECV    
tcp        0      0 172.16.4.7:50060        172.16.4.6:52402        SYN_RECV    
tcp        0      0 172.16.4.7:50060        172.16.4.6:52085        SYN_RECV    
tcp        0      0 172.16.4.7:50060        172.16.4.2:45092        SYN_RECV    
tcp        0      0 172.16.4.7:50060        172.16.4.3:41542        SYN_RECV    
tcp        0      0 172.16.4.7:50060        172.16.4.3:55977        SYN_RECV    
tcp        0      0 172.16.4.7:50060        172.16.4.4:43743        SYN_RECV    
tcp        0      0 172.16.4.7:50060        172.16.4.5:42118        SYN_RECV    
tcp        0      0 172.16.4.7:50060        172.16.4.2:44535        SYN_RECV    
tcp        0      0 172.16.4.7:50060        172.16.4.3:41890        SYN_RECV    
tcp        0      0 172.16.4.7:50060        172.16.4.3:56001        SYN_RECV    
tcp        0      0 172.16.4.7:50060        172.16.4.5:42057        SYN_RECV    
tcp        0      0 172.16.4.7:50060        172.16.4.3:56121        SYN_RECV    
tcp        0      0 172.16.4.7:50060        172.16.4.8:39173        SYN_RECV    
tcp        0      0 172.16.4.7:50060        172.16.4.8:38937        SYN_RECV    
tcp        0      0 172.16.4.7:50060        172.16.4.2:44992        SYN_RECV    
tcp      129      0 :::50060                :::*                    LISTEN      
tcp      243      0 172.16.4.7:50060        172.16.4.7:35878        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.7:50557        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.8:33735        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.6:40670        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.5:45702        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.3:50653        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.3:50538        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.6:48535        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.7:52049        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.5:45529        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.7:38282        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.7:51933        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.8:33008        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.2:50188        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.8:47068        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.3:50638        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.7:50629        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.3:50676        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.4:45076        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.7:37301        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.7:35873        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.8:33733        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.5:45487        CLOSE_WAIT  
tcp        1      0 172.16.4.7:50060        172.16.4.8:47078        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.7:51939        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.3:50578        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.7:50630        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.1:35526        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.1:57037        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.6:52755        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.1:51096        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.2:50207        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.7:51951        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.7:35876        CLOSE_WAIT  
tcp        1      0 172.16.4.7:50060        172.16.4.4:42804        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.6:52771        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.7:52110        CLOSE_WAIT  
tcp        1      0 172.16.4.7:50060        172.16.4.4:42686        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.5:45688        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.3:50590        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.6:48497        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.7:37370        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.8:33010        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.7:51908        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.8:33003        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.5:45469        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.8:33002        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.8:33737        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.2:50198        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.6:52746        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.8:47067        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.7:37300        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.3:50705        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.7:38319        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.6:47550        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.1:56333        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.7:52004        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.8:47065        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.6:52814        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.8:33739        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.8:33734        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.8:47069        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.8:47063        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.7:38392        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.7:50716        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.4:45128        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.7:38317        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.8:33007        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.8:33006        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.8:33736        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.2:49722        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.2:50185        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.6:52820        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.5:45273        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.2:49730        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.3:49957        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.6:47477        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.5:45720        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.7:52011        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.7:52079        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.3:50583        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.7:52037        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.5:45437        CLOSE_WAIT  
tcp      243      0 172.16.4.7:50060        172.16.4.2:50168        CLOSE_WAIT  
, Adding some info:
1>TT throw many exceptions of EofException and IllegalStateException:
2012-05-17 15:52:42,509 WARN  mortbay.log (Slf4jLog.java:warn(76)) - Committed before 410 getMapOutput(attempt_201205061050_13074_m_000167_0,9) failed :
org.mortbay.jetty.EofException: timeout
	at org.mortbay.jetty.AbstractGenerator$Output.blockForOutput(AbstractGenerator.java:548)
	at org.mortbay.jetty.AbstractGenerator$Output.flush(AbstractGenerator.java:572)
	at org.mortbay.jetty.HttpConnection$Output.flush(HttpConnection.java:1012)
	at org.mortbay.jetty.AbstractGenerator$Output.write(AbstractGenerator.java:651)
	at org.mortbay.jetty.AbstractGenerator$Output.write(AbstractGenerator.java:580)
	at org.apache.hadoop.mapred.TaskTracker$MapOutputServlet.doGet(TaskTracker.java:3179)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:511)
	at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:401)
	at org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216)
	at org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:182)
	at org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:766)
	at org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:450)
	at org.mortbay.jetty.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:230)
	at org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)
	at org.mortbay.jetty.Server.handle(Server.java:326)
	at org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:542)
	at org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:928)
	at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:549)
	at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:212)
	at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404)
	at org.mortbay.io.nio.SelectChannelEndPoint.run(SelectChannelEndPoint.java:410)
	at org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:582)

2012-05-17 15:52:42,510 INFO  TaskTracker.clienttrace (TaskTracker.java:doGet(3211)) - src: 172.16.4.7:10060, dest: 172.16.4.8:47139, bytes: 655360, op: MAPRED_SHUFFLE, cliID: attempt_201205061050_13074_m_000167_0
2012-05-17 15:52:42,510 ERROR mortbay.log (Slf4jLog.java:warn(87)) - /mapOutput
java.lang.IllegalStateException: Committed
	at org.mortbay.jetty.Response.resetBuffer(Response.java:1023)
	at org.mortbay.jetty.Response.sendError(Response.java:240)
	at org.apache.hadoop.mapred.TaskTracker$MapOutputServlet.doGet(TaskTracker.java:3202)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:511)
	at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:401)
	at org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216)
	at org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:182)
	at org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:766)
	at org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:450)
	at org.mortbay.jetty.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:230)
	at org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)
	at org.mortbay.jetty.Server.handle(Server.java:326)
	at org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:542)
	at org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:928)
	at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:549)
	at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:212)
	at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404)
	at org.mortbay.io.nio.SelectChannelEndPoint.run(SelectChannelEndPoint.java:410)
	at org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:582)


2> The 83 connections of CLOSE_WAIT status always exist, and not disappear., Encountered this on the 1.x line.

# post-1.1 could be time to move up to Jetty-7 via HADOOP-8515
# I could see how the TT could itself detect this (GET self on one thread with watcher on another), but I'm not sure if it could then react to it through a Jetty restart. It could maybe exit with an error message & rely on other monitoring agents to kick in. Right now it can still be heartbeating, which stops the JT realising there are problems., I see the same errors with hadoop 2.4.1 on FreeBSD:

2014-07-06 16:06:27,063 INFO  [1707749244@qtp-1646583765-1 - Acceptor0 SelectChannelConnector@nezabudka3-00.yandex.ru:8088] mortbay.log (Slf4jLog.java:info(67)) - org.mortbay.io.nio.SelectorManager$SelectSet@2e0c0189 JVM BUG(s) - injecting delay57 times
2014-07-06 16:06:27,063 INFO  [1707749244@qtp-1646583765-1 - Acceptor0 SelectChannelConnector@nezabudka3-00.yandex.ru:8088] mortbay.log (Slf4jLog.java:info(67)) - org.mortbay.io.nio.SelectorManager$SelectSet@2e0c0189 JVM BUG(s) - recreating selector 57 times, canceled keys 915 times
2014-07-06 16:07:27,064 INFO  [1707749244@qtp-1646583765-1 - Acceptor0 SelectChannelConnector@nezabudka3-00.yandex.ru:8088] mortbay.log (Slf4jLog.java:info(67)) - org.mortbay.io.nio.SelectorManager$SelectSet@2e0c0189 JVM BUG(s) - injecting delay58 times

Why Jetty can't be updated to at least version 7 (https://issues.apache.org/jira/browse/HADOOP-8515 has a patch for more that a year)?, HADOOP-10075 is the latest  "update Jetty" issue; it's dependent on the forthcoming "Java7+ only" switch.

Jetty got pulled from the shuffle phase of MapReduce so does not surface there any more. What were you doing when this surfaced?, I was running TeraSort program (from hadoop-examples.jar).  This error appeared in NameNode application.]