[Cluster setup -  : 
Cluster Capacity = 204 maps, 204 reduces
4 queues 
Q1 Capacity Percent= 40
Q2 Capacity Percent= 40
Q3 Capacity Percent= 40
Q4 Capacity Percent= 40

Each queue has user limit=100%
Submitted 8 jobs to each queue. Total 32 sleep jobs were submitted with each job having maps=10000 (sleep time 5 secs), reduce=2 (sleep time 1 min).
All jobs were initialized. Out which maps of 4 maps started running. When at least 1000 maps of each job completed, re-started JobTracker.
After recovery of JobTracker, waited up to the time when 4 jobs got completed. Killed all remaining 28 jobs.
All jobs got killed successfully.
JobTracker webui displayed all killed jobs under failed jobs list. hadoop job -list all also displays the status of 28 killed job as 5.
While browsing through jobqueue_details.jsp pages of queues found that 2 jobs which were killed have not been removed from queue of capacity scheduler. Maps of both jobs were running before kill was sent to them.
To check that cluster should be blocked because of this, submitted 3 more jobs to each queue where 2 killed were listed and verified the newly submitted jobs ran successfully.
Waited up to 20 mins before shutting down the cluster
, Analysis of the problem:
When the job tracker is restarted , RecoveryManager tries to recover the job from job history.RecoveryMaanger instantiates the JobInProgress object and sets its startTime as System.currentTimeMillis.In JobInProgress constructor JobStatus startTime is set as JIP's startTime .RecoveryManager fetches startTime information from job history and updates the JIP's startTime(remember this change is not propagated to JobStatus startTime) , hence now Jobstatus has old value of startTime . These Job statuses are used in JobQueuesManager to categorize jobs based on the state they are in. The data structure in JobQueuesManager(waitingJobs) uses startTime as the comparator.As waitingJobs has old startTime value , it has the old entry.
Whenever we try to do "hadoop job -list" JobTracker's getJobStatus method is called , this sets the JobStatus startTime value with JobInProgress startTime value , now at this point , startTime values in JIP and JobStatus are consistent, but the startTime value in waitingJobs in JobQueueManager is stale . Hence when we try to remove the jobs which are completed(Completed/killed/failed , for example issueing "hadoop job -kill <>" command ) from waitingJobs() nothing is removed as comparator startTime is changed., Beautiful! (Sorry couldn't resist myself..), Closing this as won't fix.]