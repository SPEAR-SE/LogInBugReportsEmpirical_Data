[I think the best approach would be to let the partitioner command take key/value pairs as input (just like the mapper command) and make it output a (new) key for each pair, which then gets hashed to determine the partition number for the pair. Any other thoughts or comments on this?, Klaas, could you please shed some light on how you are thinking of implementing this? I guess all what you are saying happens in the framework's PipeMapper, is that right?, I haven't thought much about the details yet, but the easiest way to implement it might be to add a {{PipePartitioner}} that extends {{PipeMapper}} yes, much like {{PipeCombiner}} is an extension of {{PipeReducer}}. The {{PipePartitioner}} would have to implement {{Partitioner}}, however, so it would also have to add an {{int getPartition(Object key, Object value, int numPartitions)}} method, which could work somewhat similarly to the {{void map(...)}} method. The way I see it, this method would use {{inWriter_}} to write the key and value to the standard input of the partitioner command and then rely on {{outReader_}} to read the key and value returned for this pair and supply them to the {{int getPartition(...)}} method of a wrapped partitioner, i.e., simplified it could look something like:

{code}
public int getPartition(K2 key, V2 value, int numPartitions) {
  if (!ignoreKey) {
    inWriter_.writeKey(key);
  }
  inWriter_.writeValue(value);
  if (!outReader_.readKeyValue()) {
    throw RuntimeException("partioner must output one key/val pair for each input pair");
  }
  Object newKey = outReader_.getCurrentKey();
  Object newValue = outReader_.getCurrentValue();
  return realPartitioner.getPartition(newKey, newValue, numPartitions);
}
{code}

Streaming users could then easily define partitioners by specifying a partitioner command that transforms key/value pairs in such a way that the wrapped partitioner shows the desired behavior. The default wrapped partitioner should probably be {{HashPartitioner}}. 

Does this make sense to you, Devaraj?, I am not able to clearly see how this whole thing would fit in the MR model in the implementation we have in Hadoop. So the way it works is that the outputcollector thread in PipeMapper collects the key/vals from the streaming mapper and emits them to the framework. The framework part of the data-path, MapTask.MapOutputBuffer.collect, then invokes getPartition on the key/value and dumps it in the key/val buffer (which at a later point is sorted and spilled to disk).
In the approach you outlined, the Partitioner would update the key/value. What would be collected by MapTask? We'd like to keep the original key/value intact, right? Where would the getPartition get called?
Another approach for implementing this feature is that you have a special Java implementation of the partitioner that in its getPartition method writes to the command and reads back the partition number. This model will be similar to the PipeMapper/Reducer models. The main difference would be that the getPartition would be a blocking call (as opposed to the map or reduce where the write-to and read-from the process is asynchronous). 
Thoughts?, Yeah, I was actually suggesting such a special Java implementation that writes to and reads from a command, but instead of letting the command generate the partition number directly, I thought it might make sense to let it output a key or even a key/value pair (which are completely separate from the other MapReduce keys and values) and determine the partition from that. So instead of generating the same number for pairs that need to go to the same reducer, the partitioner command would just have to generate the same key for those pairs. The benefits of such an approach would be that
# it's simpler (the partitioner command doesn't need to know how many partitions there are),
# it might be easier to define a suitable partitioner command (when using shell tools it might be easier to output a string instead of a specific number for example),
# we could reuse more code that's already there (if we let the the partitioner command output both a key and a value and pass that on to a wrapped partitioner, like in the code sample I gave above, we even wouldn't need any additional reading/writing logic)., bq. it's simpler (the partitioner command doesn't need to know how many partitions there are),
But still, the command needs to have an idea of how many partitions there are, isn't it? Or maybe, you are saying that it's up to the command developer to assume a certain partition count and implement the command... I agree that it's simple but am not sure whether all use cases would be covered with this model..

bq. we could reuse more code that's already there (if we let the the partitioner command output both a key and a value and pass that on to a wrapped partitioner, like in the code sample I gave above, we even wouldn't need any additional reading/writing logic).
What did you mean by "we wouldn't need any additional reading/writing logic" ? There is at least that much reading/writing as your code outlined, ist it?
, bq. But still, the command needs to have an idea of how many partitions there are, isn't it? Or maybe, you are saying that it's up to the command developer to assume a certain partition count and implement the command... I agree that it's simple but am not sure whether all use cases would be covered with this model..

Maybe it doesn't cover every possible use case, but it should cover the most common ones I think, and in case of streaming it might be more important to implement something that's very simple and easy to use instead of trying to make things as general as possible. Personally, I don't think I ever implemented a partitioner that couldn't be replaced by a command that outputs keys which then get hashed to determine the partition number. 

bq. What did you mean by "we wouldn't need any additional reading/writing logic" ? There is at least that much reading/writing as your code outlined, ist it?

I meant that {{org.apache.hadoop.streaming.io.InputWriter}} and {{org.apache.hadoop.streaming.io.OutputReader}} wouldn't have to be extended in any way.

Having said that, extending {{InputWriter}} and {{OutputReader}} is perfectly feasible, so if you think it's better to work with partition numbers directly we could also implement something like:
{code}
public int getPartition(K2 key, V2 value, int numPartitions) {
  if (!ignoreKey) {
    inWriter_.writeKey(key);
  }
  inWriter_.writeValue(value);
  inWriter_.writeNumber(numPartitions);
  return outReader_.readNumber();
}
{code}
This would definitely be more flexible and might also be more efficient in certain cases, so maybe it is indeed preferable. I guess that a partitioner command would also be a rather advanced feature anyway, so maybe it's fine to expect a bit more effort from the people who use it and let it determine the partition number directly., It would be valuable to have a non-java streaming partitioner. It should be executed once per map task, and should take as input (through stdin), the text-encoded key value pairs (one per line, separated by field separator), and output on stdout a number (again, text-encoded) for each key value pair.

Number of partitions, i.e. number of reducers should already be available to this streaming partitioner as the environment variable mapred_reduce_tasks. So, no need to pass it in each line.

Partitioner need not be an "advanced" feature. Think about a parallel bucketing operation, where number of buckets is predetermined, so the mapper makes a decision where each value should go. In this case, the key is a partition ID, and value is the record to be bucketed. HashBased partitioner of course does not work in this case. But a streaming partitioner, such as 'cut -f1' is what is needed., Ok, so we should let the partitioner command determine the partition number directly then.

Further comments:
* Can we be sure that the number of partitions if always equal to the number of reducers under all circumstances?
* The format of the data that gets written to and read from the partitioner command should, of course, depend on the used {{InputWriter}} and {{OutputReader}} classes, but Milind's suggestion sounds good for the text-based case., I don't know most of the thing which you guys were saying but I want to express clearly what thing I want from this partitioner function.

I have been trying to study mapreduce with python and while using python I have to pass the python codes as command and also provide no of reducers in command only.

Can you please implement what you suggested about this "it might be easier to define a suitable partitioner command (when using shell tools it might be easier to output a string instead of a specific number for example),"  as @Klass suggested above.]