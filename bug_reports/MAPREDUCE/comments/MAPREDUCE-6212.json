[Since issue is in MRAppMaster, moving to MapReduce project., It's more like a configuration issue instead of bug, [~maidh91], could you provide more information about what's the "basic configuration"?., This seems like an environmental issue.

JIRA is a place for tracking potential bugs in the project, not usage questions. Can you please use the user mailing lists for help with this (http://hadoop.apache.org/mailing_lists.html#User)? Thanks., Version: Hadoop 2.6.0
Cluster: grey

Master: grey5
Slaves: grey5, grey6, grey7, grey8, grey9, grey10
System info per node: 12 CPU, 24GB RAM, 6 x 500GB Hard disks, 1000Mbps bandwidth

Update .bashrc and .bash_profile

# cat .bashrc
#!/bin/bash
# unset all HADOOP environment variables
env | grep HADOOP | sed 's/.*\(HADOOP[^=]*\)=.*/\1/' > un_var
while read line; do unset "$line"; done < un_var
rm un_var

export JAVA_HOME="/usr/java/latest/"
export HADOOP_PREFIX="/home/maidinh/hadoop2/hadoop-2.6.0"
export HADOOP_YARN_USER="maidinh"

export HADOOP_HOME="$HADOOP_PREFIX"
export HADOOP_CONF_DIR="$HADOOP_PREFIX/etc/hadoop"
export HADOOP_PID_DIR="$HADOOP_PREFIX"
export HADOOP_LOG_DIR="$HADOOP_PREFIX/logs"
export HADOOP_OPTS="$HADOOP_OPTS -Djava.io.tmpdir=$HADOOP_PREFIX/tmp"

export YARN_HOME="$HADOOP_PREFIX"
export YARN_CONF_DIR="$HADOOP_PREFIX/etc/hadoop"
export YARN_PID_DIR="$HADOOP_PREFIX"
export YARN_LOG_DIR="$HADOOP_PREFIX/logs"
export YARN_OPTS="$YARN_OPTS -Djava.io.tmpdir=$HADOOP_PREFIX/tmp"
# cat .bash_profile
#!/bin/bash
if [ -f ~/.bashrc ]; then
   source ~/.bashrc
fi
Configure core-site.xml

<property>
  <name>fs.defaultFS</name>
  <value>hdfs://grey5:9000</value>
</property>
 
<property>
  <name>hadoop.tmp.dir</name>
  <value>/home/maidinh/hadoop2/hadoop-data</value>
</property>
Configure hdfs-site.xml

<property>
  <name>dfs.namenode.name.dir</name>
  <value>/home/maidinh/hadoop2/nn</value>
</property>
 
<property>
  <name>dfs.datanode.data.dir</name>
  <value>/data1/maidinh/hadoop2/dn,/data2/maidinh/hadoop2/dn,/data3/maidinh/hadoop2/dn</value>
</property>
Configure yarn-site.xml

<property>
  <name>yarn.resourcemanager.hostname</name>
  <value>grey5</value>
</property>
 
<property>
  <name>yarn.nodemanager.local-dirs</name>
  <value>/data4/maidinh/hadoop2/yarn-data,/data5/maidinh/hadoop2/yarn-data,/data6/maidinh/hadoop2/yarn-data</value>
</property>
 
<property>
  <name>yarn.nodemanager.log-dirs</name>
  <value>/data4/maidinh/hadoop2/yarn-logs,/data5/maidinh/hadoop2/yarn-logs,/data6/maidinh/hadoop2/yarn-logs</value>
</property>
 
<property>
  <name>yarn.nodemanager.aux-services</name>
  <value>mapreduce_shuffle</value>
</property>
Configure mapred-site.xml

<property>
  <name>mapreduce.framework.name</name>
  <value>yarn</value>
</property>
 
<property>
  <name>mapreduce.jobhistory.address</name>
  <value>grey5:10020</value>
</property>
<property>
  <name>mapreduce.jobhistory.webapp.address</name>
  <value>grey5:19888</value>
</property>
 
<property>
  <name>mapreduce.jobtracker.address</name>
  <value>grey5:50030</value>
</property>
Configure slaves

grey5
grey6
grey7
grey8
grey9
grey10, I have just updated the description with my configs.

Actually, I ran successfully in my local machine under a normal user. However, in the cluster, it returns that error. I spent a whole week but still no solution.

Please help me. Thank you so much., Hi [~maidh91].  This error would happen if the process was successful in opening libhadoop.so, but then the {{anchorNative}} function did not exist in that library.  I recommend making sure that the correct version of libhadoop.so is deployed on all nodes in your cluster.  The native code build version must match with the rest of your Hadoop deployment (the Java bits).

I agree with Vinod that this will end up being some kind of environmental issue.  I recommend contacting user@hadoop.apache.org if you still need further help after trying the above.]