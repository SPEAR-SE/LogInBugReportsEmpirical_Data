[Moving this to the MAPREDUCE project since the done_intermediate directory is specific to MapReduce and is not something YARN knows about.  We'll either have to change the MapReduce ApplicationMaster to treat this error more gracefully and/or change the mapreduce job client to check the permissions of the directory before submitting., Thanks [~jlowe] for stepping in.

I prefer the MR client to catch it before the submission. what do you think? Do you see any issue?
, The main issue is it adds yet more stuff for the job client to do before submitting the job when the AM is already doing the work in this area (i.e.: trying to create the directory in question).  This should be a relatively rare occurrence as the intermediate base directory not being writable indicates the cluster wasn't setup properly.  Actually I'm a bit curious as to how this even occurred in the first place.  The history server should have setup the proper permissions when it started.  [~tthompso] can you elaborate more on how the intermediate directory happened to have the wrong permissions?  I'm wondering if there's a related bug in the history server that needs to be fixed.

Arguably this wouldn't be a big deal if we solved the larger issue of diagnostics from the AM crash not making it back to the job client.  The AM logs should already be stating what's going wrong (e.g.: "Error creating user intermediate history done directory" exception and cause).  If the user saw that error message from the client when the job crashed then it would be clearer to the user why the job failed.  YARN-675 was supposed to help this at least somewhat, and providing proper diagnostics would also help similar issues like the AM crashing when metainfo split size is exceeded, see MAPREDUCE-4937., I agree, the specific issue of the directory permissions being wrong is not really the issue here.  It becomes very hard to find AM logs for a failed AM because clicking the "logs" link from the RM page takes you to the NM it executed on and with log aggregation, the logs get pushed to HDFS very quickly, and then the NM just throws an error that the container doesn't exist.  So the only way to find your logs is to browse HDFS and find them manually.  So maybe the better fix here is to get the RM to pull the logs off of HDFS instead of linking to the NM?  I'm not sure who's supposed to be handling log viewing besides the JHS which is specific to M/R jobs.

Also I got in this situation after setting up a new cluster from scratch and missing the permissions on a dir that didn't have world r/x.  The only reason I noticed it was because I knew to check those as a possible reason why an AM wouldn't launch from past experience.  The AM did properly throw the error, but it just never made it back to the user because the stderr is redirected to a file that is pushed to HDFS after it exits., bq.  It becomes very hard to find AM logs for a failed AM because clicking the "logs" link from the RM page takes you to the NM it executed on and with log aggregation, the logs get pushed to HDFS very quickly, and then the NM just throws an error that the container doesn't exist.

This is clearly a bug.  We run with log aggregation and routinely have users debugging failed AM startups by clicking on the AM log links.  The link goes to the NM which re-directs to the history server and it shows the logs.  If this isn't working then there's either a regression or the cluster isn't configured properly.  Is yarn.log.server.url configured properly so the NM can redirect to the log server after logs have been aggregated?, bq. So maybe the better fix here is to get the RM to pull the logs off of HDFS instead of linking to the NM?

The problem with this approach is that the RM may have difficulty knowing when log aggregation has completed to know whether it should continue referencing the NM or redirect to the log server.

bq.  I'm not sure who's supposed to be handling log viewing besides the JHS which is specific to M/R jobs.

The JHS can serve logs even for non-MR jobs.  It was a hack to provide an aggregated log server before one existed.  Now in recent 2.x I believe the YARN Application History/Timeline Server can serve up logs as well.  On our 0.23 clusters we are using the JHS to serve up aggregated logs, and yarn.log.server.url is configured to {noformat}http://jhs-server-name:port/jobhistory/nmlogs{noformat}, Let me double check {{yarn.log.server.url}}, I think you're on to something., So I didn't have {{yarn.log.server.url}} set, and after setting that log redirection off the NM works, yay.  It would still be nice to have a more meaningful message make it back to the RM though, because right now you have to go to the GUI to find the error message, the console just shows the generic shell exception message., Agreed the diagnostic message for crashed AMs should be better.  Wondering if this is effectively a dup of  YARN-675, MAPREDUCE-4937, or some other JIRA already tracking this., Yeah, we can probably mark this as a duplicate of YARN-675, Thanks, Travis.  Resolving as a duplicate of YARN-675.]