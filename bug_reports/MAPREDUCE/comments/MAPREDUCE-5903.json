[I figured out when\where it happens.
If you use kerberized user impersonation when submitting MR job, we actually submit with user (lets say john) via yarn (or whatever kerberos principal, whose user also presented on the box). During the shuffle phase in public void messageReceived(ChannelHandlerContext ctx, MessageEvent evt) ShuffleHandler tries to read\write the map output file as john who ran the MR job. This is not going to work in case of user impersonation, when john is not presented on local box (e.g. he comes from ActiveDirectory), because the file from local FS cannot be read.

The fix is to use the JVM process owner instead of the user:
System.getProperty("user.name") in two methods: populateHeaders, sendMapOutput

{code:title=ShuffleHandler.java|borderStyle=solid}

protected void populateHeaders(List<String> mapIds, String outputBaseStr,
                                       String user, int reduce, HttpRequest request, HttpResponse response,
                                       boolean keepAliveParam, Map<String, MapOutputInfo> mapOutputInfoMap)
                throws IOException {
{
// Some code here......................
String processOwner = System.getProperty("user.name");
MapOutputInfo outputInfo = getMapOutputInfo(base, mapId, reduce, processOwner);
// Some code here......................
}
{code}
{code:title=ShuffleHandler.java|borderStyle=solid}
protected ChannelFuture sendMapOutput(ChannelHandlerContext ctx, Channel ch,
                                              String user, String mapId, int reduce, MapOutputInfo mapOutputInfo)
                throws IOException {
// Some code here......................
String processOwner = System.getProperty("user.name");
spill = SecureIOUtils.openForRandomRead(spillfile, "r", processOwner, null);
// Some code here......................
}
{code}, Hi [~grelaxus] 

I got the exception before, the root cause is I forgot to update {{container-executor.cfg}}, does it work for you?, Hi [~dapengsun],

Thanks for comment. To be more specific, do you mean 'allowed.system.users' field in container-executor.cfg?, I use user {{yarn}} to run {{ResourceManager}} and {{NodeManager}}, Here is my {{container-executor.cfg}} 
{noformat}
yarn.nodemanager.linux-container-executor.group=yarn
banned.users=bin
min.user.id=500
{noformat}
Please also check the following configuration in {{yarn-site.xml}}
{code:xml}
  <property>
    <name>yarn.nodemanager.aux-services</name>
    <value>mapreduce_shuffle</value>
  </property>
  <property>
    <name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name>
    <value>org.apache.hadoop.mapred.ShuffleHandler</value>
  </property>
  <property>
    <name>yarn.nodemanager.container-executor.class</name>
    <value>org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor</value>
  </property>
  <property>
    <name>yarn.nodemanager.linux-container-executor.group</name>
    <value>yarn</value>
  </property>
{code}, Hi,
I seem to have encountered this bug.How i can see the exception trace of YarnChild?, Hi [~Rajesh_Veeranki]
You'd better send out your configuration first. The reason for this problem is various., Hi Dapeng Sun,
Here's a snippet of my yarn-site.xml:
{code:title=yarn-site.xml|borderStyle=solid}
 <property>
    <name>yarn.nodemanager.aux-services</name>
    <value>mapreduce_shuffle</value>
  </property>
<property>
    <name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name>
    <value>org.apache.hadoop.mapred.ShuffleHandler</value>
  </property>
    <property>
    <name>yarn.nodemanager.log-aggregation.compression-type</name>
    <value>gz</value>
  </property>
    <property>
    <name>yarn.nodemanager.health-checker.script.path</name>
    <value>/etc/hadoop/conf/health_check</value>
  </property>
    <property>
    <name>yarn.nodemanager.container-executor.class</name>
    <value>org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor</value>
  </property>
<property>
  <name>yarn.nodemanager.linux-container-executor.group</name>
  <value>yarn</value>
</property>
 <property>
    <name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name>
    <value>org.apache.hadoop.mapred.ShuffleHandler</value>
  </property>
{code}
Here's my container-executor.cfg
{code:title=container-executor.cfg}
yarn.nodemanager.local-dirs=/grid/hadoop/yarn/local
yarn.nodemanager.linux-container-executor.group=yarn
yarn.nodemanager.log-dirs=/var/log/hadoop/yarn
banned.users=hfds,bin,0
min.user.id=0
{code}, It seems okay, please remove one of {{yarn.nodemanager.aux-services.mapreduce.shuffle.class}} 
You also used FQDN (likes {{node01.sundp.com}}) in your configuration, yes?
, Yeah, I am using FQDN.Its connecting to resource manager and maps are completed, but in reduce phase it just hangs forever., bq. This is not going to work in case of user impersonation, when john is not presented on local box (e.g. he comes from ActiveDirectory), because the file from local FS cannot be read.
If you using secure mode (kerberos + LinuxContainerExecutor), you need to have user-accounts on individual machines - that is the only supported setup today. Running it without setting up user-accounts on all nodes will not work., is this mean if i want use cluster in secure mode, i must add the all user that who may use my cluster on all nodes?, is this mean if i want use cluster in secure mode, i must add the all user that who may use my cluster on all nodes?, is this mean if i want use cluster in secure mode, i must add the all user that who may use my cluster on all nodes?, is this mean if i want use cluster in secure mode, i must add the all user that who may use my cluster on all nodes?, is this mean if i want use cluster in secure mode, i must add the all user that who may use my cluster on all nodes?, is this mean if i want use cluster in secure mode, i must add the all user that who may use my cluster on all nodes?, is this mean if i want use cluster in secure mode, i must add the all user that who may use my cluster on all nodes?, is this mean if i want use cluster in secure mode, i must add the all user that who may use my cluster on all nodes?, I am also facing the same exception when enabling LDAP for windows active directory in hadoop-2.6.0. , I just found a solution for this problem and it might be the root cause. It seems a user who submit a job should have admin privilege(user from active directory). 

NodeManager log says, 

Caused by: java.io.IOException: Owner 'Administrators' for path \tmp\hadoop-Seekay\nm-local-dir\usercache\Seekay\appcache\application_1423805493973_0004\output\at
tempt_1423805493973_0004_m_000000_1\file.out.index did not match expected owner
'Seekay'

the above exception throws in the below code

{code:title=SecureIOUtils.java|borderStyle=solid}
private static void checkStat(File f, String owner, String group, 
      String expectedOwner, 
      String expectedGroup) throws IOException {
		// Some code here......................
        UserGroupInformation ugi =
            UserGroupInformation.createRemoteUser(expectedOwner);
        final String adminsGroupString = "Administrators";
        success = owner.equals(adminsGroupString)
            && Arrays.asList(ugi.getGroupNames()).contains(adminsGroupString);
      } else {
        success = false;
      }
    // Some code here......................
  }
{code}

I just added the user to one of the admin group in active directory and then map reduce job ran successfully., My comment [above|https://issues.apache.org/jira/browse/MAPREDUCE-5903?focusedCommentId=14152049&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14152049] still holds. This is not supported today.

If you don't want to create user-accounts, then you can do the following
 - Find a local unix user to map all kerberos/LDAP authenticated users to
 - Set yarn.nodemanager.linux-container-executor.nonsecure-mode.limit-users to true
 - Set yarn.nodemanager.linux-container-executor.nonsecure-mode.local-user configuration to the local unix user.

For e.g., the default for this is nobody, which means all jobs will run as the nobody unix user. Clearly this will have other security concerns as all jobs run as the same user.

Closing this as invalid for now., Refer 
https://issues.apache.org/jira/browse/MAPREDUCE-3418, HI [~vinodkv]
I have hit the same bug while trying to setup the secure yarn cluster.
I dont see any similar configs for defaultcontainerexecutor.
So we have any workaround for this issue for defaultcontainerexecutor.


]