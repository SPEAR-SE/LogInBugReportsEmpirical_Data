[Good catch [~arpitgupta]!, I think we should just make a simple change to TT so that it doesn't get TIP to cleanup when it's re-init'ing. That should fix the race., [~acmurthy]

Thanks for the suggestion. Patch attached.

Also made changes to LinuxTaskController.java to log when there is a failure in delete.

We will now see logs like

{code}
id/4/hdp/mapred/local,/grid/5/hdp/mapred/local
2013-04-30 23:05:37,033 INFO org.apache.hadoop.mapred.LinuxTaskController: deleteAsUser: [/usr/lib/hadoop/libexec/../bin/task-controller, hrt_qa, /grid/0/hdp/mapred/local,/grid/1/hdp/mapred/local,/grid/2/hdp/mapred/local,/grid/3/hdp/mapred/local,/grid/4/hdp/mapred/local,/grid/5/hdp/mapred/local, 3, ]
2013-04-30 23:05:37,033 WARN org.apache.hadoop.mapred.LinuxTaskController: Exit code from task is : 255
2013-04-30 23:05:37,033 INFO org.apache.hadoop.mapred.LinuxTaskController: Output from deleteAsUser LinuxTaskController:
2013-04-30 23:05:37,033 INFO org.apache.hadoop.mapred.TaskController: Reading task controller config from /etc/hadoop/conf.empty/taskcontroller.cfg
2013-04-30 23:05:37,033 INFO org.apache.hadoop.mapred.TaskController: main : command provided 3
2013-04-30 23:05:37,033 INFO org.apache.hadoop.mapred.TaskController: main : user is hrt_qa
2013-04-30 23:05:37,033 INFO org.apache.hadoop.mapred.TaskController: Good mapred-local-dirs are /grid/0/hdp/mapred/local,/grid/1/hdp/mapred/local,/grid/2/hdp/mapred/local,/grid/3/hdp/mapred/local,/grid/4/hdp/mapred/local,/grid/5/hdp/mapred/local
2013-04-30 23:05:37,033 INFO org.apache.hadoop.mapred.TaskController: Unreadable directory /grid/4/hdp/mapred/local/taskTracker/hrt_qa/jobcache/job_201304302257_0002/attempt_201304302257_0002_m_000022_0. Skipping..
2013-04-30 23:05:37,033 INFO org.apache.hadoop.mapred.TaskController: Couldn't delete directory /grid/5/hdp/mapred/local/taskTracker/hrt_qa/jobcache/job_201304302257_0002/attempt_201304302257_0002_m_000022_0/output - No such file or directory
2013-04-30 23:05:37,034 INFO org.apache.hadoop.mapred.TaskController: rmdir of /grid/5/hdp/mapred/local/taskTracker/hrt_qa/ failed - Directory not empty
2013-04-30 23:05:37,034 ERROR org.apache.hadoop.mapred.TaskTracker: Got fatal exception while reinitializing TaskTracker: org.apache.hadoop.util.Shell$ExitCodeException:
        at org.apache.hadoop.util.Shell.runCommand(Shell.java:255)
        at org.apache.hadoop.util.Shell.run(Shell.java:182)
        at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:375)
        at org.apache.hadoop.mapred.LinuxTaskController.deleteAsUser(LinuxTaskController.java:281)
        at org.apache.hadoop.mapred.TaskTracker.deleteUserDirectories(TaskTracker.java:779)
        at org.apache.hadoop.mapred.TaskTracker.initialize(TaskTracker.java:816)
        at org.apache.hadoop.mapred.TaskTracker.run(TaskTracker.java:2704)
        at org.apache.hadoop.mapred.TaskTracker.main(TaskTracker.java:3934)
{code}, I ran tests with this patch and it did not run into the race. Did not add unit tests as not easy to reproduce., Thanks Arpit. Is there a way to reproduce the issue, may be by adding explicit sleeps etc.?

Otherwise, the patch looks mostly good:

Nit:
# LTC#deleteAsUser() LTC#deleteLogAsUser() have unrelated (guess auto-formatting) changes
, I just committed this. Thanks Arpit!

PS: I added a javadoc to the new ttReInit param for TT.TIP.jobHasFinished during the commit., [~kkambatl], sorry - I committed before seeing your comments. Let's file a follow up. I agree with Arpit that reproducing this is super hard in a unit test since we also need LTC. Thanks., [~kkambatl] thanks for the review.

bq. Nit:
LTC#deleteAsUser() LTC#deleteLogAsUser() have unrelated (guess auto-formatting) changes

Are you talking about

{code}
String[] command = new String[] { taskControllerExe, user,
        localStorage.getDirsString(),
        Integer.toString(Commands.DELETE_LOG_AS_USER.getValue()), subDir };
{code}

The rest of the changes were related to improving the logging when there was a failure deleteAsUser and deleteLogAsUser.

, That is right, Arpit. Anyways, I guess we can let it be now that it has been committed :) No worries, Arun.

However, I am just curious to know if there is a way to reproduce this. What were the circumstances you ran into this? I understand it being hard to write a test for. , bq. However, I am just curious to know if there is a way to reproduce this. What were the circumstances you ran into this? I understand it being hard to write a test for.

We noticed this while running tests for job recovery and we noticed on a secure cluster number of task trackers in the cluster would go down eventually to 0 causing tests to hang. These tests are running mr, pig, hive oozie etc and in the back ground jobtracker would be restarted., Thanks Arpit., Closed upon release of Hadoop 1.2.0.]