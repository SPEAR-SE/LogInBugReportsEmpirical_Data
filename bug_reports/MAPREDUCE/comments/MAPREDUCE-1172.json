[I think MAPREDUCE:433 needs to be back ported to 20. Chirs?, That would solve the failure; it depends on HADOOP-2774, which is also in 0.20. However, since the failure is likely attributable to [83 bytes|https://issues.apache.org/jira/browse/MAPREDUCE-433?focusedCommentId=12722986&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#action_12722986] from the Windows rename implementation, it may not be worth it. Nicholas, is that the failure you're seeing?, I saw the failure mentioned at https://issues.apache.org/jira/browse/MAPREDUCE-433?focusedCommentId=12720119&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#action_12720119, > ... However, since the failure is likely attributable to 83 bytes from the Windows rename implementation, it may not be worth it. Nicholas, is that the failure you're seeing?

The failure was observed in Linux.  So I think it is not related to the Windows rename implementation., I just took the patch from MAPREDUCE-433 and merged it so that it would apply to my 20-branch. The testReduceFromPartialMem testcase still fails. I'm seeing the condition {{spill == 2 * out}}, which is violating the assertion {{spill < 2 * out}}.

After merging the patch in, this is what my testcase method looks like:

{code}
  public void testReduceFromPartialMem() throws Exception {
    final int MAP_TASKS = 5;
    JobConf job = mrCluster.createJobConf();
    job.setNumMapTasks(MAP_TASKS);
    job.setInt("mapred.inmem.merge.threshold", 0);
    job.set("mapred.job.reduce.input.buffer.percent", "1.0");
    job.setInt("mapred.reduce.parallel.copies", 1);
    job.setInt("io.sort.mb", 10);
    job.set("mapred.child.java.opts", "-Xmx128m");
    job.setInt("mapred.job.reduce.total.mem.bytes", 128 << 20);
    job.set("mapred.job.shuffle.input.buffer.percent", "0.14");
    job.setNumTasksToExecutePerJvm(1);
    job.set("mapred.job.shuffle.merge.percent", "1.0");
    Counters c = runJob(job);
    final long out = c.findCounter(Task.Counter.MAP_OUTPUT_RECORDS).getCounter();
    final long spill = c.findCounter(Task.Counter.SPILLED_RECORDS).getCounter();
    final long twiceOut = 2 * out;
    assertTrue("Expected some records not spilled during reduce (spill="
        + spill + ", 2*out=" + twiceOut + ")",
        spill < twiceOut); // spilled map records, some records at the reduce
  }
{code}, Update: I realized that I didn't finish merging everything. :smile: Once I did that properly, the tests passed. I am attaching a patch file which represents MAPREDUCE-433 applied on the 0.20 branch.

It would be good if this could be included on 0.20. Not marking patch-available since it won't apply on trunk and Hudson would fail it., Usually this is easier if the backport has the same issue number, so it's clear where the fix is. I reopened MAPREDUCE-433 to track this and did the backport manually (reintroducing mapred.child.java.opts could make the test unstable), Resolving as duplicate of MAPREDUCE-433]