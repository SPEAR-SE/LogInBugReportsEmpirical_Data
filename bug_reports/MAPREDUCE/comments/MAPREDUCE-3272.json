[Ramya, I could use your help trying to reproduce this.

Here is my setup.
* Not using ephemeral ports for NM
* Single node cluster setup
* Node manager time out is set to 10 minutes

# First the cluster is up and running
$ jps
1761 ResourceManager
4369 Jps
1641 DataNode
1560 NameNode
4029 NodeManager
1840 JobHistoryServer
11996 Launcher

# Next I kill the node manager
$ kill 4029

# I verify the node manager is killed
$ jps
4385 Jps
1761 ResourceManager
1641 DataNode
1560 NameNode
1840 JobHistoryServer
11996 Launcher

# I wait the full 10 minutes for the node manager to time out
2011-11-30 10:45:26,464 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: Processing machine.example.com:45454 of type EXPIRE
2011-11-30 10:45:26,465 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: Expired:machine.example.com:45454 Timed out after 600 secs
2011-11-30 10:45:26,504 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: Removed Node machine.example.com:45454
2011-11-30 10:45:26,505 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: machine.example.com:45454 Node Transitioned from RUNNING to LOST

# Total nodes on the RM is decremented by one. Lost nodes on the RM is incremented by one
# Then I restart the nodemanager
$ yarn-daemon.sh start nodemanager

# Verify the nodemanager connects successfully in the logs
2011-11-30 11:13:50,315 INFO org.apache.hadoop.yarn.util.RackResolver: Resolved machine.example.com to /default-rack
2011-11-30 11:13:50,328 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: Processing machine.example.com:45454 of type STARTED
2011-11-30 11:13:50,328 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: machine.example.com:45454 Node Transitioned from NEW to RUNNING
2011-11-30 11:13:50,328 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node machine.example.com(cmPort: 45454 httpPort: 9999) registered with capability: 8192, assigned nodeId machine.example.com:45454

# I notice the total nodes on the RM is incremented by one. Lost nodes is NOT decremented by one MAPREDUCE-3271.
# Node manager is again available for use. Expected behavior., One thing to note. I must wait the full 10 minutes to restart the nodemanager, otherwise I nodemanager is killed with this message.
2011-11-30 11:18:43,336 INFO org.apache.hadoop.yarn.util.RackResolver: Resolved machine.example.com to /default-rack
2011-11-30 11:18:43,336 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: Duplicate registration from the node at: machine.example.com, Sending SHUTDOWN Signal to the NodeManager
, If I use ephemeral ports for the nodemanager, then I do note need to wait for the lost node time out before restarting the nodemanager., Jonathan, the issue which I described was when the nodemanagers are lost and not killed i.e. kill -SIGSTOP 4029 and not kill 4029. This would suspend the nodemanager momentarily but not kill the process. To simulate rejoining of nodemanagers, I did not restart the nodemanager but used kill -SIGCONT 4029 to resume execution. , Thanks, Ramya for the quick reply. I am now able to reproduce this issue. I have set the yarn.resourcemanager.nm.liveness-monitor.expiry-interval-ms property much lower this time to save myself some grief :), After analyzing this issue, I found that it is a dup of MAPREDUCE-3034.]