[Where are you seeing the out of memory exceptions? You might want to run under java 1.6 to get stack traces., tracked it down to MergeQueue.merge(), after a couple of iterations of that loop it runs out of memory. , I think we need to investigate this further. Maybe the JVM is not spawned with enough memory. I am saying this because this same loop merges the map outputs even for the sort benchmark and in the sort benchmark this loop successfully merges 1000s of files., After a bit of profiling i see 4 buffers of size 20971520 (FSDataInputStream.Buffer) and 11 buffers of size 9532509. These are in first and second iteration respectively, and not cleaned up before VM runs out of memory. Trace snapshot attached. debugging further. , Could you please check this with the patch for HADOOP-849? Think it is the same problem. Thanks., I'm running 0.10.0 which should include the patch from HADOOP-849 (as far as I can tell), but I'm still running into OutOfMemoryErrors.

I'm following the example from this blog entry:

http://jjinux.blogspot.com/2007/01/clustering-hadoop.html

hadoop-default.xml contains:

<configuration>
<property>
  <name>hadoop.tmp.dir</name>
  <value>/state/partition1/tmp/hadoop-${user.name}</value>
</property>
<property>
  <name>fs.default.name</name>
  <value>dominatrix.local:54310</value>
</property>
<property>
  <name>mapred.job.tracker</name>
  <value>dominatrix.local:54311</value>
</property>
<property> 
  <name>dfs.replication</name>
  <value>2</value>
</property>
</configuration>

mapred settings are unchanged.

I'm using an input file generated as follows:

perl -e 'for $i(1..99999999) { print "$i\t\n"; }' > input.txt

This generates a 945 MB input file. I then run:

hadoop-0.10.0/bin/hadoop jar hadoop-0.10.0/contrib/hadoop-streaming.jar -mapper mapper.py -reducer reducer.py -input input.txt -output out-dir

I am running the job across 21 nodes.

What next? How do I debug this problem further? I'll try Java 6 in the mean time., Please tweak the mapred.child.java.opts to have a value -Xmx512m in hadoop-site.xml (look at hadoop-default.xml for an explanation of this property)., Was a user config issue, not a framework issue. Closing out.]