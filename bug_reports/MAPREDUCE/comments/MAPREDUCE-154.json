[Try increasing the child heap size in the hadoop-site.xml configuration file., I have several problems wit running 0.19.0 on EC2 

Look very carefully at you out of memory error, it might not actually be out of memory, we run on large EC21 instances, 5 mapreds per node with the following JVM config. 

-Xms2048m -Xmx2048m // preload the VM at 2G

-Xloggc:/mnt/logs/@taskid@.gc // enable VM logging

-XX:+UseConcMarkSweepGC // use concurrent garbage collection

-XX:-UseGCOverheadLimit // disable GC stall protection, otherwise processes with large memory churn tend to get aborted

The last option turns off a protection added in java 6, which will produce an out of memory exception if the GC takes too long to run, even if there is plenty of memory left, turning it off seems to have increased stability dramatically

We tend to overcommit on the JVM heaps because our usage pattern means that only a few very large tasks get run amongst a stream of smaller tasks. ]