[Hope this is a right way. Here $YARN_HOME is checked first., -1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12508804/MAPREDUCE-3605.patch
  against trunk revision .

    +1 @author.  The patch does not contain any @author tags.

    -1 tests included.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    -1 patch.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/1518//console

This message is automatically generated., -1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12508810/MAPREDUCE-3605.patch
  against trunk revision .

    +1 @author.  The patch does not contain any @author tags.

    -1 tests included.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    -1 patch.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/1519//console

This message is automatically generated., {quote}

-1 patch. The patch command could not apply the patch.

{quote}

I wonder why? , Prashanth - this needs more work. You need to add YARN & MR jars to classpath etc.

Did you test your patch?, Arun,

{quote}
Did you test your patch?
{quote}
Yes, But not thoroughly.

{quote}
Prashanth - this needs more work. You need to add YARN & MR jars to classpath etc.
{quote}

 Including YARN & MR jars on classpath wont be necessary as the hadoop script is delegating the command and its params to mapred shell command. This is similar to executing hdfs command and since that works out of the box with-out explicitly setting classpath, so a similar behavior can be expected from this as well.


Besides above. There should exist a "hadoopctl" (A typical script found with most standard opensource utils) script which provides a central way of executing scripts or doing all the tasks. Accompanied by a proper man page it would serve as a standard way of starting various daemons with complete configuration details. Standard because most of the other opensource tools and even bigger applications have such support. 

A worth-noting advantage it provides is that - with changing of design of internal classes e.g. deprecation and changes in classpath etc... The hadoopctl script will serve as a complete abstraction and wont bother end user. Second advantage will be limiting the number of variables needed to export and Third will be users will have to consult just one script to build there way of automating hadoop installation by building scripts on the top of hadoopctl by consulting a simple man page. Segregation of three projects is great but consulting documentations and script of three different projects to do one thing doesn't that cool. 

Thoughts? 
, @Prashanth,
 Looks like you already had the patch. I uploaded one on HADOOP-7971. This should probably be a hadoop common jira. I also removed jobtracker/tasktracker and others not supported options from the patch., Duplicate of HADOOP-7971.]