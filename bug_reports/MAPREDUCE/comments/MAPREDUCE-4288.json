[It is coming due to the hard-coded values in the below code,

{code:title=ResourceMgrDelegate.java|borderStyle=solid}
  public ClusterMetrics getClusterMetrics() throws IOException,
      InterruptedException {
    GetClusterMetricsRequest request = recordFactory.newRecordInstance(GetClusterMetricsRequest.class);
    GetClusterMetricsResponse response = applicationsManager.getClusterMetrics(request);
    YarnClusterMetrics metrics = response.getClusterMetrics();
    ClusterMetrics oldMetrics = new ClusterMetrics(1, 1, 1, 1, 1, 1, 
        metrics.getNumNodeManagers() * 10, metrics.getNumNodeManagers() * 2, 1,
        metrics.getNumNodeManagers(), 0, 0);
    return oldMetrics;
  }
{code} 

Here we cannot get runningMaps, runningReduces, occupiedMapSlots...etc from RM because the yarn cluster is completely based on the resources and resource usages.


It doesn't look good to show these hard-coded values always to the user when they try to get cluster status using the JobClient.getClusterStatus() API.

Any thoughts on this?, In YARN, the ClusterMetrics should only correspond to numNodeManagers, numActiveJobs(), numActiveContainers(), availableResources(). Other job/app-specific metrics should move to the corresponding AMs. JobStatus would be a good place to have these metrics.

Subsequently, JobClient.getClusterStatus() can correspond to the job-specific metrics (would be a misnomer).

Comments?, Couldn't get around to this, marking it as unassigned should anyone be interested. 

Will pick it up again if still available later., The issue is still exist in the latest code base. This issue require more discussion on whether to change the hard coded values which may break comatibility for the MR client OR bring out a new design to handle this dielema. If not planning to fix , I think this can be closed as wont fix., Linking to similar issue in MR]