[Thanks a lot for this analysis! We had the exact same problem at work , running CDH3.5, with Crunch 0.8.4 and Avro 1.7.7.

It's only after trying a couple of days to find the cause of our problem, and not finding it, that I came across this issue via a lucky Google search.
I can confirm that increasing *io.sort.mb* solved our problem.

Thank you for saving us probably weeks of investigation :) , Thanks for the feedback [~tomdeleu] -- I'm glad you found the post helpful.  It was quite tedious to come to root cause when we encountered the issue and I figured there would probably be some others that ran into it., Is this possibly still a problem?  I'm getting the error after a long running map job on Hadoop 2.7.3.
I can't increase mapreduce.task.io.sort.mb > 2047 because of [https://github.com/apache/hadoop-mapreduce/blob/HDFS-641/src/java/org/apache/hadoop/mapred/MapTask.java?source=cc#L746]
Interestingly enough some other searches from Google suggest _decreasing_ the parameter, e.g. [http://comments.gmane.org/gmane.comp.jakarta.lucene.hadoop.user/44152]
However, since it takes ~5hrs to reach the error point doing trial and error testing is problematic.
---
{color:red}
UPDATE: lowering  mapreduce.task.io.sort.mb to 1024 caused the problem to go away
{color}
---
{noformat}
Task: attempt_1478217421435_0024_m_000000_0 - exited : java.lang.ArrayIndexOutOfBoundsException
        at org.apache.hadoop.mapred.MapTask$MapOutputBuffer$Buffer.write(MapTask.java:1453)
        at java.io.DataOutputStream.writeLong(DataOutputStream.java:224)
        at org.apache.hadoop.io.LongWritable.write(LongWritable.java:52)
...
        at org.apache.hadoop.io.serializer.WritableSerialization$WritableSerializer.serialize(WritableSerialization.java:98)
        at org.apache.hadoop.io.serializer.WritableSerialization$WritableSerializer.serialize(WritableSerialization.java:82)
        at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.collect(MapTask.java:1149)
        at org.apache.hadoop.mapred.MapTask$NewOutputCollector.write(MapTask.java:715)
        at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
        at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
        at org.apache.hadoop.mapreduce.Mapper.map(Mapper.java:125)
        at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
        at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
        at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
        at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:422)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
        at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
{noformat}
, We are also seeing this problem on CDH 5.10.1.  This same issue was also reported as [AVRO-1786], Issue was resolved by increasing mapreduce.task.io.sort.mb higher than the default and larger than our largest Avro object.]