[GitHub user dennishuo opened a pull request:

    https://github.com/apache/hadoop/pull/259

    MAPREDUCE-6931. Fix TestDFSIO "Total Throughput" calculation.

    Previously it failed to convert ms to seconds and thus reports aggregate
    throughput as 1/1000x actual numbers. Also, make all the bytes-to-mb
    and milliseconds-to-seconds conversions consistent in the reporting
    messages to help avoid this type of error in the future.

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/dennishuo/hadoop trunk

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/hadoop/pull/259.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #259
    
----
commit 23a374d6e818004daa0b1cf16c4fedb439ab4943
Author: Dennis Huo <dhuo@google.com>
Date:   2017-08-02T21:30:51Z

    MAPREDUCE-6931. Fix TestDFSIO "Total Throughput" calculation.
    
    Previously it failed to convert ms to seconds and thus reports aggregate
    throughput as 1/1000x actual numbers. Also, make all the bytes-to-mb
    and milliseconds-to-seconds conversions consistent in the reporting
    messages to help avoid this type of error in the future.

----
, Hey [~dennishuo], thanks for reporting this.
As I mentioned in HDFS-9153 ([in this comment|https://issues.apache.org/jira/browse/HDFS-9153?focusedCommentId=16122049&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-16122049] the "Total Throughput" should be removed as a deceiving metrics.
Could you please fix this by removing the line.

Also, DFSIO issues should be filed on HDFS jira., Thanks for the explanation! I have no strong preference about removing the particular "Total Throughput" metric, but from my own experience using TestDFSIO in the past, I do find that the "average single-stream throughput" calculation historically provided by TestDFSIO can itself be somewhat misleading in characterizing a cluster since it makes it difficult to infer the level of concurrency corresponding to that per-stream performance without backing out the numbers manually.

I see the new metric as being a useful measure of "Effective Aggregate Throughput", all-in including overhead.

For example, if I use memory settings that only fit 1 container per physical machine at a time, my TestDFSIO will trickle through 1 task per machine at a time, and those single tasks will have very high single-stream throughput. If I instead do memory packing so that every machine runs, say, 64 tasks concurrently, then single-stream throughput will suffer significantly, while total walltime will decrease significantly. With a walltime-based calculation, I can see at a glance the approximate total throughput rating of my cluster when everything is running at full throttle; I'd expect increasing concurrency to increase aggregate throughput until IO limits are reached, where aggregate throughput will become flat w.r.t. increasing concurrency or slightly declining due to thrashing.

This could also be my cloud bias, where it becomes more important to characterize a full-blast cluster against a remote filesystem vs caring so much about per-stream throughputs.

It seems like an "effective aggregate throughput" calculation would help encompass the cluster-wide effects of things like optimal CPU oversubscription ratios, scheduler settings, speculative execution vs failure rates, etc.

I agree the wording and computation as-is might not be the right fit for this though. I see a few options that might be worthwhile, possibly in some combination:

* Change wording to say "Effective Aggregate Throughput" to more accurately describe what the number means
* Add a metric displaying the "time" as "Slot Seconds" or something like that so that user doesn't have to compute it by dividing "Total MBytes processes" by "Throughput mb/sec" explicitly. This also helps clarify that the throughput is computed in terms is slot time, not walltime.
* Additionally, maybe provide a measure of "average concurrency" taking total slot time divided by walltime. This would legitimately consider scheduler overheads; if my whole test only ran 1 task in an hour, and it only had 30 minutes of slot time, then a concurrency of 0.5 correctly characterizes the fact that I'm only squeezing out 0.5 utilization after factoring in delays.


In any case, happy to just delete the one line in-place to have the refactorings committed if you feel it's better not to change/add metrics or if these are better discussed in a followup JIRA, let me know.

Re: MAPREDUCE and HDFS, I'll be sure remember TestDFSIO goes under HDFS in the future. For this one I looked at a search for "TestDFSIO" in JIRA and eyeballed that a plurality seemed to be under MAPREDUCE, a smaller fraction in HDFS, and then remaining ones in HADOOP. Combined with this code going under the hadoop-mapreduce directory, it looked like MAPREDUCE was more correct., [~dennishuo] I agree that "Total Throughput" metric highly depends on how you run the job. This is exactly the point that it makes it a Mapreduce metric, not HDFS. One can go to Yarn UI and divide HDFS bytes written by the job time for any job, but it does not measure HDFS write operation.
I think we should just remove it., Fair enough, makes sense. I went ahead and removed that line, keeping the refactorings otherwise; I also updated my commit message and pull request title to reflect the "removal" rather than the "fix" of the line, but it sounds like guidelines are to avoid editing JIRAs inplace, so I'll leave that untouched., I see only one commit in your pull request, which still fixes the ms problem. What did I miss?
And it's fine to edit jira title if the original does not reflect the actual contents., Hmm, looking at github I only see the refactoring of the older messages, along with complete removal of the "Total Throughput" line.

The confusion might be that there's only one commit because I used "commit --amend", force of habit from other repos iI've worked on where this convention is used for review-time changes to small patches. I could probably reconstruct the commit history if you prefer., I see this pull request:
https://github.com/apache/hadoop/pull/259/commits/b6c6dc613b071105d8e0536ee4496bf750d44e9d
which includes
{code}
-      String resultLine = "Seq Test exec time sec: " + (float)execTime / 1000;
+      String resultLine = "Seq Test exec time sec: " + msToSecs(execTime);
{code}
May be you can attach a patch here., Right, that line is part of the refactor to make time and byte conversions consistently use the helper functions instead of having different places.

So the current pull request keeps the refactoring but removes the "Total Throughput" line as you suggested. If you prefer to also remove all the refactoring and keep the hard-coded "(float)execTime / 1000" stuff I can do that too, just let me know., Ah yes, missed the refactoring.
+1 on the patch, Github user clehene commented on a diff in the pull request:

    https://github.com/apache/hadoop/pull/259#discussion_r133286014
  
    --- Diff: hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/fs/TestDFSIO.java ---
    @@ -855,7 +855,7 @@ public int run(String[] args) throws IOException {
           long tStart = System.currentTimeMillis();
           sequentialTest(fs, testType, nrBytes, nrFiles);
           long execTime = System.currentTimeMillis() - tStart;
    -      String resultLine = "Seq Test exec time sec: " + (float)execTime / 1000;
    +      String resultLine = "Seq Test exec time sec: " + msToSecs(execTime);
    --- End diff --
    
    Perhaps rename variable to includes units too? E.g. `execTimeMs` ?
, Github user dennishuo commented on a diff in the pull request:

    https://github.com/apache/hadoop/pull/259#discussion_r133348688
  
    --- Diff: hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/fs/TestDFSIO.java ---
    @@ -855,7 +855,7 @@ public int run(String[] args) throws IOException {
           long tStart = System.currentTimeMillis();
           sequentialTest(fs, testType, nrBytes, nrFiles);
           long execTime = System.currentTimeMillis() - tStart;
    -      String resultLine = "Seq Test exec time sec: " + (float)execTime / 1000;
    +      String resultLine = "Seq Test exec time sec: " + msToSecs(execTime);
    --- End diff --
    
    Good suggestion, done.
, We are trying to keep refactoring separate from changes.
I'll go ahead with the first commit. You can create another jira for refactoring if needed., BTW, how do we make Jenkins run on a pull request?, Attaching patch to trigger Jenkins, | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 17s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 14m 55s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 25s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 19s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 29s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  0m 25s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 13s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 24s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 26s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 26s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 16s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 24s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} whitespace {color} | {color:red}  0m  0s{color} | {color:red} The patch has 1 line(s) that end in whitespace. Use git apply --whitespace=fix <<patch_file>>. Refer https://git-scm.com/docs/git-apply {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  0m 29s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 10s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} unit {color} | {color:green}105m 37s{color} | {color:green} hadoop-mapreduce-client-jobclient in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 28s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}125m 58s{color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:14b5c93 |
| JIRA Issue | MAPREDUCE-6931 |
| GITHUB PR | https://github.com/apache/hadoop/pull/259 |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux 4521ca488c28 3.13.0-123-generic #172-Ubuntu SMP Mon Jun 26 18:04:35 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / f29a0fc |
| Default Java | 1.8.0_144 |
| findbugs | v3.1.0-RC1 |
| whitespace | https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/7097/artifact/patchprocess/whitespace-eol.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/7097/testReport/ |
| modules | C: hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient U: hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient |
| Console output | https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/7097/console |
| Powered by | Apache Yetus 0.5.0   http://yetus.apache.org |


This message was automatically generated.

, Looks like Jenkins is applying full pull request. [~dennishuo] could you please revert last commit, which refactors variable names., Done., | (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 44s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 25m 37s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 57s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 44s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  0s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  0m 55s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 30s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 50s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 48s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 48s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 30s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 42s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  0m 47s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 15s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} unit {color} | {color:green}129m  6s{color} | {color:green} hadoop-mapreduce-client-jobclient in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 35s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}165m 18s{color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:14b5c93 |
| JIRA Issue | MAPREDUCE-6931 |
| GITHUB PR | https://github.com/apache/hadoop/pull/259 |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux 52364c7028c7 3.13.0-117-generic #164-Ubuntu SMP Fri Apr 7 11:05:26 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / bb6a3c8 |
| Default Java | 1.8.0_144 |
| findbugs | v3.1.0-RC1 |
|  Test Results | https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/7098/testReport/ |
| modules | C: hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient U: hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient |
| Console output | https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/7098/console |
| Powered by | Apache Yetus 0.5.0   http://yetus.apache.org |


This message was automatically generated.

, SUCCESS: Integrated in Jenkins build Hadoop-trunk-Commit #12278 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/12278/])
MAPREDUCE-6931. Remove TestDFSIO "Total Throughput" calculation. (shv: rev 3e0e2033cc28d48a7909822416478aff7487bfe6)
* (edit) hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/fs/TestDFSIO.java
, I just committed this to trunk, branch-2, branch-2.8, and branch-2.7.
Thank you [~dennishuo]., 2.8.2 is in RC stage. Move to 2.8.3 given this only land on branch-2.8., Hey [~djp] I got confused with jira versions, as 2.8.3 was not available. Now it is, thanks.
But I hoped the confusing field, which this jira is removing, will not sneak into any releases at all. To avoid questions like what it means and why it was removed later on. 
I would strongly recommend merging this into 2.8.2. The final decision of course is up to the release manager., This JIRA is marked as trivial, but we are in 2.8.2 RC stage. In my practice (different RM may have different practices), commits under major priority should be skipped at this stage with balance between importance of fixes and risky of careless code/merge., The change is very simple, trivial. But important from API viewpoint, as I explained above., Github user dennishuo closed the pull request at:

    https://github.com/apache/hadoop/pull/259
]