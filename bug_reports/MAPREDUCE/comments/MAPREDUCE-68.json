[It seems like it should be easy enough to pass out reduce tasks to a machine one at a time. Even with speculative execution on, this should improve the distribution of tasks., Nathan, what scheduler are you using? Assuming it is the default one, the default scheduler does have load balancing code to distribute map *and* reduce tasks evenly on all the TaskTtrackers depending on each TT's slots. Can you give more information about your observation - things like hadoop version, size of your cluster, more info about your job etc.?, I am seeing this behavior on a cluster running version 0.18.1. This is a 16 machine cluster and there are exactly 16 reducers. I tend to see 2 or 3 machines idle during the reducing., does all the 16 machines have the same configuration? i.e. number of mapper/reducer slots? Also, have you changed any of the default heartbeat intervals?, As of hadoop-0.18 the Map-Reduce scheduler does assign only 1 reducer per heartbeat and has the necessary smarts to ensure that it correctly loads up each machine upto ceil(loadfactor) on each heartbeat. I suspect that ceil(loadfactor) causes some to get overloaded... which is an unfortunate side-effect which is hard to fix. I'm assuming you don't want to reduce #reduceslots to 1 per box?, Reducing the number of reduce slots to 1 per box is impractical. This job that requires the 1 reducer per machine configuration runs as part of a much, much larger workflow, where every other job benefits from having multiple reducers on each machine., Were other jobs 'alive' in the system when this happened or was this the only other job in the queue?, This was the only job running / in the queue., Not a problem with current release schedulers.]