[Per discussions with Chris and Arun, the JT memory stats should not be in ClusterStatus. , 1. Does this mean that the webUi will not show the JT memory usage anymore?

2. There are applications that are using this information currently exposed via the ClusterStatus API? is there an alternative way to retrieving them?, bq. Does this mean that the webUi will not show the JT memory usage anymore?
No. Web UI will continue to show memory usage. Since JobTracker is the one serving web ui, It need not pass memory info through getClusterStatus() api.

bq. There are applications that are using this information currently exposed via the ClusterStatus API? 
I think we should add another api like getJTMemoryInfo() to retrieve the information from Applications. Memory info can not be added to getClusterStatus() because 
* it is not cluster info.
* getClusterStatus() is synchronized and we cannot introduce jni calls into this. See MAPREDUCE-1683., Does this need to be a blocker? We could add this in a later (point) release, no?, I am fine moving it to 0.22., Moving it to 0.22 as per Dhruba's comment.

bq. There are applications that are using this information currently exposed via the ClusterStatus API? is there an alternative way to retrieving them?
Branch 0.21 does not have a way to get this memory information from clients., Moving it to 0.22 as per Dhruba's comment.

bq. There are applications that are using this information currently exposed via the ClusterStatus API? is there an alternative way to retrieving them?
Branch 0.21 does not have a way to get this memory information from clients., Why would client applications need JobTracker's memory information. I think the reason we added it to ClusterStatus was that its maintained at one place and its passed it to the webui for display. I dont think JobTracker's memory information should be a part of ClusterStatus. If at all some admins require it, it should be made available via MRAdmin. I dont see any reason why client should be aware of JobTracker's memory details. , Two reasons:
1. Hive actually throttles new job-submissions if the heap memory on the JT exceeds a certain threshold. 
2. It is also needed to monitor the health of the JT., bq. It is also needed to monitor the health of the JT. 

This is already available in JVM Metrics.

bq. Hive actually throttles new job-submissions if the heap memory on the JT exceeds a certain threshold. 

Again, I'd like to re-iterate that this 'feature' causes *serious* performance issues on the JobTracker - JNI calls are *very* expensive, a rouge client for this feature can easily cause *severe* harm to the JobTracker and hence the entire cluster.

Hive can use JVM Metrics for the same functionality given that this is already available in JVM Metrics.  Thus, I'm -1 on this feature., Sounds like a fine idea to me, if this data is already available via JVM Metrics., Thanks Dhruba. Closing as 'wontfix'.]