[This was found by Karams while testing the fix for MAPREDUCE-1635. Thanks Karam!

I think, it is happening like this because of overflow of the long calculations. The first time a TT reports the output, the calculations that happen are roughly as below:

reportedOutputOfMap  =   10751353136 bytes(10GB)
cumulativeOutputSize =   10751353136 (same as above)
cumulativeInputSize  = 1206552881823 (10TB total input for the whole job)

getEstimatedTotalMapOutputSize()
{code}
  long estimate = Math.round((inputSize * 
          completedMapsOutputSize * 2.0)/completedMapsInputSize);
{code}

I ran a simple java program and this will come out to be 6655367 (6MB, because of overflow errors).

getEstimatedMapOutputSize():
{code}
 estimate = getEstimatedTotalMapOutputSize()  / job.desiredMaps();
{code}
This will be 59422 (59KB totally wrong).

More iterations of this estimate must be finally reaching the stabilized 9642 bytes estimate, a guess.]