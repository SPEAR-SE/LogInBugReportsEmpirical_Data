[I don't understand what went wrong. Did the jar not exist? Was the representative class found in another jar? Applications can explicitly specify a jar file and that jar file WILL be used. Most applications use the method that sets the jar file based on a representative class. That can fail if the representative class is both in the "hadoop system" jars and the user's jar file., 
The job was a Abacus (Aggregate) job.
Aggrigate is in hadoop-core now,
The main class is in hadoop-core.jar.
When the main class creates the jobconf, it has no idea what will be the user's plugin classes, nor  what jar will hold the users code.  Using the representative class to decide
which jar to ship is flawed.
I specified explicitly a jar containing my classes, but the jar file was ignored, not shipped.
That is wrong.

, Well i had the same error. This is definitely caused by 
{{JobConf theJob = new JobConf(ValueAggregatorJob.class);}} in {{ValueAggregatorJob#createValueAggregatorJob}}. 
i will attach a patch to {{ValueAggregatorJob}} to take the representative class name as argument. , Runping could you try this patch please , Well, this patch may work (I have not tried yet, but I believe the approach will work) for this case, but I think  it only address this specific case. Plus, it does not sound right 
logically to make ValueAggregatorJob  take a representative class name 
(think about how do you explain it?). The right solution is that the user should be able to 
specify any jar(s) and Hadoop should ship the jar(s) and put them on the class path in the 
executing environment.
, >think about how do you explain it
The javadoc of JobConf explains this as : 
{code}  
/** 
   * Construct a map/reduce job configuration.
   * @param exampleClass a class whose containing jar is used as the job's jar.
   */
  public JobConf(Class exampleClass) {
    initialize();
    setJarByClass(exampleClass);
  }
{code}


>The right solution is that the user should be able to specify any jar(s) and Hadoop should ship the jar(s) and put them on the class path in the 
>executing environment.

We could set a system property from {{JobRunner}} to the jar file argument, and then initialize {{JobConf}} s with with this jar from the empty constructor. However i am not sure if this is what we want. Are there any other votes for this issue? 
, Currently we ship only one job file with the application, and this job file is searched by the help of a class in the job file. Unless we do decide to take the above approach(which i personally don't like), i think it is the aggragetor's responsibility to obtain the client class(or jar file). In able to proceed  I suggest we fire a new issue, apply the patch  there, and resolve this issue as wont fix. Any thoughts ? 
, 
Patch for HADOOP-1547 makes Aggregate work.
Use this issue for the general feature for allowing the user to specify jar files 
a job depends on.
, I think the issue is nothign to do with shipping the jar. It is configuration constructor that does not carry the classloader all along. See HADOOP-6103, Very old JIRA. Seems like a dup of HADOOP-6103 per Amareshwari. Closing so.]