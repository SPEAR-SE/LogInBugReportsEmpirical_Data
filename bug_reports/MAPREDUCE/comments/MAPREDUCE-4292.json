[What exactly was the failed map's cause? Did the job not fail after 4x map fails? (Note: Reducers may fail and retrigger maps if they can't get its outputs in good time.)

Logs of the MR AM would be good to have., bq. What exactly was the failed map's cause? Did the job not fail after 4x map fails? (Note: Reducers may fail and retrigger maps if they can't get its outputs in good time.)

I was testing a scenario where some maps fail always. Job did not fail after failing 4 attempts. Reducers were waiting for the map outputs.

bq. Logs of the MR AM would be good to have.

I have attached the am log.
, I tried reproducing this with 2.0.0-alpha on a single-node cluster by modifying wordcount to fail map IDs < 4.  As expected, the job failed soon after a map failed four attempts.  Explicitly setting mapred.reduce.tasks=1 for the job had no effect.  Could you attach the job config?  I'm wondering if there are other property settings that are affecting the behavior of the job.  For example, is mapreduce.map.failures.maxpercent set to a non-zero value?, If we set non-zero value for the property 'mapred.max.map.failures.percent', then the issue is occurring.
, If this is caused by mapred.max.map.failures.percent being non-zero then this is a duplicate of MAPREDUCE-3927., Nishan or Devaraj, have we been able to confirm that this issue only occurs when mapred.max.map.failures.percent (or mapreduce.map.failures.maxpercent) is set to a non-zero value?  I'm curious if you have been able to reproduce job hangs without that property being set., Dup of MAPREDUCE-3927.]