[Now if we give invalid archive path for a job it is logging and proceeding with other archives. , I disagree with the premise of this issue. If you try to add a file to distributedcache, but it can't be localized, it makes complete sense that it should fail the task., Hi Todd, I agree with you for job specific configuration. If we configure archives (contains invalid path) common for all jobs then all jobs will fail. Here all jobs may not depend on all the archives. 

Consider the case of Hive, if we configure any invalid path for the property "hive.aux.jars.path" all the jobs will fail which is not using that jar also.
, bq. Consider the case of Hive, if we configure any invalid path for the property "hive.aux.jars.path" all the jobs will fail which is not using that jar also.

I would consider it a broken config if you configure hive.aux.jars.path to point to a jar which doesn't exist.

In your patch, if you accidentally make a typo in your DistributedCache entries, you'll see NoClassDefFound exceptions or other much scarier errors. I think it's better to fail with the "File does not exist" error during localization., Hi Todd, I feel the fix will be useful. Let us just consider the case of Java, even one of the paths mentioned in classpath is invalid, Java will execute. As you mentioned  , if it is a typo error and a required jar is missing, the program may get ClassNotFoundExceptions.

Since hive.aux.jars.path is a system level configuration, we should not fail all jobs. But some jobs may get ClassNotFoundExceptions if a required jar is missing. 

What you say?, I too contest this. We don't have a concept of optional artifacts today.

Also, I am a little confused about your report. The exception trace is showing that job-submission itself is failing. But you mention 'all tasks are failing'.

It looks like hive.aux.jars.path should really be a job specific parameter. Otherwise if a new query(?) needs a new jar, it would mean a change in a system config? Seems weird, can you throw some more light on how this configuration is intended to be used.

If the suggestion is to just accept the job removing all invalid entries, but still keep the list of valid jars consistent through the rest of system, that should be okay I guess., As the exception stack trace says, I meant in the title all map reduce jobs are failing.  

"hive.aux.jars.path" is system level config for hive. Hive uses these jars for all the jobs it submits. I think there is no provision of submitting jars for specific query.
, hive.aux.jars.path can be set per-query with hive using the "set" command from the hive shell. I would not consider it system-level... or, if it's system level, it should be pointing to jars that are guaranteed to exist., cancelling patch for discussion, It is no more problem in active versions.]