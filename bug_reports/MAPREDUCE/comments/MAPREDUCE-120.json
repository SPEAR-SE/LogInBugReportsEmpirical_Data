[I have seem similar errors when the input is a mapfile but i am using SequenceFileInputFormat. Could you please check your program if this is indeed the case. , Runping, is it the case that only one attempt for the reducer failed? Did another attempt for the task succeed?, 
All attempts failed. The job failed eventually.

, 
My input data is in SequenceFile.
Only one map outputt segment file had the problem.

I found that the machine that produces that map output segment file was in bad shape ---
its root partition (/) is 100% full. That might be the cause of the problem.
, all hell breaks loose when the root partition gets full. mysterious exceptions appear in all shapes and sizes.

use the dfs.du.reserved option and the patch that makes it work .., I am getting a similar/same problem :
wrong key class: org.apache.hadoop.io.Text is not class org.apache.hadoop.io.LongWritable.

But I want to write Text and that is what I have specified as output key class. Is there any solution to this problem?]