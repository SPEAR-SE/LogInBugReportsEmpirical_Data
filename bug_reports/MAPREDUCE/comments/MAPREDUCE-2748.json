[Not that because of this bug, the NM's environment is not passed to streaming/pipes at all. So the following commands will not work in YARN+MR.

    $HADOOP_COMMON_HOME//bin/hadoop --config $HADOOP_CONF_DIR jar $HADOOP_STREAMING_JAR -input input.txt -mapper '$HADOOP_COMMON_HOME/bin/hadoop dfs -ls /'  -reducer NONE  -output Output

The failure is because HADOOP_COMMON_HOME is not known to the streaming process. Instead the following will work, essentially you should expand HADOOP_COMMON_HOME yourselves for now:

    $HADOOP_COMMON_HOME//bin/hadoop --config $HADOOP_CONF_DIR jar $HADOOP_STREAMING_JAR -input input.txt -mapper '/path/to/common/home/bin/hadoop dfs -ls /'  -reducer NONE  -output Output, Fixed via MAPREDUCE-2880., I am reopening this ticket for tracking the effort to make the list of envs to be configurable.

MAPREDUCE-2880 already fixed the code to pass correct values for essential variables like HADOOP_COMMON_HOME from NM down to the containers. It will be useful to have this configurable - like JAVA_HOME for containers separate from the NM's JAVA_HOME, or may be extra envs that NM doesn't need to be set with.

Also another minor TODO is to verify that the streaming examples I commented about above are working now., Fixed via MAPREDUCE-3068.]