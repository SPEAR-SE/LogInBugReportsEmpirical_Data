[Attaching patch for trunk. 

While exporting job conf values as environment variables, it would look for configuration key: stream.drop.long.env.variable.value if it is set to true then it would do a length check on jobconf values and would drop it if it happens to be greater than 20KB., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12655256/MAPREDUCE-5965.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The following test timeouts occurred in hadoop-tools/hadoop-streaming:

org.apache.hadoop.streaming.TestFileArgs

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/4728//testReport/
Console output: https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/4728//console

This message is automatically generated., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12655256/MAPREDUCE-5965.patch
  against trunk revision 276485e.

    {color:red}-1 patch{color}.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/5165//console

This message is automatically generated., Cancelling patch since it no longer applies., Reattaching updated patch., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12696883/MAPREDUCE-5965.1.patch
  against trunk revision e1990ab.

    {color:red}-1 patch{color}.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/5168//console

This message is automatically generated., Cancelling the patch... again.

It needs to be rebased for the current source tree., Ran into the same issue. Re-based and cleaned up patch which does the same as the Hive patch (truncate the environment value), \\
\\
| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | pre-patch |  15m 10s | Pre-patch trunk compilation is healthy. |
| {color:green}+1{color} | @author |   0m  0s | The patch does not contain any @author tags. |
| {color:red}-1{color} | tests included |   0m  0s | The patch doesn't appear to include any new or modified tests.  Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. |
| {color:green}+1{color} | javac |   7m 48s | There were no new javac warning messages. |
| {color:green}+1{color} | javadoc |   9m 47s | There were no new javadoc warning messages. |
| {color:green}+1{color} | release audit |   0m 21s | The applied patch does not increase the total number of release audit warnings. |
| {color:green}+1{color} | checkstyle |   0m 25s | There were no new checkstyle issues. |
| {color:green}+1{color} | whitespace |   0m  0s | The patch has no lines that end in whitespace. |
| {color:green}+1{color} | install |   1m 34s | mvn install still works. |
| {color:green}+1{color} | eclipse:eclipse |   0m 33s | The patch built with eclipse:eclipse. |
| {color:green}+1{color} | findbugs |   0m 42s | The patch does not introduce any new Findbugs (version 2.0.3) warnings. |
| {color:green}+1{color} | tools/hadoop tests |   6m 14s | Tests passed in hadoop-streaming. |
| | |  42m 37s | |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12733519/MAPREDUCE-5965.2.patch |
| Optional Tests | javadoc javac unit findbugs checkstyle |
| git revision | trunk / 363c355 |
| hadoop-streaming test log | https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/5741/artifact/patchprocess/testrun_hadoop-streaming.txt |
| Test Results | https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/5741/testReport/ |
| Java | 1.7.0_55 |
| uname | Linux asf903.gq1.ygridcore.net 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Console output | https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/5741/console |


This message was automatically generated., Thanks Wilfred.  I guess I'll comment on the meta issue first.  In general, I'm not sure whether it's  a good idea to filter based purely on size.  Would it better to have a more firm whitelist and/or blacklist capability for Hadoop streaming?, Making these comments assuming the current patch is an acceptable design approach, I have the following nitpicks:

1) Can "stream.truncate.long.jobconf.values" be put in the appropriate *-default.xml file for documentation purposes?

2) Can the lenLimit correspond to a Configuration variable?
, Arup: Do you mind if I assign the jira to me? Would like to get this fixed in an upcoming release., [~wilfreds] sure. Just a comment in the patch I had submitted the check was inside a separate function with some comment on why we want to do it. As can be seen in: https://issues.apache.org/jira/secure/attachment/12696883/MAPREDUCE-5965.1.patch Is there a reason to remove those?, [~amalakar] thank you for the assignment. The comment should be added back, I'll do that with an updated patch. The move to keep it in the same method was to make the change as simple as possible.

[~rchiang] 
The streaming configuration does not really have a *-default.xml file. There is documentation (markdown) that shows some of the settings and options: adding it to the FAQ would probably be the correct place. There is a help that is printed in the main StreamJob code that shows most of the options. I will update the two files and explain the setting that is available. I can upload a new patch with that added before I do lets get the other points finalised.

A white list or black list is possible but what would we exclude or include? In the job configuration there could be any value which could be too long, a user could set something he wants. It will be really difficult to filter that consistently and be sure that we have a fix with limited impact.

Making the lenLimit configurable is possible. However I do not see what we would win with making the length configurable. The data is not used anywhere and lowering or increasing the size at which we cut it off will not give us anything extra. If you really want to make it configurable the easiest way would be to roll the two settings in one. We could make the stream.truncate.long.jobconf.values an integer: -1 do not truncate otherwise truncate at the length given., Thanks guys for good discussions here. +1 on the overall solution here. Agree that we don't need to put new streaming configuration to *-default.xml as previous practices. 

bq. If you really want to make it configurable the easiest way would be to roll the two settings in one. We could make the stream.truncate.long.jobconf.values an integer: -1 do not truncate otherwise truncate at the length given.
That sounds better. May be we should rename "stream.truncate.long.jobconf.values" to something like: "stream.jobconf.truncate.limit" and document somewhere to say -1 is the default value which doesn't do any truncate and 20K is a proper value for most cases?, Thanks for the clarification.  I'm still getting used to the non-core Hadoop parts and how those need or don't need to conform.

+1 for the suggested property name and usage better., Updated the patch using the new name and made it an integer as [~djp] proposed. The documentation and the usage that is printed in the StreamJob have been updated to show the new option and the values.

To answer the 20000 question: it would be long enough to leave all but the problem value alone.

Three values are documented:
-1: do not truncate (default)
0: only copy the key and not the value (side effect of using substring)
20000: as a safe value which should prevent the "error=7" issue, \\
\\
| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | pre-patch |  17m 44s | Pre-patch trunk compilation is healthy. |
| {color:green}+1{color} | @author |   0m  0s | The patch does not contain any @author tags. |
| {color:red}-1{color} | tests included |   0m  0s | The patch doesn't appear to include any new or modified tests.  Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. |
| {color:green}+1{color} | javac |   7m 30s | There were no new javac warning messages. |
| {color:green}+1{color} | javadoc |   9m 37s | There were no new javadoc warning messages. |
| {color:green}+1{color} | release audit |   0m 23s | The applied patch does not increase the total number of release audit warnings. |
| {color:green}+1{color} | site |   2m 57s | Site still builds. |
| {color:green}+1{color} | checkstyle |   0m 25s | There were no new checkstyle issues. |
| {color:green}+1{color} | whitespace |   0m  0s | The patch has no lines that end in whitespace. |
| {color:green}+1{color} | install |   1m 33s | mvn install still works. |
| {color:green}+1{color} | eclipse:eclipse |   0m 32s | The patch built with eclipse:eclipse. |
| {color:green}+1{color} | findbugs |   0m 38s | The patch does not introduce any new Findbugs (version 3.0.0) warnings. |
| {color:green}+1{color} | tools/hadoop tests |   6m  7s | Tests passed in hadoop-streaming. |
| | |  47m 30s | |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12735146/MAPREDUCE-5965.3.patch |
| Optional Tests | javadoc javac unit findbugs checkstyle site |
| git revision | trunk / ada233b |
| hadoop-streaming test log | https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/5753/artifact/patchprocess/testrun_hadoop-streaming.txt |
| Test Results | https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/5753/testReport/ |
| Java | 1.7.0_55 |
| uname | Linux asf909.gq1.ygridcore.net 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Console output | https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/5753/console |


This message was automatically generated., Can someone please review the latest patch and let me know if it is OK?, +1 LGTM.

Will commit this later today if nobody has any other comments., Thanks Wilfred.  Committed to trunk and branch-2!, FAILURE: Integrated in Hadoop-trunk-Commit #7959 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/7959/])
MAPREDUCE-5965. Hadoop streaming throws error if list of input files is high. Error is: "error=7, Argument list too long at if number of input file is high" (wilfreds via rkanter) (rkanter: rev cc70df98e74142331043a611a3bd8a53ff6a2242)
* hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/streaming/PipeMapRed.java
* hadoop-tools/hadoop-streaming/src/site/markdown/HadoopStreaming.md.vm
* hadoop-mapreduce-project/CHANGES.txt
* hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/streaming/StreamJob.java
, FAILURE: Integrated in Hadoop-Yarn-trunk-Java8 #218 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk-Java8/218/])
MAPREDUCE-5965. Hadoop streaming throws error if list of input files is high. Error is: "error=7, Argument list too long at if number of input file is high" (wilfreds via rkanter) (rkanter: rev cc70df98e74142331043a611a3bd8a53ff6a2242)
* hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/streaming/PipeMapRed.java
* hadoop-mapreduce-project/CHANGES.txt
* hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/streaming/StreamJob.java
* hadoop-tools/hadoop-streaming/src/site/markdown/HadoopStreaming.md.vm
, FAILURE: Integrated in Hadoop-Yarn-trunk #948 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/948/])
MAPREDUCE-5965. Hadoop streaming throws error if list of input files is high. Error is: "error=7, Argument list too long at if number of input file is high" (wilfreds via rkanter) (rkanter: rev cc70df98e74142331043a611a3bd8a53ff6a2242)
* hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/streaming/StreamJob.java
* hadoop-mapreduce-project/CHANGES.txt
* hadoop-tools/hadoop-streaming/src/site/markdown/HadoopStreaming.md.vm
* hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/streaming/PipeMapRed.java
, SUCCESS: Integrated in Hadoop-Hdfs-trunk #2146 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/2146/])
MAPREDUCE-5965. Hadoop streaming throws error if list of input files is high. Error is: "error=7, Argument list too long at if number of input file is high" (wilfreds via rkanter) (rkanter: rev cc70df98e74142331043a611a3bd8a53ff6a2242)
* hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/streaming/PipeMapRed.java
* hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/streaming/StreamJob.java
* hadoop-tools/hadoop-streaming/src/site/markdown/HadoopStreaming.md.vm
* hadoop-mapreduce-project/CHANGES.txt
, SUCCESS: Integrated in Hadoop-Hdfs-trunk-Java8 #207 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk-Java8/207/])
MAPREDUCE-5965. Hadoop streaming throws error if list of input files is high. Error is: "error=7, Argument list too long at if number of input file is high" (wilfreds via rkanter) (rkanter: rev cc70df98e74142331043a611a3bd8a53ff6a2242)
* hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/streaming/StreamJob.java
* hadoop-tools/hadoop-streaming/src/site/markdown/HadoopStreaming.md.vm
* hadoop-mapreduce-project/CHANGES.txt
* hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/streaming/PipeMapRed.java
, FAILURE: Integrated in Hadoop-Mapreduce-trunk-Java8 #216 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk-Java8/216/])
MAPREDUCE-5965. Hadoop streaming throws error if list of input files is high. Error is: "error=7, Argument list too long at if number of input file is high" (wilfreds via rkanter) (rkanter: rev cc70df98e74142331043a611a3bd8a53ff6a2242)
* hadoop-tools/hadoop-streaming/src/site/markdown/HadoopStreaming.md.vm
* hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/streaming/StreamJob.java
* hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/streaming/PipeMapRed.java
* hadoop-mapreduce-project/CHANGES.txt
, FAILURE: Integrated in Hadoop-Mapreduce-trunk #2164 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/2164/])
MAPREDUCE-5965. Hadoop streaming throws error if list of input files is high. Error is: "error=7, Argument list too long at if number of input file is high" (wilfreds via rkanter) (rkanter: rev cc70df98e74142331043a611a3bd8a53ff6a2242)
* hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/streaming/StreamJob.java
* hadoop-tools/hadoop-streaming/src/site/markdown/HadoopStreaming.md.vm
* hadoop-mapreduce-project/CHANGES.txt
* hadoop-tools/hadoop-streaming/src/main/java/org/apache/hadoop/streaming/PipeMapRed.java
]