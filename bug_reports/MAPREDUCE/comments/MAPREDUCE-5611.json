[I am suggesting following small patch for this issue. Patched line is in *bold*

{code:title=CombineFileInputFormat.java|borderStyle=solid}
for (OneBlockInfo oneblock : blocksInNode) {
        if (blockToNodes.containsKey(oneblock)) {
          *nodes.addAll(Arrays.asList(blockToNodes.get(oneblock)));*
          validBlocks.add(oneblock);
          blockToNodes.remove(oneblock);
          curSplitSize += oneblock.length;

          // if the accumulated split size exceeds the maximum, then
          // create this split.
          if (maxSize != 0 && curSplitSize >= maxSize) {
            // create an input split and add it to the splits array
            addCreatedSplit(splits, nodes, validBlocks);
            curSplitSize = 0;
            validBlocks.clear();
          }
        }
      }
{code}

This will include all the nodes on which the replica lies in the location hash set, so that whichever node JT schedules the tasks it finds all the replicas local to that node (in case of replication = cluster size). This patch even helps in 3 replication factor, this fact is evident with the following numbers in my cluster

9 replicas without patch  (all 6 tasks are rack-local)
9 replicas with patch  (5 tasks are data-local and 1 rack-local)

3 replicas without patch  (1 data-local and 5 rack-local)
3 replicas with patch  (2 data-local and 4 rack-local)

Please let me know, if I can submit the above patch., following is the newly added line (since it is not clear from above code block)

*nodes.addAll(Arrays.asList(blockToNodes.get(oneblock)));*, attaching patch against trunk, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12613866/CombineFileInputFormat-trunk.patch
  against trunk revision .

    {color:red}-1 patch{color}.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/4219//console

This message is automatically generated., 
Thanks Chandra.  This is a good perf patch.  Here are the data locality numbers which can be useful to analyze the perf improvement.


Without Patch:
Job Counters 	Launched map tasks	0	0	335
Data-local map tasks	0	0	179
Rack-local map tasks	0	0	81

With Patch:
Job Counters 	Launched map tasks	0	0	335
Data-local map tasks	0	0	279
Rack-local map tasks	0	0	47

The data locality improves a lot with this patch in Hive queries.  
, Just wanted to add the response times as well

Without Patch : 289 seconds
With Patch: 219 seconds

This testing was carried out with with Hive 0.10, If I understand correctly, the issue is that, even when the blocks referred to by a split refer reside on multiple nodes, CombineFileInputFormat only creates the split with its locations referring to a single node.  The proposed fix is to create the split with all nodes that are replicas for any of the blocks included in the split.  This would allow the scheduler to prefer placing the tasks on those nodes.

However, the proposed change could cause performance regressions in situations when we are combining many small files.  Imagine a 1000-node cluster and and we have created a split composed of 1000 small files that all have a replica on a single node.  The other replicas for these files are likely spread out on nodes all over the cluster.  If we go with the proposed approach then we would end up requesting every node on the cluster, even though we are really only likely to get a data-local performance speedup if the task gets placed on the node where all the files are together.

A fix that would not have this performance implication would be to create a split with all the nodes that are in the *intersection* of nodes that blocks in the split reside on.  So if a split contains a two blocks, one that resides on node1, node2, and node3, and another that resides on node2, node3, and node4, we would set the split's locations to node2 and node3.

If we choose to go with the second route, it would be good to do some quick back-of-the-envelope math to support that the time spent computing these intersections is worth the data-local speedup we could get.
, Agreed, ideal will be to compute and have the *intersection* of the nodes in the split information.  We will modify the patch to accommodate this and post the details., Agreed, common nodes (intersection) should be placed in the beginning of the locations set, but I feel having all the locations of all the blocks in locations set will help scheduling and data locality. Two concerns

1.  In your example, one node having all the 1000 replicas. What if, JT is not able to schedule tasks on this node (slot limitation etc). Then it will pick any random node and schedule the task (having all the blocks non local).

2. What if there is no intersection i.e common nodes for blocks in a split?, bq. What if, JT is not able to schedule tasks on this node (slot limitation etc). Then it will pick any random node and schedule the task (having all the blocks non local).
That's right.  However, picking a node with a small fraction of the input data is not much better than picking a node without any of the input data.  It is only useful to place a task on a node if the majority of the data is on that node.  There may be more optimal approaches to this that take into account the number of bytes on each node, but I think using the intersection is a good start that we know will not cause perf regressions.

bq. What if there is no intersection i.e common nodes for blocks in a split?
The change was proposed to affect the code where we are building splits out of the nodeToBlocks map.  In this part of the split creation process, there will always be an intersection because the blocks are all chosen from a specific node., \\
\\
| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:red}-1{color} | patch |   0m  0s | The patch command could not apply the patch during dryrun. |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12613866/CombineFileInputFormat-trunk.patch |
| Optional Tests | javadoc javac unit findbugs checkstyle |
| git revision | trunk / f1a152c |
| Console output | https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/5536/console |


This message was automatically generated., \\
\\
| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:red}-1{color} | patch |   0m  0s | The patch command could not apply the patch during dryrun. |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12613866/CombineFileInputFormat-trunk.patch |
| Optional Tests | javadoc javac unit findbugs checkstyle |
| git revision | trunk / f1a152c |
| Console output | https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/5545/console |


This message was automatically generated.]