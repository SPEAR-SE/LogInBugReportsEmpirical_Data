[I think the purpose of these flushes is to signal activity to the parent process, so that the streaming task is not killed for inactivity.  Removing the flushes, while more efficient, changes this contract.  Perhaps we need something like a timer-based flush running in a separate thread?, sorry - don't understand.

the Pipe mapper and the reducer classes are consuming data -isn't that signal enough to the trackers that the task is making progress?

if the data is buffered - it seems that the worst that can happen is that script output is delayed - but this seems a common pattern anyway - since reduce scripts will frequently consume huge-amounts/all of data before emitting anything.

i have checked in a patch to our local production environment to see if we observe any weirdness .., > mapper and the reducer classes are consuming data -isn't that signal enough [...]?

We currently count both consumption and generation of data as activity.  Some mappers might, e.g., take lists of file names, and not consume new input lines very often.  Noticing progress on output is important for some applications.

I'm not arguing that this is the only or even the ideal way to handle progress notification for streaming, but rather that it is the way that things currently work, and that simply eliminating these flushes has the potential to break applications which rely on them for prompt progress reports.
, understood. we can make the flush timer driven as suggested., Actually, there were so many problems with tracking progress on streaming that it was disabled by default. 

{code}
    // All streaming jobs have, by default, no time-out for tasks
    jobConf_.setLong("mapred.task.timeout", 0);
{code}

I think it is ok to remove the flushes. The only downside that I can see is if you have your input format doing slow low-volumne fetching, you'll increase the latency of the map., Task timeouts and progress reporting do function correctly in current releases of streaming, so, while the scenarios where these flushes are necessary seem a bit far fetched (some kind of low but non-zero rate input), that doesn't mean nobody is depending on them.

For jobs with task timeouts enabled, it seems reasonable to promise a flush at least every {{mapred.task.timeout/2}} interval., Fixed by HADOOP-3429]