[Index: hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/JobSubmissionFiles.java
===================================================================
--- hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/JobSubmissionFiles.java	(revision 1526271)
+++ hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/JobSubmissionFiles.java	(working copy)
@@ -41,10 +41,10 @@
 
   // job submission directory is private!
   final public static FsPermission JOB_DIR_PERMISSION =
-    FsPermission.createImmutable((short) 0700); // rwx--------
+    FsPermission.createImmutable((short) 02750); // rwx--------
   //job files are world-wide readable and owner writable
   final public static FsPermission JOB_FILE_PERMISSION = 
-    FsPermission.createImmutable((short) 0644); // rw-r--r--
+    FsPermission.createImmutable((short) 00644); // rw-r--r--
   
   public static Path getJobSplitFile(Path jobSubmissionDir) {
     return new Path(jobSubmissionDir, "job.split");
, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12605289/hadoop-2.0.5-perm.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/3129//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/3129//console

This message is automatically generated., this is a patch against the hadoop 1.2 base, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12606593/HADOOP-1.2-PERM.patch
  against trunk revision .

    {color:red}-1 patch{color}.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/3161//console

This message is automatically generated., Hi Bradley, I don't necessarily think this is the right fix, since it only works in the case that the job submitter shares a group with the user running the JT, which shouldn't have to be the case. Regardless, this doesn't seem like a Hadoop Common issue, but rather an MR one, so I'm going to move the JIRA over there., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12606593/HADOOP-1.2-PERM.patch
  against trunk revision .

    {color:red}-1 patch{color}.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/4101//console

This message is automatically generated., hi aaron,

i agree there could be more relaxed scenarios, but this would be a huge step enabling the most basic:

* data set owned by 'hadoop' group
* members of 'hadoop' group have some access to data set (full access determined by owner)
* non members are restricted from viewing data set.  Or not, this isn't a hard requirement but may be restricted by owner.
* users in hadoop group can run map/reduce jobs against data set. 

I feel that a patch to externalize these permissions to a configuration option is more acceptable but the code bulk is less likely to get accepted.  

Note that these are also BUGS.  The decimal-->octal conversion forced by the 0700 and 0644 value result in unexpected octal values for the permissions.   A simple System.out.println((short)0700); and System.out.println((short)0644); will demonstrate the resulting values.  , I have a feeling that the overall premise is wrong. This part in the bug detail sticks out:

bq.  this prevents hadoop daemon services running under different UIDs from reading the job submitters files.

IIRC, at least in 1.x, the expectation is that the JT's user will be running with root privs against HDFS. i.e., the JT needs root access to HDFS to read not only the submitted files but also to handle logging in the case of the user providing a location on HDFS to write the job logs.

Opening up the staging directory also opens up an interesting DoS attack against the user who actually runs the code if quotas are enabled.

In practice, the way I usually see this handled is by having the user switch happen on the UNIX-side of the house.  i.e., sudo to a headless account and run the job there or have another system using the proxy/doAs() system., The more and more I think about this, the more and more I'm opposed to it.  So let's make it official: -1.

Pretty much the entire execution model in Hadoop is based around the user.  Changing this so groups can execute code outside of the submission protocol means that all of the auditing is completely borked since we'll have no idea who actually submitted the job.  Plus, as mentioned earlier, Hadoop already has hooks to allow impersonation that help cover this exact case., No consensus.  Closing.]