[cc [~sarutak] & [~ajisakaa], Thanks for the report [~bibinchundatt].
I've investigated a little this issue.
I guess the change in https://github.com/apache/hadoop/commit/9d4d30243b0fc9630da51a2c17b543ef671d035c causes this issue rather than YARN-4630 if the reason why the MR job fails is as you mention., [~sarutak]
Thank you for correcting me. Will update description too.
cc [~rkanter], {{HADOOP_MAPRED_HOME}} shouldn't be necessary if you're running MR from a tarball in HDFS.  If you need to add {{HADOOP_MAPRED_HOME}}, then I believe you should be able to add it to the classpath for MR jobs via {{mapreduce.admin.user.env}}., Currently we have changed the default behaviour. In {{launch_container.sh}} shouldn't we be adding the default value too rt??
{code}
export HADOOP_MAPRED_HOME={HADOOP_MAPRED_HOME:-xxxxx}
{code}
So that without setting {{mapreduce.admin.user.env}} also we would get the old behaviour.
, Containers shouldn't be relying on getting their environment variables from the NodeManager.  For compatibility, the change in https://github.com/apache/hadoop/commit/9d4d30243b0fc9630da51a2c17b543ef671d035c was only done in trunk.  The equivalent change in branch-2, https://github.com/apache/hadoop/commit/ac8fb579c6058fec60caf30682f902413d68edf3, does not remove _all_ of the environment variables., [~rkanter]
Thank you for clarification
As mentioned above after adding {{mapreduce.admin.user.env}} and {{yarn.app.mapreduce.am.env}} it works fine.
IMHO it will be good to make it work without setting additional parameters too. Attaching patch for the same.

Could you please point me to the JIRA for which change was done to understand further.
, [~bibinchundatt] / [~rkanter]

Is it possible that we can set default value to {{mapreduce.admin.user.env}} and {{yarn.app.mapreduce.am.env}}. By default {{HADOOP_MAPRED_HOME}} can be set as HADOOP_HOME. I guess this can be helpful, and not feeling this as security issue. [~rkanter], do you any security issue if we set a default value?, [~sunilg]
Yes,Was considering this as second solution. As per the offline discussion with [~rohithsharma] Yarn shouldn't have any MR-specific configs so setting the default value as {{HADOOP_COMMON_HOME}} for {{HADOOP_MAPRED_HOME}} should fix the problem., [~bibinchundatt], would you like to update the patch to implement the approach (setting HADOOP_MAPRED_HOME to HADOOP_COMMON_HOME)?

One thing to note is that if the default is defined on the admin env and the user overrides it on the non-admin env things break because YARN would simply concatenate the values (see YARN-4789 and MAPREDUCE-6491). So until that is fixed it might be better to use {{mapred.child.env}} over {{mapreduce.admin.user.env}}., we should move this to Mapred project, if fix is on map reduce related configuration/env, [~sjlee0]/[~Naganarasimha]
Will update the patch soon after moving to mapreduce
, | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 33s {color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:red}-1{color} | {color:red} test4tests {color} | {color:red} 0m 0s {color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue} 0m 7s {color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 6m 41s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 1m 34s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 34s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 0m 54s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 27s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 1m 26s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 0m 40s {color} | {color:green} trunk passed {color} |
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue} 0m 7s {color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 0m 43s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 1m 35s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 1m 35s {color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} checkstyle {color} | {color:red} 0m 31s {color} | {color:red} hadoop-mapreduce-project/hadoop-mapreduce-client: The patch generated 2 new + 621 unchanged - 2 fixed = 623 total (was 623) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 0m 49s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 21s {color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} whitespace {color} | {color:red} 0m 0s {color} | {color:red} The patch has 20 line(s) that end in whitespace. Use git apply --whitespace=fix. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 1m 33s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 0m 32s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 2m 1s {color} | {color:green} hadoop-mapreduce-client-core in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 8m 48s {color} | {color:green} hadoop-mapreduce-client-app in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green} 0m 18s {color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 31m 0s {color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:2c91fd8 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12809399/0001-MAPREDUCE-6704.patch |
| JIRA Issue | MAPREDUCE-6704 |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux 2887d3993199 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 9581fb7 |
| Default Java | 1.8.0_91 |
| findbugs | v3.0.0 |
| checkstyle | https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/6548/artifact/patchprocess/diff-checkstyle-hadoop-mapreduce-project_hadoop-mapreduce-client.txt |
| whitespace | https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/6548/artifact/patchprocess/whitespace-eol.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/6548/testReport/ |
| modules | C: hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app U: hadoop-mapreduce-project/hadoop-mapreduce-client |
| Console output | https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/6548/console |
| Powered by | Apache Yetus 0.3.0   http://yetus.apache.org |


This message was automatically generated.

, [~bibinchundatt] thanks for your contribution.

{quote}
+      "HADOOP_MAPRED_HOME=" + Apps.crossPlatformify("HADOOP_COMMON_HOME");
{quote}

Why not making {{ "HADOOP_MAPRED_HOME="Apps.crossPlatformify("HADOOP_MAPRED_HOME");}}? I think it's more straight forward and better to understand its behaviour.



, Also, after changing default value of properties, could you update ./hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/resources/mapred-default.xml?, bq. By default HADOOP_MAPRED_HOME can be set as HADOOP_HOME. I guess this can be helpful, and not feeling this as security issue.
Agreed. If we are going to do this, we need to revert the documentation of MAPREDUCE-6702 and update the release note. Would you revert the documentation change in this issue?, [~ajisakaa] 

{quote}
Agreed. If we are going to do this, we need to revert the documentation of MAPREDUCE-6702 and update the release note. Would you revert the documentation change in this issue?
{quote}

My previous comment means I don't agree with the point. My thought is that it is not straight forward, and confusing. Hence, I think it should be {{ "HADOOP_MAPRED_HOME="Apps.crossPlatformify("HADOOP_MAPRED_HOME");}}. Could you tell me your thoughts?, IIUC, {{"HADOOP_MAPRED_HOME=" + Apps.crossPlatformify("HADOOP_MAPRED_HOME")}} does not fix the problem because {{HADOOP_MAPRED_HOME}} is not in {{yarn.nodemanager.env-whitelist}} by default (i.e. Container cannot inherit the NodeManager's environment variable {{HADOOP_MAPRED_HOME}} by default)., There has been no guarantee that HADOOP_MAPRED_HOME is the same as HADOOP_COMMON_HOME since 0.22. See libexec/hadoop-layout.sh.example., [~aw]/[~ajisakaa]
Sorry for the delay.

As already mentioned the {{HADOOP_MAPRED_HOME}} is not part of env since not inherited to launcher.Adding 
{code}
yarn.nodemanager.env-whitelist="JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME"
{code}
in yarn-site.xml of NM does solve the problem. But since its a mapreduce property its not correct to add to the whitelist of yarn .

IIUU {{HADOOP_MAPRED_HOME}} for default installation will be same as {{HADOOP_COMMON_HOME}} .
For layout change we can configure explicity mapred.child.env paths.

Till jira is fixed ,to make mapreduce job run add params as below
{code}
-Dmapred.child.env="HADOOP_MAPRED_HOME={{HADOOP_COMMON_HOME}}" -Dyarn.app.mapreduce.am.env="HADOOP_MAPRED_HOME={{HADOOP_COMMON_HOME}}"
{code}

Open to any other solution.
, 
bq.   But since its a mapreduce property its not correct to add to the whitelist of yarn .

Why can't MR add it itself?

bq. But since its a mapreduce property its not correct to add to the whitelist of yarn .

Who cares?  It's all Apache Hadoop. Users have an expectation that this stuff will work *out of the box* and be *consistent*.  They aren't going to say "Oh, of course this is completely broken!  That part over there is YARN and that part over there is MAPREDUCE!"

bq. IIUU HADOOP_MAPRED_HOME for default installation will be same as HADOOP_COMMON_HOME .

It's irrelevant.  HADOOP_MAPRED_HOME is where the mapred stuff is guaranteed to be.   There is no guarantee that HADOOP_COMMON_HOME is going to work. That's why there is a separate variable for it instead of just using HADOOP_COMMON_HOME everywhere.  Either this should be HADOOP_MAPRED_HOME or set nothing at all., 0001-YARN-5026.patch implementation is based on {{HADOOP_MAPRED_HOME}} added to whitelist.
, I encountered this issue too. Quite shocked that commit "9d4d30243b0fc" get merged without basic MRv2 test and even no YARN JIRA for it!
And it's strange that I still fail to run MRv2 application as well as Dockerized MRv2 application after tried the temporary solution mentioned by Bibin A Chundatt. YARN patch also not works for me., [~tangzhankun]

In nodemanager we can add the below config. Last time i checked below solution was  working fine.

yarn.nodemanager.env-whitelist=
"JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME"

, | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 14s {color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:red}-1{color} | {color:red} test4tests {color} | {color:red} 0m 0s {color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue} 0m 8s {color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 6m 58s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 1m 33s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 33s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 0m 55s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 28s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 1m 24s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 0m 36s {color} | {color:green} trunk passed {color} |
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue} 0m 8s {color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 0m 43s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 1m 29s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 1m 29s {color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} checkstyle {color} | {color:red} 0m 31s {color} | {color:red} hadoop-mapreduce-project/hadoop-mapreduce-client: The patch generated 2 new + 622 unchanged - 2 fixed = 624 total (was 624) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 0m 51s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 23s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green} 0m 0s {color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 1m 36s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 0m 31s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 2m 2s {color} | {color:green} hadoop-mapreduce-client-core in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 8m 54s {color} | {color:green} hadoop-mapreduce-client-app in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green} 0m 18s {color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 30m 58s {color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:9560f25 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12809399/0001-MAPREDUCE-6704.patch |
| JIRA Issue | MAPREDUCE-6704 |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux a9335e2f557f 3.13.0-93-generic #140-Ubuntu SMP Mon Jul 18 21:21:05 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 964e546 |
| Default Java | 1.8.0_101 |
| findbugs | v3.0.0 |
| checkstyle | https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/6730/artifact/patchprocess/diff-checkstyle-hadoop-mapreduce-project_hadoop-mapreduce-client.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/6730/testReport/ |
| modules | C: hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app U: hadoop-mapreduce-project/hadoop-mapreduce-client |
| Console output | https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/6730/console |
| Powered by | Apache Yetus 0.3.0   http://yetus.apache.org |


This message was automatically generated.

, {quote}Quite shocked that commit "9d4d30243b0fc" get merged without basic MRv2 test and even no YARN JIRA for it!{quote}
[~tangzhankun], commit "9d4d30243b0fc" when in to fix a security problem.  That's why there's no JIRA and why it's shrouded in mystery.  

{quote}
Who cares? It's all Apache Hadoop. Users have an expectation that this stuff will work out of the box and be consistent. They aren't going to say "Oh, of course this is completely broken! That part over there is YARN and that part over there is MAPREDUCE!"
{quote}
[~aw], my original patch for "9d4d30243b0fc" did add {{HADOOP_MAPRED_HOME}} to Yarn and things did work out of the box.  There was pushback to remove it because of the desire to keep Yarn and MR separate.  Given the difficulty people seem to be having and that there doesn't seem to be a single fix that works for everyone for some reason, perhaps we should revisit that decision?  
, HI Guys, 

Thanks for working on this issue here.  Wonder if we had a consensus about the solution? Can we document the workaround before the solution is in place?

Thanks.

, Per the discussion above, I added config
{code}
<property>
<name>yarn.nodemanager.env-whitelist</name>
<value>=JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME</value>
</property>
{code}
to yarn-site.xml

and ran into the following issue
{code}
Container exited with a non-zero exit code 127. Last 4096 bytes of stderr :
/bin/bash: /bin/java: No such file or directory
{code}

Then I created a soft link from the java I am using to /bin/java, and it works now.

It seems the code has a hardcoded dependency on the existence of /bin/java. Can we find the java in the path setting instead?

Thanks.


, [~yzhangal]
Looks like you have made wrong configuration
{noformat}
<value>=JAVA_HOME
{noformat}

Could please remove {{=}} and try again. I  thought of documenting the white list parameter configuration and closing the issue waiting for +1 which solution to take.
, Thanks [~bibinchundatt], good catch, and sorry for missing that earlier. I tried again after removing "+", it runs.
, Folks, is there any progress we can make on this JIRA? That this doesn't work out of the box anymore has been very surprising to our users. I'd like to get it fixed for alpha2 if possible., [~rkanter]
{quote}
Given the difficulty people seem to be having and that there doesn't seem to be a single fix that works for everyone for some reason, perhaps we should revisit that decision? 
{quote}
IMHO we have to rethink of the same.


Summarizing discussion and solutions

# Add HADOOP_MAPRED_HOME=HADOOP_COMMON_HOME in opts.But its not mandatory that MAPRED_HOME=HADOOP_COMMON_HOME
# Add HADOOP_MAPRED_HOME to Yarn.Since we want to keep YARN and MAPRED separate initial solution was not accepted. 
# Add documentation to configure yarn.nodemanager.env-whitelist in nodemanager to run mapred application
{noformat}
<property>
<name>yarn.nodemanager.env-whitelist</name>
<value>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME</value>
</property>
{noformat}
Waiting for +1 for any one of above solution or inputs for any other approach
, Solution 4:
We should add option in YARN to support sending addition whitelist ENV as part of ContainerLaunchContext. Addition patch for solution 4 also  {{container-whitelist-env-wip.patch}} . created a jira  YARN-5771 also. 
, | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 10s {color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:red}-1{color} | {color:red} test4tests {color} | {color:red} 0m 0s {color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue} 0m 40s {color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 6m 52s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 6m 45s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 1m 36s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 2m 46s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 1m 21s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 4m 18s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 48s {color} | {color:green} trunk passed {color} |
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue} 0m 14s {color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 2m 12s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 6m 44s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} cc {color} | {color:green} 6m 44s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 6m 44s {color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} checkstyle {color} | {color:red} 1m 38s {color} | {color:red} root: The patch generated 8 new + 865 unchanged - 3 fixed = 873 total (was 868) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 2m 45s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 1m 20s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green} 0m 0s {color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 5m 1s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 49s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 0m 24s {color} | {color:green} hadoop-yarn-api in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 2m 16s {color} | {color:green} hadoop-yarn-common in the patch passed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 14m 43s {color} | {color:red} hadoop-yarn-server-nodemanager in the patch failed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 2m 27s {color} | {color:green} hadoop-mapreduce-client-core in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 8m 31s {color} | {color:green} hadoop-mapreduce-client-app in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 111m 23s {color} | {color:green} hadoop-mapreduce-client-jobclient in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green} 0m 31s {color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 189m 53s {color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.yarn.server.nodemanager.containermanager.queuing.TestQueuingContainerManager |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:9560f25 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12834840/container-whitelist-env-wip.patch |
| JIRA Issue | MAPREDUCE-6704 |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  cc  |
| uname | Linux bace1b096a29 3.13.0-93-generic #140-Ubuntu SMP Mon Jul 18 21:21:05 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / d4725bf |
| Default Java | 1.8.0_101 |
| findbugs | v3.0.0 |
| checkstyle | https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/6771/artifact/patchprocess/diff-checkstyle-root.txt |
| unit | https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/6771/artifact/patchprocess/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-nodemanager.txt |
| unit test logs |  https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/6771/artifact/patchprocess/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-nodemanager.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/6771/testReport/ |
| modules | C: hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient U: . |
| Console output | https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/6771/console |
| Powered by | Apache Yetus 0.3.0   http://yetus.apache.org |


This message was automatically generated.

, +1 to #3, but *making it the default*, not just documenting it.  I agree with [~aw] that a little pollution is OK if it makes the out-of-box experience significantly better.  And I don't think spilling over an environment variable is so bad anyway.

#1 has several issues.  In addition to what was already stated, the vars are evaluated on the client, so if the client doesn't have the same paths as the NM hosts, it won't work.

#2 is a code-level pollution, which is a more serious thing than #3.

#4 doesn't sound like the right idea to me.  Users don't need to control the whitelisting on a per-job basis, so it's solving a problem that doesn't exist.  It also has some security implications that need to be carefully considered., As if we're not split enough on this decision, let me throw in one more option.

The final and correct answer is that users should set up distributed cache deployment (per [https://hadoop.apache.org/docs/r3.0.0-alpha1/hadoop-mapreduce-client/hadoop-mapreduce-client-core/DistributedCacheDeploy.html]).  At that point things just work, and upgrades become simpler.  The problem is that distributed cache deployment isn't an option for out of the box.

Spark does not have the problem we're trying to solve here.  Every time you submit a Spark application, they ship the assembly JAR via the distributed cache.  If we want to push users to distributed cache deployment, maybe the way to solve the out-of-box problem is the light version of dist cache deployment: -libjars.

Option #5) Add a MapReduce property that controls whether the MapReduce JARs are automatically shipped with the job via -libjars, and turn it on by default.  Yes, it's inefficient (in both time and space), but it works out of the box and is a natural segue into dist cache deployment., Either #3 (adding {{HADOOP_MAPRED_HOME}} to the classpath) or #5 (though maybe not actually using {{-libjars}} argument, but doing something equivalent) sound good to me.,  Thank you [~templedf] and [~rkanter] for inputs

#3 since for upgrade case when  we have running apps and havnt  used distributed cache.
Need to modify only one config during upgrade and everything works as old. 
Another case can happen when old clients try to submit apps too rt?

{quote}
client doesn't have the same paths as the NM hosts, it won't work.
{quote}
[~templedf] Thank you for bring this scenarios too had missed out.

Will do document update and upload patch soon.

, Since this is a rather core issue, I'd love to see some additional opinions here.  [~andrew.wang], [~varun_saxena], [~ajisakaa], [~sjlee0], [~sunilg], [~Naganarasimha], [~vinodkv], any thoughts?  Should we take this to the mailing list for more visibility?, I am +1 for #3. There is the yuck factor of mixing up MR into YARN, but the issue is significant enough and the change small enough that I think we can make an exception here.

We can move the discussion to the mailing list to expand the audience., +1 for #3.
In MAPREDUCE-6702, I wrote a patch to document that we need to set {{HADOOP_MAPRED_HOME=$HADOOP_COMMON_HOME}} to mapreduce.admin.user.env and yarn.app.mapreduce.am.env, but HADOOP_MAPRED_HOME is not always as same as HADOOP_COMMON_HOME. I'm thinking it's better to set yarn.nodemanager.env-whitelist instead of setting these parameters.
, Yep.  I was planning to submit a JIRA this morning to make exactly that change., Thank you all . Attaching patch based on solution 3, | (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 14s {color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 8m 25s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 2s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 2s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green} 0m 0s {color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green} 0m 22s {color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 11m 20s {color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:9560f25 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12837039/MAPREDUCE-6704.0002.patch |
| JIRA Issue | MAPREDUCE-6704 |
| Optional Tests |  asflicense  mvnsite  |
| uname | Linux 3866c2eb9814 3.13.0-93-generic #140-Ubuntu SMP Mon Jul 18 21:21:05 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 69dd5fa |
| modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |
| Console output | https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/6796/console |
| Powered by | Apache Yetus 0.3.0   http://yetus.apache.org |


This message was automatically generated.

, The patch looks fine.  I'm OK with this solution.  After thinking it over, I don't think we need to take it to the mailing list.  As long as we're just updating docs, this doesn't need to be a high profile issue.

Anyone have any concerns about this patch as the solution to the out-of-the-box issue for MapReduce?, Thank you [~templedf] for looking in to issue .
Attaching html files for reference., | (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 15s {color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 7m 45s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 0m 56s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 0m 48s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green} 0m 0s {color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green} 0m 18s {color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 10m 19s {color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:9560f25 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12837039/MAPREDUCE-6704.0002.patch |
| JIRA Issue | MAPREDUCE-6704 |
| Optional Tests |  asflicense  mvnsite  |
| uname | Linux 011ef3f101a1 3.13.0-93-generic #140-Ubuntu SMP Mon Jul 18 21:21:05 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / d8bab3d |
| modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |
| Console output | https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/6797/console |
| Powered by | Apache Yetus 0.3.0   http://yetus.apache.org |


This message was automatically generated.

, Sorry for coming in late.

+1 for  Option#3. I think its better if we whitelist MR related env variables.
However do we need to whitelist JAVA_HOME by default?, {quote}
However do we need to whitelist JAVA_HOME by default?
{quote}
Its already part of the default list, Yes. Thanks for clarifying. My bad., Thanks [~bibinchundatt] for providing the patch and html files. LGTM, +1., [~bibinchundatt], [~templedf]. Does option#3 works for dockerized MR application? I tried but failed(traditional MR works with option#3). I used "sequenceiq/hadoop-docker" Docker image. The image works in branch-2.8. Any idea?, [~tangzhankun]
{quote}
 I used "sequenceiq/hadoop-docker" Docker image. The image works in branch-2.8. Any idea?
{quote}
Sorry,No idea. Check with hadoop mailing list with logs

[~templedf]
Any more changes required for this jira, [~tangzhankun], I'm pretty surprised by that.  The Docker container should inherit the env vars set for the container, which is what this whitelist property does.  Could you run a Docker job with delayed cleanup ({{yarn.nodemanager.delete.debug-delay-sec}}) set so that you can see the launch script?  That should give you a good idea what's going on.

[~bibinchundatt], I'm fine with the patch, but I would like to understand why it's not working for Docker.  As there are alternative solutions, we should make sure we pick one that works across the board., [~templedf]
I was thinking of handling through mailing list and analyze the logs . We will other any other env needs to  specified 

[~tangzhankun]
As Daniel mentioned after configuring {{yarn.nodemanager.delete.debug-delay-sec}} please attach the following
# launch script
# node manager logs during docker run. 

, [~templedf], [~bibinchundatt] I have done testing again on branch2.8 and trunk to double-check this. The result is that trunk fails on Dockerized MRv2. I would like to upload the tarballs including container logs, NM logs and launch_container.sh.
But I cannot find the button to upload them in this page while I can in YARN JIRAs. Is there any permission required? , Added [~tangzhankun] into contributor role in MR JIRA. Now you can attach files here. Thanks., The tarballs uploaded. Please check., Thanks, Akira., [~tangzhankun]
Thank you for attaching logs. Had quick look are the launch_container.sh
{{HADOOP_MAPRED_HOME}} patch is set based nodemanager which should have worked in all cases.As per my understanding could fail only  when the {{HADOOP_MAPRED_HOME}} where the container do launch is different.

Could you try based on {{temp.patch}} .Currently i don't have docker setup to test my analysis.

{code}
+++ b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/ContainerExecutor.java
@@ -320,11 +320,11 @@ public void writeLaunchEnv(OutputStream out, Map<String, String> environment,
         ContainerLaunch.ShellScriptBuilder.create();
     Set<String> whitelist = new HashSet<>();
 
-    whitelist.add(ApplicationConstants.Environment.HADOOP_YARN_HOME.name());
-    whitelist.add(ApplicationConstants.Environment.HADOOP_COMMON_HOME.name());
-    whitelist.add(ApplicationConstants.Environment.HADOOP_HDFS_HOME.name());
-    whitelist.add(ApplicationConstants.Environment.HADOOP_CONF_DIR.name());
-    whitelist.add(ApplicationConstants.Environment.JAVA_HOME.name());
+    String[] nmWhiteList = conf.get(YarnConfiguration.NM_ENV_WHITELIST,
+        YarnConfiguration.DEFAULT_NM_ENV_WHITELIST).split(",");
+    for (String param : nmWhiteList) {
+      whitelist.add(param);
+    }

{code}

[~templedf] {{ContainerExecutor#writeLaunchEnv}} is handling only the default whitelist params as per current code.Looks like bug in yarn.
 The above change should allow taking the {{HADOOP_MAPRED_HOME}} from docker env during container launch.

{{launcher_container.sh}}  mapred_home_patch will get exported as following.
{noformat}
export HADOOP_MAPRED_HOME=${HADOOP_MAPRED_HOME:-"/home/hadoopbuild"}
{noformat}
instead of 
{noformat}
export HADOOP_MAPRED_HOME="/home/hadoopbuild"
{noformat}

, Thanks. [~bibinchundatt], I agree with your analysis. And will test your patch and give feedback asap., [~bibinchundatt], The temp.patch corrects the HADOOP_MAPRED_HOME variable and the MRAppMaster was found successfully. But then the AM fails on token version check. Please check the container logs uploaded(MR-6704-trunk-tempPatch.tar.gz).
{noformat}
2016-11-14 04:43:47,660 FATAL [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Error starting MRAppMaster
java.io.IOException: Exception reading /tmp/hadoop-yarn/nm-local-dir/usercache/yarn/appcache/application_1479115665737_0004/container_1479115665737_0004_02_000001/container_tokens
        at org.apache.hadoop.security.Credentials.readTokenStorageFile(Credentials.java:198)
        at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:816)
        at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:760)
        at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:633)
        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.initAndStartAppMaster(MRAppMaster.java:1495)
        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.main(MRAppMaster.java:1448)
Caused by: java.io.IOException: Unknown version 1 in token storage.
        at org.apache.hadoop.security.Credentials.readTokenStorageStream(Credentials.java:216)
        at org.apache.hadoop.security.Credentials.readTokenStorageFile(Credentials.java:195)
        ... 5 more
2016-11-14 04:43:47,662 INFO [main] org.apache.hadoop.util.ExitUtil: Exiting with status 1
{noformat}, Not able to read token files could be rights related also. Could you check rights of nm-local-dir is 755.If its a test setup try removing {{nm-local-dir/usercache/yarn}} dir and run again.

[~templedf]
Once you look into the {{temp.patch}} will file a jira in yarn, The rights of nm-local-dir is 755 and it can run MRv2 application. I tried removing nm-local-dir/usercache/yarn and ran dockerized MR, still same error., [~tangzhankun] could be related docker mount , YARN-5765 or 2.7 to hadoop.3.0 compatability Sorry i am new to docker so unaware
[~templedf] Added YARN-5877 to track white list case.
, The token exception is likely due to running a branch-2 MR tarball on trunk. The credential file format has changed from trunk to branch-2., [~vvasudev], Yes, probably. The version of hadoop in Docker image is 2.7.1. But shouldn't the credential file format be backward-compatible?, bq. But shouldn't the credential file format be backward-compatible?

There is no guarantee that running hadoop 2.x jars will work carte blanche on a hadoop 3.x system. This is covered in lots of spots by the Apache Hadoop Compatibility guidelines. More to the point, the token file format is technically Private while the APIs are Public/Evolving. It's wide open to get changed incompatibility.

Slightly off-topic: The token file format in pre-3.x is raw Java objects written to disk. This causes lots of issues, some obvious and some not-obvious. It is now protobuf which fixes a good chunk/all? of the issues.  [I'll omit the list of problems that I'm aware of--which would be incomplete at best--due to length.  It really is that broken. haha.], [~tangzhankun], you'll want to test with a branch-2 cluster so that you have all the latest fixes, so you'll either need to update the Docker image or create your own.  Let us know how the testing goes., [~templedf], [~vvasudev], [~bibinchundatt] I have built a Docker image with hadoop-3.0.0-alpha2 in it. And it passed the testing. So the documentation and temp.patch submitted is needed for fixing this blocker., Thanks, [~tangzhankun].  Just to be clear, you're saying that after resolving your versioning issues, the procedure documented in this patch worked for you?, [~templedf], Yes. First, the whitelist environment "yarn.nodemanager.env-whitelist " solved the traditional MRv2 failure. And the "temp.patch" solved the MRv2 class not found issue in launch_script.sh for LCE Docker support.

Then to run a Dockerized MRv2 application in hadoop-3, we have to build a hadoop-3.0 Docker image to bypass the secure token version issue found in hadoop-2 Docker image currently. I think this also need to be documented. , [~tangzhankun] thank you for providing test result. YARN-5877 is added to track the same.

[~templedf] As per [discussion|https://issues.apache.org/jira/browse/MAPREDUCE-6704?focusedCommentId=15596876&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-15596876] we had identified that Solution 3 is best fit. But for docker to run by default we should support change YARN-5877 (Currently the vars to be fetched from env for docker is fixed we should make it configurable) .[Comment |https://issues.apache.org/jira/browse/MAPREDUCE-6704?focusedCommentId=15661038&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-15661038] explains in details why we should support.

So combination of both would fix completely.



, Works for me., Ping, we getting close on resolving this JIRA?, [~andrew.wang]
Yes we are getting close to resolving.Only documentation update is required as part of this jira.
{{MAPREDUCE-6704.0002}} should  get committed after YARN-5877 is resolved.

, Attaching same patch again , | (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 18s {color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 14m 20s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 5s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 0m 58s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green} 0m 0s {color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green} 0m 19s {color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 17m 15s {color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:a9ad5d6 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12843551/MAPREDUCE-6704.0002.patch |
| JIRA Issue | MAPREDUCE-6704 |
| Optional Tests |  asflicense  mvnsite  |
| uname | Linux a919cfe90daa 3.13.0-95-generic #142-Ubuntu SMP Fri Aug 12 17:00:09 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / cee0c46 |
| modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |
| Console output | https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/6846/console |
| Powered by | Apache Yetus 0.3.0   http://yetus.apache.org |


This message was automatically generated.

, +1 again., Committed. Thanks all!, SUCCESS: Integrated in Jenkins build Hadoop-trunk-Commit #11031 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/11031/])
MAPREDUCE-6704. Update the documents to run MapReduce application. (aajisaka: rev 22befbd585f65934e1d9ae5782a8f961192c0750)
* (edit) hadoop-common-project/hadoop-common/src/site/markdown/ClusterSetup.md
* (edit) hadoop-common-project/hadoop-common/src/site/markdown/SingleCluster.md.vm
]