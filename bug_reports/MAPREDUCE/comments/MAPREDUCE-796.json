[I see the problem in org.apache.hadoop.mapreduce.lib.map.MultithreadedMapper.run with the following fix:

{noformat}
diff --git src/mapred/org/apache/hadoop/mapreduce/lib/map/MultithreadedMapper.java src/mapred/org/apach
index 2e0d6d9..95530f9 100644
--- src/mapred/org/apache/hadoop/mapreduce/lib/map/MultithreadedMapper.java
+++ src/mapred/org/apache/hadoop/mapreduce/lib/map/MultithreadedMapper.java
@@ -146,7 +146,7 @@ public class MultithreadedMapper<K1, V1, K2, V2>
         } else if (th instanceof InterruptedException) {
           throw (InterruptedException) th;
         } else {
-          throw (RuntimeException) th;
+          throw new RuntimeException(th);
         }
       }
     }
{noformat}

The *else* block should probably be:, Observations taken with different set of config parameters for the above mentioned scenario are as follows:

Observation 1:
=============
Heap Size - (mapred.child.java.opts) --> 640MB
Compression code - LzoCodec
Native lib enabled
Result --> ClassCastException with OutOfMemoryError 

Observation 2:
=============
Heap Size - (mapred.child.java.opts) --> 768MB
Compression code - LzoCodec
Native lib enabled
Result --> No Exception/Error

Observation 3:
=============
Heap Size - (mapred.child.java.opts) --> 640MB
Compression code - DefaultCodec
Native lib disabled
Result --> No Exception/Error, Looks like this is a problem caused by a combination of MultiThreadedMapRunner and enabling Native Compression. , Sorry, forgot to add that an increased heap size is a solution to the problem., Attaching a simple fix., +1, I just committed this. Thanks, Amar!, Integrated in Hadoop-Mapreduce-trunk #41 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-Mapreduce-trunk/41/])
    . Fixes a ClassCastException in an exception log in MultiThreadedMapRunner. Contributed by Amar Kamat.
]