[Straightforward patch brings the code in mapred up to speed with the code in mapreduce.

I ported the new tests as well and verified that they all pass., The backport looks OK. Still, there is something that worries me

{code}
+  @Override
+  protected boolean isSplitable(FileSystem fs, Path file) {
+    final CompressionCodec codec =
+      new CompressionCodecFactory(fs.getConf()).getCodec(file);
+    return codec == null;
+  }
{code}

We should take into account splittable codecs, trunk does take into account and so does 0.22. I wonder where/why this got drop in Hadoop 1. Any idea?, As some additional background, MAPREDUCE-1597, the original patch that added isSplitable to CombineFileInputFormat, took splittable codecs into account.  The only place in any history I can find CombineFileInputFormat with an isSplitable method, but without taking splittable codecs into account, is in branch-1., I agree, it should test for {{codec instanceof SplittableCompressionCodec}} like the other FileInputFormats., I filed MAPREDUCE-5046 to backport MAPREDUCE-1423, then found this.

I took a look at the patch here, but I'm not sure if it subsumes the changes contained in MAPREDUCE-1423. Specifically, rackToNodes seems still static, which is a thread-safety problem. Could you absorb the fix that's in MAPREDUCE-1423? I'd be happy to look at that if you want., Filed MAPREDUCE-5049 to handle SplittableCompressionCodec.  Uploaded a new patch that includes MAPREDUCE-1423., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12572246/MAPREDUCE-5038-1.patch
  against trunk revision .

    {color:red}-1 patch{color}.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/3387//console

This message is automatically generated., +1, Thanks Sandy. Thanks Tom for reviewing. Committed to branch-1., I think MAPREDUCE-5046 can be closed, as it is a subset of this patch., It looks like I messed this up and left out part of MAPREDUCE-1597.  Working on a replacement patch., Posted a replacement patch, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12574029/MAPREDUCE-5038-revised.patch
  against trunk revision .

    {color:red}-1 patch{color}.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/3422//console

This message is automatically generated., Attached patch that makes it so that MAPREDUCE-5049 doesn't need to be reverted as well., Sandy, I've just reverted the commit, please upload a rebased patch (note I had to resolve a conflict with MAPREDUCE-5049), {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12574195/MAPREDUCE-5038-revised-1.patch
  against trunk revision .

    {color:red}-1 patch{color}.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/3426//console

This message is automatically generated., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12574202/MAPREDUCE-5038-revised-1.patch
  against trunk revision .

    {color:red}-1 patch{color}.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/3427//console

This message is automatically generated., +1, I've just reverted this from branch-1.2 as well., Thanks Sandy for following up and providing a new patch. Committed to branch-1. Leaving it ut from branch-1.2 as it is about to be cut today per Matt's email last week., Can someone please re-investigate? This is causing hive to fail it's test with "har" filesystem. Here's the stack trace:

{noformat}
java.io.IOException: URI: har://pfile-:/grid/0/jenkins/workspace/UnitTest-Hive-condor-0.11.0/label/centos5/hdp-BUILDS/hive-0.11.0.1.3.0.0/build/ql/test/data/warehouse/tstsrcpart/ds=2008-04-08/data.har/hr=11/000000_0 is an invalid Har URI since host==null. Expecting har://<scheme>-<host>/<path>.
at org.apache.hadoop.fs.HarFileSystem.decodeHarURI(HarFileSystem.java:191)
at org.apache.hadoop.fs.HarFileSystem.initialize(HarFileSystem.java:100)
at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1482)
at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:251)
at org.apache.hadoop.fs.Path.getFileSystem(Path.java:187)
at org.apache.hadoop.mapred.lib.CombineFileInputFormat.getMoreSplits(CombineFileInputFormat.java:270)
at org.apache.hadoop.mapred.lib.CombineFileInputFormat.getSplits(CombineFileInputFormat.java:226)
at org.apache.hadoop.hive.shims.HadoopShimsSecure$CombineFileInputFormatShim.getSplits(HadoopShimsSecure.java:385)
at org.apache.hadoop.hive.shims.HadoopShimsSecure$CombineFileInputFormatShim.getSplits(HadoopShimsSecure.java:351)
at org.apache.hadoop.hive.ql.io.CombineHiveInputFormat.getSplits(CombineHiveInputFormat.java:389)
at org.apache.hadoop.mapred.JobClient.writeOldSplits(JobClient.java:1081)
at org.apache.hadoop.mapred.JobClient.writeSplits(JobClient.java:1073)
at org.apache.hadoop.mapred.JobClient.access$700(JobClient.java:179)
at org.apache.hadoop.mapred.JobClient$2.run(JobClient.java:983)
at org.apache.hadoop.mapred.JobClient$2.run(JobClient.java:936)
at java.security.AccessController.doPrivileged(Native Method)
at javax.security.auth.Subject.doAs(Subject.java:396)
at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1232)
at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:936)
at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:910)
at org.apache.hadoop.hive.ql.exec.ExecDriver.execute(ExecDriver.java:447)
at org.apache.hadoop.hive.ql.exec.ExecDriver.main(ExecDriver.java:687)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
at java.lang.reflect.Method.invoke(Method.java:597)
at org.apache.hadoop.util.RunJar.main(RunJar.java:160)
Job Submission failed with exception 'java.io.IOException(URI: har://pfile-:/grid/0/jenkins/workspace/UnitTest-Hive-condor-0.11.0/label/centos5/hdp-BUILDS/hive-0.11.0.1.3.0.0/build/ql/test/data/warehouse/tstsrcpart/ds=2008-04-08/data.har/hr=11/000000_0 is an invalid Har URI since host==null. Expecting har://<scheme>-<host>/<path>.)'
{noformat}

----

Steps to reproduce:
{noformat}
$ ant test -Dtestcase=TestCliDriver -Dqfile=archive_multi.q
{noformat}

Also, I verified the same test passes when I run with a local build after reverting this patch.

Thanks., Here are the other hive tests that fail with/pass without this patch: combine2.q, sample_is_localmode_hook.q, stats_partscan_1.q, Before MAPREDUCE-1806, CombineFileInputFormat would not interpret har URIs as such.  With the patch, it does, but it seems to be being passed an invalid har URI.  Do we know where that URI is coming from?, [~hagleitn] Thanks for pointing this, along with the test. I verified Hive breaks only with this patch too ([~sandyr] see the test Gunther pointed to).

[~sandyr] I'm mystified too - but Hive has used o.a.h.mapred.CombineFileInputFormat forever and that test (archive_multi.q) has been around since 2011 (HIVE-2278). Also, Hive has had support for HAR for a long while too (ARCHIVE syntax). Looks like we need to investigate this further to see why this broke Hive... can you please look?

Since this is not in 1.2 (currently under vote) I'm not too worried, we can revert this patch if we don't come up with a fix quickly?, Taking a look at this today, Does the version of Hive that's encountering this include HIVE-3338?, I ran the test on hive-0.11, so yes, it includes HIVE-3338. Thanks for checking on this [~sandyr], I've spent a while attempting to run Hive 0.11.0 tests over a version of Hadoop that includes this patch, due to unfamiliarity with ant and the Hive build system, have been unable to figure out how to do it.  I've tried copying into Hive the MapReduce code that touches the Paths in between Hive and where that exception is hit, and I verified that on my setup it produces the correct URL, with "localhost" instead of ":" in the authority.  Is someone who's more familiar with Hive able to figure out where that ":" in the authority is coming from?, [~hagleitn], did you get a chance to look at this?, [~sandyr] Do you know why we are getting the wrong URLs?, From taking a deep look at the CombineFileInputFormat code, as well as copying this code into Hive and running it to see what happens, there doesn't appear to be anything on the MapReduce that could be modifying the authority in the URL that's passed in.  So I think the wrong URLs must be coming from Hive., *on the MapReduce side, To elaborate on that a little further, the relevant change on the MR side was:

{code}
-      Path p = new Path(paths[i].toUri().getPath());
+      FileSystem fs = paths[i].getFileSystem(conf);
+      Path p = fs.makeQualified(paths[i]);
{code}

so a path that was previously not examined now is, which makes me think that the change exposed a preexisting bug.  Not having had success at running the Hive tests on top of a patched MR, I can't speak with 100% confidence, but if anyone knowledgeable about the Hive side wants to take a look, I'd be happy to help investigate on or offline.]