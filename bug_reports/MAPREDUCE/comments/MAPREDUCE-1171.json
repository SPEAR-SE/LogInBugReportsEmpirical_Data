[HADOOP-3327 seemed to have introduced the jobtracker notification on a single read-error., This is caused by a behavioral change in hadoop 0.20.1. In 0.18.3, the fetch-retry behavior used to be that each map output fetch will retry N (by default 6) times. Now in 0.20.1, not each map output fetch will have N retries. For a particular map output, only the first fetch attempt will have N retries. If the first N retry fails, subsequent fetch attempt, even it is from a different node, will only have 2 retries before failure. Thus, it greatly increased the chance of having "too many fetch failures".

The line of code is in src/mapred/org/apache/hadoop/mapred/ReduceTask.java, line 2090 to line 2104.

I would argue that if the subsequent map output fetch attempt is from the mapper node, it should only have 2 retries. However, if the map output is from a different mapper node (basically a different map attempt), it should still have N retries., The algorithm in hadoop-0.20 that determines when to mark a map task as having too many fetch failures seems to have big problems with jobs that have a few out-layers in map task runtimes.

The job mentioned in the description has a couple of map tasks requiring about 3 hours of runtime (1hr application execution time and 2hrs merge phase), with the overall average map runtime much smaller.
The consequence is that all reduces just wait for these few map tasks to finish, and these maps get declared as 'failed' very quickly because of many socket timeout exceptions on the reduce side although there is nothing wrong with the map tasks.

The first attempt to run the job failed after 28hrs (we allow for up to 10 map task failures), with about only 200 reduces successfully fetching map output every time the long running map tasks completed; these map tasks got declared as failed within less than 1 minute after completion.

We deployed an emergency fetch in the ReduceTask, commenting out the portion where a single read error results in a report:
{noformat}
  
              if (//cr.getError().equals(CopyOutputErrorType.READ_ERROR) ||
                 ((noFailedFetches >= fetchRetriesPerMap)
                  && ((noFailedFetches - fetchRetriesPerMap) % 2) == 0)) {
                synchronized (ReduceTask.this) {
                  taskStatus.addFetchFailedMap(mapTaskId);
{noformat}
and it helped somewhat.
The job finished after 6 re-executions of the long running map tasks (fortunately, we allow a high number of map task failures), but still took 18hrs instead of optimally less than 4 hrs. About 600 reduces got map output successfully before the map tasks got declared as failed, always because of 5+ socket timeout exceptions (one advantage of hadoop-0.20 to retry a fetch within a few seconds was counter-productive here).

With hadoop-0.18.3 this job  needed less than 9 hrs (not optimal but we could live with it).

Take away:
Current algorithm is not general enough to cover all corner cases, in particular jobs with a handful of much longer running map tasks.
It should be improved (there should be an allowance for socket timeout exceptions when a high number of reduces fetch output from a single map task in parallel) or there should be a configuration option to allow to override the threshold on a per job basis., HADOOP-3327 went into branch 0.21, Christian, are you using Yahoo! distribution for 0.20? 

In branch 0.21, MAPREDUCE-353 makes connect and read timeout configurable for a job. Moreover, Shuffle is simplified by MAPREDUCE-318. Essentially, HADOOP-3327 is no more there. 

Christian, Making connect and read timeout configurable should address this issue, right?, Just for the record, we use a 020.1 yahoo release.
I checked that Cloudera releases contain HADOOP-3327 as early as hadoop-0.20.0+61., Yes, in absence of MAPREDUCE-318, MAPREDUCE-353 should be sufficient to work around the issue., are the fixes for this problem already checked into the Yahoo 0.20 release?, No, they are not checked in., bq. In branch 0.21, MAPREDUCE-353 makes connect and read timeout configurable for a job. Moreover, Shuffle is simplified by MAPREDUCE-318. Essentially, HADOOP-3327 is no more there.

Sorry, just verified the new shuffle code, the code for HADOOP-3327 still exists., One solution I could see is
"Provide a config option whether to send a notification for read error or not, and  make number of retries (currently this is hardcoded to 10 on 0.21) on a fetch failure configurable"
However, for Yahoo! distribution, the config option to send a notification for read error or not, would suffice., bq. Provide a config option whether to send a notification for read error or not

Just to clarify this a little more. Currently a notification is sent for _every_ read error. The config option would be to disable this behavior and treat read errors similar to connection errors., Patch adding the suggested config variables.

Tested the patch manually by simulating read timeout and verified with configuration "mapreduce.reduce.shuffle.notify.readerror" set to true, the fetch failure is notified after "mapreduce.reduce.shuffle.maxfetchfailures". With "mapreduce.reduce.shuffle.notify.readerror" set to false, it is notified immediately after the failure., bq. verified with configuration "mapreduce.reduce.shuffle.notify.readerror" set to true, the fetch failure is notified after "mapreduce.reduce.shuffle.maxfetchfailures". With "mapreduce.reduce.shuffle.notify.readerror" set to false, it is notified immediately after the failure.
Sorry.. I interchanged true and false in above statement. Verified with configuration "mapreduce.reduce.shuffle.notify.readerror" set to false, the fetch failure is notified after "mapreduce.reduce.shuffle.maxfetchfailures". With "mapreduce.reduce.shuffle.notify.readerror" set to true, it is notified immediately after the failure., Patch looks fine to me, couple of minor nits

# Can we rename {{maxFetchFailuresBeforeReport}} to {{maxFetchFailuresBeforeReporting}}
# I think the documentation in mapred-default for {{mapreduce.reduce.shuffle.notify.readerror}} can be changed to probably something like {{Expert. Flag to decide whether JobTracker should be notified on every read error or not. If the flag is false, read errors are treated similar to connection errors}}.
, -1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12427455/patch-1171.txt
  against trunk revision 888761.

    +1 @author.  The patch does not contain any @author tags.

    -1 tests included.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    +1 core tests.  The patch passed core unit tests.

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Mapreduce-Patch-h6.grid.sp2.yahoo.net/308/testReport/
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Mapreduce-Patch-h6.grid.sp2.yahoo.net/308/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Mapreduce-Patch-h6.grid.sp2.yahoo.net/308/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Mapreduce-Patch-h6.grid.sp2.yahoo.net/308/console

This message is automatically generated., Patch with changes suggested by Jothi, Patch for Yahoo! distribution.

test-patch result:
{noformat}
     [exec] -1 overall.
     [exec]
     [exec]     +1 @author.  The patch does not contain any @author tags.
     [exec]
     [exec]     -1 tests included.  The patch doesn't appear to include any new or modified tests.
     [exec]                         Please justify why no tests are needed for this patch.
     [exec]
     [exec]     +1 javadoc.  The javadoc tool did not generate any warning messages.
     [exec]
     [exec]     +1 javac.  The applied patch does not increase the total number of javac compiler warnings.
     [exec]
     [exec]     +1 findbugs.  The patch does not introduce any new Findbugs warnings.
{noformat}
Manually verified the configuration is honored by simulating read time out for a map on a tasktracker., -1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12427567/patch-1171-ydist.txt
  against trunk revision 889085.

    +1 @author.  The patch does not contain any @author tags.

    -1 tests included.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    -1 patch.  The patch command could not apply the patch.

Console output: http://hudson.zones.apache.org/hudson/job/Mapreduce-Patch-h3.grid.sp2.yahoo.net/181/console

This message is automatically generated., Removed the documentation from mapred-default.xml, suggusted by Arun., Patch for trunk., -1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12427572/patch-1171-2.txt
  against trunk revision 889085.

    +1 @author.  The patch does not contain any @author tags.

    -1 tests included.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    -1 core tests.  The patch failed core unit tests.

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Mapreduce-Patch-h6.grid.sp2.yahoo.net/314/testReport/
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Mapreduce-Patch-h6.grid.sp2.yahoo.net/314/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Mapreduce-Patch-h6.grid.sp2.yahoo.net/314/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Mapreduce-Patch-h6.grid.sp2.yahoo.net/314/console

This message is automatically generated., The test failure, TestTrackerBlacklistAcrossJobs, is unrelated to the patch. The log has following ZipException :
{noformat}
2009-12-10 07:51:17,307 WARN  mapred.TaskTracker (TaskTracker.java:startNewTask(1887)) - Error initializing attempt_20091210075025802_0001_m_000001_0:
java.lang.RuntimeException: java.util.zip.ZipException: ZIP_Read: error reading zip file
	at org.apache.hadoop.conf.Configuration.loadResource(Configuration.java:1600)
	at org.apache.hadoop.conf.Configuration.loadResources(Configuration.java:1408)
	at org.apache.hadoop.conf.Configuration.getProps(Configuration.java:1352)
	at org.apache.hadoop.conf.Configuration.get(Configuration.java:574)
	at org.apache.hadoop.mapred.JobConf.checkAndWarnDeprecation(JobConf.java:1874)
	at org.apache.hadoop.mapred.JobConf.<init>(JobConf.java:392)
	at org.apache.hadoop.mapred.TaskTracker.localizeJobFiles(TaskTracker.java:925)
	at org.apache.hadoop.mapred.TaskTracker.localizeJob(TaskTracker.java:869)
	at org.apache.hadoop.mapred.TaskTracker.startNewTask(TaskTracker.java:1883)
	at org.apache.hadoop.mapred.TaskTracker.access$1200(TaskTracker.java:109)
	at org.apache.hadoop.mapred.TaskTracker$TaskLauncher.run(TaskTracker.java:1848)
{noformat}

The same test passes on my machine., All unit test except TestHdfsProxy passed on machine, with ydist patch., hi amareshwari 7 jothi: can you pl advice is you plan to check this patch into the 0.20 release? or to the yahoodist 0.20 release?, Dhruba - currently the plan is to put this into 21 and y20. , I've just committed this. Thanks, Amareshwari!, Integrated in Hadoop-Mapreduce-trunk #171 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-Mapreduce-trunk/171/])
    . Allow shuffle retries and read-error reporting to be configurable. Contributed by Amareshwari Sriramadasu.
]