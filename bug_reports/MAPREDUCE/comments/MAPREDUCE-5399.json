[While working on the fix, I figured, that this bug might not apply on the official Apache Hadoop version, since the code differs a lot in the ReduceTask.run() method from the one used in Cloudera distribution. So please close the ticket as irrelevant, if this is the case., If this is indeed an issue with Apache Hadoop-1.x, please feel free to file a jira with details specific to that. Issues with a particular vendor's distro should be redirected to the vendor in question. , As can be observed from the stack trace versus the 1.x code which is close to his used version, InMemoryFileReader on 1.x too loads up a null config object, causing the same issue (unless Configuration has itself improved recently in not always reloading defaults and overrides from disk)., This is a problem in trunk and 2.x.  Looking at IFileInputStream, it clearly creates a new Configuration object if null is passed in to the constructor, and InMemoryReader does exactly this., Appears to have been caused by MAPREDUCE-4511., [~stanislav.barton], are you planning on working on this?, I have reviewed [MAPREDUCE-4511] and it relates, the first version of the patch mentioned there would fix this bug (in case the conf == null it uses directly default values instead of creating a new conf object and try to read the defaults from there). However, I have fixed this on my side (using the sources of the Distro I am using) by introducing new constructor for InMemoryReader:

public InMemoryReader(RamManager ramManager, TaskAttemptID taskAttemptId,
                          byte[] data, int start, int length, JobConf conf)
                          throws IOException {        
      super(conf, null, length - start, null, null);
      LOG.info("Using job conf instead of creating new one");
...

and consequently replacing the usage of the old constructor (without configuration) by this new one. I have deployed and it took effect and the time in reduce's sort dropped from 3-4 minutes to 0-5 seconds. I tried to find whether the old constructor was used elsewhere but it seems its not the case and the old one could be dropped. The read ahead is used on default in IFileInputStream. , [~stanislav.barton], are you planning to work on this? Otherwise, I am thinking of taking it up.
, OK, I started preparing the patch for the trunk version, but the test take ages to finish. Hope to have it ready soon., Hi [~stanislav.barton],

Do you have the patch? As we are also hitting this issue and want to commit this asap?

Thanks,
Mayank, I have the patch for the TRUNK version (the build created 3.0.0-SNAPSHOT), but I checked out the code of the two proposed versions (1.1.0 and 2.0.2-a) and the patch for trunk is applicable only to the latter. Should I create the patch for the former as well?, I don't see the trunk patch attached to this JIRA.  Could you attach it?  Once it's attached, the Jenkins bot will notice it and can comment on it, and others can review it as well.

Usually we iterate on the trunk patch before worrying about other branches, because normally changes go through trunk and later versions before earlier versions.  This helps prevent the situation where an older Hadoop version has the fix but it's missing from a later version.  Often the trunk patch will apply to the 2.x line as-is, and we can work on the 1.x patch after iterating on the trunk version., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12595426/MAPREDUCE-5399.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/3926//testReport/
Console output: https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/3926//console

This message is automatically generated., In the proposed patch, I have replaced the constructor that allowed passing no Configuration object, then looked for all usages of the removed constructor and fixed the call by adding the Configuration object already known from the context. To my opinion, if the code compiles and the tests pass, it should be good to go, since the new constructor is not backwards compatible., The patch looks good to me.  It seems like this would be difficult to write a test for.  Have you done any benchmarking to see if/how much it improves performance?, I have patched (with a different patch) the distro we are using in the company. The idea was the same, I have replaced the Constructor with the proposed one at the InMemoryReader and it helped to cut the time spent sorting enormously (from 3mins to 3 seconds). I tried to simulate this on my local machine and the wordcount example but am having memory issues and it is not possible to change the distro here to test on the real cluster. So, provided that the configuration object is not null in the context of the call in this distro (it is not in the distro I am using) it will work as well here., +1.  Are you able to create a patch for branch-1 as well?, Upgrading this to a Blocker per an offline discussion with [~acmurthy], In that case I'm going to commit the trunk/branch-2 patch later today., [~sandyr] Can you pls commit this to trunk, branch-2, branch-2.1-beta and branch-2.1.0-beta? Thanks!, I am hitting this issue in Hadoop-1, Is anybody working on this one for Hadoop-1 patch?

Thanks,
Mayank


, I just committed this to trunk, branch-2, branch-2.1-beta, and branch-2.1.0-beta.  Thanks Stanislav!  Leaving this open for the branch-1 fix., SUCCESS: Integrated in Hadoop-trunk-Commit #4218 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/4218/])
MAPREDUCE-5399. Unnecessary Configuration instantiation in IFileInputStream slows down merge. (Stanislav Barton via Sandy Ryza) (sandy: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1510811)
* /hadoop/common/trunk/hadoop-mapreduce-project/CHANGES.txt
* /hadoop/common/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/BackupStore.java
* /hadoop/common/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/reduce/InMemoryReader.java
* /hadoop/common/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/reduce/MergeManagerImpl.java
, Thanks Sandy. I'll close this and clone one for branch-1 fix to allow me to spin rc2 for hadoop-2. Ok? , SUCCESS: Integrated in Hadoop-Yarn-trunk #293 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/293/])
MAPREDUCE-5399. Unnecessary Configuration instantiation in IFileInputStream slows down merge. (Stanislav Barton via Sandy Ryza) (sandy: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1510811)
* /hadoop/common/trunk/hadoop-mapreduce-project/CHANGES.txt
* /hadoop/common/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/BackupStore.java
* /hadoop/common/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/reduce/InMemoryReader.java
* /hadoop/common/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/reduce/MergeManagerImpl.java
, FAILURE: Integrated in Hadoop-Hdfs-trunk #1483 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1483/])
MAPREDUCE-5399. Unnecessary Configuration instantiation in IFileInputStream slows down merge. (Stanislav Barton via Sandy Ryza) (sandy: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1510811)
* /hadoop/common/trunk/hadoop-mapreduce-project/CHANGES.txt
* /hadoop/common/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/BackupStore.java
* /hadoop/common/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/reduce/InMemoryReader.java
* /hadoop/common/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/reduce/MergeManagerImpl.java
, FAILURE: Integrated in Hadoop-Mapreduce-trunk #1510 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1510/])
MAPREDUCE-5399. Unnecessary Configuration instantiation in IFileInputStream slows down merge. (Stanislav Barton via Sandy Ryza) (sandy: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1510811)
* /hadoop/common/trunk/hadoop-mapreduce-project/CHANGES.txt
* /hadoop/common/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/BackupStore.java
* /hadoop/common/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/reduce/InMemoryReader.java
* /hadoop/common/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/reduce/MergeManagerImpl.java
]