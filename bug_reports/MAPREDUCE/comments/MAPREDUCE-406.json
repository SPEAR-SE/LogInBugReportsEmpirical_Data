[first stack trace:
2009-01-28 18:15:41,531 ERROR org.apache.hadoop.mapred.EagerTaskInitializationListener: Job initialization failed:
java.lang.IllegalArgumentException
        at java.net.URI.create(URI.java:842)
        at org.apache.hadoop.fs.FileSystem.getDefaultUri(FileSystem.java:128)
        at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:208)
        at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
        at org.apache.hadoop.mapred.JobHistory$JobInfo.getJobHistoryFileName(JobHistory.java:630)
        at org.apache.hadoop.mapred.JobHistory$JobInfo.logSubmitted(JobHistory.java:803)
        at org.apache.hadoop.mapred.JobInProgress.initTasks(JobInProgress.java:353)
        at org.apache.hadoop.mapred.EagerTaskInitializationListener$JobInitThread.run(EagerTaskInitializationListener.java:55)
        at java.lang.Thread.run(Thread.java:637)
Caused by: java.net.URISyntaxException: Illegal character in authority at index 7: hdfs://${name}
        at java.net.URI$Parser.fail(URI.java:2809)
        at java.net.URI$Parser.parseAuthority(URI.java:3147)
        at java.net.URI$Parser.parseHierarchical(URI.java:3058)
        at java.net.URI$Parser.parse(URI.java:3014)
        at java.net.URI.<init>(URI.java:578)
        at java.net.URI.create(URI.java:840)
        ... 8 more

code with the problem:

class JobInitThread implements Runnable {
    public void run() {
      JobInProgress job;
      while (true) {
        job = null;
        try {
          synchronized (jobInitQueue) {
            while (jobInitQueue.isEmpty()) {
              jobInitQueue.wait();
            }
            job = jobInitQueue.remove(0);
          }
          job.initTasks();
        } catch (InterruptedException t) {
          break;
        } catch (Throwable t) {
          LOG.error("Job initialization failed:\n" +
                    StringUtils.stringifyException(t));
          if (job != null) {
            job.fail();
          }
        }
      }
    }
  }

job.fail() eventually calls garbageCollect() which trys to get the filesystem from the jobconf.  The same exceptoin as above will occur when it trys to cleanup the dfs tmp dir, but this time it's not caught (being thrown inside the catch() block) and kills the JobInitThread, and this manifests by the JobTracker never launching any more jobs (it receives ok and the jobs submitted count increases), This is only loosely related to HADOOP-5687. That was bad failing on invalid fs.default.name values in the NN. This is bad handling of the (correct) failure to parse bad fs.default.name values. The changes I'm doing for HADOOP-5687 will change the error message to be more helpful, but you still need that code in the JobInitThread to catch the bad value during the cleanup process, which is what is apparently happening here., We've seen this behavior on 0.18.3 as well, for other malformed URIs.

I believe this to be fixed in 0.20 since EagerTaskInitializationListener was refactored., closing this as fixed based upon Todd's comment.]