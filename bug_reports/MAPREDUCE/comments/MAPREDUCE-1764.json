[One option is to cache the searched result for each TT. So next time we directly skip the TT without the allowed locality level.
What do you think?, how expensive (memory wise) would it be to add indices from node->[tasks] and rack->[tasks] based on split information?

leaving slots idle seems like a real bummer. it would seem better to be greedy and always grab something (especially if the fraction of non-local tasks is within tolerable limits), Joydeep:

Matei and I had some discussion and we have also looked the code.
In JobInProgress, there is such a HashMap of node->[tasks] and rack->[tasks] exists.
It is not clear to me why this is so slow.

I agree with your point that we should not leave the slots idle especially in the case that cluster is full of jobs., it seems better to find out why the index is not helping (assuming it's actually being used) rather than adding another cache on top ..]