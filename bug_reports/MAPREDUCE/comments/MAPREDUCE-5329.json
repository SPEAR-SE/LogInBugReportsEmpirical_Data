[Can the MR AM specify the service to be used via configuration, and set the service data accordingly., Hi Siddharth,

I am not sure I understand the question.  Do you suggest that we'll have a configuration with sub-list of the AuxServices and only members of the new list will get the APPLICATION_INIT event?
- This is possible, however, it will not match the current behavior with APPLICATION_STOP event, since the last event is being sent to ALL AuxServices.

Please elaborate., It should be possible to configure the MR AM with the shuffle service that needs to be used, in which case the MR AM sets up the service id correctly (in TaskAttemptImpl), and the NodeManager can send the init event to the correct service. We should probably change the stop to behave the same way. , This idea will force us to restart mapred daemons any time we want to switch shuffle service and will limit us to having just 1 ShuffleProvider at a time.  I already discussed this idea in MAPREDUCE-4049 (look for the word multiple there).  I am pasting here one paragraph from that discussion:

{quote}
It could be that a ShuffleConsumerX will be ideal for jobs of one type, while ShuffleConsumerY will be ideal for jobs of other type (for example Grep vs. TeraSort). Hence, multiple Shuffle-Consumer plugins may run in parallel in multiple jobs. Each of the consumers will contact its desired shuffle provider. Hence, all providers should be available in parallel (also, one shuffle service can be sensitive to type of network problems that doesn't disturb other shuffle services, hence, it should be possible to fallback to another shuffle on the fly).
{quote}, With YARN, a new AM (Application) is started per job. The initApp in the NM is per app - so each job/app can choose which shuffle provider it wants to use. The shuffle service configured for an AM will be specific to a single job only.
From MAPREDUCE-4049
bq.  A shuffle consumer instance will only contact one of the shuffle providers and will request its desired files only from from this provider.

I'm assuming a single job will only use one shuffle provider - or do you see a situation where multiple shuffle providers can serve data to a single job ?

In case of multiple jobs being run by a single AM - this gets more complicated, and we may need to initialize multiple providers., Thanks for the explanation about YARN.  Still this is not enough, for two reasons:

1. It is true that *usually* "A shuffle consumer instance will only contact one of the shuffle providers". Still, as written in the quote I pasted , "it should be possible to fallback to another shuffle on the fly".  This means that one consumer can load another consumer and serve as proxy to the real consumer that will contact another provider.

2. In a single job there are multiple reducers each with its own shuffle consumer instance; hence, we have *multiple shuffle consumers per job*.  It should be possible for each consumer to choose its preffered provider based on memory/network/... condition on its machine regardless of other consumers in the same job.  
, 
Hi Siddharth
In addition to what I wrote, I just noticed that perhaps we have a misunderstanding.
See "Implementing a Custom Shuffle" from [Hadoop documentation about Pluggable Shuffle|http://hadoop.apache.org/docs/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core/PluggableShuffleAndPluggableSort.html]
{quote}
A custom shuffle implementation requires a org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices.AuxiliaryServiceimplementation class running in the NodeManagers and a org.apache.hadoop.mapred.ShuffleConsumerPlugin implementation class running in the Reducer tasks.
The default implementations provided by Hadoop can be used as references:
•	org.apache.hadoop.mapred.ShuffleHandler
•	org.apache.hadoop.mapreduce.task.reduce.Shuffle
{quote}

In this issue we are talking about the *provider side of the Shuffle*, we want to have additional ShuffleProvider(s) in addition to the default ShuffleHandler.
All shuffle providers are AuxServices running in the NodeManager.  I see them as daemons like ShuffleHandler, they are not applications or jobs. If I understand correctly, in order to simultaneously support multiple jobs of multiple users that each can contact different Shuffle provider we must have all providers in the air in parallel.
With this, the ShuffleConsumer in each reducer will be able to request MOFs from its desired provider.  However, the provider must know where in the disks are the MOFs of a particular job.  The way to know that (see ShuffleHandler) is based on the mapping: jobId -> userId.  This data for this map arrive from the APPLICATION_INIT event.  Hence, all AuxServices that serve as ShuffleProviders need to get APPLICATION_INIT events.
, bq. If I understand correctly, in order to simultaneously support multiple jobs of multiple users that each can contact different Shuffle provider we must have all providers in the air in parallel.
Multiple providers can be run by the NodeManager in parallel. An application chooses which provider(s) it wants to use when it starts a container on a NodeManager.

bq. This data for this map arrive from the APPLICATION_INIT event. Hence, all AuxServices that serve as ShuffleProviders need to get APPLICATION_INIT events.
The data in the APPLICAITON_INIT event is from the startContainer request (the serviceData in the ContainerLaunchConetxt). If the application wants the INIT event to go to multiple providers, it can set the service data accordingly. The MapReduce AM hardcodes this to the default SHUFFLE_PROVIDER which is why only that one gets the init event.

There may be auxillary services which are not responsible for shuffle, or are in general incompatible with the shuffle consumer configured by the job. I don't think they need to get an INIT event., Moved this over to MapReduce, since the MR-AM needs to set the serviceData correctly to initialize the correct ShuffleService on the nodemanager., {quote}
The data in the APPLICAITON_INIT event is from the startContainer request (the serviceData in the ContainerLaunchConetxt). If the application wants the INIT event to go to multiple providers, it can set the service data accordingly. The MapReduce AM hardcodes this to the default SHUFFLE_PROVIDER which is why only that one gets the init event.
{quote}

Thanks. I was not aware of that!
I have no experience in this, can you tell me, in case I want the INIT event to go to multiple providers, can I do that through XML configuration, or do I need to change the code of the application for that?
, Another comment,
I looked in the code of *createCommonContainerLaunchContext* in TaskAttemptImpl.java, it appears that this method *creates a brand new serviceData* and fills it explicitly with just the builtin "ShuffleHandler" using:
{code}
    // Service data
    Map<String, ByteBuffer> serviceData = new HashMap<String, ByteBuffer>();
...
      // Add shuffle token
      LOG.info("Putting shuffle token in serviceData");
      serviceData.put(ShuffleHandler.MAPREDUCE_SHUFFLE_SERVICEID,
          ShuffleHandler.serializeServiceData(jobToken));
{code}

The only external input to this code snippet is the jobToken which is truly an argument to the method.  Hence, *it seems that an application can only determine the jobToken in the serviceData, but NOT the services in the serviceData*.

Now, If you don't want all AuxServices to get INIT event, we can create a new conf param with the sub-list of AuxServices that should get INIT event (and the default value will be the builtin 'ShuffleHandler' instead of hard-coded).  However, I don't think there is an AuxService that is incompatible with INIT event since the initApp method is part of the AuxiliaryService interface. Hence, my private opinion is that sending INIT to all AuxServices matches the current design. However, it is your call to decide. I am okay with any option that can work, and the best option is without code changes - if this is possible :), bq.  I am okay with any option that can work, and the best option is without code changes - if this is possible.
That would be awesome :), but something needs to change - either the NM to send the event to all services, or the MR AM to get the list of handlers via config. I prefer the second option. Any new AuxServices should be capable of handling init/finish events though - since users can specify pretty much any service even if they aren't used., sounds very good.
Please let me know where in MR AM you want the code change, are we still talking about TaskAttemptImpl.java, or do you have something else in mind?
Also, I need to understand if you want new config for handlers/appliction-listeners, or that we can manage with the current aux-services config?
, This could end up being a complicated change depending on the kind of configuration information required by your providers / consumers. Does your custom shuffle handler have a port as the service data ? That's ingrained into the MR AM and tasks. See ContainerLauncherImpl. In this case it may not be too complicated. 

This will likely need additional config parameters to configure the list of aux services being used, along with their service IDs. TaskAttemptImpl will also need change., Hi Siddharth,

A change in TaskAttemptImpl.java is enough for ShuffleProviders.
If a 3rd party ShuffleProvider need specific configuration, it can support extra new config fields for itself that will be set by the user and will be ignored by other components.
According to my tests, a change in TaskAttemptImpl.java solves the issue. I have no problem to limit it to sub set of aux-services that will be in a new config.
Avner
, That sounds good for now. I'd change ContainerLauncherImpl as well though to deserialize the metadata returned by the specific provider., one littele concern though, In case we do the discussed change in TaskAttemptImpl.java then APPLICATION_INIT will be sent multiple times, one for each provider, which is good.  However, I believe our change will cause APPLICATION_STOP to be sent multiple times too.  Now, as a result of MAPREDUCE-2668, any time APPLICATION_STOP is arrived to AuxServices.handle() it is demultiplexed to ALL AuxServices; hence, each AuxService will receive stopApp() multiple times.

In order to prevent that, we may revert the demultiplexing in AuxServices.handle().  However, we currently have discrepency, because we send stopApp() to all AuxServices, but we suggested to send initApp() just to sub list of AuxServices.  Hence, I suggest again to send both initApp() and stopApp() to ALL AuxServices.  This also matches the interface of AuxiliaryService which declares both initApp() and stopApp() for ALL aux-services., Hi Siddharth,
just to let you know that you can ignore my previous comment.  I checked the log files and saw that, even when I changed the code and called serviceData.put(...) multiple times because of multiple handlers, still APPLICATION_STOP is arrived just once to AuxServices.handle (and demultiplexed just once to each service).  Hence, all is good and we can stay with the option you liked.
Thanks,
  Avner

, The start/stop behaviour should be consistent. We shouldn't send the stop to all service. Can you please open a YARN jira for this., Sure. I'll open it.

I understand we are talking about new config with name, default value, and description like the below.  Right?
If yes, please feel free to edit anything in the below.

{code}
  <property>
    <name>yarn.nodemanager.aux-services.application-listeners</name>
    <value>mapreduce.shuffle</value>
    <description> comma delimited list of aux-services that should receive
                  APPLICATION_INIT/APPLICATION_STOP events.  
                  This list must be sub list of yarn.nodemanager.aux-services 
    </description>
  </property>
{code}


, If the change is in the MapReduce AM - the property should be defined for that.
Something like
<name>mapreduce.shuffle.provider.class</name>
<value>Either the class name, or the service name as long as the AM has enough information to convert this into a class - based on the configured shuffle providers</value>, got it!
So in general we are talking about a change in *TaskAttemptImpl.java*, in which we should remove the hard-coded:
{code}
      serviceData.put(ShuffleHandler.MAPREDUCE_SHUFFLE_SERVICEID,
          ShuffleHandler.serializeServiceData(shuffleToken));
{code}
and replace it with something based on:
{code}
    Collection<String> shuffleProviders = conf.getStringCollection(
        "mapreduce.shuffle.provider.plugin.classes"); // the constant will come from mapreduce/MRConfig.java

    Collection<String> auxNames = conf.getStringCollection(
        YarnConfiguration.NM_AUX_SERVICES);
    for (final String serviceName : auxNames) {
      try {
        String serviceStr = String.format(YarnConfiguration.NM_AUX_SERVICE_FMT, serviceName);
        String serviceClassName = conf.get(serviceStr);
        if (shuffleProviders.contains(serviceClassName)) {
                LOG.info("Adding " + serviceName + " to serviceData, serviceClassName=" + serviceClassName);
                serviceData.put(serviceName, ShuffleHandler.serializeServiceData(shuffleToken));
        }

      } catch (RuntimeException e) {
        LOG.error("Failed in " + serviceName+ ", " + serviceClassName, e);
        throw e;
      }
    }
{code}
Is this what you have in mind? Do you see anything else?, Hi Siddharth,
Based on your request, I created YARN-886 make APPLICATION_STOP consistent with APPLICATION_INIT
Avner, bq. serviceData.put(serviceName, ShuffleHandler.serializeServiceData(shuffleToken));
Shouldn't this be specific to the shuffle provider ?

Also the alternate provider also works with a single shuffle port and makes use of job tokens, correct ? Shuffle port being ingrained in several places in the AM makes this a tough change for other types of providers.

I believe you want to fall back to a different shuffle provider if one does not work. I assume they're running on different ports - am not sure the fallback will work in that case. 

ContainerLauncherImpl likely needs some change as well - since the startContainer response contains service data set by the specific provider, and is deserialized in the AM to figure out the shuffle port. If you use a provider other than the default ShuffleHandler - the port should be read based on that providers service id.

bq.  Based on your request, I created YARN-886 make APPLICATION_STOP consistent with APPLICATION_INIT
Thanks, {quote}
serviceData.put(serviceName, ShuffleHandler.serializeServiceData(shuffleToken));
Shouldn't this be specific to the shuffle provider ?
{quote}
I don't know.  So far, I never used security.  Please let me know what do you suggest here?

{quote}
I believe you want to fall back to a different shuffle provider if one does not work. I assume they're running on different ports - am not sure the fallback will work in that case.
{quote}

The fallback already works for me in many tests.
Regarding the port, I expected that 3rd party shuffle providers will specify their port as a new user config in mapred-site.xml (according to the documentation of the shuffle service vendor).  The user will specify it in mapred-site.xml, than both the provider and the consumer will read it explicitly and use it.  This prevents the use of port=0, but other than that, I expect it to work.  In my case my provider uses an RDMA port (via JNI and C++) and I don't have any problem at all.  The consumer only takes the host machine from the URL in the MapDone event, but connects to the agreed RDMA port on that machine and ignores the builtin ShuffleHandler's port part in the URL.  I believe that the same can work for 3rd party provider that works over TCP.

{quote}
ContainerLauncherImpl likely needs some change as well - since the startContainer response contains service data set by the specific provider, and is deserialized in the AM to figure out the shuffle port. If you use a provider other than the default ShuffleHandler - the port should be read based on that providers service id.
{quote}
Please let me know if this is needed as part of this issue, or that we can create distinct issue for it, because as I told you, my provider already works with above patch including the fallback feature.

Thanks for all your comments and help.
, Hi Siddharth,
 
I read some documentation about Yarn architecture and I got a better understanding of your points.  I am trying to suggest a new solution:
 
I see 4 issues in the current implementation of AuxiliaryServices / NodeManager in Yarn:
# MAPREDUCE-5329: APPLICATION_INIT is never sent to AuxiliaryServices other than the built in ShuffleHandler.  This is in contrast to [the following Yarn/NodeManager documentation|http://hortonworks.com/blog/apache-hadoop-yarn-nodemanager/], which says: _"Auxiliary services are notified when an application’s first container starts on the node"_
# YARN-886: APPLICATION_STOP is inconsistent with APPLICATION_INIT
# New issue: We should consider shuffleToken to be specific to the shuffle provider
# New issue: AM should support multiple AuxiliaryServices, each with a distinct service port
 

for #1 & #2 we have already created JIRA issues.  *I strongly suggest creating distinct JIRA issues for #3 & #4 as well*.  This will allow progressing in parallel and for the users to benefit from the fixes independently (without binding one fix to the other).
  
Last comment, regarding #3, I think that perhaps we should leave shuffleToken to be general to all shuffle providers.  This is for 2 reasons:
* AFAICS, shuffleToken is based on jobToken and user credentials; hence, it is not specific to the provider but it is to the job&user.
* In the shuffle-consumer side, the token is not specific to the shuffle-consumer, but it is part of the reduceTask; hence, it is general for all shuffle-consumers.
Hence all shuffle services can use the same ShuffleToken without any problem.

Please let me know what do you think.

Thanks for your help,
Avner
 , bq. "Auxiliary services are notified when an application’s first container starts on the node"
The documentation likely needs an update for this.

bq. New issue: We should consider shuffleToken to be specific to the shuffle provider
Isn't the ShuffleToken already specific to a shuffle provider (specifically an Aux service) - in terms of YARN. Regarding your follow up, an AM (MapReduce) in this case can choose to use the same ShuffleToken for multiple Aux services.

bq. AM should support multiple AuxiliaryServices, each with a distinct service port
That would be a MapReduce specific jira. YARN-1065 is likely to be helpful towards supporting this., Hi Siddharth,
Thanks for your prompt answer.

{quote}
  --- AM should support multiple AuxiliaryServices, each with a distinct service port
That would be a MapReduce specific jira. YARN-1065 is likely to be helpful towards supporting this.
{quote}
I agree with you.  I think that for this we'll need to clarify which aux-services belong to the MapReduce AM.  Probably a new conf will be needed.  *Do you want me to open a ditinct MapReduce JIRA for that?*  I want to keep this one focused on APPLICATION_INIT.

Thanks,
  Avner , bq. I agree with you. I think that for this we'll need to clarify which aux-services belong to the MapReduce AM. Probably a new conf will be needed. Do you want me to open a ditinct MapReduce JIRA for that? I want to keep this one focused on APPLICATION_INIT.
If the MR AM knows how to handle multiple services, and informs the NM about all of these, APPLICATION_INIT should just go out to all of them. Sounds like this jira can be used to fix this ?, Hi Siddharth,

*Regarding your previous comment:*
{quote}
Isn't the ShuffleToken already specific to a shuffle provider (specifically an Aux service) - in terms of YARN
{quote}

I don’t think there is an architectural reason for having _shuffleToken_ specific per shuffle provider.  *It is safe and reasonable to have one _shuffleToken_ for all shuffle-providers and for all shuffle-consumers of a job.*
Looking in the current code, _TaskAttemptImpl_ creates _shuffleToken_ on the fly for shuffle needs based on the job token and on user credentials.  The _shuffleToken_ is stored in _TokenCache/Credentials map_ under the general shuffle label _"MapReduceShuffleToken"_.  
Also, in the shuffle-consumer side, _shuffleToken_ is part of the ReduceTask and it is not specific to a shuffle-consumer in any way.

The only thing that may relate _shuffleToken_ to a specific aux-service is an existing biased in the current code. The code for serializing/deserializing _shuffleToken_ is located in 2 static methods in the _AuxiliaryService_ class _ShuffleHandler_.  However, I think there is no real justification for that and it is very easy to move these 2 simple methods to a more appropriate place like the _Token_ class itself.



*Regarding your current comment:*
{quote}
If the MR AM knows how to handle multiple services, and informs the NM about all of these, APPLICATION_INIT should just go out to all of them. Sounds like this jira can be used to fix this?
{quote}

I think that sending _APPLICATION_INIT_ message worth an issue for itself and fixing it can help a lot several aux-services regardless of any additional fix for service port (for example aux-services that rely on RDMA and do not use TCP at all, or aux-services that can read port from conf).

The purpose of the suggested new MAPREDUCE issue is one step further - for *configuring multiple aux-services* with service-port, regardless of shuffle-providers and regardless of _APPLICATION_INIT_.  Beside, the new issue is blocked on YARN-1065.  Hence, I prefer to fix this little issue without waiting for a comprehensive fix for all the “neighbor” issues.

Thanks for your help,
Avner
, bq. The only thing that may relate shuffleToken to a specific aux-service is an existing biased in the current code. The code for serializing/deserializing shuffleToken is located in 2 static methods in the AuxiliaryService class ShuffleHandler. However, I think there is no real justification for that and it is very easy to move these 2 simple methods to a more appropriate place like the Token class itself.
In terms of the application - MR AM, ReduceTask etc - the shuffle token can be shared. In terms of YARN - each auxiliary servive that an app needs to know will only receive this bit of information if it is specified for that Aux service.

The MR AM is pretty tightly tied to it's current shuffle service. The AM itself is aware of the existing shuffle service, the fact that it uses ports, and how to construct URLs for the existing Shuffle consumer to use.

I'm assuming you're planning to write a different auxiliary service running in the NodeManager as your alternate shuffle provider ? Does this need any node specific configuration. How will the consumers find out when and where to fetch data from ? The new ShuffleConsumer can fetch completion events from the AM - which will have a URL constructed based on the existing ShuffleProvider. Is this information sufficient for your consumer to fetch the data ?

If it is, to get your provider initialized by the NM (i.e. the APPLICATION_INIT event), you'll need to modify the {serviceData} in the startContainer call. That is a map containing the serviceId for the auxiliary service and data that it needs for initialization. In case of the current ShuffleProvider - this is ShuffleHandler.MAPREDUCE_SHUFFLE_SERVICEID and the token. You just need to add another entry to this map for your own Provider. If it's using the same token, send that as the payload.
If not, the changes are likely to be more extensive.

bq. The purpose of the suggested new MAPREDUCE issue is one step further - for configuring multiple aux-services with service-port, regardless of shuffle-providers and regardless of APPLICATION_INIT. Beside, the new issue is blocked on YARN-1065.
I'm not sure I understand your use case - and how this is separate, but if you think it's independent you should just create a jira with details., Hi Siddharth,

{quote}
I'm assuming you're planning to write a different auxiliary service running in the NodeManager as your alternate shuffle provider ? 
{quote}
Right

{quote}
Does this need any node specific configuration? 
{quote}
No. The Configuration object that any AbstractService gets in its init() method is enough.

{quote}
How will the consumers find out when and where to fetch data from? 
{quote}
The consumers will fetch completion events from the AM same as the vanilla ShuffleConsumer does

{quote}
The new ShuffleConsumer can fetch completion events from the AM - which will have a URL constructed based on the existing ShuffleProvider. Is this information sufficient for your consumer to fetch the data?
{quote}
Yes. The URL doesn't contain path to the MOF, but it contains the values of <jobid, mapid>. The consumer will extract <hostname, jobid, mapid> from the url.  It will contact the hostname over RDMA and ask its segment for <jobid, mapid>. This is all a provider need for finding the MOF on one of its local disks (in addition to the mapping jobid->userid that comes from APPLICATION_INIT messages) *and this is exactly what the vanilla provider does*.

{quote}
If it is, to get your provider initialized by the NM (i.e. the APPLICATION_INIT event), you'll need to modify the _serviceData_ in the startContainer call. That is a map containing the serviceId for the auxiliary service and data that it needs for initialization. In case of the current ShuffleProvider - this is ShuffleHandler.MAPREDUCE_SHUFFLE_SERVICEID and the token. You just need to add another entry to this map for your own Provider. If it's using the same token, send that as the payload.
{quote}
Great! I would like to do that! 
If I understand correctly, startContainer gets ContainerLaunchContext that is created in createCommonContainerLaunchContext and this is the right place for adding entries to the serviceData map.
I think the code for that should be similar to what I wrote above in my 24/Jun/13 comment.
*Please let me know if I can continue based on this code.*

{quote}
If not, the changes are likely to be more extensive.
{quote}
I prefer to go for the simple case :-)

…

{quote}
but if you think it's independent you should just create a jira with details
{quote}
Thanks.  I’ll create another JIRA with details for supporting multiple aux-services with different ports and link it to this issue.


I want to add I really appreciate all your efforts on this matter,
 Avner
, bq. I think the code for that should be similar to what I wrote above in my 24/Jun/13 comment.
This JIRA has been open a long time!
Yep, it does look like the change will be something along those lines. I don't particularly like the fact that the ShuffleHandler is being used to serialize data for additional Aux services. Unless the jobToken is required, how about sending an empty byte buffer to ensure the additional service is initialized.
Considering how the ShuffleHandler is tied into the TaskAttemptImpl as well as ContainerLauncher for the port information - I think this should just be left as it is - i.e. ShuffleHandler will always be used. To configure an additional ShuffleProvider - add a separate config like your previous patch. That's really an 'advanced' config - with restrictions on how it can be used in the MR case - i.e. any service data returned by the plugin is not used, service data sent to the plugin is either the jobToken or an empty ByteBuffer., fine.  I'll go for it :)

I understand that in my code I'll need to add 'if' for filtering out the builtin ShuffleHandler in case the user will mistakenly specify ShuffleHandler among the providers in the "advanced" config. Right?
, {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12602814/MAPREDUCE-5329.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/3996//testReport/
Console output: https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/3996//console

This message is automatically generated., Hi Siddharth,

My patch is ready for your review.  Its core part is ~25 lines.  The rest is mainly tests.

Thanks,
  Avner
, Comments on the patch.
- Rename "mapreduce.shuffle.provider.plugin.classes" - this is a job specific configuration. mapreduce.job.shuffle.provider.plugin.classes. Also, this should be in MRJobConfig and not MRConfig
- Given that this is not going to be used very often, I think it can be left out of mapred-default.xml - and instead documented in MRJobConfig itself.
- Would prefer avoiding the fully qualified name (java.util.Collection)
- Should the loading walk over the specified ShuffleProvider list, rather than the ones available on the NodeManager - and log providers which are not available.
- For the unit test, is the security setup really required - kerberos, acl setup etc.
Also, you may want to change the service name to not have a "." in it. YARN-1229

Will get to the next patch quicker. Thanks for the patience., Hi Siddharth,
I want to thank you for all your comments and advices.

I have one comment back: 
{quote}
Rename "mapreduce.shuffle.provider.plugin.classes" - this is a job specific configuration. mapreduce.job.shuffle.provider.plugin.classes. Also, this should be in MRJobConfig and not MRConfig
{quote}

It is true that *shuffle-consumer* is at job level.  However, here we are dealing with *shuffle-provider* which is an aux-service that serves multiple jobs.  Hence, it is not at job level.
Also, if possible, I prefer that we'll stay aligned with the names that were chosen in MAPREDUCE-4049 (for hadoop-1), there I was requested to fulfil an opposite comment: ??the value of the constant TT_SHUFFLE_PROVIDER_PLUGIN should not have 'job' as this plugin is not per job but per TT??


Please let me know if I can ignore this particular comment?

, last comment, we already have shuffle.consumer.plugin in mapred-site.xml, wouldn't it will be appropriate to have the shuffle.provider.plugin next to it.  This is not critical for me, just let me know what you prefer.

, very last comment, 
{quote}
Should the loading walk over the specified ShuffleProvider list, rather than the ones available on the NodeManager
{quote}

I found it difficult to do it, because it is easy to get service-class-name from service-name, but the opposite direction is harder.  Do you mind if I'll leave the loading as is, BUT I'll surround it with 
{code}
if (! shuffleProviders.isEmpty())
{code}
, bq. It is true that shuffle-consumer is at job level. However, here we are dealing with shuffle-provider which is an aux-service that serves multiple jobs. Hence, it is not at job level.
An AM is per job - and the config being used is really a per AM/job configuration. The config is just saying that this particular job may use an alternate shuffle mechanism - but isn't related to what services will be run on the cluster. The NM would have this configured at a cluster level (equivalent to the TT config).

bq. last comment, we already have shuffle.consumer.plugin in mapred-site.xml, wouldn't it will be appropriate to have the shuffle.provider.plugin next to it. This is not critical for me, just let me know what you prefer.
I prefer leaving it out. Also it'd be good to have a comment which says that this needs to be able to work with the host:port information provided by the AM (i.e. plugins which require custom location / other configuration are not supported)

bq. I'll surround it with ...
Shouldn't an attempt be made to initialize plugins which are specified by the job ? Walking over configured NM plugins ends up potentially skipping plugins which the job may have configured, but are not running in the NodeManager., let me summarize what I understand for making sure we are on the same page:
1. you still want "mapreduce.job.shuffle.provider.plugin.classes" (that I don't like)
2. I'll remove this propery from mapred-default.xml
3. I'll add a comment next to serviceData.put saying that this needs to be able to work with the host:port ...

now, for the rest:
{quote}
Shouldn't an attempt be made to initialize plugins which are specified by the job ? Walking over configured NM plugins ends up potentially skipping plugins which the job may have configured, but are not running in the NodeManager.
{quote}
In this case, I don't know how to calculate serviceName from serviceClass.  I think we'll need to change the config to contain serviceNames instead of serviceClasses.  Is this what you mean?, bq.  1. you still want "mapreduce.job.shuffle.provider.plugin.classes" (that I don't like)
Not sure why you don't like that. This config is being used by the AM, on a per job-basis to configure ShuffleProviders that the job will use.

bq. In this case, I don't know how to calculate serviceName from serviceClass. I think we'll need to change the config to contain serviceNames instead of serviceClasses. Is this what you mean?
Is it possible to at least track which of the configured services have been found - i.e. the job wants X & Y, but the NM is only running X. The tracking can be independent of how you loop over the services., {quote}
Not sure why you don't like that.
{quote}
This is only because I prefer to have same config name in hadoop-1 & hadoop-2, as I wrote in aprevious comment.

{quote}
Is it possible to at least track which of the configured services have been found
{quote}
sure.  I understand you want log. right?
In this case I will add tracking log, and I will stay with the current loading and I will surround all with _"if (! shuffleProviders.isEmpty())"_

Is this okay to go?, bq. In this case I will add tracking log, and I will stay with the current loading and I will surround all with "if (! shuffleProviders.isEmpty())"
Sounds good. The other question is, should this be a log of all missing services, or should the AM just die - saying the required services are not running., bq. In this case I will add tracking log, and I will stay with the current loading and I will surround all with "if (! shuffleProviders.isEmpty())"
Sounds good. The other question is, should this be a log of all missing services, or should the AM just die - saying the required services are not running., Hi Siddharth,

All sounds great!  Thank you.

One very last comment, regarding *mapreduce.job.shuffle.provider.plugin.classes*, can we change it to be *mapreduce.job.shuffle.provider.services* and list the *service names* instead of the *service classes*.  This will prevent confusion in the config name of hadoop-1 vs. hadoop-2 which is good for me.  Also, this will be good for your concern about services that are not running on the specific NM.

In this case the code will simply be something like this:
{code}
// add external shuffle-providers - if any
Collection<String> shuffleProviders = conf.getStringCollection(
    MRJobConfig.SHUFFLE_PROVIDER_SERVICES);

for (final String provider : shuffleProviders) {
  if (provider.equals(ShuffleHandler.MAPREDUCE_SHUFFLE_SERVICEID)) {
    continue; // skip built-in shuffle-provider that was already inserted with shuffle secret key
  }
  LOG.info("Adding " + provider + " to serviceData");
  // Please note, the shuffleProvider needs to be able to work with the host:port information provided
  // by the AM (i.e. plugins which require custom location / other configuration are not supported)
  serviceData.put(provider, ByteBuffer.allocate(0)); // This only serves for INIT_APP notifications
}
{code}
, PS, also, as you asked, I will add tracking of the configured services that have not been found - i.e. the job wants X & Y, but the NM is only running X.
In this case, I can die the AM (saying the required services are not running).  Unless, you think that a log of all missing services is better.

, I would just like to make sure that you know that I am waiting for your approval for changing *mapreduce.job.shuffle.provider.plugin.classes* to *mapreduce.job.shuffle.provider.services* and for listing the *service names* instead of *service classes*.
I appreciate your help., Using service names sounds good to me. I'm in favour of killing the AM if there's missing services as well., {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12607543/MAPREDUCE-5329.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/4106//testReport/
Console output: https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/4106//console

This message is automatically generated., {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12607556/MAPREDUCE-5329.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/4107//testReport/
Console output: https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/4107//console

This message is automatically generated., Hi Siddharth

 * The last patch that I just submitted closes all the points that we discussed.
 * Please note, In addition to the trunk, this patch itself should smoothly be applied to all the live svn 2.x branches: branch-2.1-beta, branch-2.2, branch-2

Thank you very much for your help,
  Avner
, +1. Thanks Avner!, Committed to trunk, branch-2 and branch-2.2., SUCCESS: Integrated in Hadoop-trunk-Commit #4593 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/4593/])
MAPREDUCE-5329. Allow MR applications to use additional AuxServices, which are compatible with the default MapReduce shuffle. Contributed by Avner BenHanoch. (sseth: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1531741)
* /hadoop/common/trunk/hadoop-mapreduce-project/CHANGES.txt
* /hadoop/common/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TaskAttemptImpl.java
* /hadoop/common/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/test/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TestShuffleProvider.java
* /hadoop/common/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/MRJobConfig.java
, FAILURE: Integrated in Hadoop-Yarn-trunk #362 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/362/])
MAPREDUCE-5329. Allow MR applications to use additional AuxServices, which are compatible with the default MapReduce shuffle. Contributed by Avner BenHanoch. (sseth: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1531741)
* /hadoop/common/trunk/hadoop-mapreduce-project/CHANGES.txt
* /hadoop/common/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TaskAttemptImpl.java
* /hadoop/common/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/test/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TestShuffleProvider.java
* /hadoop/common/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/MRJobConfig.java
, FAILURE: Integrated in Hadoop-Hdfs-trunk #1552 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1552/])
MAPREDUCE-5329. Allow MR applications to use additional AuxServices, which are compatible with the default MapReduce shuffle. Contributed by Avner BenHanoch. (sseth: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1531741)
* /hadoop/common/trunk/hadoop-mapreduce-project/CHANGES.txt
* /hadoop/common/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TaskAttemptImpl.java
* /hadoop/common/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/test/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TestShuffleProvider.java
* /hadoop/common/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/MRJobConfig.java
, FAILURE: Integrated in Hadoop-Mapreduce-trunk #1578 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1578/])
MAPREDUCE-5329. Allow MR applications to use additional AuxServices, which are compatible with the default MapReduce shuffle. Contributed by Avner BenHanoch. (sseth: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1531741)
* /hadoop/common/trunk/hadoop-mapreduce-project/CHANGES.txt
* /hadoop/common/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TaskAttemptImpl.java
* /hadoop/common/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/test/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TestShuffleProvider.java
* /hadoop/common/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/MRJobConfig.java
, Thanks for all Siddharth,
It was a pleasure working with you.  I appreciate all your help and the prompt commits to branch-2 and branch-2.2.
, Please let me know if you want me to open an issue for updating the [Pluggable Shuffle and Pluggable Sort documentation|http://hadoop.apache.org/docs/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core/PluggableShuffleAndPluggableSort.html] with the new config - *mapreduce.job.shuffle.provider.services*, and if you want me to handle that task (I may need some explanation on the documentation creation).]