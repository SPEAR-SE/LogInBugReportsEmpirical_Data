[bq. This could be avoided by either improving the estimation of the size of the spill (increasing it by a constant amount or by constant percentage), or LocalDirAllocator could take into consideration a configuration parameter specifying how much extra unused space should be on the path returned by getLocalPathForWrite

Yet another esoteric, static configuration parameter would be an unfortunate approach and a fixed percentage is patently wrong (wordcount-like applications will overestimate, not underestimate space requirements). A decent fix could estimate and adapt requests for space based on the expansion/contraction observed in prior spills. Most combiners' ratio won't be a simple scalar, but a function of key distribution during both the collection and merge phases; this ratio may not be stable between those phases, either. That said, it's not a bad place to start.

One approach could initialize a float using a configurable ratio (defaulting to 1.0) adjusted at each spill. This could naively update a global average for each spill, use an exponential moving average to avoid radical shifts due to abnormally large records, odd skews, etc. Whether the ratio is tracked for each invocation of the combiner and not over the entire spill doesn't seem too important if the ratio is stable, which this implicitly assumes. Tracking per-partition expansion/contraction is probably more correct for some applications, but of dubious value generally.

bq. In case there is no space left on a device designated for writing intermediate data on, the spill could be retried on a different device (without the failure of the map task).

This is slightly tricky, as one would want to copy the data already spilled to the end of the prior partition and re-run the combiner on the partition that caused the error (since partially serialized data causes all sorts of problems) before continuing the spill.]