[stack traces of tests that fail once the JobTracker closes its filesystem when terminated

TestMultipleLevelCaching	testMultiLevelCaching	Error	Filesystem closed

java.io.IOException: Filesystem closed
at org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:197)
at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:537)
at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:201)
at org.apache.hadoop.mapred.TestMultipleLevelCaching.testCachingAtLevel(TestMultipleLevelCaching.java:116)
at org.apache.hadoop.mapred.TestMultipleLevelCaching.testMultiLevelCaching(TestMultipleLevelCaching.java:69)

TestRackAwareTaskPlacement	testTaskPlacement	Error	Filesystem closed

java.io.IOException: Filesystem closed
at org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:197)
at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:574)
at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:400)
at org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:651)
at org.apache.hadoop.mapred.TestRackAwareTaskPlacement.launchJobAndTestCounters(TestRackAwareTaskPlacement.java:78)
at org.apache.hadoop.mapred.TestRackAwareTaskPlacement.testTaskPlacement(TestRackAwareTaskPlacement.java:156)

, both these failures are triggered by the same event; inside launchJobAndTestCounters the jobtracker gets terminated; if this is set to shut down the filesystem client then the RPC proxy gets closed,

  public synchronized void close() throws IOException {
    checkOpen();
    clientRunning = false;
    leasechecker.close();

    // close connections to the namenode
    RPC.stopProxy(rpcNamenode);
  }
 and there, apparently goes filesystem access to that namenode, across the entire JVM. Which seems a bit of overkill. , the problem with the tests failing if the JT is set to close its filesystem when shut down is triggered by the FS caching

Two solutions
# loading these tests using the HADOOP-6231 trick with a config with {{fs.hdfs.impl.disable.cache=true}}. Fixes the tests, leaves the problem lurking around
# have the JT connect to the filesystem using {{FileSystem.newInstance()}} instead of {{FileSystem.get()}}

I would favour #2 as I can't see any reason why you'd want to share the filesystem reference for the JT with anything else running in the same VM, including JUnit tests, as it only changes system behavior.  With a move over to {{newInstance()}} the JT can close the filesystem on termination without any concerns about adverse consequences., +1 for the solution #2. I think this should be THE general pattern in all the services, but guess fixing that's a superset of this issue..., The HDFS-925 patch is what I used to see who else was closing the shared instance, Reviewing the code in trunk, the problem is a bit more serious and relates to what happens when a cached FS instance is closed: everyone who has a reference to that instance cannot use the filesystem. 

this does not normally surface in production as the JT runs in its own VM. It does exist in MiniMR clusters, in testing, but hasn't shown up because nobody other than me has tried to shut down an FS instance while the JT is still live.

Proposed actions
 1-rename this issue to be more explicit: JT must ask for a new FS instance and close it when terminated.
 2-add a test to verify that a miniMR cluster will fail if you get the same instance and close it
 3-have the JT get a new instance on startup/going live and verify that test 2 now passes
 4-have the JT close its filesystem on shutdown, set its local reference to null
I can't think of an easy way to test #4 unless there is a method to get the JT filesystem reference, changing title, marking versions it affects. Leaving as minor as this will not show up in production if you start the JT in its own VM, Patch including tests that
 -check the FS instance not shared
 -check the FS is closed and set to null on shutdown.
, This patch
1. creates a new private FS instance in the job tracker when needed.
2. closes and sets this instance to null when the JT is shutdown.
3. tests both operations.
, This looks good, except the patch seems to be reversed. Also, there's a comment in the test saying "repeat the call", which looks incomplete or redundant. , -1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12470964/MAPREDUCE-437.patch
  against trunk revision 1075422.

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 2 new or modified tests.

    -1 patch.  The patch command could not apply the patch.

Console output: https://hudson.apache.org/hudson/job/PreCommit-MAPREDUCE-Build/99//console

This message is automatically generated., implicitly fixed post YARN as the JT is dynamically created in its own process]