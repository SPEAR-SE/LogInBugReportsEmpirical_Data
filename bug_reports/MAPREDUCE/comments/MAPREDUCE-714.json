[I just confirmed this on Windows vs Linux. On Windows, the URL that you get back from ClassLoader.getResource has spaces encoded as "%20". On Linux it doesn't.

Anyone have a creative solution to deal with this? We'd like to have +s in our version numbers due to standards in RPM and Debian land, but this is blocking that., Here's a potential fix, which is really klugey. If no one objects to this I'll upload it as a real patch in the next couple of days:

{code}
diff --git a/src/mapred/org/apache/hadoop/mapred/JobConf.java b/src/mapred/org/apache/hadoop/mapred/JobConf.java
index 11be95a..4794eab 100644
--- a/src/mapred/org/apache/hadoop/mapred/JobConf.java
+++ b/src/mapred/org/apache/hadoop/mapred/JobConf.java
@@ -1452,6 +1452,13 @@ public class JobConf extends Configuration {
           if (toReturn.startsWith("file:")) {
             toReturn = toReturn.substring("file:".length());
           }
+          // URLDecoder is a misnamed class, since it actually decodes
+          // x-www-form-urlencoded MIME type rather than actual
+          // URL encoding (which the file path has). Therefore it would
+          // decode +s to ' 's which is incorrect (spaces are actually
+          // either unencoded or encoded as "%20"). Replace +s first, so
+          // that they are kept sacred during the decoding process.
+          toReturn = toReturn.replaceAll("\\+", "%2B");
           toReturn = URLDecoder.decode(toReturn, "UTF-8");
           return toReturn.replaceAll("!.*$", "");
         }
{code}, Are there any other characters that need to be fixed? I'm worried that this is a point solution for one character rather than the right solution., Owen: that's the only difference I know of that's mentioned in the spec: http://www.w3.org/MarkUp/html-spec/html-spec_8.html#SEC8.2.1

I spent about 4 hours trying to find a portable non-klugey fix. The trouble is that the behavior is different on Windows compared to Linux. On a Windows JVM, it encodes spaces as "%20" and +s as "%2B" and on Linux it does neither, best I can tell.

I definitely agree that this fix is not optimal, but I think '+' is the most common case for a "weird" character in a JAR name. In Debian and RPM packages, the non-alphanumeric characters allowed in version numbers are [+-~.:] and I think all of those should be fine after this patch., Of course, you could detect the operating system like Path does.

Look at the definition of Path.WINDOWS. Of course, we probably should make a method that checks that boolean...

That said, I'm ok with the quoting as long as it works on both operating systems. (I agree, it is kludgy, but...), Here's a patch including proper unit test.,      [exec] -1 overall.  
     [exec] 
     [exec]     +1 @author.  The patch does not contain any @author tags.
     [exec] 
     [exec]     +1 tests included.  The patch appears to include 3 new or modified tests.
     [exec] 
     [exec]     +1 javadoc.  The javadoc tool did not generate any warning messages.
     [exec] 
     [exec]     +1 javac.  The applied patch does not increase the total number of javac compiler warnings.
     [exec] 
     [exec]     -1 findbugs.  The patch appears to introduce 13 new Findbugs warnings.
     [exec] 
     [exec]     -1 release audit.  The applied patch generated 2 release audit warnings (more than the trunk's current 1 warnings).
     [exec] 
     [exec]     +1 system test framework.  The patch passed system test framework compile.

The findbugs warnings are bogus (none related to this patch). The release audit warnings are also unrelated ("smoke-tests" file and "robots.txt" file). See MAPREDUCE-2172.
, +1

This patch looks good to me. Looks like there may be other potential incorrect uses of URLDecode in the HarFileSystem, minding filling a jira to fix those?, bq. Looks like there may be other potential incorrect uses of URLDecode in the HarFileSystem, minding filling a jira to fix those?

Looking at HarFileSystem, it seems like it's actually safe - it's using URLDecoder to decode something that was encoded using URLEncoder in HadoopArchives.java. Using these as a pair is OK:
{code}
groovy:000> URLDecoder.decode(URLEncoder.encode("foo+bar baz 100%"))
===> foo+bar baz 100%
{code}, Committed to branch and trunk, thanks Eli., Integrated in Hadoop-Mapreduce-trunk-Commit #565 (See [https://hudson.apache.org/hudson/job/Hadoop-Mapreduce-trunk-Commit/565/])
    MAPREDUCE-714. JobConf.findContainingJar unescapes unnecessarily on linux. Contributed by Todd Lipcon
, Integrated in Hadoop-Mapreduce-22-branch #33 (See [https://hudson.apache.org/hudson/job/Hadoop-Mapreduce-22-branch/33/])
    , Integrated in Hadoop-Mapreduce-trunk #643 (See [https://hudson.apache.org/hudson/job/Hadoop-Mapreduce-trunk/643/])
    ]