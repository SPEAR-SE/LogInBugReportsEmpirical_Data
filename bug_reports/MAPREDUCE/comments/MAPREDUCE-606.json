[I don't see the problem with using TextInputFormat. After HADOOP-2285, the TextInputFormat will move binary data straight from the file into the Text object. Streaming needs to be changed to get the bytes from the Text and move them straight to the application without converting to a string. That would also speed up streaming..., +1
This something that has been waited for for years!
The same thing (no extra processing) may be done on the output side, too (final output), 
+1 overall.

Some details have to be considered.

How does the input format define split boundary?
You may still use "\n" as the separator. But that is  not a true binary input format.

What does the binary output format do?
a pure bytewritable record writer?
I think the streaming framework needs to make some changes 
so that it does not do any parsing on the streaming output data.
Rather, it passes the output data to the byte writable output record writer directly.
, I agree with Runping. For input, you *need* to know the record breaks, or you can't split file between maps. This requires that \n be special and therefore quoted when in the non-record boundary case. I think we should just do that quoting so that the streaming apps can just echo their input to output and get an Identity map/reduce. Of course this all got a little trickier now that you can change the delimiter from tab to an arbitrary string..., we created two classes that process the standard binary file for hadoop0.19.1.
it's BinaryInputFormat and BinaryOutputFormat
It is necessary to modify the PipeMapper,PipeMapRed,PipeReducer class for that.

The attached file(hadoop-3227.patch) is patch.
The attached file(hadoop-0.19.1-streaming.jar) is jar file.

Usage is:
$HADOOP_HOME/bin/hadoop jar contrib/streaming/hadoop-0.19.1-streaming.jar
-input myInputDirs
-output myOutputDir
-mapper "command1"
-reducer "command2"
-inputformat org.apache.hadoop.streaming.BinaryInputFormat
-outputformat org.apache.hadoop.streaming.BinaryOutputFormat

for example:
1.the input is binary of map task,the output is text,and no reducer
$bin/hadoop jar contrib/streaming/hadoop-0.19.1-streaming.jar
-input myInputDirs
-output myOutputDir
-mapper "wc -c"
-numReduceTasks 0
-inputformat org.apache.hadoop.streaming.BinaryInputFormat

2.the map's input is binary file,the output is binary file too,and no reducer
$bin/hadoop jar contrib/streaming/hadoop-0.19.1-streaming.jar
-input myInputDirs
-output myOutputDir
-mapper "convert -resize 200% - -"
-numReduceTasks 0
-inputformat org.apache.hadoop.streaming.BinaryInputFormat
-outputformat org.apache.hadoop.streaming.BinaryOutputFormat

notes:the convert is from ImageMagick

3.the map's input is binary file,the output is binary file too,and the reducer's input is binary file,but the output is text
$bin/hadoop jar contrib/streaming/hadoop-0.19.1-streaming.jar
-input myInputDirs
-output myOutputDir
-mapper "convert -resize 200% - -"
-reducer "wc -c"
ã€€ -numReduceTasks 1
-inputformat org.apache.hadoop.streaming.BinaryInputFormat
-outputformat org.apache.hadoop.streaming.BinaryOutputFormat

4.the map's input is binary file,the output is binary file too,and the reducer's input is binary file,but the output is 

binary file too

It doesn't support it., -1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12401366/hadoop-0.19.1-streaming.jar
  against trunk revision 749919.

    +1 @author.  The patch does not contain any @author tags.

    -1 tests included.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no tests are needed for this patch.

    -1 patch.  The patch command could not apply the patch.

Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-minerva.apache.org/4/console

This message is automatically generated., So Hudson can apply the patch, would you mind generating it so that it can be applied using {{patch -p0 -E < _patchfile_}}? Thanks, I'd propose that we implement this in terms of the org.apache.hadoop.streaming.io.InputWriter and OutputReader. A reader/writer that left the bytes alone, but that quoted the other characters would be great:

{noformat}
newline -> \n
return -> \r
backslash -> \\
tab -> \t
{noformat}

Then it would be easy to get quoted binary into streaming applications., This seems equivalent to HADOOP-1722, raw format. Eric opposed quoting back then for reasons unclear to me, but eventually the choice was <rec length><raw bytes>. I may be be missing the fine points here, but this seem to me a revival of the quoting idea rejected back then., I'm closing this as fixed.  The streaming input/output system has been enhanced since this jira was filed.]