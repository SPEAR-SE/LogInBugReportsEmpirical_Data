[Here's the first attempt at this to get it rolling (smells like a regression!).

Will add a test case for this soon and up a fresh patch post-verification., I wonder whether we want to add this to the new API, when we could instead suggest that people launch their own subprocess (as Owen suggests here: http://mail-archives.apache.org/mod_mbox/hadoop-common-user/201108.mbox/%3cCAFQoU9Ekv+SBvAv-bSF5dORJO68VSj6zTqXywWUT+qHS3V3bbA@mail.gmail.com%3e).

As I understand it, the record skipping feature finds bad records by doing a binary search on the record range covered by a given task, so it has to re-run the task many times until the size of the window is below a given threshold. Also, I'm not sure how it copes with the case of multiple corrupted records in a single split., The record skipping had a very unintuitive api and has not been well tested. 

I'd recommend having best practices to deal with it rather than a bunch of framework changes., Won't Fix, per Tom and Owen's comments above., Shouldn't MAPREDUCE-2165 be closed as Won't Fix also, as it is a dependent sub-task of this one?, Done, didn't notice that one.]