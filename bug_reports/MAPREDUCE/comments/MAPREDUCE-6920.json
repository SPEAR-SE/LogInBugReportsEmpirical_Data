[I agree that mapreduce.job.speculative.slowtaskthreshold is essentially useless.  It will have very little effect in practice unless set to a very large value and the standard deviation of completed task durations is significant.  And even then, all it would do is serve to disable speculation which is of dubious utility.

If I were to guess it looked like someone originally intended for this property to control the speculation trigger threshold via scaling the standard deviation of task completion times.  If an estimated running task duration were to be below that threshold then we would never speculate it until the estimate changed to exceed that threshold.  But that's not what it does in practice.  Essentially thresholdRuntime is returning a boolean value, via Long.MAX_VALUE or otherwise, that a task should or should not be speculated, so calculating a realistic threshold is a waste of time.

If my guess is correct, I'm not sure that check would actually matter in practice if performed.  We already do not speculate a task if we expect the existing task to complete before a newly scheduled task would complete, and usually the existing task already has a significant head start.]