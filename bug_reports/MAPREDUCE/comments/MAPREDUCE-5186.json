[I understand this check was introduced early on with MAPREDUCE-1943. However, the way CombineFileInputFormat works, the default value (10) for this just doesn't work nicely with it.

Currently we work around it by setting this value to a large value (> number of data nodes). But it would be great if we can come up with a way to reconcile these two needs., I think CombineFileInputFormat needs to consider the max split locations value to change the way how the splits are formed. Having said that, however, trying to create splits to conform to the limit of 10 locations would have a major impact on how CombineFileInputFormat works.

How critical is it to limit the split locations? Is the default value (10) reasonable?, Thoughts on this? It seems to me that CombineFileInputFormat and what prompted MAPREDUCE-1943 have some competing concerns., Any inputs on this ?, Raising the priority. The default value of mapreduce.job.max.split.locations effectively renders CombineFileInputFormat DOA on any decent sized clusters. Have others encountered this issue?, We recently ran into this as well. While the check is superficial (throws a warning) in Hadoop-1, it throws an Exception essentially failing the job submission in Hadoop-2. MAPREDUCE-4146 seems to have introduced this. 

[~tomwhite], do you remember the reason for throwing an Exception. 

If there is no particular reason, it would be nice to revert to old behavior., This patch restores the 1.0 behavior. Defines mapreduce.job.max.split.locations in the mapred-default.xml. Fixed the test that was "succeeding" on the "Max block location exceeded" IOException instead of the "Job failed!" IOException.  Pending [~tomwhite]'s input., Thanks for the patch [~robsparker]!

Quick question: I noticed there are these calls in the patch:

{code}
locations = Arrays.copyOf(locations, maxBlockLocations);
{code}

What is the reason for cutting out the original locations? Wouldn't it be limiting the number of block locations to the max block locations? Then some splits that truly need to collect blocks from more locations would not be created?, [~sjlee0] I originally tried to restore the mrv1 functionality, but it seems that max block locations is an artifact from mrv1 to protect the jobtracker and it is not clear to me what function it serves with respect to an AM.  I am modified the patch to remove m.j,max.split.locations., I understand that is the mrv1 behavior. But for CombineFileInputFormat, "global splits" are definitely possibilities, and I'm not sure whether it would result in a correct split if we simply picked the first max_block_location locations in that case...

We may need [~tomwhite]'s input for this, but I think it is acceptable to log WARNING if the block location count exceeds max block locations but let it proceed. Thoughts?, I think the first patch is closer to what we might want. Comments on that patch:
# Warning alone should be enough, can get rid of Arrays.copyOf statements.
# The test checking the exception can be dropped. Instead manually verifying the WARN message should be good enough., +1 on that suggestion., I think it's correct to restore the MR1 behaviour for this, so logging a warning is fine., Maybe I'm misreading the code, but the first patch essentially is the MR1 behavior.  It logs a message and truncates the splits to the configured maximum locations.  IMHO we either should replicate the MR1 behavior or we should just allow the splits to be what they are and not log anything.  I'm not sure there's a lot of utility to warning the user about a lot of splits if we're not going to do anything about it.  In MR1 the warning is informing the user that some of their split locations were ignored due to the truncation, but if we're not going to truncate is there a point in warning?

[~sjlee0] points out that truncating the splits could be problematic for CombineFileInputFormat, so the MR1 behavior may not be desirable.  In that case I think the second patch is more appropriate.  Thoughts?, I am also comfortable with not logging, but I wasn't sure whether the concern that led to the max split locations is no longer valid (at least in hadoop 2).

I am more concerned about truncating the split locations. I'm not 100% familiar with this part of the code, but by truncating aren't we dropping some of these locations on the floor? Then when the splits are run on the cluster, would it always lead to working splits and mappers? It wasn't clear to me whether it would always work even if we dropped these on the floor when we write the splits. I would appreciate if you could shed some insight on this... And yes, if this is a valid concern, it sounds like it would be a valid concern in MR1 too., bq. I wasn't sure whether the concern that led to the max split locations is no longer valid (at least in hadoop 2).

AFAIK the limit was primarily intended to protect the JobTracker from being excessively bogged down by jobs with huge numbers of split locations.  In Hadoop 2 the concern is lessened somewhat since part of the JT responsibilities are in the job-specific AM.  However the RM could still be impacted since it will see a large request from the AM as it tries to obtain locality for the split.

bq. I'm not 100% familiar with this part of the code, but by truncating aren't we dropping some of these locations on the floor? 

No, I don't believe so.  If you look at JobSplitWriter it is writing out the split details separately from the locations.  The locations are used solely for determining locality for map tasks.  From a map task perspective, the locations aren't very interesting since it just needs to be able to open the file(s).  It doesn't need the locations to do that, and if some split did need location details they'd be written out as part of serializing the split itself.  So bottom line for truncating the locations is that data locality might not be as ideal as it could be for the task processing the split, but the split will still be processed properly regardless.

Given that a user/admin can disable the location truncation off by setting the config to a very large value if desired, I think we should preserve the MR1 behavior to lighten the load on the AM/RM for jobs with lots of split locations.  I think the first patch is very close, although the unit test change in that patch isn't appropriate.  It should really be more of a unit test (i.e.: no minicluster) that invokes the JobSplitWriter to write out splits with more locations than the configured maximum and verify that the locations were truncated in the job split file written.  There should be unit tests for both old-style splits and new-style splits to verify the truncation is occurring in both places., Thanks for the clarification. Then I'm +1 on restoring the MR1 behavior., Updating Rob's patch with unit tests to verify truncation of locations is occurring when necessary.  Also removed the TestBlockLimits test since it was checking for an exception in this case and is no longer necessary., Looks good to me. Thanks!, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12611465/MAPREDUCE-5186v3.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:red}-1 javac{color:red}.  The patch appears to cause the build to fail.

Console output: https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/4162//console

This message is automatically generated., Apache build machine had a bunch of processes that had "escaped" and caused the Jenkins user to hit the process ulimit.  Those have been cleaned up, so resubmitting the same patch to kick Jenkins again., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12611483/MAPREDUCE-5186v3.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The following test timeouts occurred in hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient:

org.apache.hadoop.mapreduce.v2.TestUberAM

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/4163//testReport/
Console output: https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/4163//console

This message is automatically generated., TestUberAM timeout is unrelated, see MAPREDUCE-5481., +1 After a walkthrough of the code, it looks good to me, or at least on par with 1.x., Thanks Rob for the contribution, and thanks Sangjin and Daryn for reviews.  I committed this to trunk and branch-2., SUCCESS: Integrated in Hadoop-trunk-Commit #4713 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/4713/])
MAPREDUCE-5186. mapreduce.job.max.split.locations causes some splits created by CombineFileInputFormat to fail. Contributed by Robert Parker and Jason Lowe (jlowe: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1540813)
* /hadoop/common/trunk/hadoop-mapreduce-project/CHANGES.txt
* /hadoop/common/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/split/JobSplitWriter.java
* /hadoop/common/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/resources/mapred-default.xml
* /hadoop/common/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/test/java/org/apache/hadoop/mapreduce/split
* /hadoop/common/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/test/java/org/apache/hadoop/mapreduce/split/TestJobSplitWriter.java
* /hadoop/common/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestBlockLimits.java
, Thanks for patching this Jason!, SUCCESS: Integrated in Hadoop-Yarn-trunk #390 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/390/])
MAPREDUCE-5186. mapreduce.job.max.split.locations causes some splits created by CombineFileInputFormat to fail. Contributed by Robert Parker and Jason Lowe (jlowe: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1540813)
* /hadoop/common/trunk/hadoop-mapreduce-project/CHANGES.txt
* /hadoop/common/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/split/JobSplitWriter.java
* /hadoop/common/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/resources/mapred-default.xml
* /hadoop/common/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/test/java/org/apache/hadoop/mapreduce/split
* /hadoop/common/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/test/java/org/apache/hadoop/mapreduce/split/TestJobSplitWriter.java
* /hadoop/common/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestBlockLimits.java
, FAILURE: Integrated in Hadoop-Mapreduce-trunk #1607 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1607/])
MAPREDUCE-5186. mapreduce.job.max.split.locations causes some splits created by CombineFileInputFormat to fail. Contributed by Robert Parker and Jason Lowe (jlowe: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1540813)
* /hadoop/common/trunk/hadoop-mapreduce-project/CHANGES.txt
* /hadoop/common/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/split/JobSplitWriter.java
* /hadoop/common/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/resources/mapred-default.xml
* /hadoop/common/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/test/java/org/apache/hadoop/mapreduce/split
* /hadoop/common/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/test/java/org/apache/hadoop/mapreduce/split/TestJobSplitWriter.java
* /hadoop/common/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestBlockLimits.java
, SUCCESS: Integrated in Hadoop-Hdfs-trunk #1581 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1581/])
MAPREDUCE-5186. mapreduce.job.max.split.locations causes some splits created by CombineFileInputFormat to fail. Contributed by Robert Parker and Jason Lowe (jlowe: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1540813)
* /hadoop/common/trunk/hadoop-mapreduce-project/CHANGES.txt
* /hadoop/common/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/split/JobSplitWriter.java
* /hadoop/common/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/resources/mapred-default.xml
* /hadoop/common/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/test/java/org/apache/hadoop/mapreduce/split
* /hadoop/common/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/test/java/org/apache/hadoop/mapreduce/split/TestJobSplitWriter.java
* /hadoop/common/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestBlockLimits.java
]