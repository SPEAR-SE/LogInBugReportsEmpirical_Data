[Nice Catch!
As "/tmp/hadoop-yarn/staging/username/.staging" is exceeded, all JOB failed., Probably MAPREDUCE-6607 is related. As I commented [there|https://issues.apache.org/jira/browse/MAPREDUCE-6607?focusedCommentId=15140967&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-15140967], if the parameter is set, the files for failed tasks are kept. However, the files in .staging can be used for all tasks, so it's difficult to search what is the files in .staging of the failed tasks. That's why if the parameter is set, all the files in .staging are preserved for now.
Therefore you need to set the parameter to true only for the failing jobs to avoid the issue. I'm thinking this is what the document want to say., However, the document is confusing for me. I'd like to add a parameter "mapreduce.tasks.files.preserve.failedjobs" for keep the .staging dir only for the failing jobs. What do you think?, We will move the .staging dir away while Job finished or failed. As the Job is not alive, i think no need to keep the .staging dir at that time., When task failure but job is successful, that .staging dir shouldn't be keept. I think that is good idea to add a parameter "mapreduce.tasks.files.preserve.failedjobs".]