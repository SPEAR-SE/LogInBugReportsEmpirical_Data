[Doesn't seem like a problem anymore, was prolly a single node., This is occurring again.  See any of the following:

https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/2011//testReport/
https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/2002//testReport/
https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/2006//testReport/, I can take a look at it.

The failures all seem to look like

chmod: cannot access `/tmp/hadoop-jenkins/mapred/staging/jenkins1901628609/.staging/job_local_0001': No such file or directory

Almost like the files in /tmp are getting deleted out from under the process or something. , Looking at the code there appear to be a couple of things happening.  The code to create the submitJobDir calls FileSystem.mkdirs, which calls fs.mkdirs, and then tries to call fs.setPermission.  If the first mkdirs fails the result is ignored and the chmod call throws the exception that we are seeing.  There are lots of reasons why the mkdirs could fail.  My guess is that either /tmp is full or /tmp/hadoop-jenkins/mapred/staging has over 32000 entires in it, which is the limit for ext3.  Why is that my guess, well because when I looked at my directory I have close to 4000 in mine, and I have not been running nearly as long or under as much of a load as this one has.

I need to log onto the box to be sure of any of that though., I ran into this sometime back on my machine too. This happens when the tests are run by some user but the temp directories are created and some other user tries to run the tests.

I asked [~gkesavan] to cleanup the temp dirs on apache jenkins for now. We can fix our code to avoid this from happening., Oh and all of the failures appear to be on hadoop3, so my guess is that it is something with the box.  But once I know what the problem is we might need to make some changes so the box does not get into that state again., Vinod,

If this is a directory permission issue, I am not really sure what we can do in our code to fix the issue.  Can you think of something besides putting in a check in FileSystem.mkdir that blows up with a cleaner exception?, Dropping priority because Giri fixed the current test failures.  Still looking into code changes so the failures do not come back again., I have been thinking about this and how we can fix the issue in the code.  I am a bit confused about how /tmp/hadoop-jenkins is created by a user that is not jenkins? unless the other person explicitly set user.name to be jenkins, or they manually created that directory before running.  Vinod or Giri, did you look at the directories before this happened?

If I don't know what caused the bad directory t begin with I really don't have much hope of understanding how to prevent it in the future.  If the directory was manually created then there is nothing we can do.  If the user explicitly set user.name to jenkins we can detect that, and blow up.

We cannot delete the directory after a job finishes in local mode because more jobs could still be running., It looks like there is really no way to make code changes unless we can get this to happen again.  And even then it is questionable what kind of changes we could make to prevent this in the future.]