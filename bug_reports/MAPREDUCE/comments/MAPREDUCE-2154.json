[Since combiner was there in original job, the actual map output records at the end of map task is less than the value shown in the counter "Map output records". See MAPREDUCE-2135 for details of the issue.
You can check the sum of reduceInputRecords of the 3 reduces of original job(=19794) is same as the value in the simulated job and is equal to the sum of map output records of simulated job., The problem reported is not there for the attached json file.
But the problem will be there when there are multiple spills happened in map tasks.
Because the MapReduce counter "Map output bytes" is representing the bytes before combiner is applied, gridmix doesn't have a way to get the actual map-output-file-size of original job's map task. This is leading to bigger sized map-output-file in the simulated jobs. See MR-2135 for more details of the MapReduce framework issue., Instead of relying on the value of map output bytes counter(which is wrong value for gridmix mapper in case of original job having a combiner), I propose gridmix's mapper can do the following to emulate approximate disk I/O :

(1) Read mapInputBytes data first. This should mostly satisfy the HDFS_BYTES_READ counter of map task almost all the time.

(2) Create map-output-file of size obtained by the following calculation:
Create an array of reduceInputBytes[ ] of size equal to number of reduce tasks that contains the number of input bytes of all reduce tasks of original job.
{code}mapOutputSizeForReduce_n = reduceInputBytes[n] / numMaps;{code}

(3) At this point of time, if this simulated job's map task is behind the FILE_BYTES_WRITTEN counter of original job's map task, then write {code}FILE_BYTES_WRITTEN_Of_Original_Map_Task - FILE_BYTES_WRITTEN_of_current_task{code} bytes to some temporary localFileSystem file. Then delete this temporary file.

(4) At this point of time, if this simulated job's map task is behind the FILE_BYTES_READ counter of original job's map task, then read {code}FILE_BYTES_READ_Of_Original_Map_Task - FILE_BYTES_READ_of_current_task{code} bytes from map-output-file that was created in step-2.

Steps (3) and (4) could be important for the case where original map task had lot of spills.
]