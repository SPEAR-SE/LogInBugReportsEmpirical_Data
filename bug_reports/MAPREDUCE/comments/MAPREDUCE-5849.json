[I think that is not a bug, but, can be a design mistake on the signature of reduce method. Thinking about the following (simplified)  scenario:
1. The reduce fase can start reducer tasks if there is some slot available in some task tracker.
2. So, if some reducer for a specific key (in some specific partition) has started, then, the iterator within the values can only reach the end (false hasNext) after the map fase has reached the end.
3. Therefore, if you try to iterate the values again. That will only happens after all the mappers has ended up its work.

Because receiving an Iterable<VALUE> make us naturally to think that iterator() method will return an new instance of Iterator<VALUE> positioned at the beginning. I would like to propose that the reduce method receive the Iterator<VALUE> (just like reduce on MRv1), instead of an Iterable<VALUE>. It can be done by implementing a new Reducer class which extends and deprecates the existent one and overriding the run() method calling the new reduce.

@Deprecated
public class Reducer<KEYIN,VALUEIN,KEYOUT,VALUEOUT>{
...
}

public class NewReducer<KEYIN,VALUEIN,KEYOUT,VALUEOUT> extends Reducer<KEYIN,VALUEIN,KEYOUT,VALUEOUT>{

protected void reduce(KEYIN key, Iterator<VALUEIN> values, Context context
                        ) throws IOException, InterruptedException {
   
    for (;iterator.hasNext();) {
        VALUEIN value = iterator.next();
        context.write((KEYOUT) key, (VALUEOUT) value);
    }
  }

@Overrides
public void run(Context context) throws IOException, InterruptedException {
    setup(context);
    while (context.nextKey()) {
      Iterator<VALUEIN> iter = context.getValues().iterator();
      reduce(context.getCurrentKey(), iter, context);
      // If a back up store is used, reset it
      if(iter instanceof ReduceContext.ValueIterator) {
        ((ReduceContext.ValueIterator<VALUEIN>)iter).resetBackupStore();       
      }
    }
    cleanup(context);
  }
}]