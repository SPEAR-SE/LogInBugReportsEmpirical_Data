[patch removing all slot millis logic and deprecates the 2 JobCounter constants., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12586837/MAPREDUCE-5311.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 3 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient:

                  org.apache.hadoop.mapreduce.v2.TestRMNMInfo

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/3753//testReport/
Console output: https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/3753//console

This message is automatically generated., test failure is unrelated, it is failing on trunk as well. Created MAPREDUCE-5312 to track/fix those failures., The test failures have already been fixed by MAPREDUCE-5312, so we are good here., {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12586837/MAPREDUCE-5311.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 3 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/3757//testReport/
Console output: https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/3757//console

This message is automatically generated., Why remove this? We can keep the value by not normalizing, I believe JT doesn't normalize either (though I need to check)., Many of our users leverage the slot millis counter as a metric for cluster utilization for jobs.  While I agree the "slot" concept is confusing in 0.23/2.x, our users need some counter to track their utilization.  If these counters are deprecated, we need to create something more appropriate to replace them so users can still track cluster utilization.

I would like to see some sort of "resource-millis" counters so we can track the amount of time a job was consuming a particular cluster resource and how much of that resource during that time.  So memory would be tracked via MB-millis or GB-millis, CPU could be core-millis or vcore-millis, etc.  It would be great if this was tracked by YARN directly and available regardless of the app framework used, but that's a much bigger change., [~acmurthy], [~jlowe], [~sseth]. If I'm getting correct the current logic we are using the memory requested by the AM for the task, not the allocated (RM scheduler normalized) memory. 

As it seems users are relying on this we could:

* Use the memory from the container allocation for the calculation. This will give a more correct idea of the 'real' utilization without exposing the normalization logic to the MRAM. This effectively would be memory-millis.
* Do the same for vcore-millis.
* Add memory-millis and vcore-millis counters and deprecate slot-millis keeping it wired to memory-millis.

If we agree on this, I'll repurpose this JIRA to do so., I like the idea of a memory-millis counter that uses the granted container size to remove the need to know how it was rounded to that value.

However I'm not sure it's best to have slot-millis suddenly start returning something that isn't slot-millis.  That could throw off calculations from downstream tools that assume a particular slot size (e.g.: min-allocation from today's setup).  Probably better to simply not provide slot-millis when it cannot be calculated and supply memory-millis as an alternative., I'd prefer to remove it as well., do we agree on removing slot-millis then? If we do, we can commit this one and then we can take care of YARN-787 (removing min from YARN client API) before 2.1-beta., I would rather not see slot-millis disappear without memory-millis to replace it.  That would leave users without a metric to calculate resource utilization for their job., I was hoping to get rid of it so we can go ahead with YARN-787 which is a YARN proto/API change before 2.1. Would then be acceptable to do the current calculation picking up MIN from the yarn configuration of the client? If so, I can do that in YARN-787 as part of removing MIN. and we make this one to be blocked by a new JIRA that introduces MEM-millis and CPU-millis. Thoughts?, Seems reasonable if it's critical to remove MIN before 2.1, as I'm not sure how else it could be computed.  I could see yarn-site.xml for an application not being consistent with the one used by the RM, which could lead to a bad computation for the counter value.  Consumers of the counter would need to be aware that the slot was computed based on the AM's perception of a slot rather than what the RM used.

Thoughts, [~acmurthy]? I know you had reservations earlier., How about?

*for 2.1-beta:*

* we change the calculation to use the MIN value from the local config (typically people use the in the clients the same confs as in the cluster)
* we get rid of the MIN from the Yarn Client API

*for the next release:*

* introduce mem-millis and vcores-millis using allocation info
* map slot-millis to mem-millis
* deprecate slot-millis counter names

If folks agree I can put a patch changing the calculation to use the MIN value from the local config
, I'm OK with either faking the calculation with the RM config value read by the AM *iff* mem-millis shows up very soon after 2.1-beta.  A number of our users use this counter value, and if it's missing we need another counter value to point them to instead.

By "map slot-millis to mem-millis" what does that entail?  I don't think a direct mapping makes sense, as the units are totally different.  Or are you planning on doing something like dividing mem-millis by the min allocation from the config to continue faking slot-millis?
, Looks like YARN-787 and friends have already mapped the slot-millis calculation to the AM's view of the RM's config value, so all that's left is to clarify what will happen to slot-millis once mem-millis shows up., Uploading a patch that gets rid of slots-millis (but keeps the enum values in JobCounter) and adds mem-millis.  I think we should hold off on cpu-millis for now, because
* This patch is required for YARN-1004, which is marked as a blocker for the release
* We still haven't resolved how we want to do define vcores (YARN-972)., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12595627/MAPREDUCE-5311.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 3 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:red}-1 findbugs{color}.  The patch appears to introduce 3 new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient:

                  org.apache.hadoop.mapreduce.v2.TestUberAM

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/3929//testReport/
Findbugs warnings: https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/3929//artifact/trunk/patchprocess/newPatchFindbugsWarningshadoop-mapreduce-client-app.html
Console output: https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/3929//console

This message is automatically generated., New patch addresses findbugs warnings., This is an incompatible change isn't it?, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12595636/MAPREDUCE-5311-1.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 3 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient:

                  org.apache.hadoop.mapreduce.v2.TestUberAM

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/3930//testReport/
Console output: https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/3930//console

This message is automatically generated., It's not source or binary incompatible, but it will break users that rely on non-zero values of SLOTS_MILLIS_MAPS or SLOTS_MILLIS_REDUCES., Right, which is why [~jlowe] and other MR users would be really unhappy., [~acmurthy], per [~jlowe]'s comment above "so all that's left is to clarify what will happen to slot-millis once mem-millis shows up." he does not seem unhappy.

I think the problem we have at hand here is that there is a legacy metrics, slots-millis, which does not make sense in YARN regardless what it returns 0 or mem-millis. Anybody relying on this value coming from Hadoop 1 will get something completely different to what was getting when running in Hadoop 1.

This means that if we make it disappear or we leave around returning the wrong value (a funny mem-millis based on MIN config now), current users relying on it will have to adjust how they see/process this value.

Because of that, I would say, we just bite the problem, and we make the slot-millis counter to return 0 (or better -1), deprecate the constants, print a warning when somebody uses this constant indicating the user to user look for memory-millis (and eventually cpu-millis).
, SLOTS_MILLIS_MAPS is a confusing property that I think we should remove if at all possible.  Independent of YARN-1004, the current way of calculating it is a hack that neither adheres to its behavior in MR1 nor its description.

In MR1, it was calculated as the sum of all map task's running times multiplied by the number of slots each task took up.

The description, "Total time spent by all maps in occupied slots (ms)", with its unit being ms and not slots-ms, reads to me as a sum of all map task's running times, independent of the number of slots consumed by each. 

On most clusters, however, these were equivalent, because a map task would only take up more than one slot if mapred.cluster.map.memory.mb were set to something other than its default, -1.

The MR2 counter, which is calculated as the sum of all map task's running times multiplied by the memory allocated by each one, divided by the minimum allocation, adheres to neither of these.  The average MR1 user who did not set mapred.cluster.map.memory.mb will find, upon upgrading the MR2, that SLOTS_MILLIS_MAPS functions differently than it did in MR1, as well as be confused by YARN's claim that it gets rid of slots.

This is not an obscure feature.  It's one of the things that any person running a MapReduce job will see, and I think keeping it in its current form will help to confuse those who are trying to upgrade to MR2 and understand the new resource model. , [~acmurthy], unless I got things wrong, we agreed to keep slot-millis around until we have memory-millis. And the latest patch here is doing that. , We need to take care of this for 2.1.0, making it a blocker., This will break every single MR app. I'm -1 on this., To Sandy's point - several folks do use mapred.cluster.(map,reduce).memory.mb, so it will be a big BC break for them.

Also, what does this mean for BC after we spent all the time fixing MAPREDUCE-5108., I am missing how the change would break every single MR app - we would leave the API intact.  However, does this sound like a reasonable compromise:  We keep SLOTS_MILLIS_MAPS, but instead of trying to map resources to slots (which will make even less sense when we introduce other resources), we compute it as the sum of the execution times for all map tasks.  Essentially SLOTS_MILLIS_MAPS functions as CONTAINERS_MILLIS_MAPS would and is computed independently from container capabilities.  This will break semantic compatibility in some cases for people using the mapred.cluster.(map,reduce).memory.mb properties, but it will restore semantic compatibility for people not using those properties (which I believe is a much larger number). It will also make the counter function in a more understandable way that is more in line with its description.
, We seem to understand that we can't remove SLOTS_MILLIS_MAPS - that will break BC.

For now, let's punt on this for 2.1.0-beta since we can add new counters (CONTAINERS_MILLIS_MAPS) after a bit more discussion., [~acmurthy], I don't see how this will break BC, it is not being proposed removing the counter, but either making it zero or as [~sandyr] suggested introduced CONTAINER_MILLIS_MAP and map SLOT_MILLIS_MAP to it (approach that will make more sense than the current value). I don't want to punt because you are blocking YARN-1004 because of this one. YARN-1004 should go in 2.1.0-beta. Please ping me if you want to chat offline over the phone if you think will be easier to discussed it. , [~acmurthy], I guess you removing it from 2.1.0-beta and my last comment had a race condition, making it blocker for 2.1.0-beta again., I've repeatedly pointed out that SLOT_MILLIS is something which is very useful and is used by a lot of end-users. I know of a lot of users who have built rudimentary reporting/charge-back systems using SLOT_MILLIS. Breaking compatibility (semantic or api) is not an option. We've done a lot of work on MR to keep it compatible so far.

The more I think about it, the more strongly I believe YARN-787 went too far by removing 'minimum' from the API. We can/should keep RegisterApplicationMasterResponse.getMinimumResourceCapability as a LimitedPrivate api and use it only for calculation of SLOT_MILLIS. We don't have to expose it to users or other applications. Makes sense?, [~acmurthy], it seems we are talking pass each other here. 

* 1. SLOT_MILLIS does make sense in YARN. yes/no?
* 2. We need to redefine what SLOT_MILLIS means/reports in YARN. yes/no?

Are we in agreement that the answers to these questions is #1 NO and #2 YES.

If we are in agreement, then we have to see how to address this in the least disruptive way.

Sandy's latest proposal suggests we do the following:

* Introduce the concept of CONTAINER_MILLIS (regardless of the container size)
* Deprecate SLOT_MILLIS and map it to report CONTAINER_MILLIS

And we could later augment this with additional counters:

* Introduce the concept of MEMORY_MILLIS
* Introduce the concept of CPU_MILLIS

, Let's up-level.

We agree we can't break compatibility for existing applications ?

If so, we can figure ways around how to fix YARN-1004, MAPREDUCE-5310 etc. without breaking compatibility., As slots no longer exist in MR2, we cannot avoid breaking compatibility for some existing applications.

Keeping SLOTS_MILLIS as it is will break compatibility for the majority of MR1 clusters.

Defining SLOTS_MILLIS to be the same as CONTAINER_MILLIS will break compatibility for the minority of clusters that both used the mapred.cluster.map.memory.mb property in MR1 and chose to configure memory in MR2 in a way that exactly lines up with slots in MR1 (i.e. setting yarn.scheduler.minimum-allocation-mb to exactly the same as mapred.cluster.map.memory.mb, which is often not the right choice)., bq. As slots no longer exist in MR2, we cannot avoid breaking compatibility for some existing applications.

The original intention was to model the old notion of 'slots' as a minimum container.

So, we have 2 cases:
# mapred.cluster.(map,reduce).memory.mb set to -1 for the job. In this case, we just divide the 'timing' by 1.
# mapred.cluster.(map,reduce).memory.mb set to non-zero then we normalize to yarn.scheduler.minimum-allocation-mb and divide 'timing' by that number.

Makes sense?, bq. Defining SLOTS_MILLIS to be the same as CONTAINER_MILLIS will break compatibility for the minority of clusters that both used the mapred.cluster.map.memory.mb property in MR1 and chose to configure memory in MR2 in a way that exactly lines up with slots in MR1 (i.e. setting yarn.scheduler.minimum-allocation-mb to exactly the same as mapred.cluster.map.memory.mb, which is often not the right choice).

It will also break compatibility for those on 0.23 where SLOT_MILLIS is currently based on the minimum allocation.  Changing the units from slots to containers for those cases will significantly lower the reported value and could be misinterpreted as lower cluster utilization.  That's why I'm not in favor of changing the SLOT_MILLIS units but still calling it SLOT_MILLIS.  I'd rather the counter disappear than have it be a completely wrong value.  As Arun mentioned, there are in-house tools to compute cluster utilization based on these metrics.

I agree that supporting SLOT_MILLIS long-term is problematic due to the removal of the minimum or slot concept, hence my earlier suggestion for something more supportable like MEM_MILLIS or CPU_MILLIS.  For backwards compatibility, we could consider doing something along the lines of what it's already doing today, i.e.: having the AM read a config and computing the "slot" size from there.  That way admins can configure whatever is appropriate for a "slot" for their cluster to keep legacy tools reporting something appropriate when they try to look for SLOT_MILLIS.  If the property is not configured then arguably the AM should not report a SLOT_MILLIS job counter since it doesn't know how big a slot should be., [~jlowe], thanks for jumping in, I was no aware you guys have in-house tools using this stuff with the current reported SLOT_MILLIS. With that in mind, and along the lines of what Jason proposes would the following satisfy all parties?

This JIRA would then be repurposed to:

* Introduce and deprecate a {{MRConf.SLOT_MILLIS_MINIMUM_ALLOCATION_MB}} with no default
* If set, use the {{MRConf.SLOT_MILLIS_MINIMUM_ALLOCATION_MB}} value to compute, using today's logic, the SLOT_MILLIS counter values.
* If no set, SLOT_MILLIS counter should report 0.

This means than anybody relying on current SLOT_MILLIS reporting can continue getting it until we decide to trash it (a few versions down the road).

A different JIRA would introduce MEM_MILLIS and CPU_MILLIS which have an accurate meaning in Yarn's world.

YARN-1004 is then unblocked.

I believe this address the problem without breaking backwards compatibility as [~acmurthy] asked.

Arun, Jason, [~sandyr], are you OK with this approach?

, I'm glad we are coming around to understand we can break existing users of SLOT_MILLIS.

I wasn't thrilled about using configs and I'm even more leery of adding new configs to track existing configs in RM. This can lead to all sorts of configuration-error hell with mismatch in configs b/w YarnConfiguration and MRConf. I'm against getting into that sort of situations.

A much simpler approach is to re-introduce a LimitedPrivate RegisterApplicationMasterResponse.getMinimumResourceCapability as described here (http://bit.ly/18uA8zj). This would revert some part of YARN-787., [~acmurthy], I'm glad you are glad, *smile*.

Yes, we agree we need to leave SLOT_MILLIS because Hadoop 0.23 users are relying on it.

We also agreed before that we should remove 'minimum resource capability' from the protocol and the API because it is a scheduler implementation internal thing that should not be exposed to the users.

The current code relies on using 'minimum resource capability' configuration property which is internal. We've also agreed on doing that until this JIRA is fixed.

The proposed solution is a tweak to the current code just using a different configuration property, nothing else.

Adding 'minimum resource capability' back to the protocol and API to support deprecated functionality that we all agree it should go away does not seem right.

I prefer [~jlowe] suggestion to have a new  (& deprecated) configuration property that users upgrading from 0.23 and wanting to preserve the SLOT_MILLIS counter information can use (and if they don't -default setting- SLOT_MILLIS is always zero).

Also, doing the constant replacement is much simple that reintroducing the protocol and API minimum field.

Lets move forward with this.
, The uber problem seems that MR happens to be a special user that for historical reasons has its fingers poked into all kinds of YARN internals and as such is suffering when we close those gaps in YARN. Is there an issue with MR code using the existing (and possible in future deprecated) min resource YARN configuration for its internal calculations? That value was basically exposed by YARN via the min API which we removed since we believed it wasnt relevant to users. MR as a special user needs that info. How about we just get it from the config directly., [~bikassaha], you are on the spot. The only difference being proposed is that instead of using the scheduler MIN property directly, to define a new one for this particular use case in the MRAM namepsace (and deprecate it). The reason for doing this is that the exiting scheduler MIN propery would go away per YARN-1004., I'll say this again, I'm -1 on adding a new config to track another one in the scheduler. Expecting admins to remember another config for the same value (one for YARN & another for MR) is not kosher - our configuration is bad enough.

We can use the same one in the scheduler (i.e. don't fix YARN-1004) or we can add back RegisterApplicationMasterResponse.getMinimumResourceCapability as LimitedPrivate("MapReduce").

I'm ok with either of the above. , [~acmurthy], there are other 4 committers that are OK with the idea of a separate config to enable SLOT_MILLIS because it is a special usecase for 0.23 users. The changes are must less disruptive and (IMO) adequate given the usecase.

Can you please reconsider your -1?, This isn't a special case for 0.23. 

It will break tools built atop both hadoop-1.x & hadoop-0.23.*., bq. Is there an issue with MR code using the existing (and possible in future deprecated) min resource YARN configuration for its internal calculations?
Lets just do this and like I argued on YARN-1004, let's keep the min around as a RM property and use it for the SLOTS_MILLIS calculation. For Fifo and CS, things will just work. For FairScheduler, the new config hack is same as forcing operators to set the existing RM property.

BTW, please edit back the title to just indicate the problem., I'm ok with Vinod's suggestion too., [~tucu00] Can you please decide on one of the 3 options available which are reasonable? 

I'm ready to roll 2.1.0-rc2 ATM, this is the only issue I can think of. Thanks., Given than this is a legacy thing coming from Hadoop 1, I don't think we should use at all YARN constants properties.

Why we don't use the Hadoop 1 JT properties for the same, in the mapred-site.xml documenting how they have to be set to the  MIN of the scheduler for SLOT_MILLIS counter to kick in? To me this seem a much more correct way of doing it., I'll repeat that I'm against multiple configs for the same property which leads to operator errors (admins setting one but forgetting to set the other) and am willing to live with other alternatives which seem better from a technical standpoint.

bq. Why we don't use the Hadoop 1 JT properties for the same, in the mapred-site.xml documenting how they have to be set to the MIN of the scheduler for SLOT_MILLIS counter to kick in? To me this seem a much more correct way of doing it.

ATM, I don't see where this argument is going at all - frankly, we seem to be making YARN-1004 much bigger deal than it is.

Several folks have expressed concerns about multiple configs and yet we don't seem to converge; this is in spite of, IMO, very reasonable alternatives. 

I'm inclined to go ahead with rc2 without MAPREDUCE-5311 & YARN-1004. Of course, we can revisit both for 2.1.1 via deprecation of yarn.scheduler.min being discussed in YARN-1004. 

I'll stress that we can continue talking and get both in once we all agree.

My plan is to cut an rc2 by noon PST tmrw (9/15). Let's revisit this discussion after if we can't converge before then. Makes sense? Thanks., Let me understand this a bit.
There is existing yarn.min config. This is used by schedulers to do their internal logic. MR AM uses this same config. This is not optimal but has the virtue of being simple and relatively error free since there is only 1 config to change.

If we change yarn.min to yarn.sched-name.min and introduce mr.min for MR then who will keep both of these in sync. Also the sync value depends on the scheduler being currently used. This is also sub optimal but is less preferable than the former because 1) new config 2) manual synch of 2 configs based on scheduler being used. 

If YARN-1004 doesnt touch yarn.min then we are good. Currently both schedulers are using the min values and will probably continue to use it for the foreseeable future. IMO yarn.max is not scheduler specific. Its an admin config that must be enforced by any scheduler. Lets just leave these configs as they are because removing them is causing more grief than gain (including this jira). And let MR use these configs to do internal calculations. I wish we had more foresight earlier and done the right thing for slot_millis when we wrote the original code., Given the conclusions here and on YARN-1004, resolving this as "won't fix".  Filed MAPREDUCE-5463 for deprecating the SLOTS_MILLIS counters and MAPREDUCE-5464 for adding in MEM_MILLIS.]