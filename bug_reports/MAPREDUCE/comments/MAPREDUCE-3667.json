[This was caused by over-aggressive configs in the reduce., Hi Arun 
I have similar setting for 0.23 and Hadoop-0.20.204 with GridMix and same trace
mapred.job.shuffle.input.buffer.percent=0.7 is Hadoop 0.20.204
And
mapreduce.reduce.shuffle.input.buffer.percent=0.7

Hadoop 0.20.204 reducers does not goes OOM, I have seen this in Hadoop.Next only.
And even in Hadoop 0.23 the behavior is not consistent, random number of job used fail due to this.
W.r.t to Hadoop-0.20.204 is not a regression

, bq. Hadoop 0.20.204 reducers does not goes OOM, I have seen this in Hadoop.Next only.
That is right, Karam. We would ideally want YARN+MR to be able to run with the same configuration. Unfortunately mrv2 reduce runtime has changed a lot, and it performs better in so many other situations but worse in this particular case. The implementation has changed in such a way that supporting 0.7 is not possible with the current set of jobs in gridmix without running into OOM.

I agree that it is a regression but for now this should be fine. We'd ideally want to fix this, will open a separate ticket, but the timelines for that fix are uncertain at this point.
]