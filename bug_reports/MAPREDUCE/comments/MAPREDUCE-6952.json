[Calling this code during job submit where /tmp/f1 exists in the default filesystem:
{code}
  DistributedCache.addFileToClassPath(new Path(new URI("/tmp/f1#fizgig")), conf);
{code}
causes job submission to fail with this error:
{noformat}
java.io.FileNotFoundException: File does not exist: hdfs://localhost:8020/tmp/f1#fizgig
	at org.apache.hadoop.hdfs.DistributedFileSystem$29.doCall(DistributedFileSystem.java:1480)
	at org.apache.hadoop.hdfs.DistributedFileSystem$29.doCall(DistributedFileSystem.java:1473)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1488)
	at org.apache.hadoop.fs.FileSystem.resolvePath(FileSystem.java:902)
	at org.apache.hadoop.mapreduce.v2.util.MRApps.addToClasspathIfNotJar(MRApps.java:339)
	at org.apache.hadoop.mapreduce.v2.util.MRApps.setClasspath(MRApps.java:272)
	at org.apache.hadoop.mapred.YARNRunner.setupContainerLaunchContextForAM(YARNRunner.java:480)
	at org.apache.hadoop.mapred.YARNRunner.createApplicationSubmissionContext(YARNRunner.java:538)
	at org.apache.hadoop.mapred.YARNRunner.submitJob(YARNRunner.java:317)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:253)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1344)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1962)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1362)
	at org.apache.hadoop.mapreduce.SleepJob.run(SleepJob.java:282)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)
	at org.apache.hadoop.mapreduce.SleepJob.main(SleepJob.java:197)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.hadoop.util.ProgramDriver$ProgramDescription.invoke(ProgramDriver.java:71)
	at org.apache.hadoop.util.ProgramDriver.run(ProgramDriver.java:144)
	at org.apache.hadoop.test.MapredTestDriver.run(MapredTestDriver.java:139)
	at org.apache.hadoop.test.MapredTestDriver.main(MapredTestDriver.java:147)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.hadoop.util.RunJar.run(RunJar.java:239)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:153)
{noformat}

The intent is to have /tmp/f1 localized as "fizgig" in the container directory path just like one can with the -libjars flag for files on the client's local filesystem.

The problem occurs because DistributedCache.getFileClasspaths should interpret the strings as URIs rather than Paths here:
{code}
  public static Path[] getFileClassPaths(Configuration conf) {
    ArrayList<String> list = (ArrayList<String>)conf.getStringCollection(
                                MRJobConfig.CLASSPATH_FILES);
    if (list.size() == 0) {
      return null;
    }
    Path[] paths = new Path[list.size()];
    for (int i = 0; i < list.size(); i++) {
      paths[i] = new Path(list.get(i));
    }
    return paths;
  }
{code}
]