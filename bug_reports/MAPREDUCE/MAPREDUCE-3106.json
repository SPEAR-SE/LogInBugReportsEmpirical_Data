{
    "expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields",
    "fields": {
        "aggregateprogress": {
            "progress": 0,
            "total": 0
        },
        "aggregatetimeestimate": null,
        "aggregatetimeoriginalestimate": null,
        "aggregatetimespent": null,
        "assignee": null,
        "components": [],
        "created": "2011-09-27T07:28:48.000+0000",
        "creator": {
            "active": true,
            "avatarUrls": {
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452",
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
            },
            "displayName": "Arsen Zahray",
            "key": "menkaur",
            "name": "menkaur",
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=menkaur",
            "timeZone": "Etc/UTC"
        },
        "customfield_10010": null,
        "customfield_12310191": null,
        "customfield_12310192": null,
        "customfield_12310220": "2011-09-28T08:16:49.662+0000",
        "customfield_12310222": "1_*:*_1_*:*_96192301_*|*_5_*:*_1_*:*_0",
        "customfield_12310230": null,
        "customfield_12310250": null,
        "customfield_12310290": null,
        "customfield_12310291": null,
        "customfield_12310300": null,
        "customfield_12310310": "0.0",
        "customfield_12310320": null,
        "customfield_12310420": "17173",
        "customfield_12310920": "112637",
        "customfield_12310921": null,
        "customfield_12311020": null,
        "customfield_12311024": null,
        "customfield_12311120": null,
        "customfield_12311820": "0|i0jmvr:",
        "customfield_12312022": null,
        "customfield_12312023": null,
        "customfield_12312024": null,
        "customfield_12312026": null,
        "customfield_12312220": null,
        "customfield_12312320": null,
        "customfield_12312321": null,
        "customfield_12312322": null,
        "customfield_12312323": null,
        "customfield_12312324": null,
        "customfield_12312325": null,
        "customfield_12312326": null,
        "customfield_12312327": null,
        "customfield_12312328": null,
        "customfield_12312329": null,
        "customfield_12312330": null,
        "customfield_12312331": null,
        "customfield_12312332": null,
        "customfield_12312333": null,
        "customfield_12312334": null,
        "customfield_12312335": null,
        "customfield_12312336": null,
        "customfield_12312337": null,
        "customfield_12312338": null,
        "customfield_12312339": null,
        "customfield_12312340": null,
        "customfield_12312341": null,
        "customfield_12312520": null,
        "customfield_12312521": "Wed Sep 28 10:11:10 UTC 2011",
        "customfield_12312720": null,
        "customfield_12312823": null,
        "customfield_12312920": null,
        "customfield_12312921": null,
        "customfield_12312923": null,
        "customfield_12313422": "false",
        "customfield_12313520": null,
        "description": "I have a hadoop job, which works perfectly fine when done with a class implementing Mapper. When I do replace Mapper with MultithreadMapper, the job crashes with following message:\n\njava.io.IOException: Type mismatch in key from map: expected org.apache.hadoop.io.IntWritable, recieved org.apache.hadoop.io.LongWritable\n\tat org.apache.hadoop.mapred.MapTask$MapOutputBuffer.collect(MapTask.java:862)\n\tat org.apache.hadoop.mapred.MapTask$NewOutputCollector.write(MapTask.java:549)\n\tat org.apache.hadoop.mapreduce.TaskInputOutputContext.write(TaskInputOutputContext.java:80)\n\tat org.apache.hadoop.mapreduce.lib.map.MultithreadedMapper$SubMapRecordWriter.write(MultithreadedMapper.java:211)\n\tat org.apache.hadoop.mapreduce.TaskInputOutputContext.write(TaskInputOutputContext.java:80)\n\tat org.apache.hadoop.mapreduce.Mapper.map(Mapper.java:124)\n\tat org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:144)\n\tat org.apache.hadoop.mapreduce.lib.map.MultithreadedMapper$MapRunner.run(MultithreadedMapper.java:264)\n\nHere are the relevant source codes:\n\npublic class MapReduceMain {\n\n\t/**\n\t * @param args\n\t */\n\tpublic static void main(String[] args) {\n\t\ttry {\n\t\t\tif (args.length != 2) {\n\t\t\t\tSystem.err.println(\"Usage: MapReduceMain <input path> <output path>\");\n\t\t\t\tSystem.exit(123);\n\t\t\t}\n\t\t\tJob job = new Job();\n\t\t\tjob.setJarByClass(MapReduceMain.class);\n\t\t\tjob.setInputFormatClass(TextInputFormat.class);\n\t\t\tFileSystem fs = FileSystem.get(URI.create(args[0]), job.getConfiguration());\n\t\t\tFileStatus[] files = fs.listStatus(new Path(args[0]));\n\t\t\tfor(FileStatus sfs:files){\n\t\t\t\tFileInputFormat.addInputPath(job, sfs.getPath());\n\t\t\t}\n\t\t\tFileOutputFormat.setOutputPath(job, new Path(args[1]));\n\t\t\t\n\t\t\tjob.setMapperClass(MyMultithreadMapper.class);\n\t\t\tjob.setReducerClass(MyReducer.class);\n\t\t\tMultithreadedMapper.setNumberOfThreads(job, MyMultithreadMapper.nThreads);\n\n\t\t\tjob.setOutputKeyClass(IntWritable.class); \n\t\t\tjob.setOutputValueClass(MyPage.class);\n\t\t\t\n\t\t\tjob.setOutputFormatClass(SequenceFileOutputFormat.class);\n\t\t\t\n\t\t\tSystem.exit(job.waitForCompletion(true) ? 0 : 1);\n\t\t} catch (Exception e) {\n\t\t\te.printStackTrace();\n\t\t}\n\n\t}\n\n\npublic class MyMultithreadMapper extends MultithreadedMapper<LongWritable, Text, IntWritable, MyPage> {\n\n\tConcurrentLinkedQueue<MyScraper>\tscrapers\t= new ConcurrentLinkedQueue<MyScraper>();\n\n\tpublic static final int\t\t\t\tnThreads\t= 5;\n\n\tpublic VrboMultithreadMapper() {\n\t\tfor (int i = 0; i < nThreads; i++) {\n\t\t\tscrapers.add(new MyScraper());\n\t\t}\n\t}\n\n\tpublic void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {\n\t\tMyScraper scraper = scrapers.poll();\n\n\t\tMyPage result = null;\n\t\tfor (int i = 0; i < 10; i++) {\n\t\t\ttry {\n\t\t\t\tresult = scraper.scrapPage(value.toString(), true);\n\t\t\t\tbreak;\n\t\t\t} catch (Exception e) {\n\t\t\t\te.printStackTrace();\n\t\t\t}\n\t\t}\n\n\t\tif (result == null) {\n\t\t\tresult = new MyPage();\n\t\t\tresult.setUrl(key.toString());\n\t\t}\n\n\t\tcontext.write(new IntWritable(result.getUrl().hashCode()), result);\n\n\t\tscrapers.add(scraper);\n\t}\n}\n\n\nand here's the code for the working mapper class, just to be sure:\n\npublic class MyMapper extends Mapper<LongWritable, Text, IntWritable,MyPage> {\n\tMyScraper scr = new MyScraper();\n\t\n\tpublic void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {\n\t\tMyPage result =null;\n\t\tfor(int i=0;i<10;i++){\n\t\t\ttry{\n\t\t\t\tresult = scr.scrapPage(value.toString(), true);\n\t\t\t\tbreak;\n\t\t\t}catch(Exception e){\n\t\t\t\te.printStackTrace();\n\t\t\t}\n\t\t}\n\t\t\n\t\tif(result==null){\n\t\t\tresult = new MyPage();\n\t\t\tresult.setUrl(key.toString());\n\t\t}\n\t\t\n\t\tcontext.write(new IntWritable(result.getUrl().hashCode()),result);\n\t}\n}\n\n\nThis appears to be a hadoop bug",
        "duedate": null,
        "environment": null,
        "fixVersions": [],
        "issuelinks": [],
        "issuetype": {
            "avatarId": 21133,
            "description": "A problem which impairs or prevents the functions of the product.",
            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
            "id": "1",
            "name": "Bug",
            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
            "subtask": false
        },
        "labels": [],
        "lastViewed": null,
        "priority": {
            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/blocker.svg",
            "id": "1",
            "name": "Blocker",
            "self": "https://issues.apache.org/jira/rest/api/2/priority/1"
        },
        "progress": {
            "progress": 0,
            "total": 0
        },
        "project": {
            "avatarUrls": {
                "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310941&avatarId=10096",
                "24x24": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310941&avatarId=10096",
                "32x32": "https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310941&avatarId=10096",
                "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12310941&avatarId=10096"
            },
            "id": "12310941",
            "key": "MAPREDUCE",
            "name": "Hadoop Map/Reduce",
            "projectCategory": {
                "description": "Scalable Distributed Computing",
                "id": "10292",
                "name": "Hadoop",
                "self": "https://issues.apache.org/jira/rest/api/2/projectCategory/10292"
            },
            "self": "https://issues.apache.org/jira/rest/api/2/project/12310941"
        },
        "reporter": {
            "active": true,
            "avatarUrls": {
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452",
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452"
            },
            "displayName": "Arsen Zahray",
            "key": "menkaur",
            "name": "menkaur",
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=menkaur",
            "timeZone": "Etc/UTC"
        },
        "resolution": {
            "description": "The problem described is an issue which will never be fixed.",
            "id": "2",
            "name": "Won't Fix",
            "self": "https://issues.apache.org/jira/rest/api/2/resolution/2"
        },
        "resolutiondate": "2011-09-28T10:12:00.000+0000",
        "status": {
            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
            "id": "5",
            "name": "Resolved",
            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
            "statusCategory": {
                "colorName": "green",
                "id": 3,
                "key": "done",
                "name": "Done",
                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3"
            }
        },
        "subtasks": [],
        "summary": "Replacing Mapper with MultithreadedMapper causes the job to crash with \"Type mismatch in key from map\" ",
        "timeestimate": null,
        "timeoriginalestimate": null,
        "timespent": null,
        "updated": "2011-09-28T10:12:00.000+0000",
        "versions": [{
            "archived": false,
            "description": "",
            "id": "12316151",
            "name": "0.20.203.0",
            "releaseDate": "2011-05-11",
            "released": true,
            "self": "https://issues.apache.org/jira/rest/api/2/version/12316151"
        }],
        "votes": {
            "hasVoted": false,
            "self": "https://issues.apache.org/jira/rest/api/2/issue/MAPREDUCE-3106/votes",
            "votes": 0
        },
        "watches": {
            "isWatching": false,
            "self": "https://issues.apache.org/jira/rest/api/2/issue/MAPREDUCE-3106/watchers",
            "watchCount": 1
        },
        "workratio": -1
    },
    "id": "12524811",
    "key": "MAPREDUCE-3106",
    "self": "https://issues.apache.org/jira/rest/api/2/issue/12524811"
}