{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12399248","self":"https://issues.apache.org/jira/rest/api/2/issue/12399248","key":"MAPREDUCE-15","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310941","id":"12310941","key":"MAPREDUCE","name":"Hadoop Map/Reduce","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310941&avatarId=10096","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310941&avatarId=10096","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310941&avatarId=10096","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310941&avatarId=10096"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":"2008-06-30T15:46:47.240+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Fri Nov 06 15:17:01 UTC 2015","customfield_12310420":"148422","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/MAPREDUCE-15/watchers","watchCount":7,"isWatching":false},"created":"2008-06-30T01:32:06.399+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[],"issuelinks":[{"id":"12448050","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12448050","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"12426283","key":"MAPREDUCE-21","self":"https://issues.apache.org/jira/rest/api/2/issue/12426283","fields":{"summary":"NegativeArraySizeException in reducer with new api","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}}],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2015-11-06T15:17:59.356+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/4","description":"This issue was once resolved, but the resolution was deemed incorrect. From here issues are either marked assigned or resolved.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/reopened.png","name":"Reopened","id":"4","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"components":[],"timeoriginalestimate":null,"description":"Currently a bad record in a sequencefile leads to entire job being failed. the best workaround is to skip an errant file manually (by looking at what map task failed).  This is a sucky option because it's manual and because one should be able to skip a sequencefile block (instead of entire file).\n\nWhile we don't see this often (and i don't know why this corruption happened) - here's an example stack:\nStatus : FAILED java.lang.NegativeArraySizeException\n\tat org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:96)\n\tat org.apache.hadoop.io.BytesWritable.setSize(BytesWritable.java:75)\n\tat org.apache.hadoop.io.BytesWritable.readFields(BytesWritable.java:130)\n\tat org.apache.hadoop.io.SequenceFile$Reader.getCurrentValue(SequenceFile.java:1640)\n\tat org.apache.hadoop.io.SequenceFile$Reader.next(SequenceFile.java:1712)\n\tat org.apache.hadoop.mapred.SequenceFileRecordReader.next(SequenceFileRecordReader.java:79)\n\tat org.apache.hadoop.mapred.MapTask$1.next(MapTask.java:176)\n\nIdeally the recordreader should just skip the entire chunk if it gets an unrecoverable error while reading.\n\nThis was the consensus in hadoop-153 as well (that data corruptions should be handled by recordreaders) and hadoop-3144 did something similar for textinputformat.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"107932","customfield_12312823":null,"summary":"SequenceFile RecordReader should skip bad records","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jsensarma","name":"jsensarma","key":"jsensarma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Joydeep Sen Sarma","active":true,"timeZone":"Asia/Kolkata"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jsensarma","name":"jsensarma","key":"jsensarma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Joydeep Sen Sarma","active":true,"timeZone":"Asia/Kolkata"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12399248/comment/12609267","id":"12609267","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley","name":"owen.omalley","key":"owen.omalley","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=29697","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=29697","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=owen.omalley&avatarId=29697","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=owen.omalley&avatarId=29697"},"displayName":"Owen O'Malley","active":true,"timeZone":"America/Los_Angeles"},"body":"This is a duplicate of HADOOP-153.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley","name":"owen.omalley","key":"owen.omalley","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=29697","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=29697","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=owen.omalley&avatarId=29697","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=owen.omalley&avatarId=29697"},"displayName":"Owen O'Malley","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-06-30T15:46:47.240+0000","updated":"2008-06-30T15:46:47.240+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12399248/comment/12609278","id":"12609278","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jsensarma","name":"jsensarma","key":"jsensarma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Joydeep Sen Sarma","active":true,"timeZone":"Asia/Kolkata"},"body":"hadoop-153 is addressing application errors only at this point. i thought there was agreement that recordreaders should implement any logic for skipping corrupt records internally (and outside the scope of 153). please see:\n\nhttp://issues.apache.org/jira/browse/HADOOP-153?focusedCommentId=12593425#action_12593425","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jsensarma","name":"jsensarma","key":"jsensarma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Joydeep Sen Sarma","active":true,"timeZone":"Asia/Kolkata"},"created":"2008-06-30T16:16:40.439+0000","updated":"2008-06-30T16:16:40.439+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12399248/comment/12609288","id":"12609288","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley","name":"owen.omalley","key":"owen.omalley","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=29697","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=29697","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=owen.omalley&avatarId=29697","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=owen.omalley&avatarId=29697"},"displayName":"Owen O'Malley","active":true,"timeZone":"America/Los_Angeles"},"body":"So what is the approach here?\n\n1. Internal errors (negative lengths, any others?)\n  throw exception and skip to next sync block\n2. reader errors (ie. errors in the deserializer)\n  skip to next record\n\nIs that your intent?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley","name":"owen.omalley","key":"owen.omalley","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=29697","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=29697","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=owen.omalley&avatarId=29697","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=owen.omalley&avatarId=29697"},"displayName":"Owen O'Malley","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-06-30T16:42:52.690+0000","updated":"2008-06-30T16:42:52.690+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12399248/comment/12610193","id":"12610193","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sharadag","name":"sharadag","key":"sharadag","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sharad Agarwal","active":true,"timeZone":"Etc/UTC"},"body":"The recordReader should somehow inform the framework about skipping any of the records. I think it wont be acceptable for the user job to skip a record and not notify about it.\nDoing it may require RecordReader interface to change. One way of doing that without changing the interface would be throw a specific exception from next(). The framework can catch it and based on the exception type can decide to again call next() or just fail the job. Also it would allow framework to keep something like skipped records counter.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sharadag","name":"sharadag","key":"sharadag","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sharad Agarwal","active":true,"timeZone":"Etc/UTC"},"created":"2008-07-03T10:54:31.859+0000","updated":"2008-07-03T10:54:31.859+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12399248/comment/12610271","id":"12610271","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jsensarma","name":"jsensarma","key":"jsensarma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Joydeep Sen Sarma","active":true,"timeZone":"Asia/Kolkata"},"body":"sorry - i didn't see Owen's comment earlier: - yes #2 was the intent.\n\nI agree that this causes the absence of any policy hooks (max number of errors tolerable, reporting errors out to JobTracker.) - and i think that's leading to Sharad's comment. One problem with his proposal is how will the RecordReader differentiate between the first and second next() call?\n\nOne simple method to integrate this with the policy framework would be for the recordreader to export an error counter (as an additional interface). The TT/JT can make go/no-go decision based on the number of errors they observe. By default a recordreader would attempt to skip bad records, while raising the error count - but based on job spec - this may lead to job being aborted by Hadoop.\n\nOne wrinkle is that the number of errors is not the same as the amount of data skipped. That may be a design point (report bytes skipped versus # of bad records).\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jsensarma","name":"jsensarma","key":"jsensarma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Joydeep Sen Sarma","active":true,"timeZone":"Asia/Kolkata"},"created":"2008-07-03T16:26:30.016+0000","updated":"2008-07-03T16:26:30.016+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12399248/comment/12610458","id":"12610458","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sharadag","name":"sharadag","key":"sharadag","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sharad Agarwal","active":true,"timeZone":"Etc/UTC"},"body":"{quote}One problem with his proposal is how will the RecordReader differentiate between the first and second next() call? {quote}\nDoes RecordReader really need to differentiate? When next() is called the first time, the RecordReader would skip to the sane record boundary, BEFORE throwing an Exception (a subclass of IOException, something like SkippedRecordException), so that framework knows that the record has been skipped. Calling next() again would read the next() record.\nThis way we are also not forcing all RecordReaders to implement this feature. \n\n{quote} One simple method to integrate this with the policy framework would be for the Recordreader to export an error counter (as an additional interface). {quote}\n That would be the better way. But given that lot of user code may get impacted, we can try to avoid interface change as far as possible.\n\nmakes sense?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sharadag","name":"sharadag","key":"sharadag","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sharad Agarwal","active":true,"timeZone":"Etc/UTC"},"created":"2008-07-04T06:01:12.332+0000","updated":"2008-07-04T06:01:12.332+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12399248/comment/12610582","id":"12610582","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jsensarma","name":"jsensarma","key":"jsensarma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Joydeep Sen Sarma","active":true,"timeZone":"Asia/Kolkata"},"body":"cool - that sounds perfect.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jsensarma","name":"jsensarma","key":"jsensarma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Joydeep Sen Sarma","active":true,"timeZone":"Asia/Kolkata"},"created":"2008-07-04T13:32:21.923+0000","updated":"2008-07-04T13:32:21.923+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12399248/comment/12901479","id":"12901479","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dking","name":"dking","key":"dking","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Dick King","active":true,"timeZone":"Etc/UTC"},"body":"Should the framework carry a {{mapreduce.max.corrupt.input.record.fraction}} and {{mapreduce.max.corrupt.input.record.excess}} ?\n\nThe framework catches and skips the corrupt records, and the bad and good record counts flow back to the job tracker as counters, and if the number of bad records ever exceeds, {{...fraction * number-of-good-records + ...excess}} the job is killed?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dking","name":"dking","key":"dking","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Dick King","active":true,"timeZone":"Etc/UTC"},"created":"2010-08-23T16:58:06.727+0000","updated":"2010-08-23T16:58:06.727+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12399248/comment/14237425","id":"14237425","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dmontauk","name":"dmontauk","key":"dmontauk","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Dobromir Montauk","active":true,"timeZone":"America/Los_Angeles"},"body":"Curious what the current state is; can the RecordReader skip bad records? This seems like the best default behavior in a complex distributed environment where bad records are non-trivial...","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dmontauk","name":"dmontauk","key":"dmontauk","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Dobromir Montauk","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-12-08T04:28:12.000+0000","updated":"2014-12-08T04:28:12.000+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12399248/comment/14993792","id":"14993792","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=noslowerdna","name":"noslowerdna","key":"noslowerdna","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Andrew Olson","active":true,"timeZone":"America/Chicago"},"body":"We encountered the stack trace in this issue's description a few days ago. The SequenceFile \"corruption\" (unreadability) happens because of an integer math overflow [1], if the BytesWritable size is > Integer.MAX_VALUE / 3 (about 682MB). Here is [2] a stackoverflow discussion about this.\n\n[1] https://github.com/apache/hadoop/blob/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/BytesWritable.java#L123\n[2] http://stackoverflow.com/questions/24127304/negativearraysizeexception-when-creating-a-sequencefile-with-large-1gb-bytesw","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=noslowerdna","name":"noslowerdna","key":"noslowerdna","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Andrew Olson","active":true,"timeZone":"America/Chicago"},"created":"2015-11-06T15:17:01.918+0000","updated":"2015-11-06T15:17:01.918+0000"}],"maxResults":10,"total":10,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/MAPREDUCE-15/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i0itv3:"}}