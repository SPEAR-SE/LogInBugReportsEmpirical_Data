{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12598418","self":"https://issues.apache.org/jira/rest/api/2/issue/12598418","key":"MAPREDUCE-4428","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310941","id":"12310941","key":"MAPREDUCE","name":"Hadoop Map/Reduce","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310941&avatarId=10096","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310941&avatarId=10096","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310941&avatarId=10096","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310941&avatarId=10096"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":"2012-07-11T18:55:01.816+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Fri Jul 13 20:52:27 UTC 2012","customfield_12310420":"253839","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/MAPREDUCE-4428/watchers","watchCount":13,"isWatching":false},"created":"2012-07-11T18:26:23.602+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"4.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12320354","id":"12320354","description":"hadoop-2.0.0-alpha release","name":"2.0.0-alpha","archived":false,"released":true,"releaseDate":"2012-05-23"}],"issuelinks":[{"id":"12375137","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12375137","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"12659684","key":"MAPREDUCE-5418","self":"https://issues.apache.org/jira/rest/api/2/issue/12659684","fields":{"summary":"JobHistoryServer has no information about applications if the MR-AM crashes","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/2","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/critical.svg","name":"Critical","id":"2"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12356725","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12356725","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"inwardIssue":{"id":"12603664","key":"MAPREDUCE-4559","self":"https://issues.apache.org/jira/rest/api/2/issue/12603664","fields":{"summary":"Job logs not accessible through job history server for AM killed due to am.liveness-monitor expiry","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=revans2","name":"revans2","key":"revans2","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Robert Joseph Evans","active":true,"timeZone":"America/Chicago"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2013-09-12T04:41:38.250+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12315343","id":"12315343","name":"jobhistoryserver"},{"self":"https://issues.apache.org/jira/rest/api/2/component/12312907","id":"12312907","name":"jobtracker"}],"timeoriginalestimate":null,"description":"We have observed this issue consistently running hadoop CDH4 version (based upon 2.0 alpha release):\n\nIn case our hadoop client code gets a notification for a completed job ( using RunningJob object job, with (job.isComplete() && job.isSuccessful()==false)\nthe hadoop client code does an unconditional job.killJob() to terminate the job.\n\nWith earlier hadoop versions (verified on hadoop 0.20.2 version), we still  have full access to job logs afterwards through hadoop console. However, when using MapReduceV2, the failed hadoop job no longer shows up under jobhistory server. Also, the tracking URL of the job still points to the non-existent Application master http port.\n\nOnce we removed the call to job.killJob() for failed jobs from our hadoop client code, we were able to access the job in job history with mapreduce V2 as well. Therefore this appears to be a race condition in the job management wrt. job history for failed jobs.\n\nWe do have the application master and node manager logs collected for this scenario if that'll help isolate the problem and the fix better.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12536244","id":"12536244","filename":"am_failed_counter_limits.txt","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rjain7","name":"rjain7","key":"rjain7","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rahul Jain","active":true,"timeZone":"America/Los_Angeles"},"created":"2012-07-12T17:46:10.938+0000","size":2517007,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12536244/am_failed_counter_limits.txt"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12536099","id":"12536099","filename":"appMaster_bad.txt","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rjain7","name":"rjain7","key":"rjain7","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rahul Jain","active":true,"timeZone":"America/Los_Angeles"},"created":"2012-07-11T19:53:12.700+0000","size":524377,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12536099/appMaster_bad.txt"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12536100","id":"12536100","filename":"appMaster_good.txt","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rjain7","name":"rjain7","key":"rjain7","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rahul Jain","active":true,"timeZone":"America/Los_Angeles"},"created":"2012-07-11T19:53:12.710+0000","size":591732,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12536100/appMaster_good.txt"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12536176","id":"12536176","filename":"resrcmgr_bad.txt","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rjain7","name":"rjain7","key":"rjain7","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rahul Jain","active":true,"timeZone":"America/Los_Angeles"},"created":"2012-07-12T05:54:03.144+0000","size":206635,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12536176/resrcmgr_bad.txt"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"80665","customfield_12312823":null,"summary":"A failed job is not available under job history if the job is killed right around the time job is notified as failed ","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rjain7","name":"rjain7","key":"rjain7","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rahul Jain","active":true,"timeZone":"America/Los_Angeles"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rjain7","name":"rjain7","key":"rjain7","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rahul Jain","active":true,"timeZone":"America/Los_Angeles"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12598418/comment/13411853","id":"13411853","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=revans2","name":"revans2","key":"revans2","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Robert Joseph Evans","active":true,"timeZone":"America/Chicago"},"body":"This can be caused by a number of things.  Most likely it is caused by a bug in the AM that is making it crash before it can move the job history log to where the history server will pick it up.  If that is the case you need to get access to the AM logs so that we can look at what is happening there.  I am not familiar with what CDH4 has in the UI, but if you click on the application id in the main RM web page you should see a link to the AM's logs.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=revans2","name":"revans2","key":"revans2","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Robert Joseph Evans","active":true,"timeZone":"America/Chicago"},"created":"2012-07-11T18:55:01.816+0000","updated":"2012-07-11T18:55:01.816+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12598418/comment/13411904","id":"13411904","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rjain7","name":"rjain7","key":"rjain7","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rahul Jain","active":true,"timeZone":"America/Los_Angeles"},"body":"Robert,\n\nThe link to AM logs for failed + killed case does not work , instead the error goes like:\n{code}\nFailed while trying to construct the redirect url to the log server. Log Server url may not be configured\nUnknown container. Container either has not started or has already completed or doesn't belong to this node at all.\n{code} \n\nThis is what makes the problem diagnostics quite hard for users.\n\nHowever I did sifting through hdfs (log aggregation was enabled) to search for AM container logs; I believe I have the right one which I will upload next.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rjain7","name":"rjain7","key":"rjain7","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rahul Jain","active":true,"timeZone":"America/Los_Angeles"},"created":"2012-07-11T19:50:07.199+0000","updated":"2012-07-11T19:50:07.199+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12598418/comment/13411906","id":"13411906","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rjain7","name":"rjain7","key":"rjain7","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rahul Jain","active":true,"timeZone":"America/Los_Angeles"},"body":"Included both a good case from web interface (appMaster_good.txt) where no kill was done on the job;\nAnd the bad case logs collected from hdfs sifting (appMaster_bad.txt)","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rjain7","name":"rjain7","key":"rjain7","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rahul Jain","active":true,"timeZone":"America/Los_Angeles"},"created":"2012-07-11T19:53:12.752+0000","updated":"2012-07-11T19:53:12.752+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12598418/comment/13412022","id":"13412022","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=revans2","name":"revans2","key":"revans2","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Robert Joseph Evans","active":true,"timeZone":"America/Chicago"},"body":"From the logs it looks like you had many tasks failing because of the following exception.\n\n{noformat}\n2012-07-11 03:04:27,122 FATAL [IPC Server handler 4 on 37900] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1341894680756_0017_m_000012_0 - exited : java.io.IOException: Exception occured validating bulk loader output\n\tat com.carrieriq.m2m.platform.mmp3.output.db.BulkLoaderOutputWriter.doFinish(BulkLoaderOutputWriter.java:408)\n\tat com.carrieriq.m2m.platform.mmp3.output.db.BulkLoaderOutputWriter.finish(BulkLoaderOutputWriter.java:331)\n\tat com.carrieriq.m2m.platform.mmp3.output.db.DfsAndDbOutputWriter.finish(DfsAndDbOutputWriter.java:89)\n\tat com.carrieriq.m2m.platform.mmp3.output.fact2db.LoadFactsToDatamartMapper.onClose(LoadFactsToDatamartMapper.java:769)\n\tat com.carrieriq.m2m.platform.util.hadoop.AbstractReportingMapper.close(AbstractReportingMapper.java:94)\n\tat org.apache.hadoop.mapred.lib.Chain.close(Chain.java:283)\n\tat org.apache.hadoop.mapred.lib.ChainMapper.close(ChainMapper.java:179)\n\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:399)\n\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:334)\n\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:152)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:396)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1232)\n\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:147)\nCaused by: java.io.IOException: Error(s) found in bulk loader output files.\n\tat com.carrieriq.m2m.platform.mmp3.output.db.BulkLoaderOutputWriter.doFinish(BulkLoaderOutputWriter.java:405)\n\t... 14 more\n{noformat}\n\nThis caused the job itself to fail, and as the AM was trying to tell the RM that it was exiting the RM said who are you, I've never heard of appattempt_1341894680756_0017_000001. It looks almost like the RM somehow was restarted in the middle of the job running, or that it somehow forgot about this particular Application.  Having the RM logs for around the time this was running would help trace down what happened in the RM. \n\n{noformat}\n2012-07-11 03:04:28,574 INFO [Thread-1] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Setting job diagnostics to Task failed task_1341894680756_0017_m_000014\nJob failed as tasks failed. failedMaps:1 failedReduces:0\n\n2012-07-11 03:04:28,575 INFO [Thread-1] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: History url is sjc1-ciq-ibm-grid06.carrieriq.com:19888/jobhistory/job/job_1341894680756_0017\n2012-07-11 03:04:28,580 ERROR [Thread-1] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Exception while unregistering \nRemoteTrace: \n at LocalTrace: \n\torg.apache.hadoop.yarn.exceptions.impl.pb.YarnRemoteExceptionPBImpl: RemoteTrace: \n at LocalTrace: \n\torg.apache.hadoop.yarn.exceptions.impl.pb.YarnRemoteExceptionPBImpl: Application doesn't exist in cache appattempt_1341894680756_0017_000001\n\tat org.apache.hadoop.yarn.factories.impl.pb.YarnRemoteExceptionFactoryPBImpl.createYarnRemoteException(YarnRemoteExceptionFactoryPBImpl.java:39)\n\tat org.apache.hadoop.yarn.ipc.RPCUtil.getRemoteException(RPCUtil.java:47)\n\tat org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService.finishApplicationMaster(ApplicationMasterService.java:222)\n\tat org.apache.hadoop.yarn.api.impl.pb.service.AMRMProtocolPBServiceImpl.finishApplicationMaster(AMRMProtocolPBServiceImpl.java:69)\n\tat org.apache.hadoop.yarn.proto.AMRMProtocol$AMRMProtocolService$2.callBlockingMethod(AMRMProtocol.java:85)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:427)\n\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:916)\n\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1692)\n\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1688)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:396)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1232)\n\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:1686)\n\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)\n\tat java.lang.reflect.Constructor.newInstance(Constructor.java:513)\n\tat org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:90)\n\tat org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:57)\n\tat org.apache.hadoop.yarn.exceptions.impl.pb.YarnRemoteExceptionPBImpl.unwrapAndThrowException(YarnRemoteExceptionPBImpl.java:123)\n\tat org.apache.hadoop.yarn.api.impl.pb.client.AMRMProtocolPBClientImpl.finishApplicationMaster(AMRMProtocolPBClientImpl.java:85)\n\tat org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator.unregister(RMCommunicator.java:190)\n\tat org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator.stop(RMCommunicator.java:216)\n\tat org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.stop(RMContainerAllocator.java:226)\n\tat org.apache.hadoop.mapreduce.v2.app.MRAppMaster$ContainerAllocatorRouter.stop(MRAppMaster.java:668)\n\tat org.apache.hadoop.yarn.service.CompositeService.stop(CompositeService.java:99)\n\tat org.apache.hadoop.yarn.service.CompositeService.stop(CompositeService.java:89)\n\tat org.apache.hadoop.mapreduce.v2.app.MRAppMaster$MRAppMasterShutdownHook.run(MRAppMaster.java:1036)\n\tat org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)\n{noformat}\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=revans2","name":"revans2","key":"revans2","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Robert Joseph Evans","active":true,"timeZone":"America/Chicago"},"created":"2012-07-11T21:30:48.754+0000","updated":"2012-07-11T21:30:48.754+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12598418/comment/13412537","id":"13412537","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rjain7","name":"rjain7","key":"rjain7","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rahul Jain","active":true,"timeZone":"America/Los_Angeles"},"body":"\nHere are the resource manager logs appended for failure case. Note that resource manager was not restarted any time; and the same stack trace can be found on the resource manager when the application attempts to unregister\n{code}\norg.apache.hadoop.yarn.exceptions.impl.pb.YarnRemoteExceptionPBImpl:     Application doesn't exist in cache appattempt_1341894680756_0017_000001....\n{code}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rjain7","name":"rjain7","key":"rjain7","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rahul Jain","active":true,"timeZone":"America/Los_Angeles"},"created":"2012-07-12T05:54:03.182+0000","updated":"2012-07-12T05:54:03.182+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12598418/comment/13412773","id":"13412773","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=revans2","name":"revans2","key":"revans2","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Robert Joseph Evans","active":true,"timeZone":"America/Chicago"},"body":"It looks like someone killed your application\n\n{noformat}\n2012-07-11 03:04:28,481 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop\tIP=10.202.50.180\tOPERATION=Kill Application Request\tTARGET=ClientRMService\tRESULT=SUCCESS\tAPPID=application_1341894680756_0017\n2012-07-11 03:04:28,481 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1341894680756_0017 State change from RUNNING to KILLED\n{noformat}\n\nThis caused the RM to forget about the application, and it happened just as your application was about to fail, so the AM asked to unregister, but the RM said I don't know who you are, when in reality it should have said didn't I try to kill you?  I don't know who tried to kill this application or really why it went to the RM instead of the AM.  The issue here is that normally for mapreduce job -kill the client is first going to request that the AM commit suicide.  That way it can put the logs where they are supposed to be, before it tries to ask the RM to kill the application.  If you do a yarn application kill there is no guarantee what the AM will or will not be able to do before it is killed. If the AM had been slower the NodeManager would have just sent a kill -9 to the AM, and then it would not have had any chance at putting the logs in the correct place.  You should probably look at who was on 10.202.50.180 and what they were doing that might have asked the RM to kill this AM.\n\nFixing this in the general case so that the job history logs always are copied to the correct place is going to be difficult.  This is because we have to insert something that will always run after the AM has exited, it is probably best to make it so it will only run after the AM has exited badly, even for a kill.  It is possible, just not that simple of a fix.  It is even more difficult if we want to handle the case where the node appears to go down just as the AM is crashing.  there are lots of corner cases that potentially make this very difficult to get right.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=revans2","name":"revans2","key":"revans2","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Robert Joseph Evans","active":true,"timeZone":"America/Chicago"},"created":"2012-07-12T13:29:04.732+0000","updated":"2012-07-12T13:29:04.732+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12598418/comment/13412781","id":"13412781","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=revans2","name":"revans2","key":"revans2","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Robert Joseph Evans","active":true,"timeZone":"America/Chicago"},"body":"Just as an FYI if the user does an mapreduce job -kill and the AM reports back that it is no running, then it will ask the RM to kill the job instead of asking the AM to commit suicide.  So if you lost two races then it could be caused by someone running mapreduce job -kill.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=revans2","name":"revans2","key":"revans2","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Robert Joseph Evans","active":true,"timeZone":"America/Chicago"},"created":"2012-07-12T13:36:33.166+0000","updated":"2012-07-12T13:36:33.166+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12598418/comment/13412950","id":"13412950","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rjain7","name":"rjain7","key":"rjain7","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rahul Jain","active":true,"timeZone":"America/Los_Angeles"},"body":"Robert,\n\nTo make the user perspective clear here:\n\nThis grid is a single user managed grid, no other process was running at the time and no one else tried to do kill on the job here.\n\nThe sequence is:\n\na) The job creator application submitted the job to hadoop grid.\n\nb) Max retry count was set to 1 for both mappers and reducers; so as soon as a task failed, the system (AM?) decided to kill all other tasks.\n\nc) The submitter application is waiting in a sleep loop, waking up every 1 second to check the status of the task\ncalling: JobClient.getJob()\n\nd) When the above condition happens, the application receives the running job status as completed , failed (isSuccessful()=false, isComplete()=true on RunningJob object)\n\ne) The application issues a killJob() on the running job object at this time\n\nf) As a result, nothing is accessible in job history from hadoop console, even the AM container logs cannot be accessed.\n\nRemoving (e) from the above sequence make logs accessible again. As I mentioned, with older version of map-reduce, we never encountered the issues of logs getting lost. I believe we need to handle the case of user initiated 'KILL' of the job better in MapReduceV2; 90% of the time we look at map-reduce logs only for failed and killed jobs; so this functionality should work reliably as much as possible.\n\n\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rjain7","name":"rjain7","key":"rjain7","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rahul Jain","active":true,"timeZone":"America/Los_Angeles"},"created":"2012-07-12T17:10:35.517+0000","updated":"2012-07-12T17:10:35.517+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12598418/comment/13412995","id":"13412995","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rjain7","name":"rjain7","key":"rjain7","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rahul Jain","active":true,"timeZone":"America/Los_Angeles"},"body":"Am attaching another case (not directly related to the ticket) that illustrates the point on more reliable way of getting job history.\n\nOur map-reduce jobs generate counters beyond the standard 120 limit imposed by yarn. We increased the counters to 1000 but the jobs went over that limit as well.\n\nAs you can see in attached file am_failed_counter_limits.txt, the AM encountered exceptions trying to handle the large # of counters; at the end no job history was accessible either. \n\nNote that we did increase counters for the job submitter task to 2000, however the only way to have AM use a higher # of counters is to change the global yarn settings and restart yarn.\n ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rjain7","name":"rjain7","key":"rjain7","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rahul Jain","active":true,"timeZone":"America/Los_Angeles"},"created":"2012-07-12T17:46:11.248+0000","updated":"2012-07-12T17:46:11.248+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12598418/comment/13413840","id":"13413840","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=revans2","name":"revans2","key":"revans2","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Robert Joseph Evans","active":true,"timeZone":"America/Chicago"},"body":"You should not need to restart all of yarn to update the counters max.  You should be able to set it on a per application basis assuming that you do not have it marked as final in mapred-site.xml, although you may get similar errors in the History Server if you do that.\n\nCould you please file a separate JIRA for the counter's limit issue.  We should have a cleaner way to deal with the counter's limit being exceeded.  \n\nI agree with you that this is a fix that needs to happen, Sadly it is just not a simple fix.  I will talk with some co-workers about this to see that we can come up with.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=revans2","name":"revans2","key":"revans2","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Robert Joseph Evans","active":true,"timeZone":"America/Chicago"},"created":"2012-07-13T16:01:01.303+0000","updated":"2012-07-13T16:01:01.303+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12598418/comment/13413864","id":"13413864","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=revans2","name":"revans2","key":"revans2","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Robert Joseph Evans","active":true,"timeZone":"America/Chicago"},"body":"OK I think I have an idea, but Sid I would like your opinion on this.  If you want to pull in Arun on this too I am happy for his opinion too.\n\nWhat if we augment the ContainerLaunchContext to have something like a cleanup on kill boolean and a cleanup on bad exit boolean.  If cleanup on kill is set and the container is forcibly killed or if cleanup on bad exit is set and the container exits with a non-zero status, the NM would try to rerun the container, but with an environment variable set saying that it is being rerun for cleanup.  The NM would give it a configurable amount of time, say 20 seconds, to do the cleanup, and then if it has not already exited it will shoot it.\n\nThe RM would need a new variable when the AM is submitted to indicate that this should happen, and then if that is set it would turn on cleanup on kill for the AM when it is launched, and it would turn on cleanup on bad exit, when it is launching the AM for the last retry.\n\nThe MR AM would have to be modified to look for the environment variable and only do cleanup if it sees it.  The MR client would have to be modified to set this boolean variable.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=revans2","name":"revans2","key":"revans2","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Robert Joseph Evans","active":true,"timeZone":"America/Chicago"},"created":"2012-07-13T16:38:58.862+0000","updated":"2012-07-13T16:38:58.862+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12598418/comment/13414017","id":"13414017","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rjain7","name":"rjain7","key":"rjain7","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rahul Jain","active":true,"timeZone":"America/Los_Angeles"},"body":"OK, will create a separate one for the counter limit exceeded issue.\n\nBTW, I did open MAPREDUCE-4442 for a related issue: we are unable to access job counters for the period AM is possibly shutting down as well, it may be a good idea to consider that issue in the final fix. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rjain7","name":"rjain7","key":"rjain7","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rahul Jain","active":true,"timeZone":"America/Los_Angeles"},"created":"2012-07-13T20:26:34.451+0000","updated":"2012-07-13T20:26:34.451+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12598418/comment/13414039","id":"13414039","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rjain7","name":"rjain7","key":"rjain7","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rahul Jain","active":true,"timeZone":"America/Los_Angeles"},"body":"MAPREDUCE-4443 created to track the AM reliability for counters limit exceeded issue.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rjain7","name":"rjain7","key":"rjain7","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rahul Jain","active":true,"timeZone":"America/Los_Angeles"},"created":"2012-07-13T20:52:27.678+0000","updated":"2012-07-13T20:52:27.678+0000"}],"maxResults":13,"total":13,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/MAPREDUCE-4428/votes","votes":3,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i0e5kn:"}}