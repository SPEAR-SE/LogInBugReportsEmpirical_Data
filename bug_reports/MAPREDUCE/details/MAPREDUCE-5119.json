{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12639568","self":"https://issues.apache.org/jira/rest/api/2/issue/12639568","key":"MAPREDUCE-5119","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310941","id":"12310941","key":"MAPREDUCE","name":"Hadoop Map/Reduce","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310941&avatarId=10096","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310941&avatarId=10096","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310941&avatarId=10096","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310941&avatarId=10096"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":"2013-03-28T17:59:13.176+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Fri Mar 29 13:22:06 UTC 2013","customfield_12310420":"320037","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/MAPREDUCE-5119/watchers","watchCount":3,"isWatching":false},"created":"2013-03-28T12:47:15.548+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/4","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/minor.svg","name":"Minor","id":"4"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12323594","id":"12323594","description":"maintenance release on branch-1.1","name":"1.1.2","archived":false,"released":true,"releaseDate":"2013-02-15"}],"issuelinks":[],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2013-03-29T14:33:35.324+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/4","description":"This issue was once resolved, but the resolution was deemed incorrect. From here issues are either marked assigned or resolved.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/reopened.png","name":"Reopened","id":"4","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"components":[],"timeoriginalestimate":null,"description":"#make a long text line. It seems only long line text causing issue.\n$ cat abook.txt | base64 –w 0 >onelinetext.b64 #200KB+ long\n$ hadoop fs –put onelinetext.b64 /input/onelinetext.b64\n$ hadoop jar hadoop-streaming.jar  \\\n    -input /input/onelinetext.b64 \\\n    -output /output \\\n    -inputformat org.apache.hadoop.mapred.lib.NLineInputFormat \\\n    –mapper wc \nNum task: 1, and output has one line:\nLine 1: 1 2 202699\nwhich makes sense because one line per mapper is intended.\n\nThen, using compression with NLineInputFormat \n$ gzip onelinetext.b64\n$ hadoop fs –put onelinetext.b64.bz2  /input/onelinetext.b64.gz\n$ hadoop jar hadoop-streaming.jar \\\n      -Dmapred.input.compress=true \\\n      -Dmapred.input.compression.codec=org.apache.hadoop.io.compress.GzipCodec \\\n      -input /input/onelinetext.b64.gz \\\n      -output /output \\\n      -inputformat org.apache.hadoop.mapred.lib.NLineInputFormat \\\n      –mapper wc \nI am expecting the same results as above, 'coz decompressing should occur before processing one-line text (i.e. wc), however, I am getting:\n\nNum task: 397 (or other large numbers depend on environments), and output has 397 lines:\nLine1-396: 0 0 0\nLine 397: 1 2 202699\n\nAny idea why so many mapred.map.tasks >>1? Is it incorrect splitting? I purposely choose gzip because I believe it is NOT split-able. I got similar results when using bzip2 and lzop codecs.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"320378","customfield_12312823":null,"summary":"Splitting issue when using NLineInputFormat with compression","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=openresearch","name":"openresearch","key":"openresearch","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Qiming He","active":true,"timeZone":"America/New_York"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=openresearch","name":"openresearch","key":"openresearch","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Qiming He","active":true,"timeZone":"America/New_York"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":"Try in Apache Hadoop 1.1.1, CDH4, and Amazon EMR. Same result.","customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12639568/comment/13616479","id":"13616479","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sureshms","name":"sureshms","key":"sureshms","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10450","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10450","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10450","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10450"},"displayName":"Suresh Srinivas","active":true,"timeZone":"America/Los_Angeles"},"body":"Jira is for reporting bugs and not for asking bugs. Please use the user mailing lists for questions such as this.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sureshms","name":"sureshms","key":"sureshms","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10450","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10450","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10450","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10450"},"displayName":"Suresh Srinivas","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-03-28T17:59:13.176+0000","updated":"2013-03-28T17:59:13.176+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12639568/comment/13616524","id":"13616524","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=openresearch","name":"openresearch","key":"openresearch","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Qiming He","active":true,"timeZone":"America/New_York"},"body":"It could be a bug, for Hadoop not splitting compressed data correctly using NLineInputFormat. \nSame question have been posted to hadoop user mailing list with no answer. \n\nIf you do not think it is a bug, can you explain why it is NOT?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=openresearch","name":"openresearch","key":"openresearch","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Qiming He","active":true,"timeZone":"America/New_York"},"created":"2013-03-28T18:48:13.289+0000","updated":"2013-03-28T18:48:13.289+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12639568/comment/13616525","id":"13616525","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=openresearch","name":"openresearch","key":"openresearch","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Qiming He","active":true,"timeZone":"America/New_York"},"body":"see my comments","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=openresearch","name":"openresearch","key":"openresearch","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Qiming He","active":true,"timeZone":"America/New_York"},"created":"2013-03-28T18:48:39.718+0000","updated":"2013-03-28T18:48:39.718+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12639568/comment/13617327","id":"13617327","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sureshms","name":"sureshms","key":"sureshms","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10450","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10450","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10450","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10450"},"displayName":"Suresh Srinivas","active":true,"timeZone":"America/Los_Angeles"},"body":"bq. It could be a bug, for Hadoop not splitting compressed data correctly using NLineInputFormat. \nThe description of the jira made it sound like you were asking a question. There are many such jiras created in Hadoop where jira is misused for asking questions. Perhaps this could be a bug. So reopening is the right thing to do. I will ask someone with more mapreduce background to comment on this.\n\nI am also moving this to jira to MapReduce.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sureshms","name":"sureshms","key":"sureshms","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10450","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10450","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10450","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10450"},"displayName":"Suresh Srinivas","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-03-29T13:22:06.316+0000","updated":"2013-03-29T13:28:07.561+0000"}],"maxResults":4,"total":4,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/MAPREDUCE-5119/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i1j7xj:"}}