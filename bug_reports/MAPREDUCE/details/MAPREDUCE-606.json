{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12393617","self":"https://issues.apache.org/jira/rest/api/2/issue/12393617","key":"MAPREDUCE-606","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310941","id":"12310941","key":"MAPREDUCE","name":"Hadoop Map/Reduce","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310941&avatarId=10096","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310941&avatarId=10096","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310941&avatarId=10096","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310941&avatarId=10096"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2008-04-10T07:41:29.257+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Fri Jul 18 05:09:24 UTC 2014","customfield_12310420":"148934","customfield_12312320":null,"customfield_12310222":"10002_*:*_1_*:*_1936151601_*|*_1_*:*_2_*:*_195911842412_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2014-07-18T05:09:24.168+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/MAPREDUCE-606/watchers","watchCount":12,"isWatching":false},"created":"2008-04-10T07:22:50.225+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"1.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[],"issuelinks":[{"id":"12391710","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12391710","type":{"id":"12310000","name":"Duplicate","inward":"is duplicated by","outward":"duplicates","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/12310000"},"outwardIssue":{"id":"12383254","key":"MAPREDUCE-598","self":"https://issues.apache.org/jira/rest/api/2/issue/12383254","fields":{"summary":"Streaming: better conrol over input splits","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/4","id":"4","description":"An improvement or enhancement to an existing feature or task.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype","name":"Improvement","subtask":false,"avatarId":21140}}}},{"id":"12332931","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12332931","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"inwardIssue":{"id":"12376160","key":"HADOOP-1722","self":"https://issues.apache.org/jira/rest/api/2/issue/12376160","fields":{"summary":"Make streaming to handle non-utf8 byte array","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/4","id":"4","description":"An improvement or enhancement to an existing feature or task.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype","name":"Improvement","subtask":false,"avatarId":21140}}}},{"id":"12364622","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12364622","type":{"id":"12310051","name":"Supercedes","inward":"is superceded by","outward":"supercedes","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/12310051"},"inwardIssue":{"id":"12633405","key":"MAPREDUCE-5018","self":"https://issues.apache.org/jira/rest/api/2/issue/12633405","fields":{"summary":"Support raw binary data with Hadoop streaming","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/10002","description":"A patch for this issue has been uploaded to JIRA by a contributor.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/document.png","name":"Patch Available","id":"10002","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/4","id":4,"key":"indeterminate","colorName":"yellow","name":"In Progress"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/4","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/minor.svg","name":"Minor","id":"4"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/2","id":"2","description":"A new feature of the product, which has yet to be developed.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype","name":"New Feature","subtask":false,"avatarId":21141}}}}],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2014-07-18T05:09:24.232+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12312905","id":"12312905","name":"contrib/streaming"}],"timeoriginalestimate":null,"description":"Lots of streaming applications process textual data with 1 record per line and fields separated by a delimiter. It turns out that there is no point in using any of Hadoop's input/output formats since the streaming script/binary itself will parse the input and break into records and fields. In such cases we should provide users with a binary input/output format which just sends 64k (or so) blocks of data directly from HDFS to the streaming application.\n\nI did something very similar for Pig-Streaming (PIG-94 - BinaryStorage) which resulted in 300%+ speedup for scanning (identity mapper & map-only jobs) data... the parsing done by input/output formats in these cases were pure-overhead.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12401365","id":"12401365","filename":"hadoop-3227.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chinashuimin","name":"chinashuimin","key":"chinashuimin","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"weimin zhu","active":true,"timeZone":"Etc/UTC"},"created":"2009-03-04T05:04:07.241+0000","size":6558,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12401365/hadoop-3227.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"107865","customfield_12312823":null,"summary":"Implement a binary input/output format for Streaming","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=acmurthy","name":"acmurthy","key":"acmurthy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun C Murthy","active":true,"timeZone":"America/Los_Angeles"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=acmurthy","name":"acmurthy","key":"acmurthy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun C Murthy","active":true,"timeZone":"America/Los_Angeles"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12393617/comment/12587512","id":"12587512","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley","name":"owen.omalley","key":"owen.omalley","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=29697","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=29697","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=owen.omalley&avatarId=29697","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=owen.omalley&avatarId=29697"},"displayName":"Owen O'Malley","active":true,"timeZone":"America/Los_Angeles"},"body":"I don't see the problem with using TextInputFormat. After HADOOP-2285, the TextInputFormat will move binary data straight from the file into the Text object. Streaming needs to be changed to get the bytes from the Text and move them straight to the application without converting to a string. That would also speed up streaming...","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley","name":"owen.omalley","key":"owen.omalley","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=29697","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=29697","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=owen.omalley&avatarId=29697","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=owen.omalley&avatarId=29697"},"displayName":"Owen O'Malley","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-04-10T07:41:29.257+0000","updated":"2008-04-10T07:41:29.257+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12393617/comment/12587679","id":"12587679","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=aborkovsky","name":"aborkovsky","key":"aborkovsky","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arkady Borkovsky","active":true,"timeZone":"Etc/UTC"},"body":"+1\nThis something that has been waited for for years!\nThe same thing (no extra processing) may be done on the output side, too (final output)","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=aborkovsky","name":"aborkovsky","key":"aborkovsky","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arkady Borkovsky","active":true,"timeZone":"Etc/UTC"},"created":"2008-04-10T15:52:23.718+0000","updated":"2008-04-10T15:52:23.718+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12393617/comment/12587688","id":"12587688","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=runping","name":"runping","key":"runping","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Runping Qi","active":true,"timeZone":"Etc/UTC"},"body":"\n+1 overall.\n\nSome details have to be considered.\n\nHow does the input format define split boundary?\nYou may still use \"\\n\" as the separator. But that is  not a true binary input format.\n\nWhat does the binary output format do?\na pure bytewritable record writer?\nI think the streaming framework needs to make some changes \nso that it does not do any parsing on the streaming output data.\nRather, it passes the output data to the byte writable output record writer directly.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=runping","name":"runping","key":"runping","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Runping Qi","active":true,"timeZone":"Etc/UTC"},"created":"2008-04-10T16:11:56.113+0000","updated":"2008-04-10T16:11:56.113+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12393617/comment/12610462","id":"12610462","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley","name":"owen.omalley","key":"owen.omalley","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=29697","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=29697","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=owen.omalley&avatarId=29697","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=owen.omalley&avatarId=29697"},"displayName":"Owen O'Malley","active":true,"timeZone":"America/Los_Angeles"},"body":"I agree with Runping. For input, you *need* to know the record breaks, or you can't split file between maps. This requires that \\n be special and therefore quoted when in the non-record boundary case. I think we should just do that quoting so that the streaming apps can just echo their input to output and get an Identity map/reduce. Of course this all got a little trickier now that you can change the delimiter from tab to an arbitrary string...","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley","name":"owen.omalley","key":"owen.omalley","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=29697","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=29697","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=owen.omalley&avatarId=29697","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=owen.omalley&avatarId=29697"},"displayName":"Owen O'Malley","active":true,"timeZone":"America/Los_Angeles"},"created":"2008-07-04T06:23:45.449+0000","updated":"2008-07-04T06:23:45.449+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12393617/comment/12678522","id":"12678522","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chinashuimin","name":"chinashuimin","key":"chinashuimin","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"weimin zhu","active":true,"timeZone":"Etc/UTC"},"body":"we created two classes that process the standard binary file for hadoop0.19.1.\nit's BinaryInputFormat and BinaryOutputFormat\nIt is necessary to modify the PipeMapper,PipeMapRed,PipeReducer class for that.\n\nThe attached file(hadoop-3227.patch) is patch.\nThe attached file(hadoop-0.19.1-streaming.jar) is jar file.\n\nUsage is:\n$HADOOP_HOME/bin/hadoop jar contrib/streaming/hadoop-0.19.1-streaming.jar\n-input myInputDirs\n-output myOutputDir\n-mapper \"command1\"\n-reducer \"command2\"\n-inputformat org.apache.hadoop.streaming.BinaryInputFormat\n-outputformat org.apache.hadoop.streaming.BinaryOutputFormat\n\nfor example:\n1.the input is binary of map task,the output is text,and no reducer\n$bin/hadoop jar contrib/streaming/hadoop-0.19.1-streaming.jar\n-input myInputDirs\n-output myOutputDir\n-mapper \"wc -c\"\n-numReduceTasks 0\n-inputformat org.apache.hadoop.streaming.BinaryInputFormat\n\n2.the map's input is binary file,the output is binary file too,and no reducer\n$bin/hadoop jar contrib/streaming/hadoop-0.19.1-streaming.jar\n-input myInputDirs\n-output myOutputDir\n-mapper \"convert -resize 200% - -\"\n-numReduceTasks 0\n-inputformat org.apache.hadoop.streaming.BinaryInputFormat\n-outputformat org.apache.hadoop.streaming.BinaryOutputFormat\n\nnotes:the convert is from ImageMagick\n\n3.the map's input is binary file,the output is binary file too,and the reducer's input is binary file,but the output is text\n$bin/hadoop jar contrib/streaming/hadoop-0.19.1-streaming.jar\n-input myInputDirs\n-output myOutputDir\n-mapper \"convert -resize 200% - -\"\n-reducer \"wc -c\"\n　 -numReduceTasks 1\n-inputformat org.apache.hadoop.streaming.BinaryInputFormat\n-outputformat org.apache.hadoop.streaming.BinaryOutputFormat\n\n4.the map's input is binary file,the output is binary file too,and the reducer's input is binary file,but the output is \n\nbinary file too\n\nIt doesn't support it.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chinashuimin","name":"chinashuimin","key":"chinashuimin","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"weimin zhu","active":true,"timeZone":"Etc/UTC"},"created":"2009-03-04T00:26:58.849+0000","updated":"2009-03-04T05:05:44.093+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12393617/comment/12678809","id":"12678809","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"-1 overall.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12401366/hadoop-0.19.1-streaming.jar\n  against trunk revision 749919.\n\n    +1 @author.  The patch does not contain any @author tags.\n\n    -1 tests included.  The patch doesn't appear to include any new or modified tests.\n                        Please justify why no tests are needed for this patch.\n\n    -1 patch.  The patch command could not apply the patch.\n\nConsole output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-minerva.apache.org/4/console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2009-03-04T17:48:44.362+0000","updated":"2009-03-04T17:48:44.362+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12393617/comment/12689420","id":"12689420","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"body":"So Hudson can apply the patch, would you mind generating it so that it can be applied using {{patch -p0 -E < _patchfile_}}? Thanks","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chris.douglas","name":"chris.douglas","key":"chris.douglas","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chris Douglas","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-03-26T10:17:35.109+0000","updated":"2009-03-26T10:17:35.109+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12393617/comment/12787620","id":"12787620","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley","name":"owen.omalley","key":"owen.omalley","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=29697","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=29697","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=owen.omalley&avatarId=29697","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=owen.omalley&avatarId=29697"},"displayName":"Owen O'Malley","active":true,"timeZone":"America/Los_Angeles"},"body":"I'd propose that we implement this in terms of the org.apache.hadoop.streaming.io.InputWriter and OutputReader. A reader/writer that left the bytes alone, but that quoted the other characters would be great:\n\n{noformat}\nnewline -> \\n\nreturn -> \\r\nbackslash -> \\\\\ntab -> \\t\n{noformat}\n\nThen it would be easy to get quoted binary into streaming applications.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley","name":"owen.omalley","key":"owen.omalley","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=29697","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=29697","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=owen.omalley&avatarId=29697","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=owen.omalley&avatarId=29697"},"displayName":"Owen O'Malley","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-12-08T18:17:01.464+0000","updated":"2009-12-08T18:17:01.464+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12393617/comment/13420931","id":"13420931","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=piccolbo","name":"piccolbo","key":"piccolbo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Antonio Piccolboni","active":true,"timeZone":"America/Los_Angeles"},"body":"This seems equivalent to HADOOP-1722, raw format. Eric opposed quoting back then for reasons unclear to me, but eventually the choice was <rec length><raw bytes>. I may be be missing the fine points here, but this seem to me a revival of the quoting idea rejected back then.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=piccolbo","name":"piccolbo","key":"piccolbo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Antonio Piccolboni","active":true,"timeZone":"America/Los_Angeles"},"created":"2012-07-23T20:12:54.173+0000","updated":"2012-07-23T20:12:54.173+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12393617/comment/14066032","id":"14066032","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=aw","name":"aw","key":"aw","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=aw&avatarId=23681","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=aw&avatarId=23681","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=aw&avatarId=23681","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=aw&avatarId=23681"},"displayName":"Allen Wittenauer","active":true,"timeZone":"America/Tijuana"},"body":"I'm closing this as fixed.  The streaming input/output system has been enhanced since this jira was filed.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=aw","name":"aw","key":"aw","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=aw&avatarId=23681","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=aw&avatarId=23681","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=aw&avatarId=23681","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=aw&avatarId=23681"},"displayName":"Allen Wittenauer","active":true,"timeZone":"America/Tijuana"},"created":"2014-07-18T05:09:24.225+0000","updated":"2014-07-18T05:09:24.225+0000"}],"maxResults":10,"total":10,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/MAPREDUCE-606/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i0itg7:"}}