{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12438924","self":"https://issues.apache.org/jira/rest/api/2/issue/12438924","key":"MAPREDUCE-1144","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310941","id":"12310941","key":"MAPREDUCE","name":"Hadoop Map/Reduce","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310941&avatarId=10096","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310941&avatarId=10096","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310941&avatarId=10096","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310941&avatarId=10096"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/2","id":"2","description":"The problem described is an issue which will never be fixed.","name":"Won't Fix"},"customfield_12312322":null,"customfield_12310220":"2009-10-24T07:59:15.187+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Fri Jan 10 01:39:07 UTC 2014","customfield_12310420":"149308","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_102502482_*|*_5_*:*_2_*:*_265134_*|*_4_*:*_1_*:*_150250950759","customfield_12312321":null,"resolutiondate":"2014-07-29T19:07:01.704+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/MAPREDUCE-1144/watchers","watchCount":14,"isWatching":false},"created":"2009-10-23T14:11:43.371+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"1.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12314047","id":"12314047","description":"","name":"0.20.1","archived":false,"released":true,"releaseDate":"2009-09-01"}],"issuelinks":[{"id":"12380898","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12380898","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"12687631","key":"MAPREDUCE-5711","self":"https://issues.apache.org/jira/rest/api/2/issue/12687631","fields":{"summary":"When JobTracker writing JobHistory to HDFS, it may hung for long time due to DataNode error","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}}],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2015-03-19T23:14:28.417+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12312907","id":"12312907","name":"jobtracker"}],"timeoriginalestimate":null,"description":"I've seen behavior a few times now where the DFS is being slow for one reason or another, and the JT essentially locks up waiting on it while one thread tries for a long time to write history files out. The stack trace blocking everything is:\n\nThread 210 (IPC Server handler 10 on 7277):\n  State: WAITING\n  Blocked count: 171424\n  Waited count: 1209604\n  Waiting on java.util.LinkedList@407dd154\n  Stack:\n    java.lang.Object.wait(Native Method)\n    java.lang.Object.wait(Object.java:485)\n    org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.flushInternal(DFSClient.java:3122)\n    org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.closeInternal(DFSClient.java:3202)\n    org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.close(DFSClient.java:3151)\n    org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:67)\n    org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:106)\n    sun.nio.cs.StreamEncoder.implClose(StreamEncoder.java:301)\n    sun.nio.cs.StreamEncoder.close(StreamEncoder.java:130)\n    java.io.OutputStreamWriter.close(OutputStreamWriter.java:216)\n    java.io.BufferedWriter.close(BufferedWriter.java:248)\n    java.io.PrintWriter.close(PrintWriter.java:295)\n    org.apache.hadoop.mapred.JobHistory$JobInfo.logFinished(JobHistory.java:1349)\n    org.apache.hadoop.mapred.JobInProgress.jobComplete(JobInProgress.java:2167)\n    org.apache.hadoop.mapred.JobInProgress.completedTask(JobInProgress.java:2111)\n    org.apache.hadoop.mapred.JobInProgress.updateTaskStatus(JobInProgress.java:873)\n    org.apache.hadoop.mapred.JobTracker.updateTaskStatuses(JobTracker.java:3598)\n    org.apache.hadoop.mapred.JobTracker.processHeartbeat(JobTracker.java:2792)\n    org.apache.hadoop.mapred.JobTracker.heartbeat(JobTracker.java:2581)\n    sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)\n\nWe should try not to do external IO while holding the JT lock, and instead write the data to an in-memory buffer, drop the lock, and then write.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12622316","id":"12622316","filename":"MAPREDUCE-1144-branch-1.2.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=zhaoyunjiong","name":"zhaoyunjiong","key":"zhaoyunjiong","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"yunjiong zhao","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-01-10T01:39:07.304+0000","size":7427,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12622316/MAPREDUCE-1144-branch-1.2.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"48789","customfield_12312823":null,"summary":"JT should not hold lock while writing user history logs to DFS","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12438924/comment/12769229","id":"12769229","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"Last things in the logs before it hung:\n\n2009-10-23 01:56:55,216 INFO org.apache.hadoop.mapred.JobInProgress: Job job_200910191402_1443 has completed successfully.\n2009-10-23 01:57:41,853 WARN org.apache.hadoop.hdfs.DFSClient: DFSOutputStream ResponseProcessor exception  for block blk_-2046762813438535112_105966370java.net.SocketTimeoutException: 69\n000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.100.50.253:40763 remote=/10.100.50.13:50010]\n        at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)\n        at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:155)\n        at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:128)\n        at java.io.DataInputStream.readFully(DataInputStream.java:178)\n        at java.io.DataInputStream.readLong(DataInputStream.java:399)\n        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$ResponseProcessor.run(DFSClient.java:2398)\n\n2009-10-23 01:57:41,854 WARN org.apache.hadoop.hdfs.DFSClient: Error Recovery for block blk_-2046762813438535112_105966370 bad datanode[0] 10.100.50.13:50010\n2009-10-23 01:57:41,854 WARN org.apache.hadoop.hdfs.DFSClient: Error Recovery for block blk_-2046762813438535112_105966370 in pipeline 10.100.50.13:50010, 10.100.50.11:50010, 10.100.50.69\n:50010: bad datanode 10.100.50.13:50010\n2009-10-23 02:08:52,658 WARN org.apache.hadoop.hdfs.DFSClient: DFSOutputStream ResponseProcessor exception  for block blk_7310325538633196445_105957594java.net.SocketTimeoutException: 690\n00 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.100.50.253:54118 remote=/10.100.50.71:50010]\n        at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)\n        at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:155)\n        at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:128)\n        at java.io.DataInputStream.readFully(DataInputStream.java:178)\n        at java.io.DataInputStream.readLong(DataInputStream.java:399)\n        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$ResponseProcessor.run(DFSClient.java:2398)\n\n2009-10-23 02:08:52,659 WARN org.apache.hadoop.hdfs.DFSClient: Error Recovery for block blk_7310325538633196445_105957594 bad datanode[0] 10.100.50.71:50010\n2009-10-23 02:08:52,659 WARN org.apache.hadoop.hdfs.DFSClient: Error Recovery for block blk_7310325538633196445_105957594 in pipeline 10.100.50.71:50010, 10.100.50.61:50010, 10.100.50.28:\n50010: bad datanode 10.100.50.71:50010\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2009-10-23T14:23:18.305+0000","updated":"2009-10-23T14:23:18.305+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12438924/comment/12769611","id":"12769611","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sharadag","name":"sharadag","key":"sharadag","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sharad Agarwal","active":true,"timeZone":"Etc/UTC"},"body":"0.21 has a feature (MAPREDUCE-814) where completed job history logs from JT local disk are moved to HDFS in a separate thread. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sharadag","name":"sharadag","key":"sharadag","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sharad Agarwal","active":true,"timeZone":"Etc/UTC"},"created":"2009-10-24T07:59:15.187+0000","updated":"2009-10-24T07:59:15.187+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12438924/comment/12769686","id":"12769686","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"Is there any chance this could be voted into 0.20.2? It's causing pretty bad stability issues on one cluster.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2009-10-24T17:58:15.063+0000","updated":"2009-10-24T17:58:15.063+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12438924/comment/12769694","id":"12769694","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"Sharad: it actually looks like the code base this cluster is running already does include MAPREDUCE-814. I guess this means we potentially have a configuration issue where it's writing to HDFS to begin with rather than a local file before moving it. I'll circle back with more info when I have it.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2009-10-24T18:20:58.257+0000","updated":"2009-10-24T18:20:58.257+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12438924/comment/12769697","id":"12769697","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=acmurthy","name":"acmurthy","key":"acmurthy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun C Murthy","active":true,"timeZone":"America/Los_Angeles"},"body":"Already fixed in MAPREDUCE-816.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=acmurthy","name":"acmurthy","key":"acmurthy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun C Murthy","active":true,"timeZone":"America/Los_Angeles"},"created":"2009-10-24T18:40:05.813+0000","updated":"2009-10-24T18:40:05.813+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12438924/comment/12769698","id":"12769698","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"Upon further investigation, it's actually the user log history file (default hadoop.job.user.history.location value) that's blocked the JT. This does not appear to be fixed by MAPREDUCE-814, which was already applied on the cluster in question.\n\nIt seems to me that the actions on the user log directory should also be done in another thread to avoid the issue above. One cranky datanode can lock the jobtracker for hours at a time (the lack of timeouts seems to be a DFS bug)","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2009-10-24T18:44:30.985+0000","updated":"2009-10-24T18:44:30.985+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12438924/comment/12770383","id":"12770383","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sharadag","name":"sharadag","key":"sharadag","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sharad Agarwal","active":true,"timeZone":"Etc/UTC"},"body":"Since MAPREDUCE-814 adds the capability to have job logs in HDFS, there is not much utility in enabling the user logs. Users can directly access those from HDFS done folder location. Infact in 0.21, user log has been removed as part of job history format/API refactoring - MAPREDUCE-157","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sharadag","name":"sharadag","key":"sharadag","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sharad Agarwal","active":true,"timeZone":"Etc/UTC"},"created":"2009-10-27T05:06:02.840+0000","updated":"2009-10-27T05:06:02.840+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12438924/comment/12771080","id":"12771080","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"body":"Sharad: would you support a patch for branch-20 that puts user log writing in a separate thread? It's a shame that a DFS stall can lock up all of mapreduce.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tlipcon","name":"tlipcon","key":"tlipcon","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=tlipcon&avatarId=26804","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=tlipcon&avatarId=26804","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=tlipcon&avatarId=26804","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=tlipcon&avatarId=26804"},"displayName":"Todd Lipcon","active":true,"timeZone":"America/Tijuana"},"created":"2009-10-28T19:35:09.157+0000","updated":"2009-10-28T19:35:09.157+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12438924/comment/13474484","id":"13474484","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kkambatl","name":"kkambatl","key":"kkambatl","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Karthik Kambatla","active":false,"timeZone":"America/Los_Angeles"},"body":"In this particular case of moving history related files, the simplest approach seems to be to modify the behavior in job-history management. For instance, {{#moveToDone()}} can be executed asynchronously using a thread-pool; in fact, the method notifies JT of the completion when it is done moving files.\n\nShould more such situations arise, we can always use a thread-pool in JT for calls to external entities - DFS in this case, unless it needs to be blocking for correctness. We can cross that bridge when we get there. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kkambatl","name":"kkambatl","key":"kkambatl","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Karthik Kambatla","active":false,"timeZone":"America/Los_Angeles"},"created":"2012-10-11T20:27:49.127+0000","updated":"2012-10-11T20:27:49.127+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12438924/comment/13651182","id":"13651182","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=frsyuki","name":"frsyuki","key":"frsyuki","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sadayuki Furuhashi","active":true,"timeZone":"Etc/UTC"},"body":"I think I got the same (or similar) problem. A thread locks JobTracker instance in a synchronized block in JobTracker.submitJob method.\nHere are stacktraces at the moment: https://gist.github.com/frsyuki/b26904890f889c2bc0c0#file-jt-stacktrace-4-L299 (hadoop-2.0.0-mr1-cdh4.2.0)\nOther threads including jetty's HTTP handler threads and all org.apache.hadoop.ipc.Server$Handler threads are blocked.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=frsyuki","name":"frsyuki","key":"frsyuki","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sadayuki Furuhashi","active":true,"timeZone":"Etc/UTC"},"created":"2013-05-07T19:04:38.437+0000","updated":"2013-05-07T19:04:38.437+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12438924/comment/13867404","id":"13867404","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=zhaoyunjiong","name":"zhaoyunjiong","key":"zhaoyunjiong","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"yunjiong zhao","active":true,"timeZone":"America/Los_Angeles"},"body":"We have same problem too in our cluster.\nThis patch put JobHistory log to a queue first. So JobTracker won't hung due to DataNode.\nThe original TestJobHistory is enough, so I didn't add any new test case.\nJobHistory is already rewrite for trunk, no patch for trunk.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=zhaoyunjiong","name":"zhaoyunjiong","key":"zhaoyunjiong","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"yunjiong zhao","active":true,"timeZone":"America/Los_Angeles"},"created":"2014-01-10T01:39:07.309+0000","updated":"2014-01-10T01:39:07.309+0000"}],"maxResults":11,"total":11,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/MAPREDUCE-1144/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i08pv3:"}}