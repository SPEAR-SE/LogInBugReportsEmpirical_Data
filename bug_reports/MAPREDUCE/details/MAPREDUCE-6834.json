{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"13030147","self":"https://issues.apache.org/jira/rest/api/2/issue/13030147","key":"MAPREDUCE-6834","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310941","id":"12310941","key":"MAPREDUCE","name":"Hadoop Map/Reduce","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310941&avatarId=10096","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310941&avatarId=10096","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310941&avatarId=10096","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310941&avatarId=10096"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":"2017-01-23T20:50:56.033+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Fri Mar 17 17:11:37 UTC 2017","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/MAPREDUCE-6834/watchers","watchCount":8,"isWatching":false},"created":"2016-12-22T15:44:31.977+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/2","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/critical.svg","name":"Critical","id":"2"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"1.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12327586","id":"12327586","description":"2.7.0 release","name":"2.7.0","archived":false,"released":true,"releaseDate":"2015-04-20"}],"issuelinks":[{"id":"12495950","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12495950","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"12771100","key":"YARN-3112","self":"https://issues.apache.org/jira/rest/api/2/issue/12771100","fields":{"summary":"AM restart and keep containers from previous attempts, then new container launch failed","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=abalitsky1","name":"abalitsky1","key":"abalitsky1","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Aleksandr Balitsky","active":true,"timeZone":"Europe/Kiev"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2017-03-17T17:11:37.618+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12315340","id":"12315340","name":"resourcemanager"},{"self":"https://issues.apache.org/jira/rest/api/2/component/12331061","id":"12331061","name":"yarn"}],"timeoriginalestimate":null,"description":"*Steps to reproduce:*\n1) Submit MR application (for example PI app with 50 containers)\n2) Find MRAppMaster process id for the application \n3) Kill MRAppMaster by kill -9 command\n\n*Expected:* ResourceManager launch new MRAppMaster container and MRAppAttempt and application finish correctly\n\n*Actually:* After launching new MRAppMaster and MRAppAttempt the application fails with the following exception:\n\n{noformat}\n2016-12-22 23:17:53,929 ERROR [ContainerLauncher #9] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Container launch failed for container_1482408247195_0002_02_000011 : org.apache.hadoop.security.token.SecretManager$InvalidToken: No NMToken sent for node1:43037\n\tat org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:254)\n\tat org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)\n\tat org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:129)\n\tat org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl.getCMProxy(ContainerLauncherImpl.java:395)\n\tat org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl$Container.launch(ContainerLauncherImpl.java:138)\n\tat org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl$EventProcessor.run(ContainerLauncherImpl.java:361)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\n\n{noformat}\n\n*Problem*:\nWhen RMCommunicator sends \"registerApplicationMaster\" request to RM, RM generates NMTokens for new RMAppAttempt. Those new NMTokens are transmitted to RMCommunicator in RegisterApplicationMasterResponse  (getNMTokensFromPreviousAttempts method). But we don't handle these tokens in RMCommunicator.register method. RM don't transmit tese tokens again for other allocated requests, but we don't have these tokens in NMTokenCache. Accordingly we get \"No NMToken sent for node\" exception.\n\nI have found that this issue appears after changes from the https://github.com/apache/hadoop/commit/9b272ccae78918e7d756d84920a9322187d61eed \n\nI tried to do the same scenario without the commit and application completed successfully after RMAppMaster recovery\n","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12844416","id":"12844416","filename":"YARN-6019.001.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=abalitsky1","name":"abalitsky1","key":"abalitsky1","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Aleksandr Balitsky","active":true,"timeZone":"Europe/Kiev"},"created":"2016-12-22T16:01:30.816+0000","size":6620,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12844416/YARN-6019.001.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"MR application fails with \"No NMToken sent\" exception after MRAppMaster recovery","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=abalitsky1","name":"abalitsky1","key":"abalitsky1","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Aleksandr Balitsky","active":true,"timeZone":"Europe/Kiev"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=abalitsky1","name":"abalitsky1","key":"abalitsky1","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Aleksandr Balitsky","active":true,"timeZone":"Europe/Kiev"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":"Centos 7","customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/13030147/comment/15770392","id":"15770392","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=abalitsky1","name":"abalitsky1","key":"abalitsky1","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Aleksandr Balitsky","active":true,"timeZone":"Europe/Kiev"},"body":"I tried to save NMTokens and containers form previous attempt in RMCommunicator and checked the steps to reproduce again. Application finished successfully with no exceptions. Could somebody review my patch (001) ?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=abalitsky1","name":"abalitsky1","key":"abalitsky1","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Aleksandr Balitsky","active":true,"timeZone":"Europe/Kiev"},"created":"2016-12-22T16:06:48.674+0000","updated":"2016-12-22T16:06:48.674+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13030147/comment/15835189","id":"15835189","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jlowe","name":"jlowe","key":"jlowe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jason Lowe","active":true,"timeZone":"America/Chicago"},"body":"Thanks for the report and the patch!  I moved this to the MapReduce project since that covers the MRAppMaster and where the initial patch is targeted.\n\nIs this a scenario where somehow the MRAppMaster is asking to preserve containers across app attempts?  I ask because ApplicationMasterService normally does not call setNMTokensFromPreviousAttempts on RegisterApplicationMasterResponse unless getKeepContainersAcrossApplicationAttempts on the application submission context is true.  Last I checked the MapReduce client (YARNRunner) wasn't specifying that when the application is submitted to YARN.\n\nI agree this would be an issue if MapReduce supported preserving containers across application attempts.  We have MRAppMasters that are being restarted/recovered all the time in our clusters and have never seen this issue, but none of them are telling YARN to preserve containers across app attempts either.\n\nGeneral comments on the patch itself, assuming eventually it would be necessary once MRAppMaster supports container preservation:\n- setNMTokens is of questionable benefit since it's a trivial iteration over other public methods.  If kept it should just take a Collection as the parameter type.  It doesn't need to be a List.\n- why are we trying to schedule the previously assigned containers during serviceInit rather than serviceStart?  I would not expect the service to allocate/assign containers until started.\n- containersFromPreviousAttempt should be set to null after being passed to scheduling since the reference is no longer necessary beyond that point.  Otherwise that memory will persist for the duration of the MRAppMaster.\n- it would be great to have a regression unit test that exercises this scenario\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jlowe","name":"jlowe","key":"jlowe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jason Lowe","active":true,"timeZone":"America/Chicago"},"created":"2017-01-23T20:50:56.033+0000","updated":"2017-01-23T20:50:56.033+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13030147/comment/15876826","id":"15876826","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=haibochen","name":"haibochen","key":"haibochen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Haibo Chen","active":true,"timeZone":"America/Los_Angeles"},"body":"We have also seen issue very much similar to this. The MR AM was preempted, right after the second attempt was started, it got some container allocations from RM and then MR AM assigned them to tasks attempts. Eventually, the job failed due to too many \"No NMToken sent\" exceptions in launching containers.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=haibochen","name":"haibochen","key":"haibochen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Haibo Chen","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-02-21T22:03:19.038+0000","updated":"2017-02-21T22:03:19.038+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13030147/comment/15876843","id":"15876843","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=haibochen","name":"haibochen","key":"haibochen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Haibo Chen","active":true,"timeZone":"America/Los_Angeles"},"body":"Tracing the code in MR, it looks like MR just uses whatever NM tokens are contained in the allocation response from RM to launch containers with NMs.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=haibochen","name":"haibochen","key":"haibochen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Haibo Chen","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-02-21T22:14:28.212+0000","updated":"2017-02-21T22:14:28.212+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13030147/comment/15878300","id":"15878300","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jlowe","name":"jlowe","key":"jlowe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jason Lowe","active":true,"timeZone":"America/Chicago"},"body":"bq. The MR AM was preempted, right after the second attempt was started, it got some container allocations from RM and then MR AM assigned them to tasks attempts. Eventually, the job failed due to too many \"No NMToken sent\" exceptions in launching containers.\n\nAssuming there weren't changes to have MapReduce start trying to preserve containers across app attempts, I don't see how this can be a MapReduce issue.  It is the RM's responsibility to ensure corresponding NM tokens are conveyed for each allocation returned, so the RM seems to be the one messing up here.  I noticed it is the scheduler's responsibility to return the NM tokens in the Allocation, maybe this is something specific to fairscheduler?  That would explain why we've never seen something like this, since we're not running that scheduler.  However I thought the handling of the NM tokens for allocations was essentially the same between the schedulers.\n\nThis patch relies on the registration response specifying containers that were preserved from the old attempt.  Unless I'm missing something, the RM only fills out this registration response field if the app specifies it is preserving containers, and I do not believe the MapReduce app framework ever does that.  Therefore even if you guys are seeing a similar issue, unless MapReduce asks to preserve containers across attempts I don't see how this patch will address that problem.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jlowe","name":"jlowe","key":"jlowe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jason Lowe","active":true,"timeZone":"America/Chicago"},"created":"2017-02-22T14:26:17.553+0000","updated":"2017-02-22T14:26:17.553+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13030147/comment/15878710","id":"15878710","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=haibochen","name":"haibochen","key":"haibochen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Haibo Chen","active":true,"timeZone":"America/Los_Angeles"},"body":"bq.  the RM only fills out this registration response field if the app specifies it is preserving containers, and I do not believe the MapReduce app framework ever does that.Therefore even if you guys are seeing a similar issue, unless MapReduce asks to preserve containers across attempts I don't see how this patch will address that problem.\nAgreed. My intension was more to report another instance. We should probably move this jira to YARN for scheduler folks to look at? \n\nbq. However I thought the handling of the NM tokens for allocations was essentially the same between the schedulers.\nYeah, it looks like both schedulers use the common code to handle this. [~abalitsky1], which scheduler were you running?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=haibochen","name":"haibochen","key":"haibochen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Haibo Chen","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-02-22T16:53:44.870+0000","updated":"2017-02-22T16:53:44.870+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13030147/comment/15888952","id":"15888952","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=haibochen","name":"haibochen","key":"haibochen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Haibo Chen","active":true,"timeZone":"America/Los_Angeles"},"body":"Looks like very much like the same problem at https://issues.apache.org/jira/browse/YARN-3112","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=haibochen","name":"haibochen","key":"haibochen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Haibo Chen","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-02-28T22:09:14.101+0000","updated":"2017-02-28T22:09:14.101+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13030147/comment/15890310","id":"15890310","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jlowe","name":"jlowe","key":"jlowe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jason Lowe","active":true,"timeZone":"America/Chicago"},"body":"Yes, which is why I've been asking all along if this is a case where MapReduce has been modified to preserve containers across AM attempts.  If that is indeed the case then this is essentially a bug report against an internal patch that is not part of Apache Hadoop.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jlowe","name":"jlowe","key":"jlowe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jason Lowe","active":true,"timeZone":"America/Chicago"},"created":"2017-03-01T14:54:24.015+0000","updated":"2017-03-01T14:54:24.015+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13030147/comment/15891327","id":"15891327","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=haibochen","name":"haibochen","key":"haibochen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Haibo Chen","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks for the clarification, [~jlowe]. We have not made changes to preserve containers in MR. Chasing the code in more details, I came to a similar conclusion as https://issues.apache.org/jira/browse/YARN-3112?focusedCommentId=14299003&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14299003   MR relies on YARN RM to get the NMtokens needed to launch containers with NMs. Given the code today, it is possible that a null NMToken is sent to MR, which contracts with the javadoc in SchedulerApplicationAttempt.java here\n{code:java}\n  // Create container token and NMToken altogether, if either of them fails for\n  // some reason like DNS unavailable, do not return this container and keep it\n  // in the newlyAllocatedContainers waiting to be refetched.\n  public synchronized ContainersAndNMTokensAllocation {...}\n{code}\nThis could be a duplicate of YARN-3112.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=haibochen","name":"haibochen","key":"haibochen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Haibo Chen","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-03-01T23:52:09.485+0000","updated":"2017-03-01T23:55:13.507+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13030147/comment/15892400","id":"15892400","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=abalitsky1","name":"abalitsky1","key":"abalitsky1","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Aleksandr Balitsky","active":true,"timeZone":"Europe/Kiev"},"body":"Hi [~haibochen], [~jlowe]\nSorry for late reply. \n\n{quote}\nIs this a scenario where somehow the MRAppMaster is asking to preserve containers across app attempts? I ask because ApplicationMasterService normally does not call setNMTokensFromPreviousAttempts on RegisterApplicationMasterResponse unless getKeepContainersAcrossApplicationAttempts on the application submission context is true. Last I checked the MapReduce client (YARNRunner) wasn't specifying that when the application is submitted to YARN.\n{quote}\n\nActually you are right. I did not consider that MR doesn't support AM work-preserving restart and currently I see that my first patch isn't good solution for this problem. Thanks for the review!\n\n{quote}\nAleksandr Balitsky, which scheduler were you running?\n{quote}\n\nI'm running Fair Scheduler. I don't think that this issue depends on a scheduler, but I will check it with another schedulers. \n\n{quote}\nWe have not made changes to preserve containers in MR. Chasing the code in more details, I came to a similar conclusion as https://issues.apache.org/jira/browse/YARN-3112?focusedCommentId=14299003&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14299003 MR relies on YARN RM to get the NMtokens needed to launch containers with NMs. Given the code today, it is possible that a null NMToken is sent to MR, which contracts with the javadoc in SchedulerApplicationAttempt.java here\n{quote}\n\nI totally agree with you that we have not made changes to preserve containers in MR. But the solution that you mentioned contradicts YARN design:\n{quote}\nAs for network optimization, NMTokens are not sent to the ApplicationMasters for each and every allocated container, but only for the first time or if NMTokens have to be invalidated due to the rollover of the underlying master key\n{quote}\n\nThat's so true, it is possible that a null NMToken is sent to MR. NMTokens sends only after first creation, it's designed feature. Then it saves to NMTokenCache from AM side. It's not necessary to pass NM tokens during each allocation interaction. So, it's not the best decision to clear NMTokenSecretManager cache during each allocation, because it disables \"cache\" feature and new NM Tokens will be generated (instead of using instance from cache) during each allocation response. IMHO, we shouldn't do this, because it's not the fix for root cause. It looks like workaround. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=abalitsky1","name":"abalitsky1","key":"abalitsky1","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Aleksandr Balitsky","active":true,"timeZone":"Europe/Kiev"},"created":"2017-03-02T15:18:41.704+0000","updated":"2017-03-02T15:27:56.164+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13030147/comment/15892407","id":"15892407","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jlowe","name":"jlowe","key":"jlowe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jason Lowe","active":true,"timeZone":"America/Chicago"},"body":"Based the patch which claims to fix the problem, I would argue it is not a duplicate.  The patch is all about transferring containers from the previous attempt in the registration response, but that is not filled in unless the application was submitted with preservation of containers across application attempts.  MapReduce does not do this, therefore I don't see how this patch helps the problem unless MapReduce was patched to do so.  I agree the symptom is similar to YARN-3112, but I doubt a fix for YARN-3112 will address [~abalitsky1]'s issue if the original patch in this JIRA also corrected it.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jlowe","name":"jlowe","key":"jlowe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jason Lowe","active":true,"timeZone":"America/Chicago"},"created":"2017-03-02T15:22:33.871+0000","updated":"2017-03-02T15:22:33.871+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13030147/comment/15892416","id":"15892416","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jlowe","name":"jlowe","key":"jlowe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jason Lowe","active":true,"timeZone":"America/Chicago"},"body":"Ah, comment race!  ;-)\n\n[~abalitsky1] so if I understand correctly, you're saying that the patch in this JIRA does _not_ fix the issue?  I'm trying to resolve that with [this comment|https://issues.apache.org/jira/browse/MAPREDUCE-6834?focusedCommentId=15770392&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-15770392].  If you agree that the patch here isn't appropriate, then I agree we should just duplicate this to YARN-3112.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jlowe","name":"jlowe","key":"jlowe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jason Lowe","active":true,"timeZone":"America/Chicago"},"created":"2017-03-02T15:28:49.697+0000","updated":"2017-03-02T15:28:49.697+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13030147/comment/15892442","id":"15892442","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=abalitsky1","name":"abalitsky1","key":"abalitsky1","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Aleksandr Balitsky","active":true,"timeZone":"Europe/Kiev"},"body":"[~jlowe], yep, 001 patch isn't good from design point of view. \nI'm going to investigate the code again to find the root cause. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=abalitsky1","name":"abalitsky1","key":"abalitsky1","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Aleksandr Balitsky","active":true,"timeZone":"Europe/Kiev"},"created":"2017-03-02T15:49:39.378+0000","updated":"2017-03-02T15:49:39.378+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13030147/comment/15892455","id":"15892455","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=abalitsky1","name":"abalitsky1","key":"abalitsky1","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Aleksandr Balitsky","active":true,"timeZone":"Europe/Kiev"},"body":"[~jlowe], I'm not sure that YARN-3112 the same issue that I reported. \n\nFrom YARN-3112 description:\n{code}\nNew AM has inherited the old tokens from previous AM according to my configuration (keepContainers=true), so the token for new containers are replaced by the old one in the NMTokenCache.\n{code}\n\nI have not used \"keep-containers-across-application-attempts\" feature, and I definitely didn't faced with problem when the token for new containers are replaced by the old one in the NMTokenCache (my debug can confirm it), because AM was restarted and all old tokens was removed. \n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=abalitsky1","name":"abalitsky1","key":"abalitsky1","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Aleksandr Balitsky","active":true,"timeZone":"Europe/Kiev"},"created":"2017-03-02T15:59:07.637+0000","updated":"2017-03-02T15:59:58.649+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13030147/comment/15892631","id":"15892631","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=haibochen","name":"haibochen","key":"haibochen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Haibo Chen","active":true,"timeZone":"America/Los_Angeles"},"body":"bq. IMHO, we shouldn't do this, because it's not the fix for root cause. It looks like workaround\nSorry for the confusion. I should have been more specific, I meant to say that the root cause analysis looks correct to me. I agree with you that we should not follow the proposed fix there.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=haibochen","name":"haibochen","key":"haibochen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Haibo Chen","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-03-02T17:15:15.237+0000","updated":"2017-03-02T17:15:15.237+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13030147/comment/15894205","id":"15894205","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=abalitsky1","name":"abalitsky1","key":"abalitsky1","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Aleksandr Balitsky","active":true,"timeZone":"Europe/Kiev"},"body":"After deeper investigation I have found the root cause:\nhttps://github.com/apache/hadoop/blob/branch-2.7.0/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ApplicationMasterService.java#L299-L327\n\nMentioned code should be executed only when \"work-preserving AM restart\" is true. Resource Manager saves new NMTokens into NMTokenSecretManagerInRM and sends this tokens only once with AM register response. But MR's AM doesn't handle those tokens, because it doesn't support work-preserving AM restart. Obviously, RM will no longer send those tokens again during next allocation requests.\n\nWhen I use MR job (or another kind of frameworks, that doesn't support work-preserving AM restart), RM shouldn't retrieve previous attempt's containers and corresponding NM tokens. \n\nBut as far as I see, this problem has bean already fixed in scope of YARN-3136. So 2.8.0 and next versions don't have this issue. \n\nhttps://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ApplicationMasterService.java#L272-L273\n\n[~haibochen], [~jlowe], thank you guys for the help and review. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=abalitsky1","name":"abalitsky1","key":"abalitsky1","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Aleksandr Balitsky","active":true,"timeZone":"Europe/Kiev"},"created":"2017-03-03T11:55:12.624+0000","updated":"2017-03-03T12:03:47.175+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13030147/comment/15894844","id":"15894844","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=haibochen","name":"haibochen","key":"haibochen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Haibo Chen","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks [~abalitsky1] for your detailed analysis! Agree with the root cause your identified. We have not seen the issue either in branches that contain YARN-3136. Do you think this is the same issue as in YARN-3112? If so, we should probably link our discussion here and close it.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=haibochen","name":"haibochen","key":"haibochen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Haibo Chen","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-03-03T18:52:59.108+0000","updated":"2017-03-03T18:52:59.108+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13030147/comment/15930259","id":"15930259","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=abalitsky1","name":"abalitsky1","key":"abalitsky1","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Aleksandr Balitsky","active":true,"timeZone":"Europe/Kiev"},"body":"[~haibochen], I think that this issue not the same as in YARN-3112.\n\nFrom YARN-3112 description:\n{noformat}\nNew AM has inherited the old tokens from previous AM according to my configuration (keepContainers=true), so the token for new containers are replaced by the old one in the NMTokenCache.\n{noformat}\n\nI have not used \"keep-containers-across-application-attempts\" feature, and I definitely didn't faced with problem when the token for new containers are replaced by the old one in the NMTokenCache (my debug can confirm it), because AM was restarted and all old tokens was removed.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=abalitsky1","name":"abalitsky1","key":"abalitsky1","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Aleksandr Balitsky","active":true,"timeZone":"Europe/Kiev"},"created":"2017-03-17T16:32:55.376+0000","updated":"2017-03-17T16:32:55.376+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13030147/comment/15930314","id":"15930314","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=haibochen","name":"haibochen","key":"haibochen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Haibo Chen","active":true,"timeZone":"America/Los_Angeles"},"body":"The posted stacktrace and affect version (2.6.0) in YARN-3113 makes me think the version was an apache release that does not include MR's support of keep-container-across-application-attempts (thus, the analysis there may be incorrect, I think). Anyway, we cannot say for sure. Let's keep it open and do not link it as a duplicate then.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=haibochen","name":"haibochen","key":"haibochen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Haibo Chen","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-03-17T17:11:37.618+0000","updated":"2017-03-17T17:11:37.618+0000"}],"maxResults":19,"total":19,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/MAPREDUCE-6834/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i37xzb:"}}