{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12953179","self":"https://issues.apache.org/jira/rest/api/2/issue/12953179","key":"MAPREDUCE-6659","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310941","id":"12310941","key":"MAPREDUCE","name":"Hadoop Map/Reduce","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310941&avatarId=10096","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310941&avatarId=10096","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310941&avatarId=10096","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310941&avatarId=10096"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":"2017-09-04T14:01:59.112+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Wed Nov 08 15:05:21 UTC 2017","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/MAPREDUCE-6659/watchers","watchCount":8,"isWatching":false},"created":"2016-03-24T12:01:08.052+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12327180","id":"12327180","description":"2.6.0 release","name":"2.6.0","archived":false,"released":true,"releaseDate":"2014-11-18"}],"issuelinks":[{"id":"12517417","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12517417","type":{"id":"12310000","name":"Duplicate","inward":"is duplicated by","outward":"duplicates","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/12310000"},"inwardIssue":{"id":"13109216","key":"MAPREDUCE-6982","self":"https://issues.apache.org/jira/rest/api/2/issue/13109216","fields":{"summary":"Containers on lost nodes are considered failed after a too long time.","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/4","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/minor.svg","name":"Minor","id":"4"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12461762","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12461762","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"12838048","key":"YARN-3809","self":"https://issues.apache.org/jira/rest/api/2/issue/12838048","fields":{"summary":"Failed to launch new attempts because ApplicationMasterLauncher's threads all hang","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=nfraison.criteo","name":"nfraison.criteo","key":"nfraison.criteo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Nicolas Fraison","active":true,"timeZone":"Etc/UTC"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2017-11-08T15:05:21.829+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12315342","id":"12315342","name":"mr-am"}],"timeoriginalestimate":null,"description":"MR Application master waits for very long time to cleanup and relaunch the tasks on lost nodes. Wait time is actually 2.5 hours (ipc.client.connect.max.retries * ipc.client.connect.max.retries.on.timeouts * ipc.client.connect.timeout = 10 * 45 * 20 = 9000 seconds = 2.5 hours)\n\nSome similar issue related in RM-AM rpc protocol is fixed in YARN-3809.\nAs fixed in YARN-3809, we may need to introduce new configurations to control this RPC retry behavior.\n\nAlso, I feel this total retry time should honor and capped maximum to global task time out (mapreduce.task.timeout = 600000 default)","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"Mapreduce App master waits long to kill containers on lost nodes.","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lakshman","name":"lakshman","key":"lakshman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Laxman","active":true,"timeZone":"Asia/Kolkata"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lakshman","name":"lakshman","key":"lakshman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Laxman","active":true,"timeZone":"Asia/Kolkata"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12953179/comment/15210196","id":"15210196","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lakshman","name":"lakshman","key":"lakshman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Laxman","active":true,"timeZone":"Asia/Kolkata"},"body":"Please note that this issue happens with lost nodes (i.e, Unreachable hosts). NM crash with a reachable host is exhibiting a totally a different expected retry behavior. There liveness configurations are coming into play (yarn.resourcemanager.container.liveness-monitor.interval-ms, yarn.nm.liveness-monitor.expiry-interval-ms, yarn.am.liveness-monitor.expiry-interval-ms) as expected.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=lakshman","name":"lakshman","key":"lakshman","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Laxman","active":true,"timeZone":"Asia/Kolkata"},"created":"2016-03-24T13:19:54.807+0000","updated":"2016-03-24T13:19:54.807+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12953179/comment/16152640","id":"16152640","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=nfraison.criteo","name":"nfraison.criteo","key":"nfraison.criteo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Nicolas Fraison","active":true,"timeZone":"Etc/UTC"},"body":"We have developed a patch that should help on this issue by managing NodeManager lost events on AM as described below:\n* on nodemanager service unavailibility (crash, oom ...):\n\t\tWhen receiving lost NodeManager events, it failed the impacted attempt and do not go through the cleanup stage.\n\n* on nodemanager server unavailibility with default settings AM detect first that the attempt is in timeout and try to cleanup the attempt:\n\t\tWhen receiving lost NodeManager events, it stop the cleanup process on the impacted container and failed the attempt.\n\nThis reduce the duration of the timeout to the timeout for detecting a down NodeManager.\nCould you please provide me rights to attached the patch in this request?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=nfraison.criteo","name":"nfraison.criteo","key":"nfraison.criteo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Nicolas Fraison","active":true,"timeZone":"Etc/UTC"},"created":"2017-09-04T14:01:59.112+0000","updated":"2017-09-04T14:01:59.112+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12953179/comment/16162870","id":"16162870","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=nfraison.criteo","name":"nfraison.criteo","key":"nfraison.criteo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Nicolas Fraison","active":true,"timeZone":"Etc/UTC"},"body":"Do I have to create another request to provide this potential patch?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=nfraison.criteo","name":"nfraison.criteo","key":"nfraison.criteo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Nicolas Fraison","active":true,"timeZone":"Etc/UTC"},"created":"2017-09-12T12:38:57.239+0000","updated":"2017-09-12T12:38:57.239+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12953179/comment/16203553","id":"16203553","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jlowe","name":"jlowe","key":"jlowe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jason Lowe","active":true,"timeZone":"America/Chicago"},"body":"This has been sitting idle, so I'm assigning this to Nicolas to help move this forward.\r\n\r\nI'm wondering if this is an issue in 2.8 or later.  I would expect the RM to send completed container events along with the lost node event.  After MAPREDUCE-5465 the AM does not attempt to kill containers that have been marked by the RM as already completed.  Seems like porting that portion of the state machine change from MAPREDUCE-5465 would be another viable alternative.\r\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jlowe","name":"jlowe","key":"jlowe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jason Lowe","active":true,"timeZone":"America/Chicago"},"created":"2017-10-13T13:19:03.093+0000","updated":"2017-10-13T13:19:03.093+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12953179/comment/16243637","id":"16243637","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=nfraison.criteo","name":"nfraison.criteo","key":"nfraison.criteo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Nicolas Fraison","active":true,"timeZone":"Etc/UTC"},"body":"[~jlowe], MAPREDUCE-5465 is already applied on the hadoop release I use (cdh5.5.0).\r\nI've tested on cdh5.5 and trunk the behaviour when a nodemanager is lost and it is the same. \r\nThe RM send a LostNM event to the AM which try to cleanup containers running on it (on cdh5.5 and on trunk). The attempt is failed only after a timeout to connect to the lost NM.\r\nThe main difference between cdh5.5 and the trunk is the timeout being really slower in trunk (3 min instead of 30 min at least).\r\nThis is thanks to patches YARN-4414 and YARN-3554\r\nBackporting those patches can be consider sufficient, what do you think about this?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=nfraison.criteo","name":"nfraison.criteo","key":"nfraison.criteo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Nicolas Fraison","active":true,"timeZone":"Etc/UTC"},"created":"2017-11-08T09:58:38.695+0000","updated":"2017-11-08T09:58:54.573+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12953179/comment/16243990","id":"16243990","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jlowe","name":"jlowe","key":"jlowe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jason Lowe","active":true,"timeZone":"America/Chicago"},"body":"Ah, looks like this would have \"just worked\" if the AM had not tried to process the NM lost event.  The RM probably also sent container completed events for these containers due to the lost NM, but the AM is trying anyway to kill the containers.  Wondering if MAPREDUCE-6119 would help here (assuming AM is configured to ignore node events).\r\n\r\nbq. The main difference between cdh5.5 and the trunk is the timeout being really slower in trunk (3 min instead of 30 min at least). This is thanks to patches YARN-4414 and YARN-3554 Backporting those patches can be consider sufficient, what do you think about this?\r\n\r\nDid you mean to say \"slower than trunk\" rather than \"slower in trunk\"?   Sure, if the AM spends a lot less time trying to kill the containers it will never be able to kill then that also mitigates the issue.  Not as efficient as not trying in the first place, but yes, I can see lowering the NM client retries/timeouts as a viable approach.\r\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jlowe","name":"jlowe","key":"jlowe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jason Lowe","active":true,"timeZone":"America/Chicago"},"created":"2017-11-08T14:08:12.481+0000","updated":"2017-11-08T14:08:31.118+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12953179/comment/16244108","id":"16244108","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=nfraison.criteo","name":"nfraison.criteo","key":"nfraison.criteo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Nicolas Fraison","active":true,"timeZone":"Etc/UTC"},"body":"I mean that cleanup timeout after at least 30 min in cdh5.5 and only after 3 min in trunk.\r\nI will double check if there is in fact some container completed events send by RM and then check the behaviour if we apply MAPREDUCE-6119  to ignore the Lost NM events.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=nfraison.criteo","name":"nfraison.criteo","key":"nfraison.criteo","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Nicolas Fraison","active":true,"timeZone":"Etc/UTC"},"created":"2017-11-08T15:05:21.829+0000","updated":"2017-11-08T15:05:21.829+0000"}],"maxResults":7,"total":7,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/MAPREDUCE-6659/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i2v5iv:"}}