{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"13037344","self":"https://issues.apache.org/jira/rest/api/2/issue/13037344","key":"MAPREDUCE-6835","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310941","id":"12310941","key":"MAPREDUCE","name":"Hadoop Map/Reduce","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310941&avatarId=10096","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310941&avatarId=10096","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310941&avatarId=10096","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310941&avatarId=10096"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":"2017-04-11T11:38:58.565+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Tue Apr 11 11:38:58 UTC 2017","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/MAPREDUCE-6835/watchers","watchCount":3,"isWatching":false},"created":"2017-01-24T12:15:09.960+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":"EBADF; MapReduce; BadFileDescriptor","customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12334007","id":"12334007","description":"2.7.3 release","name":"2.7.3","archived":false,"released":true,"releaseDate":"2016-08-25"}],"issuelinks":[{"id":"12499361","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12499361","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"12909199","key":"YARN-4322","self":"https://issues.apache.org/jira/rest/api/2/issue/12909199","fields":{"summary":"local framwork + io.ReadaheadPool is throwing Failed readahead on ifile EBADF: Bad file descriptor","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}}],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2017-04-11T11:38:58.565+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"components":[],"timeoriginalestimate":null,"description":"Whenever a MapReduce job is executed, the warning of Bad file desciptor is displayed. This mostly happens when the Combiner/Reducer is running.\nThis bug is resulting in incorrect results for the reducers where the warning is shown.\n\nThe following is the entire job execution log.\n17/01/24 14:34:25 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id\n17/01/24 14:34:25 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=\n17/01/24 14:34:25 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.\n17/01/24 14:34:26 INFO input.FileInputFormat: Total input paths to process : 1\n17/01/24 14:34:26 INFO mapreduce.JobSubmitter: number of splits:5\n17/01/24 14:34:26 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1576831426_0001\n17/01/24 14:34:26 INFO mapreduce.Job: The url to track the job: http://localhost:8080/\n17/01/24 14:34:26 INFO mapreduce.Job: Running job: job_local1576831426_0001\n17/01/24 14:34:26 INFO mapred.LocalJobRunner: OutputCommitter set in config null\n17/01/24 14:34:26 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n17/01/24 14:34:26 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter\n17/01/24 14:34:26 INFO mapred.LocalJobRunner: Waiting for map tasks\n17/01/24 14:34:26 INFO mapred.LocalJobRunner: Starting task: attempt_local1576831426_0001_m_000000_0\n17/01/24 14:34:27 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n17/01/24 14:34:27 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n17/01/24 14:34:27 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/user/krishna/flightinfo/input/2000.csv:0+134217728\n17/01/24 14:34:27 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n17/01/24 14:34:27 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n17/01/24 14:34:27 INFO mapred.MapTask: soft limit at 83886080\n17/01/24 14:34:27 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n17/01/24 14:34:27 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n17/01/24 14:34:27 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n17/01/24 14:34:27 INFO mapreduce.Job: Job job_local1576831426_0001 running in uber mode : false\n17/01/24 14:34:27 INFO mapreduce.Job:  map 0% reduce 0%\n17/01/24 14:34:33 INFO mapred.LocalJobRunner: map > map\n17/01/24 14:34:33 INFO mapreduce.Job:  map 9% reduce 0%\n17/01/24 14:34:35 INFO mapred.LocalJobRunner: map > map\n17/01/24 14:34:35 INFO mapred.MapTask: Starting flush of map output\n17/01/24 14:34:35 INFO mapred.MapTask: Spilling map output\n17/01/24 14:34:35 INFO mapred.MapTask: bufstart = 0; bufend = 17437459; bufvoid = 104857600\n17/01/24 14:34:35 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 20849028(83396112); length = 5365369/6553600\n17/01/24 14:34:35 INFO mapred.MapTask: Finished spill 0\n17/01/24 14:34:35 INFO mapred.Task: Task:attempt_local1576831426_0001_m_000000_0 is done. And is in the process of committing\n17/01/24 14:34:35 INFO mapred.LocalJobRunner: map\n17/01/24 14:34:35 INFO mapred.Task: Task 'attempt_local1576831426_0001_m_000000_0' done.\n17/01/24 14:34:35 INFO mapred.LocalJobRunner: Finishing task: attempt_local1576831426_0001_m_000000_0\n17/01/24 14:34:35 INFO mapred.LocalJobRunner: Starting task: attempt_local1576831426_0001_m_000001_0\n17/01/24 14:34:35 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n17/01/24 14:34:35 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n17/01/24 14:34:35 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/user/krishna/flightinfo/input/2000.csv:134217728+134217728\n17/01/24 14:34:36 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n17/01/24 14:34:36 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n17/01/24 14:34:36 INFO mapred.MapTask: soft limit at 83886080\n17/01/24 14:34:36 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n17/01/24 14:34:36 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n17/01/24 14:34:36 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n17/01/24 14:34:36 INFO mapreduce.Job:  map 100% reduce 0%\n17/01/24 14:34:41 INFO mapred.LocalJobRunner: map > map\n17/01/24 14:34:42 INFO mapred.LocalJobRunner: map > map\n17/01/24 14:34:42 INFO mapred.MapTask: Starting flush of map output\n17/01/24 14:34:42 INFO mapred.MapTask: Spilling map output\n17/01/24 14:34:42 INFO mapred.MapTask: bufstart = 0; bufend = 17438733; bufvoid = 104857600\n17/01/24 14:34:42 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 20848636(83394544); length = 5365761/6553600\n17/01/24 14:34:42 INFO mapreduce.Job:  map 32% reduce 0%\n17/01/24 14:34:42 INFO mapred.MapTask: Finished spill 0\n17/01/24 14:34:42 INFO mapred.Task: Task:attempt_local1576831426_0001_m_000001_0 is done. And is in the process of committing\n17/01/24 14:34:42 INFO mapred.LocalJobRunner: map\n17/01/24 14:34:42 INFO mapred.Task: Task 'attempt_local1576831426_0001_m_000001_0' done.\n17/01/24 14:34:42 INFO mapred.LocalJobRunner: Finishing task: attempt_local1576831426_0001_m_000001_0\n17/01/24 14:34:42 INFO mapred.LocalJobRunner: Starting task: attempt_local1576831426_0001_m_000002_0\n17/01/24 14:34:42 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n17/01/24 14:34:42 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n17/01/24 14:34:42 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/user/krishna/flightinfo/input/2000.csv:268435456+134217728\n17/01/24 14:34:43 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n17/01/24 14:34:43 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n17/01/24 14:34:43 INFO mapred.MapTask: soft limit at 83886080\n17/01/24 14:34:43 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n17/01/24 14:34:43 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n17/01/24 14:34:43 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n17/01/24 14:34:44 INFO mapreduce.Job:  map 100% reduce 0%\n17/01/24 14:34:48 INFO mapred.LocalJobRunner: map > map\n17/01/24 14:34:49 INFO mapreduce.Job:  map 52% reduce 0%\n17/01/24 14:34:49 INFO mapred.LocalJobRunner: map > map\n17/01/24 14:34:49 INFO mapred.MapTask: Starting flush of map output\n17/01/24 14:34:49 INFO mapred.MapTask: Spilling map output\n17/01/24 14:34:49 INFO mapred.MapTask: bufstart = 0; bufend = 17438941; bufvoid = 104857600\n17/01/24 14:34:49 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 20848572(83394288); length = 5365825/6553600\n17/01/24 14:34:50 INFO mapred.MapTask: Finished spill 0\n17/01/24 14:34:50 INFO mapred.Task: Task:attempt_local1576831426_0001_m_000002_0 is done. And is in the process of committing\n17/01/24 14:34:50 INFO mapred.LocalJobRunner: map\n17/01/24 14:34:50 INFO mapred.Task: Task 'attempt_local1576831426_0001_m_000002_0' done.\n17/01/24 14:34:50 INFO mapred.LocalJobRunner: Finishing task: attempt_local1576831426_0001_m_000002_0\n17/01/24 14:34:50 INFO mapred.LocalJobRunner: Starting task: attempt_local1576831426_0001_m_000003_0\n17/01/24 14:34:50 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n17/01/24 14:34:50 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n17/01/24 14:34:50 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/user/krishna/flightinfo/input/2000.csv:402653184+134217728\n17/01/24 14:34:50 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n17/01/24 14:34:50 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n17/01/24 14:34:50 INFO mapred.MapTask: soft limit at 83886080\n17/01/24 14:34:50 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n17/01/24 14:34:50 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n17/01/24 14:34:50 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n17/01/24 14:34:51 INFO mapreduce.Job:  map 100% reduce 0%\n17/01/24 14:34:56 INFO mapred.LocalJobRunner: \n17/01/24 14:34:56 INFO mapred.MapTask: Starting flush of map output\n17/01/24 14:34:56 INFO mapred.MapTask: Spilling map output\n17/01/24 14:34:56 INFO mapred.MapTask: bufstart = 0; bufend = 17284761; bufvoid = 104857600\n17/01/24 14:34:56 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 20896012(83584048); length = 5318385/6553600\n17/01/24 14:34:56 INFO mapred.LocalJobRunner: map > sort\n17/01/24 14:34:56 INFO mapred.MapTask: Finished spill 0\n17/01/24 14:34:56 INFO mapred.Task: Task:attempt_local1576831426_0001_m_000003_0 is done. And is in the process of committing\n17/01/24 14:34:56 INFO mapred.LocalJobRunner: map\n17/01/24 14:34:56 INFO mapred.Task: Task 'attempt_local1576831426_0001_m_000003_0' done.\n17/01/24 14:34:56 INFO mapred.LocalJobRunner: Finishing task: attempt_local1576831426_0001_m_000003_0\n17/01/24 14:34:56 INFO mapred.LocalJobRunner: Starting task: attempt_local1576831426_0001_m_000004_0\n17/01/24 14:34:56 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n17/01/24 14:34:56 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n17/01/24 14:34:56 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/user/krishna/flightinfo/input/2000.csv:536870912+33280701\n17/01/24 14:34:56 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n17/01/24 14:34:56 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n17/01/24 14:34:56 INFO mapred.MapTask: soft limit at 83886080\n17/01/24 14:34:56 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n17/01/24 14:34:56 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n17/01/24 14:34:56 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n17/01/24 14:34:58 INFO mapred.LocalJobRunner: \n17/01/24 14:34:58 INFO mapred.MapTask: Starting flush of map output\n17/01/24 14:34:58 INFO mapred.MapTask: Spilling map output\n17/01/24 14:34:58 INFO mapred.MapTask: bufstart = 0; bufend = 4279717; bufvoid = 104857600\n17/01/24 14:34:58 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 24897564(99590256); length = 1316833/6553600\n17/01/24 14:34:59 INFO mapred.MapTask: Finished spill 0\n17/01/24 14:34:59 INFO mapred.Task: Task:attempt_local1576831426_0001_m_000004_0 is done. And is in the process of committing\n17/01/24 14:34:59 INFO mapred.LocalJobRunner: map\n17/01/24 14:34:59 INFO mapred.Task: Task 'attempt_local1576831426_0001_m_000004_0' done.\n17/01/24 14:34:59 INFO mapred.LocalJobRunner: Finishing task: attempt_local1576831426_0001_m_000004_0\n17/01/24 14:34:59 INFO mapred.LocalJobRunner: map task executor complete.\n17/01/24 14:34:59 INFO mapred.LocalJobRunner: Waiting for reduce tasks\n17/01/24 14:34:59 INFO mapred.LocalJobRunner: Starting task: attempt_local1576831426_0001_r_000000_0\n17/01/24 14:34:59 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n17/01/24 14:34:59 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n17/01/24 14:34:59 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@55bf46b\n17/01/24 14:34:59 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=334338464, maxSingleShuffleLimit=83584616, mergeThreshold=220663392, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n17/01/24 14:34:59 INFO reduce.EventFetcher: attempt_local1576831426_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n17/01/24 14:34:59 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1576831426_0001_m_000003_0 decomp: 17 len: 21 to MEMORY\n17/01/24 14:34:59 INFO reduce.InMemoryMapOutput: Read 17 bytes from map-output for attempt_local1576831426_0001_m_000003_0\n17/01/24 14:34:59 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 17, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->17\n17/01/24 14:34:59 WARN io.ReadaheadPool: Failed readahead on ifile\nEBADF: Bad file descriptor\n\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\n\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\n\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\n\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:206)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n17/01/24 14:34:59 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1576831426_0001_m_000002_0 decomp: 17 len: 21 to MEMORY\n17/01/24 14:34:59 INFO reduce.InMemoryMapOutput: Read 17 bytes from map-output for attempt_local1576831426_0001_m_000002_0\n17/01/24 14:34:59 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 17, inMemoryMapOutputs.size() -> 2, commitMemory -> 17, usedMemory ->34\n17/01/24 14:34:59 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1576831426_0001_m_000001_0 decomp: 17 len: 21 to MEMORY\n17/01/24 14:34:59 WARN io.ReadaheadPool: Failed readahead on ifile\nEBADF: Bad file descriptor\n\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\n\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\n\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\n\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:206)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n17/01/24 14:34:59 INFO reduce.InMemoryMapOutput: Read 17 bytes from map-output for attempt_local1576831426_0001_m_000001_0\n17/01/24 14:34:59 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 17, inMemoryMapOutputs.size() -> 3, commitMemory -> 34, usedMemory ->51\n17/01/24 14:34:59 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1576831426_0001_m_000004_0 decomp: 17 len: 21 to MEMORY\n17/01/24 14:34:59 INFO reduce.InMemoryMapOutput: Read 17 bytes from map-output for attempt_local1576831426_0001_m_000004_0\n17/01/24 14:34:59 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 17, inMemoryMapOutputs.size() -> 4, commitMemory -> 51, usedMemory ->68\n17/01/24 14:34:59 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1576831426_0001_m_000000_0 decomp: 17 len: 21 to MEMORY\n17/01/24 14:34:59 WARN io.ReadaheadPool: Failed readahead on ifile\nEBADF: Bad file descriptor\n\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\n\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\n\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\n\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:206)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n17/01/24 14:34:59 INFO reduce.InMemoryMapOutput: Read 17 bytes from map-output for attempt_local1576831426_0001_m_000000_0\n17/01/24 14:34:59 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 17, inMemoryMapOutputs.size() -> 5, commitMemory -> 68, usedMemory ->85\n17/01/24 14:34:59 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning\n17/01/24 14:34:59 INFO mapred.LocalJobRunner: 5 / 5 copied.\n17/01/24 14:34:59 INFO reduce.MergeManagerImpl: finalMerge called with 5 in-memory map-outputs and 0 on-disk map-outputs\n17/01/24 14:34:59 INFO mapred.Merger: Merging 5 sorted segments\n17/01/24 14:34:59 INFO mapred.Merger: Down to the last merge-pass, with 5 segments left of total size: 50 bytes\n17/01/24 14:34:59 INFO reduce.MergeManagerImpl: Merged 5 segments, 85 bytes to disk to satisfy reduce memory limit\n17/01/24 14:34:59 INFO reduce.MergeManagerImpl: Merging 1 files, 81 bytes from disk\n17/01/24 14:34:59 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce\n17/01/24 14:34:59 INFO mapred.Merger: Merging 1 sorted segments\n17/01/24 14:34:59 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 70 bytes\n17/01/24 14:34:59 INFO mapred.LocalJobRunner: 5 / 5 copied.\n17/01/24 14:34:59 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\n17/01/24 14:34:59 INFO mapred.Task: Task:attempt_local1576831426_0001_r_000000_0 is done. And is in the process of committing\n17/01/24 14:34:59 INFO mapred.LocalJobRunner: 5 / 5 copied.\n17/01/24 14:34:59 INFO mapred.Task: Task attempt_local1576831426_0001_r_000000_0 is allowed to commit now\n17/01/24 14:34:59 INFO output.FileOutputCommitter: Saved output of task 'attempt_local1576831426_0001_r_000000_0' to hdfs://localhost:9000/user/krishna/flightinfo/flighttotaldistance/_temporary/0/task_local1576831426_0001_r_000000\n17/01/24 14:34:59 INFO mapred.LocalJobRunner: reduce > reduce\n17/01/24 14:34:59 INFO mapred.Task: Task 'attempt_local1576831426_0001_r_000000_0' done.\n17/01/24 14:34:59 INFO mapred.LocalJobRunner: Finishing task: attempt_local1576831426_0001_r_000000_0\n17/01/24 14:34:59 INFO mapred.LocalJobRunner: reduce task executor complete.\n17/01/24 14:35:00 INFO mapreduce.Job:  map 100% reduce 100%\n17/01/24 14:35:00 INFO mapreduce.Job: Job job_local1576831426_0001 completed successfully\n17/01/24 14:35:00 INFO mapreduce.Job: Counters: 35\n\tFile System Counters\n\t\tFILE: Number of bytes read=34276\n\t\tFILE: Number of bytes written=1980499\n\t\tFILE: Number of read operations=0\n\t\tFILE: Number of large read operations=0\n\t\tFILE: Number of write operations=0\n\t\tHDFS: Number of bytes read=2482554234\n\t\tHDFS: Number of bytes written=16\n\t\tHDFS: Number of read operations=61\n\t\tHDFS: Number of large read operations=0\n\t\tHDFS: Number of write operations=8\n\tMap-Reduce Framework\n\t\tMap input records=5683048\n\t\tMap output records=5683047\n\t\tMap output bytes=73879611\n\t\tMap output materialized bytes=105\n\t\tInput split bytes=625\n\t\tCombine input records=5683047\n\t\tCombine output records=5\n\t\tReduce input groups=1\n\t\tReduce shuffle bytes=105\n\t\tReduce input records=5\n\t\tReduce output records=1\n\t\tSpilled Records=10\n\t\tShuffled Maps =5\n\t\tFailed Shuffles=0\n\t\tMerged Map outputs=5\n\t\tGC time elapsed (ms)=2068\n\t\tTotal committed heap usage (bytes)=2224029696\n\tShuffle Errors\n\t\tBAD_ID=0\n\t\tCONNECTION=0\n\t\tIO_ERROR=0\n\t\tWRONG_LENGTH=0\n\t\tWRONG_MAP=0\n\t\tWRONG_REDUCE=0\n\tFile Input Format Counters \n\t\tBytes Read=570167997\n\tFile Output Format Counters \n\t\tBytes Written=16\n","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"WARN io.ReadaheadPool: Failed readahead on ifile","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=krishnakumarn","name":"krishnakumarn","key":"krishnakumarn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Krishna Kumar Nanjundaprasad","active":true,"timeZone":"Etc/UTC"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=krishnakumarn","name":"krishnakumarn","key":"krishnakumarn","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Krishna Kumar Nanjundaprasad","active":true,"timeZone":"Etc/UTC"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":"OS: Ubuntu Desktop 16.04 LTS\nJVM : Oracle Java 8 update 111\nHadoop: 2.7.3 on pseudo distributed environment\nHardware: Virtual Machine\nProceesor - 2 cores\nRAM - 4 Gb\nSwap - 1 Gb","customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/13037344/comment/15964231","id":"15964231","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=amitbhagat8167","name":"amitbhagat8167","key":"amitbhagat8167","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Amit","active":true,"timeZone":"Etc/UTC"},"body":"I frequently keep on getting the same Warning  \"WARN io.ReadaheadPool: Failed readahead on ifile\nEBADF: Bad file descriptor\" . What can be done to fix the same?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=amitbhagat8167","name":"amitbhagat8167","key":"amitbhagat8167","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Amit","active":true,"timeZone":"Etc/UTC"},"created":"2017-04-11T11:38:58.565+0000","updated":"2017-04-11T11:38:58.565+0000"}],"maxResults":1,"total":1,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/MAPREDUCE-6835/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i394kn:"}}