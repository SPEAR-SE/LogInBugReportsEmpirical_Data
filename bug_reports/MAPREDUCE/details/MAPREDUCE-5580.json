{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12673528","self":"https://issues.apache.org/jira/rest/api/2/issue/12673528","key":"MAPREDUCE-5580","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310941","id":"12310941","key":"MAPREDUCE","name":"Hadoop Map/Reduce","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310941&avatarId=10096","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310941&avatarId=10096","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310941&avatarId=10096","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310941&avatarId=10096"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":null,"customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"2013-10-12 02:02:45.676","customfield_12310420":"353151","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/MAPREDUCE-5580/watchers","watchCount":4,"isWatching":false},"created":"2013-10-12T02:02:45.676+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12314205","id":"12314205","description":"","name":"0.20.2","archived":false,"released":true,"releaseDate":"2010-02-16"}],"issuelinks":[],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2013-10-12T02:02:45.676+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12312920","id":"12312920","name":"task","description":"The code that runs in the child task process."}],"timeoriginalestimate":null,"description":"I have had several reduce tasks fail during the shuffle phase with the following error and stack trace (on CHD 4.1.2):\n\nError: java.lang.OutOfMemoryError: Java heap space\n\tat org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.shuffleInMemory(ReduceTask.java:1644)\n\tat org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.getMapOutput(ReduceTask.java:1504)\n\tat org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.copyOutput(ReduceTask.java:1339)\n\tat org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.run(ReduceTask.java:1271)\n\nI found many web posts that report the same problem and a prior hadoop issue that is already fixed (that one involved a int overflow problem). \n\nThe task had 1 GB of java heap and the mapred.job.shuffle.input.buffer.percent parameter in mapred-site.xml was set to the default of 0.7.  This mean that 1 GB * 0.7 = 717 MB of java heap will hold the map outputs that are no bigger than 717 / 4 = 179 MB.\n\nWe were able to capture a heap dump of one reduce task.  The heap contained 8 byte arrays that were 127 MB each.  These byte arrays were all referenced by their own DataInputBuffer.  Six of the buffers were referenced by the linked lists in ReduceTask$ReduceCopier.mapOutputsFilesInMemory.  These six byte arrays consume 127 MB * 6 = 762 MB of the heap.  Curiously, this 762 MB exceeds the 717 MB limit.  The ShuffleRamManager.fullSize = 797966777 = 761MB, so something is a bit off in my original value of 717...  But this is not the major source of trouble.\n\nThere are two more large byte arrays of 127 MB * 2 = 254 MB that are still in memory.  These are referenced from DataInputBuffers that are referenced indirectly by the static Merger.MergeQueue instance.  \n\nOne of these is referenced twice by the 'key' and 'value' fields of the MergeQueue.  These fields store the current minimum key and value by pointing at the full byte array of the map output and a range of a few bytes in that array.  These fields are needed during the active merge process, but not needed when the merge is complete.  In my heap dump, the 'segments' list has been cleared, so no active merge is in progress.  However, the 'key' and 'value' are still set from the last merge pass.  This pins one in-memory map output in memory, which can be as big as 0.7 / 4 = 17.5% of memory with default settings.  When a merge phase is complete, these two fields should be set null.\n\nThe second byte array is referenced via the MergeQueue.comparator RawComparator.  In my case, this is a WritableComparator. This is most likely caused by this method:\n\n  public int compare(byte[] b1, int s1, int l1, byte[] b2, int s2, int l2) {\n    try {\n      buffer.reset(b1, s1, l1);                   // parse key1\n      key1.readFields(buffer);\n      \n      buffer.reset(b2, s2, l2);                   // parse key2\n      key2.readFields(buffer);\n      \n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n    \n    return compare(key1, key2);                   // compare them\n  }\n\nThis causes the comparator to remember the last 'b2' byte array passed into compare().  This byte array could be an in-memory map output, which by default is 0.7/4 = 17.5% of memory.  This code could have a finally { buffer.clear() } to drop the reference.  Alternatively, the API could include a reset() call to clear such unnecessary state.\n\nGiven this information, we can see why we can easily cause an OOM error:  By default we have 70% of ram dedicated to map output, and we can have 17.5 * 2 = 35% of memory unaccounted for by the two referenced described.  Even without accounting for any other memory overhead, we already have 70% + 35% = 105% of ram occupied in the unlucky case that these two references are pointing at the largest possible in-memory map outputs.\n\nThere may be other leakage of these byte arrays, but these were all the large byte arrays in my heap dump.  A test that makes many map outputs that are 0.7 / 4 = 17.5% of the reduce task heap can reliably recreate this problem and perhaps find other unaccounted large byte arrays.\n","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"353438","customfield_12312823":null,"summary":"OutOfMemoryError in ReduceTask shuffleInMemory","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kbeyer","name":"kbeyer","key":"kbeyer","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Kevin Beyer","active":true,"timeZone":"America/Los_Angeles"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kbeyer","name":"kbeyer","key":"kbeyer","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Kevin Beyer","active":true,"timeZone":"America/Los_Angeles"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[],"maxResults":0,"total":0,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/MAPREDUCE-5580/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i1ovwn:"}}