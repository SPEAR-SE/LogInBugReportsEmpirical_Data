{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12438494","self":"https://issues.apache.org/jira/rest/api/2/issue/12438494","key":"MAPREDUCE-1122","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310941","id":"12310941","key":"MAPREDUCE","name":"Hadoop Map/Reduce","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310941&avatarId=10096","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310941&avatarId=10096","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310941&avatarId=10096","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310941&avatarId=10096"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":"2010-05-10T09:04:38.170+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Sun Dec 08 09:12:50 UTC 2013","customfield_12310420":"35697","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/MAPREDUCE-1122/watchers","watchCount":14,"isWatching":false},"created":"2009-10-19T20:35:31.630+0000","customfield_12310192":null,"customfield_12310191":[{"self":"https://issues.apache.org/jira/rest/api/2/customFieldOption/10342","value":"Incompatible change","id":"10342"}],"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"2.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12314047","id":"12314047","description":"","name":"0.20.1","archived":false,"released":true,"releaseDate":"2009-09-01"}],"issuelinks":[{"id":"12332774","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12332774","type":{"id":"10032","name":"Blocker","inward":"is blocked by","outward":"blocks","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10032"},"inwardIssue":{"id":"12468324","key":"MAPREDUCE-1905","self":"https://issues.apache.org/jira/rest/api/2/issue/12468324","fields":{"summary":"Context.setStatus() and progress() api are ignored","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/1","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/blocker.svg","name":"Blocker","id":"1"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12346876","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12346876","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"12537305","key":"MAPREDUCE-3619","self":"https://issues.apache.org/jira/rest/api/2/issue/12537305","fields":{"summary":"Change streaming code to use new mapreduce api.","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/4","id":"4","description":"An improvement or enhancement to an existing feature or task.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype","name":"Improvement","subtask":false,"avatarId":21140}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=amareshwari","name":"amareshwari","key":"amareshwari","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Amareshwari Sriramadasu","active":true,"timeZone":"Asia/Kolkata"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2013-12-08T09:12:50.558+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12312905","id":"12312905","name":"contrib/streaming"}],"timeoriginalestimate":null,"description":"When trying to implement a custom input format for use with streaming, I have found that streaming does not support the new API, org.apache.hadoop.mapreduce.InputFormat, but requires the old API, org.apache.hadoop.mapred.InputFormat.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12448755","id":"12448755","filename":"patch-1122.txt","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=amareshwari","name":"amareshwari","key":"amareshwari","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Amareshwari Sriramadasu","active":true,"timeZone":"Asia/Kolkata"},"created":"2010-07-06T09:39:33.863+0000","size":242016,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12448755/patch-1122.txt"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12458320","id":"12458320","filename":"patch-1122-1.txt","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=amareshwari","name":"amareshwari","key":"amareshwari","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Amareshwari Sriramadasu","active":true,"timeZone":"Asia/Kolkata"},"created":"2010-10-29T10:24:21.952+0000","size":277981,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12458320/patch-1122-1.txt"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"43262","customfield_12312823":null,"summary":"streaming with custom input format does not support the new API","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kjackson","name":"kjackson","key":"kjackson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Keith Jackson","active":true,"timeZone":"Etc/UTC"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kjackson","name":"kjackson","key":"kjackson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Keith Jackson","active":true,"timeZone":"Etc/UTC"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":"any OS","customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12438494/comment/12865708","id":"12865708","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jaideep","name":"jaideep","key":"jaideep","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jaideep","active":true,"timeZone":"Etc/UTC"},"body":"Some changes that are needed in order to support this.\n* Everywhere in StreamJob, o.a.h.mapred.JobConf is used. To allow \nnew input and output formats, new o.a.h.mapreduce.Job object should be \nused instead. Alternatively we can create and set configuration without \nrelying on JobConf or Job methods, and only create a JobConf or Job \nobject depending upon whether old or new API is being used.\n\n* PipeMapper and PipeReducer are also based on the old api. We will have \nto create new Mappers and Reducers based on the new API in order to \nsupport newer input and output formats. PipeMapRed also uses JobConf at \na number of places. Almost all of these calls could be replaced by calls \nto Configuration object.\n\n* StreamInputFormat extends o.a.h.mapred.KeyValueTextInputFormat. It \nshould extend o.a.h.mapreduce.lib.input.KeyValueTextInputFormat\n\n* StreamBaseRecordReader extends o.a.h.mapred.RecordReader. New class \nconfirming to new API is needed.\n\n* Some static methods in StreamUtil.java are using old api -\n     getCurrentSplit - uses o.a.h.mapred.FileSplit and Jobconf. This \nmethod is not used anywhere else in the code.\n     isLocalJobTracker - uses JobConf.\n     getTaskInfo - uses JobConf to get type of a task and taskid. used \nin PipeMapRed.setStreamJobDetails to set the taskid.\n     addJobConfToEnvironment - takes a JobConf as argument. Should also \ntake a Job.\n    There is a static TaskID class in StreamUtils.java as well. If its not needed can it be removed?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jaideep","name":"jaideep","key":"jaideep","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jaideep","active":true,"timeZone":"Etc/UTC"},"created":"2010-05-10T09:04:38.170+0000","updated":"2010-05-10T09:04:38.170+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12438494/comment/12878515","id":"12878515","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=amareshwari","name":"amareshwari","key":"amareshwari","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Amareshwari Sriramadasu","active":true,"timeZone":"Asia/Kolkata"},"body":"Users can specify Mapper/Reducer to be Java Mapper/Reducer or a command. Also, he could specify input format, output format and partitioner for his streaming job. The below tables summarize the mapper or reducer in use when streaming supports both old and new api.\n\nNote : In the tables below, NS stands for 'Not specified\".\n\n*Table 1* Mapper-in-use for given spec, when num reducers  = 0:\n||Mapper || InputFormat || OutputFormat || Valid conf?|| Mapper-in-use ||\n|Command|NS|NS|Yes|New|\n|Command|Old|NS|Yes|Old|\n|Command|Old|Old|Yes|Old|\n|Command|Old|New|{color:red}No{color}|\n|Command|New|NS|Yes|New|\n|Command|New|Old|{color:red}No{color}|\n|Command|New|New|Yes|New|\n|Old|NS|NS|Yes|Old|\n|Old|NS|Old|Yes|Old|\n|Old|Old|NS|Yes|Old|\n|Old|Old|Old|Yes|Old|\n|Old|-|New|{color:red}No{color}|\n|Old|New|-|{color:red}No{color}|\n|New|NS|NS|Yes|New|\n|New|NS|New|Yes|New|\n|New|New|NS|Yes|New|\n|New|New|New|Yes|New|\n|New|-|Old|{color:red}No{color}|\n|New|Old|-|{color:red}No{color}|\n\n*Table 2* Mapper-in-use for given spec, when num reducers != 0:\n||Mapper || InputFormat || Partitioner|| Valid conf?|| Mapper-in-use ||\n|Command|NS|NS|Yes|New|\n|Command|Old|NS|Yes|Old|\n|Command|Old|Old|Yes|Old|\n|Command|Old|New|{color:red}No{color}|\n|Command|New|NS|Yes|New|\n|Command|New|Old|{color:red}No{color}|\n|Command|New|New|Yes|New|\n|Old|NS|NS|Yes|Old|\n|Old|NS|Old|Yes|Old|\n|Old|Old|NS|Yes|Old|\n|Old|Old|Old|Yes|Old|\n|Old|New|-|{color:red}No{color}|\n|Old|-|New|{color:red}No{color}|\n|New|NS|NS|Yes|New|\n|New|NS|New|Yes|New|\n|New|New|NS|Yes|New|\n|New|New|New|Yes|New|\n|New|Old|-|{color:red}No{color}|\n|New|-|Old|{color:red}No{color}|\n\n*Table 3* Reducer-in-use for a given spec :\n|| Reducer || OutputFormat || Valid conf?|| Reducer-in-use ||\n| Command | NS |Yes |New|\n| Command | Old |Yes |Old |\n| Command | New |Yes |New| \n|Old|NS|Yes|Old|\n|New|NS|Yes|New|\n|Old|Old|Yes|Old|\n|New|New|Yes|New|\n|Old|New|{color:red}No{color}|\n|New|Old|{color:red}No{color}|\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=amareshwari","name":"amareshwari","key":"amareshwari","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Amareshwari Sriramadasu","active":true,"timeZone":"Asia/Kolkata"},"created":"2010-06-14T09:35:48.741+0000","updated":"2010-06-14T09:35:48.741+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12438494/comment/12885482","id":"12885482","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=amareshwari","name":"amareshwari","key":"amareshwari","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Amareshwari Sriramadasu","active":true,"timeZone":"Asia/Kolkata"},"body":"For supporting new api in streaming, the implementation involves two major tasks:\n# Setting job configuration for the streaming job: set appropriate mapper and reducer depending on the arguments passed. Summarizing the above requirements table :\n ** The old api mapper, PipeMapper, is used as mapper for the job only if mapper is command and \n    a) old api input format is passed  or\n    b) #reduces=0 and old api output format is passed or \n    c) #reduces !=0 and old api partitioner is passed.\n ** Similarly the old api reducer, PipeReducer, is used as reducer for the job only if reducer is command and old output format is passed.\n# Implementation of new api streaming mapper, reducer and etc.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=amareshwari","name":"amareshwari","key":"amareshwari","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Amareshwari Sriramadasu","active":true,"timeZone":"Asia/Kolkata"},"created":"2010-07-06T09:36:12.895+0000","updated":"2010-07-06T09:36:12.895+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12438494/comment/12885483","id":"12885483","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=amareshwari","name":"amareshwari","key":"amareshwari","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Amareshwari Sriramadasu","active":true,"timeZone":"Asia/Kolkata"},"body":"Attaching a patch which does the following:\n* Deprectaes all the library classes in streaming such as AutoInputFormat, StreamInputFormat, StreamXmlRecordReader etc. and adds new classes which use new api. \n* Changes the tools DumpTypedBytes and LoadTypedBytes to use new api classes.\n* Adds StreamJobConfig holding all the configuration properties used in streaming.\n* Adds classes StreamingMapper, StreamingReducer and StreamingCombiner which extend new api Mapper and Reducer classes.\n  ** Adds a class StreamingProcess which starts streaming process, MR output/error threads and waits for the threads and etc. This functionality is in PipeMapred.java for the old api mapper/reducer; PipeMapper and PipeReducer extend PipeMapred and implement old Mapper/Reducer interfaces. We cannot make StreamingMapper/StreamingReducer extend StreamingProcess because in new api mapper and reducer are not interfaces. So moved this into a separate class so that StreamingMapper/StreamingReducer composes it.\n  ** InputWriter and OutputReader added in HADOOP-1722 take PipeMapred instance as a parameter for the constructor. But it does not make sense now because the process handling is served by separate class, StreamingProcess, for new api mapper/reducer. So, did a following Incompatible change (looks clean now):\n  *** Changes OutputReader constructor to take DataInput as parameter, instead of PipeMapRed\n  *** Changes InputWriter constructor to take DataOutput as parameter, instead of PipeMapRed\n* Moves some utility methods in PipeMapRed to StreamUtil.\n* Removes deprectaed StreamJob(String[] argv, boolean mayExit); Deprecates static public JobConf createJob(String[] argv); and adds static public Job createStreamingJob(String[] argv)\n* Refactors setJobConf() into multiple setters to set appropriate mapper/reducer in use.\n* Adds unit tests for all the usecases described [above|https://issues.apache.org/jira/browse/MAPREDUCE-1122?focusedCommentId=12878515&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#action_12878515]\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=amareshwari","name":"amareshwari","key":"amareshwari","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Amareshwari Sriramadasu","active":true,"timeZone":"Asia/Kolkata"},"created":"2010-07-06T09:39:34.036+0000","updated":"2010-07-06T09:39:34.036+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12438494/comment/12885484","id":"12885484","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=amareshwari","name":"amareshwari","key":"amareshwari","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Amareshwari Sriramadasu","active":true,"timeZone":"Asia/Kolkata"},"body":"Patch is ready for review.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=amareshwari","name":"amareshwari","key":"amareshwari","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Amareshwari Sriramadasu","active":true,"timeZone":"Asia/Kolkata"},"created":"2010-07-06T09:41:37.316+0000","updated":"2010-07-06T09:41:37.316+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12438494/comment/12885573","id":"12885573","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"-1 overall.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12448755/patch-1122.txt\n  against trunk revision 960808.\n\n    +1 @author.  The patch does not contain any @author tags.\n\n    +1 tests included.  The patch appears to include 92 new or modified tests.\n\n    +1 javadoc.  The javadoc tool did not generate any warning messages.\n\n    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.\n\n    +1 findbugs.  The patch does not introduce any new Findbugs warnings.\n\n    +1 release audit.  The applied patch does not increase the total number of release audit warnings.\n\n    +1 core tests.  The patch passed core unit tests.\n\n    -1 contrib tests.  The patch failed contrib unit tests.\n\nTest results: http://hudson.zones.apache.org/hudson/job/Mapreduce-Patch-h4.grid.sp2.yahoo.net/287/testReport/\nFindbugs warnings: http://hudson.zones.apache.org/hudson/job/Mapreduce-Patch-h4.grid.sp2.yahoo.net/287/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html\nCheckstyle results: http://hudson.zones.apache.org/hudson/job/Mapreduce-Patch-h4.grid.sp2.yahoo.net/287/artifact/trunk/build/test/checkstyle-errors.html\nConsole output: http://hudson.zones.apache.org/hudson/job/Mapreduce-Patch-h4.grid.sp2.yahoo.net/287/console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2010-07-06T16:04:42.191+0000","updated":"2010-07-06T16:04:42.191+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12438494/comment/12885819","id":"12885819","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=amareshwari","name":"amareshwari","key":"amareshwari","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Amareshwari Sriramadasu","active":true,"timeZone":"Asia/Kolkata"},"body":"bq. -1 contrib tests.\nThe failure is because of MAPREDUCE-1834.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=amareshwari","name":"amareshwari","key":"amareshwari","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Amareshwari Sriramadasu","active":true,"timeZone":"Asia/Kolkata"},"created":"2010-07-07T04:19:35.133+0000","updated":"2010-07-07T04:19:35.133+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12438494/comment/12887308","id":"12887308","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=amareshwari","name":"amareshwari","key":"amareshwari","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Amareshwari Sriramadasu","active":true,"timeZone":"Asia/Kolkata"},"body":"Forgot to mention that skipping bad records functionality is not added for new api classes, because the support is not there for new api in the framework itself(MAPREDUCE-1932).","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=amareshwari","name":"amareshwari","key":"amareshwari","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Amareshwari Sriramadasu","active":true,"timeZone":"Asia/Kolkata"},"created":"2010-07-12T08:34:43.515+0000","updated":"2010-07-12T08:34:43.515+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12438494/comment/12890205","id":"12890205","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinodkv","name":"vinodkv","key":"vinodkv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinod Kumar Vavilapalli","active":true,"timeZone":"America/Los_Angeles"},"body":"I started looking at this patch. Its BIG, and streaming isn't exactly my 'home-ground' :) I had to spend quite some time reviewing it. Please bear with me, we will need to go through some iterations, at-least one more big one, to get this close.\n\n - First up, the patch needs some merging to be done to accommodate recent commits in streaming.\n\n - It'd be really good if we can separate the new classes into new packages, library classes into a lib package and implementation classes to an impl package?\n\n - There are two ways of handing the skipping of bad records in the new api - (1) put the code in place and document that it isn't supported yet so that whenever MAPREDUCE-1932 moves in skipping automatically works in streaming or (2) remove the code altogether and create a child issue of MAPREDUCE-1932 for streaming. Looks like you intended to do (2) but I do see some (dead) code related to skipping in the new api classes, for e.g. StreamingMapper. We should either chose (1) completely or (2) completely.\n\nOtherwise the overall functionality looks good to me, correctness including. Just some minor comments.\n\nStreamingMapper.java\n - This log statement is new and we are doing for every key. Too aggressive?\n    LOG.info(\"input \" + key + \" \"+ value);\n - Difference in logging compared to old PipeMapred class when exceptions happen in map.\n - Missing @Override annotation for methods overridden.\n\nStreamingReducer.java\n - Not logging exit code when exceptions happen in reduce. Used to be the case in old code.\n - Missing @Override annotation for methods overridden.\n\nHow about passing configuration configuration to InputWriter.initialize() and let TextInputWriter/TextOutputReader maintain themselves the key/vaule separators and related information instead of polluting StreamingMapper and StreamingReducer?\n\nStreamingCombiner\n - Missing @Override annotation for method overridden.\n\nAutoinputformat2\n - No configure method like in AutoInputFormat?\n - Name? Once we move the lib classes to a  new package, this class's name can stay the same old AutoInputFormat.\n\nStreamingXmlRecordReader.java\n - Log.info statement in init() bears the wrong (parent) class name.\n - nextKeyValue() should be synchronized? In old api it was.\n\nStreamingBaseRecordReader.java\n - getStatus() has changed w.r.t printing 'pos' also when compared to the older StreamBaseRecordReader.java\n\nStreamJob.java\n - bq. Removes deprectaed StreamJob(String[] argv, boolean mayExit);\n   Just checking. Is the compatibility left in one release?\n - Same for StreamJob.go()?\n - boolean isOldIF argument to setOutputFormat is not used at all.\n - Cluster and hence StreamJob never close client connection themselves at all! ( May be another ticket)\n\nTestStreamingStatus: \n - +    //testStreamJob(false);// nonempty input\nCommented intentionally, in testReporing()?\n - Comments from +262 to +265 are no longer valid, right?\n\nTrApp.java\n - Some expect() and expectDefined() calls are dropped. I could understand why the ones related to output format are dropped to accommodate testing both new and old apis. But removing of the checks related to input file and file length didn't make sense to me.\n\nTaskInputOuputContextImpl.\n - The changes here were a surprise to me. Should be related to MAPREDUCE-1905. Are you incorporating that here, or just kept them in the patch for running. If it's the later, please provide a patch without these changes. If it is the former, we will need to include the testcase from there too.\n\nMiscellaneous comments:\n - It's right time for us to  mark all the touched classes/interfaces according to the classification taxonomy.\n - Should we make the initialize methods in InputWriter and OutputReader abstract now?\n - TestStreamingAPICompatibility class needs some javadoc.\n - TODO: In the end we need to be sure tests pass with LinuxTaskController as well. Please do this with your next patch if you'ven't already.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinodkv","name":"vinodkv","key":"vinodkv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinod Kumar Vavilapalli","active":true,"timeZone":"America/Los_Angeles"},"created":"2010-07-20T07:55:16.966+0000","updated":"2010-07-20T07:55:16.966+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12438494/comment/12919340","id":"12919340","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jeromatron","name":"jeromatron","key":"jeromatron","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jeremy Hanna","active":true,"timeZone":"America/Chicago"},"body":"Is there any update on this?  It's kind of a pain to have to support the old and new API in a custom InputFormat/RecordReader in order to enable streaming.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jeromatron","name":"jeromatron","key":"jeromatron","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jeremy Hanna","active":true,"timeZone":"America/Chicago"},"created":"2010-10-08T18:24:45.820+0000","updated":"2010-10-08T18:24:45.820+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12438494/comment/12919601","id":"12919601","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=amareshwari","name":"amareshwari","key":"amareshwari","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Amareshwari Sriramadasu","active":true,"timeZone":"Asia/Kolkata"},"body":"Will upload a new patch soon.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=amareshwari","name":"amareshwari","key":"amareshwari","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Amareshwari Sriramadasu","active":true,"timeZone":"Asia/Kolkata"},"created":"2010-10-10T13:00:55.079+0000","updated":"2010-10-10T13:00:55.079+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12438494/comment/12926228","id":"12926228","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=amareshwari","name":"amareshwari","key":"amareshwari","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Amareshwari Sriramadasu","active":true,"timeZone":"Asia/Kolkata"},"body":"Patch is updated to trunk with most of the review comments incorporated. Patch should be applied on top of MAPREDUCE-1905 to pass all tests.\n\nbq. It'd be really good if we can separate the new classes into new packages, library classes into a lib package and implementation classes to an impl package?\nDone\n\nbq. There are two ways of handing the skipping of bad records in the new api ...........\nRemoved the dead code related to skipping in new api classes. Will add a subtask to MAPREDUCE-1932 to add support for streaming.\n\nStreamingReducer.java\nbq. Not logging exit code when exceptions happen in reduce. Used to be the case in old code.\nExit code is already logged in StreamingProcessManager. Even in old code, it was getting logged twice.\n\nbq. How about passing configuration configuration to InputWriter.initialize() and let TextInputWriter/TextOutputReader maintain themselves the key/vaule separators and related information instead of polluting StreamingMapper and StreamingReducer?\nDid not do this. It makes the code more complicated because, mapper and reducers have different configuration parameter names.\n\nAutoinputformat2\nbq. No configure method like in AutoInputFormat?\nNew api does not have configure for inputformat.\n\nStreamJob.java\nbq. Is the compatibility left in one release?\nYes. all the removed deprecated methods have been deprectaed since release 0.19\n\n\nTrApp.java\nbq. Some expect() and expectDefined() calls are dropped. I could understand why the ones related to output format are dropped to accommodate testing both new and old apis. But removing of the checks related to input file and file length didn't make sense to me.\nNew api does not have the configuration parameters for input file and length (HADOOP-5973).\n\nbq. Should we make the initialize methods in InputWriter and OutputReader abstract now?\nDid not do this. I don't think it is required.\n\nPatch incorporates all other commands","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=amareshwari","name":"amareshwari","key":"amareshwari","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Amareshwari Sriramadasu","active":true,"timeZone":"Asia/Kolkata"},"created":"2010-10-29T10:24:22.175+0000","updated":"2010-10-29T10:24:22.175+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12438494/comment/13000545","id":"13000545","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"-1 overall.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12458320/patch-1122-1.txt\n  against trunk revision 1075216.\n\n    +1 @author.  The patch does not contain any @author tags.\n\n    +1 tests included.  The patch appears to include 100 new or modified tests.\n\n    +1 javadoc.  The javadoc tool did not generate any warning messages.\n\n    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.\n\n    +1 findbugs.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.\n\n    +1 release audit.  The applied patch does not increase the total number of release audit warnings.\n\n    +1 core tests.  The patch passed core unit tests.\n\n    -1 contrib tests.  The patch failed contrib unit tests.\n\n    +1 system test framework.  The patch passed system test framework compile.\n\nTest results: https://hudson.apache.org/hudson/job/PreCommit-MAPREDUCE-Build/93//testReport/\nFindbugs warnings: https://hudson.apache.org/hudson/job/PreCommit-MAPREDUCE-Build/93//artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html\nConsole output: https://hudson.apache.org/hudson/job/PreCommit-MAPREDUCE-Build/93//console\n\nThis message is automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2011-02-28T21:52:34.631+0000","updated":"2011-02-28T21:52:34.631+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12438494/comment/13098744","id":"13098744","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=acmurthy","name":"acmurthy","key":"acmurthy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun C Murthy","active":true,"timeZone":"America/Los_Angeles"},"body":"Sorry to come in late, the patch has gone stale. Can you please rebase? Thanks.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=acmurthy","name":"acmurthy","key":"acmurthy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun C Murthy","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-09-07T08:21:18.911+0000","updated":"2011-09-07T08:21:18.911+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12438494/comment/13842465","id":"13842465","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=herberts","name":"herberts","key":"herberts","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Mathias Herberts","active":true,"timeZone":"Etc/UTC"},"body":"What is needed for this issue to move forward? Input and Output formats using the new API will become more and more frequent these days, people using streaming won't be able to benefit from those.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=herberts","name":"herberts","key":"herberts","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Mathias Herberts","active":true,"timeZone":"Etc/UTC"},"created":"2013-12-08T09:12:50.558+0000","updated":"2013-12-08T09:12:50.558+0000"}],"maxResults":15,"total":15,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/MAPREDUCE-1122/votes","votes":5,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i07rr3:"}}