{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12352251","self":"https://issues.apache.org/jira/rest/api/2/issue/12352251","key":"MAPREDUCE-185","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310941","id":"12310941","key":"MAPREDUCE","name":"Hadoop Map/Reduce","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310941&avatarId=10096","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310941&avatarId=10096","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310941&avatarId=10096","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310941&avatarId=10096"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/6","id":"6","description":"The problem isn't valid and it can't be fixed.","name":"Invalid"},"customfield_12312322":null,"customfield_12310220":"2006-10-03T17:32:00.000+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Mon Jan 16 10:03:03 UTC 2012","customfield_12310420":"148575","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_166855908335_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2012-01-16T10:03:03.231+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/MAPREDUCE-185/watchers","watchCount":1,"isWatching":false},"created":"2006-10-03T05:11:15.000+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[],"issuelinks":[],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley","name":"owen.omalley","key":"owen.omalley","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=29697","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=29697","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=owen.omalley&avatarId=29697","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=owen.omalley&avatarId=29697"},"displayName":"Owen O'Malley","active":true,"timeZone":"America/Los_Angeles"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2012-01-16T10:03:03.326+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[],"timeoriginalestimate":null,"description":"Many reduce tasks got killed due to checksum error. The strange thing is that the file was generated by the sort function, and was on a local disk. Here is the stack: \n\nChecksum error:  ../task_0011_r_000140_0/all.2.1 at 5342920704\n\tat org.apache.hadoop.fs.FSDataInputStream$Checker.verifySum(FSDataInputStream.java:134)\n\tat org.apache.hadoop.fs.FSDataInputStream$Checker.read(FSDataInputStream.java:110)\n\tat org.apache.hadoop.fs.FSDataInputStream$PositionCache.read(FSDataInputStream.java:170)\n\tat java.io.BufferedInputStream.fill(BufferedInputStream.java:218)\n\tat java.io.BufferedInputStream.read1(BufferedInputStream.java:256)\n\tat java.io.BufferedInputStream.read(BufferedInputStream.java:313)\n\tat java.io.DataInputStream.readFully(DataInputStream.java:176)\n\tat org.apache.hadoop.io.DataOutputBuffer$Buffer.write(DataOutputBuffer.java:55)\n\tat org.apache.hadoop.io.DataOutputBuffer.write(DataOutputBuffer.java:89)\n\tat org.apache.hadoop.io.SequenceFile$Reader.readBuffer(SequenceFile.java:1061)\n\tat org.apache.hadoop.io.SequenceFile$Reader.seekToCurrentValue(SequenceFile.java:1126)\n\tat org.apache.hadoop.io.SequenceFile$Reader.nextRaw(SequenceFile.java:1354)\n\tat org.apache.hadoop.io.SequenceFile$Sorter$MergeStream.next(SequenceFile.java:1880)\n\tat org.apache.hadoop.io.SequenceFile$Sorter$MergeQueue.merge(SequenceFile.java:1938)\n\tat org.apache.hadoop.io.SequenceFile$Sorter$MergePass.run(SequenceFile.java:1802)\n\tat org.apache.hadoop.io.SequenceFile$Sorter.mergePass(SequenceFile.java:1749)\n\tat org.apache.hadoop.io.SequenceFile$Sorter.sort(SequenceFile.java:1494)\n\tat org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:240)\n\tat org.apache.hadoop.mapred.TaskTracker$Child.main(TaskTracker.java:1066)\n","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"107537","customfield_12312823":null,"summary":"Checksum error during sorting in reducer","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=runping","name":"runping","key":"runping","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Runping Qi","active":true,"timeZone":"Etc/UTC"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=runping","name":"runping","key":"runping","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Runping Qi","active":true,"timeZone":"Etc/UTC"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12352251/comment/12439567","id":"12439567","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"body":"Sort is actually the place where most checksum errors have been reported.  I believe this is because sorting keeps data in memory longer than other operations, increasing the chance that it will be corrupted there.  Does this node have ECC memory?  If so, memory errors are unlikely.  Sorting also accounts for a large portion of the number of times data is written to disk, so the corruption could have happened there.  It would be worth examining the syslog on that node to see if any disk or memory errors are reported.\n\nI assume the reduce was rescheduled and completed?  If so, then I will resolve this issue.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"created":"2006-10-03T17:32:00.000+0000","updated":"2006-10-03T17:32:00.000+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12352251/comment/12439670","id":"12439670","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=runping","name":"runping","key":"runping","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Runping Qi","active":true,"timeZone":"Etc/UTC"},"body":"\nYes, the task was rescheduled and finished successfully. That is the good news. \nThe syslog does not have any error reports.\n\nI think it is possible that the problem is due to a software bug. Thus, it is better to leave it open for tracking purpose.\n\n\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=runping","name":"runping","key":"runping","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Runping Qi","active":true,"timeZone":"Etc/UTC"},"created":"2006-10-03T21:54:18.000+0000","updated":"2006-10-03T21:54:18.000+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12352251/comment/12462172","id":"12462172","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=notthekarl-misc%40yahoo.com","name":"notthekarl-misc@yahoo.com","key":"notthekarl-misc@yahoo.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"notthekarl-misc@yahoo.com","active":true,"timeZone":"Etc/UTC"},"body":"\n\n\nHi,\n\nI'm getting the same problem but don't know enough about Hadoop to\nreschedule the reduce task.  Could somebody point me to some\ndocumentation or let me know how to do this?\n\nMany thanks,\nK.\n\n\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=notthekarl-misc%40yahoo.com","name":"notthekarl-misc@yahoo.com","key":"notthekarl-misc@yahoo.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"notthekarl-misc@yahoo.com","active":true,"timeZone":"Etc/UTC"},"created":"2007-01-04T09:16:27.892+0000","updated":"2007-01-04T09:16:27.892+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12352251/comment/12462175","id":"12462175","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=notthekarl-misc%40yahoo.com","name":"notthekarl-misc@yahoo.com","key":"notthekarl-misc@yahoo.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"notthekarl-misc@yahoo.com","active":true,"timeZone":"Etc/UTC"},"body":"Sorry, I should have added that I get the error whilst in the fetch stage using Nutch:\n\n2007-01-03 02:29:15,062 WARN  dfs.DistributedFileSystem - Moving bad file C:\\tmp\\hadoop\\mapred\\local\\reduce_dyohnt\\map_0.out to C:\\tmp\\hadoop\\mapred\\local\\reduce_dyohnt\\bad_files\\map_0.out.61591645\n2007-01-03 02:29:15,093 WARN  mapred.LocalJobRunner - job_kh2gl7\norg.apache.hadoop.fs.ChecksumException: Checksum error: /tmp/hadoop/mapred/local/reduce_dyohnt/map_0.out at 217448448\n\tat org.apache.hadoop.fs.FSDataInputStream$Checker.verifySum(FSDataInputStream.java:123)\n\tat org.apache.hadoop.fs.FSDataInputStream$Checker.read(FSDataInputStream.java:99)\n\n\nK.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=notthekarl-misc%40yahoo.com","name":"notthekarl-misc@yahoo.com","key":"notthekarl-misc@yahoo.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"notthekarl-misc@yahoo.com","active":true,"timeZone":"Etc/UTC"},"created":"2007-01-04T09:38:13.818+0000","updated":"2007-01-04T09:38:13.818+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12352251/comment/12499677","id":"12499677","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bigjules","name":"bigjules","key":"bigjules","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Julian Neil","active":true,"timeZone":"Etc/UTC"},"body":"I've been seeing the same problem, and other checksum problems. I am somewhat sceptical of the suggestion that is a memory hardware issue, but to be thorough I tried replacing my memory.  The errors continued. If there is any additional information I can provide to help track the probem down, please let me know.  \nRunning on a single Windows Server 2003 (with cygwin) as both namenode and datanode.\nStrangely, some large map/reduce jobs never get checksum errors in the maps or reduces, but one particular job always does. \n \nIn addition I have been getting many lost map outputs due to checksum errors.  The error usually disappears when the task is retried:\n\nMap output lost, rescheduling: getMapOutput(task_0008_m_000007_0,0) failed :\norg.apache.hadoop.fs.ChecksumException: Checksum error: /tmp/hadoop-sshd_server/mapred/local/task_0008_m_000007_0/file.out at 60215808\n\tat org.apache.hadoop.fs.ChecksumFileSystem$FSInputChecker.verifySum(ChecksumFileSystem.java:258)\n\tat org.apache.hadoop.fs.ChecksumFileSystem$FSInputChecker.readBuffer(ChecksumFileSystem.java:211)\n\tat org.apache.hadoop.fs.ChecksumFileSystem$FSInputChecker.read(ChecksumFileSystem.java:167)\n\tat org.apache.hadoop.fs.FSDataInputStream$PositionCache.read(FSDataInputStream.java:41)\n\tat java.io.BufferedInputStream.read1(BufferedInputStream.java:256)\n\tat java.io.BufferedInputStream.read(BufferedInputStream.java:317)\n\tat java.io.DataInputStream.read(DataInputStream.java:132)\n\tat org.apache.hadoop.mapred.TaskTracker$MapOutputServlet.doGet(TaskTracker.java:1674)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:689)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:802)\n\tat org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:427)\n\tat org.mortbay.jetty.servlet.WebApplicationHandler.dispatch(WebApplicationHandler.java:475)\n\tat org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:567)\n\tat org.mortbay.http.HttpContext.handle(HttpContext.java:1565)\n\tat org.mortbay.jetty.servlet.WebApplicationContext.handle(WebApplicationContext.java:635)\n\tat org.mortbay.http.HttpContext.handle(HttpContext.java:1517)\n\tat org.mortbay.http.HttpServer.service(HttpServer.java:954)\n\tat org.mortbay.http.HttpConnection.service(HttpConnection.java:814)\n\tat org.mortbay.http.HttpConnection.handleNext(HttpConnection.java:981)\n\tat org.mortbay.http.HttpConnection.handle(HttpConnection.java:831)\n\tat org.mortbay.http.SocketListener.handleConnection(SocketListener.java:244)\n\tat org.mortbay.util.ThreadedServer.handle(ThreadedServer.java:357)\n\tat org.mortbay.util.ThreadPool$PoolThread.run(ThreadPool.java:534)\n\nI'm alse getting errors in final output of the previous map/reduce job which is fed in as input to the next job.  These errors do not disappear when the map task retries:\n\norg.apache.hadoop.fs.ChecksumException: Checksum error: hdfs://xxx.xxx.xxx:9900/aa/datamining/deviations_part-00002_step-00001/part-00000 at 13781504\n\tat org.apache.hadoop.fs.ChecksumFileSystem$FSInputChecker.verifySum(ChecksumFileSystem.java:258)\n\tat org.apache.hadoop.fs.ChecksumFileSystem$FSInputChecker.readBuffer(ChecksumFileSystem.java:211)\n\tat org.apache.hadoop.fs.ChecksumFileSystem$FSInputChecker.read(ChecksumFileSystem.java:167)\n\tat org.apache.hadoop.fs.FSDataInputStream$PositionCache.read(FSDataInputStream.java:41)\n\tat java.io.BufferedInputStream.fill(BufferedInputStream.java:218)\n\tat java.io.BufferedInputStream.read(BufferedInputStream.java:237)\n\tat org.apache.hadoop.fs.FSDataInputStream$Buffer.read(FSDataInputStream.java:93)\n\tat java.io.DataInputStream.readInt(DataInputStream.java:372)\n\tat org.apache.hadoop.io.SequenceFile$Reader.next(SequenceFile.java:1523)\n\tat org.apache.hadoop.io.SequenceFile$Reader.next(SequenceFile.java:1436)\n\tat org.apache.hadoop.io.SequenceFile$Reader.next(SequenceFile.java:1482)\n\tat org.apache.hadoop.mapred.SequenceFileRecordReader.next(SequenceFileRecordReader.java:73)\n\tat org.apache.hadoop.mapred.MapTask$1.next(MapTask.java:157)\n\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:46)\n\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:175)\n\tat org.apache.hadoop.mapred.TaskTracker$Child.main(TaskTracker.java:1445)\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bigjules","name":"bigjules","key":"bigjules","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Julian Neil","active":true,"timeZone":"Etc/UTC"},"created":"2007-05-29T04:12:27.473+0000","updated":"2007-05-29T04:12:27.473+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12352251/comment/12499868","id":"12499868","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"body":"> I tried replacing my memory. The errors continued.\n\nTo be clear, did you replace it with ECC memory?\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"created":"2007-05-29T18:17:21.067+0000","updated":"2007-05-29T18:17:21.067+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12352251/comment/12500087","id":"12500087","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bigjules","name":"bigjules","key":"bigjules","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Julian Neil","active":true,"timeZone":"Etc/UTC"},"body":"\nNo. Sorry, should have been clearer. Replaced it with non-ECC memory. You still think this may be the cause?  Can you explain why you think this would fix the problem.  \n\nReading the other similar issues on checksum errors, it appears that files (or their checksum files) at various stages of the map/reduce processing are becoming corrupted when written to disk.  There are reports of errors in map output, during sorting, and in reduce output.\n\nIt smacks of a tricky threading issue. Both because hadoop is fairly complex in its use of threads, and because the bug is intermittent.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bigjules","name":"bigjules","key":"bigjules","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Julian Neil","active":true,"timeZone":"Etc/UTC"},"created":"2007-05-30T10:38:17.514+0000","updated":"2007-05-30T10:38:17.514+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12352251/comment/12500462","id":"12500462","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"body":"> Replaced it with non-ECC memory.\n\nDid you see Dennis Kubes' message?\n\nhttp://mail-archives.apache.org/mod_mbox/lucene-hadoop-dev/200705.mbox/%3c465C3065.9050501@dragonflymc.com%3e\n\nThis has come up before.  Folks who have ECC memory don't see checksum errors.  Perhaps we should add this to an FAQ.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"created":"2007-05-31T19:42:18.161+0000","updated":"2007-05-31T19:42:18.161+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12352251/comment/12500558","id":"12500558","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bigjules%40froggyfrog.com","name":"bigjules@froggyfrog.com","key":"bigjules@froggyfrog.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Big Jules","active":true,"timeZone":"Etc/UTC"},"body":"Apologies again.. I didn't see Dennis' reply..  Will try to convince management to replace with ECC memory.  I am running tests to see if we should invest in a cluster and move some of our recommendation system algorithms over to hadoop.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bigjules%40froggyfrog.com","name":"bigjules@froggyfrog.com","key":"bigjules@froggyfrog.com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Big Jules","active":true,"timeZone":"Etc/UTC"},"created":"2007-06-01T02:43:17.047+0000","updated":"2007-06-01T02:43:17.047+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12352251/comment/12500771","id":"12500771","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"body":"> I am running tests to see if we should invest in a cluster [ ... ]\n\nFYI, Amazon EC2 provides an easy way to experiment with Hadoop.\n\nhttp://wiki.apache.org/lucene-hadoop/AmazonEC2\n\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=cutting","name":"cutting","key":"cutting","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Doug Cutting","active":true,"timeZone":"America/Los_Angeles"},"created":"2007-06-01T17:32:02.932+0000","updated":"2007-06-01T17:32:02.932+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12352251/comment/13186828","id":"13186828","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=qwertymaniac","name":"qwertymaniac","key":"qwertymaniac","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=qwertymaniac&avatarId=16780","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=qwertymaniac&avatarId=16780","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=qwertymaniac&avatarId=16780","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=qwertymaniac&avatarId=16780"},"displayName":"Harsh J","active":true,"timeZone":"Asia/Kolkata"},"body":"This looked to have been a user-end issue, but was not closed earlier.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=qwertymaniac","name":"qwertymaniac","key":"qwertymaniac","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=qwertymaniac&avatarId=16780","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=qwertymaniac&avatarId=16780","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=qwertymaniac&avatarId=16780","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=qwertymaniac&avatarId=16780"},"displayName":"Harsh J","active":true,"timeZone":"Asia/Kolkata"},"created":"2012-01-16T10:03:03.310+0000","updated":"2012-01-16T10:03:03.310+0000"}],"maxResults":11,"total":11,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/MAPREDUCE-185/votes","votes":2,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i0irfb:"}}