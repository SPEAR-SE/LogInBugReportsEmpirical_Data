{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12501214","self":"https://issues.apache.org/jira/rest/api/2/issue/12501214","key":"MAPREDUCE-2378","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310941","id":"12310941","key":"MAPREDUCE","name":"Hadoop Map/Reduce","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310941&avatarId=10096","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310941&avatarId=10096","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310941&avatarId=10096","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310941&avatarId=10096"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/5","id":"5","description":"All attempts at reproducing this issue failed, or not enough information was available to reproduce the issue. Reading the code produces no clues as to why this behavior would occur. If more information appears later, please reopen the issue.","name":"Cannot Reproduce"},"customfield_12312322":null,"customfield_12310220":"2011-06-06T20:38:51.460+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Thu Jul 17 15:22:59 UTC 2014","customfield_12310420":"19096","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_105725040167_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2014-07-17T15:22:59.156+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/MAPREDUCE-2378/watchers","watchCount":3,"isWatching":false},"created":"2011-03-11T23:18:59.071+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":["1","failed","file","log4j","reduce","single","small","tiny"],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"1.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12314045","id":"12314045","description":"","name":"0.21.0","archived":false,"released":true,"releaseDate":"2010-08-23"}],"issuelinks":[],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2014-07-17T15:22:59.230+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[],"timeoriginalestimate":null,"description":"If i run the wordcount example on 1 small (less than 2MB) file i get the following error:\n\nlog4j:ERROR Failed to flush writer,\njava.io.InterruptedIOException\n        at java.io.FileOutputStream.writeBytes(Native Method)\n        at java.io.FileOutputStream.write(FileOutputStream.java:260)\n        at sun.nio.cs.StreamEncoder.writeBytes(StreamEncoder.java:202)\n        at sun.nio.cs.StreamEncoder.implFlushBuffer(StreamEncoder.java:272)\n        at sun.nio.cs.StreamEncoder.implFlush(StreamEncoder.java:276)\n        at sun.nio.cs.StreamEncoder.flush(StreamEncoder.java:122)\n        at java.io.OutputStreamWriter.flush(OutputStreamWriter.java:212)\n        at org.apache.log4j.helpers.QuietWriter.flush(QuietWriter.java:58)\n        at org.apache.log4j.WriterAppender.subAppend(WriterAppender.java:316)\n        at org.apache.log4j.WriterAppender.append(WriterAppender.java:160)\n        at org.apache.hadoop.mapred.TaskLogAppender.append(TaskLogAppender.java:58)\n        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)\n        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)\n        at org.apache.log4j.Category.callAppenders(Category.java:206)\n        at org.apache.log4j.Category.forcedLog(Category.java:391)\n        at org.apache.log4j.Category.log(Category.java:856)\n        at org.apache.commons.logging.impl.Log4JLogger.info(Log4JLogger.java:199)\n        at org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler.freeHost(ShuffleScheduler.java:345)\n        at org.apache.hadoop.mapreduce.task.reduce.Fetcher.run(Fetcher.java:152)\n\n\nIf i run the wordcount test with 2 files, it works fine. \n\nI have actually repeated this with my own code. I am working on something that requires me to map/reduce a small file and I had to work around the problem by splitting the file into 2 1MB pieces for my job to run. \n\nAll our jobs that run on 1 single larger file (over 1GB) work flawlessly. I am not exactly sure the threshold, From the testing i have done it seems to be any file smaller than the default HDFS block size (64MB) Sometimes it seems random in the 5-64MB range. But its 100% for the 5MB and smaller files. \n\n\n","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12481619","id":"12481619","filename":"failed reduce task log.html","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=drizzt321","name":"drizzt321","key":"drizzt321","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Aaron Baff","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-06-06T20:38:51.433+0000","size":13874,"mimeType":"text/html","content":"https://issues.apache.org/jira/secure/attachment/12481619/failed+reduce+task+log.html"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"80992","customfield_12312823":null,"summary":"Reduce fails when running on 1 small file. ","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=simonbsd","name":"simonbsd","key":"simonbsd","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Simon Dircks","active":true,"timeZone":"Etc/UTC"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=simonbsd","name":"simonbsd","key":"simonbsd","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Simon Dircks","active":true,"timeZone":"Etc/UTC"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":"java version \"1.6.0_07\"\nDiablo Java(TM) SE Runtime Environment (build 1.6.0_07-b02)\nDiablo Java HotSpot(TM) 64-Bit Server VM (build 10.0-b23, mixed mode)\n","customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12501214/comment/13005896","id":"13005896","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=simonbsd","name":"simonbsd","key":"simonbsd","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Simon Dircks","active":true,"timeZone":"Etc/UTC"},"body":"To make a clarification the reduce fails and retrys untill the retry threshold is reached, and then the job fails. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=simonbsd","name":"simonbsd","key":"simonbsd","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Simon Dircks","active":true,"timeZone":"Etc/UTC"},"created":"2011-03-11T23:26:11.948+0000","updated":"2011-03-11T23:26:11.948+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12501214/comment/13045080","id":"13045080","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=drizzt321","name":"drizzt321","key":"drizzt321","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Aaron Baff","active":true,"timeZone":"America/Los_Angeles"},"body":"Log for a failed Reduce task that exhibits this behavior. In looking at the thread states of the remaining threads, it appears that the ShuffleSort has hit a deadlock, where for some reason the InterruptedIOException wasn't caught and so a Fetcher thread failed to complete normally. Not really sure why this might have occured, I'm not terribly familiar with the code base, although I'm wondering ifThis issue from log4j could be related https://issues.apache.org/bugzilla/show_bug.cgi?id=44157. This is fixed in 1.2.16 released on April 2010. Hadoop is still using 1.2.15.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=drizzt321","name":"drizzt321","key":"drizzt321","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Aaron Baff","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-06-06T20:38:51.460+0000","updated":"2011-06-06T20:38:51.460+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12501214/comment/13046118","id":"13046118","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=drizzt321","name":"drizzt321","key":"drizzt321","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Aaron Baff","active":true,"timeZone":"America/Los_Angeles"},"body":"Just tried out using log4j 1.2.16, and it solved the problem! So, Hadoop should look to move to the new version of log4j.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=drizzt321","name":"drizzt321","key":"drizzt321","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Aaron Baff","active":true,"timeZone":"America/Los_Angeles"},"created":"2011-06-08T18:17:22.090+0000","updated":"2011-06-08T18:17:22.090+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12501214/comment/14065026","id":"14065026","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=aw","name":"aw","key":"aw","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=aw&avatarId=23681","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=aw&avatarId=23681","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=aw&avatarId=23681","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=aw&avatarId=23681"},"displayName":"Allen Wittenauer","active":true,"timeZone":"America/Tijuana"},"body":"Closing this as 'cannot reproduce' as log4j has since been upgraded.  A few times, actually.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=aw","name":"aw","key":"aw","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=aw&avatarId=23681","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=aw&avatarId=23681","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=aw&avatarId=23681","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=aw&avatarId=23681"},"displayName":"Allen Wittenauer","active":true,"timeZone":"America/Tijuana"},"created":"2014-07-17T15:22:59.210+0000","updated":"2014-07-17T15:22:59.210+0000"}],"maxResults":4,"total":4,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/MAPREDUCE-2378/votes","votes":1,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i0e7lb:"}}