{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12380705","self":"https://issues.apache.org/jira/rest/api/2/issue/12380705","key":"MAPREDUCE-14","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310941","id":"12310941","key":"MAPREDUCE","name":"Hadoop Map/Reduce","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310941&avatarId=10096","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310941&avatarId=10096","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310941&avatarId=10096","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310941&avatarId=10096"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/8","id":"8","description":"The described issue is not actually a problem - it is as designed.","name":"Not A Problem"},"customfield_12312322":null,"customfield_12310220":"2007-10-18T18:44:58.178+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Sat Dec 31 08:56:15 UTC 2011","customfield_12310420":"148421","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_132589356158_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2011-12-31T08:56:15.407+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/MAPREDUCE-14/watchers","watchCount":2,"isWatching":false},"created":"2007-10-18T18:33:39.391+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[],"issuelinks":[],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2011-12-31T08:56:15.545+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[],"timeoriginalestimate":null,"description":"A job with 3600 tasks on a cluster of 1350 nodes (up 3 tasks per node) shows extensive map tasks failures because of connection timeouts at the end of the task (c++ application using pipes interface completed successfully)\nMore than 600 tasks failed, slowing down the job because of retries. Only a portion of the tasks fail because of the timeout issue, but they spawn other failures because retries and speculatively executed tasks cannot even get  a connection and fail just after a few seconds.\n\nJobTracker is running with 60 handlers. We allow up to 10 attempts for maps.\n\nI attach the log of a task failing because of timeout (which includes a thread dump), and the log of one task which could not start.\n\n2007-10-18 15:58:41,743 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=MAP, sessionId=\n2007-10-18 15:58:41,827 INFO org.apache.hadoop.mapred.MapTask: numReduceTasks: 3600\n2007-10-18 16:12:28,918 INFO org.apache.hadoop.util.NativeCodeLoader: Loaded the native-hadoop library\n2007-10-18 16:12:28,920 INFO org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library\n2007-10-18 17:43:00,785 INFO org.apache.hadoop.mapred.TaskRunner: Communication exception: java.net.SocketTimeoutException: timed out waiting for rpc response\n\tat org.apache.hadoop.ipc.Client.call(Client.java:484)\n\tat org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:184)\n\tat org.apache.hadoop.mapred.$Proxy0.statusUpdate(Unknown Source)\n\tat org.apache.hadoop.mapred.Task$1.run(Task.java:293)\n\tat java.lang.Thread.run(Thread.java:619)\n\n2007-10-18 17:44:03,833 INFO org.apache.hadoop.mapred.TaskRunner: Communication exception: java.net.SocketTimeoutException: timed out waiting for rpc response\n\tat org.apache.hadoop.ipc.Client.call(Client.java:484)\n\tat org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:184)\n\tat org.apache.hadoop.mapred.$Proxy0.statusUpdate(Unknown Source)\n\tat org.apache.hadoop.mapred.Task$1.run(Task.java:293)\n\tat java.lang.Thread.run(Thread.java:619)\n\n2007-10-18 17:45:06,838 INFO org.apache.hadoop.mapred.TaskRunner: Communication exception: java.net.SocketTimeoutException: timed out waiting for rpc response\n\tat org.apache.hadoop.ipc.Client.call(Client.java:484)\n\tat org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:184)\n\tat org.apache.hadoop.mapred.$Proxy0.statusUpdate(Unknown Source)\n\tat org.apache.hadoop.mapred.Task$1.run(Task.java:293)\n\tat java.lang.Thread.run(Thread.java:619)\n\n2007-10-18 17:45:40,258 INFO org.apache.hadoop.mapred.TaskRunner: Process Thread Dump: Communication exception\n8 active threads\nThread 13 (Comm thread for task_200710172336_0016_m_000071_0):\n  State: RUNNABLE\n  Blocked count: 0\n  Waited count: 4128\n  Stack:\n    sun.management.ThreadImpl.getThreadInfo0(Native Method)\n    sun.management.ThreadImpl.getThreadInfo(ThreadImpl.java:147)\n    sun.management.ThreadImpl.getThreadInfo(ThreadImpl.java:123)\n    org.apache.hadoop.util.ReflectionUtils.printThreadInfo(ReflectionUtils.java:114)\n    org.apache.hadoop.util.ReflectionUtils.logThreadInfo(ReflectionUtils.java:162)\n    org.apache.hadoop.mapred.Task$1.run(Task.java:315)\n    java.lang.Thread.run(Thread.java:619)\nThread 12 (org.apache.hadoop.dfs.DFSClient$LeaseChecker@141b571):\n  State: TIMED_WAITING\n  Blocked count: 0\n  Waited count: 6403\n  Stack:\n    java.lang.Thread.sleep(Native Method)\n    org.apache.hadoop.dfs.DFSClient$LeaseChecker.run(DFSClient.java:558)\n    java.lang.Thread.run(Thread.java:619)\nThread 9 (IPC Client connection to /127.0.0.1:49458):\n  State: RUNNABLE\n  Blocked count: 21\n  Waited count: 2063\n  Stack:\n    java.net.SocketInputStream.socketRead0(Native Method)\n    java.net.SocketInputStream.read(SocketInputStream.java:129)\n    java.io.FilterInputStream.read(FilterInputStream.java:116)\n    org.apache.hadoop.ipc.Client$Connection$1.read(Client.java:181)\n    java.io.BufferedInputStream.fill(BufferedInputStream.java:218)\n    java.io.BufferedInputStream.read(BufferedInputStream.java:237)\n    java.io.DataInputStream.readInt(DataInputStream.java:370)\n    org.apache.hadoop.ipc.Client$Connection.run(Client.java:258)\nThread 8 (org.apache.hadoop.io.ObjectWritable Connection Culler):\n  State: TIMED_WAITING\n  Blocked count: 0\n  Waited count: 6402\n  Stack:\n    java.lang.Thread.sleep(Native Method)\n    org.apache.hadoop.ipc.Client$ConnectionCuller.run(Client.java:404)\nThread 4 (Signal Dispatcher):\n  State: RUNNABLE\n  Blocked count: 0\n  Waited count: 0\n  Stack:\nThread 3 (Finalizer):\n  State: WAITING\n  Blocked count: 398\n  Waited count: 2270\n  Waiting on java.lang.ref.ReferenceQueue$Lock@c278b5\n  Stack:\n    java.lang.Object.wait(Native Method)\n    java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:116)\n    java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:132)\n    java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:159)\nThread 2 (Reference Handler):\n  State: WAITING\n  Blocked count: 257\n  Waited count: 2269\n  Waiting on java.lang.ref.Reference$Lock@1c66ec7\n  Stack:\n    java.lang.Object.wait(Native Method)\n    java.lang.Object.wait(Object.java:485)\n    java.lang.ref.Reference$ReferenceHandler.run(Reference.java:116)\nThread 1 (main):\n  State: RUNNABLE\n  Blocked count: 1\n  Waited count: 10\n  Stack:\n    java.io.FileInputStream.readBytes(Native Method)\n    java.io.FileInputStream.read(FileInputStream.java:199)\n    org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileInputStream.read(RawLocalFileSystem.java:105)\n    java.io.BufferedInputStream.fill(BufferedInputStream.java:218)\n    java.io.BufferedInputStream.read1(BufferedInputStream.java:258)\n    java.io.BufferedInputStream.read(BufferedInputStream.java:317)\n    java.io.DataInputStream.read(DataInputStream.java:132)\n    org.apache.hadoop.fs.FSInputChecker.readFully(FSInputChecker.java:378)\n    org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.readChunk(ChecksumFileSystem.java:200)\n    org.apache.hadoop.fs.FSInputChecker.readChecksumChunk(FSInputChecker.java:234)\n    org.apache.hadoop.fs.FSInputChecker.fill(FSInputChecker.java:176)\n    org.apache.hadoop.fs.FSInputChecker.read1(FSInputChecker.java:193)\n    org.apache.hadoop.fs.FSInputChecker.read(FSInputChecker.java:157)\n    org.apache.hadoop.fs.FSInputChecker.readFully(FSInputChecker.java:378)\n    org.apache.hadoop.fs.FSInputChecker.seek(FSInputChecker.java:359)\n    org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.seek(ChecksumFileSystem.java:254)\n    org.apache.hadoop.fs.FSDataInputStream.seek(FSDataInputStream.java:37)\n    org.apache.hadoop.io.SequenceFile$Reader.seek(SequenceFile.java:1793)\n    org.apache.hadoop.io.SequenceFile$Reader.(SequenceFile.java:1217)\n    org.apache.hadoop.io.SequenceFile$Reader.(SequenceFile.java:1142)\n\n2007-10-18 17:45:40,258 WARN org.apache.hadoop.mapred.TaskRunner: Last retry, killing task_200710172336_0016_m_000071_0\n\n\nLog of task that could not start:\n2007-10-18 17:43:55,766 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /127.0.0.1:53972. Already tried 1 time(s).\n2007-10-18 17:43:56,768 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /127.0.0.1:53972. Already tried 2 time(s).\n2007-10-18 17:43:57,770 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /127.0.0.1:53972. Already tried 3 time(s).\n2007-10-18 17:43:58,772 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /127.0.0.1:53972. Already tried 4 time(s).\n2007-10-18 17:43:59,774 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /127.0.0.1:53972. Already tried 5 time(s).\n2007-10-18 17:44:00,776 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /127.0.0.1:53972. Already tried 6 time(s).\n2007-10-18 17:44:01,778 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /127.0.0.1:53972. Already tried 7 time(s).\n2007-10-18 17:44:02,780 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /127.0.0.1:53972. Already tried 8 time(s).\n2007-10-18 17:44:03,783 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /127.0.0.1:53972. Already tried 9 time(s).\n2007-10-18 17:44:04,785 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /127.0.0.1:53972. Already tried 10 time(s).","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"107700","customfield_12312823":null,"summary":"extensive map tasks failures because of SocketTimeoutException during statusUpdate","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ckunz","name":"ckunz","key":"ckunz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Christian Kunz","active":true,"timeZone":"Etc/UTC"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ckunz","name":"ckunz","key":"ckunz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Christian Kunz","active":true,"timeZone":"Etc/UTC"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":"Oct 17 #718 nightly build with patches 2033 and 2048","customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12380705/comment/12536011","id":"12536011","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley","name":"owen.omalley","key":"owen.omalley","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=29697","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=29697","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=owen.omalley&avatarId=29697","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=owen.omalley&avatarId=29697"},"displayName":"Owen O'Malley","active":true,"timeZone":"America/Los_Angeles"},"body":"Christian, please try a build with hadoop-2070, which was committed last night. I suspect you are seeing the same problem.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=owen.omalley","name":"owen.omalley","key":"owen.omalley","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=owen.omalley&avatarId=29697","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=owen.omalley&avatarId=29697","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=owen.omalley&avatarId=29697","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=owen.omalley&avatarId=29697"},"displayName":"Owen O'Malley","active":true,"timeZone":"America/Los_Angeles"},"created":"2007-10-18T18:44:58.178+0000","updated":"2007-10-18T18:44:58.178+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12380705/comment/12536082","id":"12536082","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ckunz","name":"ckunz","key":"ckunz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Christian Kunz","active":true,"timeZone":"Etc/UTC"},"body":"Owen, I am not convinced that this is related to Hadoop-2070.\n\nAs a matter of fact, as far as I can see the original patch for HADOOP-1788 flushed the buffer when the application is done, but missed two cases: when the application does not use a java inputformat and when it gets aborted. That's why the first 3 out of 4 unit tests were successful; the 4th unit test does not use a java input format, therefore, it failed. I would have thought that without any flushing all unit tests would have failed.\n\nOur application uses a java inputformat and has the input flushed (it actually completes). Also the symptom of missing flushing is that the task it self times out.\n\nThe current issue seems to be related to bad communication between task and taskTracker. I checked the tasktracker log around the same time, and found that it was running out of threads \n\n2007-10-18 19:27:43,719 INFO org.mortbay.http.SocketListener: LOW ON THREADS ((40-40+0)<1) on SocketListener0@0.0.0.0:50060\n\n2007-10-18 19:27:44,432 INFO org.apache.hadoop.mapred.TaskTracker: task_200710172336_0016_m_000045_1 <status msg>\n2007-10-18 19:27:44,432 INFO org.apache.hadoop.mapred.TaskTracker: task_200710172336_0016_r_000889_1 <statusmsg> > reduce\n2007-10-18 19:27:44,437 INFO org.apache.hadoop.mapred.TaskTracker: task_200710172336_0016_r_003314_0 0.70760524% reduce > reduce\n2007-10-18 19:27:44,997 INFO org.apache.hadoop.mapred.TaskTracker: task_200710172336_0016_r_003312_0 0.6736239% reduce > reduce\n2007-10-18 19:27:45,430 INFO org.apache.hadoop.mapred.TaskTracker: task_200710172336_0016_m_001001_1 0<statusmsg>\n\n2007-10-18 19:27:45,498 WARN org.mortbay.http.SocketListener: OUT OF THREADS: SocketListener0@0.0.0.0:50060\n\n2007-10-18 19:27:47,436 INFO org.apache.hadoop.mapred.TaskTracker: task_200710172336_0016_m_000045_1 <statusmsg>\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ckunz","name":"ckunz","key":"ckunz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Christian Kunz","active":true,"timeZone":"Etc/UTC"},"created":"2007-10-19T00:18:47.332+0000","updated":"2007-10-19T00:18:47.332+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12380705/comment/12536390","id":"12536390","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ckunz","name":"ckunz","key":"ckunz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Christian Kunz","active":true,"timeZone":"Etc/UTC"},"body":"With input from Owen and Devaraj, I will try to use less jetty threads to reduce contention and see whether this helps","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ckunz","name":"ckunz","key":"ckunz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Christian Kunz","active":true,"timeZone":"Etc/UTC"},"created":"2007-10-20T02:26:26.804+0000","updated":"2007-10-20T02:26:26.804+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12380705/comment/12539627","id":"12539627","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ckunz","name":"ckunz","key":"ckunz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Christian Kunz","active":true,"timeZone":"Etc/UTC"},"body":"Even with 30 jetty threads (instead of default 40) this still happens frequently, generating a very long tail for the job. I noticed that during that time the nodes running map tasks are disk bound.\nI will now try with 20 jetty threads, but the protocol between Task and TaskTracker should be fixed to use retries.\nI make this a blocker because it slows us down tremendously.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ckunz","name":"ckunz","key":"ckunz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Christian Kunz","active":true,"timeZone":"Etc/UTC"},"created":"2007-11-02T16:15:02.977+0000","updated":"2007-11-02T16:15:02.977+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12380705/comment/12539742","id":"12539742","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ckunz","name":"ckunz","key":"ckunz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Christian Kunz","active":true,"timeZone":"Etc/UTC"},"body":"I looked at the system resources during the time a node exhibits the timeout problem. At the end of the map phase, nodes which are just  finishing the map tasks (probably merging the output taking of the order of  an hour in our case such that there is a good chance that all of the map tasks do the merging at the same time), with reduce tasks already fetching remote map output, can be completely overwhelmed (load factor > 10, several processes running at relatively high CPU, and some disks at high utilization with at least one at 100%). No wonder that we get socket timeouts.\n\nChanging tasks to do retries when there are socket connection timeouts would  only be a bandaid. Rather, the taskTracker should monitor system resources and throttle the reduce tasks (maybe even the map tasks) during contention.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ckunz","name":"ckunz","key":"ckunz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Christian Kunz","active":true,"timeZone":"Etc/UTC"},"created":"2007-11-02T23:20:13.496+0000","updated":"2007-11-02T23:20:13.496+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12380705/comment/12540089","id":"12540089","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=devaraj","name":"devaraj","key":"devaraj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Devaraj Das","active":true,"timeZone":"Pacific/Pitcairn"},"body":"Christian, for this job, could you please set the tasks per node to 2 and see whether it improves the situation?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=devaraj","name":"devaraj","key":"devaraj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Devaraj Das","active":true,"timeZone":"Pacific/Pitcairn"},"created":"2007-11-04T18:42:40.593+0000","updated":"2007-11-04T18:42:40.593+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12380705/comment/12540257","id":"12540257","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ckunz","name":"ckunz","key":"ckunz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Christian Kunz","active":true,"timeZone":"Etc/UTC"},"body":"A couple of days ago, I ran the job successfully with 20 (instead of 30) jetty threads (although with some long tail because of the socket connection timeouts).\nTo save time I would like to not repeat the job as this time, because we made some progress in a batch of jobs and are further down the line.\nOnce we hit the problem again (requires a job with some substantial intermediate output), I will try your suggestion.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ckunz","name":"ckunz","key":"ckunz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Christian Kunz","active":true,"timeZone":"Etc/UTC"},"created":"2007-11-05T19:35:20.801+0000","updated":"2007-11-05T19:35:20.801+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12380705/comment/12541701","id":"12541701","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=devaraj","name":"devaraj","key":"devaraj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Devaraj Das","active":true,"timeZone":"Pacific/Pitcairn"},"body":"Some thoughts : if we have the thing about monitoring/throttling tasks, we can have the monitoring in place for the running tasks and based on the load on system resources the tasktracker can ask for a new task or not (as part of the heartbeat). However, for your case (and for tasktracker running long running tasks in general), this may or may not work since the system goes into that state towards the middle of the tasks' lives. So, the option is to kill some currently running task(s) or to reduce the (nice) priority of some. This runtime tuning can be made an optional feature since it might adversely affect the performance of some jobs (since in this approach we speculate/analyze, etc.).\n\nThe other option, as I commented on earlier, is to control the number of running tasks for a job on a tasktracker. That can be configured by the user (and this affects whether a new task for that job is assigned to a tasktracker or not, when the latter asks for a new task). The runtime tuning is probably the best approach, but this is a simpler one and should generally help (and maybe we can implement both).\n\nThoughts?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=devaraj","name":"devaraj","key":"devaraj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Devaraj Das","active":true,"timeZone":"Pacific/Pitcairn"},"created":"2007-11-12T07:58:06.436+0000","updated":"2007-11-12T07:58:06.436+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12380705/comment/12541849","id":"12541849","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ckunz","name":"ckunz","key":"ckunz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Christian Kunz","active":true,"timeZone":"Etc/UTC"},"body":"We changed the max number of tasks per node to 2, but currently scaling issues with the namenode are obscuring this issue here (also, we still run with 20 jetty threads).\n\nIt would be nice if the user was not forced to reduce the number of tasks when the node resources could handle as many simultaneous applications as CPU's, but not the post-processing inside the infrastructure (simultaneous merging of map tasks and remote fetching by reduce tasks). Would it be possible to optionally let the reduce tasks hold off fetching for a while when the map tasks do the final merge and/or serialize the final merge of map tasks, but do it only when resource contention is detected?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ckunz","name":"ckunz","key":"ckunz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Christian Kunz","active":true,"timeZone":"Etc/UTC"},"created":"2007-11-12T17:06:36.845+0000","updated":"2007-11-12T17:06:36.845+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12380705/comment/12542068","id":"12542068","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=devaraj","name":"devaraj","key":"devaraj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Devaraj Das","active":true,"timeZone":"Pacific/Pitcairn"},"body":"Christian, since this issue doesn't break anything and, as you pointed out, things work with a different configuration, I think that we should downgrade the Priority to 'Major'. The fix for this issue seems to involve quite a lot of benchmarking work and IMO should not block a release.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=devaraj","name":"devaraj","key":"devaraj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Devaraj Das","active":true,"timeZone":"Pacific/Pitcairn"},"created":"2007-11-13T08:37:23.206+0000","updated":"2007-11-13T08:37:23.206+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12380705/comment/12542260","id":"12542260","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=nidaley","name":"nidaley","key":"nidaley","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Nigel Daley","active":true,"timeZone":"Etc/UTC"},"body":"Determined to not be a blocker.  Assigning to 0.16","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=nidaley","name":"nidaley","key":"nidaley","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Nigel Daley","active":true,"timeZone":"Etc/UTC"},"created":"2007-11-13T22:41:30.962+0000","updated":"2007-11-13T22:41:30.962+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12380705/comment/12542283","id":"12542283","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ckunz","name":"ckunz","key":"ckunz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Christian Kunz","active":true,"timeZone":"Etc/UTC"},"body":"My apologies for late response.\nWill try to get by with using more mappers producing less output.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ckunz","name":"ckunz","key":"ckunz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Christian Kunz","active":true,"timeZone":"Etc/UTC"},"created":"2007-11-13T23:42:36.217+0000","updated":"2007-11-13T23:42:36.217+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12380705/comment/13177929","id":"13177929","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=qwertymaniac","name":"qwertymaniac","key":"qwertymaniac","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=qwertymaniac&avatarId=16780","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=qwertymaniac&avatarId=16780","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=qwertymaniac&avatarId=16780","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=qwertymaniac&avatarId=16780"},"displayName":"Harsh J","active":true,"timeZone":"Asia/Kolkata"},"body":"Haven't seen this occur with any of recent versions, having also seen jobs with more tasks than was reported here. Works just fine.\n\nLooked to be a user issue, here.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=qwertymaniac","name":"qwertymaniac","key":"qwertymaniac","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=qwertymaniac&avatarId=16780","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=qwertymaniac&avatarId=16780","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=qwertymaniac&avatarId=16780","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=qwertymaniac&avatarId=16780"},"displayName":"Harsh J","active":true,"timeZone":"Asia/Kolkata"},"created":"2011-12-31T08:56:15.461+0000","updated":"2011-12-31T08:56:15.461+0000"}],"maxResults":13,"total":13,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/MAPREDUCE-14/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i0isfj:"}}