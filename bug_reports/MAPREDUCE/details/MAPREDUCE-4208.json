{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12553245","self":"https://issues.apache.org/jira/rest/api/2/issue/12553245","key":"MAPREDUCE-4208","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310941","id":"12310941","key":"MAPREDUCE","name":"Hadoop Map/Reduce","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310941&avatarId=10096","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310941&avatarId=10096","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310941&avatarId=10096","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310941&avatarId=10096"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/8","id":"8","description":"The described issue is not actually a problem - it is as designed.","name":"Not A Problem"},"customfield_12312322":null,"customfield_12310220":"2012-04-30T16:12:58.107+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Fri May 04 15:24:52 UTC 2012","customfield_12310420":"237344","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_533709399_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2012-05-04T15:25:20.126+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/MAPREDUCE-4208/watchers","watchCount":3,"isWatching":false},"created":"2012-04-28T11:10:10.760+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[],"issuelinks":[],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2012-05-04T15:25:20.144+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[],"timeoriginalestimate":null,"description":"I use the hive MR query on hbase,but the job is never end.\nThe job is hanging but never continuing util you kill the child process \n\n\n2012-04-28 18:22:33,661 Stage-1 map = 0%,  reduce = 0%\n2012-04-28 18:22:59,760 Stage-1 map = 25%,  reduce = 0%\n2012-04-28 18:23:04,782 Stage-1 map = 38%,  reduce = 0%\n2012-04-28 18:23:07,796 Stage-1 map = 50%,  reduce = 0%\n2012-04-28 18:23:08,801 Stage-1 map = 50%,  reduce = 8%\n2012-04-28 18:23:17,839 Stage-1 map = 50%,  reduce = 17%\n2012-04-28 18:23:19,848 Stage-1 map = 63%,  reduce = 17%\n2012-04-28 18:23:32,909 Stage-1 map = 63%,  reduce = 21%\n2012-04-28 18:23:57,017 Stage-1 map = 75%,  reduce = 21%\n2012-04-28 18:24:09,075 Stage-1 map = 75%,  reduce = 25%\n2012-04-28 18:25:09,397 Stage-1 map = 75%,  reduce = 25%\n2012-04-28 18:26:09,688 Stage-1 map = 75%,  reduce = 25%\n2012-04-28 18:27:09,980 Stage-1 map = 75%,  reduce = 25%\n2012-04-28 18:28:10,262 Stage-1 map = 75%,  reduce = 25%\n2012-04-28 18:29:10,522 Stage-1 map = 75%,  reduce = 25%\n2012-04-28 18:30:10,742 Stage-1 map = 75%,  reduce = 25%\n2012-04-28 18:31:10,985 Stage-1 map = 75%,  reduce = 25%\n2012-04-28 18:32:11,238 Stage-1 map = 75%,  reduce = 25%\n2012-04-28 18:33:11,467 Stage-1 map = 75%,  reduce = 25%\n2012-04-28 18:34:11,731 Stage-1 map = 75%,  reduce = 25%\n2012-04-28 18:35:11,968 Stage-1 map = 75%,  reduce = 25%\n2012-04-28 18:36:12,213 Stage-1 map = 75%,  reduce = 25%\n2012-04-28 18:37:12,508 Stage-1 map = 75%,  reduce = 25%\n2012-04-28 18:38:12,747 Stage-1 map = 75%,  reduce = 25%\n2012-04-28 18:39:12,970 Stage-1 map = 75%,  reduce = 25%\n2012-04-28 18:40:13,205 Stage-1 map = 75%,  reduce = 25%\n\nI checked the TT log,\n\n2012-04-28 18:31:53,879 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%\n2012-04-28 18:31:56,883 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%\n2012-04-28 18:31:59,887 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%\n2012-04-28 18:32:02,892 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%\n2012-04-28 18:32:05,897 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%\n2012-04-28 18:32:08,902 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%\n2012-04-28 18:32:11,906 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%\n2012-04-28 18:32:14,910 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%\n2012-04-28 18:32:17,915 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%\n2012-04-28 18:32:20,920 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%\n2012-04-28 18:32:23,924 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%\n2012-04-28 18:32:26,929 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%\n2012-04-28 18:32:29,934 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%\n2012-04-28 18:32:32,938 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%\n2012-04-28 18:32:35,943 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%\n2012-04-28 18:32:38,948 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%\n2012-04-28 18:32:41,953 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%\n2012-04-28 18:32:44,957 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%\n2012-04-28 18:32:47,961 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%\n2012-04-28 18:32:50,966 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%\n2012-04-28 18:32:53,970 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%\n2012-04-28 18:32:56,974 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%\n2012-04-28 18:32:59,979 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%\n2012-04-28 18:33:02,983 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%\n2012-04-28 18:33:05,987 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%\n2012-04-28 18:33:08,992 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%\n2012-04-28 18:33:11,997 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%\n2012-04-28 18:33:15,001 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%\n2012-04-28 18:33:18,006 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%\n2012-04-28 18:33:21,011 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%\n2012-04-28 18:33:24,015 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%\n2012-04-28 18:33:27,020 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%\n2012-04-28 18:33:30,025 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%\n2012-04-28 18:33:33,029 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%\n2012-04-28 18:33:36,034 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%\n2012-04-28 18:33:39,038 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%\n2012-04-28 18:33:42,043 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%\n2012-04-28 18:33:45,047 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%\n2012-04-28 18:33:48,051 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%\n2012-04-28 18:33:51,057 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%\n2012-04-28 18:33:54,062 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%\n\n\n\n\n[hadoop@mem1 logs]$ jps\n3282 Child\n31547 QuorumPeerMain\n1840 TaskTracker\n3469 Jps\n31070 HRegionServer\n30120 DataNode\n\n\n[hadoop@mem1 logs]$  kill 3282\n\nWhen I kill the child process , then the job continue and complete.\n\n2012-04-28 18:40:51,324 Stage-1 map = 88%,  reduce = 25%\n2012-04-28 18:41:04,364 Stage-1 map = 88%,  reduce = 29%\n2012-04-28 18:41:31,448 Stage-1 map = 100%,  reduce = 29%\n2012-04-28 18:41:43,485 Stage-1 map = 100%,  reduce = 100%","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"112811","customfield_12312823":null,"summary":"The job is hanging up but never continuing until you kill the child process ","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rzhzhz","name":"rzhzhz","key":"rzhzhz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ccw","active":true,"timeZone":"Etc/UTC"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rzhzhz","name":"rzhzhz","key":"rzhzhz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ccw","active":true,"timeZone":"Etc/UTC"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":"Hadoop 0.20.203.0\nHbase 0.90.3\nHive 0.80.1","customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12553245/comment/13265002","id":"13265002","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=revans2","name":"revans2","key":"revans2","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Robert Joseph Evans","active":true,"timeZone":"America/Chicago"},"body":"ccw,\n\nWithout a heap dump, a stack trace, or even process logs for the hung process I am not really sure what more we can do but tell you that it looks like it was an intermittent issue, because it recovered after rerunning the task.  The task should have timed out after a default of 10 mins with no progress being made, but I don’t know if you disabled that, or if there is something the mr code is doing to prevent it.  If you can post some of that information to this JIRA we might be able to help, otherwise I think we will have to close this as Incomplete.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=revans2","name":"revans2","key":"revans2","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Robert Joseph Evans","active":true,"timeZone":"America/Chicago"},"created":"2012-04-30T16:12:58.107+0000","updated":"2012-04-30T16:12:58.107+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12553245/comment/13265859","id":"13265859","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rzhzhz","name":"rzhzhz","key":"rzhzhz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ccw","active":true,"timeZone":"Etc/UTC"},"body":"OK，I will try to reproduce this problem and tell you more message about it tomorrow.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rzhzhz","name":"rzhzhz","key":"rzhzhz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ccw","active":true,"timeZone":"Etc/UTC"},"created":"2012-05-01T15:21:47.017+0000","updated":"2012-05-01T15:21:47.017+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12553245/comment/13266360","id":"13266360","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rzhzhz","name":"rzhzhz","key":"rzhzhz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ccw","active":true,"timeZone":"Etc/UTC"},"body":"I checkd all logs,but there is no error .I want to know why each job encounter this problem until I kill one or more child process. I set the property 'mapred.task.timeout' ,but it is unhelpful for this.  I know the child task is not dead , but also it never work. It is terrible that every time I need to kill the hanging task.I think  it need to be controlled by JT or TT.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rzhzhz","name":"rzhzhz","key":"rzhzhz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ccw","active":true,"timeZone":"Etc/UTC"},"created":"2012-05-02T05:44:04.350+0000","updated":"2012-05-02T05:44:04.350+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12553245/comment/13267483","id":"13267483","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=revans2","name":"revans2","key":"revans2","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Robert Joseph Evans","active":true,"timeZone":"America/Chicago"},"body":"So have you been able to reproduce it?  I also think that it is a really bad bug that I want to fix, but I don't know where to start debugging it without more information about how it happened.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=revans2","name":"revans2","key":"revans2","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Robert Joseph Evans","active":true,"timeZone":"America/Chicago"},"created":"2012-05-03T14:57:29.463+0000","updated":"2012-05-03T14:57:29.463+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12553245/comment/13268065","id":"13268065","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rzhzhz","name":"rzhzhz","key":"rzhzhz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ccw","active":true,"timeZone":"Etc/UTC"},"body":"Thank you! I found the cause of the problem . The fundamental reason is that data access of Hbase . Because the data(region server) of map task is not on local region server ,so each data access is very slow .\nBut I think there must be a timeout mechanism to prevent the occurrence of such events. If a task is running too slow ,Hadoop should automatically kill the task rather than manually kill.\nThank you!","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rzhzhz","name":"rzhzhz","key":"rzhzhz","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"ccw","active":true,"timeZone":"Etc/UTC"},"created":"2012-05-04T03:09:02.572+0000","updated":"2012-05-04T03:09:02.572+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12553245/comment/13268104","id":"13268104","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xieguiming","name":"xieguiming","key":"xieguiming","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=xieguiming&avatarId=14331","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=xieguiming&avatarId=14331","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=xieguiming&avatarId=14331","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=xieguiming&avatarId=14331"},"displayName":"xieguiming","active":true,"timeZone":"Etc/UTC"},"body":"Hi ccw:\n whether the speculative is on? and the speculative is useful for your scenario?\n\nI think that the timeout mechanism is not good. because that the service will spend \n\nlong time indeed.\n\nso, if kill the task by timeout mechanism, and the job is failed in fact.\nand is the same with killing the job.\n\n\nso, I suggest that it is suitable for user's application to kill the job when the job does not complete for long time.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=xieguiming","name":"xieguiming","key":"xieguiming","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=xieguiming&avatarId=14331","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=xieguiming&avatarId=14331","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=xieguiming&avatarId=14331","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=xieguiming&avatarId=14331"},"displayName":"xieguiming","active":true,"timeZone":"Etc/UTC"},"created":"2012-05-04T04:07:03.593+0000","updated":"2012-05-04T04:07:03.593+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12553245/comment/13268447","id":"13268447","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=revans2","name":"revans2","key":"revans2","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Robert Joseph Evans","active":true,"timeZone":"America/Chicago"},"body":"There are two types of timeouts that happen for a task.  The first is a user configurable timeout with a default of 10 min.  If a task does not make any progress for 10 min then the task will timeout.  Progress is defined as reading a record of input, writing a record of output, or explicitly in your map/reduce code calling a method in the Context to indicate that you are still making progress. \n\nThe other timeout is that if your task does not heartbeat into the AM for 5 min the task is assumed to be dead.\n\nIn your case you are still making progress, it is just very slow, so neither of the timeouts would take place.  You could possible set the progress interval to be something very small and that would probably detect the problem.  We do not want to change the default value for the progress interval because there are lots of jobs that may be doing significant amounts of computation for each record, and we don't want to kill them off.\n\nmapreduce.task.timeout is the timeout you would want to configure.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=revans2","name":"revans2","key":"revans2","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Robert Joseph Evans","active":true,"timeZone":"America/Chicago"},"created":"2012-05-04T15:24:52.873+0000","updated":"2012-05-04T15:24:52.873+0000"}],"maxResults":7,"total":7,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/MAPREDUCE-4208/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i0jnyf:"}}