{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12464170","self":"https://issues.apache.org/jira/rest/api/2/issue/12464170","key":"MAPREDUCE-1781","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310941","id":"12310941","key":"MAPREDUCE","name":"Hadoop Map/Reduce","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310941&avatarId=10096","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310941&avatarId=10096","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310941&avatarId=10096","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310941&avatarId=10096"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/6","id":"6","description":"The problem isn't valid and it can't be fixed.","name":"Invalid"},"customfield_12312322":null,"customfield_12310220":"2010-05-11T01:55:59.167+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Wed Jun 09 05:11:26 UTC 2010","customfield_12310420":"149752","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_2541234422_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2010-06-09T05:11:26.813+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/MAPREDUCE-1781/watchers","watchCount":3,"isWatching":false},"created":"2010-05-10T19:17:32.391+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12310230":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12314205","id":"12314205","description":"","name":"0.20.2","archived":false,"released":true,"releaseDate":"2010-02-16"}],"issuelinks":[],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2010-06-09T05:11:26.800+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12312905","id":"12312905","name":"contrib/streaming"}],"timeoriginalestimate":null,"description":"Hello\n\nI am a new user of Hadoop and I have some trouble using Hadoop Streaming and the \"-D mapred.tasktracker.map.tasks.maximum\" option. \n\nI'm experimenting with an unmanaged application (C++) which I want to run over several nodes in 2 scenarios\n1) the number of maps (input splits) is equal to the number of nodes\n2) the number of maps is a multiple of the number of nodes (5, 10, 20, ...\n\nInitially, when running the tests in scenario 1 I would sometimes get 2 process/node on half the nodes. However I fixed this by adding the optin \"-D mapred.tasktracker.map.tasks.maximum=1\", so everything works fine.\n\nIn the case of scenario 2 (more maps than nodes) this directive no longer works, always obtaining 2 processes/node. I tested the even with putting maximum=5 and I still get 2 processes/node.\n\nThe entire command I use is:\n\n/usr/bin/time --format=\"-duration:\\t%e |\\t-MFaults:\\t%F |\\t-ContxtSwitch:\\t%w\" \\\n /opt/hadoop/bin/hadoop jar /opt/hadoop/contrib/streaming/hadoop-0.20.2-streaming.jar \\\n -D mapred.tasktracker.map.tasks.maximum=1 \\\n -D mapred.map.tasks=30 \\\n -D mapred.reduce.tasks=0 \\\n -D io.file.buffer.size=5242880 \\\n -libjars \"/opt/hadoop/contrib/streaming/hadoop-7debug.jar\" \\\n -input input/test \\\n -output out1 \\\n -mapper \"/opt/jobdata/script_1k\" \\\n -inputformat \"me.MyInputFormat\"\n\nWhy is this happening and how can I make it work properly (i.e. be able to limit exactly how many mappers I can have at 1 time per node)?\n\nThank you in advance","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"111752","customfield_12312823":null,"summary":"option \"-D mapred.tasktracker.map.tasks.maximum=1\" does not work when no of mappers is bigger than no of nodes - always spawns 2 mapers/node","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ctv","name":"ctv","key":"ctv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Tudor Vlad","active":true,"timeZone":"Etc/UTC"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ctv","name":"ctv","key":"ctv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Tudor Vlad","active":true,"timeZone":"Etc/UTC"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":"Debian Lenny x64, and Hadoop 0.20.2, 2GB RAM","customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12464170/comment/12866020","id":"12866020","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yhemanth","name":"yhemanth","key":"yhemanth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hemanth Yamijala","active":true,"timeZone":"Asia/Kolkata"},"body":"mapred.tasktracker.map.tasks.maximum is a startup configuration parameter and cannot be modified per job. Even in your first scenario (where it seemed to work), I am guessing that the system started running 1 map per node because of scheduling decisions and not because the tasktrackers were configured to run with only 1 task per node.\n\nbq. Why is this happening and how can I make it work properly (i.e. be able to limit exactly how many mappers I can have at 1 time per node)?\n\nCan  you provide some more details of why you want to limit a job to use only one mapper at a time on a node ?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yhemanth","name":"yhemanth","key":"yhemanth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hemanth Yamijala","active":true,"timeZone":"Asia/Kolkata"},"created":"2010-05-11T01:55:59.167+0000","updated":"2010-05-11T01:55:59.167+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12464170/comment/12866309","id":"12866309","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ctv","name":"ctv","key":"ctv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Tudor Vlad","active":true,"timeZone":"Etc/UTC"},"body":"Thank you, I put the option in the config file and from the preliminary test it works as I intended.\n\nThe reason I am using only 1 mapper/node at 1 time is because I am testing the parallelization efficiency of a highly-CPU and memory bound application over Hadoop, focusing on the parallelization via distributed computing, not multicore. \nAdditionally, I will use more splits scenarious (different approx of a multiple of the no of nodes) on a heterogenous datacenter in order to determine a good input split size (and also how many nodes might be necessary to keep the scalability efficiency over 0.8). The application time is approx linear with the input size but has poor performance if the input is too small (I'm trying to find the exact point).\n\nIn real-life scenarious I will use Hadoop with every resourse it has. However I have a question here: what if the cluster is highly heterogenous and I have both single-cores, dual-cores, dual processors with dual cores, quads, .... - is it possible to specify that I want 4 mappers/processors or am I limited to a static value at the startup of Hadoop?\n\nRegarding the initial problem, I think it would help a lot of people (especially new users) to specify in the config page[ http://hadoop.apache.org/common/docs/current/mapred-default.html ] which parameters are set at startup and which at job runtime.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ctv","name":"ctv","key":"ctv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Tudor Vlad","active":true,"timeZone":"Etc/UTC"},"created":"2010-05-11T20:16:46.633+0000","updated":"2010-05-11T20:16:46.633+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12464170/comment/12867205","id":"12867205","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yhemanth","name":"yhemanth","key":"yhemanth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hemanth Yamijala","active":true,"timeZone":"Asia/Kolkata"},"body":"bq. - is it possible to specify that I want 4 mappers/processors or am I limited to a static value at the startup of Hadoop?\n\nThe configuration per tasktracker can be different for each node, in general. However, that makes managing configurations much harder. Does that work for you now though ?\n\nbq. which parameters are set at startup and which at job runtime.\n\nOK. Possibly you should file a JIRA asking for this to be explained. But the general rule of thumb is that configurations whose names contain the names of daemons like 'tasktracker' will be start-up only parameters. Configurations whose names contain 'job' or 'task' can be overridden per job.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yhemanth","name":"yhemanth","key":"yhemanth","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hemanth Yamijala","active":true,"timeZone":"Asia/Kolkata"},"created":"2010-05-13T18:14:00.891+0000","updated":"2010-05-13T18:14:00.891+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12464170/comment/12876957","id":"12876957","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=amareshwari","name":"amareshwari","key":"amareshwari","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Amareshwari Sriramadasu","active":true,"timeZone":"Asia/Kolkata"},"body":"bq. Regarding the initial problem, I think it would help a lot of people (especially new users) to specify in the config page[ http://hadoop.apache.org/common/docs/current/mapred-default.html ] which parameters are set at startup and which at job runtime.\nIn branch 0.21, the configuration names are standardized through MAPREDUCE-849. The configuration names with prefix as mapreduce.cluster/mapreduce.jobtracker/mapreduce.tasktracker are server level configurations and need to be setup before the cluster is brought up. The other configurations with prefix mapreduce.job/mapreduce.task/mapreduce.map/mapreduce.reduce are job level configurations. \nDocumenting all of them in mapred-default is being tracked in MAPREDUCE-1021.\n\nClosing this as invalid.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=amareshwari","name":"amareshwari","key":"amareshwari","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Amareshwari Sriramadasu","active":true,"timeZone":"Asia/Kolkata"},"created":"2010-06-09T05:11:26.790+0000","updated":"2010-06-09T05:11:26.790+0000"}],"maxResults":4,"total":4,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/MAPREDUCE-1781/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i0jhf3:"}}