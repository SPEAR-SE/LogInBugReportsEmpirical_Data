{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12927988","self":"https://issues.apache.org/jira/rest/api/2/issue/12927988","key":"YARN-4549","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12313722","id":"12313722","key":"YARN","name":"Hadoop YARN","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12313722&avatarId=15135","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12313722&avatarId=15135","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12313722&avatarId=15135","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12313722&avatarId=15135"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/6","id":"6","description":"The problem isn't valid and it can't be fixed.","name":"Invalid"},"customfield_12312322":null,"customfield_12310220":"2016-01-06T16:11:21.371+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Fri Jan 08 15:47:05 UTC 2016","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_191242848_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2016-01-08T15:47:05.621+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/YARN-4549/watchers","watchCount":9,"isWatching":false},"created":"2016-01-06T10:39:42.824+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12331976","id":"12331976","description":"2.7.1 release","name":"2.7.1","archived":false,"released":true,"releaseDate":"2015-07-06"}],"issuelinks":[],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2016-01-08T15:47:05.670+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[],"timeoriginalestimate":null,"description":"We are running samza 0.8 on YARN 2.7.1 with {{LinuxContainerExecutor}} as the container-executor with cgroups configuration. Also we have NM recovery enabled.\n\nWe observe a lot of containers that get stuck in the KIILLING state after the NM tries to kill them. The container remains running indefinitely, this causes some duplication as new containers are brought up to replace them. Looking through the logs NM can't seem to get the container PID.\n\n{noformat}\n16/01/05 05:16:44 INFO containermanager.ContainerManagerImpl: Stopping container with container Id: container_1448454866800_0023_01_000005\n16/01/05 05:16:44 INFO nodemanager.NMAuditLogger: USER=ec2-user IP=10.51.111.243        OPERATION=Stop Container Request        TARGET=ContainerManageImpl      RESULT=SUCCESS  APPID=application_1448454866800_0023    CONTAINERID=container_1448454866800_0023_01_000005\n16/01/05 05:16:44 INFO container.ContainerImpl: Container container_1448454866800_0023_01_000005 transitioned from RUNNING to KILLING\n16/01/05 05:16:44 INFO launcher.ContainerLaunch: Cleaning up container container_1448454866800_0023_01_000005\n16/01/05 05:16:47 INFO launcher.ContainerLaunch: Could not get pid for container_1448454866800_0023_01_000005. Waited for 2000 ms.\n{noformat}\n\nThe PID files for containers in the KILLING state are missing, and a few other container that have been in the RUNNING state for a few weeks are also missing them.  We waren't able to consistently replicate this and hoping that someone has come across this before.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"Containers stuck in KILLING state","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=danil","name":"danil","key":"danil","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Danil Serdyuchenko","active":true,"timeZone":"Etc/UTC"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=danil","name":"danil","key":"danil","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Danil Serdyuchenko","active":true,"timeZone":"Etc/UTC"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12927988/comment/15085737","id":"15085737","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jlowe","name":"jlowe","key":"jlowe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jason Lowe","active":true,"timeZone":"America/Chicago"},"body":"Did the kill occur shortly after the container was started?  I'm wondering if the pid file somehow appeared _after_ the attempt to kill.  What does {{ls -l --full-time}} show for the pid file, and how does that correlate to the timestamps in the NM log?  Also just to verify it's in the right place, where is the pid file located relative to the yarn local directory root?\n\nYou mentioned NM recovery is enabled.  Does this only occur on containers that were recovered on NM startup or also for containers that are started and killed within the same NM session?\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jlowe","name":"jlowe","key":"jlowe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jason Lowe","active":true,"timeZone":"America/Chicago"},"created":"2016-01-06T16:11:21.371+0000","updated":"2016-01-06T16:11:21.371+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12927988/comment/15087217","id":"15087217","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=danil","name":"danil","key":"danil","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Danil Serdyuchenko","active":true,"timeZone":"Etc/UTC"},"body":"We did some more digging and found that a few containers that are currently in RUNNING state, are missing directories under {{nmPrivate}} dir. The web interface reports that the containers are running on that node and the container processes are there too, but we are missing the the entire application dir under {{nmPrivate}}.\n\n[~jlowe] This usually happens to long running containers. The PID files are missing for containers in KILLING state, and for certain RUNNING containers. The pid file should be under {{nm-local-dir}}, for us it's: {{/tmp/hadoop-ec2-user/nm-local-dir/nmPrivate/<application_id>/<container_id>/<container_id>.pid}}.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=danil","name":"danil","key":"danil","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Danil Serdyuchenko","active":true,"timeZone":"Etc/UTC"},"created":"2016-01-07T11:14:19.165+0000","updated":"2016-01-07T11:14:19.165+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12927988/comment/15087548","id":"15087548","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jlowe","name":"jlowe","key":"jlowe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jason Lowe","active":true,"timeZone":"America/Chicago"},"body":"If this only happens to long-running containers and the pid files are missing for even RUNNING containers that have been up a while then I'm thinking something is coming along at some point and blowing away the pid files because they're too old.  Is there a tmp cleaner like tmpwatch or some other periodic maintenance process that could be cleaning up these \"old\" files?  A while back someone reported NM recovery issues because they were storing the NM leveldb state store files in /tmp and a tmp cleaner was periodically deleting some of the old leveldb files and corrupting the database.\n\nYou could also look in other areas under nmPrivate and see if some of the distributed cache directories have also been removed.  If that's the case then you should see messages like \"Resource XXX is missing, localizing it again\" in the NM logs as it tries to re-use a distcache entry but then discovers it's mysteriously missing from the local disk.  If whole directories have been reaped including the dist cache entries then it would strongly point to something like a periodic cleanup like tmpwatch or something similar.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jlowe","name":"jlowe","key":"jlowe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jason Lowe","active":true,"timeZone":"America/Chicago"},"created":"2016-01-07T15:10:30.159+0000","updated":"2016-01-07T15:10:30.159+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12927988/comment/15088981","id":"15088981","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=danil","name":"danil","key":"danil","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Danil Serdyuchenko","active":true,"timeZone":"Etc/UTC"},"body":"Yep, looks like we had tmpwatch delete all files older than 10 days. We have set the NM local-dirs to be outside of tmp. [~jlowe] thanks for your help. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=danil","name":"danil","key":"danil","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Danil Serdyuchenko","active":true,"timeZone":"Etc/UTC"},"created":"2016-01-08T09:51:56.194+0000","updated":"2016-01-08T09:51:56.194+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12927988/comment/15089376","id":"15089376","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jlowe","name":"jlowe","key":"jlowe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jason Lowe","active":true,"timeZone":"America/Chicago"},"body":"Glad to hear the cause was found!  Be sure to check that the NM state store is also stored outside of /tmp, or it too can become a victim of tmpwatch.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=jlowe","name":"jlowe","key":"jlowe","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Jason Lowe","active":true,"timeZone":"America/Chicago"},"created":"2016-01-08T15:47:05.657+0000","updated":"2016-01-08T15:47:05.657+0000"}],"maxResults":5,"total":5,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/YARN-4549/votes","votes":1,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i2qxev:"}}