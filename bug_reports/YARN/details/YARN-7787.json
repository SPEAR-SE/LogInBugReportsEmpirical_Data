{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"13132839","self":"https://issues.apache.org/jira/rest/api/2/issue/13132839","key":"YARN-7787","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12313722","id":"12313722","key":"YARN","name":"Hadoop YARN","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12313722&avatarId=15135","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12313722&avatarId=15135","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12313722&avatarId=15135","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12313722&avatarId=15135"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":"2018-01-25T22:14:42.464+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Thu Jan 25 22:14:42 UTC 2018","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/YARN-7787/watchers","watchCount":6,"isWatching":false},"created":"2018-01-22T19:24:56.879+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/2","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/critical.svg","name":"Critical","id":"2"},"labels":[],"customfield_12312333":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[],"issuelinks":[],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2018-01-25T22:14:42.464+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12331058","id":"12331058","name":"yarn-native-services"}],"timeoriginalestimate":null,"description":"Steps:\r\n\r\n1) update httpd.json by adding below block.\r\n{code:java}\r\n\"kerberos_principal\" : {\r\n    \"principal_name\" : \"hrt_qa@EXAMPLE.COM\",\r\n    \"keytab\" : \"file:///home/hrt_qa/hadoopqa/keytabs/hrt_qa.headless.keytab\"\r\n  }{code}\r\n2) Launch http example as hrt_qa user\r\n{code:java}\r\n2018-01-19 22:00:37,238|INFO|MainThread|machine.py:150 - run()||GUID=6b0714d0-1377-43ee-8959-9ae380e1486c|RUNNING: /usr/hdp/current/hadoop-yarn-client/bin/yarn app -launch httpd-hrt-qa httpd\r\n2018-01-19 22:00:37,295|INFO|WARNING: YARN_LOG_DIR has been replaced by HADOOP_LOG_DIR. Using value of YARN_LOG_DIR.\r\n2018-01-19 22:00:37,295|INFO|WARNING: YARN_LOGFILE has been replaced by HADOOP_LOGFILE. Using value of YARN_LOGFILE.\r\n2018-01-19 22:00:37,295|INFO|WARNING: YARN_PID_DIR has been replaced by HADOOP_PID_DIR. Using value of YARN_PID_DIR.\r\n2018-01-19 22:00:37,296|INFO|WARNING: YARN_OPTS has been replaced by HADOOP_OPTS. Using value of YARN_OPTS.\r\n2018-01-19 22:00:38,173|INFO|18/01/19 22:00:38 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\r\n2018-01-19 22:00:39,530|INFO|18/01/19 22:00:39 WARN shortcircuit.DomainSocketFactory: The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.\r\n2018-01-19 22:00:39,545|INFO|18/01/19 22:00:39 INFO client.ServiceClient: Loading service definition from local FS: /usr/hdp/3.0.0.0-xx/hadoop-yarn/yarn-service-examples/httpd/httpd.json\r\n2018-01-19 22:00:40,186|INFO|18/01/19 22:00:40 INFO client.ConfiguredRMFailoverProxyProvider: Failing over to rm2\r\n2018-01-19 22:00:40,492|INFO|18/01/19 22:00:40 INFO client.ServiceClient: Persisted service httpd-hrt-qa at hdfs://mycluster/user/hrt_qa/.yarn/services/httpd-hrt-qa/httpd-hrt-qa.json\r\n2018-01-19 22:00:40,589|INFO|18/01/19 22:00:40 INFO conf.Configuration: found resource resource-types.xml at file:/etc/hadoop/3.0.0.0-xx/0/resource-types.xml\r\n2018-01-19 22:00:40,719|INFO|18/01/19 22:00:40 INFO client.ServiceClient: Uploading all dependency jars to HDFS. For faster submission of apps, pre-upload dependency jars to HDFS using command: yarn app -enableFastLaunch\r\n2018-01-19 22:00:48,253|INFO|18/01/19 22:00:48 INFO hdfs.DFSClient: Created token for hrt_qa: HDFS_DELEGATION_TOKEN owner=hrt_qa@EXAMPLE.COM, renewer=yarn, realUser=, issueDate=1516399248244, maxDate=1517004048244, sequenceNumber=4, masterKeyId=4 on ha-hdfs:mycluster\r\n2018-01-19 22:00:49,463|INFO|18/01/19 22:00:49 INFO impl.YarnClientImpl: Submitted application application_1516398459631_0001{code}\r\n3) Run \"yarn application -status <appname>\"\r\n{code:java}\r\n2018-01-19 22:01:05,570|INFO|RUNNING: /usr/hdp/current/hadoop-yarn-client/bin/yarn application -status httpd-hrt-qa\r\n2018-01-19 22:01:05,626|INFO|WARNING: YARN_LOG_DIR has been replaced by HADOOP_LOG_DIR. Using value of YARN_LOG_DIR.\r\n2018-01-19 22:01:05,626|INFO|WARNING: YARN_LOGFILE has been replaced by HADOOP_LOGFILE. Using value of YARN_LOGFILE.\r\n2018-01-19 22:01:05,626|INFO|WARNING: YARN_PID_DIR has been replaced by HADOOP_PID_DIR. Using value of YARN_PID_DIR.\r\n2018-01-19 22:01:05,626|INFO|WARNING: YARN_OPTS has been replaced by HADOOP_OPTS. Using value of YARN_OPTS.\r\n2018-01-19 22:01:06,529|INFO|18/01/19 22:01:06 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\r\n2018-01-19 22:01:07,851|INFO|18/01/19 22:01:07 WARN shortcircuit.DomainSocketFactory: The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.\r\n2018-01-19 22:01:08,003|INFO|18/01/19 22:01:08 INFO utils.ServiceApiUtil: Loading service definition from hdfs://mycluster/user/hrt_qa/.yarn/services/httpd-hrt-qa/httpd-hrt-qa.json\r\n2018-01-19 22:01:08,563|INFO|18/01/19 22:01:08 INFO client.ConfiguredRMFailoverProxyProvider: Failing over to rm2\r\n2018-01-19 22:01:08,787|INFO|Exception in thread \"main\" java.io.IOException: Failed on local exception: java.io.IOException: Couldn't set up IO streams: java.lang.IllegalArgumentException: Kerberos principal name does NOT have the expected hostname part: hrt_qa@EXAMPLE.COM; Host Details : local host is: “host1/xx.xx.xx.xx\"; destination host is: “host1”:40318;\r\n2018-01-19 22:01:08,788|INFO|at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:808)\r\n2018-01-19 22:01:08,788|INFO|at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1495)\r\n2018-01-19 22:01:08,788|INFO|at org.apache.hadoop.ipc.Client.call(Client.java:1437)\r\n2018-01-19 22:01:08,788|INFO|at org.apache.hadoop.ipc.Client.call(Client.java:1347)\r\n2018-01-19 22:01:08,789|INFO|at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)\r\n2018-01-19 22:01:08,789|INFO|at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)\r\n2018-01-19 22:01:08,789|INFO|at com.sun.proxy.$Proxy40.getStatus(Unknown Source)\r\n2018-01-19 22:01:08,789|INFO|at org.apache.hadoop.yarn.service.impl.pb.client.ClientAMProtocolPBClientImpl.getStatus(ClientAMProtocolPBClientImpl.java:68)\r\n2018-01-19 22:01:08,789|INFO|at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n2018-01-19 22:01:08,789|INFO|at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n2018-01-19 22:01:08,790|INFO|at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n2018-01-19 22:01:08,790|INFO|at java.lang.reflect.Method.invoke(Method.java:498)\r\n2018-01-19 22:01:08,790|INFO|at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)\r\n2018-01-19 22:01:08,790|INFO|at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)\r\n2018-01-19 22:01:08,790|INFO|at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)\r\n2018-01-19 22:01:08,790|INFO|at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\r\n2018-01-19 22:01:08,791|INFO|at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)\r\n2018-01-19 22:01:08,791|INFO|at com.sun.proxy.$Proxy41.getStatus(Unknown Source)\r\n2018-01-19 22:01:08,791|INFO|at org.apache.hadoop.yarn.service.client.ServiceClient.getStatus(ServiceClient.java:958)\r\n2018-01-19 22:01:08,791|INFO|at org.apache.hadoop.yarn.service.client.ServiceClient.getStatusString(ServiceClient.java:910)\r\n2018-01-19 22:01:08,791|INFO|at org.apache.hadoop.yarn.client.cli.ApplicationCLI.run(ApplicationCLI.java:316)\r\n2018-01-19 22:01:08,791|INFO|at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)\r\n2018-01-19 22:01:08,792|INFO|at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:90)\r\n2018-01-19 22:01:08,792|INFO|at org.apache.hadoop.yarn.client.cli.ApplicationCLI.main(ApplicationCLI.java:111)\r\n2018-01-19 22:01:08,792|INFO|Caused by: java.io.IOException: Couldn't set up IO streams: java.lang.IllegalArgumentException: Kerberos principal name does NOT have the expected hostname part: hrt_qa@EXAMPLE.COM\r\n2018-01-19 22:01:08,792|INFO|at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:860)\r\n2018-01-19 22:01:08,792|INFO|at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)\r\n2018-01-19 22:01:08,792|INFO|at org.apache.hadoop.ipc.Client.getConnection(Client.java:1552)\r\n2018-01-19 22:01:08,793|INFO|at org.apache.hadoop.ipc.Client.call(Client.java:1383)\r\n2018-01-19 22:01:08,793|INFO|... 21 more\r\n2018-01-19 22:01:08,793|INFO|Caused by: java.lang.IllegalArgumentException: Kerberos principal name does NOT have the expected hostname part: hrt_qa@EXAMPLE.COM\r\n2018-01-19 22:01:08,793|INFO|at org.apache.hadoop.security.SaslRpcClient.getServerPrincipal(SaslRpcClient.java:332)\r\n2018-01-19 22:01:08,793|INFO|at org.apache.hadoop.security.SaslRpcClient.createSaslClient(SaslRpcClient.java:234)\r\n2018-01-19 22:01:08,793|INFO|at org.apache.hadoop.security.SaslRpcClient.selectSaslClient(SaslRpcClient.java:160)\r\n2018-01-19 22:01:08,794|INFO|at org.apache.hadoop.security.SaslRpcClient.saslConnect(SaslRpcClient.java:390)\r\n2018-01-19 22:01:08,794|INFO|at org.apache.hadoop.ipc.Client$Connection.setupSaslConnection(Client.java:613)\r\n2018-01-19 22:01:08,794|INFO|at org.apache.hadoop.ipc.Client$Connection.access$2200(Client.java:409)\r\n2018-01-19 22:01:08,794|INFO|at org.apache.hadoop.ipc.Client$Connection$2.run(Client.java:798)\r\n2018-01-19 22:01:08,795|INFO|at org.apache.hadoop.ipc.Client$Connection$2.run(Client.java:794)\r\n2018-01-19 22:01:08,795|INFO|at java.security.AccessController.doPrivileged(Native Method)\r\n2018-01-19 22:01:08,795|INFO|at javax.security.auth.Subject.doAs(Subject.java:422)\r\n2018-01-19 22:01:08,795|INFO|at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1965)\r\n2018-01-19 22:01:08,795|INFO|at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:794)\r\n2018-01-19 22:01:08,795|INFO|... 24 more\r\n{code}\r\nyarn application -status should not fail with \"java.lang.IllegalArgumentException: Kerberos principal name does NOT have the expected hostname part: hrt_qa@EXAMPLE.COM\".\r\n It should accept the principal name without hostname.\r\n\r\n ","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"Yarn service can not be launched with User Principal","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yeshavora","name":"yeshavora","key":"yeshavora","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10436","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10436","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10436","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10436"},"displayName":"Yesha Vora","active":true,"timeZone":"Etc/UTC"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yeshavora","name":"yeshavora","key":"yeshavora","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10436","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10436","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10436","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10436"},"displayName":"Yesha Vora","active":true,"timeZone":"Etc/UTC"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/13132839/comment/16340186","id":"16340186","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=eyang","name":"eyang","key":"eyang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eric Yang","active":true,"timeZone":"America/Los_Angeles"},"body":"YARN Service code contains one implementation of ApplicationMaster code that extends \r\n\r\norg.apache.hadoop.service.AbstractService.  AM's responsibility is to report service status, and other application logic.  Hadoop RPC setup by ApplicationMaster must follow basic Hadoop security practice.  HADOOP-9698 added logic to make sure saslRPCClient verifies server side credential against list of configuration defined principal names.  The goal is to prevents men in middle attack or replay attack.  This is hard coded into Hadoop security design when service are statically deploy on cluster of nodes. \r\n\r\nTherefore, user must use server principal in Yarn Service to launch YARN service:\r\n{code:java}\r\n  \"kerberos_principal\" : {\r\n    \"principal_name\" : \"hbase/_HOST@EXAMPLE.COM\",\r\n    \"keytab\" : \"file:///etc/security/keytabs/hbase.service.keytab\"\r\n  },{code}\r\n \r\n\r\nThis ticket is to discuss whether there is any wiggle room to relax security and allow end user principal to be used for starting service.  ApplicationMaster can run on any node in YARN cluster.  This security check seems cumbersome to generate a keytab that contains the proper server principals for ApplicationMaster.  In large scale cluster, using server principal is definitely preferred to prevent men-in-middle attack even within trusted security perimeter.  This request can have profound impact to Hadoop security design for sasl rpc client and worthy of discussion.  The alternative is to reimplement AM not base on Hadoop RPC, and new implementation needs to solve men-in-middle attack in other shape or forms.  It seems like a lot disadvantages to enable end user principal to run ApplicationMaster.  Thoughts?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=eyang","name":"eyang","key":"eyang","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Eric Yang","active":true,"timeZone":"America/Los_Angeles"},"created":"2018-01-25T22:14:42.464+0000","updated":"2018-01-25T22:14:42.464+0000"}],"maxResults":1,"total":1,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/YARN-7787/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i3p7nb:"}}