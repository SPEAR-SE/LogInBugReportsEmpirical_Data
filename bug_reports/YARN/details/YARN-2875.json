{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12756166","self":"https://issues.apache.org/jira/rest/api/2/issue/12756166","key":"YARN-2875","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12313722","id":"12313722","key":"YARN","name":"Hadoop YARN","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12313722&avatarId=15135","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12313722&avatarId=15135","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12313722&avatarId=15135","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12313722&avatarId=15135"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/3","id":"3","description":"The problem is a duplicate of an existing issue.","name":"Duplicate"},"customfield_12312322":null,"customfield_12310220":"2014-11-19T09:56:55.261+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Fri May 01 18:50:34 UTC 2015","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_14172179298_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2015-05-01T18:50:34.814+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/YARN-2875/watchers","watchCount":4,"isWatching":false},"created":"2014-11-18T18:07:35.601+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/4","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/minor.svg","name":"Minor","id":"4"},"labels":[],"customfield_12312333":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[],"issuelinks":[{"id":"12401701","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12401701","type":{"id":"10001","name":"dependent","inward":"is depended upon by","outward":"depends upon","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10001"},"outwardIssue":{"id":"12756354","key":"HADOOP-11317","self":"https://issues.apache.org/jira/rest/api/2/issue/12756354","fields":{"summary":"Increment SLF4J version to 1.7.10","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/7","id":"7","description":"The sub-task of the issue","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype","name":"Sub-task","subtask":true,"avatarId":21146}}}}],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2015-05-01T18:50:34.887+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[],"timeoriginalestimate":null,"description":"hadoop-yarn-common [uses log4j directly|https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/pom.xml#L167] and when trying to redirect that through an SLF4J bridge version 1.7.5 has issues, due to use of AppenderSkeleton which is missing in log4j-over-slf4j version 1.7.5.\n\nThis is documented on the [1.7.6 release notes|http://www.slf4j.org/news.html] but 1.7.7 should be suitable.\n\nThis is applicable to all the projects using Hadoop motherpom, but Yarn appears to be bringing Log4J in, rather than coding to the SLF4J API.\n\nThe issue shows in the logs as follows in Yarn MR apps, which is painful to diagnose.\n{code}\nWARN  [2014-11-18 09:58:06,390+0100] [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Caught exception in callback postStart\njava.lang.reflect.InvocationTargetException: null\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.7.0_71]\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) ~[na:1.7.0_71]\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.7.0_71]\n\tat java.lang.reflect.Method.invoke(Method.java:606) ~[na:1.7.0_71]\n\tat org.apache.hadoop.metrics2.impl.MetricsSystemImpl$3.invoke(MetricsSystemImpl.java:290) ~[job.jar:0.22-SNAPSHOT]\n\tat com.sun.proxy.$Proxy2.postStart(Unknown Source) [na:na]\n\tat org.apache.hadoop.metrics2.impl.MetricsSystemImpl.start(MetricsSystemImpl.java:185) [job.jar:0.22-SNAPSHOT]\n\tat org.apache.hadoop.metrics2.impl.MetricsSystemImpl.init(MetricsSystemImpl.java:157) [job.jar:0.22-SNAPSHOT]\n\tat org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.init(DefaultMetricsSystem.java:54) [job.jar:0.22-SNAPSHOT]\n\tat org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.initialize(DefaultMetricsSystem.java:50) [job.jar:0.22-SNAPSHOT]\n\tat org.apache.hadoop.mapreduce.v2.app.MRAppMaster.serviceStart(MRAppMaster.java:1036) [job.jar:0.22-SNAPSHOT]\n\tat org.apache.hadoop.service.AbstractService.start(AbstractService.java:193) [job.jar:0.22-SNAPSHOT]\n\tat org.apache.hadoop.mapreduce.v2.app.MRAppMaster$1.run(MRAppMaster.java:1478) [job.jar:0.22-SNAPSHOT]\n\tat java.security.AccessController.doPrivileged(Native Method) [na:1.7.0_71]\n\tat javax.security.auth.Subject.doAs(Subject.java:415) [na:1.7.0_71]\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614) [job.jar:0.22-SNAPSHOT]\n\tat org.apache.hadoop.mapreduce.v2.app.MRAppMaster.initAndStartAppMaster(MRAppMaster.java:1474) [job.jar:0.22-SNAPSHOT]\n\tat org.apache.hadoop.mapreduce.v2.app.MRAppMaster.main(MRAppMaster.java:1407) [job.jar:0.22-SNAPSHOT]\nCaused by: java.lang.IncompatibleClassChangeError: Implementing class\n\tat java.lang.ClassLoader.defineClass1(Native Method) ~[na:1.7.0_71]\n\tat java.lang.ClassLoader.defineClass(ClassLoader.java:800) ~[na:1.7.0_71]\n\tat java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142) ~[na:1.7.0_71]\n\tat java.net.URLClassLoader.defineClass(URLClassLoader.java:449) ~[na:1.7.0_71]\n\tat java.net.URLClassLoader.access$100(URLClassLoader.java:71) ~[na:1.7.0_71]\n\tat java.net.URLClassLoader$1.run(URLClassLoader.java:361) ~[na:1.7.0_71]\n\tat java.net.URLClassLoader$1.run(URLClassLoader.java:355) ~[na:1.7.0_71]\n\tat java.security.AccessController.doPrivileged(Native Method) [na:1.7.0_71]\n\tat java.net.URLClassLoader.findClass(URLClassLoader.java:354) ~[na:1.7.0_71]\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:425) ~[na:1.7.0_71]\n\tat sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308) ~[na:1.7.0_71]\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:358) ~[na:1.7.0_71]\n\tat org.apache.hadoop.metrics2.source.JvmMetrics.getEventCounters(JvmMetrics.java:183) ~[job.jar:0.22-SNAPSHOT]\n\tat org.apache.hadoop.metrics2.source.JvmMetrics.getMetrics(JvmMetrics.java:100) ~[job.jar:0.22-SNAPSHOT]\n\tat org.apache.hadoop.metrics2.impl.MetricsSourceAdapter.getMetrics(MetricsSourceAdapter.java:195) ~[job.jar:0.22-SNAPSHOT]\n\tat org.apache.hadoop.metrics2.impl.MetricsSourceAdapter.updateJmxCache(MetricsSourceAdapter.java:172) ~[job.jar:0.22-SNAPSHOT]\n\tat org.apache.hadoop.metrics2.impl.MetricsSourceAdapter.getMBeanInfo(MetricsSourceAdapter.java:151) ~[job.jar:0.22-SNAPSHOT]\n\tat com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getNewMBeanClassName(DefaultMBeanServerInterceptor.java:333) ~[na:1.7.0_71]\n\tat com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:319) ~[na:1.7.0_71]\n\tat com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522) ~[na:1.7.0_71]\n\tat org.apache.hadoop.metrics2.util.MBeans.register(MBeans.java:57) ~[job.jar:0.22-SNAPSHOT]\n\tat org.apache.hadoop.metrics2.impl.MetricsSourceAdapter.startMBeans(MetricsSourceAdapter.java:221) ~[job.jar:0.22-SNAPSHOT]\n\tat org.apache.hadoop.metrics2.impl.MetricsSourceAdapter.start(MetricsSourceAdapter.java:96) ~[job.jar:0.22-SNAPSHOT]\n\tat org.apache.hadoop.metrics2.impl.MetricsSystemImpl.registerSource(MetricsSystemImpl.java:245) [job.jar:0.22-SNAPSHOT]\n\tat org.apache.hadoop.metrics2.impl.MetricsSystemImpl$1.postStart(MetricsSystemImpl.java:229) ~[job.jar:0.22-SNAPSHOT]\n\t... 18 common frames omitted\n{code}\n\n\n","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"Bump SLF4J to 1.7.7 from 1.7.5 ","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=timrobertson100","name":"timrobertson100","key":"timrobertson100","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Tim Robertson","active":true,"timeZone":"Etc/UTC"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=timrobertson100","name":"timrobertson100","key":"timrobertson100","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Tim Robertson","active":true,"timeZone":"Etc/UTC"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12756166/comment/14217669","id":"14217669","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"Linking to HADOOP-11317 to cover project-wide use.\nI don't think yarn-common needs to explicitly declare a dependency on log4j, at least outside the test run. If you comment out that dependency â€”does everything still build?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2014-11-19T09:56:55.261+0000","updated":"2014-11-19T09:56:55.261+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12756166/comment/14218160","id":"14218160","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=timrobertson100","name":"timrobertson100","key":"timrobertson100","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Tim Robertson","active":true,"timeZone":"Etc/UTC"},"body":"Sadly no.  \n\nIt is used in the [ContainerLogAppender|https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/ContainerLogAppender.java#L37] and [ContainerRollingLogAppender|https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/ContainerRollingLogAppender.java#L34].\n\nI tried to remove it and compile using the [log4j-over-slf4j v1.7.7 bridge|http://search.maven.org/#artifactdetails%7Corg.slf4j%7Clog4j-over-slf4j%7C1.7.7%7Cjar] but that fails because the SLF4J classes are not the same API.  For example [the SLF4J RollingFileAppender| https://github.com/qos-ch/slf4j/blob/master/log4j-over-slf4j/src/main/java/org/apache/log4j/RollingFileAppender.java] does not implement  methods like setFile(), setAppend() etc.  The build will fail with the following:\n\n{code}\n[INFO] -------------------------------------------------------------\n[ERROR] COMPILATION ERROR : \n[INFO] -------------------------------------------------------------\n[ERROR] /Users/tim/dev/git/hadoop/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/ContainerRollingLogAppender.java:[41,6] error: cannot find symbol\n[ERROR]   symbol:   method setFile(String)\n  location: class ContainerRollingLogAppender\n/Users/tim/dev/git/hadoop/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/ContainerRollingLogAppender.java:[42,6] error: cannot find symbol\n[ERROR]   symbol:   method setAppend(boolean)\n  location: class ContainerRollingLogAppender\n/Users/tim/dev/git/hadoop/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/ContainerRollingLogAppender.java:[43,11] error: cannot find symbol\n[ERROR]   symbol: method activateOptions()\n/Users/tim/dev/git/hadoop/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/ContainerRollingLogAppender.java:[38,2] error: method does not override or implement a method from a supertype\n[ERROR] /Users/tim/dev/git/hadoop/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/ContainerRollingLogAppender.java:[49,8] error: cannot find symbol\n[ERROR]   symbol:   variable qw\n  location: class ContainerRollingLogAppender\n/Users/tim/dev/git/hadoop/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/ContainerRollingLogAppender.java:[50,6] error: cannot find symbol\n[ERROR]   symbol:   variable qw\n  location: class ContainerRollingLogAppender\n/Users/tim/dev/git/hadoop/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/ContainerLogAppender.java:[37,7] error: no suitable constructor found for FileAppender()\n[ERROR]     constructor FileAppender.FileAppender(Layout,String,boolean,boolean,int) is not applicable\n      (actual and formal argument lists differ in length)\n    constructor FileAppender.FileAppender(Layout,String,boolean) is not applicable\n      (actual and formal argument lists differ in length)\n    constructor FileAppender.FileAppender(Layout,String) is not applicable\n      (actual and formal argument lists differ in length)\n/Users/tim/dev/git/hadoop/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/ContainerLogAppender.java:[52,6] error: cannot find symbol\n[ERROR]   symbol:   method setFile(String)\n  location: class ContainerLogAppender\n/Users/tim/dev/git/hadoop/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/ContainerLogAppender.java:[53,6] error: cannot find symbol\n[ERROR]   symbol:   method setAppend(boolean)\n  location: class ContainerLogAppender\n/Users/tim/dev/git/hadoop/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/ContainerLogAppender.java:[65,13] error: cannot find symbol\n[ERROR]   symbol: method append(LoggingEvent)\n/Users/tim/dev/git/hadoop/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/ContainerLogAppender.java:[58,2] error: method does not override or implement a method from a supertype\n[ERROR] /Users/tim/dev/git/hadoop/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/ContainerLogAppender.java:[77,8] error: cannot find symbol\n[ERROR]   symbol:   variable qw\n  location: class ContainerLogAppender\n/Users/tim/dev/git/hadoop/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/ContainerLogAppender.java:[78,6] error: cannot find symbol\n[ERROR]   symbol:   variable qw\n  location: class ContainerLogAppender\n/Users/tim/dev/git/hadoop/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/ContainerLogAppender.java:[87,13] error: cannot find symbol\n[ERROR]   symbol: method append(LoggingEvent)\n/Users/tim/dev/git/hadoop/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/ContainerLogAppender.java:[90,9] error: cannot find symbol\n[ERROR]   symbol: method close()\n/Users/tim/dev/git/hadoop/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/ContainerLogAppender.java:[82,2] error: method does not override or implement a method from a supertype\n[INFO] 16 errors \n[INFO] -------------------------------------------------------------\n[INFO] ------------------------------------------------------------------------\n[INFO] BUILD FAILURE\n[INFO] ------------------------------------------------------------------------\n{code} ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=timrobertson100","name":"timrobertson100","key":"timrobertson100","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Tim Robertson","active":true,"timeZone":"Etc/UTC"},"created":"2014-11-19T17:13:24.995+0000","updated":"2014-11-19T17:13:24.995+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12756166/comment/14292529","id":"14292529","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"tim, add a patch in  HADOOP-11317  to increment the SLF4J version and I'll apply it","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2015-01-26T22:29:50.572+0000","updated":"2015-01-26T22:29:50.572+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12756166/comment/14294932","id":"14294932","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=timrobertson100","name":"timrobertson100","key":"timrobertson100","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Tim Robertson","active":true,"timeZone":"Etc/UTC"},"body":"Done - bumped to 1.7.10 which the release notes suggest should be fine.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=timrobertson100","name":"timrobertson100","key":"timrobertson100","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Tim Robertson","active":true,"timeZone":"Etc/UTC"},"created":"2015-01-28T09:39:25.178+0000","updated":"2015-01-28T09:39:25.178+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12756166/comment/14523663","id":"14523663","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=leftnoteasy","name":"leftnoteasy","key":"leftnoteasy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=leftnoteasy&avatarId=18647","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=leftnoteasy&avatarId=18647","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=leftnoteasy&avatarId=18647","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=leftnoteasy&avatarId=18647"},"displayName":"Wangda Tan","active":true,"timeZone":"America/Los_Angeles"},"body":"Resolved this since HADOOP-11317 bumped to 1.7.10","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=leftnoteasy","name":"leftnoteasy","key":"leftnoteasy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=leftnoteasy&avatarId=18647","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=leftnoteasy&avatarId=18647","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=leftnoteasy&avatarId=18647","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=leftnoteasy&avatarId=18647"},"displayName":"Wangda Tan","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-05-01T18:50:34.869+0000","updated":"2015-05-01T18:50:34.869+0000"}],"maxResults":5,"total":5,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/YARN-2875/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i22imf:"}}