{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12953738","self":"https://issues.apache.org/jira/rest/api/2/issue/12953738","key":"YARN-4881","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12313722","id":"12313722","key":"YARN","name":"Hadoop YARN","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12313722&avatarId=15135","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12313722&avatarId=15135","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12313722&avatarId=15135","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12313722&avatarId=15135"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":"2016-03-26T09:07:22.955+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Sat Mar 26 09:55:18 UTC 2016","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/YARN-4881/watchers","watchCount":5,"isWatching":false},"created":"2016-03-26T08:50:40.188+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/2","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/critical.svg","name":"Critical","id":"2"},"labels":[],"customfield_12312333":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[],"issuelinks":[{"id":"12463386","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12463386","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"12958051","key":"YARN-4948","self":"https://issues.apache.org/jira/rest/api/2/issue/12958051","fields":{"summary":"Support node labels store in zookeeper","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/7","id":"7","description":"The sub-task of the issue","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype","name":"Sub-task","subtask":true,"avatarId":21146}}}}],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2016-04-12T09:46:19.570+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12319322","id":"12319322","name":"resourcemanager"}],"timeoriginalestimate":null,"description":"It is observed in the production cluster that RM fail to become active and keep continuously switching if the HDFS is too busy and node label is configured. This is causing RM down time as very high. \n\nException from RM logs\n{noformat}\nCaused by: org.apache.hadoop.service.ServiceStateException: org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/mapred/node-labels/nodelabel.mirror.writing could only be replicated to 0 nodes instead of minReplication (=1). There are 7 datanode(s) running and no node(s) are excluded in this operation.\n{noformat}\n\n","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"RM continuously switch if HDFS is too busy when NodeLabel is configured","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rohithsharma","name":"rohithsharma","key":"rohithsharma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rohith Sharma K S","active":true,"timeZone":"Australia/Sydney"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rohithsharma","name":"rohithsharma","key":"rohithsharma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rohith Sharma K S","active":true,"timeZone":"Australia/Sydney"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12953738/comment/15212893","id":"15212893","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rohithsharma","name":"rohithsharma","key":"rohithsharma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rohith Sharma K S","active":true,"timeZone":"Australia/Sydney"},"body":"Exception trace has message like *There are 7 datanode(s) running and no node(s) are excluded in this operation*. I think client is fail to write into file system without excluding any datanodes. Need to check with HDFS experts about the behavior!\n\nException log trace. \n{noformat}\n2016-03-24 11:15:14,823 | WARN | main-EventThread | Exception handling the winning of election | ActiveStandbyElector.java:836\norg.apache.hadoop.ha.ServiceFailedException: RM could not transition to Active\nat org.apache.hadoop.yarn.server.resourcemanager.EmbeddedElectorService.becomeActive(EmbeddedElectorService.java:128)\nat org.apache.hadoop.ha.ActiveStandbyElector.becomeActive(ActiveStandbyElector.java:832)\nat org.apache.hadoop.ha.ActiveStandbyElector.processResult(ActiveStandbyElector.java:422)\nat org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:694)\nat org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:566)\nCaused by: org.apache.hadoop.ha.ServiceFailedException: Error when transitioning to Active mode\nat org.apache.hadoop.yarn.server.resourcemanager.AdminService.transitionToActive(AdminService.java:319)\nat org.apache.hadoop.yarn.server.resourcemanager.EmbeddedElectorService.becomeActive(EmbeddedElectorService.java:126)\n... 4 more\nCaused by: org.apache.hadoop.service.ServiceStateException: org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/mapred/node-labels/nodelabel.mirror.writing could only be replicated to 0 nodes instead of minReplication (=1). There are 7 datanode(s) running and no node(s) are excluded in this operation.\nat org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:1693)\nat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getNewBlockTargets(FSNamesystem.java:3049)\nat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2971)\nat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:741)\nat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:502)\nat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\nat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)\nat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:973)\nat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2141)\nat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2137)\nat java.security.AccessController.doPrivileged(Native Method)\nat javax.security.auth.Subject.doAs(Subject.java:422)\nat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1732)\nat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2137)\n\nat org.apache.hadoop.service.ServiceStateException.convert(ServiceStateException.java:59)\nat org.apache.hadoop.service.AbstractService.start(AbstractService.java:204)\nat org.apache.hadoop.service.CompositeService.serviceStart(CompositeService.java:120)\nat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMActiveServices.serviceStart(ResourceManager.java:636)\nat org.apache.hadoop.service.AbstractService.start(AbstractService.java:193)\nat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.startActiveServices(ResourceManager.java:1033)\nat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$1.run(ResourceManager.java:1074)\nat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$1.run(ResourceManager.java:1070)\nat java.security.AccessController.doPrivileged(Native Method)\nat javax.security.auth.Subject.doAs(Subject.java:422)\nat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1711)\nat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.transitionToActive(ResourceManager.java:1070)\nat org.apache.hadoop.yarn.server.resourcemanager.AdminService.transitionToActive(AdminService.java:314)\n... 5 more\nCaused by: org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/mapred/node-labels/nodelabel.mirror.writing could only be replicated to 0 nodes instead of minReplication (=1). There are 7 datanode(s) running and no node(s) are excluded in this operation.\nat org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:1693)\nat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getNewBlockTargets(FSNamesystem.java:3049)\nat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2971)\nat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:741)\nat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:502)\nat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\nat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)\nat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:973)\nat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2141)\nat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2137)\nat java.security.AccessController.doPrivileged(Native Method)\nat javax.security.auth.Subject.doAs(Subject.java:422)\nat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1732)\nat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2137)\n\nat org.apache.hadoop.ipc.Client.call(Client.java:1511)\nat org.apache.hadoop.ipc.Client.call(Client.java:1447)\nat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)\nat com.sun.proxy.$Proxy88.addBlock(Unknown Source)\nat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:418)\nat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\nat java.lang.reflect.Method.invoke(Method.java:497)\nat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)\nat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)\nat com.sun.proxy.$Proxy89.addBlock(Unknown Source)\nat org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1708)\nat org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1509)\nat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:583)\n{noformat}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rohithsharma","name":"rohithsharma","key":"rohithsharma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rohith Sharma K S","active":true,"timeZone":"Australia/Sydney"},"created":"2016-03-26T08:59:25.930+0000","updated":"2016-03-26T08:59:25.930+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12953738/comment/15212899","id":"15212899","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sunilg","name":"sunilg","key":"sunilg","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sunil Govindan","active":true,"timeZone":"Asia/Kolkata"},"body":"One more thing to note is that for NodeLabel, we explicitly use {{dfs.client.retry.policy.enabled}} as true. And for single RM cases, i think it will be a fatal as RM will be go down. [~rohithsharma], is it correct?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sunilg","name":"sunilg","key":"sunilg","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sunil Govindan","active":true,"timeZone":"Asia/Kolkata"},"created":"2016-03-26T09:07:22.955+0000","updated":"2016-03-26T09:07:22.955+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12953738/comment/15212903","id":"15212903","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rohithsharma","name":"rohithsharma","key":"rohithsharma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rohith Sharma K S","active":true,"timeZone":"Australia/Sydney"},"body":"In our cluster RM HA is enabled. Both RM's are up and running. But none of the RM's are becoming active and continuously switching. So either it is single RM or HA enabled, in both cases RM will not be up.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rohithsharma","name":"rohithsharma","key":"rohithsharma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rohith Sharma K S","active":true,"timeZone":"Australia/Sydney"},"created":"2016-03-26T09:16:08.481+0000","updated":"2016-03-26T09:16:08.481+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12953738/comment/15212908","id":"15212908","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sunilg","name":"sunilg","key":"sunilg","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sunil Govindan","active":true,"timeZone":"Asia/Kolkata"},"body":"Yes. Thanks for clarifying. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sunilg","name":"sunilg","key":"sunilg","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sunil Govindan","active":true,"timeZone":"Asia/Kolkata"},"created":"2016-03-26T09:21:11.062+0000","updated":"2016-03-26T09:21:11.062+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12953738/comment/15212912","id":"15212912","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rohithsharma","name":"rohithsharma","key":"rohithsharma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rohith Sharma K S","active":true,"timeZone":"Australia/Sydney"},"body":"Another issue noticed if RM continuously switches is about the logs. In a short period, because of recovering the applications RM is flooded with huge logs which get rolled out. I think, recovering completed applications should be changed to DEBUG log. I will raise separate ticket for discussion","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rohithsharma","name":"rohithsharma","key":"rohithsharma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rohith Sharma K S","active":true,"timeZone":"Australia/Sydney"},"created":"2016-03-26T09:37:02.809+0000","updated":"2016-03-26T09:37:02.809+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12953738/comment/15212924","id":"15212924","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rohithsharma","name":"rohithsharma","key":"rohithsharma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rohith Sharma K S","active":true,"timeZone":"Australia/Sydney"},"body":"I logged ticket YARN-4882 for discussion about log level change.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rohithsharma","name":"rohithsharma","key":"rohithsharma","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Rohith Sharma K S","active":true,"timeZone":"Australia/Sydney"},"created":"2016-03-26T09:55:18.441+0000","updated":"2016-03-26T09:55:18.441+0000"}],"maxResults":6,"total":6,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/YARN-4881/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i2v8z3:"}}