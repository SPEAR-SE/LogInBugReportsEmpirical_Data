{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12972534","self":"https://issues.apache.org/jira/rest/api/2/issue/12972534","key":"YARN-5140","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12313722","id":"12313722","key":"YARN","name":"Hadoop YARN","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12313722&avatarId=15135","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12313722&avatarId=15135","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12313722&avatarId=15135","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12313722&avatarId=15135"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":"2017-10-03T01:15:26.627+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Tue Oct 03 01:15:26 UTC 2017","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/YARN-5140/watchers","watchCount":7,"isWatching":false},"created":"2016-05-24T21:56:36.123+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/4","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/minor.svg","name":"Minor","id":"4"},"labels":[],"customfield_12312333":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12327585","id":"12327585","description":"2.7.0 release","name":"2.7.0","archived":false,"released":true,"releaseDate":"2015-04-20"}],"issuelinks":[],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2017-10-03T01:15:26.627+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12319323","id":"12319323","name":"nodemanager"}],"timeoriginalestimate":null,"description":"A burst or rapid rate of submitted jobs with substantial NM usercache resource localization footprint may lead to rapid fill up of the NM local temporary IO FS (/tmp by default) with negative consequences in terms of stability.\n\nThe core issue seems to be the fact that NM continues to localize the resources beyond the maximum local cache size (yarn.nodemanager.localizer.cache.target-size-mb , default 10G). Since maximum local cache size is effectively not taken into account when localizing new resources (note that default cache cleanup interval is 10 min controlled by yarn.nodemanager.localizer.cache.cleanup.interval-ms), this basically leads to sort of self-destruction scenario : once /tmp FS utilization reaches the threshold of 90%, NM will automatically de-register from RM, effectively leading to NM outage.\n\nThis issue may offline many NMs simultaneously at the same time and thus is quite critical in terms of platform stability.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"NM usercache fill up with burst of jobs leading to rapid temp IO FS fill up and potentially NM outage","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=okalinin","name":"okalinin","key":"okalinin","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Oleksandr Kalinin","active":true,"timeZone":"Etc/UTC"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=okalinin","name":"okalinin","key":"okalinin","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Oleksandr Kalinin","active":true,"timeZone":"Etc/UTC"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":"Linux RHEL 6.7, Hadoop 2.7.0\n\n","customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12972534/comment/15400654","id":"15400654","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=okalinin","name":"okalinin","key":"okalinin","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Oleksandr Kalinin","active":true,"timeZone":"Etc/UTC"},"body":"Workaround option to this issue is explicit yarn.nodemanager.local-dirs configuration pointing to DFS disks.\n\nDefault parameter value ${hadoop.tmp.dir}/nm-local-dir will imply usage of local FS on system disk in most installations. Besides of FS fill up risk explained in the description, this is not scalable and performs poorly for any heavy localization as well as some particular workload phases like Spark on YARN shuffle.\n\nPerhaps those drawbacks of using single local FS directory should be better documented in yarn.nodemanager.local-dirs parameter description.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=okalinin","name":"okalinin","key":"okalinin","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Oleksandr Kalinin","active":true,"timeZone":"Etc/UTC"},"created":"2016-07-30T12:15:47.399+0000","updated":"2016-07-31T13:02:57.946+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12972534/comment/16189144","id":"16189144","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=airbots","name":"airbots","key":"airbots","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=airbots&avatarId=34730","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=airbots&avatarId=34730","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=airbots&avatarId=34730","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=airbots&avatarId=34730"},"displayName":"Chen He","active":true,"timeZone":"America/Los_Angeles"},"body":"Hi [~okalinin], this is a interesting issue. According to the description, if I understand correctly, could we avoid multiple NM crash if we reduce the \"yarn.nodemanager.localizer.cache.cleanup.interval-ms\" and increasing \"yarn.nodemanager.localizer.cache.target-size-mb\"?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=airbots","name":"airbots","key":"airbots","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=airbots&avatarId=34730","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=airbots&avatarId=34730","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=airbots&avatarId=34730","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=airbots&avatarId=34730"},"displayName":"Chen He","active":true,"timeZone":"America/Los_Angeles"},"created":"2017-10-03T01:15:26.627+0000","updated":"2017-10-03T01:15:26.627+0000"}],"maxResults":2,"total":2,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/YARN-5140/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i2yg6n:"}}