{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"13083103","self":"https://issues.apache.org/jira/rest/api/2/issue/13083103","key":"YARN-6745","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12313722","id":"12313722","key":"YARN","name":"Hadoop YARN","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12313722&avatarId=15135","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12313722&avatarId=15135","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12313722&avatarId=15135","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12313722&avatarId=15135"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":null,"customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"2017-06-28 11:26:16.235","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/YARN-6745/watchers","watchCount":3,"isWatching":false},"created":"2017-06-28T11:26:16.235+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12332791","id":"12332791","description":"2.7.2 release","name":"2.7.2","archived":false,"released":true,"releaseDate":"2016-01-25"}],"issuelinks":[],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2017-06-28T11:26:16.235+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12319414","id":"12319414","name":"applications"}],"timeoriginalestimate":null,"description":"When submit Spark 2.x applications to YARN cluster on Windows, we found two errors:\n# If  [dynamic resource allocation|https://spark.apache.org/docs/latest/job-scheduling.html#dynamic-resource-allocation]is enabled for Spark, we will get exception in thread \"main\" java.lang.NoSuchMethodError: org.apache.spark.network.util.JavaUtils.byteStringAs(Ljava/lang/String;Lorg/apache/spark/network/util/ByteUnit)\n# We cannot open spark application running web UI\n\nThe two errors are both related to YARN cannot parse correct Spark 2.x jars wildcard classpath on Windows, and I checked the latest code from hadoop-3.x, this part of code seems not changed and would cause this error again.\n\nA typical appacahe folder to run spark executor/driver in our windows yarn looks like below:\n!http://wx1.sinaimg.cn/large/62eae5a9gy1fh14j38zvbj20bb0990tm.jpg!\nThe link folder of ‘__spark_libs_’ points to a filecache folder with spark-2+ needed jars;\nThe classpath-xxx.jar containing a manifest file of the runtime classpath to work around the 8k maximum command line length problem in windows (https://issues.apache.org/jira/browse/YARN-358) .\nThe ‘launch_container.cmd’ is the script to start YARN container, please note that after running launch_container.cmd, the shortcut ‘__spark_conf_’ , ‘__spark_libs_’ and ‘__app__.jar’ could then be created.\n\n\n=================================================\nThe typical CLASSPATH of hadoop-2.7.2 in launch_container.cmd looks like below:\n!http://wx4.sinaimg.cn/large/62eae5a9gy1fh14j2c801j20sh023weh.jpg!\nThe ‘classpath-3177336218981224920.jar’ contains a manifest file containing all the hadoop runtime jars, in which we could find spark-1.6.2-nao-yarn-shuffle.jar and servlet-api-2.5.jar. The two problems are all due to java runtime first load class from those two old jars, while spark 1.x shuffle external service is not compatible with spark 2.x and servlet-api-2.x is not compatible with servlet-api-3.x (used in spark-2).\n\nSo, that is to say, the “xxx/spark_libs/*” should place before the classpath-jar. OK, let’s see what is the CLASSPATH in Linux.\n\n=================================================\nThe classpath in launch_container.sh looks like:\n!http://wx2.sinaimg.cn/large/62eae5a9gy1fh14ivycpxj20um01tjre.jpg!\nWe can see the “xxx/spark_libs/*” placed before hadoop jars so that the #1 and #2 problem would not happen in Linux environment.\n\n*Root cause*:\nTwo steps for the whole process\n1.{color:blue}org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch{color} will transform original CLASSPATH into the classpath-jar in method ‘sanitizeEnv’. The CLASSPATH is:\n{code:java}\n%PWD%;%PWD%/__spark_conf__;%PWD%/__app__.jar;%PWD%/__spark_libs__/*;%HADOOP_CONF_DIR%;%HADOOP_COMMON_HOME%/share/hadoop/common/*;%HADOOP_COMMON_HOME%/share/hadoop/common/lib/*;%HADOOP_HDFS_HOME%/share/hadoop/hdfs/*;%HADOOP_HDFS_HOME%/share/hadoop/hdfs/lib/*;%HADOOP_YARN_HOME%/share/hadoop/yarn/*;%HADOOP_YARN_HOME%/share/hadoop/yarn/lib/*;%HADOOP_MAPRED_HOME%\\share\\hadoop\\mapreduce\\*;%HADOOP_MAPRED_HOME%\\share\\hadoop\\mapreduce\\lib\\*;\n{code}\n\nWithin this method, it will call ‘createJarWithClassPath’ method from {color:blue}org.apache.hadoop.fs.FileUtil{color}\n\n2. For the wildcard path, {color:blue}org.apache.hadoop.fs.FileUtil{color} will find the files in that folder with suffix of ‘jar’ or ‘JAR’. The previous %PWD%/__spark_libs__/* transformed to \n{code:java}\nD:/Data/Yarn/nm-local-dir/usercache/xxx/appcache/application_1494151518127_0073/container_e3752_1494151518127_0073_01_000001/__spark_libs__/* .\n{code}\n\nHowever, this folder is not existing when generating the classpath-jar, only after running ‘launch_container.cmd’ we could have the ‘_spark_libs_’ folder in current directory, which results in YARN put the “xxx/_spark_libs_/*” classpath into unexpandedWildcardClasspath. And the unexpandedWildcardClasspath is placed after the classpath-jar in CLASSPATH, that’s why we see the “xxx/__spark_libs__/” located in the end. \n\nIn other words, the correct order should be “xxx/spark_libs/*\" placed before the classpath-jar just like Linux case or parse the “xxx/spark_libs/xxx.jar” into the classpath-jar, which means changing current wrong order satisfied the original design. \n\n","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"Cannot parse correct Spark 2.x jars classpath in YARN on Windows","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yunta","name":"yunta","key":"yunta","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=yunta&avatarId=29430","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=yunta&avatarId=29430","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=yunta&avatarId=29430","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=yunta&avatarId=29430"},"displayName":"Yun Tang","active":true,"timeZone":"Etc/UTC"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=yunta","name":"yunta","key":"yunta","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=yunta&avatarId=29430","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=yunta&avatarId=29430","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=yunta&avatarId=29430","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=yunta&avatarId=29430"},"displayName":"Yun Tang","active":true,"timeZone":"Etc/UTC"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":"Windows cluster, Yarn-2.7.2","customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[],"maxResults":0,"total":0,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/YARN-6745/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i3gu1b:"}}