{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12829255","self":"https://issues.apache.org/jira/rest/api/2/issue/12829255","key":"YARN-3633","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12313722","id":"12313722","key":"YARN","name":"Hadoop YARN","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12313722&avatarId=15135","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12313722&avatarId=15135","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12313722&avatarId=15135","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12313722&avatarId=15135"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":"2015-05-13T22:36:14.869+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Tue Jan 24 01:06:42 UTC 2017","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/YARN-3633/watchers","watchCount":13,"isWatching":false},"created":"2015-05-12T17:15:18.214+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/2","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/critical.svg","name":"Critical","id":"2"},"labels":[],"customfield_12312333":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"2.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12327197","id":"12327197","description":"2.6.0 release","name":"2.6.0","archived":false,"released":true,"releaseDate":"2014-11-18"}],"issuelinks":[],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ragarwal","name":"ragarwal","key":"ragarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=ragarwal&avatarId=18538","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=ragarwal&avatarId=18538","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=ragarwal&avatarId=18538","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=ragarwal&avatarId=18538"},"displayName":"Rohit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2017-01-24T01:06:42.489+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/10002","description":"A patch for this issue has been uploaded to JIRA by a contributor.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/document.png","name":"Patch Available","id":"10002","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/4","id":4,"key":"indeterminate","colorName":"yellow","name":"In Progress"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12322906","id":"12322906","name":"fairscheduler","description":"Fair Scheduler"}],"timeoriginalestimate":null,"description":"It's possible to logjam a cluster by submitting many applications at once in different queues.\n\nFor example, let's say there is a cluster with 20GB of total memory. Let's say 4 users submit applications at the same time. The fair share of each queue is 5GB. Let's say that maxAMShare is 0.5. So, each queue has at most 2.5GB memory for AMs. If all the users requested AMs of size 3GB - the cluster logjams. Nothing gets scheduled even when 20GB of resources are available.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12733674","id":"12733674","filename":"YARN-3633.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ragarwal","name":"ragarwal","key":"ragarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=ragarwal&avatarId=18538","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=ragarwal&avatarId=18538","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=ragarwal&avatarId=18538","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=ragarwal&avatarId=18538"},"displayName":"Rohit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-05-19T00:07:21.519+0000","size":17139,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12733674/YARN-3633.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12733912","id":"12733912","filename":"YARN-3633-1.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ragarwal","name":"ragarwal","key":"ragarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=ragarwal&avatarId=18538","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=ragarwal&avatarId=18538","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=ragarwal&avatarId=18538","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=ragarwal&avatarId=18538"},"displayName":"Rohit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-05-19T18:40:34.684+0000","size":17236,"mimeType":"text/plain","content":"https://issues.apache.org/jira/secure/attachment/12733912/YARN-3633-1.patch"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"With Fair Scheduler, cluster can logjam when there are too many active queues","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ragarwal","name":"ragarwal","key":"ragarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=ragarwal&avatarId=18538","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=ragarwal&avatarId=18538","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=ragarwal&avatarId=18538","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=ragarwal&avatarId=18538"},"displayName":"Rohit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ragarwal","name":"ragarwal","key":"ragarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=ragarwal&avatarId=18538","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=ragarwal&avatarId=18538","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=ragarwal&avatarId=18538","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=ragarwal&avatarId=18538"},"displayName":"Rohit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12829255/comment/14540491","id":"14540491","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ragarwal","name":"ragarwal","key":"ragarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=ragarwal&avatarId=18538","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=ragarwal&avatarId=18538","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=ragarwal&avatarId=18538","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=ragarwal&avatarId=18538"},"displayName":"Rohit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"body":"So, in essence the problem is that when there are too many queues, the fair share of each queue gets low and thus the maxAMShare, which is calculated from the fairShare of each queue, gets too low to run any container.\n\nI propose the following solution:\nInstead of setting\n{code}\nmaxAMShare = 0.5*fairShare\n{code}\nwe set it to\n{code}\nmaxAMShare = max(0.5*fairShare, SomeMinimumSizeEnoughToRunOneContainer)\n{code}\nAnd then add a cluster-wide maxAMShare to be {{0.5*totalClusterCapacity}}\n\nAll these ratios/values can be configurable.\n\nSo, in the scenario described in the JIRA, we would still run AMs in some queues but we won't overrun the cluster with AMs because it will hit the cluster-wide limit.\n\nIf this proposal sounds reasonable, I can start working on this.\n\nHowever, I am not sure how this would interact with preemption.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ragarwal","name":"ragarwal","key":"ragarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=ragarwal&avatarId=18538","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=ragarwal&avatarId=18538","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=ragarwal&avatarId=18538","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=ragarwal&avatarId=18538"},"displayName":"Rohit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-05-12T19:01:36.895+0000","updated":"2015-05-12T19:01:36.895+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12829255/comment/14542855","id":"14542855","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kasha","name":"kasha","key":"kasha","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Karthik Kambatla","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks for reporting this, Rohit. \n\nExtrapolating the example, consider the applications' containers also need 3 GB. With the proposed change, the AMs would come up but will not be able to run any containers. Note that this is only an issue on a cluster where a single AM fills up the am-share; is this likely to happen on larger clusters and production deployments?\n\nThe scheduler could realize there aren't enough resources to run applications from multiple queues and run them in some order, but that would violate the fairness policies. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=kasha","name":"kasha","key":"kasha","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Karthik Kambatla","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-05-13T22:36:14.869+0000","updated":"2015-05-13T22:36:14.869+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12829255/comment/14542895","id":"14542895","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ragarwal","name":"ragarwal","key":"ragarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=ragarwal&avatarId=18538","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=ragarwal&avatarId=18538","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=ragarwal&avatarId=18538","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=ragarwal&avatarId=18538"},"displayName":"Rohit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"body":"Can you elaborate the scenario where the AMs would come up but the containers would not? There is still a cluster-wide maxAMShare which is, let's say, 0.5 times the cluster-capacity.\n\nA dry run of my proposed change:\n\nCluster Resource: 20GB\nApplications submitted to 4 queues simultaneously - queue a, b, c, and d. Each application requests AMs of size 3GB and containers of size 3GB.\nFair share for each queue = 5GB.\nmaxAMShare is 0.5\nLet's say {{SomeMinimumSizeEnoughToRunOneContainer}} is 3GB.\n\n\nqueue a will start AM1. (maxAMShare = max(0.5*5GB, 3GB) = 3GB). cluster-wide AMShare = 3GB < 0.5*20GB\nqueue b will start AM2. (maxAMShare = max(0.5*5GB, 3GB) = 3GB). cluster-wide AMShare = 6GB < 0.5*20GB\nqueue c will start AM3. (maxAMShare = max(0.5*5GB, 3GB) = 3GB). cluster-wide AMShare = 9GB < 0.5*20GB\nFS will try to run AM4 on queue d. But now it would hit the cluster-wide maxAMShare limit. So, nothing will run there. Then, FS will try to run something on queue a (or b or c) - and so the application1 container would start.\n\nThis would repeat. FS will try to run AM4 on queue d. It would again hit the cluster-wide maxAMShare limit. It would then try to run something on queue b (or c) - and so application2 container would start.\n\nAnd so on.\n\nFinally one of app1, app2, app3 AM would finish. At which time FS should schedule AM4 on queue d.\n\nI agree that queue d is not getting its fair share till one of app1, app2 and app3 complete (and that is why I am unsure how my proposed change would work when preemption is enabled.) But I think it is better than not scheduling anything?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ragarwal","name":"ragarwal","key":"ragarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=ragarwal&avatarId=18538","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=ragarwal&avatarId=18538","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=ragarwal&avatarId=18538","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=ragarwal&avatarId=18538"},"displayName":"Rohit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-05-13T23:17:51.066+0000","updated":"2015-05-13T23:17:51.066+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12829255/comment/14542897","id":"14542897","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sandyr","name":"sandyr","key":"sandyr","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sandy Ryza","active":true,"timeZone":"America/Los_Angeles"},"body":"Another thought is that we could say the max AM share only applies after first AM.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=sandyr","name":"sandyr","key":"sandyr","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sandy Ryza","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-05-13T23:20:43.472+0000","updated":"2015-05-13T23:20:43.472+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12829255/comment/14542902","id":"14542902","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ragarwal","name":"ragarwal","key":"ragarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=ragarwal&avatarId=18538","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=ragarwal&avatarId=18538","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=ragarwal&avatarId=18538","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=ragarwal&avatarId=18538"},"displayName":"Rohit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"body":"[~sandyr] If we do that and have no cluster-wide AMShare then we may have a situation where all queues are just running AMs - imagine lots of apps submitted at the same time to different queues.\n\nBut yes we can use this 'max AM share applies after first AM' property instead of setting {{maxAMShare for queue = max(0.5*fairShare, SomeMinimumSizeEnoughToRunOneContainer)}}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ragarwal","name":"ragarwal","key":"ragarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=ragarwal&avatarId=18538","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=ragarwal&avatarId=18538","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=ragarwal&avatarId=18538","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=ragarwal&avatarId=18538"},"displayName":"Rohit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-05-13T23:26:01.027+0000","updated":"2015-05-13T23:26:01.027+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12829255/comment/14542929","id":"14542929","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ragarwal","name":"ragarwal","key":"ragarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=ragarwal&avatarId=18538","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=ragarwal&avatarId=18538","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=ragarwal&avatarId=18538","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=ragarwal&avatarId=18538"},"displayName":"Rohit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"body":"Actually, I like the idea of not enforcing the queue maxAMShare till one AM is running. This in conjunction with a cluster-wide maxAMShare is easier to implement than what I originally proposed and doesn't introduce another new parameter.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ragarwal","name":"ragarwal","key":"ragarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=ragarwal&avatarId=18538","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=ragarwal&avatarId=18538","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=ragarwal&avatarId=18538","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=ragarwal&avatarId=18538"},"displayName":"Rohit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-05-13T23:49:27.511+0000","updated":"2015-05-13T23:49:27.511+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12829255/comment/14549550","id":"14549550","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ragarwal","name":"ragarwal","key":"ragarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=ragarwal&avatarId=18538","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=ragarwal&avatarId=18538","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=ragarwal&avatarId=18538","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=ragarwal&avatarId=18538"},"displayName":"Rohit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"body":"Added a patch. Please review.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ragarwal","name":"ragarwal","key":"ragarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=ragarwal&avatarId=18538","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=ragarwal&avatarId=18538","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=ragarwal&avatarId=18538","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=ragarwal&avatarId=18538"},"displayName":"Rohit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-05-19T00:09:27.386+0000","updated":"2015-05-19T00:09:27.386+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12829255/comment/14549675","id":"14549675","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"\\\\\n\\\\\n| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | pre-patch |  14m 52s | Pre-patch trunk compilation is healthy. |\n| {color:green}+1{color} | @author |   0m  0s | The patch does not contain any @author tags. |\n| {color:green}+1{color} | tests included |   0m  0s | The patch appears to include 1 new or modified test files. |\n| {color:green}+1{color} | javac |   7m 34s | There were no new javac warning messages. |\n| {color:green}+1{color} | javadoc |   9m 41s | There were no new javadoc warning messages. |\n| {color:green}+1{color} | release audit |   0m 24s | The applied patch does not increase the total number of release audit warnings. |\n| {color:red}-1{color} | checkstyle |   0m 51s | The applied patch generated  8 new checkstyle issues (total was 120, now 126). |\n| {color:red}-1{color} | whitespace |   0m  1s | The patch has 1  line(s) that end in whitespace. Use git apply --whitespace=fix. |\n| {color:green}+1{color} | install |   1m 34s | mvn install still works. |\n| {color:green}+1{color} | eclipse:eclipse |   0m 33s | The patch built with eclipse:eclipse. |\n| {color:red}-1{color} | findbugs |   1m 17s | The patch appears to introduce 1 new Findbugs (version 3.0.0) warnings. |\n| {color:green}+1{color} | yarn tests |  50m  3s | Tests passed in hadoop-yarn-server-resourcemanager. |\n| | |  86m 54s | |\n\\\\\n\\\\\n|| Reason || Tests ||\n| FindBugs | module:hadoop-yarn-server-resourcemanager |\n|  |  Inconsistent synchronization of org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore.isHDFS; locked 66% of time  Unsynchronized access at FileSystemRMStateStore.java:66% of time  Unsynchronized access at FileSystemRMStateStore.java:[line 156] |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Patch URL | http://issues.apache.org/jira/secure/attachment/12733674/YARN-3633.patch |\n| Optional Tests | javadoc javac unit findbugs checkstyle |\n| git revision | trunk / 0790275 |\n| checkstyle |  https://builds.apache.org/job/PreCommit-YARN-Build/7988/artifact/patchprocess/diffcheckstylehadoop-yarn-server-resourcemanager.txt |\n| whitespace | https://builds.apache.org/job/PreCommit-YARN-Build/7988/artifact/patchprocess/whitespace.txt |\n| Findbugs warnings | https://builds.apache.org/job/PreCommit-YARN-Build/7988/artifact/patchprocess/newPatchFindbugsWarningshadoop-yarn-server-resourcemanager.html |\n| hadoop-yarn-server-resourcemanager test log | https://builds.apache.org/job/PreCommit-YARN-Build/7988/artifact/patchprocess/testrun_hadoop-yarn-server-resourcemanager.txt |\n| Test Results | https://builds.apache.org/job/PreCommit-YARN-Build/7988/testReport/ |\n| Java | 1.7.0_55 |\n| uname | Linux asf907.gq1.ygridcore.net 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |\n| Console output | https://builds.apache.org/job/PreCommit-YARN-Build/7988/console |\n\n\nThis message was automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2015-05-19T02:26:43.959+0000","updated":"2015-05-19T02:26:43.959+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12829255/comment/14549949","id":"14549949","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=asuresh","name":"asuresh","key":"asuresh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun Suresh","active":true,"timeZone":"America/Los_Angeles"},"body":"Thanks for the patch [~ragarwal],\nAssuming we allow, as per the patch, the first AM to be scheduled, then, as per the example you specified in the description, the AM will take up 3GB in an 5GB queue... presuming each worker task requires more resources that the AM (I am guessing this should be true for most cases), then no other task can be scheduled on that queue. and remaining queues are anyway log-jammed since the maxAMshare logic would kick in.\nWondering if its a valid scenario..\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=asuresh","name":"asuresh","key":"asuresh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun Suresh","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-05-19T07:12:44.242+0000","updated":"2015-05-19T07:12:44.242+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12829255/comment/14550008","id":"14550008","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ragarwal","name":"ragarwal","key":"ragarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=ragarwal&avatarId=18538","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=ragarwal&avatarId=18538","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=ragarwal&avatarId=18538","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=ragarwal&avatarId=18538"},"displayName":"Rohit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"body":"Other non-AM containers can be scheduled in the queue - unlike the maxAMShare limit, the fair share is not a hard limit. So, the FS will schedule non-AM containers in this queue when it cannot schedule AM containers in other queues.\n\nI gave a walkthrough in this comment: https://issues.apache.org/jira/browse/YARN-3633?focusedCommentId=14542895&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14542895","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ragarwal","name":"ragarwal","key":"ragarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=ragarwal&avatarId=18538","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=ragarwal&avatarId=18538","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=ragarwal&avatarId=18538","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=ragarwal&avatarId=18538"},"displayName":"Rohit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-05-19T08:06:25.503+0000","updated":"2015-05-19T08:06:25.503+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12829255/comment/14551146","id":"14551146","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"\\\\\n\\\\\n| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | pre-patch |  15m 17s | Pre-patch trunk compilation is healthy. |\n| {color:green}+1{color} | @author |   0m  0s | The patch does not contain any @author tags. |\n| {color:green}+1{color} | tests included |   0m  0s | The patch appears to include 1 new or modified test files. |\n| {color:green}+1{color} | javac |   7m 48s | There were no new javac warning messages. |\n| {color:green}+1{color} | javadoc |   9m 51s | There were no new javadoc warning messages. |\n| {color:green}+1{color} | release audit |   0m 22s | The applied patch does not increase the total number of release audit warnings. |\n| {color:red}-1{color} | checkstyle |   0m 47s | The applied patch generated  2 new checkstyle issues (total was 120, now 120). |\n| {color:green}+1{color} | whitespace |   0m  2s | The patch has no lines that end in whitespace. |\n| {color:green}+1{color} | install |   1m 32s | mvn install still works. |\n| {color:green}+1{color} | eclipse:eclipse |   0m 34s | The patch built with eclipse:eclipse. |\n| {color:red}-1{color} | findbugs |   1m 19s | The patch appears to introduce 1 new Findbugs (version 3.0.0) warnings. |\n| {color:green}+1{color} | yarn tests |  50m 40s | Tests passed in hadoop-yarn-server-resourcemanager. |\n| | |  88m 17s | |\n\\\\\n\\\\\n|| Reason || Tests ||\n| FindBugs | module:hadoop-yarn-server-resourcemanager |\n|  |  Inconsistent synchronization of org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore.isHDFS; locked 66% of time  Unsynchronized access at FileSystemRMStateStore.java:66% of time  Unsynchronized access at FileSystemRMStateStore.java:[line 156] |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Patch URL | http://issues.apache.org/jira/secure/attachment/12733912/YARN-3633-1.patch |\n| Optional Tests | javadoc javac unit findbugs checkstyle |\n| git revision | trunk / fd3cb53 |\n| checkstyle |  https://builds.apache.org/job/PreCommit-YARN-Build/8005/artifact/patchprocess/diffcheckstylehadoop-yarn-server-resourcemanager.txt |\n| Findbugs warnings | https://builds.apache.org/job/PreCommit-YARN-Build/8005/artifact/patchprocess/newPatchFindbugsWarningshadoop-yarn-server-resourcemanager.html |\n| hadoop-yarn-server-resourcemanager test log | https://builds.apache.org/job/PreCommit-YARN-Build/8005/artifact/patchprocess/testrun_hadoop-yarn-server-resourcemanager.txt |\n| Test Results | https://builds.apache.org/job/PreCommit-YARN-Build/8005/testReport/ |\n| Java | 1.7.0_55 |\n| uname | Linux asf903.gq1.ygridcore.net 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |\n| Console output | https://builds.apache.org/job/PreCommit-YARN-Build/8005/console |\n\n\nThis message was automatically generated.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2015-05-19T20:21:30.075+0000","updated":"2015-05-19T20:21:30.075+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12829255/comment/14551213","id":"14551213","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ragarwal","name":"ragarwal","key":"ragarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=ragarwal&avatarId=18538","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=ragarwal&avatarId=18538","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=ragarwal&avatarId=18538","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=ragarwal&avatarId=18538"},"displayName":"Rohit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"body":"The remaining checkstyle and findbugs issues seem to be preexisting.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ragarwal","name":"ragarwal","key":"ragarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=ragarwal&avatarId=18538","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=ragarwal&avatarId=18538","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=ragarwal&avatarId=18538","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=ragarwal&avatarId=18538"},"displayName":"Rohit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-05-19T20:59:16.313+0000","updated":"2015-05-19T20:59:16.313+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12829255/comment/14609119","id":"14609119","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=asuresh","name":"asuresh","key":"asuresh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun Suresh","active":true,"timeZone":"America/Los_Angeles"},"body":"[~ragarwal], Was just wondering.. wrt the scenario you mentioned in [here|https://issues.apache.org/jira/browse/YARN-3633?focusedCommentId=14542895&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14542895]. Isnt it possible that AM4 can remain unscheduled (starved) until AM1/AM2 or AM3 completes ? Basically containers started by AM1/2 and 3 might start and end, but until an application itself completes, AM4 will not be scheduled.. right ?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=asuresh","name":"asuresh","key":"asuresh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun Suresh","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-06-30T21:34:41.296+0000","updated":"2015-06-30T21:34:41.296+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12829255/comment/14609163","id":"14609163","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ragarwal","name":"ragarwal","key":"ragarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=ragarwal&avatarId=18538","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=ragarwal&avatarId=18538","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=ragarwal&avatarId=18538","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=ragarwal&avatarId=18538"},"displayName":"Rohit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"body":"Yes, that is very much possible. But without this change - this scenario will result in none of the applications making any progress. I would take one application getting starved over the whole cluster getting starved any day. :-)\n\nFWIW, we have been running our clusters with this patch for a month now and haven't seen any cluster logjam since.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ragarwal","name":"ragarwal","key":"ragarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=ragarwal&avatarId=18538","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=ragarwal&avatarId=18538","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=ragarwal&avatarId=18538","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=ragarwal&avatarId=18538"},"displayName":"Rohit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-06-30T22:08:03.114+0000","updated":"2015-06-30T22:08:03.114+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12829255/comment/14609175","id":"14609175","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=asuresh","name":"asuresh","key":"asuresh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun Suresh","active":true,"timeZone":"America/Los_Angeles"},"body":"Agreed..\nSo just so that Im on the same page, the {{clusterMaxAMShare}} is essentially acting as an upper limit.. right ? Can we have the default as negative, to preserve current behavior by default ?\n\nOtherwise, the patch looks good.. although I feel in the {{addAMResourceUsage}}, I think we should synchronize the part where we add the {{amResource}} to the scheduler's total am resource usage field.\n+1 after that.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=asuresh","name":"asuresh","key":"asuresh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun Suresh","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-06-30T22:23:15.236+0000","updated":"2015-06-30T22:23:15.236+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12829255/comment/14609248","id":"14609248","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ragarwal","name":"ragarwal","key":"ragarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=ragarwal&avatarId=18538","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=ragarwal&avatarId=18538","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=ragarwal&avatarId=18538","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=ragarwal&avatarId=18538"},"displayName":"Rohit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"body":"Yes, the {{clusterMaxAMShare}} is acting as an upper limit.\n\nTo maintain the current behavior, we should keep the default {{clusterMaxAMShare}} as 0.5 only.\nRight now, the default for {{queueMaxAMShare}} is 0.5, which results in an implicit {{clusterMaxAMShare}} of 0.5, this is because no queue allows more than 50% of its resources to be allocated to AMs and hence no more than 50% of the cluster resources can be allocated to AMs.\nWith this change, queueMaxAMShare only restricts AMs when there is already at least one AM running in the queue. So, {{clusterMaxAMShare}} is needed to avoid the cluster from getting overrun with AMs (YARN-1913).\n\nWe should set {{clusterMaxAMShare}} to negative, only in those cases where we would set {{queueMaxAMShare}} to negative - i.e. when we don't want to restrict AM usage.\n\n----------------------------------------------\n\nRegarding synchronization, I am wondering why the existing line in addAMResourceUsage not synchronized? Is this code called concurrently? Also, if I should synchronize, should I synchronize the method or just the line I added?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ragarwal","name":"ragarwal","key":"ragarwal","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=ragarwal&avatarId=18538","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=ragarwal&avatarId=18538","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=ragarwal&avatarId=18538","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=ragarwal&avatarId=18538"},"displayName":"Rohit Agarwal","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-06-30T23:30:22.482+0000","updated":"2015-06-30T23:30:22.482+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12829255/comment/14609278","id":"14609278","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=asuresh","name":"asuresh","key":"asuresh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun Suresh","active":true,"timeZone":"America/Los_Angeles"},"body":"I guess the line that was introduced needs to be synchronized (guess we need to do the same for {{removeApp}} where we are subtracting).. given that you are adding/subtracting from \"totalAmResourceUsage\" defined in the {{FairScheduler}}.. and considering that the {{Resources#addTo/subtractFrom}} actually performs a get and set (and the value can change in between if some other AM is added/removed.. possibly during a concurrently running continuous scheduling attempt)","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=asuresh","name":"asuresh","key":"asuresh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun Suresh","active":true,"timeZone":"America/Los_Angeles"},"created":"2015-06-30T23:54:51.119+0000","updated":"2015-06-30T23:54:51.119+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12829255/comment/15835478","id":"15835478","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m  0s{color} | {color:blue} Docker mode activated. {color} |\n| {color:red}-1{color} | {color:red} patch {color} | {color:red}  0m  5s{color} | {color:red} YARN-3633 does not apply to trunk. Rebase required? Wrong Branch? See https://wiki.apache.org/hadoop/HowToContribute for help. {color} |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| JIRA Issue | YARN-3633 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12733912/YARN-3633-1.patch |\n| Console output | https://builds.apache.org/job/PreCommit-YARN-Build/14739/console |\n| Powered by | Apache Yetus 0.5.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2017-01-24T01:06:42.489+0000","updated":"2017-01-24T01:06:42.489+0000"}],"maxResults":18,"total":18,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/YARN-3633/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i2emq7:"}}