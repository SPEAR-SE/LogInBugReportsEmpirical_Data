{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12855530","self":"https://issues.apache.org/jira/rest/api/2/issue/12855530","key":"YARN-4048","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12313722","id":"12313722","key":"YARN","name":"Hadoop YARN","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12313722&avatarId=15135","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12313722&avatarId=15135","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12313722&avatarId=15135","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12313722&avatarId=15135"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":"2015-08-26T21:34:05.064+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Tue Sep 19 19:09:20 UTC 2017","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/YARN-4048/watchers","watchCount":25,"isWatching":false},"created":"2015-08-12T12:02:40.243+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/2","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/critical.svg","name":"Critical","id":"2"},"labels":[],"customfield_12312333":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"1.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12331976","id":"12331976","description":"2.7.1 release","name":"2.7.1","archived":false,"released":true,"releaseDate":"2015-07-06"}],"issuelinks":[{"id":"12464674","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12464674","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"inwardIssue":{"id":"12932114","key":"YARN-4599","self":"https://issues.apache.org/jira/rest/api/2/issue/12932114","fields":{"summary":"Set OOM control for memory cgroups","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/7","id":"7","description":"The sub-task of the issue","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype","name":"Sub-task","subtask":true,"avatarId":21146}}}},{"id":"12465737","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12465737","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"inwardIssue":{"id":"12965150","key":"YARN-5040","self":"https://issues.apache.org/jira/rest/api/2/issue/12965150","fields":{"summary":"CPU Isolation with CGroups triggers kernel panics on Centos 7.1/7.2 when yarn.nodemanager.resource.percentage-physical-cpu-limit < 100","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}}],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2017-09-19T19:09:20.634+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12319323","id":"12319323","name":"nodemanager"}],"timeoriginalestimate":null,"description":"With YARN-2440 and YARN-2531, we have seen some kernel panics happening under heavy pressure. Even with YARN-2809, it still panics.\n\nWe are using CentOS 6.5, hadoop 2.5.0-cdh5.2.0 with the above patches. I guess the latest version also has the same issue.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12750069","id":"12750069","filename":"panic.png","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chengbing.liu","name":"chengbing.liu","key":"chengbing.liu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chengbing Liu","active":true,"timeZone":"Asia/Shanghai"},"created":"2015-08-12T12:04:39.788+0000","size":16808,"mimeType":"image/png","content":"https://issues.apache.org/jira/secure/attachment/12750069/panic.png"}],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"Linux kernel panic under strict CPU limits(on CentOS/RHEL 6.x)","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chengbing.liu","name":"chengbing.liu","key":"chengbing.liu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chengbing Liu","active":true,"timeZone":"Asia/Shanghai"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chengbing.liu","name":"chengbing.liu","key":"chengbing.liu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chengbing Liu","active":true,"timeZone":"Asia/Shanghai"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12855530/comment/14693377","id":"14693377","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chengbing.liu","name":"chengbing.liu","key":"chengbing.liu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chengbing Liu","active":true,"timeZone":"Asia/Shanghai"},"body":"Stacktrace attached. I'm sorry it is not available in text now.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=chengbing.liu","name":"chengbing.liu","key":"chengbing.liu","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Chengbing Liu","active":true,"timeZone":"Asia/Shanghai"},"created":"2015-08-12T12:04:39.792+0000","updated":"2015-08-12T12:04:39.792+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12855530/comment/14715561","id":"14715561","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ccondit","name":"ccondit","key":"ccondit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=ccondit&avatarId=36345","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=ccondit&avatarId=36345","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=ccondit&avatarId=36345","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=ccondit&avatarId=36345"},"displayName":"Craig Condit","active":true,"timeZone":"America/Chicago"},"body":"Just my two cents: Using cgroups on CentOS/RHEL 6.x is asking for it... We've experienced similar crashes using anything that utilizes cgroups, not just YARN (for example -- docker).\n\nCgroups is widely regarded as unstable in Linux kernel versions < 3.10 or so.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ccondit","name":"ccondit","key":"ccondit","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=ccondit&avatarId=36345","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=ccondit&avatarId=36345","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=ccondit&avatarId=36345","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=ccondit&avatarId=36345"},"displayName":"Craig Condit","active":true,"timeZone":"America/Chicago"},"created":"2015-08-26T21:34:05.064+0000","updated":"2015-08-26T21:34:05.064+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12855530/comment/15009343","id":"15009343","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=Naganarasimha","name":"Naganarasimha","key":"naganarasimha","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Naganarasimha G R","active":true,"timeZone":"Asia/Kolkata"},"body":"Hi [~ccondit] \nWe too have faced this many times and as alternative where OS cannot be upgraded we have CPU isolation based on CPUset which is not same as existing which based on period & quota but atleast will ensure the cpu usage of the Node doesnt exceed the number of cores assigned for YARN containers.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=Naganarasimha","name":"Naganarasimha","key":"naganarasimha","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Naganarasimha G R","active":true,"timeZone":"Asia/Kolkata"},"created":"2015-11-17T19:34:51.572+0000","updated":"2015-11-17T19:34:51.572+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12855530/comment/15096166","id":"15096166","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=geynard","name":"geynard","key":"geynard","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Guillaume E.B.","active":true,"timeZone":"Europe/Paris"},"body":"Hi,\n\nI am also facing this issue on Cent OS 6.3 nodes. I tried to upgrade kernel and libcgroup to CentOS 6.7 versions, but hit the same problem.\nCurrently out of option (RHEL 7 upgrade don't seem plausible), but I need to have a CPU isolation mechanism because otherwise some jobs launched on our platform just take too much resources and I see tasks failures and some jobs failures too.\n[~Naganarasimha], is it possible to have a grasp of what your solution based on CPUset is ?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=geynard","name":"geynard","key":"geynard","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Guillaume E.B.","active":true,"timeZone":"Europe/Paris"},"created":"2016-01-13T13:18:11.139+0000","updated":"2016-01-13T13:18:11.139+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12855530/comment/15096214","id":"15096214","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=geynard","name":"geynard","key":"geynard","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Guillaume E.B.","active":true,"timeZone":"Europe/Paris"},"body":"Forget to precise that our cluster is running on hadoop 2.6.0-CDH5.4.0, with patch YARN-2809.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=geynard","name":"geynard","key":"geynard","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Guillaume E.B.","active":true,"timeZone":"Europe/Paris"},"created":"2016-01-13T14:00:14.615+0000","updated":"2016-01-13T14:00:14.615+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12855530/comment/15096669","id":"15096669","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=Naganarasimha","name":"Naganarasimha","key":"naganarasimha","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Naganarasimha G R","active":true,"timeZone":"Asia/Kolkata"},"body":"Hi [~geynard],\nSorry to hear you too faced the same problem, \nwhat we did is we have a configuration to optionally opt for cpuset based approach if we face issues like this. And suppose its 16 core machine and we configured 75% of cpu can be used for YARN, then we try to configure 12 (we try to round it off to lower value if the configurations doesnt match) cores for YARN in the CPU  cgroup subsystem. So yarn's containers will be ensured to run only on the first 12 cores of the system and remaining 4 will be at the system's disposal for other processes. *This approach ensures CPU is isolated with other processes but not among the yarn's containers.*","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=Naganarasimha","name":"Naganarasimha","key":"naganarasimha","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Naganarasimha G R","active":true,"timeZone":"Asia/Kolkata"},"created":"2016-01-13T17:50:29.178+0000","updated":"2016-01-13T17:50:29.178+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12855530/comment/15253619","id":"15253619","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=scootli","name":"scootli","key":"scootli","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"lihuaqing","active":true,"timeZone":"Asia/Chongqing"},"body":"Hi Naganarasimha G R:\n   I want to know how config the cgroup cpuset with hadoop 2.7.1. I don't find  in the document of hadoop. Please show me?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=scootli","name":"scootli","key":"scootli","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"lihuaqing","active":true,"timeZone":"Asia/Chongqing"},"created":"2016-04-22T09:32:04.078+0000","updated":"2016-04-22T09:32:04.078+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12855530/comment/15253789","id":"15253789","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=Naganarasimha","name":"Naganarasimha","key":"naganarasimha","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Naganarasimha G R","active":true,"timeZone":"Asia/Kolkata"},"body":"Hi [~scootli]\n\nIt was a private code modification based on 2.7.0 and is not available outside. Hence no documentation of it either.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=Naganarasimha","name":"Naganarasimha","key":"naganarasimha","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Naganarasimha G R","active":true,"timeZone":"Asia/Kolkata"},"created":"2016-04-22T11:46:49.982+0000","updated":"2016-04-22T11:46:49.982+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12855530/comment/15392949","id":"15392949","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=imstefanlee","name":"imstefanlee","key":"imstefanlee","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10448","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10448","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10448","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10448"},"displayName":"stefanlee","active":true,"timeZone":"Asia/Shanghai"},"body":"i have the same problem, my hadoop version is 2.6.2","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=imstefanlee","name":"imstefanlee","key":"imstefanlee","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10448","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10448","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10448","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10448"},"displayName":"stefanlee","active":true,"timeZone":"Asia/Shanghai"},"created":"2016-07-26T01:00:49.100+0000","updated":"2016-07-26T01:00:49.100+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12855530/comment/16172195","id":"16172195","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=Tagar","name":"Tagar","key":"tagar","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10448","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10448","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10448","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10448"},"displayName":"Ruslan Dautkhanov","active":true,"timeZone":"America/Denver"},"body":"Information on this linux kernel panic from RHEL CASE 01901460.\nThey have analyzed the crash file dumped during panic and came up with below analysis of the problem.\n\n{noformat}\nKwon, Daniel on Aug 02 2017 at 11:25 PM -06:00 \nHi, \n\nThis is Daniel Kwon from Kernel team. I'm working with the case owner to support your case. \n\nThe system was crashed due to hard lockup which means there was a process holding a CPU for more than 60 seconds. \n\n------------------------------------------------------------------------------ \nCPUS: 88 \nDATE: Fri Jul 28 14:37:44 2017 \nUPTIME: 15 days, 16:42:29 \nLOAD AVERAGE: 109.16, 39.97, 15.17 \nTASKS: 3728 \nNODENAME: pc1udahad14 \nRELEASE: 2.6.32-696.3.2.el6.x86_64 \nVERSION: #1 SMP Wed Jun 7 11:51:39 EDT 2017 \nMACHINE: x86_64 (2397 Mhz) \nMEMORY: 511.9 GB \nPANIC: \"Kernel panic - not syncing: Hard LOCKUP\" \n------------------------------------------------------------------------------ \n\nChecking the runqueue time shows that there were many CPUs not updated lately which means processes were holding those CPUs for long. \n\n------------------------------------------------------------------------------ \ncrash> runq -t | grep CPU | sort -k3r | awk 'NR==1{now=strtonum(\"0x\"$3)}1{printf\"%s\\t%7.2fs behind\\n\",$0,(now-strtonum(\"0x\"$3))/1000000000}' \nCPU 25: 4d0f5bec32555 0.00s behind \nCPU 2: 4d0f5bec32015 0.00s behind \n<... cut ...> \nCPU 4: 4d0f5bb9984fb 0.05s behind \nCPU 61: 4d0f5bb8f5619 0.05s behind \nCPU 57: 4d0f5bb83f85d 0.05s behind \nCPU 17: 4d0f5bb78ad7d 0.06s behind \nCPU 12: 4d0f5ba972dbd 0.07s behind \nCPU 48: 4d0f5ba8b4980 0.07s behind \nCPU 84: 4d0f5ba72ca7e 0.07s behind \nCPU 13: 4d0f5966bef24 0.68s behind \nCPU 15: 4d0f58a123cfd 0.88s behind \nCPU 54: 4d0f5832e5754 1.00s behind \nCPU 62: 4d0f581d593b7 1.02s behind \nCPU 49: 4d0f54868608e 1.99s behind \nCPU 52: 4d0f5480bd287 1.99s behind \nCPU 24: 4d0eb096f58da 45.99s behind \nCPU 35: 4d0e730040f57 62.52s behind \nCPU 85: 4d0e42eaeaea0 75.43s behind \nCPU 46: 4d0e3287e8aae 79.83s behind \nCPU 1: 4d0e1072119ac 88.98s behind \nCPU 45: 4d0e061ec766a 91.75s behind \nCPU 60: 4d0db70bc6ad6 112.98s behind \nCPU 6: 4d0db002d7b9b 114.87s behind \nCPU 14: 4d0d9679efaad 121.72s behind \nCPU 9: 4d0d938f74e97 122.50s behind \nCPU 51: 4d0d912c6d77e 123.14s behind \nCPU 5: 4d0d807a6de65 127.63s behind \nCPU 53: 4d0d80637174f 127.65s behind \nCPU 70: 4d0d78c599c8e 129.69s behind \nCPU 44: 4d0d75602d3c3 130.61s behind \nCPU 3: 4d0d6fe84455e 132.07s behind \nCPU 0: 4d0d6f1c22d11 132.29s behind \nCPU 47: 4d0d6f16a2e95 132.29s behind \nCPU 64: 4d0d6f06851ee 132.31s behind \nCPU 59: 4d0d6da9596d6 132.68s behind \nCPU 23: 4d0d6d89ecaaa 132.71s behind \nCPU 22: 4d0d6c8ad9dd2 132.98s behind \nCPU 67: 4d0d6c853e44d 132.98s behind \n------------------------------------------------------------------------------ \n\nI have checked the two longest holders which are CPU 22 and CPU 67. \n\nThe process on CPU 67 was awaiting for runqueue lock for the current CPU. \n\n------------------------------------------------------------------------------ \ncrash> runq -c 67 \nCPU 67 RUNQUEUE: ffff8841616f6ec0 \nCURRENT: PID: 40639 TASK: ffff885c89c5b520 COMMAND: \"java\" \nRT PRIO_ARRAY: ffff8841616f7048 \n[ 0] PID: 271 TASK: ffff8840266c7520 COMMAND: \"migration/67\" \n[ 0] PID: 274 TASK: ffff8840266d6ab0 COMMAND: \"watchdog/67\" \nCFS RB_ROOT: ffff8841616f6f58 \n[120] PID: 422 TASK: ffff884026392ab0 COMMAND: \"events/67\" \n[120] PID: 7857 TASK: ffff888005966040 COMMAND: \"kondemand/67\" \ncrash> bt 40639 \nPID: 40639 TASK: ffff885c89c5b520 CPU: 67 COMMAND: \"java\" \n#0 [ffff8841616e6e90] crash_nmi_callback at ffffffff81036726 \n#1 [ffff8841616e6ea0] notifier_call_chain at ffffffff81551085 \n#2 [ffff8841616e6ee0] atomic_notifier_call_chain at ffffffff815510ea \n#3 [ffff8841616e6ef0] notify_die at ffffffff810acd0e \n#4 [ffff8841616e6f20] do_nmi at ffffffff8154ec09 \n#5 [ffff8841616e6f50] nmi at ffffffff8154e5b3 \n[exception RIP: wait_for_rqlock+0x31] \n<... cut ...> \n--- <NMI exception stack> --- \n#6 [ffff887fd461feb8] wait_for_rqlock at ffffffff8105d751 \n#7 [ffff887fd461fec0] do_exit at ffffffff81081dbc \n#8 [ffff887fd461ff40] do_group_exit at ffffffff810820c8 \n#9 [ffff887fd461ff70] sys_exit_group at ffffffff81082157 \n#10 [ffff887fd461ff80] system_call_fastpath at ffffffff8100b0d2 \n<... cut ...> \n------------------------------------------------------------------------------ \n\nThe process on CPU 22 was also waiting for runqueue lock. This time it was waiting for the runqueue lock for a specific task which is java (40639) that was running on CPU 67. \n\n------------------------------------------------------------------------------ \ncrash> runq -c 22 \nCPU 22 RUNQUEUE: ffff884161416ec0 \nCURRENT: PID: 8944 TASK: ffff88801833eab0 COMMAND: \"cmf-agent\" \nRT PRIO_ARRAY: ffff884161417048 \n[no tasks queued] \nCFS RB_ROOT: ffff884161416f58 \n[no tasks queued] \n\ncrash> bt 8944 \nPID: 8944 TASK: ffff88801833eab0 CPU: 22 COMMAND: \"cmf-agent\" \n#0 [ffff884161406e90] crash_nmi_callback at ffffffff81036726 \n#1 [ffff884161406ea0] notifier_call_chain at ffffffff81551085 \n#2 [ffff884161406ee0] atomic_notifier_call_chain at ffffffff815510ea \n#3 [ffff884161406ef0] notify_die at ffffffff810acd0e \n#4 [ffff884161406f20] do_nmi at ffffffff8154ec09 \n#5 [ffff884161406f50] nmi at ffffffff8154e5b3 \n[exception RIP: task_rq_unlock_wait+0x2a] \nRIP: ffffffff8105d7ba RSP: ffff88800676fdb8 RFLAGS: 00000016 \nRAX: 0000000048a1488f RBX: ffff885c89c5b520 RCX: ffff8841616f6ec0 \nRDX: 00000000000048a1 RSI: ffff882bbb9e6060 RDI: ffff885c89c5b520 \nRBP: ffff88800676fdb8 R8: ffff888005e28310 R9: dead000000200200 \nR10: ffff888005e28310 R11: 0000000000000000 R12: 0000000000011958 \nR13: ffff888005e281c0 R14: 0000000000009e01 R15: ffff888018314cc0 \nORIG_RAX: ffffffffffffffff CS: 0010 SS: 0018 \n--- <NMI exception stack> --- \n#6 [ffff88800676fdb8] task_rq_unlock_wait at ffffffff8105d7ba \n#7 [ffff88800676fdc0] release_task at ffffffff8107ff19 \n#8 [ffff88800676fe10] wait_consider_task at ffffffff81080a26 \n#9 [ffff88800676fe80] do_wait at ffffffff81080e56 \n#10 [ffff88800676fee0] sys_wait4 at ffffffff81081043 \n#11 [ffff88800676ff80] system_call_fastpath at ffffffff8100b0d2 \n<... cut ...> \n\nvoid task_rq_unlock_wait(struct task_struct *p) \n{ \nstruct rq *rq = task_rq(p); \n\nsmp_mb(); /* spin-unlock-wait is not a full memory barrier */ \nspin_unlock_wait(&rq->lock); \n} \n\n\n#7 [ffff88800676fdc0] release_task at ffffffff8107ff19 \nffff88800676fdc8: 0000000045c0e1a1 ffff8880183154c8 \nffff88800676fdd8: 0000000000000000 00007fffffffeffd \nffff88800676fde8: ffff885c89c5b520 0000000000000000 \n^ \n+--- task waiting \nffff88800676fdf8: 0000000000009ebf 0000000000009ebf \nffff88800676fe08: ffff88800676fe78 ffffffff81080a26 \n#8 [ffff88800676fe10] wait_consider_task at ffffffff81080a26 \n\n\ncrash> set ffff885c89c5b520\t<-- same lock as the first one. \nPID: 40639 \nCOMMAND: \"java\" \nTASK: ffff885c89c5b520 [THREAD_INFO: ffff887fd461c000] \nCPU: 67 \nSTATE: EXIT_DEAD (ACTIVE) \n\n\n/** \n* spin_unlock_wait - wait until the spinlock gets unlocked \n* @lock: the spinlock in question. \n*/ \n#define spin_unlock_wait(lock) __raw_spin_unlock_wait(&(lock)->raw_lock) \n\n\ncrash> struct rq.lock ffff8841616f6ec0 -ox \nstruct rq { \n[ffff8841616f6ec0] spinlock_t lock; \n} \n------------------------------------------------------------------------------ \n\nSo, both processes were blocked in CPUs waiting for the same runqueue lock. We need to find out who was holding this runqueue lock (ffff8841616f6ec0). \n\n\nThis runqueue lock was held by process running on CPU 30. \n\n------------------------------------------------------------------------------ \ncrash> bt \nPID: 0 TASK: ffff8840268e6ab0 CPU: 30 COMMAND: \"swapper\" \n#0 [ffff884161506e90] crash_nmi_callback at ffffffff81036726 \n#1 [ffff884161506ea0] notifier_call_chain at ffffffff81551085 \n#2 [ffff884161506ee0] atomic_notifier_call_chain at ffffffff815510ea \n#3 [ffff884161506ef0] notify_die at ffffffff810acd0e \n#4 [ffff884161506f20] do_nmi at ffffffff8154ec09 \n#5 [ffff884161506f50] nmi at ffffffff8154e5b3 \n[exception RIP: load_balance_fair+0xb7] \n<... cut ...> \n--- <NMI exception stack> --- \n#6 [ffff884161503cc0] load_balance_fair at ffffffff8106bcb7 \n#7 [ffff884161503d88] rebalance_domains at ffffffff810707f3 \n#8 [ffff884161503e78] run_rebalance_domains at ffffffff81070bfc \n#9 [ffff884161503ec8] __do_softirq at ffffffff81085335 \n#10 [ffff884161503f48] call_softirq at ffffffff8100c38c \n#11 [ffff884161503f60] do_softirq at ffffffff8100fc95 \n#12 [ffff884161503f80] irq_exit at ffffffff810851c5 \n#13 [ffff884161503f90] smp_apic_timer_interrupt at ffffffff81554c5a \n#14 [ffff884161503fb0] apic_timer_interrupt at ffffffff8100bc13 \n--- <IRQ stack> --- \n#15 [ffff8840268f3d98] apic_timer_interrupt at ffffffff8100bc13 \n<... cut ...> \n#16 [ffff8840268f3ee0] cpuidle_idle_call at ffffffff81443a7a \n#17 [ffff8840268f3f00] cpu_idle at ffffffff81009fe6 \n------------------------------------------------------------------------------ \n\nWhile it's doing moving tasks between CPUs, it had to take the CPU 67's runqueue lock. \n\n------------------------------------------------------------------------------ \n/usr/src/debug/kernel-2.6.32-696.3.2.el6/linux-2.6.32-696.3.2.el6.x86_64/kernel/sched.c: 3622 \n0xffffffff810707c8 <rebalance_domains+0x2b8>: lea -0x40(%rbp),%rdi \n0xffffffff810707cc <rebalance_domains+0x2bc>: lea -0x38(%rbp),%rax \n<... cut ...> \n0xffffffff810707e2 <rebalance_domains+0x2d2>: mov %rax,(%rsp) \n0xffffffff810707e6 <rebalance_domains+0x2d6>: mov %r15,%rdx\t<--- busiest \n0xffffffff810707e9 <rebalance_domains+0x2d9>: mov -0x74(%rbp),%esi \n0xffffffff810707ec <rebalance_domains+0x2dc>: mov -0x70(%rbp),%rdi \n0xffffffff810707f0 <rebalance_domains+0x2e0>: callq *0x40(%rbx) \n\n\n3611 static int move_tasks(struct rq *this_rq, int this_cpu, struct rq *busiest , \n3612 unsigned long max_load_move, \n3613 struct sched_domain *sd, enum cpu_idle_type idle, \n3614 int *all_pinned) \n3615 { \n3616 const struct sched_class *class = sched_class_highest; \n3617 unsigned long total_load_moved = 0; \n3618 int this_best_prio = this_rq->curr->prio; \n3619 \n3620 do { \n3621 total_load_moved += \n3622 class->load_balance(this_rq, this_cpu, busiest, \n3623 max_load_move - total_load_moved, \n3624 sd, idle, all_pinned, &this_best_prio); \n\n\n\n\n4594 static int load_balance(int this_cpu, struct rq *this_rq, \n4595 struct sched_domain *sd, enum cpu_idle_type idle, \n4596 int *balance) \n4597 { \n<... cut ...> \n4652 imbalance, sd, idle, &all_pinned); \n\n\n/usr/src/debug/kernel-2.6.32-696.3.2.el6/linux-2.6.32-696.3.2.el6.x86_64/kernel/ \nsched.c: 4650 \n0xffffffff81070796 <rebalance_domains+0x286>: mov -0x70(%rbp),%rdi\t<-- this_rq \n0xffffffff8107079a <rebalance_domains+0x28a>: mov %r15,%rsi\t<-- busiest \n/usr/src/debug/kernel-2.6.32-696.3.2.el6/linux-2.6.32-696.3.2.el6.x86_64/kernel/ \nsched.c: 3618 \n<... cut ...> \n\n/usr/src/debug/kernel-2.6.32-696.3.2.el6/linux-2.6.32-696.3.2.el6.x86_64/kernel/ \nsched_fair.c: 2795 \n0xffffffff8106bc26 <load_balance_fair+0x26>: mov %rdx,-0x78(%rbp)\t<--- busiest \n\ncrash> bt -f | grep \" rebalance\" -B 1 \nffff884161503d88: ffffffff810707f3 \n#7 [ffff884161503d88] rebalance_domains at ffffffff810707f3 \ncrash> px 0xffff884161503d80-0x78 \n$15 = 0xffff884161503d08 \ncrash> rd 0xffff884161503d08 \nffff884161503d08: ffff8841616f6ec0 .noaA... \ncrash> runq | grep ffff8841616f6ec0 \nCPU 67 RUNQUEUE: ffff8841616f6ec0 \n------------------------------------------------------------------------------ \n\nWhile it is holding the lock, it was checking each task_groups and tried to rebalance some tasks. \n\n\n------------------------------------------------------------------------------ \n2803 list_for_each_entry_rcu(tg, &task_groups, list) { \n2804 struct cfs_rq *busiest_cfs_rq = tg->cfs_rq[busiest_cpu]; \n2805 unsigned long busiest_h_load = busiest_cfs_rq->h_load; \n2806 unsigned long busiest_weight = busiest_cfs_rq->load.weight;\t<--- was running this part \n------------------------------------------------------------------------------ \n\nAs it's not blocked, it will be released some time later, but checking the number of groups pointed in task_groups was 2421 which means takes quite some time for this looping operation. \n\n------------------------------------------------------------------------------ \ncrash> list 0xffff886d001a54d8 | wc -l \n2421 \n------------------------------------------------------------------------------ \n\nWe can tell that there were at least 2,421 task_groups. I didn't check children of each task_group as it's too long tedious task ans 2,421 is already a big number. Even with this big number it can take long time to traverse and moving tasks. By default there's only one task_group and we can add task_group using 'cgroup', but in this case there were too big number of task_groups which was causing of overall slowness. \n\nChecking the sosreport confirms nothing was configured in /etc/cgconfig.conf. However, I could see that there's runtime generated cgroups. \n\n------------------------------------------------------------------------------ \n$ grep cgroup df \ncm_cgroups 0 0 0 - /var/run/cloudera-scm-agent/cgroups/blkio \ncm_cgroups 0 0 0 - /var/run/cloudera-scm-agent/cgroups/cpuacct \ncm_cgroups 0 0 0 - /var/run/cloudera-scm-agent/cgroups/cpu \ncm_cgroups 0 0 0 - /var/run/cloudera-scm-agent/cgroups/memory \n------------------------------------------------------------------------------ \n\n\nAnd this cgroups were used by hadoop applications. \n\n------------------------------------------------------------------------------ \nyarn 83493 0.0 0.0 23368 1144 ? S 13:13 0:00 /opt/cloudera/parcels/CDH-5.10.1-1.cdh5.10.1.p2224.2407/lib/hadoop-yarn/bin/container-executor dsteiner dsteiner 1 application_1501200023435_0120 container_e130_1501200023435_0120_01_000209 /hdfs01/yarn/nm/usercache/dsteiner/appcache/application_1501200023435_0120/container_e130_1501200023435_0120_01_000209 /hdfs06/yarn/nm/nmPrivate/application_1501200023435_0120/container_e130_1501200023435_0120_01_000209/launch_container.sh /hdfs08/yarn/nm/nmPrivate/application_1501200023435_0120/container_e130_1501200023435_0120_01_000209/container_e130_1501200023435_0120_01_000209.tokens /hdfs02/yarn/nm/nmPrivate/application_1501200023435_0120/container_e130_1501200023435_0120_01_000209/container_e130_1501200023435_0120_01_000209.pid /hdfs01/yarn/nm /hdfs02/yarn/nm /hdfs03/yarn/nm /hdfs04/yarn/nm /hdfs05/yarn/nm /hdfs06/yarn/nm /hdfs07/yarn/nm /hdfs08/yarn/nm /hdfs09/yarn/nm /hdfs10/yarn/nm /var/log/hadoop-yarn/container cgroups=/var/run/cloudera-scm-agent/cgroups/cpu/hadoop-yarn/container_e130_1501200023435_0120_01_000209/tasks \n\n\n$ grep cgroups ps | wc -l \n23 \n------------------------------------------------------------------------------ \n\nI checked some task_groups from the list and could see that they were all belong to 'hadoop-yarn'. \n\n------------------------------------------------------------------------------ \ncrash> list 0xffff886d001a54d8 | head \nffff886d001a54d8 \nffff883d335eb8d8 \n<... cut ...> \nffff8831c4c490d8 \ncrash> px 0xffff886d001a54d8-0xd8 \n$23 = 0xffff886d001a5400 \n\ncrash> task_group.css 0xffff886d001a5400 \ncss = { \ncgroup = 0xffff8871fbdc8000, \nrefcnt = { \ncounter = 0x1 \n}, \nflags = 0x0, \nid = 0x0 \n} \n\ncrash> cgroup.dentry 0xffff8871fbdc8000 \ndentry = 0xffff8851949eba80 \n\ncrash> dentry.d_parent,d_iname 0xffff8851949eba80 \nd_parent = 0xffff884014da5a40 \nd_iname = \"META-INF\\000\\071\\063\\000\\062_0.data\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\" \ncrash> dentry.d_parent,d_iname 0xffff884014da5a40 \nd_parent = 0xffff884014ca3680 \nd_iname = \"hadoop-yarn\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\" \ncrash> dentry.d_parent,d_iname 0xffff884014ca3680 \nd_parent = 0xffff884014ca3680 \nd_iname = \"/\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\"\n\ncrash> px 0xffff883d335eb8d8-0xd8 \n$24 = 0xffff883d335eb800 \ncrash> task_group.css 0xffff883d335eb800 \ncss = { \ncgroup = 0xffff88201b512800, \nrefcnt = { \ncounter = 0x1 \n}, \nflags = 0x0, \nid = 0x0 \n} \ncrash> cgroup.dentry 0xffff88201b512800 \ndentry = 0xffff8824e144d980 \ncrash> dentry.d_parent,d_iname 0xffff8824e144d980 \nd_parent = 0xffff884014da5a40 \nd_iname = \"META-INF\\000ult.xml\\000ata\\000a\\000\\000\\060\\332D\\341$\\210\\377\\377\" \ncrash> dentry.d_parent,d_iname 0xffff884014da5a40 \nd_parent = 0xffff884014ca3680 \nd_iname = \"hadoop-yarn\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\" \ncrash> dentry.d_parent,d_iname 0xffff884014ca3680 \nd_parent = 0xffff884014ca3680 \nd_iname = \"/\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\"\n\ncrash> px 0xffff8831c4c490d8-0xd8 \n$25 = 0xffff8831c4c49000 \ncrash> task_group.css 0xffff8831c4c49000 \ncss = { \ncgroup = 0xffff883582c55a00, \nrefcnt = { \ncounter = 0x1 \n}, \nflags = 0x0, \nid = 0x0 \n} \ncrash> cgroup.dentry 0xffff883582c55a00 \ndentry = 0xffff882d8f4769c0 \ncrash> dentry.d_parent,d_iname 0xffff882d8f4769c0 \nd_parent = 0xffff884014da5a40 \nd_iname = \"org\\000affinity\\000\\060\\071_0.data\\000meta\\000\\000\\000\\000\" \ncrash> dentry.d_parent,d_iname 0xffff884014da5a40 \nd_parent = 0xffff884014ca3680 \nd_iname = \"hadoop-yarn\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\" \ncrash> dentry.d_parent,d_iname 0xffff884014ca3680 \nd_parent = 0xffff884014ca3680 \nd_iname = \"/\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\"\n------------------------------------------------------------------------------ \n\nI don't see any other applications using this cgroup. As it's the only cgroup used by hadoop, could you check with application team the way to reduce the number of cgroups generated by this applications? Please let us know if you have any questions regarding above. Thank you. \n\nBest regards, \nDaniel Kwon \nSenior Software Maintenance Engineer, GSS, Red Hat Asia Pacific \n\n{noformat}\n\nHope this helps.\nNumber of cgroups seems to be the culprit. \nRHEL6/linux kernel 2 may not scale well when a number of cgroups is high.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=Tagar","name":"Tagar","key":"tagar","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10448","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10448","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10448","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10448"},"displayName":"Ruslan Dautkhanov","active":true,"timeZone":"America/Denver"},"created":"2017-09-19T19:09:20.634+0000","updated":"2017-09-19T19:09:20.634+0000"}],"maxResults":10,"total":10,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/YARN-4048/votes","votes":1,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i2itk7:"}}