{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12631401","self":"https://issues.apache.org/jira/rest/api/2/issue/12631401","key":"YARN-389","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12313722","id":"12313722","key":"YARN","name":"Hadoop YARN","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12313722&avatarId=15135","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12313722&avatarId=15135","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12313722&avatarId=15135","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12313722&avatarId=15135"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":"2013-02-08T19:23:58.858+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Mon Sep 02 01:44:08 UTC 2013","customfield_12310420":"311897","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/YARN-389/watchers","watchCount":16,"isWatching":false},"created":"2013-02-08T08:36:10.256+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[],"issuelinks":[{"id":"12366178","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12366178","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"12631866","key":"YARN-394","self":"https://issues.apache.org/jira/rest/api/2/issue/12631866","fields":{"summary":"RM should be able to return requests that it cannot fulfill","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/7","id":"7","description":"The sub-task of the issue","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype","name":"Sub-task","subtask":true,"avatarId":21146}}}},{"id":"12372585","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12372585","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"outwardIssue":{"id":"12659426","key":"YARN-957","self":"https://issues.apache.org/jira/rest/api/2/issue/12659426","fields":{"summary":"Capacity Scheduler tries to reserve the memory more than what node manager reports.","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/1","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/blocker.svg","name":"Blocker","id":"1"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12364435","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12364435","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"inwardIssue":{"id":"12632666","key":"YARN-407","self":"https://issues.apache.org/jira/rest/api/2/issue/12632666","fields":{"summary":"The requested AM memory is not checked against the maximum resource capacity in ResourceMgrDelegate and MRAppMaster","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133}}}},{"id":"12372584","self":"https://issues.apache.org/jira/rest/api/2/issueLink/12372584","type":{"id":"10030","name":"Reference","inward":"is related to","outward":"relates to","self":"https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"},"inwardIssue":{"id":"12604534","key":"YARN-56","self":"https://issues.apache.org/jira/rest/api/2/issue/12604534","fields":{"summary":"Handle container requests that request more resources than currently available in the cluster","status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/4","id":"4","description":"An improvement or enhancement to an existing feature or task.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype","name":"Improvement","subtask":false,"avatarId":21140}}}}],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ojoshi","name":"ojoshi","key":"ojoshi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=ojoshi&avatarId=16634","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=ojoshi&avatarId=16634","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=ojoshi&avatarId=16634","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=ojoshi&avatarId=16634"},"displayName":"Omkar Vinit Joshi","active":true,"timeZone":"America/Los_Angeles"},"customfield_12312337":null,"customfield_12312338":null,"updated":"2013-09-02T01:44:08.214+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"components":[],"timeoriginalestimate":null,"description":"I've run wordcount example on branch-2 and trunk. I've set yarn.nodemanager.resource.memory-mb to 1G and yarn.app.mapreduce.am.resource.mb to 1.5G. Therefore, resourcemanager is to assign a 2G AM container for AM. However, the nodemanager doesn't have enough memory to assign the container. The problem is that the assignment operation will be repeated infinitely, if the assignment cannot be accomplished. Logs follow.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12324806","id":"12324806","description":"2.1.1-beta bug-fix release","name":"2.1.1-beta","archived":false,"released":true,"releaseDate":"2013-09-16"}],"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"312243","customfield_12312823":null,"summary":"Infinitely assigning containers when the required resource exceeds the cluster's absolute capacity","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=zjshen","name":"zjshen","key":"zjshen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10443","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10443","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10443","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10443"},"displayName":"Zhijie Shen","active":true,"timeZone":"America/Los_Angeles"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=zjshen","name":"zjshen","key":"zjshen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10443","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10443","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10443","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10443"},"displayName":"Zhijie Shen","active":true,"timeZone":"America/Los_Angeles"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12631401/comment/13574751","id":"13574751","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinodkv","name":"vinodkv","key":"vinodkv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinod Kumar Vavilapalli","active":true,"timeZone":"America/Los_Angeles"},"body":"Zhijie, a meta comment: It's better to post the problem only in description (and summary) and provide solutions and logs as a followup. Logs can be in follow up comments or attached as separate files.\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinodkv","name":"vinodkv","key":"vinodkv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinod Kumar Vavilapalli","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-02-08T19:23:58.858+0000","updated":"2013-02-08T19:23:58.858+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12631401/comment/13574753","id":"13574753","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinodkv","name":"vinodkv","key":"vinodkv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinod Kumar Vavilapalli","active":true,"timeZone":"America/Los_Angeles"},"body":"Logs:\n\n{code}\n2013-02-07 19:05:05,947 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 1\n2013-02-07 19:05:06,477 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Storing Application with id application_1360292699925_0001\n2013-02-07 19:05:06,479 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1360292699925_0001\n2013-02-07 19:05:06,479 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 1 submitted by user zshen\n2013-02-07 19:05:06,481 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=zshen\tIP=127.0.0.1\tOPERATION=Submit Application Request\tTARGET=ClientRMService\tRESULT=SUCCESS\tAPPID=application_1360292699925_0001\n2013-02-07 19:05:06,493 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1360292699925_0001 State change from NEW to SUBMITTED\n2013-02-07 19:05:06,494 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering appattempt_1360292699925_0001_000001\n2013-02-07 19:05:06,495 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1360292699925_0001_000001 State change from NEW to SUBMITTED\n2013-02-07 19:05:06,506 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1360292699925_0001 from user: zshen activated in queue: default\n2013-02-07 19:05:06,506 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1360292699925_0001 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@4965d0e0, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1\n2013-02-07 19:05:06,506 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1360292699925_0001 user: zshen leaf-queue of parent: root #applications: 1\n2013-02-07 19:05:06,506 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Submission: appattempt_1360292699925_0001_000001, user: zshen queue: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0, currently active: 1\n2013-02-07 19:05:06,508 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1360292699925_0001_000001 State change from SUBMITTED to SCHEDULED\n2013-02-07 19:05:06,509 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1360292699925_0001 State change from SUBMITTED to ACCEPTED\n2013-02-07 19:05:07,163 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default usedResources: <memory:0, vCores:0> clusterResources: <memory:1024, vCores:16> currentCapacity 0.0 required <memory:2048, vCores:1> potentialNewCapacity: 2.0 (  max-capacity: 1.0)\n2013-02-07 19:05:08,164 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default usedResources: <memory:0, vCores:0> clusterResources: <memory:1024, vCores:16> currentCapacity 0.0 required <memory:2048, vCores:1> potentialNewCapacity: 2.0 (  max-capacity: 1.0)\n2013-02-07 19:05:09,167 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default usedResources: <memory:0, vCores:0> clusterResources: <memory:1024, vCores:16> currentCapacity 0.0 required <memory:2048, vCores:1> potentialNewCapacity: 2.0 (  max-capacity: 1.0)\n2013-02-07 19:05:10,168 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default usedResources: <memory:0, vCores:0> clusterResources: <memory:1024, vCores:16> currentCapacity 0.0 required <memory:2048, vCores:1> potentialNewCapacity: 2.0 (  max-capacity: 1.0)\n2013-02-07 19:05:11,170 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default usedResources: <memory:0, vCores:0> clusterResources: <memory:1024, vCores:16> currentCapacity 0.0 required <memory:2048, vCores:1> potentialNewCapacity: 2.0 (  max-capacity: 1.0)\n2013-02-07 19:05:12,173 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default usedResources: <memory:0, vCores:0> clusterResources: <memory:1024, vCores:16> currentCapacity 0.0 required <memory:2048, vCores:1> potentialNewCapacity: 2.0 (  max-capacity: 1.0)\n2013-02-07 19:05:13,175 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default usedResources: <memory:0, vCores:0> clusterResources: <memory:1024, vCores:16> currentCapacity 0.0 required <memory:2048, vCores:1> potentialNewCapacity: 2.0 (  max-capacity: 1.0)\n2013-02-07 19:05:14,177 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default usedResources: <memory:0, vCores:0> clusterResources: <memory:1024, vCores:16> currentCapacity 0.0 required <memory:2048, vCores:1> potentialNewCapacity: 2.0 (  max-capacity: 1.0)\n2013-02-07 19:05:15,179 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default usedResources: <memory:0, vCores:0> clusterResources: <memory:1024, vCores:16> currentCapacity 0.0 required <memory:2048, vCores:1> potentialNewCapacity: 2.0 (  max-capacity: 1.0)\n...\n2013-02-07 23:51:02,976 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default usedResources: <memory:0, vCores:0> clusterResources: <memory:1024, vCores:16> currentCapacity 0.0 required <memory:2048, vCores:1> potentialNewCapacity: 2.0 (  max-capacity: 1.0)\n2013-02-07 23:51:03,977 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default usedResources: <memory:0, vCores:0> clusterResources: <memory:1024, vCores:16> currentCapacity 0.0 required <memory:2048, vCores:1> potentialNewCapacity: 2.0 (  max-capacity: 1.0)\n2013-02-07 23:51:04,978 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default usedResources: <memory:0, vCores:0> clusterResources: <memory:1024, vCores:16> currentCapacity 0.0 required <memory:2048, vCores:1> potentialNewCapacity: 2.0 (  max-capacity: 1.0)\n2013-02-07 23:51:05,979 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default usedResources: <memory:0, vCores:0> clusterResources: <memory:1024, vCores:16> currentCapacity 0.0 required <memory:2048, vCores:1> potentialNewCapacity: 2.0 (  max-capacity: 1.0)\n2013-02-07 23:51:06,981 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default usedResources: <memory:0, vCores:0> clusterResources: <memory:1024, vCores:16> currentCapacity 0.0 required <memory:2048, vCores:1> potentialNewCapacity: 2.0 (  max-capacity: 1.0)\n2013-02-07 23:51:07,982 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default usedResources: <memory:0, vCores:0> clusterResources: <memory:1024, vCores:16> currentCapacity 0.0 required <memory:2048, vCores:1> potentialNewCapacity: 2.0 (  max-capacity: 1.0)\n2013-02-07 23:51:08,983 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default usedResources: <memory:0, vCores:0> clusterResources: <memory:1024, vCores:16> currentCapacity 0.0 required <memory:2048, vCores:1> potentialNewCapacity: 2.0 (  max-capacity: 1.0)\n...\n{code}\n\n[~zjshen]'s solution repasted:\n{quote}\nIn my opinion, the attempt of assigning containers should be terminated in the following two cases.\n1. Required > Cluster's absolute capacity: the assignment is impossible to be accomplished. The assignment should be failed immediately.\n2. Required + Already used > Cluster's absolute capacity: the assignment should be failed after a certain number of rounds of assignment attempt or a certain duration. The number of rounds or the duration length should be configurable.\n{quote}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinodkv","name":"vinodkv","key":"vinodkv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinod Kumar Vavilapalli","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-02-08T19:24:56.875+0000","updated":"2013-02-08T19:24:56.875+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12631401/comment/13574755","id":"13574755","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinodkv","name":"vinodkv","key":"vinodkv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinod Kumar Vavilapalli","active":true,"timeZone":"America/Los_Angeles"},"body":"Zhijie, what is your setting for yarn.scheduler.maximum-allocation-mb? That is the configs that should reject allocations that aren't satisfiable.\n\nIn either case, there should be infinite assignments, can you investigate? Thanks!","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinodkv","name":"vinodkv","key":"vinodkv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinod Kumar Vavilapalli","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-02-08T19:28:21.675+0000","updated":"2013-02-08T19:28:21.675+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12631401/comment/13574756","id":"13574756","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=acmurthy","name":"acmurthy","key":"acmurthy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun C Murthy","active":true,"timeZone":"America/Los_Angeles"},"body":"The way to fix this to cap yarn.scheduler.maximum-allocation-mb to be max(cluster-capacity, yarn.scheduler.maximum-allocation-mb) in a dynamic manner (as nodes come up or go down).","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=acmurthy","name":"acmurthy","key":"acmurthy","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Arun C Murthy","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-02-08T19:29:32.210+0000","updated":"2013-02-08T19:29:32.210+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12631401/comment/13574759","id":"13574759","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=zjshen","name":"zjshen","key":"zjshen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10443","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10443","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10443","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10443"},"displayName":"Zhijie Shen","active":true,"timeZone":"America/Los_Angeles"},"body":"Vinod, I didn't specify yarn.scheduler.maximum-allocation-mb, such that by default it should be 8G. I'll investigate this property as well.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=zjshen","name":"zjshen","key":"zjshen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10443","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10443","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10443","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10443"},"displayName":"Zhijie Shen","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-02-08T19:42:09.034+0000","updated":"2013-02-08T19:42:09.034+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12631401/comment/13577128","id":"13577128","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=zjshen","name":"zjshen","key":"zjshen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10443","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10443","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10443","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10443"},"displayName":"Zhijie Shen","active":true,"timeZone":"America/Los_Angeles"},"body":"{quote}\nZhijie, what is your setting for yarn.scheduler.maximum-allocation-mb? That is the configs that should reject allocations that aren't satisfiable.\n{quote}\n\nHi Vinod, I set yarn.scheduler.maximum-allocation-mb <= yarn.nodemanager.resource.memory-mb (single node cluster). However, the requested resource wasn't bounded by yarn.scheduler.maximum-allocation-mb. On the other side, I saw the code to set amMemory to maxMemory if amMemory > maxMemory. I need to dig deeper.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=zjshen","name":"zjshen","key":"zjshen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10443","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10443","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10443","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10443"},"displayName":"Zhijie Shen","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-02-12T22:47:32.402+0000","updated":"2013-02-12T22:47:32.402+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12631401/comment/13579562","id":"13579562","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=zjshen","name":"zjshen","key":"zjshen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10443","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10443","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10443","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10443"},"displayName":"Zhijie Shen","active":true,"timeZone":"America/Los_Angeles"},"body":"I've checked reason why the requested AM size is larger than yarn.scheduler.maximum-allocation-mb. In fact, the AM size is not checked before requesting a container. It is because MR jobs are submitted through ResourceMgrDelegate and managed by MRAppMaster, while checking AM size against the maximum resource capability is only implemented in Client and ApplicationMaster of the distributed shell.\n\nIn addition, since the requested AM size will be rounded up, it is at the risk of the roundup value goes beyond yarn.scheduler.maximum-allocation-mb.\n\nAnyway, the aforementioned situation is a separate issue, which I've filed in YARN-407. Here, the focused issue is that if the requested resource is impossible to be supplied, there should be some mechanism to stop the infinite loop of assignment. This issue seems to be similar to YARN-56 and YARN-394.\n\n\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=zjshen","name":"zjshen","key":"zjshen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10443","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10443","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10443","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10443"},"displayName":"Zhijie Shen","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-02-15T22:44:06.753+0000","updated":"2013-02-15T22:44:06.753+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12631401/comment/13611037","id":"13611037","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bikassaha","name":"bikassaha","key":"bikassaha","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=bikassaha&avatarId=29845","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=bikassaha&avatarId=29845","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=bikassaha&avatarId=29845","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=bikassaha&avatarId=29845"},"displayName":"Bikas Saha","active":true,"timeZone":"America/Los_Angeles"},"body":"bq. I've checked reason why the requested AM size is larger than yarn.scheduler.maximum-allocation-mb. In fact, the AM size is not checked before requesting a container. It is because MR jobs are submitted through ResourceMgrDelegate and managed by MRAppMaster, while checking AM size against the maximum resource capability is only implemented in Client and ApplicationMaster of the distributed shell.\n\nThe AM launcher checking limits is great but its the RM's responsibility to not accept requests that it cannot fulfill. From reading the comments, it not clear to me what exactly the root issue is in the RM itself. Is it that the RM is accepting container requests that are greater than the maximum resource available on any 1 node? I dont think we should be comparing against the entire cluster resource since a container request needs to be satisfied within a single node.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bikassaha","name":"bikassaha","key":"bikassaha","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=bikassaha&avatarId=29845","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=bikassaha&avatarId=29845","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=bikassaha&avatarId=29845","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=bikassaha&avatarId=29845"},"displayName":"Bikas Saha","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-03-22T18:27:59.571+0000","updated":"2013-03-22T18:27:59.571+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12631401/comment/13611266","id":"13611266","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=zjshen","name":"zjshen","key":"zjshen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10443","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10443","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10443","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10443"},"displayName":"Zhijie Shen","active":true,"timeZone":"America/Los_Angeles"},"body":"@Bikas, the problem was produced by two issues:\n\n1. The problematic configuration, which made the AM container require more resource than a node had (In my previous comments, I wrongly mentioned the entire cluster resource, because I was testing it on one-node cluster, such that the maximum cluster resource is equal to that of a single node). This issue can be eliminated when YARN-193 gets fixed.\n\n2. Anyway, when the request is impossible to be fulfilled (e.g., the requested resource is more than any node has), it should be somehow prohibited instead of being executed again and again. YARN-56 and YARN-394 are the two tickets that want to solve the similar issue.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=zjshen","name":"zjshen","key":"zjshen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10443","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10443","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10443","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10443"},"displayName":"Zhijie Shen","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-03-22T21:15:55.683+0000","updated":"2013-03-22T21:15:55.683+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12631401/comment/13718504","id":"13718504","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ojoshi","name":"ojoshi","key":"ojoshi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=ojoshi&avatarId=16634","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=ojoshi&avatarId=16634","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=ojoshi&avatarId=16634","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=ojoshi&avatarId=16634"},"displayName":"Omkar Vinit Joshi","active":true,"timeZone":"America/Los_Angeles"},"body":"[~zjshen] [~bikassaha] I think we should reject the problematic requests at allocate call but not when it is accepted. As that will be a problem.\n* For allocate call today we are only rejecting requests if their request is more than what cluster has but we don't do any validation w.r.t. how much a single container will need to run. I think we should add that check. SchedulerUtils#validateResourceRequest().. thoughts??\n* We can not reject requests once they are accepted. How the AM will come to know which requests were rejected later? is there anyway we can inform AM about the accepted (earlier) but now rejected requests? One more thing to be considered here is that Node manager having large amount of resources may go down and come back in short span.. (node reconnect or..node removed and added back after very small time)..in whichever case we should not reject that request if it was accepted....large jobs will definitely suffer if few nodes restart in very short span.. thoughts?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ojoshi","name":"ojoshi","key":"ojoshi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=ojoshi&avatarId=16634","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=ojoshi&avatarId=16634","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=ojoshi&avatarId=16634","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=ojoshi&avatarId=16634"},"displayName":"Omkar Vinit Joshi","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-07-24T15:49:25.131+0000","updated":"2013-07-24T15:49:25.131+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12631401/comment/13718568","id":"13718568","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tucu00","name":"tucu00","key":"tucu00","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Alejandro Abdelnur","active":true,"timeZone":"Europe/Madrid"},"body":"Wouldn't make sense to add a new status DISCARDED where an accepted resource request could transition to DISCARDED if there are no nodes that can satisfy the resource request?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=tucu00","name":"tucu00","key":"tucu00","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Alejandro Abdelnur","active":true,"timeZone":"Europe/Madrid"},"created":"2013-07-24T16:55:36.304+0000","updated":"2013-07-24T16:55:36.304+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12631401/comment/13718571","id":"13718571","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bikassaha","name":"bikassaha","key":"bikassaha","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=bikassaha&avatarId=29845","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=bikassaha&avatarId=29845","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=bikassaha&avatarId=29845","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=bikassaha&avatarId=29845"},"displayName":"Bikas Saha","active":true,"timeZone":"America/Los_Angeles"},"body":"We should check for container level requests during allocate RPC request processing. The check that container resource > resource in the cluster is probably less useful compared to checking the container resource > resource on the largest machine.\n\nI think its fine to be able to reject requests later on if they cannot be fulfilled because the cluster has changed state. eg. the only machine with enough resources for a container has failed or container wants a specific machine and that has failed. Thats why I had linked this jira to YARN-394.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bikassaha","name":"bikassaha","key":"bikassaha","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=bikassaha&avatarId=29845","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=bikassaha&avatarId=29845","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=bikassaha&avatarId=29845","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=bikassaha&avatarId=29845"},"displayName":"Bikas Saha","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-07-24T16:57:12.720+0000","updated":"2013-07-24T16:57:12.720+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12631401/comment/13718643","id":"13718643","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=zjshen","name":"zjshen","key":"zjshen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10443","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10443","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10443","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10443"},"displayName":"Zhijie Shen","active":true,"timeZone":"America/Los_Angeles"},"body":"bq. The check that container resource > resource in the cluster is probably less useful compared to checking the container resource > resource on the largest machine.\n\nAgree, and should the resource here be the remaining unused resource?\n\nbq. I think we should reject the problematic requests at allocate call but not when it is accepted\n\nIMHO, should we give a second chance to the request? The resource of a cluster is dynamic due to NM churn and container acquisition/release. A requests that cannot be fulfilled immediately may be affordable later. Shall we allow some time or retry quota to the request? As [~tucu00] suggested, maybe we can accepted the request, and move it to DISCARDED if no NM can fulfill the request before it expires.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=zjshen","name":"zjshen","key":"zjshen","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10443","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10443","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10443","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10443"},"displayName":"Zhijie Shen","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-07-24T18:04:28.307+0000","updated":"2013-07-24T18:04:28.307+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12631401/comment/13718653","id":"13718653","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ojoshi","name":"ojoshi","key":"ojoshi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=ojoshi&avatarId=16634","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=ojoshi&avatarId=16634","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=ojoshi&avatarId=16634","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=ojoshi&avatarId=16634"},"displayName":"Omkar Vinit Joshi","active":true,"timeZone":"America/Los_Angeles"},"body":"Today this limit is static. This by default (under well maintained cluster) will be less than or equal to maximum single node manager resource capability. However for node update or when node is considered dead we don't update it. Probably we should update it or some other flag and start logging this information when it drops below this value... thoughts?\n{code}\n      this.maximumAllocation = \n        Resources.createResource(conf.getInt(\n            YarnConfiguration.RM_SCHEDULER_MAXIMUM_ALLOCATION_MB,\n            YarnConfiguration.DEFAULT_RM_SCHEDULER_MAXIMUM_ALLOCATION_MB));\n{code}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ojoshi","name":"ojoshi","key":"ojoshi","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=ojoshi&avatarId=16634","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=ojoshi&avatarId=16634","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=ojoshi&avatarId=16634","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=ojoshi&avatarId=16634"},"displayName":"Omkar Vinit Joshi","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-07-24T18:14:41.649+0000","updated":"2013-07-24T18:14:41.649+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12631401/comment/13718666","id":"13718666","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bikassaha","name":"bikassaha","key":"bikassaha","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=bikassaha&avatarId=29845","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=bikassaha&avatarId=29845","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=bikassaha&avatarId=29845","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=bikassaha&avatarId=29845"},"displayName":"Bikas Saha","active":true,"timeZone":"America/Los_Angeles"},"body":"I dont think we can be good at predicting the future and so it may not be useful to add more logic that allows unsatisfiable requests for some time before rejecting them. We should reject requests when we see that they cannot be allocated. The current example that works in the code is when the request is for resources > than configured maximum. Later on, when requests become unsatisfiable then we need a way reject requests and inform the AM during the allocate heartbeat. This is tracked by YARN-394.\n\nFor this jira itself, is it correct to say that the cluster was misconfigured? MR AM container request was set to 1.5G which is greater than memory on NM 1G. What was the value of YarnConfiguration.RM_SCHEDULER_MAXIMUM_ALLOCATION_MB? That should have been <= 1G. Then the request should have been rejected by the RM ApplicationMasterService.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bikassaha","name":"bikassaha","key":"bikassaha","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=bikassaha&avatarId=29845","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=bikassaha&avatarId=29845","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=bikassaha&avatarId=29845","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=bikassaha&avatarId=29845"},"displayName":"Bikas Saha","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-07-24T18:25:03.230+0000","updated":"2013-07-24T18:25:03.230+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12631401/comment/13718673","id":"13718673","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hitesh","name":"hitesh","key":"hitesh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hitesh Shah","active":true,"timeZone":"America/Los_Angeles"},"body":"The static limit is there for a reason. No application should ask for a container above a certain limit as defined by the admins. For example, if most nodes in a cluster have 4 GB resources, it can be used to set the cap to 4 GB to ensure that even if all large nodes ( ones with more than 4 GB ) disappear, the cluster is still healthy. \n\nThe issue at hand is a scheduling/allocation problem:\n  - can this allocation request be fulfilled? \n     - can it be fulfilled now?\n     - can it be fulfilled within a short window?\n     - can it ever be fulfilled? \n  - When an allocation request deemed to be non-fulfill-able?\n     - is this based on static configuration?\n     - is this based on a single snapshot of the dynamic view of the cluster?\n     - is this based on snapshots over a period of time?\n  - If time, on what basis is time defined?\n     - clock time?\n     - no. of rounds of heartbeats by all healthy nodes in the cluster.\n\nHow is the application informed of the necessary information that it needs to make a decision? Information could be:\n  - your request could not be fulfilled\n  - your partial request could not be fulfilled \n    - the reason why it could not be fulfilled\n  - the current view of the cluster such as max available container size\n  \n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hitesh","name":"hitesh","key":"hitesh","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hitesh Shah","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-07-24T18:29:14.816+0000","updated":"2013-07-24T18:29:14.816+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12631401/comment/13755859","id":"13755859","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinodkv","name":"vinodkv","key":"vinodkv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinod Kumar Vavilapalli","active":true,"timeZone":"America/Los_Angeles"},"body":"Let's see if we can do something for 2.1.1.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vinodkv","name":"vinodkv","key":"vinodkv","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Vinod Kumar Vavilapalli","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-09-02T01:44:08.210+0000","updated":"2013-09-02T01:44:08.210+0000"}],"maxResults":17,"total":17,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/YARN-389/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i1htq7:"}}