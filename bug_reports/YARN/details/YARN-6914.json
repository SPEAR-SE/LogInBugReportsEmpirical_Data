{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"13091439","self":"https://issues.apache.org/jira/rest/api/2/issue/13091439","key":"YARN-6914","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12313722","id":"12313722","key":"YARN","name":"Hadoop YARN","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12313722&avatarId=15135","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12313722&avatarId=15135","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12313722&avatarId=15135","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12313722&avatarId=15135"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/6","id":"6","description":"The problem isn't valid and it can't be fixed.","name":"Invalid"},"customfield_12312322":null,"customfield_12310220":"2017-08-01T04:32:21.788+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Wed Aug 02 04:39:54 UTC 2017","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":"1_*:*_1_*:*_88784023_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"resolutiondate":"2017-08-02T03:53:39.000+0000","workratio":0,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/YARN-6914/watchers","watchCount":2,"isWatching":false},"created":"2017-08-01T03:13:55.025+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/2","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/critical.svg","name":"Critical","id":"2"},"labels":[],"customfield_12312333":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":1209600,"aggregatetimeoriginalestimate":1209600,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12334006","id":"12334006","description":"2.7.3 release","name":"2.7.3","archived":false,"released":true,"releaseDate":"2016-08-25"}],"issuelinks":[],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2017-08-02T04:39:54.696+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/5","description":"A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/resolved.png","name":"Resolved","id":"5","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12325004","id":"12325004","name":"yarn"}],"timeoriginalestimate":1209600,"description":"I am getting below error while running \nspark-shell --master yarn\n\nApplication application_1501553373419_0001 failed 2 times due to AM Container for appattempt_1501553373419_0001_000002 exited with exitCode: -1000\nFor more detailed output, check application tracking page:http://abhisheks-mbp:8088/cluster/app/application_1501553373419_0001Then, click on links to logs of each attempt.\nDiagnostics: null\nFailing this attempt. Failing the application.\n\n\nBelow are the contents of yarn-site.xml :\n<configuration>\n        <!-- Site specific YARN configuration properties -->\n        <property>\n                <name>yarn.nodemanager.aux-services</name>\n                <value>mapreduce_shuffle</value>\n        </property>\n\n       <property>\n                <name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name>\n                <value>org.apache.hadoop.mapred.ShuffleHandler</value>\n       </property>\n\n        <property>\n                <name>yarn.nodemanager.aux-services.spark_shuffle.class</name>\n                <value>org.apache.spark.network.yarn.YarnShuffleService</value>\n        </property>\n\n        <property>\n                <name>yarn.log-aggregation-enable</name>\n                <value>true</value>\n        </property>\n\n        <property>\n                <name>yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds</name>\n                <value>3600</value>\n        </property>\n\n        <property>\n                <name>yarn.resourcemanager.hostname</name>\n                <value>localhost</value>\n        </property>\n\n        <property>\n                        <name>yarn.resourcemanager.resourcetracker.address</name>\n                        <value>${yarn.resourcemanager.hostname}:8025</value>\n                        <description>Enter your ResourceManager hostname.</description>\n        </property>\n\n        <property>\n                        <name>yarn.resourcemanager.scheduler.address</name>\n                        <value>${yarn.resourcemanager.hostname}:8035</value>\n                        <description>Enter your ResourceManager hostname.</description>\n        </property>\n\n        <property>\n                        <name>yarn.resourcemanager.address</name>\n                        <value>${yarn.resourcemanager.hostname}:8055</value>\n                        <description>Enter your ResourceManager hostname.</description>\n        </property>\n\n        <property>\n                        <description>The http address of the RM web application.</description>\n                        <name>yarn.resourcemanager.webapp.address</name>\n                        <value>${yarn.resourcemanager.hostname}:8088</value>\n        </property>\n\nI tried many solutions but none of them is working :\n\n1.Added property yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage to yarn-site.xml with value as 98.5\n2.added below property to yarn-site.xml yarn.nodemanager.aux-services.spark_shuffle.class org.apache.spark.network.yarn.YarnShuffleService  \n3.Added property in spark-defaults.conf spark.yarn.jars=hdfs://localhost:50010/users/spark/jars/*.jar\n\n","customfield_10010":null,"timetracking":{"originalEstimate":"336h","remainingEstimate":"336h","originalEstimateSeconds":1209600,"remainingEstimateSeconds":1209600},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":1209600,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"Application application_1501553373419_0001 failed 2 times due to AM Container for appattempt_1501553373419_0001_000002 exited with exitCode: -1000","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bharaniabhishek123","name":"bharaniabhishek123","key":"bharaniabhishek123","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"abhishek bharani","active":true,"timeZone":"America/New_York"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bharaniabhishek123","name":"bharaniabhishek123","key":"bharaniabhishek123","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"abhishek bharani","active":true,"timeZone":"America/New_York"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":1209600,"percent":0},"customfield_12311024":null,"environment":"Mac OS","customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":1209600,"percent":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/13091439/comment/16108363","id":"16108363","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bibinchundatt","name":"bibinchundatt","key":"bibinchundatt","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=bibinchundatt&avatarId=29912","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=bibinchundatt&avatarId=29912","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=bibinchundatt&avatarId=29912","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=bibinchundatt&avatarId=29912"},"displayName":"Bibin A Chundatt","active":true,"timeZone":"Asia/Kolkata"},"body":"[~bharaniabhishek123]\nLooks like issue with configuration.\n\n{code}\n<property>\n  <name>yarn.nodemanager.aux-services</name>\n<value>mapreduce_shuffle,spark_shuffle</value>\n  </property>\n<property>\n  <name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name>\n<value>org.apache.hadoop.mapred.ShuffleHandler</value>\n</property>\n<property>\n  <name>yarn.nodemanager.aux-services.spark_shuffle.class</name>\n<value>org.apache.spark.network.yarn.YarnShuffleService</value>\n  </property>\n{code}\n\nPlease contact in user mailing list for questions and discussion. user@hadoop.apache.org","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bibinchundatt","name":"bibinchundatt","key":"bibinchundatt","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=bibinchundatt&avatarId=29912","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=bibinchundatt&avatarId=29912","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=bibinchundatt&avatarId=29912","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=bibinchundatt&avatarId=29912"},"displayName":"Bibin A Chundatt","active":true,"timeZone":"Asia/Kolkata"},"created":"2017-08-01T04:32:21.788+0000","updated":"2017-08-01T04:34:06.756+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13091439/comment/16108415","id":"16108415","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bharaniabhishek123","name":"bharaniabhishek123","key":"bharaniabhishek123","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"abhishek bharani","active":true,"timeZone":"America/New_York"},"body":"Updated the configuration as above, I am still getting the same error.\n ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bharaniabhishek123","name":"bharaniabhishek123","key":"bharaniabhishek123","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"abhishek bharani","active":true,"timeZone":"America/New_York"},"created":"2017-08-01T05:53:48.198+0000","updated":"2017-08-01T05:53:48.198+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13091439/comment/16108449","id":"16108449","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=Naganarasimha","name":"Naganarasimha","key":"naganarasimha","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Naganarasimha G R","active":true,"timeZone":"Asia/Kolkata"},"body":"No info from the NM logs too ?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=Naganarasimha","name":"Naganarasimha","key":"naganarasimha","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Naganarasimha G R","active":true,"timeZone":"Asia/Kolkata"},"created":"2017-08-01T06:24:44.033+0000","updated":"2017-08-01T06:24:44.033+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13091439/comment/16109048","id":"16109048","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bharaniabhishek123","name":"bharaniabhishek123","key":"bharaniabhishek123","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"abhishek bharani","active":true,"timeZone":"America/New_York"},"body":"Below is the information from NM Logs :\n\n2017-08-01 10:19:50,510 ERROR org.apache.spark.network.util.LevelDBProvider: error opening leveldb file /usr/local/hadoop/tmp/nm-local-dir/registeredExecutors.ldb.  Creating new file, will not be able to recover state for existing applications\norg.fusesource.leveldbjni.internal.NativeDB$DBException: IO error: /usr/local/hadoop/tmp/nm-local-dir/registeredExecutors.ldb/LOCK: No such file or directory\n\tat org.fusesource.leveldbjni.internal.NativeDB.checkStatus(NativeDB.java:200)\n\tat org.fusesource.leveldbjni.internal.NativeDB.open(NativeDB.java:218)\n\tat org.fusesource.leveldbjni.JniDBFactory.open(JniDBFactory.java:168)\n\tat org.apache.spark.network.util.LevelDBProvider.initLevelDB(LevelDBProvider.java:48)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.<init>(ExternalShuffleBlockResolver.java:116)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.<init>(ExternalShuffleBlockResolver.java:94)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockHandler.<init>(ExternalShuffleBlockHandler.java:65)\n\tat org.apache.spark.network.yarn.YarnShuffleService.serviceInit(YarnShuffleService.java:166)\n\tat org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices.serviceInit(AuxServices.java:143)\n\tat org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)\n\tat org.apache.hadoop.service.CompositeService.serviceInit(CompositeService.java:107)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.serviceInit(ContainerManagerImpl.java:245)\n\tat org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)\n\tat org.apache.hadoop.service.CompositeService.serviceInit(CompositeService.java:107)\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeManager.serviceInit(NodeManager.java:261)\n\tat org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeManager.initAndStartNodeManager(NodeManager.java:495)\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeManager.main(NodeManager.java:543)\n2017-08-01 10:19:50,511 WARN org.apache.spark.network.util.LevelDBProvider: error deleting /usr/local/hadoop/tmp/nm-local-dir/registeredExecutors.ldb\n2017-08-01 10:19:50,511 INFO org.apache.hadoop.service.AbstractService: Service spark_shuffle failed in state INITED; cause: java.io.IOException: Unable to create state store\njava.io.IOException: Unable to create state store\n\tat org.apache.spark.network.util.LevelDBProvider.initLevelDB(LevelDBProvider.java:77)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.<init>(ExternalShuffleBlockResolver.java:116)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.<init>(ExternalShuffleBlockResolver.java:94)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockHandler.<init>(ExternalShuffleBlockHandler.java:65)\n\tat org.apache.spark.network.yarn.YarnShuffleService.serviceInit(YarnShuffleService.java:166)\n\tat org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices.serviceInit(AuxServices.java:143)\n\tat org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)\n\tat org.apache.hadoop.service.CompositeService.serviceInit(CompositeService.java:107)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.serviceInit(ContainerManagerImpl.java:245)\n\tat org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)\n\tat org.apache.hadoop.service.CompositeService.serviceInit(CompositeService.java:107)\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeManager.serviceInit(NodeManager.java:261)\n\tat org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeManager.initAndStartNodeManager(NodeManager.java:495)\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeManager.main(NodeManager.java:543)\nCaused by: org.fusesource.leveldbjni.internal.NativeDB$DBException: IO error: /usr/local/hadoop/tmp/nm-local-dir/registeredExecutors.ldb/LOCK: No such file or directory\n\tat org.fusesource.leveldbjni.internal.NativeDB.checkStatus(NativeDB.java:200)\n\tat org.fusesource.leveldbjni.internal.NativeDB.open(NativeDB.java:218)\n\tat org.fusesource.leveldbjni.JniDBFactory.open(JniDBFactory.java:168)\n\tat org.apache.spark.network.util.LevelDBProvider.initLevelDB(LevelDBProvider.java:75)\n\t... 15 more\n2017-08-01 10:19:50,513 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl:  Using ResourceCalculatorPlugin : null\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bharaniabhishek123","name":"bharaniabhishek123","key":"bharaniabhishek123","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"abhishek bharani","active":true,"timeZone":"America/New_York"},"created":"2017-08-01T14:59:47.077+0000","updated":"2017-08-01T14:59:47.077+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13091439/comment/16110239","id":"16110239","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=Naganarasimha","name":"Naganarasimha","key":"naganarasimha","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Naganarasimha G R","active":true,"timeZone":"Asia/Kolkata"},"body":"Hi [~bharaniabhishek123],\nGenerally the approach which is followed is raise your issue in the forum and if in the forum it gets confirmed to be a defect then raise it in jira. Please ensure next time we follow this procedure else every query will become a jira !\nWill close this issue, please raise this in the forum and if required lets reopen this issue.\n\nAnd coming to the logs, has the NM started ? seems to be a spark issue may be you can check in the spark forum.\nOne possible reason would be spark aux service leveldb files might have got corrupted, if not production cluster please empty/backup the dir \" /usr/local/hadoop/tmp/nm-local-dir/\"  and then try.\n\n\n\n\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=Naganarasimha","name":"Naganarasimha","key":"naganarasimha","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Naganarasimha G R","active":true,"timeZone":"Asia/Kolkata"},"created":"2017-08-02T03:52:53.532+0000","updated":"2017-08-02T03:52:53.532+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13091439/comment/16110283","id":"16110283","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bharaniabhishek123","name":"bharaniabhishek123","key":"bharaniabhishek123","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"abhishek bharani","active":true,"timeZone":"America/New_York"},"body":"Sure [~naganarasimha_gr@apache.org], Thank you for your support !\nI didn't knew that we first need to raise issues in forums.  I raised this issue on other forums like stack overflow but din't received any response..\nCould you please provide the link to the forum. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=bharaniabhishek123","name":"bharaniabhishek123","key":"bharaniabhishek123","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"abhishek bharani","active":true,"timeZone":"America/New_York"},"created":"2017-08-02T04:27:12.673+0000","updated":"2017-08-02T04:27:12.673+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/13091439/comment/16110293","id":"16110293","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=Naganarasimha","name":"Naganarasimha","key":"naganarasimha","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Naganarasimha G R","active":true,"timeZone":"Asia/Kolkata"},"body":"Sorry i meant Hadoop mailing list, refer all mailing lists @ https://hadoop.apache.org/mailing_lists.html\nyou can send mail to user@hadoop.apache.org\nbut seems like spark issue, so first you could try what i suggested if not a prod setup.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=Naganarasimha","name":"Naganarasimha","key":"naganarasimha","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Naganarasimha G R","active":true,"timeZone":"Asia/Kolkata"},"created":"2017-08-02T04:39:54.696+0000","updated":"2017-08-02T04:39:54.696+0000"}],"maxResults":7,"total":7,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/YARN-6914/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i3i8wf:"}}