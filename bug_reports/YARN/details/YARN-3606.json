{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12828478","self":"https://issues.apache.org/jira/rest/api/2/issue/12828478","key":"YARN-3606","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12313722","id":"12313722","key":"YARN","name":"Hadoop YARN","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12313722&avatarId=15135","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12313722&avatarId=15135","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12313722&avatarId=15135","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12313722&avatarId=15135"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/10292","id":"10292","description":"Scalable Distributed Computing","name":"Hadoop"}},"fixVersions":[],"aggregatetimespent":null,"resolution":null,"customfield_12312322":null,"customfield_12310220":"2015-05-11T17:12:52.687+0000","customfield_12312520":null,"customfield_12312323":null,"customfield_12312521":"Mon May 11 17:12:52 UTC 2015","customfield_12310420":"9223372036854775807","customfield_12312320":null,"customfield_12310222":null,"customfield_12312321":null,"resolutiondate":null,"workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312923":null,"customfield_12312326":null,"customfield_12312920":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312921":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/YARN-3606/watchers","watchCount":6,"isWatching":false},"created":"2015-05-08T20:34:31.813+0000","customfield_12310192":null,"customfield_12310191":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/4","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/minor.svg","name":"Minor","id":"4"},"labels":[],"customfield_12312333":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12311120":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12327197","id":"12327197","description":"2.6.0 release","name":"2.6.0","archived":false,"released":true,"releaseDate":"2014-11-18"}],"issuelinks":[],"customfield_12312339":null,"assignee":null,"customfield_12312337":null,"customfield_12312338":null,"updated":"2015-05-11T17:12:52.687+0000","customfield_12312335":null,"customfield_12312336":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/1","description":"The issue is open and ready for the assignee to start work on it.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/open.png","name":"Open","id":"1","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/2","id":2,"key":"new","colorName":"blue-gray","name":"To Do"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12325004","id":"12325004","name":"yarn"}],"timeoriginalestimate":null,"description":"In a YARN cluster, when submitting a Spark job, the Spark job will fail to run because YARN fails to launch containers on the other nodes (not the node where the job submission took place).\n\nYARN checks for similar spark-assembly.jar file by looking at the timestamps. This check will fail when the spark-assembly.jar is the same but copied to the location at different time.\n\nYARN throws this exception:\n\n15/05/07 20:13:22 INFO yarn.ExecutorRunnable: Setting up executor with commands: List({{JAVA_HOME}}/bin/java, -server, -XX:OnOutOfMemoryError='kill %p', -Xms1024m, -Xmx1024m, -Djava.io.tmpdir={{PWD}}/tmp, '-Dspark.driver.port=52357', -Dspark.yarn.app.container.log.dir=<LOG_DIR>, org.apache.spark.executor.CoarseGrainedExecutorBackend, --driver-url, akka.tcp://sparkDriver@xxx:52357/user/CoarseGrainedScheduler, --executor-id, 4, --hostname, xxx, --cores, 1, --app-id, application_1431047540996_0001, --user-class-path, file:$PWD/__app__.jar, 1>, <LOG_DIR>/stdout, 2>, <LOG_DIR>/stderr)\n15/05/07 20:13:22 INFO impl.ContainerManagementProtocolProxy: Opening proxy : xxx:34165\n15/05/07 20:13:27 INFO yarn.YarnAllocator: Completed container container_1431047540996_0001_02_000005 (state: COMPLETE, exit status: -1000)\n15/05/07 20:13:27 INFO yarn.YarnAllocator: Container marked as failed: container_1431047540996_0001_02_000005. Exit status: -1000. Diagnostics: Resource file:/home/spark/spark-1.3.1-bin-hadoop2.6/lib/spark-assembly-1.3.1-hadoop2.6.0.jar changed on src filesystem (expected 1430944255000, was 1430944249000\njava.io.IOException: Resource file:/home/spark/spark-1.3.1-bin-hadoop2.6/lib/spark-assembly-1.3.1-hadoop2.6.0.jar changed on src filesystem (expected 1430944255000, was 1430944249000\n        at org.apache.hadoop.yarn.util.FSDownload.copy(FSDownload.java:253)\n        at org.apache.hadoop.yarn.util.FSDownload.access$000(FSDownload.java:61)\n        at org.apache.hadoop.yarn.util.FSDownload$2.run(FSDownload.java:359)\n        at org.apache.hadoop.yarn.util.FSDownload$2.run(FSDownload.java:357)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:415)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)\n        at org.apache.hadoop.yarn.util.FSDownload.call(FSDownload.java:356)\n        at org.apache.hadoop.yarn.util.FSDownload.call(FSDownload.java:60)\n        at java.util.concurrent.FutureTask.run(FutureTask.java:262)\n        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)\n        at java.util.concurrent.FutureTask.run(FutureTask.java:262)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n        at java.lang.Thread.run(Thread.java:745)\n\n\nProblem can be easily replicated by setting up two nodes and copying the spark-assembly.jar to each node but changing the timestamp of the file on one of the nodes. Then execute spark-shell --master yarn-client. Observe the nodemanager log on the other node to find the error.\n\nWork around is to make sure the jar file has the same timestamp. But it looks like perhaps the function that does the copy and check of the jar file (org.apache.hadoop.yarn.util.FSDownload.copy(FSDownload.java:253) should check for file similarity using a checksum rather than timestamp.\n","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12310320":null,"customfield_12312024":null,"customfield_12312340":null,"attachment":[],"aggregatetimeestimate":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"9223372036854775807","customfield_12312823":null,"summary":"Spark container fails to launch if spark-assembly.jar file has different timestamp","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mvle","name":"mvle","key":"mvle","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Michael Le","active":true,"timeZone":"Etc/UTC"},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mvle","name":"mvle","key":"mvle","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Michael Le","active":true,"timeZone":"Etc/UTC"},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":"YARN 2.6.0\nSpark 1.3.1","customfield_12313520":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12828478/comment/14538190","id":"14538190","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"body":"Looking at timestamp is the strategy chosen based on a key assumption : there is a single artifact to localise by downloading from a single shared filesystem. Trying to use local filesystems, each with a cached copy of the artifact, isn't what the NM expects to be doing. If it is, then the normal localisation checks aren't\n\n\nI think the checksum is probably omitted as you have to read the whole file to see if it has changed; plus there's the cost of actually recalculating that checksum prior to launching every container. Timestamps aren't too great though —the check as stands will reject the same file with two different times *or* two differently sized files with the same timestamp.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org","name":"stevel@apache.org","key":"stevel@apache.org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"},"displayName":"Steve Loughran","active":true,"timeZone":"Europe/London"},"created":"2015-05-11T17:12:52.687+0000","updated":"2015-05-11T17:12:52.687+0000"}],"maxResults":1,"total":1,"startAt":0},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/YARN-3606/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i2ei07:"}}