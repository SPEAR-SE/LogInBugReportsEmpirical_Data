{
    "expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields",
    "fields": {
        "aggregateprogress": {
            "progress": 0,
            "total": 0
        },
        "aggregatetimeestimate": null,
        "aggregatetimeoriginalestimate": null,
        "aggregatetimespent": null,
        "assignee": null,
        "components": [{
            "id": "12332529",
            "name": "RM",
            "self": "https://issues.apache.org/jira/rest/api/2/component/12332529"
        }],
        "created": "2018-05-24T08:54:47.000+0000",
        "creator": {
            "active": true,
            "avatarUrls": {
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10442",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10442",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10442",
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10442"
            },
            "displayName": "LongGang Chen",
            "key": "longgang",
            "name": "LongGang",
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=LongGang",
            "timeZone": "Asia/Shanghai"
        },
        "customfield_10010": null,
        "customfield_12310191": null,
        "customfield_12310192": null,
        "customfield_12310220": null,
        "customfield_12310222": null,
        "customfield_12310250": null,
        "customfield_12310290": null,
        "customfield_12310291": null,
        "customfield_12310300": null,
        "customfield_12310310": "0.0",
        "customfield_12310320": null,
        "customfield_12310420": "9223372036854775807",
        "customfield_12310920": "9223372036854775807",
        "customfield_12310921": null,
        "customfield_12311020": null,
        "customfield_12311024": null,
        "customfield_12311120": null,
        "customfield_12311820": "0|i3u3xr:",
        "customfield_12312022": null,
        "customfield_12312023": null,
        "customfield_12312024": null,
        "customfield_12312026": null,
        "customfield_12312220": null,
        "customfield_12312320": null,
        "customfield_12312321": null,
        "customfield_12312322": null,
        "customfield_12312323": null,
        "customfield_12312324": null,
        "customfield_12312325": null,
        "customfield_12312326": null,
        "customfield_12312327": null,
        "customfield_12312328": null,
        "customfield_12312329": null,
        "customfield_12312330": null,
        "customfield_12312331": null,
        "customfield_12312332": null,
        "customfield_12312333": null,
        "customfield_12312334": null,
        "customfield_12312335": null,
        "customfield_12312336": null,
        "customfield_12312337": null,
        "customfield_12312338": null,
        "customfield_12312339": null,
        "customfield_12312340": null,
        "customfield_12312341": null,
        "customfield_12312520": null,
        "customfield_12312521": "2018-05-24 08:54:47.0",
        "customfield_12312720": null,
        "customfield_12312823": null,
        "customfield_12312920": null,
        "customfield_12312921": null,
        "customfield_12312923": null,
        "customfield_12313422": "false",
        "customfield_12313520": null,
        "description": "first, Quickly go through the update logic, Increase as an example：\r\n * 1: normal work in ApplicationMasterService, DefaultAMSProcessor.    \r\n * 2: CapacityScheduler.allocate will call AbstractYarnScheduler.handleContainerUpdates\r\n * 3: AbstractYarnScheduler.handleContainerUpdates will call handleIncreaseRequests, then call ContainerUpdateContext.checkAndAddToOutstandingIncreases\r\n * 4: cancle && and new: checkAndAddToOutstandingIncreases will check this inc update for this container, if there is an outstanding inc, it will cancle it by calling appSchedulingInfo.allocate(...) to allocate a dummy container; if the update is a fresh one, it will call appSchedulingInfo.updateResourceRequests to add a new request. the capacity of this new request is gap value between existing container and capacity of updateRequest, for example, if original capacity is <memory:10GB>, the target capacity of UpdateRequest is <memory:20GB>, the gap[the capacity of the new request which will be added to appSchedulingInfo] is <memory:10GB>.\r\n * 5: swap temp container and existing container: CapacityScheduler.allocate call FiCaSchedulerApp.getAllocation(...), getAllocation will call SchedulerApplicationAttempt.pullNewlyIncreasedContainers, then call ContainerUpdateContext.swapContainer,swapContainer will swap the newly allocated inc temp container with existing container, for example: original capacity <memory:10GB>, temp inc container's capacity <memory:10GB>, so the updated existing container has capacity <memory:10+10=20GB>,inc update done.\r\n\r\nthe problem is:\r\n if we send inc update twice for a certain container, for example: send inc <memory:10> to <memory:12>, then send inc with new target <memory:14>, the final updated capacity is uncertain.\r\n\r\nScenes one:\r\n * 1: send inc update from <memory:10> to <memory:12>\r\n * 2: scheduler aproves it, and commit it, so app.liveContainers has this temp inc container with capacity<memory:2> in it.\r\n * 3: send inc with new target <memory:14>, a new resourceRequest with capacity<memory:4> will add to appSchedulingInfo, and swap first temp container<memory:2>, after that, the existing container has new capacity<memory:12>\r\n * 4: scheduler aproves the send temp resourceRequest, allocate second temp container with capacity<memory:4>\r\n * 5: swap the second inc temp container. so the updated capacity of this existing container is <memory:4+12> = <memory:16>, but wanted is <memory:14>\r\n\r\nScenes two:\r\n * 1: send send inc update from <memory:10> to <memory:12>\r\n * 2: scheduler aproves it, but the temp container with capacity<memory:2> is queued in commitService, wait to commit\r\n * 3: send inc with new target <memory:14>, will add a new resourceRequest to appSchedulingInfo, but with same SchedulerRequestKey.\r\n * 4: the first temp container commit, app.apply will call appSchedulingInfo.allocate to reduce pending num, at this situation, it will cancle the second inc request.\r\n * 5: swap the first int temp container. the updated existing container's capacity is <memory:12>, but the wanted is <memory:14>\r\n\r\ntwo key points:\r\n * 1: when ContainerUpdateContext.checkAndAddToOutstandingIncreases cancle previous inc request and put current inc request, it use same SchedulerRequestKey , this action has competition with app.apply, like scenes two, app.apply will cancle second inc update's request.\r\n * 2: ContainerUpdateContext.swapContainer do not check the update target change or not.\r\n\r\nhow to fix: \r\n * 1: after ContainerUpdateContext.checkAndAddToOutstandingIncreases cancle previous inc update request , use a new SchedulerRequestKey for current inc update request . we can add a new field createTime to distinguish them, default value of createTime is 0\r\n * 2: change ContainerUpdateContext.swapContainer to checkAndSwapContainer, check update target change or not, if change, just ignore this temp container and release it. like Scenes one, when we swap first temp inc container, we found that if we do this swap, the updated capacity is <memory:12>, but the newly target's capacity is <memory:14>, so we just ignore this swap, and release the temp container<memory:2>.\r\n\r\n ",
        "duedate": null,
        "environment": null,
        "fixVersions": [],
        "issuelinks": [],
        "issuetype": {
            "avatarId": 21133,
            "description": "A problem which impairs or prevents the functions of the product.",
            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
            "id": "1",
            "name": "Bug",
            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
            "subtask": false
        },
        "labels": [],
        "lastViewed": null,
        "priority": {
            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
            "id": "3",
            "name": "Major",
            "self": "https://issues.apache.org/jira/rest/api/2/priority/3"
        },
        "progress": {
            "progress": 0,
            "total": 0
        },
        "project": {
            "avatarUrls": {
                "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12313722&avatarId=15135",
                "24x24": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12313722&avatarId=15135",
                "32x32": "https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12313722&avatarId=15135",
                "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12313722&avatarId=15135"
            },
            "id": "12313722",
            "key": "YARN",
            "name": "Hadoop YARN",
            "projectCategory": {
                "description": "Scalable Distributed Computing",
                "id": "10292",
                "name": "Hadoop",
                "self": "https://issues.apache.org/jira/rest/api/2/projectCategory/10292"
            },
            "self": "https://issues.apache.org/jira/rest/api/2/project/12313722"
        },
        "reporter": {
            "active": true,
            "avatarUrls": {
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10442",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10442",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10442",
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10442"
            },
            "displayName": "LongGang Chen",
            "key": "longgang",
            "name": "LongGang",
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=LongGang",
            "timeZone": "Asia/Shanghai"
        },
        "resolution": null,
        "resolutiondate": null,
        "status": {
            "description": "The issue is open and ready for the assignee to start work on it.",
            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/open.png",
            "id": "1",
            "name": "Open",
            "self": "https://issues.apache.org/jira/rest/api/2/status/1",
            "statusCategory": {
                "colorName": "blue-gray",
                "id": 2,
                "key": "new",
                "name": "To Do",
                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/2"
            }
        },
        "subtasks": [],
        "summary": "container update error because of competition",
        "timeestimate": null,
        "timeoriginalestimate": null,
        "timespent": null,
        "updated": "2018-09-01T22:56:21.000+0000",
        "versions": [],
        "votes": {
            "hasVoted": false,
            "self": "https://issues.apache.org/jira/rest/api/2/issue/YARN-8355/votes",
            "votes": 0
        },
        "watches": {
            "isWatching": false,
            "self": "https://issues.apache.org/jira/rest/api/2/issue/YARN-8355/watchers",
            "watchCount": 3
        },
        "workratio": -1
    },
    "id": "13161702",
    "key": "YARN-8355",
    "self": "https://issues.apache.org/jira/rest/api/2/issue/13161702"
}