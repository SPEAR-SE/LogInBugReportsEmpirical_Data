[The headroom for an app should be set to the min(app's queue's max share, cluster capacity) - app's queues resources consumed., One thing I don't understand from reading the Capacity Scheduler headroom calculation is how it prevents apps from starving when a max capacity isn't set.  It's defined as min((userLimit, queue-max-cap) - consumed).  If no max capacities are set and two users are running in a queue, each taking up half the queue's capacity, the headroom for each user will be half the queue's capacity.  If the cluster is saturated to the extent that the queue's usage can't go above its capacity, the headroom is being vastly overreported.

[~jlowe], any insight on this?, Yes, over-reporting of the headroom in the CapacityScheduler is a known issue.  See YARN-1857.  I think the calculation for the CapacityScheduler should be more like min((userLimit-userConsumed), (queueMax-queueConsumed)).  The idea being that one can't go over the user limit but also can't go over what the queue has free either., Ah, ok, thanks Jason.  With your formula, assuming no user limits, what happens if queueMax is 100%?  All queue maxes are 100% by default in the Capacity Scheduler, right?  If there are two queues both with max 100%, and both using 50% of resources, they would both end up with 50% headroom., Good point, it would also need to min against the available cluster resources to cover the case of cross-queue contention., Cool, wanted to make sure I understood how it worked.

In that case, I think the best choice for the Fair Scheduler would probably be min(cluster capacity - cluster consumed, queue max share - queue consumed).
, Would it make more sense to have it to be {{queue-fair-share - queue-consumed}}? Now that the fairshare is instantaneous, it is the maximum resources the app can safely expect to get. No? , Preliminary patch as per discussion - does min of clusterAvailable and fairShare available as per policy (ie if using FairPolicy sets CPU to whatever is available in cluster)
Need to add tests, Approach looks good. Couple of comments: 
# Can we add a single method to SchedulingPolicy that takes "available" cluster resources, queue's fairshare and current usage? May be, we can call that method computeHeadroom? 
# The amount of resources available in the cluster can be looked up in FairScheduler.rootMetrics. , Addressed feedback, Thanks Anubhav. 

Thought about this a little more, and I wonder if we need to have separate headroom calculations for policies. Would DRF#getHeadroom not work for other policies? , The queue fair share for fifo and fair policies, sets CPU to zero always. Thus using DRF calculations would cause the headroom to always be set to zero CPU. That can be incorrectly interpreted by the user as having no headroom for CPU (instead of don't care about CPU headroom). , {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12670524/YARN-1959.001.patch
  against trunk revision 43efdd3.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The following test timeouts occurred in hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager:

org.apache.hadoop.yarn.server.resourcemanager.applicationsmanager.TestAMRestart
org.apache.hadoop.yarn.server.resourcemanager.TestWorkPreservingRMRestart
org.apache.hadoop.yarn.server.resourcemanager.TestRMRestart
org.apache.hadoop.yarn.server.resourcemanager.recovery.TestZKRMStateStore
org.apache.hadoop.yarn.server.resourcemanager.security.TestRMDelegationTokens
org.apache.hadoop.yarn.server.resourcemanager.TestSubmitApplicationWithRMHA
org.apache.hadoop.yarn.server.resourcemanager.TestApplicationCleanup
org.apache.hadoop.yarn.server.resourcemanager.TestContainerResourceUsage
org.apache.hadoop.yarn.server.resourcemanager.TestKillApplicationWithRMHA

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-YARN-Build/5076//testReport/
Console output: https://builds.apache.org/job/PreCommit-YARN-Build/5076//console

This message is automatically generated., Thanks for the clarification here and offline. I understand why the headroom needs to policy specific. Couple of nits:
# In FifoPolicy and FairSharePolicy, we can avoid one instance of Resource - {{queueAvailable}}, and use an int for memory instead. May be, we should just use two ints in DRFPolicy as well. 
# TestFSAppAttempt#VerifyHeadroom should be verifyHeadroom. 

, Addressed feedback, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12670555/YARN-1959.002.patch
  against trunk revision 7b8df93.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The following test timeouts occurred in hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager:

org.apache.hadoop.yarn.server.resourcemanager.applicationsmanager.TestAMRestart
org.apache.hadoop.yarn.server.resourcemanager.security.TestRMDelegationTokens
org.apache.hadoop.yarn.server.resourcemanager.TestRMRestart
org.apache.hadoop.yarn.server.resourcemanager.TestWorkPreservingRMRestart
org.apache.hadoop.yarn.server.resourcemanager.TestSubmitApplicationWithRMHA
org.apache.hadoop.yarn.server.resourcemanager.recovery.TestZKRMStateStore
org.apache.hadoop.yarn.server.resourcemanager.TestKillApplicationWithRMHA
org.apache.hadoop.yarn.server.resourcemanager.TestApplicationCleanup
org.apache.hadoop.yarn.server.resourcemanager.TestContainerResourceUsage

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-YARN-Build/5077//testReport/
Console output: https://builds.apache.org/job/PreCommit-YARN-Build/5077//console

This message is automatically generated., +1., Thanks Anubhav for the patch, and Sandy, Jason for your inputs. 

Just committed this to trunk and branch-2. , FAILURE: Integrated in Hadoop-Yarn-trunk #689 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/689/])
YARN-1959. Fix headroom calculation in FairScheduler. (Anubhav Dhoot via kasha) (kasha: rev 568d3dc2bbe43b7d2833d5da2b0e6d75eb86e5dd)
* hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/policies/DominantResourceFairnessPolicy.java
* hadoop-yarn-project/CHANGES.txt
* hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/SchedulingPolicy.java
* hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/policies/FifoPolicy.java
* hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/TestFSAppAttempt.java
* hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FSAppAttempt.java
* hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/policies/FairSharePolicy.java
, FAILURE: Integrated in Hadoop-Mapreduce-trunk #1905 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1905/])
YARN-1959. Fix headroom calculation in FairScheduler. (Anubhav Dhoot via kasha) (kasha: rev 568d3dc2bbe43b7d2833d5da2b0e6d75eb86e5dd)
* hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/policies/FifoPolicy.java
* hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FSAppAttempt.java
* hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/SchedulingPolicy.java
* hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/TestFSAppAttempt.java
* hadoop-yarn-project/CHANGES.txt
* hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/policies/FairSharePolicy.java
* hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/policies/DominantResourceFairnessPolicy.java
, SUCCESS: Integrated in Hadoop-Hdfs-trunk #1880 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1880/])
YARN-1959. Fix headroom calculation in FairScheduler. (Anubhav Dhoot via kasha) (kasha: rev 568d3dc2bbe43b7d2833d5da2b0e6d75eb86e5dd)
* hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FSAppAttempt.java
* hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/TestFSAppAttempt.java
* hadoop-yarn-project/CHANGES.txt
* hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/policies/FifoPolicy.java
* hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/SchedulingPolicy.java
* hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/policies/FairSharePolicy.java
* hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/policies/DominantResourceFairnessPolicy.java
]