[I'm not sure this configuration parameter is necessary. Only the launching user can flex the service, so this user should know whether flexing makes sense for components of their service. I am also not sure about having different defaults for different policies; it seems like this will be confusing and require complex documentation., If people disagree with me and we do allow this to be configured, it should be through a configuration property read with YarnServiceConf.getBoolean rather than a new field. I'd prefer it to default to true (allowing flexing) for all types, but am flexible on its default for the NEVER type., Instead of introduce another field to enable or disable flex.  We can identify if the workload can perform flex operation base on restart_policy.

When restart_policy=ON_FAILURE or ALWAYS, this means the data can be recomputed, or the process can resume from failure.  Flex operation can be enabled.

When restart_policy=NEVER, this means the data is stateful, and can not reprocess.  (i.e. mapreduce writes to HBase without transaction property.) . This type of containers are not allowed to have flexing operation.

By reasoning deduction, it is possible to reduce combinations that will be supported.  This also implies that restart_policy=NEVER doesn't have to support upgrade., Thanks [~suma.shivaprasad] for filing the JIRA and suggestions from [~eyang] / [~billie.rinaldi], 

I think the service flexing is different from restart policy: As mentioned by [~eyang], restart policy = on_failure / always means some part of the job can be *recomputed*. *Recomputable* is different from *Expandable*, an example is map-reduce, # of mappers and reducers are determined by InputFormat, which is determined before job get launched. Allocating more mappers or reducers than pre-calculated while job is running doesn't helpful. Many computation frameworks are in this pattern, such as Tensorflow/OpenMPI, etc. adding tasks while job is running isn't helpful.

Considering this, I would prefer what Suma suggested, allow user to specify allow_flexing, sometimes adding a new instance to a component could lead task or even master failure because it is unexpected. I tend to agree making allow_flexing=false by default, but I'm also fine with the opposite., [~leftnoteasy] Recompute and expandable are intertwined.  They are not the same thing.  At conceptual level, teragen has no dependency of input format.  You can add more partitions to get more data generated.  Hadoop's own implementation limited this from happening, but this does not mean docker containers should be imposed by the same initialization time limitation.  On the other hand, we must optimize the framework for general purpose usage and prevent ourselves from giving too many untested and unsupported options.  I think it make sense to reduce the flex options to 2 main types instead of giving all 6 options., [~eyang], 

Thanks for commenting, your suggestion makes sense, and has less dev/testing overhead. I think we can do as you suggested: allow flexing when restart-policy  = always / on-failure; and disallow flexing when restart-policy = never.

We can add a separate allow_flexing flag to spec if once we see solid requirements from users.

[~suma.shivaprasad], does this make sense to you, please feel free to share your opinions., I agree with Eric's suggestion as well., One usecase I can think of is in the case of Spark applications which have Dynamic Allocation enabled on the Spark driver and executors need to flex up and down based on driver's discretion. There could two be components here - one for Spark Driver and one for Spark Executor and the driver needs to flex the executor component instances up and down based on workload at that point in time /idle timeout. 

Thoughts [~eyang] [~leftnoteasy] [~billie.rinaldi], [~suma.shivaprasad] Restart_policy = ON_FAILURE covers Spark use case to start more executor base on workload demand, no?]