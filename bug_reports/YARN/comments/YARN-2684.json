[Hi [~kasha], Shall I work on this jira?, All yours, Rohith. Thanks for taking this up. , While going through writing test cases for queue removed scenario, found different behavior that even leafqueue does not exist in fair-scheduler, queue got created!!! 
Any configuration am I missing?, IIUC, to simulate queueplacement policy should be changed.I am able to simulate same using rule name *reject*. Basically, as I seen fairscheduler code no other rule rejects applications other then only rule *reject*. Will upload patch to fix the issue soon., Attached the patch fixinng this issue. Kindly review the patch., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12690068/0001-YARN-2684.patch
  against trunk revision 21c6f01.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 2 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:red}-1 findbugs{color}.  The patch appears to introduce 1 new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager.

Test results: https://builds.apache.org/job/PreCommit-YARN-Build/6243//testReport/
Findbugs warnings: https://builds.apache.org/job/PreCommit-YARN-Build/6243//artifact/patchprocess/newPatchFindbugsWarningshadoop-yarn-server-resourcemanager.html
Console output: https://builds.apache.org/job/PreCommit-YARN-Build/6243//console

This message is automatically generated., [~kasha] Kindly review the patch, Looks like the patch here handles queue configuration changes gracefully. [~rohithsharma] - is my understand correct? 

I am open to getting this in, but we should also work on ensuring the configuration changes are preserved across restarts, may be in a follow-up JIRA., Thanks [~kasha] for reviewing the patch

bq. Looks like the patch here handles queue configuration changes gracefully
QueueNotFoundException has thrown and exit the RM. Basically, configuration change during RM restart is not supported as of now as per CS fix. I made in sync with as CS.

bq. we should also work on ensuring the configuration changes are preserved across restarts
sounds good. , [~kasha] kindly provide your thoughts any more changes to be done as part of this JIRA., Cancel the patch since it does not apply anymore.
[~rohithsharma] Could you re-base the patch, please ?, [~xgong] thanks for looking in the patch..
Rebased the patch and updated. Kindly review the updated patch, \\
\\
| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | pre-patch |  14m 33s | Pre-patch trunk compilation is healthy. |
| {color:green}+1{color} | @author |   0m  0s | The patch does not contain any @author tags. |
| {color:green}+1{color} | tests included |   0m  0s | The patch appears to include 1 new or modified test files. |
| {color:green}+1{color} | javac |   7m 30s | There were no new javac warning messages. |
| {color:green}+1{color} | javadoc |   9m 36s | There were no new javadoc warning messages. |
| {color:green}+1{color} | release audit |   0m 23s | The applied patch does not increase the total number of release audit warnings. |
| {color:red}-1{color} | checkstyle |   0m 46s | The applied patch generated  1 new checkstyle issues (total was 74, now 75). |
| {color:red}-1{color} | whitespace |   0m  0s | The patch has 1  line(s) that end in whitespace. Use git apply --whitespace=fix. |
| {color:green}+1{color} | install |   1m 35s | mvn install still works. |
| {color:green}+1{color} | eclipse:eclipse |   0m 32s | The patch built with eclipse:eclipse. |
| {color:green}+1{color} | findbugs |   1m 14s | The patch does not introduce any new Findbugs (version 2.0.3) warnings. |
| {color:green}+1{color} | yarn tests |  52m 33s | Tests passed in hadoop-yarn-server-resourcemanager. |
| | |  88m 45s | |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12731104/0002-YARN-2684.patch |
| Optional Tests | javadoc javac unit findbugs checkstyle |
| git revision | trunk / 305e473 |
| checkstyle |  https://builds.apache.org/job/PreCommit-YARN-Build/7757/artifact/patchprocess/diffcheckstylehadoop-yarn-server-resourcemanager.txt |
| whitespace | https://builds.apache.org/job/PreCommit-YARN-Build/7757/artifact/patchprocess/whitespace.txt |
| hadoop-yarn-server-resourcemanager test log | https://builds.apache.org/job/PreCommit-YARN-Build/7757/artifact/patchprocess/testrun_hadoop-yarn-server-resourcemanager.txt |
| Test Results | https://builds.apache.org/job/PreCommit-YARN-Build/7757/testReport/ |
| Java | 1.7.0_55 |
| uname | Linux asf906.gq1.ygridcore.net 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Console output | https://builds.apache.org/job/PreCommit-YARN-Build/7757/console |


This message was automatically generated., Sorry for the delay in following up here.

Until we actually preserve queue changes on RM restarts by storing the information about queues, we should fail the application with a descriptive enough message, and not bring the RM down. 


, In CS, RM is brought down if queue configuration is changed. I think it is better to keep in sync across the schedulers. Any suggestions?, It would definitely be nice to have the same behavior across schedulers, but I am not convinced crashing the RM is the preferred approach.

We have a bunch of these cases where we need to pick between failing the RM vs failing the application. I can see users preferring one vs the other. May be, we should have a config for this. And, all places where we have to make a choice, we decide based on the value of this config. , One scenario I am thinking for failling the RM instead of failing the applications is in bigger cluster where hundreds or thousands of applications are long running. Because of the probably admin configuration mistake , failing all the applications is not good then failing RM. If RM is failed, then more likely to recover the running applications., [~rohithsharma] - agree. As I said earlier and on YARN-3607, there is no right/wrong answer here. I don't think we are in a position to make the call for our users without understanding their requirements.

Discussed YARN-2308 with [~vinodkv] and [~leftnoteasy] - they seem to think crashing the RM is too aggressive. , [~rohithsharma]/[~kasha], do you have bandwidth to finish this recently? May I move this to 2.9 if you don't?, This require more discussion, I will move this to 2.9, Unassigning this JIRA, so that any other folks can work on this.]