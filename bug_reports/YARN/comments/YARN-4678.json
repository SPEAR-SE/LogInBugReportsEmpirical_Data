[ *As reserved memory is include in the used resources. queue capacity > 100* ..Please let me know any thoughts on this..

2016-02-22 01:15:09,359 | INFO  | ResourceManager Event Processor | completedContainer queue=root usedCapacity=0.9583333 absoluteUsedCapacity=0.9583333  *{color:red}used=<memory:23552, vCores:7> cluster=<memory:24576, vCores:24>{color}*  | ParentQueue.java:631
2016-02-22 01:15:09,359 | INFO  | ResourceManager Event Processor | Re-sorting completed queue: root.QueueA stats: QueueA: capacity=0.4, absoluteCapacity=0.4, usedResources=<memory:17920, vCores:5>, usedCapacity=1.8229909, absoluteUsedCapacity=0.7291667, numApps=1, numContainers=5 | ParentQueue.java:648
2016-02-22 01:15:09,359 | INFO  | ResourceManager Event Processor | Application attempt appattempt_1456061422894_0003_000001 released container container_e05_1456061422894_0003_01_004504 on  *{color:blue}node: host: vm-3:26009{color}*  #containers=1 available=<memory:6656, vCores:7> used=<memory:1536, vCores:1> with event: FINISHED | CapacityScheduler.java:1452
2016-02-22 01:15:09,359 | INFO  | ResourceManager Event Processor | Trying to fulfill reservation for application application_1456061422894_0003 on node: vm-3:26009 | CapacityScheduler.java:1110
2016-02-22 01:15:09,359 | INFO  | ResourceManager Event Processor | Application application_1456061422894_0003 *{color:blue}unreserved  on node host: vm-3:26009{color}*  #containers=1 available=<memory:6656, vCores:7> used=<memory:1536, vCores:1>, currently has 0 at priority 20; currentReservation <memory:0, vCores:0> on node-label= | FiCaSchedulerApp.java:229
2016-02-22 01:15:09,359 | INFO  | ResourceManager Event Processor | container_e05_1456061422894_0003_01_004505 Container Transitioned from NEW to ALLOCATED | RMContainerImpl.java:419
2016-02-22 01:15:09,359 | INFO  | ResourceManager Event Processor | Assigned container container_e05_1456061422894_0003_01_004505 of capacity <memory:4096, vCores:1> on  *{color:blue}host vm-3:26009{color}* , which has 2 containers, <memory:5632, vCores:2> used and <memory:2560, vCores:6> available after allocation | SchedulerNode.java:154
2016-02-22 01:15:09,359 | INFO  | ResourceManager Event Processor | assignedContainer application attempt=appattempt_1456061422894_0003_000001 container=Container: [ContainerId: container_e05_1456061422894_0003_01_004505, NodeId: vm-3:26009, NodeHttpAddress: vm-3:26010, Resource: <memory:4096, vCores:1>, Priority: 20, Token: null, ] queue=QueueA: capacity=0.4, absoluteCapacity=0.4, usedResources=<memory:17920, vCores:5>, usedCapacity=1.8229909, absoluteUsedCapacity=0.7291667, numApps=1, numContainers=5 clusterResource=<memory:24576, vCores:24> | LeafQueue.java:1731
2016-02-22 01:15:09,360 | INFO  | ResourceManager Event Processor | container_e05_1456061422894_0003_01_004508 Container Transitioned from *{color:blue}NEW to RESERVED{color}*  | RMContainerImpl.java:419
2016-02-22 01:15:09,360 | INFO  | ResourceManager Event Processor |  *Reserved container  application=application_1456061422894_0003 resource=<memory:4096, vCores:1>*  queue=QueueA: capacity=0.4, absoluteCapacity=0.4, usedResources=<memory:17920, vCores:5>, usedCapacity=1.8229909, absoluteUsedCapacity=0.7291667, numApps=1, numContainers=5 usedCapacity=1.8229909 absoluteUsedCapacity=0.7291667 used=<memory:17920, vCores:5> cluster=<memory:24576, vCores:24> | LeafQueue.java:1764
2016-02-22 01:15:09,360 | INFO  | ResourceManager Event Processor | Re-sorting assigned queue: root.QueueA stats: QueueA: capacity=0.4, absoluteCapacity=0.4, usedResources=<memory:22016, vCores:6>, usedCapacity=2.2396743, absoluteUsedCapacity=0.8958333, numApps=1, numContainers=6 | ParentQueue.java:585
2016-02-22 01:15:09,360 | INFO  | ResourceManager Event Processor |  *assignedContainer queue=root {color:red}usedCapacity=1.125 absoluteUsedCapacity=1.125 
used=<memory:27648, vCores:8> 
cluster=<memory:24576, vCores:24>{color}*  | ParentQueue.java:465, Hi [~brahma]
Yes, {{usedCapacity}} also includes {{reservedCapacity}}. So we can get this corner cases where total resource may shoot more than 100%.
I think we can avoid this problem by showing only usedCapacity in UI for queues. ClusterMetrics is already updated with this change. I think its fine to take this to Queues also., Hi [~brahmareddy]
Sharing an initial version of patch based on above explanation., [~sunilg] thanks for the patch..Approach looks good to me.

 *One comment:* 
Need to correct following testcase,as new field ({{reservedCapacity}}) introduced.

TestRMWebServicesCapacitySched#verifyClusterScheduler(JSONObject json)
  {{assertEquals("incorrect number of elements", 8, info.length());}}, it should be 9 now.
   , Thanks [~brahmareddy]. Yes, it will result in test case failure. I will handle in the next patch, also will attach screen shot., Updating patch addressing the comments., Checking with Jenkins again.., [~sunilg]  Patch almost looks good to me...

one more scenario which is found by [~bibinchundatt].

Parent and leaf queue usage percentages are  different when only one subqueue is present( i.e default) and reservation happens.

So I am thinking , can we handle as part of this jira only..? and fix can be like following,, what do you say..?

{{QueueBlock#render(Block html)}}

{code}
-        used = partitionQueueCapsInfo.getUsedCapacity() / 100;
+        used =
+            (partitionQueueCapsInfo.getUsedCapacity() - partitionQueueCapsInfo
+                .getReservedCapacity()) / 100;
         absCap = partitionQueueCapsInfo.getAbsoluteCapacity() / 100;
         absMaxCap = partitionQueueCapsInfo.getAbsoluteMaxCapacity() / 100;
         absUsedCap = partitionQueueCapsInfo.getAbsoluteUsedCapacity() / 100;
{code}, [~brahmareddy] Thanks for sharing the scenario.

We have made changes only to parent queue in current patch. We could have been done similar change in LeafQueue, but I had one concern. To select an under serving queue while processing a node heartbeat, we still consider usedCapacity(inclusive of reservedCapacity), so there might be difference is showing queue capacity on these two cases. I still feel its fine to go ahead with UI changes as reservation metrics are displayed in LeafQueue page.. Let me make change to consider this scenario. Meantime if you or [~bibinchundatt] see the above mentioned scenario as a pblm, pls share your thoughts., Updating patch by removing reservedCapacity from LeafQueue also. Hence this will be in line with ParentQueue / root. Since we have more information about reservedCapacity in ClusterMetrics and in QueueInfo area, I think this will be fine. [~brahmareddy], could you pls confirm if its fine., | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 14s {color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green} 0m 0s {color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 6m 30s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 0m 25s {color} | {color:green} trunk passed with JDK v1.8.0_74 {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 0m 29s {color} | {color:green} trunk passed with JDK v1.7.0_95 {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 22s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 0m 34s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 14s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 1m 6s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 0m 20s {color} | {color:green} trunk passed with JDK v1.8.0_74 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 0m 26s {color} | {color:green} trunk passed with JDK v1.7.0_95 {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 0m 29s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 0m 23s {color} | {color:green} the patch passed with JDK v1.8.0_74 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 0m 23s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 0m 26s {color} | {color:green} the patch passed with JDK v1.7.0_95 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 0m 26s {color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} checkstyle {color} | {color:red} 0m 19s {color} | {color:red} hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager: patch generated 8 new + 333 unchanged - 1 fixed = 341 total (was 334) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 0m 31s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 12s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green} 0m 0s {color} | {color:green} Patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 1m 14s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 0m 18s {color} | {color:green} the patch passed with JDK v1.8.0_74 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 0m 23s {color} | {color:green} the patch passed with JDK v1.7.0_95 {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 70m 20s {color} | {color:red} hadoop-yarn-server-resourcemanager in the patch failed with JDK v1.8.0_74. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 71m 54s {color} | {color:red} hadoop-yarn-server-resourcemanager in the patch failed with JDK v1.7.0_95. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green} 0m 17s {color} | {color:green} Patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 158m 24s {color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| JDK v1.8.0_74 Failed junit tests | hadoop.yarn.server.resourcemanager.TestClientRMTokens |
|   | hadoop.yarn.server.resourcemanager.webapp.TestRMWebServicesForCSWithPartitions |
|   | hadoop.yarn.server.resourcemanager.TestAMAuthorization |
| JDK v1.7.0_95 Failed junit tests | hadoop.yarn.server.resourcemanager.TestClientRMTokens |
|   | hadoop.yarn.server.resourcemanager.webapp.TestRMWebServicesForCSWithPartitions |
|   | hadoop.yarn.server.resourcemanager.TestAMAuthorization |
|   | hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:0ca8df7 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12793189/0003-YARN-4678.patch |
| JIRA Issue | YARN-4678 |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux 54fe868d6bda 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 658ee95 |
| Default Java | 1.7.0_95 |
| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_74 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_95 |
| findbugs | v3.0.0 |
| checkstyle | https://builds.apache.org/job/PreCommit-YARN-Build/10774/artifact/patchprocess/diff-checkstyle-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-resourcemanager.txt |
| unit | https://builds.apache.org/job/PreCommit-YARN-Build/10774/artifact/patchprocess/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-resourcemanager-jdk1.8.0_74.txt |
| unit | https://builds.apache.org/job/PreCommit-YARN-Build/10774/artifact/patchprocess/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-resourcemanager-jdk1.7.0_95.txt |
| unit test logs |  https://builds.apache.org/job/PreCommit-YARN-Build/10774/artifact/patchprocess/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-resourcemanager-jdk1.8.0_74.txt https://builds.apache.org/job/PreCommit-YARN-Build/10774/artifact/patchprocess/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-resourcemanager-jdk1.7.0_95.txt |
| JDK v1.7.0_95  Test Results | https://builds.apache.org/job/PreCommit-YARN-Build/10774/testReport/ |
| modules | C: hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager U: hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager |
| Console output | https://builds.apache.org/job/PreCommit-YARN-Build/10774/console |
| Powered by | Apache Yetus 0.2.0   http://yetus.apache.org |


This message was automatically generated.

, Hi [~sunilg],

Thanks for working on this JIRA, it is useful to record reserved resources separately.

However, I'm thinking how this could happen: ParentQueue's capacity will be checked when we reserve container, we should make sure that allocation of reserved container shouldn't violate parent queue's max capacity., Actually I think we may need to consider this task to be 3 separate tasks:
1) Understand why reserved resource + allocated resource could excess queue's max capacity, maybe we can add a test to make sure it won't happen
2) If we simply deduct reserved resources from used and show on the UI, user could find cluster utilization is < 100 in most of the time, and it gonna be hard to explain the reason of why it cannot reach 100%. The ideal solution is that we can show reserved and allocated resources on the same bar with different color.
3) Record reserved resources in ResourceUsage and QueueCapacities separately.

Thoughts?, Thank you [~leftnoteasy] for sharing the thoughts.

bq.1) reserved resource + allocated resource could excess queue's max capacity, maybe we can add a test to make sure it won't happen

With minimum allocation configured to a low number and if the node label resource is not perfectly divisible by application demand (one container request as 512 MB etc), its possible that used+reserved will reach more than 100%. Its not very big margin, may be like 108%. [~brahmareddy], if you could share the test scenario which you performed,  it ll be great.

I can prepare a test case from YARN side to prove this. I will attach soon.

bq. If we simply deduct reserved resources from used and show on the UI, user could find cluster utilization is < 100 in most of the time, and it gonna be hard to explain the reason of why it cannot reach 100%.

Currently cluster metrics is shown differently when reservation happens. Attaching a screen shot to clarify. {{Refer:reservedCapInClusterMetrics.png}}. Here Total capacity is shown as 14 and reserved as 2GB. Total capacity is 16. So cluster metrics is already showing reserved separately. But I liked the idea of two colors for used and reserved. Its better to do that way. I will check this option . However as mentioned in point 1), still total can show more than 100% unless we fix the corner case. We can fix this from a  stricter check (by dividing with minimum allocation there can be few round-off case). 

bq.3) Record reserved resources in ResourceUsage and QueueCapacities separately.
Yes, I will raise a different ticket to handle this., Hi [~sunilg],

bq. Yes, I will raise a different ticket to handle this.
If it is possible, could you do this first? I plan to use it in YARN-4390, and it's dependency of other JIRAs as well.

Thanks,, Thank You

YARN-4865 is raised for tracking the same. I will share a patch there., bq.1) Understand why reserved resource + allocated resource could excess queue's max capacity, maybe we can add a test to make sure it won't happen

Total= 9216 MB ( 9GB) where each NM is having 3GB ( total 3 NM's)
Configure a queueA with 10% and submit  pi job with 2GB map memory and total-5 Containers request. Please check the following for same.


||Used||Usedcapacity||absoluteUsedCapacity||NM-Remaining||
|512 MB ( AM Conatiner Request)|0.55 ( 512 MB/ 921 MB)|0.055 ( 512MB /9216 MB)|{color:blue}NodeA{color}-2560MB|
|2560 MB ( Container allocation with 2GB)|2.7795875|0.2777778|{color:green}NodeB{color}-1024MB|
|4608 MB ( Container Reservation with 2GB)|5.0032573|0.5|{color:green}NodeB{color}-1024MB,{color:red}2048MB Reserved{color}|
|6656 MB ( Container allocation with 2GB)|7.226927|0.7222222|NodeC-1024MB|
|8704 MB ( Container Reservation with 2GB)| 9.450597|0.9444444|NodeC-1024MB,{color:red}2048MB Reserved{color}||
|10752 MB ( Container allocation with 2GB)| 11.674267|1.1674267|{color:blue}NodeA{color}-512MB|

bq. 2) If we simply deduct reserved resources from used and show on the UI, user could find cluster utilization is < 100 in most of the time, and it gonna be hard to explain the reason of why it cannot reach 100%. The ideal solution is that we can show reserved and allocated resources on the same bar with different color.

I think, will it make confusion ..? as sunil mentioned we are giving metrics for both resereved and used.. I feel, subracting from used should be ok.
, [~brahmareddy],

Are you using latest branch-2 or trunk to run the test?

bq. I think, will it make confusion ..? as sunil mentioned we are giving metrics for both resereved and used.. I feel, subracting from used should be ok.
It will be fine after we can show reserved / allocated separately on the UI., Attaching a test case to prove Queue's Used capacity can go more than 100%. 
, [~sunilg],

Thanks for uploading test case, however, it doesn't demonstrate maximum resource of queue (or cluster total resource) will be is violated:
Total cluster resource in your test case is 16G, and the queue only uses 8+G.

IIUC, [~brahmareddy] mentioned in the JIRA is, cluster total used capacity could be more than 100%.

Thanks,
Wangda, Thanks [~leftnoteasy] for pointing out. I was trying to check the case where queue's cap is going more than 100% eventhough it has only defined limit.
For cluster level, i could see its taking always  < 100. This is as per trunk, I wll check with [~brahmareddy] offline for clarification.]