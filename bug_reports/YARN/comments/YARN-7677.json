[Linking YARN-3611 since this is related to Docker development. Not putting it as a subtask, however, because this JIRA has impacts outside of Docker., My proposal would be to remove {{HADOOP_CONF_DIR}}, as well as potentially {{USER}}, {{LOGNAME}}, {{HOME}}, and {{PWD}} from ContainerLaunch.java and require them to be in the environment whitelist if they are to be taken from Nodemanager environment. Arguably, these all should be removed, but the strongest case can be made for {{HADOOP_CONF_DIR}}, since it is already in the default environment whitelist. So the only way this would break a use case is if someone was using their own whitelist and didn't include {{HADOOP_CONF_DIR}}. 

While this change would be incompatible, I think it makes sense for the non-docker case, and is paramount for the docker case., [~ebadger] Happy new year.  I think it will be safer for {{HADOOP_CONF_DIR}} to be passed from host to docker image as default.  This is better for preventing mistakes instead of allowing override system specific settings at container level.  This will also ensure that when an application requires system settings, docker doesn't need to reconstruct the environment, but simply mount the {{HADOOP_CONF_DIR}} as source of truth.  If docker container wants to generate its own environment, there shouldn't be anything getting in the way for docker application to accomplish that.  I don't understand how is this paramount for docker case, could you elaborate?  Thanks, [~eyang], the docker container file system layout doesn't have to be the same as the host. It's entirely possible for an image to have {{HADOOP_CONF_DIR}} set to something like {{/home/conf}}, while the host has it in {{/tmp/conf}}. In the current implementation, there is no way for {{HADOOP_CONF_DIR}} to be set correctly in this case without the user explicitly setting it with their job. Even if you set up {{HADOOP_CONF_DIR}} in the image as an environment variable, it will be overridden by the container startup script, since {{HADOOP_CONF_DIR}} is being passed in by default regardless. In the case where a user doesn't set {{HADOOP_CONF_DIR}} explicitly, it makes sense that the docker image will know where to set it (via ENV), while the NM will not, since their layouts are not necessarily the same., [~ebadger] I think I understand your scenario better now.  When host and docker environments runs two separate Hadoop clusters, we do not want the host Hadoop configuration to be exposed to docker because disk settings and file system layout do not apply.  Other scenarios, such as HDFS is outside of docker container, and running Spark python application in docker container to access host level HDFS, Hadoop configuration should be inherited from host to make sure well optimized timing settings are exposed.  For huge clusters, the first scenario maybe used to isolate virtual clusters.  

For smaller clusters, it is most likely to run mix workload and use docker to isolate programming libraries.  Host level node manager white list can not get overwritten by container.  I think both cases can be supported, and the default is probably inheriting {{HADOOP_CONF_DIR}} for smaller clusters to boost efficient utilization of system resource.  It would be better if we build a switch for env_reset as part of job submission flag to disable Hadoop system environment variable inheritance., [~eyang], it doesn't necessarily need to be separate hadoop clusters. It could just be a node where the NM runs on the bare metal host and the tasks run in docker containers. In that case, they would need to know where {{HADOOP_CONF_DIR}} is. Since the docker image is completely separate from the host layout, we can't assume that hadoop is going to be put in the same place. {{HADOOP_CONF_DIR}} isn't getting bind-mounted into the container, so the only way this would even work is by a happy coincidence and/or planning the layout of the image to match that of the host. But that coupling is certainly not necessary and the docker image is the one that actually knows where {{HADOOP_CONF_DIR}} is located. The nodemanager knows where its {{HADOOP_CONF_DIR}} is located, but that is on the host, not in the docker container. 

And again, since {{HADOOP_CONF_DIR}} is in the default env whitelist, the behavior here will only change if you explicitly change the env whitelist and remove it. So I believe the impact here to be fairly low. Regardless, I don't think it's correct for the NM to be defining the layout of the docker image (i.e. where {{HADOOP_CONF_DIR}} has to be located). , [~ebadger] My initial reaction would be to make docker container to follow the host layout for single cluster setup.  Some Hadoop features will not work, i.e. short circuits read, if host and docker containers are not matching.  For docker container to regenerate fine tuned Hadoop configuration to match host, it could take some effort from docker container developer.  There is a high probability that developers end up using bind-mount to transport Hadoop configuration.

If we handle security properly with white list mount (YARN-5534), container-executor validation (YARN-7590), and check sudo privileges before launching privileged container (YARN-7221).  Any particular reason that we shouldn't allow read-only bind-mount {{HADOOP_CONF_DIR}}?  , I think I am stuck on understanding:

{quote}
It completely bypasses the whitelist and so there is no way for a task to not have HADOOP_CONF_DIR set. 
{quote}

White list is used by container-executor, which resides in host, and not docker container.  How is the by pass happened?, bq. Some Hadoop features will not work, i.e. short circuits read, if host and docker containers are not matching.
This is true. I would like to work towards a solution where we use something similar {{dfs.domain.socket.path}}, since it already defines the short-circuit socket. However, I'm not sure how to do that without copying the config, since this is a dfs property that will be used by the datanode (i.e. not the container-executor).

bq. If we handle security properly with white list mount (YARN-5534), container-executor validation (YARN-7590), and check sudo privileges before launching privileged container (YARN-7221). Any particular reason that we shouldn't allow read-only bind-mount HADOOP_CONF_DIR?
Nope, I don't think there is any problem with bind-mounting {{HADOOP_CONF_DIR}}. However, I don't think it should be a requirement. For example, you should be able to use an older version of hadoop as the client (task), while the server (NM) uses a newer version. If we pass in {{HADOOP_CONF_DIR}} then this is not possible. If we are constantly bind-mounting in hadoop to all of the containers, then we lose some of the wonder of docker, which is that the container stays constant and consistent over time. Some may choose to bind-mount hadoop, but it should be a choice, not a requirement

bq. White list is used by container-executor, which resides in host, and not docker container. How is the by pass happens?
This happens because of a call in {{ContainerLaunch.java}} that automatically adds {{HADOOP_CONF_DIR}} to the environment. This environment is parsed in {{launch_container.sh}}, which is the script that the docker container is started with.

{noformat:title=ContainerLaunch.sh}
1388    putEnvIfAbsent(environment, Environment.HADOOP_CONF_DIR.name());
{noformat}, [~ebadger] I think I understand the goal now.  Thank you.  In current implementation, partial declaration of bind-mount may allow HADOOP_CONF_DIR to be sourced implicitly without proper user consent.  This change will make yarnfile content more consistent that environment variable and mounting directories both needs to present in yarnfile to show {{HADOOP_CONF_DIR}} is exposed to docker container.  , bq. This change will make yarnfile content more consistent that environment variable and mounting directories both needs to present in yarnfile to show HADOOP_CONF_DIR is exposed to docker container.
Yes, that is correct. I'll go ahead an put up a patch in a little bit once I get a free moment., Based on the discussion here and in YARN-7226, and after discussing with [~jlowe] and [~ebadger], I have put up a patch for this.

The change is as follows:
 # Remove the line in ContainerLaunch.sh that explicitly adds HADOOP_CONF_DIR to the environment (as noted above).
 # Instead of ignoring the whitelist in the case of docker, always add the whitelist environment variables that are not already defined in the containers context using the {{var:-default}} variable expansion syntax.

In the docker case where a whitelist environment variable is defined in the image, this will prevent the launch script from overwriting it with the one from the Nodemanager's environment.

The non-docker case behaves the same as before, except that the whitelisted environment variables 
 that are not defined by the container context are set using the {{var:-default}} syntax, but in this case the default value is always used.
, Uploaded patch for testing., | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 15s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 14m 50s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 45s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 18s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 39s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green}  9m 42s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  0m 45s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 19s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 29s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 44s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 44s{color} | {color:green} the patch passed {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 16s{color} | {color:orange} hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager: The patch generated 4 new + 157 unchanged - 0 fixed = 161 total (was 157) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 27s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green}  9m 45s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  0m 49s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 18s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 19m 21s{color} | {color:red} hadoop-yarn-server-nodemanager in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 22s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 59m 53s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.yarn.server.nodemanager.containermanager.TestContainerManager |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:5b98639 |
| JIRA Issue | YARN-7677 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12908215/YARN-7677.001.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |
| uname | Linux 31bf9018ad69 4.4.0-64-generic #85-Ubuntu SMP Mon Feb 20 11:50:30 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 901d15a |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_151 |
| findbugs | v3.1.0-RC1 |
| checkstyle | https://builds.apache.org/job/PreCommit-YARN-Build/19526/artifact/out/diff-checkstyle-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-nodemanager.txt |
| unit | https://builds.apache.org/job/PreCommit-YARN-Build/19526/artifact/out/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-nodemanager.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-YARN-Build/19526/testReport/ |
| Max. process+thread count | 410 (vs. ulimit of 5000) |
| modules | C: hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager U: hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager |
| Console output | https://builds.apache.org/job/PreCommit-YARN-Build/19526/console |
| Powered by | Apache Yetus 0.8.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

, I believe the unit test failure (testContainerUpgradeRollbackDueToFailure) is unrelated to this change.

I will fix the style issues and submit a new patch.
, | (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 32s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 15m 22s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 47s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 19s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 30s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green}  9m  6s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  0m 47s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 19s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 29s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 42s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 42s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 15s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 27s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green}  9m 36s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  0m 51s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 20s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 19m 28s{color} | {color:green} hadoop-yarn-server-nodemanager in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 18s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 60m 14s{color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:5b98639 |
| JIRA Issue | YARN-7677 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12908365/YARN-7677.002.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |
| uname | Linux 20d6d9ece274 4.4.0-89-generic #112-Ubuntu SMP Mon Jul 31 19:38:41 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 901d15a |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_151 |
| findbugs | v3.1.0-RC1 |
|  Test Results | https://builds.apache.org/job/PreCommit-YARN-Build/19527/testReport/ |
| Max. process+thread count | 441 (vs. ulimit of 5000) |
| modules | C: hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager U: hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager |
| Console output | https://builds.apache.org/job/PreCommit-YARN-Build/19527/console |
| Powered by | Apache Yetus 0.8.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

, Thanks for the patch!

+1 lgtm.  I will commit this tomorrow if there are no objections., +1 (non-binding). Looks good to me. Thanks for fixing this [~Jim_Brennan], Thanks to [~Jim_Brennan] for the contribution and to [~ebadger] for additional review!  I committed this to trunk and branch-3.0.

The patch does not apply to branch-2.  Jim, would you mind providing a patch for that branch?, SUCCESS: Integrated in Jenkins build Hadoop-trunk-Commit #13591 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/13591/])
YARN-7677. Docker image cannot set HADOOP_CONF_DIR. Contributed by Jim (jlowe: rev 12eaae383ad06de8f9959241b2451dec82cf9ceb)
* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/linux/runtime/DelegatingLinuxContainerRuntime.java
* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/runtime/ContainerRuntime.java
* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/launcher/ContainerLaunch.java
* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/linux/runtime/DockerLinuxContainerRuntime.java
* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/launcher/TestContainerLaunch.java
* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/ContainerExecutor.java
* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/linux/runtime/DefaultLinuxContainerRuntime.java
* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/LinuxContainerExecutor.java
, Thanks [~jlowe] I will put up a patch for branch-2.
, [~Jim_Brennan], thanks for putting this together. With this patch in, all AM's are failing to launch with classpath related issue in my dev environment. Still looking into the cause, but do you have any thoughts?, [~shanekumpf@gmail.com] are you running with docker?, Is this with Docker containers or without?  There are two main changes with this patch:
# HADOOP_CONF_DIR needs to be in the whitelist config to be inherited from the NM.  (It is in the default whitelist setting already).
# In Docker, whitelisted variables that would be inherited from the NM but are also set by the Docker image will use the Docker image setting instead of the NM setting.
, Docker is enabled, but the applications in question are not leveraging docker. These are simple apps like MR sleep and distributed shell. All mapreduce classpath settings, yarn.application.classpath, and whitelist env are not set and are using the defaults. I've tried setting these in various ways that used to work, but haven't found a working combination yet., Ultimately one way to debug this would be to compare the container launch scripts between the two scenarios (i.e.: with and without YARN-7677 applied).  The only difference should be that some variables in the launch script will have the export var=$\{_var_:-_value_\} syntax that didn't before.  In the non-Docker case, all of those variables should be getting the NM settings unless somehow those variables already are set to _different_ values in the environment before the launch script runs.
, If all AMs are failing in [~shanekumpf@gmail.com]'s case, shouldn't we revert first, and ask questions later? We don't want to destabilize the build., [~shanekumpf@gmail.com], I am trying to repro locally. In my dev setup, it is currently working, but I typically run with mapreduce.application.framework.path and mapreduce.application.classpath defined in my mapred-site.xml file, pointing to a tarball in my home dir in hdfs.

If i remove those, I do get errors like these:
{noformat}
Error: Could not find or load main class org.apache.hadoop.mapreduce.v2.app.MRAppMaster

Please check whether your etc/hadoop/mapred-site.xml contains the below configuration:
<property>
  <name>yarn.app.mapreduce.am.env</name>
  <value>HADOOP_MAPRED_HOME=${full path of your hadoop distribution directory}</value>
</property>
<property>
  <name>mapreduce.map.env</name>
  <value>HADOOP_MAPRED_HOME=${full path of your hadoop distribution directory}</value>
</property>
<property>
  <name>mapreduce.reduce.env</name>
  <value>HADOOP_MAPRED_HOME=${full path of your hadoop distribution directory}</value>
</property>
{noformat}
Is this what you are seeing? I don't think this behavior was different before my change, but I'm going to revert it locally and double-check., [~shanekumpf@gmail.com], [~jlowe], [~ebadger] I have verified that this does not fail in the same way when I revert this change, so I agree with [~ebadger], we should revert this change until I can find a fix.

It is not immediately clear to me why it is failing.  Apologies for not catching this before submitting my patch., I reverted this from trunk and branch-3.0., [~Jim_Brennan] - Thanks for the update. [~billie.rinaldi] and I have been looking into it as well and we believe we have it figured out.

When comparing launch_container.sh with and without the change, HADOOP_CONF_DIR, HADOOP_COMMON_HOME, HADOOP_HDFS_HOME, etc are defined before CLASSPATH. With this change, all of the whilte listed env processing happens last, so the variables are the last to be defined. Moving the whitelist processing before the rest of environment processing fixed the issue for us., SUCCESS: Integrated in Jenkins build Hadoop-trunk-Commit #13598 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/13598/])
Revert "YARN-7677. Docker image cannot set HADOOP_CONF_DIR. Contributed (jlowe: rev 682ea21f2bbc587e1b727b3c895c2f513a908432)
* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/runtime/ContainerRuntime.java
* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/linux/runtime/DefaultLinuxContainerRuntime.java
* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/linux/runtime/DockerLinuxContainerRuntime.java
* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/launcher/ContainerLaunch.java
* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/launcher/TestContainerLaunch.java
* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/linux/runtime/DelegatingLinuxContainerRuntime.java
* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/ContainerExecutor.java
* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/LinuxContainerExecutor.java
, Thanks [~shanekumpf@gmail.com] and [~billie.rinaldi], I will try out that change., I'm not sure if it will be appropriate to address here, but I think we need to improve how we handle the ordering of the environment variables within the launch script. Right now it depends on hash map ordering... We likely need to ensure that any variable values are expanded out or defined prior to use to avoid this kind of issue., Agreed - given that we are just processing the hash map in order, it seems like we've just been getting lucky that the variables on which the classpath depends are coming before it in the launch_container.sh script.
, YARN-5714 is very relevant here.  In the general case, we're not going to be able to order the variables without doing a dependency analysis between them, and that's what YARN-5714 proposes to do.  I'll see what I can do to push that forward, since it looks like a more deterministic ordering will be a prerequisite to doing any sort of change relative to how environment variables are handled.  Otherwise we'll risk breaking some case where variable ordering happened to work, and the user has little recourse to restore it to a working condition.
, I have tested a version of the patch where I write out the whitelisted variables first, and it does work for my test cases. But looking at the launch_container.sh that is produced, the order of other variables is not the same as launch_container.sh from before my changes. Since the whitelisted variables are not added to the environment hash map, the order of traversal is different. I'm not comfortable with putting this change in as-is, because while the ordering differences I'm seeing are not a problem in my test cases, there is no guarantee that others would not run into problems due to this change.

I discussed this with [~jlowe], and he pointed me at YARN-5714. I think we need to address that problem before putting this change in., bq. In the general case, we're not going to be able to order the variables without doing a dependency analysis between them
It seems as if the dependency analysis ticket stalled due to disagreement about approach. I don't think we necessarily need dependency analysis; the primary use case is AM-defined vars being able to reference NM-defined vars, which we could accomplish by writing NM vars to the launch script first., Thanks for pointing out the existing issue and the prompt support on looking into this [~Jim_Brennan] and [~jlowe].
{quote}there is no guarantee that others would not run into problems due to this change
{quote}
I agree that having them first could have other unforeseen consequences and think the plan to address this after YARN-5714 makes sense.

 , bq. the primary use case is AM-defined vars being able to reference NM-defined vars, which we could accomplish by writing NM vars to the launch script first.

That assumes NM vars don't ever reference variables that could be overridden by the user.  For example, admin exports JAVA_HOME="/some/node/path/$JDKVER" and also sets JDKVER="1.8.0_u152", making sure both JAVA_HOME and JDKVER are both in the whitelist.  The idea here is users can select java versions by simply setting JDKVER to the version they need and don't need to know the specific path where it exists.  That's a case where NM whitelist variables could reference user variables, and listing NM vars first won't work.  Granted it might not always be working right now, but if it is, forcing NM variables to be first would guarantee it stopped working.
, It would be much more straightforward for the user to set JAVA_HOME to their desired value in that case., True, but that assumes the user even knows what the path is.  The point of such a setup is to decouple desired java version from where admins installed it., They'd have to be told the available versions by the admins, so they could just as easily be told the full paths. :), [~jlowe] I agree with [~billie.rinaldi] and YARN-5714 approach.  The classic unix approach to source system environment first, and user can override it in their own .profile or .bashrc.  System does not reference user environment variables to prevent user from doing harm to the system., I realize now that the theoretical example cannot work in practice.  In order for there to be a "hook" variable for the user to leverage, the variable would need to have escaped variable expansion by the shell when it was originally set.  The variable would need to be set in the NM's environment like, JAVA_HOME="/some/node/path/\$JDKVER".  While that could be a valid path for the user when it is expanded in the container launch script, it is not a valid setting for JAVA_HOME in the nodemanager itself.  NM whitelist variables are going to be variables coming from a shell environment and not from XML property settings, so it's highly unlikely they will retain unexpanded variable references.

In short, I'm cool with simply placing the NM whitelist variables first and simplifying YARN-5714 to list the variables in the launch script in the order they appear in their corresponding configuration properties.  My apologies for the detour.
, That sounds like a good approach, NM vars followed by preserving the order of the user variables. I'd prefer if the NM vars included all the ones defined by the NM (see ContainerLaunch.sanitizeEnv), not just the whitelist vars., Thanks everyone!  I will work on a new patch using this approach.
, I've put up another patch for this that addresses the ordering issues.

The new patch writes environment variables to the launch script in the following order:
 # Whitelisted variables that are coming from the NM environment (they were not set in the ContainerLaunchContext).  These are written using the default value syntax, so that whitelisted variables that are also set in the docker container will use the docker container setting.  These are written in the order they are listed in the NM_ENV_WHITELIST yarn config.
 # Variables that are explicitly set by the nodemanager (mostly in ContainerLaunch.sanitizeEnv()).  These are tracked so that they are written to the launch script in the order they are added in code.
 # Remaining variables from the ContainerLaunchContext.  Note that these are still not ordered - they are just written in hash-map order.  Changing these to ordered is covered by YARN-5714.  This patch just ensures that they come after whitelisted and NM vars.

 A couple notes about this patch:
 * Variables that are listed in NM_ENV_WHITELIST, but are also set in the ContainerLaunchContext() are written along with the rest of the ContainerLaunchContext environment variables (after NM variables).
 * I am currently tracking as an NM variable the CLASSPATH that is touched in sanitizeWindowsEnv(), but I think this is incorrect.  sanitizeWindowsEnv() only modifies CLASSPATH if it's already in the ContainerLaunchContext().
 * The variables defined in NM_ADMIN_USER_ENV are tracked along with those set by NM.  I'm not sure this is correct.

The patch includes a new test that verifies this ordering.

 , | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 34s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 10s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:red}-1{color} | {color:red} mvninstall {color} | {color:red}  7m 48s{color} | {color:red} root in trunk failed. {color} |
| {color:red}-1{color} | {color:red} compile {color} | {color:red}  1m 51s{color} | {color:red} hadoop-yarn in trunk failed. {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 54s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  9s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 11m 15s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 55s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 53s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 10s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m  6s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  9m 26s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} javac {color} | {color:red}  9m 26s{color} | {color:red} hadoop-yarn-project_hadoop-yarn generated 41 new + 46 unchanged - 0 fixed = 87 total (was 46) {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  1m  0s{color} | {color:orange} hadoop-yarn-project/hadoop-yarn: The patch generated 6 new + 163 unchanged - 2 fixed = 169 total (was 165) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 13s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 10m 11s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 33s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m  5s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  3m 22s{color} | {color:green} hadoop-yarn-common in the patch passed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 20m 21s{color} | {color:red} hadoop-yarn-server-nodemanager in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 30s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 76m 49s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.yarn.server.nodemanager.containermanager.TestContainerManager |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:5b98639 |
| JIRA Issue | YARN-7677 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12910272/YARN-7677.003.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |
| uname | Linux dc556b1ba171 4.4.0-64-generic #85-Ubuntu SMP Mon Feb 20 11:50:30 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 87e2570 |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_151 |
| mvninstall | https://builds.apache.org/job/PreCommit-YARN-Build/19664/artifact/out/branch-mvninstall-root.txt |
| compile | https://builds.apache.org/job/PreCommit-YARN-Build/19664/artifact/out/branch-compile-hadoop-yarn-project_hadoop-yarn.txt |
| findbugs | v3.1.0-RC1 |
| javac | https://builds.apache.org/job/PreCommit-YARN-Build/19664/artifact/out/diff-compile-javac-hadoop-yarn-project_hadoop-yarn.txt |
| checkstyle | https://builds.apache.org/job/PreCommit-YARN-Build/19664/artifact/out/diff-checkstyle-hadoop-yarn-project_hadoop-yarn.txt |
| unit | https://builds.apache.org/job/PreCommit-YARN-Build/19664/artifact/out/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-nodemanager.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-YARN-Build/19664/testReport/ |
| Max. process+thread count | 407 (vs. ulimit of 5500) |
| modules | C: hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager U: hadoop-yarn-project/hadoop-yarn |
| Console output | https://builds.apache.org/job/PreCommit-YARN-Build/19664/console |
| Powered by | Apache Yetus 0.8.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

, I submitted a new patch that addresses some of the style-check issues.  The other failures appear to be unrelated temporary build issues.  Hopefully those will not recur.  I did not address the style-check issue of too many arguments for writeLaunchEnv() - adding an argument in this case seemed the most appropriate approach., | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 35s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 52s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 16m 11s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 10m  6s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 56s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 17s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 11m 43s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 13s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 12s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 12s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m  5s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  8m 37s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  8m 37s{color} | {color:green} the patch passed {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 55s{color} | {color:orange} hadoop-yarn-project/hadoop-yarn: The patch generated 3 new + 164 unchanged - 2 fixed = 167 total (was 166) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 13s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green}  9m 56s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 20s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m  7s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  3m 12s{color} | {color:green} hadoop-yarn-common in the patch passed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 20m 10s{color} | {color:red} hadoop-yarn-server-nodemanager in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 28s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 93m 47s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.yarn.server.nodemanager.containermanager.scheduler.TestContainerSchedulerQueuing |
|   | hadoop.yarn.server.nodemanager.containermanager.TestContainerManager |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:5b98639 |
| JIRA Issue | YARN-7677 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12910396/YARN-7677.004.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |
| uname | Linux 1948c8cbd198 4.4.0-89-generic #112-Ubuntu SMP Mon Jul 31 19:38:41 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 0c5d7d7 |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_151 |
| findbugs | v3.1.0-RC1 |
| checkstyle | https://builds.apache.org/job/PreCommit-YARN-Build/19678/artifact/out/diff-checkstyle-hadoop-yarn-project_hadoop-yarn.txt |
| unit | https://builds.apache.org/job/PreCommit-YARN-Build/19678/artifact/out/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-nodemanager.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-YARN-Build/19678/testReport/ |
| Max. process+thread count | 440 (vs. ulimit of 5500) |
| modules | C: hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager U: hadoop-yarn-project/hadoop-yarn |
| Console output | https://builds.apache.org/job/PreCommit-YARN-Build/19678/console |
| Powered by | Apache Yetus 0.8.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

, I believe these are intermittent failures:
{noformat}
ERROR] Failures: 
[ERROR]   TestContainerManager.testContainerUpgradeRollbackDueToFailure:880 The Rolled-back process should be a different pid. Actual: 17405
[ERROR]   TestContainerSchedulerQueuing.testKillOpportunisticForGuaranteedContainer:547 expected:<SCHEDULED> but was:<RUNNING>
{noformat}

The check-style issues are due to adding an 8th argument to writeLaunchEnv(), and ContainerLaunch.call() going over 150 lines.  I can remove an empty line to address that, but I'm not sure it's worth it?

Aside from those issues, I think this Jira is ready to review.
([~jlowe], [~ebadger], [~shanekumpf@gmail.com], [~billie.rinaldi])
, Thanks for updating the patch!  Looks good overall, just a few nits:

It might be useful to reduce the varname duplication in sanitizeEnv and help avoid future copy-n-paste errors by creating a small helper function that takes the NM var set, the env to update, the variable name, and the value and updates both the env and the nm var set.

I don't think writeLaunchEnv should expect nmVars to be null.  Then NM will always have at least one variable to set for each container (e.g.: CONTAINER_ID), so in practice this will never be null.  It can only be null for tests, and I would argue the test code is responsible for passing something sane (e.g: Collections.emptySet());

sanitizeEnv and sanitizeWindowsEnv should take a Set rather than a LinkedHashSet.  Those method implementations do not require the incoming set to be a LinkedHashSet for them to do what they do (even though in practice that is what it will be).
, Thanks for the review!  I will address these issues and put up a new patch.

 , Uploaded another patch with updates based on [~jlowe]'s review., | (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 30s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 11s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 15m 45s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  8m 22s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m  2s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 24s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 11m 59s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m  6s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 15s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 11s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m  6s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  6m 24s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  6m 24s{color} | {color:green} the patch passed {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 59s{color} | {color:orange} hadoop-yarn-project/hadoop-yarn: The patch generated 2 new + 162 unchanged - 3 fixed = 164 total (was 165) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 20s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 10m 13s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 26s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 12s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  3m 17s{color} | {color:green} hadoop-yarn-common in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 19m 20s{color} | {color:green} hadoop-yarn-server-nodemanager in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 33s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 89m  3s{color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:5b98639 |
| JIRA Issue | YARN-7677 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12910619/YARN-7677.005.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |
| uname | Linux a41262b6c071 4.4.0-64-generic #85-Ubuntu SMP Mon Feb 20 11:50:30 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 1f20f43 |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_151 |
| findbugs | v3.1.0-RC1 |
| checkstyle | https://builds.apache.org/job/PreCommit-YARN-Build/19692/artifact/out/diff-checkstyle-hadoop-yarn-project_hadoop-yarn.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-YARN-Build/19692/testReport/ |
| Max. process+thread count | 441 (vs. ulimit of 5500) |
| modules | C: hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager U: hadoop-yarn-project/hadoop-yarn |
| Console output | https://builds.apache.org/job/PreCommit-YARN-Build/19692/console |
| Powered by | Apache Yetus 0.8.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

, The remaining check-style issue is for adding an 8th parameter to writeLaunchEnv().

[~jlowe], please review.

 

 , Thanks for updating the patch!  Overall looks good, but I noticed that sanitizeWindowsEnv no longer adds CLASSPATH to the set of NM vars as it did in the previous patch.  Intentional?, {quote}I noticed that sanitizeWindowsEnv no longer adds CLASSPATH to the set of NM vars as it did in the previous patch. Intentional?
{quote}
Yes.  That was intentional.  I don't think it should be adding it.   sanitizeWindowsEnv only adds to an existing CLASSPATH to make it work in the Windows Env.  It seems to me like the CLASSPATH belongs with the user variables, after the NM variables.

I think this becomes more important when we address YARN-5714 - if we preserve the order of the ContainerLaunchContext (user) variables, I don't think we'd want to pull the CLASSPATH out and define it with the NM variables, potentially reordering it with respect to other user variables.  That said, there is currently no guarantee about the relative ordering of user-defined variables., [~jlowe], do you agree about the CLASSPATH for windows?  Let me know if you want me to add it back.

 , That makes sense.  Agreed it is probably safer to leave the CLASSPATH in the batch of user vars.

 +1 for the latest patch.  I'll commit this later today if there are no objections., Thanks, [~Jim_Brennan]!  I committed this to trunk and branch-3.1., SUCCESS: Integrated in Jenkins build Hadoop-trunk-Commit #13667 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/13667/])
YARN-7677. Docker image cannot set HADOOP_CONF_DIR. Contributed by Jim (jlowe: rev 8013475d447a8377b5aed858208bf8b91dd32366)
* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/util/AuxiliaryServiceHelper.java
* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/ContainerExecutor.java
* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/runtime/ContainerRuntime.java
* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/util/Apps.java
* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/linux/runtime/DelegatingLinuxContainerRuntime.java
* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/launcher/ContainerLaunch.java
* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/linux/runtime/DefaultLinuxContainerRuntime.java
* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/launcher/TestContainerLaunch.java
* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/LinuxContainerExecutor.java
* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/linux/runtime/DockerLinuxContainerRuntime.java
, This patch causing MR job launch failure! See MAPREDUCE-7055 cc :/ [~jlowe] [~shanekumpf@gmail.com], Thanks [~rohithsharma] for reporting this issue. 

This is reproducible and resolved after revert of YARN-7677. 

I found launch_container.sh includes following entry:

{code}
export CLASSPATH="$PWD:$HADOOP_CONF_DIR:$HADOOP_COMMON_HOME/share/hadoop/common/*:$HADOOP_COMMON_HOME/share/hadoop/common/lib/*:$HADOOP_HDFS_HOME/share/hadoop/hdfs/*:$HADOOP_HDFS_HOME/share/hadoop/hdfs/lib/*:$HADOOP_YARN_HOME/share/hadoop/yarn/*:$HADOOP_YARN_HOME/share/hadoop/yarn/lib/*:$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/*:$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/lib/*:job.jar/*:job.jar/classes/:job.jar/lib/*:$PWD/*"
export APP_SUBMIT_TIME_ENV="1519011470691"
export LD_LIBRARY_PATH="$PWD:$HADOOP_COMMON_HOME/lib/native"
export HADOOP_MAPRED_HOME=""/Users/wtan/project/github/hadoop-common-trunk/hadoop-dist/target/hadoop-3.2.0-SNAPSHOT/""
{code} 

I think {{HADOOP_MAPRED_HOME}} should occur before {{CLASSPATH}}.

cc: [~Jim_Brennan]/[~jlowe]/[~ebadger], bq. I think {{HADOOP_MAPRED_HOME}} should occur before {{CLASSPATH}}.
You are right, I compared both working vs not-working launch_container.sh file. In working script, HADOOP_MAPRED_HOME is exported before CLASSPATH and not-working script HADOOP_MAPRED_HOME is exported after CLASSPATH!
, SUCCESS: Integrated in Jenkins build Hadoop-trunk-Commit #13681 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/13681/])
Revert "YARN-7677. Docker image cannot set HADOOP_CONF_DIR. Contributed (jlowe: rev b9a429bb2854910add8d4cf787e6ee65ebdfc9cf)
* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/launcher/ContainerLaunch.java
* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/linux/runtime/DockerLinuxContainerRuntime.java
* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/linux/runtime/DelegatingLinuxContainerRuntime.java
* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/launcher/TestContainerLaunch.java
* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/ContainerExecutor.java
* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/util/Apps.java
* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/runtime/ContainerRuntime.java
* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/util/AuxiliaryServiceHelper.java
* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/linux/runtime/DefaultLinuxContainerRuntime.java
* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/LinuxContainerExecutor.java
, I reverted this from trunk and branch-3.1.  While the breakage is definitely triggered by this JIRA, I actually think the root cause is the same problem described in YARN-5714.

The only explicit ordering change done by this JIRA is to place inherited NM whitelisted variables before variables in the container launch context.  Looking at Rohith's configs, neither CLASSPATH nor HADOOP_MAPRED_HOME are in the NM whitelist variables.  Therefore I think this JIRA ended up inadvertently changing the iteration order of the user environment hashmap due to fewer variables being stored in that hashmap than before.

We're going to have to wait until YARN-5714 is fixed before this can go in., Agreed. Without this patch, the ordering of variables in the launch_container.sh script is random - it is just iterating a hashmap, so there is no guarantee of the order for any of the variables.

With this patch, the following order is imposed:
 # Whitelisted variables not overridden by user, in the order they are listed in NM_ENV_WHITELIST
 # Variables set explicitly by the NM, in the order they are written in code.
 # User-defined variables, with no ordering guarantee.

[~rohithsharma], it looks like you are running into the last category, where CLASSPATH and HADOOP_MAPRED_HOME are both user-defined.   As [~jlowe] said, it looks like we will have to address YARN-5714 so that we can guarantee the order of the user-defined variables before we can put this patch in.

Thanks for reporting the problem - and thanks [~jlowe] for reverting this one., Now that YARN-5714 has been resolved, we have two options for resolving this Jira. Environment variables now go through a dependency sort before being written to the launch_container.sh script. So we need to decide whether we want to retain the ordering of the 3 categories of environment variables from the last patch for this Jira, or just do the minimal changes to address the original issue- allowing (docker) container images to override the whitelisted variables.

So the two options are:

Minimal changes:
 * Remove the explicit setting of HADOOP_CONF_DIR, and treat it like other whitelisted variables.
 * Whitelisted variables not overridden by the user are written first, in the order they are listed in the NM_ENV_WHITELIST, using the {{var:-default}} variable expansion syntax
 * All other variables are then written in dependency sorted order.

Category sorted order:
 * Remove the explicit setting of HADOOP_CONF_DIR, and treat it like other whitelisted variables.
 * Whitelisted variables not overridden by the user are written first, in the order they are listed in the NM_ENV_WHITELIST, using the {{var:-default}} variable expansion syntax.
 * Then write variables set explicitly by the NM, in the order they are written in code.
 * Finally, write user-defined variables in dependency sorted order.

The main difference is that the second approach ensures all of the explicitly set NM variables are always written before all user variables, in a consistent order.   I do like seeing that consistency when looking at the scripts, but I'm not sure it's required, just nice.

[~jlowe], [~ebadger], [~shanekumpf@gmail.com], [~billie.rinaldi], please let me know if you have a preference., [~Jim_Brennan] What variables are set explicitly by NM?
, {quote}What variables are set explicitly by NM?{quote}

Primarily those set in ContainerLaunch.sanitizeEnv():  CONTAINER_ID, NM_PORT, NM_HOST, etc...
, Can user override NM_HOST, NM_PORT etc?  I think it would be safer when those variables can not be overwritten.  If this is true, category sorted order is preferred implementation from security point of view., [~eyang] the user cannot override the variables that are explicitly set by NM (NM_HOST, NM_PORT, etc...).  The NM explicitly sets these variables, overwriting any value the user may have set.

That said, I am leaning towards the category order as well.  I will put up a patch using the category ordering (basically the same as the previous patch for this Jira, but updated to integrate with YARN-5714

Thanks!

 , This patch implements the category sorting method, which ensures all NM variables come before user variables.

 , | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 28s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 11s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 15m 52s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  7m 35s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 56s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 18s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 11m 45s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m  8s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m  5s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 12s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m  7s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  6m 40s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  6m 40s{color} | {color:green} the patch passed {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 58s{color} | {color:orange} hadoop-yarn-project/hadoop-yarn: The patch generated 3 new + 162 unchanged - 3 fixed = 165 total (was 165) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 18s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 10m 23s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 25s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 13s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  3m 18s{color} | {color:green} hadoop-yarn-common in the patch passed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 19m 46s{color} | {color:red} hadoop-yarn-server-nodemanager in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 34s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 88m 44s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.yarn.server.nodemanager.containermanager.scheduler.TestContainerSchedulerQueuing |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:5b98639 |
| JIRA Issue | YARN-7677 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12912455/YARN-7677.006.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |
| uname | Linux 6b75711dfa11 4.4.0-64-generic #85-Ubuntu SMP Mon Feb 20 11:50:30 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / f20e10b |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_151 |
| findbugs | v3.1.0-RC1 |
| checkstyle | https://builds.apache.org/job/PreCommit-YARN-Build/19837/artifact/out/diff-checkstyle-hadoop-yarn-project_hadoop-yarn.txt |
| unit | https://builds.apache.org/job/PreCommit-YARN-Build/19837/artifact/out/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-nodemanager.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-YARN-Build/19837/testReport/ |
| Max. process+thread count | 407 (vs. ulimit of 10000) |
| modules | C: hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager U: hadoop-yarn-project/hadoop-yarn |
| Console output | https://builds.apache.org/job/PreCommit-YARN-Build/19837/console |
| Powered by | Apache Yetus 0.8.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

, Uploaded another patch that fixes the extra import reported by checkstyle.  As noted for previous patches, I am not going to fix the too many arguments checkstyle issues, as adding an argument to writeLaunchEnv and sanitizeEnv is appropriate for this change.

The unit test failure for TestContainerSchedulerQueuing is a separate issue: [YARN-7700]

 , | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 27s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 10s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 16m  3s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  7m 41s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 51s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 14s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 10m 49s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m  1s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m  3s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m  9s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m  8s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  6m 35s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  6m 35s{color} | {color:green} the patch passed {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 51s{color} | {color:orange} hadoop-yarn-project/hadoop-yarn: The patch generated 2 new + 162 unchanged - 3 fixed = 164 total (was 165) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 12s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green}  9m 42s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 25s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 11s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  3m 16s{color} | {color:green} hadoop-yarn-common in the patch passed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 19m 36s{color} | {color:red} hadoop-yarn-server-nodemanager in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 30s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 86m 33s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.yarn.server.nodemanager.containermanager.scheduler.TestContainerSchedulerQueuing |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:5b98639 |
| JIRA Issue | YARN-7677 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12912487/YARN-7677.007.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |
| uname | Linux b4c2640bb3b4 4.4.0-64-generic #85-Ubuntu SMP Mon Feb 20 11:50:30 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 3100903 |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_151 |
| findbugs | v3.1.0-RC1 |
| checkstyle | https://builds.apache.org/job/PreCommit-YARN-Build/19840/artifact/out/diff-checkstyle-hadoop-yarn-project_hadoop-yarn.txt |
| unit | https://builds.apache.org/job/PreCommit-YARN-Build/19840/artifact/out/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-nodemanager.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-YARN-Build/19840/testReport/ |
| Max. process+thread count | 440 (vs. ulimit of 10000) |
| modules | C: hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager U: hadoop-yarn-project/hadoop-yarn |
| Console output | https://builds.apache.org/job/PreCommit-YARN-Build/19840/console |
| Powered by | Apache Yetus 0.8.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

, Check-style issues are expected, as noted above. 

Unit test failure is tracked by YARN-7700

[~jlowe], this is ready for review., Thanks for updating the patch!

+1 lgtm.  I'll commit this tomorrow if there are no objections., +1 works on my system., +1 (non-binding) from me as well. I ran my usual suite of tests with and without Docker and did not see any issues. Thanks for driving this [~Jim_Brennan]!, Thanks to [~Jim_Brennan] for the contribution and to [~eyang] and [~shanekumpf@gmail.com] for additional review!  I committed this to trunk and branch-3.1., SUCCESS: Integrated in Jenkins build Hadoop-trunk-Commit #13786 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/13786/])
YARN-7677. Docker image cannot set HADOOP_CONF_DIR. Contributed by Jim (jlowe: rev d69b31f7f70f296ddd180e004fa0f827c2f737f2)
* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/util/Apps.java
* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/linux/runtime/DelegatingLinuxContainerRuntime.java
* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/ContainerExecutor.java
* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/util/AuxiliaryServiceHelper.java
* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/LinuxContainerExecutor.java
* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/linux/runtime/DefaultLinuxContainerRuntime.java
* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/linux/runtime/DockerLinuxContainerRuntime.java
* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/launcher/ContainerLaunch.java
* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/runtime/ContainerRuntime.java
* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/launcher/TestContainerLaunch.java
]