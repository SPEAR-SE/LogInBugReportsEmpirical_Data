[There are severals reasons why that could happen.  [~yufeigu], any suggestions?, Seems like an deadlock or an infinity loop in RM. Please check YARN-4477., [~yufeigu] [~templedf] Big thanks for you reply.
I noticed that the  the bug mentioned at [YARN-4477|https://issues.apache.org/jira/browse/YARN-4477]  is just for hadoop 2.8.0 or higher, but my hadoop version is 2.7.2. I have already checked my 2.7.2 source code , there didn't exists the method *reservationExceedsThreshold()* metioned there.
Would you please give me more suggestions?, [~yufeigu] [~templedf] I have attatched my ResourceManager log during the time problem occurs., Below is some explanation  about the log:

Before 2017-11-11 09:04, everything seems OK , application submitted and become runnings state.

At about 2017-11-11 09:04:47, no more applications become RUNNING , all the new-comming applications keep in pending state, and the already-running applications seem never finished.

At about 2017-11-11 13:58, namely about 5 hours after when problem occurs , I killed some applications，and yarn seems alive again. You can see that many pending applications' state become running , everything seems OK.

During the problem , Yarn's cluster resource usage is about half of the total YARN cluster resources and keeped unchanged , abosolutely unchanged, it seems static and dead., [~yufeigu] [~templedf]

From the ResourceManager log，I see:
At 09:04 when the problem start to occur , all NodeManagers in my yarn cluster has just been reserved ,below is the result of grepping the *Making reservation* from the log:

{code:java}
2017-11-11 09:00:30,343 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Making reservation: node=10.120.117.106 app_id=application_1507795051888_183354
2017-11-11 09:00:30,346 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Making reservation: node=10.120.117.105 app_id=application_1507795051888_183354
2017-11-11 09:00:30,401 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Making reservation: node=10.120.117.84 app_id=application_1507795051888_183354
2017-11-11 09:00:30,412 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Making reservation: node=10.120.117.85 app_id=application_1507795051888_183354
2017-11-11 09:00:30,535 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Making reservation: node=10.120.117.102 app_id=application_1507795051888_183354
2017-11-11 09:00:30,687 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Making reservation: node=10.120.117.86 app_id=application_1507795051888_183354
2017-11-11 09:00:30,824 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Making reservation: node=10.120.117.108 app_id=application_1507795051888_183354
2017-11-11 09:00:30,865 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Making reservation: node=10.120.117.104 app_id=application_1507795051888_183354
2017-11-11 09:00:30,991 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Making reservation: node=10.120.117.103 app_id=application_1507795051888_183354
2017-11-11 09:00:31,232 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Making reservation: node=10.120.117.107 app_id=application_1507795051888_183354
2017-11-11 09:00:31,249 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Making reservation: node=10.120.117.101 app_id=application_1507795051888_183354
2017-11-11 09:00:34,547 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Making reservation: node=10.120.117.100 app_id=application_1507795051888_183358
2017-11-11 09:01:06,277 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Making reservation: node=10.120.117.100 app_id=application_1507795051888_183342
2017-11-11 09:01:16,525 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Making reservation: node=10.120.117.100 app_id=application_1507795051888_183342
2017-11-11 09:01:25,348 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Making reservation: node=10.120.117.100 app_id=application_1507795051888_183342
2017-11-11 09:01:28,351 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Making reservation: node=10.120.117.100 app_id=application_1507795051888_183342
2017-11-11 09:02:29,658 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Making reservation: node=10.120.117.100 app_id=application_1507795051888_183342
2017-11-11 09:04:14,788 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Making reservation: node=10.120.117.100 app_id=application_1507795051888_183376
2017-11-11 09:04:26,307 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Making reservation: node=10.120.117.100 app_id=application_1507795051888_183380
2017-11-11 09:04:51,200 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Making reservation: node=10.120.117.100 app_id=application_1507795051888_183383
{code}

So, I guess if it is caused by a reservation deadlock , which means ,  all nodes has been reserved , these reserved containers cannot be turned to allocated , and new-coming application cannot make reservation anymore so they are all pending, thus , my yarn cluster become dead.
, Finally I get the reason.
A submitted application's container has make reservations on all NodeManagers , which make all NodeManagers become unavailable.

I think I have configured the *yarn.scheduler.maximum-allocation-mb* far too big (about half of *yarn.nodemanager.resource.memory-mb*) so that it is possible that a bad-configured application's containers will make reservation on all nodes and can never switched to allocated ,namely result in a deadlock.]