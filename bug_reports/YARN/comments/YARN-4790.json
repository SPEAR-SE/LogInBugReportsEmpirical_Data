[I agree with the problem statement but not necessarily the proposal. Please edit the title so that it highlights the problem only so that we can figure out whatever the solution is.

What we need is to *not* penalize applications for system related issues. When YARN finds a node with configuration / permission issues, it should itself take an action to (a) avoid scheduling on that node, (b) alert administrators etc.

Implementing heuristics for app / user level blacklisting to work-around platform problems should be a last-ditch effort. We did that in Hadoop 1 MapReduce as we didn't have clear demarcation between app vs system failures. But that isn't the case with YARN - part of the reason why we never implemented heuristics based per-app blacklisting *in YARN* - we left that completely up to applications., bq. when enabling LinuxContainerExecutor, but some node doesn't have such user exists
As for the root-cause reported on this JIRA, this invalidates our fundamental assumptions of LinuxContainerExecutor. We assume that user-accounts corresponding to all job-submitters are present on all the machines. If not it is a gross misconfiguration of the system, and should be handled by lower layers like installers / management systems.

If it is really deemed that we should support different user-accounts on different hosts (for whatever reason), then the right way to look at solving that problem is by recognizing user-accounts as a resource on each host - kind of like node-constraints. Blacklisting that node for an app is absolutely the wrong way to go about it.]