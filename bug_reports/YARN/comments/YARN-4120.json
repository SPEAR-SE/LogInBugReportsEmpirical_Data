[Good catch, [~xinxianyin]. 

I believe the reason we are subtracting preempted resources is so we don't preempt more resources from the same queue. We might have to track that information separately. [~asuresh], [~ashwinshankar77] - thoughts? , Thanks [~kasha]. How about distinguishing getResourceUsage() (the current gross resource usage) and getNetResourceUsage() (the current gross resource usage minus preempted)? The latter are used for preemption related calculations and the former for others?, [~kasha@cloudera.com], tracking usage and (usage - preemption) information separately makes sense to me., Hi [~kasha], there's another issue in the current preemption logic, it's in {{FSParentQueue.java}} and {{FSLeafQueue.java}},
{code}
  public RMContainer preemptContainer() {
    RMContainer toBePreempted = null;

    // Find the childQueue which is most over fair share
    FSQueue candidateQueue = null;
    Comparator<Schedulable> comparator = policy.getComparator();

    readLock.lock();
    try {
      for (FSQueue queue : childQueues) {
        if (candidateQueue == null ||
            comparator.compare(queue, candidateQueue) > 0) {
          candidateQueue = queue;
        }
      }
    } finally {
      readLock.unlock();
    }

    // Let the selected queue choose which of its container to preempt
    if (candidateQueue != null) {
      toBePreempted = candidateQueue.preemptContainer();
    }
    return toBePreempted;
  }
{code}
{code}
  public RMContainer preemptContainer() {
    RMContainer toBePreempted = null;

    // If this queue is not over its fair share, reject
    if (!preemptContainerPreCheck()) {
      return toBePreempted;
    }
{code}
If the queue's hierarchy like that in the *Description*, suppose queue1 and queue2 have the same weight, and the cluster has 8 containers, 4 occupied by queue1.1 and 4 occupied by queue2. If new app was added in queue1.2, 2 containers should be preempted from queue1.1. However, according the above code, queue1 and queue2 are both at their fairshare, so the preemption will not happen.

So if all of the childqueues at any level are at their fairshare, preemption will not happen even though there is/are resource deficit in some leafqueues.

I think we have to drop this logic in this case. As a candidate, we can calculates an ideal preemption distribution by traversing the queues. Any thoughts?, That is also a valid concern. Can we track it in a separate JIRA? 

The preemption logic definitely needs revisiting. YARN-2154 is a starting point. [~asuresh] and I have been considering significant logic changes to better accommodate both preemption and future features like node-labeling, but haven't found the time to write it up and post here. 

, Create YARN-4134 to track it., Link to YARN-4134, the two can be solved together., Currently, pre-emption happens in two passes:

1) Iterate through the leaf Queues, find resource deficits (sum of resources to be preempted to from other apps to allow apps below share to run)
2) iterate through Schedulables and pre-empt enough containers to match the resource collected in 1.

One goal of YARN-2154 (when its ready) is to try to address the issue brought up here, wherein, instead of asking a root queue to find Schedulables within its hierarchy that can pre-empt containers, it tries to match an actual resource ask (by an app below fair share) with containers from apps (above fair share).

I believe the above logic might solve both issues raised here.. thoughts ?, hi [~asuresh], thanks for your comment. I've go through YARN-2154, i believe it is a nice solution for the problems of current preemption logic. But i think the current patch of YARN-2154 could not solve the issue raised in this jira (please correct me if i wrongly understood YARN-2154.). We should distinguish {{usage}} and {{usage - preemption}} in {{getResourceUsgae}}, because {{getResourceUsage}} is used both by the preemption logic and the resource allocation logic. Of course we can consider this in the new implemention in YARN-2154 and solve them together., Hi [~kasha], [~asuresh], [~ashwinshankar77], now both the preemption logic and resource allocation logic uses {{comparator}} to sort the {{Schedulables}}. I think we have to introduce a different comparator to separate {{usage}} and {{usage - preemption}}, just as the patch in YARN-4134. There're also some discussion on changing {{Comparator.compare()}} in YARN-3453. I think for a collection of comparables, we can use different comparators to compare different attributes for different purpose. Any thoughts?, [~xinxianyin] - splitting out getResourceUsage and getNetResourceUsage makes sense, but can we wait until YARN-4752 is done? ]