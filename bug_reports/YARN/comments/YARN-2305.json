[Are you using fair scheduler? If yes, then I thinks it's the same reason of YARN-2306., Iam using Capacity Scheduler, No. Its a capacity scheduler. I could collect logs from Andreina for same. I will take over and analyze for Capacity Scheduler.

{noformat}
2014-07-15 16:56:50,720 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1405414066690_0023_01_000129 Container Transitioned from NEW to RESERVED
2014-07-15 16:56:50,720 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Reserved container  application attempt=appattempt_1405414066690_0023_000001 resource=<memory:2048, vCores:1> queue=a: capacity=0.5, absoluteCapacity=0.5, usedResources=<memory:7168, vCores:4>, usedCapacity=0.875, absoluteUsedCapacity=0.4375, numApps=1, numContainers=4 node=host: host-10-18-40-14:45026 #containers=4 available=1024 used=7168 clusterResource=<memory:16384, vCores:16>
2014-07-15 16:56:50,720 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.a stats: a: capacity=0.5, absoluteCapacity=0.5, usedResources=<memory:9216, vCores:5>, usedCapacity=1.125, absoluteUsedCapacity=0.5625, numApps=1, numContainers=5
2014-07-15 16:56:50,720 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=1.0625 absoluteUsedCapacity=1.0625 used=<memory:17408, vCores:10> cluster=<memory:16384, vCores:16>
{noformat}, Hi [~zhiguohong], Could I take over the issue.., OK, Hi [~sunilg],
Thanks for taking this issue,
I think there're two issues in your screenshot,
1) Root queue usage above 100%
It is possible that queue used resource is larger than its guaranteed resource because of container reservation. We may need show reserved resource and used resource separately in our web UI. I encountered a similar problem in YARN-2285 too.

2) Total cluster memory showing on web UI is different from CapacityScheduler.clusterResource
This seems a new issue to me, memory showing on web UI is usedMemory+availableMemory of root queue. I feel like CSQueueUtils.updateQueueStatistics has some issues when we reserve container in LeafQueue. Hope to get more thoughts in your side.

Thanks,
Wangda, 1. Yes [~leftnoteasy], GUI display of 106% is similar to YARN-2285. It can be tackled there.
2. 

As mentioned in earlier comment, Total MB in GUI is internally sum of availableMB+allottedMB.

a. *LeafQueue#usedResources* is sum of used and reserved memory.  
But *CSQueueUtils#updateQueueStatistics()* code may give a -ve value in case of reservation which sets availableMB in QueueMetrics.
{code}
Resource available = Resources.subtract(queueLimit, usedResources);
{code}

If this comes as -ve, then *availableMB* is set as 0.

b. *allocatedMB*: This is set when a container is really allocated. This is the real queue usage.

In above scenario, it should have come as 
{noformat}15(availableMb)+1(allocatedMB)=16{noformat}
But due to reservation, allocatedMB became 0. Hence total shown as 15.
I feel instead of showing Total as *allocated+available*, we can show *clusterResource* here. Any particular reason why we need like allocated+available, thoughts?
, Thanks for your elaboration,
I understand now, I think this is inconsistency between ParentQueue and LeafQueue, using clusterResource instead of allocated+available can definitely solve this problem., This JIRA should be resolved already, now CSQueueUtils uses QueueResourceUsage instead of QueueMetrics, it is updated for every container allocation/resource update., Yes. This is can be closed. I have checked, and it was not occurring. Still i will perform few more tests, and if persists, I will reopen.

Thank you [~leftnoteasy], Updated the duplicated id link.]