[NodeManager and ApplicationMaster logs attached , Some useful log observation from NodeManager

2013-07-07 13:39:40,158 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1373184544832_0001_01_000002
2013-07-07 13:39:40,683 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Getting container-status for container_1373184544832_0001_01_000002 

Seems like after container is removed/dis-owned from NodeManager, ContainerManagerImpl tries to fetch the status for the same. Hence resulting in exception.  , On further investigation it was found out the container is successfully completed with EXITED_WITH_SUCCESS to DONE and is being removed.
There is no harm because application executed successfully. But the exception can be mis-leading. , yes looks like the exception is misleading... at this point of time because we don't remember past running containers on node manager whenever we get stopContainer request if we don't find that container to be running we log an exception. Also we on node manager side don't know whether the call came from resource manager or from application master to stop container.
 
when an application finishes; normal containers as well as container in which AM was running exits successfully on node manager side. Before exiting, AM informs resource manager that the application finished successfully which in turn tries to stop all the containers running on different node managers. Now on node manager side after successful authentication / authorization it tries to check whether that container is still running or not. if it is not running then as we are not storing past running containers on node manager node manager logs this as an invalid attempt to stop unknown container on node manager. We are logging (in nm.logs + in NMAuditLogs) this exception for security reasons.

After YARN-62 goes in we will be in a state to remember past running containers for some time on node manager. This way we will be in a position to ignore these logically valid attempts for that duration.
 
any thoughts?, planning to fix this.. I am planning to remember completed containers (only id) at node manager for predefined time (10min). Does that time sounds reasonable or we should make it configurable? ... I don't really think adding a new configuration parameter will be a good idea but I am open for any different approach / adding conf .. thoughts? This will have a similar implementation like YARN-62 but only difference is that YARN-62 only tracks container for a time after it starts to avoid duplicate launch..where as this tries to avoid logging errors for valid stop attempts..., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12592903/YARN-903-20130717.1.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-YARN-Build/1513//testReport/
Console output: https://builds.apache.org/job/PreCommit-YARN-Build/1513//console

This message is automatically generated., Attaching a simple test to verify this., {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12593065/YARN-903-20130718.1.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-tests.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-YARN-Build/1522//testReport/
Console output: https://builds.apache.org/job/PreCommit-YARN-Build/1522//console

This message is automatically generated., Few comments on the patch
 - The logic in ContainerManager can be made more readable:
{code}
if (container == null) {
  if (!recentlyStopped) {
    throw Exception()
  }
} else {
  // stop the container
}
{code}
 - Use the same recentlyStopped information to throw different exceptions in getContainerStatus() ?
 - Add recently-stopped containers to NMContext?
 - Please do add an undocumented config for the 10 minutes cache. It may be useful IF we run into issues like NM memory pressure.
 - TestContainerManagerSecurity.stopContainer() doesn't actually do any stop-container in your patch.
 - Also validate that once the 10 mins time elapses, we will get exceptions again. The undocumented config can be used for this. Or may be by directly removing the container from recentlyStopped list., Thanks [~vinodkv] for reviewing...

bq. The logic in ContainerManager can be made more readable:
Done..

bq. Add recently-stopped containers to NMContext?
I don't see any point why anyone other than NodeStatusUpdaterImpl will need this.

bq. Please do add an undocumented config for the 10 minutes cache. It may be useful IF we run into issues like NM memory pressure.
added.(yarn.nodemanager.duration-to-track-stopped-containers)

bq. TestContainerManagerSecurity.stopContainer() doesn't actually do any stop-container in your patch.
fixed.

bq. Also validate that once the 10 mins time elapses, we will get exceptions again. The undocumented config can be used for this. Or may be by directly removing the container from recentlyStopped list.
Waiting that long will not be good... added clear cache method for it. calling it from test code.
{code}
  @VisibleForTesting
  @Private
  public void clearTrackedFinishedContainersFromCache() {
    ((NodeStatusUpdaterImpl) nodeStatusUpdater)
      .clearTrackedFinishedContainersFromCache();
  }
{code}

uploading updated patch.., {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12593798/YARN-903-20130723.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-tests.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-YARN-Build/1555//testReport/
Console output: https://builds.apache.org/job/PreCommit-YARN-Build/1555//console

This message is automatically generated., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12593798/YARN-903-20130723.patch
  against trunk revision .

    {color:red}-1 patch{color}.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-YARN-Build/1568//console

This message is automatically generated., Cancelling patch, needs update against latest trunk., Updated patch for latest trunk.., {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12594787/YARN-903-20130729.1.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-tests.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-YARN-Build/1608//testReport/
Console output: https://builds.apache.org/job/PreCommit-YARN-Build/1608//console

This message is automatically generated., bq. Add recently-stopped containers to NMContext?
bq. I don't see any point why anyone other than NodeStatusUpdaterImpl will need this.
Not as of now, but potentially in future. I was okay with this but the ugly object casting in the latest patch tells me putting in the NMContext is the right approach.

bq. added.(yarn.nodemanager.duration-to-track-stopped-containers)
Can you define a constant inside NodeStatusUpdaterImpl and then also use YARN_NODEMANAGER_PREFIX etc.

Other comments on the patch:

ContainerManagerImpl
 - Move isContainerRecentlyStopped() method call in stopContainerInternal into the null container conditional just like you did in getContainerStatusInternal().

NodeStatusUpdaterImpl:
 - Move the log "Initialized nodemanager for" to the end of the serviceInit method.
 - removeVeryOldStoppedContainersFromTracker() method is super expensive. We can't look at 10 mins worth of stopped containers in every heartbeat., bq. Not as of now, but potentially in future. I was okay with this but the ugly object casting in the latest patch tells me putting in the NMContext is the right approach.
yeah ..I was thinking not to add it NodeStatusUpdater. Added now. Still can't see why NMContext will need it.. keeping it in NodeStatusUpdater.

bq. Can you define a constant inside NodeStatusUpdaterImpl and then also use YARN_NODEMANAGER_PREFIX etc.
yes fixed it..

bq. Move isContainerRecentlyStopped() method call in stopContainerInternal into the null container conditional just like you did in getContainerStatusInternal().
yeah fixed it

bq. Move the log "Initialized nodemanager for" to the end of the serviceInit method.
fixed

bq. removeVeryOldStoppedContainersFromTracker() method is super expensive. We can't look at 10 mins worth of stopped containers in every heartbeat.
It is called only when container stops on node manager i.e. it is removed from containers map. Forgot to add break; added now. Also "recentlyStoppedContainersTracker" is holding (containerId, timestamp) with timestamp in sorted order., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12595109/YARN-903-20130730.1.patch
  against trunk revision .

    {color:red}-1 patch{color}.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-YARN-Build/1620//console

This message is automatically generated., NMContext is all about shared state. You are sharing state between ContainerManager and NodeStatusUpdater. We don't keep any shared state outside NMContext. You still having more casting in NodeManager. If you go this route, you will have to add clearTrackedFinishedContainersFromCache() to NodeStatusUpdater. Seems completely odd to have such a method on NodeStatusUpdater. I still prefer NMContext.

bq. It is called only when container stops on node manager i.e. it is removed from containers map. Forgot to add break; added now. Also "recentlyStoppedContainersTracker" is holding (containerId, timestamp) with timestamp in sorted order.
Yes, the missing break is the main bug. We should add a very simple unit test that validates this addition and expiry. Only at NodeStatusUpdater unit level is fine enough., bq. NMContext is all about shared state. You are sharing state between ContainerManager and NodeStatusUpdater. We don't keep any shared state outside NMContext. You still having more casting in NodeManager. If you go this route, you will have to add clearTrackedFinishedContainersFromCache() to NodeStatusUpdater. Seems completely odd to have such a method on NodeStatusUpdater. I still prefer NMContext

Yes added method clearTrackedFinishedContainersFromCache() to NodeStatusUpdater.

bq. Yes, the missing break is the main bug. We should add a very simple unit test that validates this addition and expiry. Only at NodeStatusUpdater unit level is fine enough.
yes adding one.., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12595291/YARN-903-20130731.1.patch
  against trunk revision .

    {color:red}-1 patch{color}.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-YARN-Build/1630//console

This message is automatically generated., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12595315/YARN-903-20130731.2.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 2 new or modified test files.

    {color:red}-1 javac{color:red}.  The patch appears to cause the build to fail.

Console output: https://builds.apache.org/job/PreCommit-YARN-Build/1632//console

This message is automatically generated., Cancelling the patch for the javac issues.., fixed missing import., {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12595464/YARN-903-20130801.1.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 2 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-tests.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-YARN-Build/1640//testReport/
Console output: https://builds.apache.org/job/PreCommit-YARN-Build/1640//console

This message is automatically generated., +1, looks good. Checking it in., Committed this to trunk, branch-2 and branch-2.1. Thanks Omkar!, SUCCESS: Integrated in Hadoop-trunk-Commit #4205 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/4205/])
YARN-903. Changed ContainerManager to suppress unnecessary warnings when stopping already stopped containers. Contributed by Omkar Vinit Joshi. (vinodkv: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1509560)
* /hadoop/common/trunk/hadoop-yarn-project/CHANGES.txt
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/NodeManager.java
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/NodeStatusUpdater.java
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/NodeStatusUpdaterImpl.java
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/ContainerManagerImpl.java
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/TestNodeStatusUpdater.java
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-tests/src/test/java/org/apache/hadoop/yarn/server/TestContainerManagerSecurity.java
, SUCCESS: Integrated in Hadoop-Yarn-trunk #289 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/289/])
YARN-903. Changed ContainerManager to suppress unnecessary warnings when stopping already stopped containers. Contributed by Omkar Vinit Joshi. (vinodkv: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1509560)
* /hadoop/common/trunk/hadoop-yarn-project/CHANGES.txt
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/NodeManager.java
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/NodeStatusUpdater.java
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/NodeStatusUpdaterImpl.java
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/ContainerManagerImpl.java
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/TestNodeStatusUpdater.java
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-tests/src/test/java/org/apache/hadoop/yarn/server/TestContainerManagerSecurity.java
, FAILURE: Integrated in Hadoop-Hdfs-trunk #1479 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1479/])
YARN-903. Changed ContainerManager to suppress unnecessary warnings when stopping already stopped containers. Contributed by Omkar Vinit Joshi. (vinodkv: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1509560)
* /hadoop/common/trunk/hadoop-yarn-project/CHANGES.txt
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/NodeManager.java
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/NodeStatusUpdater.java
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/NodeStatusUpdaterImpl.java
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/ContainerManagerImpl.java
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/TestNodeStatusUpdater.java
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-tests/src/test/java/org/apache/hadoop/yarn/server/TestContainerManagerSecurity.java
, FAILURE: Integrated in Hadoop-Mapreduce-trunk #1506 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1506/])
YARN-903. Changed ContainerManager to suppress unnecessary warnings when stopping already stopped containers. Contributed by Omkar Vinit Joshi. (vinodkv: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1509560)
* /hadoop/common/trunk/hadoop-yarn-project/CHANGES.txt
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/NodeManager.java
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/NodeStatusUpdater.java
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/NodeStatusUpdaterImpl.java
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/ContainerManagerImpl.java
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/TestNodeStatusUpdater.java
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-tests/src/test/java/org/apache/hadoop/yarn/server/TestContainerManagerSecurity.java
]