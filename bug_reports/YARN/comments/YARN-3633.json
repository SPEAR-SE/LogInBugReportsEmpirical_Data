[So, in essence the problem is that when there are too many queues, the fair share of each queue gets low and thus the maxAMShare, which is calculated from the fairShare of each queue, gets too low to run any container.

I propose the following solution:
Instead of setting
{code}
maxAMShare = 0.5*fairShare
{code}
we set it to
{code}
maxAMShare = max(0.5*fairShare, SomeMinimumSizeEnoughToRunOneContainer)
{code}
And then add a cluster-wide maxAMShare to be {{0.5*totalClusterCapacity}}

All these ratios/values can be configurable.

So, in the scenario described in the JIRA, we would still run AMs in some queues but we won't overrun the cluster with AMs because it will hit the cluster-wide limit.

If this proposal sounds reasonable, I can start working on this.

However, I am not sure how this would interact with preemption., Thanks for reporting this, Rohit. 

Extrapolating the example, consider the applications' containers also need 3 GB. With the proposed change, the AMs would come up but will not be able to run any containers. Note that this is only an issue on a cluster where a single AM fills up the am-share; is this likely to happen on larger clusters and production deployments?

The scheduler could realize there aren't enough resources to run applications from multiple queues and run them in some order, but that would violate the fairness policies. , Can you elaborate the scenario where the AMs would come up but the containers would not? There is still a cluster-wide maxAMShare which is, let's say, 0.5 times the cluster-capacity.

A dry run of my proposed change:

Cluster Resource: 20GB
Applications submitted to 4 queues simultaneously - queue a, b, c, and d. Each application requests AMs of size 3GB and containers of size 3GB.
Fair share for each queue = 5GB.
maxAMShare is 0.5
Let's say {{SomeMinimumSizeEnoughToRunOneContainer}} is 3GB.


queue a will start AM1. (maxAMShare = max(0.5*5GB, 3GB) = 3GB). cluster-wide AMShare = 3GB < 0.5*20GB
queue b will start AM2. (maxAMShare = max(0.5*5GB, 3GB) = 3GB). cluster-wide AMShare = 6GB < 0.5*20GB
queue c will start AM3. (maxAMShare = max(0.5*5GB, 3GB) = 3GB). cluster-wide AMShare = 9GB < 0.5*20GB
FS will try to run AM4 on queue d. But now it would hit the cluster-wide maxAMShare limit. So, nothing will run there. Then, FS will try to run something on queue a (or b or c) - and so the application1 container would start.

This would repeat. FS will try to run AM4 on queue d. It would again hit the cluster-wide maxAMShare limit. It would then try to run something on queue b (or c) - and so application2 container would start.

And so on.

Finally one of app1, app2, app3 AM would finish. At which time FS should schedule AM4 on queue d.

I agree that queue d is not getting its fair share till one of app1, app2 and app3 complete (and that is why I am unsure how my proposed change would work when preemption is enabled.) But I think it is better than not scheduling anything?, Another thought is that we could say the max AM share only applies after first AM., [~sandyr] If we do that and have no cluster-wide AMShare then we may have a situation where all queues are just running AMs - imagine lots of apps submitted at the same time to different queues.

But yes we can use this 'max AM share applies after first AM' property instead of setting {{maxAMShare for queue = max(0.5*fairShare, SomeMinimumSizeEnoughToRunOneContainer)}}, Actually, I like the idea of not enforcing the queue maxAMShare till one AM is running. This in conjunction with a cluster-wide maxAMShare is easier to implement than what I originally proposed and doesn't introduce another new parameter., Added a patch. Please review., \\
\\
| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | pre-patch |  14m 52s | Pre-patch trunk compilation is healthy. |
| {color:green}+1{color} | @author |   0m  0s | The patch does not contain any @author tags. |
| {color:green}+1{color} | tests included |   0m  0s | The patch appears to include 1 new or modified test files. |
| {color:green}+1{color} | javac |   7m 34s | There were no new javac warning messages. |
| {color:green}+1{color} | javadoc |   9m 41s | There were no new javadoc warning messages. |
| {color:green}+1{color} | release audit |   0m 24s | The applied patch does not increase the total number of release audit warnings. |
| {color:red}-1{color} | checkstyle |   0m 51s | The applied patch generated  8 new checkstyle issues (total was 120, now 126). |
| {color:red}-1{color} | whitespace |   0m  1s | The patch has 1  line(s) that end in whitespace. Use git apply --whitespace=fix. |
| {color:green}+1{color} | install |   1m 34s | mvn install still works. |
| {color:green}+1{color} | eclipse:eclipse |   0m 33s | The patch built with eclipse:eclipse. |
| {color:red}-1{color} | findbugs |   1m 17s | The patch appears to introduce 1 new Findbugs (version 3.0.0) warnings. |
| {color:green}+1{color} | yarn tests |  50m  3s | Tests passed in hadoop-yarn-server-resourcemanager. |
| | |  86m 54s | |
\\
\\
|| Reason || Tests ||
| FindBugs | module:hadoop-yarn-server-resourcemanager |
|  |  Inconsistent synchronization of org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore.isHDFS; locked 66% of time  Unsynchronized access at FileSystemRMStateStore.java:66% of time  Unsynchronized access at FileSystemRMStateStore.java:[line 156] |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12733674/YARN-3633.patch |
| Optional Tests | javadoc javac unit findbugs checkstyle |
| git revision | trunk / 0790275 |
| checkstyle |  https://builds.apache.org/job/PreCommit-YARN-Build/7988/artifact/patchprocess/diffcheckstylehadoop-yarn-server-resourcemanager.txt |
| whitespace | https://builds.apache.org/job/PreCommit-YARN-Build/7988/artifact/patchprocess/whitespace.txt |
| Findbugs warnings | https://builds.apache.org/job/PreCommit-YARN-Build/7988/artifact/patchprocess/newPatchFindbugsWarningshadoop-yarn-server-resourcemanager.html |
| hadoop-yarn-server-resourcemanager test log | https://builds.apache.org/job/PreCommit-YARN-Build/7988/artifact/patchprocess/testrun_hadoop-yarn-server-resourcemanager.txt |
| Test Results | https://builds.apache.org/job/PreCommit-YARN-Build/7988/testReport/ |
| Java | 1.7.0_55 |
| uname | Linux asf907.gq1.ygridcore.net 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Console output | https://builds.apache.org/job/PreCommit-YARN-Build/7988/console |


This message was automatically generated., Thanks for the patch [~ragarwal],
Assuming we allow, as per the patch, the first AM to be scheduled, then, as per the example you specified in the description, the AM will take up 3GB in an 5GB queue... presuming each worker task requires more resources that the AM (I am guessing this should be true for most cases), then no other task can be scheduled on that queue. and remaining queues are anyway log-jammed since the maxAMshare logic would kick in.
Wondering if its a valid scenario..
, Other non-AM containers can be scheduled in the queue - unlike the maxAMShare limit, the fair share is not a hard limit. So, the FS will schedule non-AM containers in this queue when it cannot schedule AM containers in other queues.

I gave a walkthrough in this comment: https://issues.apache.org/jira/browse/YARN-3633?focusedCommentId=14542895&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14542895, \\
\\
| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | pre-patch |  15m 17s | Pre-patch trunk compilation is healthy. |
| {color:green}+1{color} | @author |   0m  0s | The patch does not contain any @author tags. |
| {color:green}+1{color} | tests included |   0m  0s | The patch appears to include 1 new or modified test files. |
| {color:green}+1{color} | javac |   7m 48s | There were no new javac warning messages. |
| {color:green}+1{color} | javadoc |   9m 51s | There were no new javadoc warning messages. |
| {color:green}+1{color} | release audit |   0m 22s | The applied patch does not increase the total number of release audit warnings. |
| {color:red}-1{color} | checkstyle |   0m 47s | The applied patch generated  2 new checkstyle issues (total was 120, now 120). |
| {color:green}+1{color} | whitespace |   0m  2s | The patch has no lines that end in whitespace. |
| {color:green}+1{color} | install |   1m 32s | mvn install still works. |
| {color:green}+1{color} | eclipse:eclipse |   0m 34s | The patch built with eclipse:eclipse. |
| {color:red}-1{color} | findbugs |   1m 19s | The patch appears to introduce 1 new Findbugs (version 3.0.0) warnings. |
| {color:green}+1{color} | yarn tests |  50m 40s | Tests passed in hadoop-yarn-server-resourcemanager. |
| | |  88m 17s | |
\\
\\
|| Reason || Tests ||
| FindBugs | module:hadoop-yarn-server-resourcemanager |
|  |  Inconsistent synchronization of org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore.isHDFS; locked 66% of time  Unsynchronized access at FileSystemRMStateStore.java:66% of time  Unsynchronized access at FileSystemRMStateStore.java:[line 156] |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12733912/YARN-3633-1.patch |
| Optional Tests | javadoc javac unit findbugs checkstyle |
| git revision | trunk / fd3cb53 |
| checkstyle |  https://builds.apache.org/job/PreCommit-YARN-Build/8005/artifact/patchprocess/diffcheckstylehadoop-yarn-server-resourcemanager.txt |
| Findbugs warnings | https://builds.apache.org/job/PreCommit-YARN-Build/8005/artifact/patchprocess/newPatchFindbugsWarningshadoop-yarn-server-resourcemanager.html |
| hadoop-yarn-server-resourcemanager test log | https://builds.apache.org/job/PreCommit-YARN-Build/8005/artifact/patchprocess/testrun_hadoop-yarn-server-resourcemanager.txt |
| Test Results | https://builds.apache.org/job/PreCommit-YARN-Build/8005/testReport/ |
| Java | 1.7.0_55 |
| uname | Linux asf903.gq1.ygridcore.net 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Console output | https://builds.apache.org/job/PreCommit-YARN-Build/8005/console |


This message was automatically generated., The remaining checkstyle and findbugs issues seem to be preexisting., [~ragarwal], Was just wondering.. wrt the scenario you mentioned in [here|https://issues.apache.org/jira/browse/YARN-3633?focusedCommentId=14542895&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14542895]. Isnt it possible that AM4 can remain unscheduled (starved) until AM1/AM2 or AM3 completes ? Basically containers started by AM1/2 and 3 might start and end, but until an application itself completes, AM4 will not be scheduled.. right ?, Yes, that is very much possible. But without this change - this scenario will result in none of the applications making any progress. I would take one application getting starved over the whole cluster getting starved any day. :-)

FWIW, we have been running our clusters with this patch for a month now and haven't seen any cluster logjam since., Agreed..
So just so that Im on the same page, the {{clusterMaxAMShare}} is essentially acting as an upper limit.. right ? Can we have the default as negative, to preserve current behavior by default ?

Otherwise, the patch looks good.. although I feel in the {{addAMResourceUsage}}, I think we should synchronize the part where we add the {{amResource}} to the scheduler's total am resource usage field.
+1 after that., Yes, the {{clusterMaxAMShare}} is acting as an upper limit.

To maintain the current behavior, we should keep the default {{clusterMaxAMShare}} as 0.5 only.
Right now, the default for {{queueMaxAMShare}} is 0.5, which results in an implicit {{clusterMaxAMShare}} of 0.5, this is because no queue allows more than 50% of its resources to be allocated to AMs and hence no more than 50% of the cluster resources can be allocated to AMs.
With this change, queueMaxAMShare only restricts AMs when there is already at least one AM running in the queue. So, {{clusterMaxAMShare}} is needed to avoid the cluster from getting overrun with AMs (YARN-1913).

We should set {{clusterMaxAMShare}} to negative, only in those cases where we would set {{queueMaxAMShare}} to negative - i.e. when we don't want to restrict AM usage.

----------------------------------------------

Regarding synchronization, I am wondering why the existing line in addAMResourceUsage not synchronized? Is this code called concurrently? Also, if I should synchronize, should I synchronize the method or just the line I added?, I guess the line that was introduced needs to be synchronized (guess we need to do the same for {{removeApp}} where we are subtracting).. given that you are adding/subtracting from "totalAmResourceUsage" defined in the {{FairScheduler}}.. and considering that the {{Resources#addTo/subtractFrom}} actually performs a get and set (and the value can change in between if some other AM is added/removed.. possibly during a concurrently running continuous scheduling attempt), | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m  0s{color} | {color:blue} Docker mode activated. {color} |
| {color:red}-1{color} | {color:red} patch {color} | {color:red}  0m  5s{color} | {color:red} YARN-3633 does not apply to trunk. Rebase required? Wrong Branch? See https://wiki.apache.org/hadoop/HowToContribute for help. {color} |
\\
\\
|| Subsystem || Report/Notes ||
| JIRA Issue | YARN-3633 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12733912/YARN-3633-1.patch |
| Console output | https://builds.apache.org/job/PreCommit-YARN-Build/14739/console |
| Powered by | Apache Yetus 0.5.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

]