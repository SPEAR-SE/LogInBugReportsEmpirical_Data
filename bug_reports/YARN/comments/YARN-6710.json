[Can you give us more details?  Looking at the screenshot, I see 3600 completed apps, which doesn't tell me much., [~daniel@cloudera.com] I am sorry, I am try to express myself. But my english is so poor, so it is very slow
for me to express myself., [~daemon], IIUC, the root cause is APP_ATTEMPT_REMOVED event doesn't unregister AM in time so that delay of AM resource usage decreasing blocks new applications. Is it? , [~yufeigu]  使用中文表述可能更清楚些， 这个问题导致的原因对于YARN端主要是由于
1. Application attempt运行完成之后，AM 向RM发送unregisterApplicationMaster RPC请求。RM在处理
这个消息时，做些简单的处理然后就向FairScheduler发送APP_ATTEMPT_REMOVED消息就返回了。 
而APP_ATTEMPT_REMOVED的处理是异步的，所以在FairScheduler中，对应的FSAppAttempt会过段时间
才会被remove掉。

这个问题会导致两个比较严重的后果发生：
1. 在这个时间间隔，FairScheduler还会给FSAppAttempt 分派Container。 并且会在分派Container的时候，如果
if (getLiveContainers().size() == 1 && !getUnmanagedAM()) 情况满足的话，会继续累加am resource的值到amResourceUsage，使得amResourceUsage的值比实际的值大很多。 在实际的情况中，可能会导致队列中的
作业一直pending，并且永远得不到资源， 这个就是我在上面描述的情况。  
对于amResourceUsage统计的值比实际大很多问题，社区已经有patch fix这个问题了。 具体可以查看这个jira：
https://issues.apache.org/jira/browse/YARN-3415。

2. 导致FairScheduler会给已经Finished的Application attempt分派Container， 虽然对应的Container，在NM汇报
心跳的时候，RM会给NM发送Response，让对应的NM cleanup它。 但是会造成资源的浪费。 并且目前调度速度那么快，
这种问题会更加明显。

虽然社区版本中已经解决了amResourceUsage的问题，但我觉得它只是解决了问题域中的一部分。 
上述的问题2也是急需要解决的问题。 虽然我看到YARN-3415对应的也解决了Spark框架中unreigster application attempt之前把对应的pending的申请资源申请都清空了。 
但是YARN作为一个通用的资源分派框架是需要Cover这些所有可能遇到的情况。对于一个通用的资源分派框架，我们不能限定用户的使用方式。
不能依赖用户每次unregister application master的时候，会在之前释放所有pending的request。

所以，我们需要在分派container之前就要做对应的判断，这个是急需解决的问题。麻烦yufei根据我所说的，再
评估下这个问题有没有需要解决。

谢谢，
, Thanks [~daemon] for the detailed information.

Basically you are saying the latency of handling APP_ATTEMPT_REMOVED cause some issues: 1) the amResourceUsage issue which has been fixed in YARN-3415, 2) RM shouldn't assign any container to the application if its appAttempt has finished and there are still resource requests. Issue 2 seems a legitimate issue. For me, it is more a design issue in AM(Mapreduce, Spark) instead of an RM issue. I am not sure how the scheduler check the status of application attempt for that situation. If the scheduler already know app attempt has finished, it shouldn't assign any resources to it at all. Better to check if that part is already here before we move on. ]