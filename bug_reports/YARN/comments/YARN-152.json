[This is also happens on 2.0.1-alpha, it seems related to the resource localization. In the DistributedShell example, the ContainerLaunchContext of AM has LocalResources which are the AppMaster.jar, but other task containers do not have this. And only the container with local resources will create the directory like /tmp/nm-local-dir/usercache/jiangbing/appcache/application_1325062142731_0006, so the non-AM containers will fail to use these directories., Then this is a bug in YARN.  It should create the appropriate directories even if no localization is going to happen. I moved this to YARN because of that. , This exception will not happen in a single node cluster, and only happens sometimes in a full distributed mode. 
In single node cluster, the AM container will create the directory first, so other containers will not have this issue. 
In full distributed mode, if your containers do not need many resources (determined by containers_number and container_memory parameter), YARN will allocate the task containers on the same node with AM container, so this will be the same situation as the single node cluster above., There must be a work around for this?, FWIW, running the job as the yarn user work for me.

To me it looks like there is some issue with user resolution. Note the directory after the usercache directory below.

CWD set to /var/lib/hadoop-yarn/cache/yarn/nm-local-dir/usercache/brock/appcache/application_1354339131583_0001 = file:/var/lib/hadoop-yarn/cache/yarn/nm-local-d

java.io.FileNotFoundException: File /var/lib/hadoop-yarn/cache/yarn/nm-local-dir/usercache/yarn/appcache/application_1354339131583_0001 does not exist

, I think this is the same as YARN-253., bq. I think this is the same as YARN-253.
Yes it is.]