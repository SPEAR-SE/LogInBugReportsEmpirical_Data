[The container's working directories are cleaned up by YARN immediately after the container terminates (unless the debug delay is configured on the NM).  The application directories are not cleaned up until the application completes, as that is where a container can leave local data that may be accessed by a subsequent container on the node or via an auxiliary service (e.g.: shuffle data served up by a shuffle handler auxiliary service as is done for MapReduce, Tez, and Spark).

Are you sure the data is being placed in the container's working directory and not the application directory?, Thanks for your answer [~jlowe]. As it is stated in the question on SO (https://stackoverflow.com/questions/46893123/how-can-i-make-spark-thrift-server-clean-up-its-cache) I think the application directory is used. I see why the data is not removed by YARN from you comment above, though. So I think we have to investigate why Spark is using the application directory in this case. Thanks., Closing this as invalid since YARN is deleting the container directory and leaving the application directory as designed.  This appears to be a problem with the application rather than a problem with YARN.]