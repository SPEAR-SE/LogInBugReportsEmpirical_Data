[After a 2 hours running SLS (with YARN-6363 synth generator), I got an NPE in handling NODE_UPDATE. 
[~asuresh] suspects this to be related to the processing of a NODE_UPDATE after the application is completed.
Below the stack trace for this:

2017-03-28 20:07:53,059 FATAL [SchedulerEventDispatcher:Event Processor] event.EventDispatcher (EventDispatcher.java:run(75)) - Error in handling event type NODE_UPDATE to the Event Dispatcher
java.lang.NullPointerException
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.UsersManager.computeUserLimit(UsersManager.java:732)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.UsersManager.reComputeUserLimits(UsersManager.java:611)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.UsersManager.getComputedResourceLimitForActiveUsers(UsersManager.java:463)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.getResourceLimitForActiveUsers(LeafQueue.java:1370)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.getHeadroom(LeafQueue.java:1243)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.getHeadroom(LeafQueue.java:1235)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityHeadroomProvider.getHeadroom(CapacityHeadroomProvider.java:57)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp.getHeadroom(FiCaSchedulerApp.java:757)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.releaseResource(LeafQueue.java:1618)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.completedContainer(LeafQueue.java:1528)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.completedContainerInternal(CapacityScheduler.java:1600)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler.completedContainer(AbstractYarnScheduler.java:602)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler.updateCompletedContainers(AbstractYarnScheduler.java:965)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler.nodeUpdate(AbstractYarnScheduler.java:1038)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.nodeUpdate(CapacityScheduler.java:971)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:1368)
        at org.apache.hadoop.yarn.sls.scheduler.SLSCapacityScheduler.handle(SLSCapacityScheduler.java:254)
        at org.apache.hadoop.yarn.sls.scheduler.SLSCapacityScheduler.handle(SLSCapacityScheduler.java:84)
        at org.apache.hadoop.yarn.event.EventDispatcher$EventProcessor.run(EventDispatcher.java:66)
        at java.lang.Thread.run(Thread.java:745)
, I will help to take a look.

It seems we got NPE from here {{getUser(userName).setUserResourceLimit(userLimitResource);}}.
It seems the user was removed was never added while computeUserLimit was executing from SLS. Since {{computeUserLimit}} and {{removeUser}} has writeLock, i suspect that the user was not added. 

I ll check the sls part a lil bit more and will share my feedback, It looks like the userName was probably removed (last app for this user) and then we tried to update a missing entry:

{color:red}
    getUser(userName).setUserResourceLimit(userLimitResource);
    return userLimitResource;
 {color}

I put a simple null-check, though I would like someone to validate it, as I am not sure that is enough: [~wangda], [~jianhe], [~asuresh], thoughts?
]