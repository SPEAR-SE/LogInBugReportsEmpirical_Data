[As a result of above sometimes RM itself wont get resources to publish which causes entity publish fails.
Exception trace-
{noformat}
2016-03-01 11:34:34,325 ERROR org.apache.hadoop.yarn.server.resourcemanager.metrics.SystemMetricsPublisher: Error when publishing entity [YARN_APPLICATION,application_1456545891178_0950]
com.sun.jersey.api.client.ClientHandlerException: java.net.SocketException: Too many open files
	at com.sun.jersey.client.urlconnection.URLConnectionClientHandler.handle(URLConnectionClientHandler.java:149)
	at org.apache.hadoop.yarn.client.api.impl.TimelineClientImpl$TimelineJerseyRetryFilter$1.run(TimelineClientImpl.java:235)
	at org.apache.hadoop.yarn.client.api.impl.TimelineClientImpl$TimelineClientConnectionRetry.retryOn(TimelineClientImpl.java:184)
	at org.apache.hadoop.yarn.client.api.impl.TimelineClientImpl$TimelineJerseyRetryFilter.handle(TimelineClientImpl.java:246)
	at com.sun.jersey.api.client.Client.handle(Client.java:648)
	at com.sun.jersey.api.client.WebResource.handle(WebResource.java:670)
	at com.sun.jersey.api.client.WebResource.access$200(WebResource.java:74)
	at com.sun.jersey.api.client.WebResource$Builder.post(WebResource.java:563)
	at org.apache.hadoop.yarn.client.api.impl.TimelineClientImpl.doPostingObject(TimelineClientImpl.java:481)
	at org.apache.hadoop.yarn.client.api.impl.TimelineClientImpl$1.run(TimelineClientImpl.java:324)
	at org.apache.hadoop.yarn.client.api.impl.TimelineClientImpl$1.run(TimelineClientImpl.java:321)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1711)
	at org.apache.hadoop.yarn.client.api.impl.TimelineClientImpl.doPosting(TimelineClientImpl.java:321)
	at org.apache.hadoop.yarn.client.api.impl.TimelineClientImpl.putEntities(TimelineClientImpl.java:306)
	at org.apache.hadoop.yarn.server.resourcemanager.metrics.SystemMetricsPublisher.putEntity(SystemMetricsPublisher.java:456)
	at org.apache.hadoop.yarn.server.resourcemanager.metrics.SystemMetricsPublisher.publishApplicationACLsUpdatedEvent(SystemMetricsPublisher.java:320)
	at org.apache.hadoop.yarn.server.resourcemanager.metrics.SystemMetricsPublisher.handleSystemMetricsEvent(SystemMetricsPublisher.java:232)
	at org.apache.hadoop.yarn.server.resourcemanager.metrics.SystemMetricsPublisher$ForwardingEventHandler.handle(SystemMetricsPublisher.java:473)
	at org.apache.hadoop.yarn.server.resourcemanager.metrics.SystemMetricsPublisher$ForwardingEventHandler.handle(SystemMetricsPublisher.java:468)
	at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:189)
	at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:117)
	at java.lang.Thread.run(Thread.java:745)
{noformat}, [~rohithsharma], is this 2.7.2 version ?, I think this is happening because we are not calling {{ClientResponse#close}}.
This should be a problem in trunk too., The relevant code in {{TimelineWriter#putEntities}}.
close will close the underlying input stream.

{code}
  public TimelinePutResponse putEntities(
      TimelineEntity... entities) throws IOException, YarnException {
    .....
    ClientResponse resp = doPosting(entitiesContainer, null);
    return resp.getEntity(TimelinePutResponse.class);   // ClientResponse object is not closed here.
  }
{code}, Sorry, getEntity would close the connection if entity type is not Closeable. I had overlooked that part., Initially i also suspected the same and then realised that if its ClientResponse is read then the stream is closed. so not sure whats leaking the events ..
[~rohithsharma] any other error logs while processing the events ? , I still see 2 places where we are not closing ClientResponse, when we call {{putDomain}} and in {{doPosting}} if response is not 200 OK., This should be closed as per what I understand from Jersey API documentation. [~rohithsharma] can confirm if scenario is same in his case or not., As I see ATS logs, there were no exception. In RM logs, there was exception as I mentioned in first comment {{SocketException: Too many open files}}.
I am recovering the applications once again, and will check it out for close_wait connections., bq. I still see 2 places where we are not closing ClientResponse, when we call putDomain and in doPosting if response is not 200 OK.
It looks to be this is the case. After RM recovery completes, timeline entities are published in background. During this span of time, if there timeline sever is restarted or down for sometime, it is able to see many connections are kept CLOSE_WAIT state., Hi [~varun_saxena], [~rohithsharma], if I understand this correctly, is the following change enough for this?

{code:title=TimelineWriter.java|borderStyle=solid}

// Moving this call "resp.getEntity(String.class)" out of the if block of " if (LOG.isDebugEnabled())" 

private ClientResponse doPosting(final Object obj, final String path)
    throws IOException, YarnException {
 ... ...
  if (resp == null ||
      resp.getStatusInfo().getStatusCode()
          != ClientResponse.Status.OK.getStatusCode()) {
     ... ...
    if (resp != null) {
      msg += " HTTP error code: " + resp.getStatus();
      String output = resp.getEntity(String.class);
      if (LOG.isDebugEnabled()) {
        LOG.debug("HTTP error code: " + resp.getStatus()
            + " Server response : \n" + output);
      }
... ...
}
{code}, [~rohithsharma], [~varun_saxena], [~Ying Zhang], is this still a problem? If so, are we on track for 2.9.0 (27th Oct)? Thanks!, It's quite long time I stopped focusing on ATSv1, so I am unable to say does this issue still a valid or not! I need to verify once launching ATSv1 daemon! , [~rohithsharma], did you get a chance to check this out? Also, is this still critical now that we have ATS v2 in 2.9?, Apologies for not looking into this. I have not verified with ATSv1/1.5 yet. I will remove target version and keep it JIRA open as-is. ]