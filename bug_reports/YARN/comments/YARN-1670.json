[Attaching the patch for trunk, branch2  and branch23., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12632518/YARN-1670.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:red}-1 javac{color:red}.  The patch appears to cause the build to fail.

Console output: https://builds.apache.org/job/PreCommit-YARN-Build/3241//console

This message is automatically generated., updated patch for trunk and branch-2, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12632525/YARN-1670.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-YARN-Build/3243//testReport/
Console output: https://builds.apache.org/job/PreCommit-YARN-Build/3243//console

This message is automatically generated., It is a code change and there are no unit tests for this change, Looked at the patch. The core changes look fine. Couple of comments
 - There is formatting issue where you declare fileLength. It is not indented in the right away.
 - I think you can write a very simple test in TestLogAggregationService.
    -- Make a container write logs
    -- Start and finish the aggregation
    -- Make the container write more logs (may be disable deletion for log-file locally for this)
    -- Then try to read the logs using our utils. It should throw the same exception.
Am I reading that correctly?

Fix this issue also that Thomas raised?
bq. We also noticed that a bug in readAContainerLogsForALogType where it is using an int for curRead whereas it should be using a long. , Adding patch for trunk, branch-2 and branch23 (This patch has previous change + Unit test verifying the change ), {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12635891/YARN-1670-v2.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common:

                  org.apache.hadoop.yarn.logaggregation.TestAggregatedLogFormat

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-YARN-Build/3414//testReport/
Console output: https://builds.apache.org/job/PreCommit-YARN-Build/3414//console

This message is automatically generated., Seems like you missed this, you are using tabs there
bq. There is formatting issue where you declare fileLength. It is not indented in the right away.

Also please look at the test failure on Jenkins. It also failed in my IDE (eclipse 1GB heap) because of insufficient heap-space., Thanks [~vinodkv] for the feedback.
1- I changed the formatting.
2- I have modified the patch to use up less memory. It should work now. I have also tested the new patch on my Eclipse IDE with HeapSize=1GB and the test pass every time I run it.
, {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12636040/YARN-1670-v3.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-YARN-Build/3422//testReport/
Console output: https://builds.apache.org/job/PreCommit-YARN-Build/3422//console

This message is automatically generated., Looks good, checking this in., Committed this to trunk, branch-2 and branch-2.4. Thanks Mit!

[~jlowe]/[~tgraves], feel free to pull it into 0.23.x if needed., SUCCESS: Integrated in Hadoop-trunk-Commit #5371 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/5371/])
YARN-1670. Fixed a bug in log-aggregation that can cause the writer to write more log-data than the log-length that it records. Contributed by Mit Desai. (vinodkv: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1580005)
* /hadoop/common/trunk/hadoop-yarn-project/CHANGES.txt
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/AggregatedLogFormat.java
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/test/java/org/apache/hadoop/yarn/logaggregation/TestAggregatedLogFormat.java
, Mit, I'm worried that we are still going to have this issue except in the opposite way. On the last read that puts us over the initial filelength, we are not going to write the last part of the data that still fits into the original filelength. In this case our Aggregate File Log length will be smaller than the filelength written to the data structure.

jeagles, I've reopened this ticket to verify the correctness of the patch that went into branch-2 and branch-2.4., Good catch Jon.  Yep I think you are correct here.  We can actually still write more then we should. It should be checking to make sure the curRead + len read is < fileLength before writing and if its not only writing the difference.  , Good catch, Jon!

Just checking for {{curRead + len < fileLength}} will also not work no? We have to explicitly write only {{fileLength - curRead}} bytes if {{curRead + len > fileLength}}. Right?, It'll be useful to write a test for this case too, though.., Thats correct Vinod. In the last iteration, where the buf length is greater than the remaining portion of the file, we will have to write the {{fileLength-curRead}} bytes, SUCCESS: Integrated in Hadoop-Yarn-trunk #517 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/517/])
YARN-1670. Fixed a bug in log-aggregation that can cause the writer to write more log-data than the log-length that it records. Contributed by Mit Desai. (vinodkv: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1580005)
* /hadoop/common/trunk/hadoop-yarn-project/CHANGES.txt
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/AggregatedLogFormat.java
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/test/java/org/apache/hadoop/yarn/logaggregation/TestAggregatedLogFormat.java
, SUCCESS: Integrated in Hadoop-Hdfs-trunk #1709 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1709/])
YARN-1670. Fixed a bug in log-aggregation that can cause the writer to write more log-data than the log-length that it records. Contributed by Mit Desai. (vinodkv: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1580005)
* /hadoop/common/trunk/hadoop-yarn-project/CHANGES.txt
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/AggregatedLogFormat.java
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/test/java/org/apache/hadoop/yarn/logaggregation/TestAggregatedLogFormat.java
, SUCCESS: Integrated in Hadoop-Mapreduce-trunk #1734 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1734/])
YARN-1670. Fixed a bug in log-aggregation that can cause the writer to write more log-data than the log-length that it records. Contributed by Mit Desai. (vinodkv: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1580005)
* /hadoop/common/trunk/hadoop-yarn-project/CHANGES.txt
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/AggregatedLogFormat.java
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/test/java/org/apache/hadoop/yarn/logaggregation/TestAggregatedLogFormat.java
, [~tgraves], [~jeagles] and [~vinodkv], I am adding new patch. I have included the check in the while loop to make sure that we do not write the whole buffer if the last iteration has the file contents less than buffer size., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12636288/YARN-1670-v4.patch
  against trunk revision .

    {color:red}-1 patch{color}.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-YARN-Build/3440//console

This message is automatically generated., Thanks, [~mdesai]. The above logic seems correct, now. Two minor things.
 - If we move from a count up byte counter to a count down byte counter,  does this seem easier to understand?
{code}
long bytesLeft = file.length();
while (len = in.read(buf)) != -1) {
  //If buffer contents within fileLength, write
  if (len < bytesLeft) {
    out.write(buf, 0, len);
    bytesLeft -= len;
  }
  //else only write contents that are within fileLength, then exit early 
  else {
    out.write(buf, 0, (int)bytesLeft);
    break;
  }
}
{code}
 - I see the buffer size of 65535 being used (I know, not your code). I wonder if this is really intended to be block aligned (64K) since that will result in theoretical optimal read performance., I realize that I created the patch based on the trunk before the commit of the earlier patch so it fails. I will upload a new one.
[~jeagles]
# Nice logic. This is much easier to understand. I will incorporate your suggestion in the new change.
# For the buffer size, you are correct. I already did some analysis on that. I read some discussions/articles online which say that 64K buffer size performs efficiently., Attaching the patch with the updated changes., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12636350/YARN-1670-v4.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-YARN-Build/3442//testReport/
Console output: https://builds.apache.org/job/PreCommit-YARN-Build/3442//console

This message is automatically generated., +1 on this change. committing to trunk, branch-2.4, branch-2, branch-0.23, SUCCESS: Integrated in Hadoop-trunk-Commit #5387 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/5387/])
YARN-1670. aggregated log writer can write more log data then it says is the log length (Mit Desai via jeagles) (jeagles: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1580957)
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/AggregatedLogFormat.java
, FAILURE: Integrated in Hadoop-Yarn-trunk #520 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/520/])
YARN-1670. aggregated log writer can write more log data then it says is the log length (Mit Desai via jeagles) (jeagles: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1580957)
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/AggregatedLogFormat.java
, FAILURE: Integrated in Hadoop-Mapreduce-trunk #1737 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1737/])
YARN-1670. aggregated log writer can write more log data then it says is the log length (Mit Desai via jeagles) (jeagles: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1580957)
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/AggregatedLogFormat.java
, FAILURE: Integrated in Hadoop-Hdfs-trunk #1712 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1712/])
YARN-1670. aggregated log writer can write more log data then it says is the log length (Mit Desai via jeagles) (jeagles: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1580957)
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/AggregatedLogFormat.java
, It reports similar error in YARN-2146. [~mitdesai] are working on it.]