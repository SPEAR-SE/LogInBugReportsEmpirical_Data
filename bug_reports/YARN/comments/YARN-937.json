[Hey [~tucu00], is there a chance you can get to this one quickly? Much appreciated, thanks!, I'll start with it this afternoon, thx, [~acmurthy], [~vinodkv], the approach I'm taking is adding to {{ApplicationReport}} a {{getAmToRmToken()}} method. Then the {{RMAppIMpl}} during {{createAndGetApplicationReport()}}, in case of unmanaged AMs only, adds the token from {{currentAttempt.getAMRMToken()}} if available (if i got things right it will have it once the app is running). Still I have to iron out a few details. Does this approach seems reasonable?, questioning myself, why do we need an unmanaged AM to get RM tokens? the uAM has always direct contact with the RM, so it can authenticate itself if needed., After a bit of more digging, my current thinking for this is:

AM to RM communication should require tokens ONLY when dealing with managed AMs.

For unmanaged AMs, AMRM tokens are not necessary because all the interactions with the RM -from creating the APP, registering it, doing allocations and finishing- are always from the same process. And, in a secure setup, kerberos will be required for the same.

The changes introduced in YARN-701 configure the RPC server to always require token auth.

I think we should revert that change in the {{ApplicationMasterService}} {{serviceStart()}} method and instead in the {{authorizeRequest()}} method we should check for the {{UGI.getAuthenticationMethod()}} to be {{TOKEN}} only if the AM is managed.

[~vinodkv], [~acmurthy], [~sandyr], thoughts?
, The thing is throughout YARN, and from my other conversations with [~daryn] on other tickets in larger Hadoop, we are trying to move to digest auth irrespective of kerberos. In your latest solution, unmanaged AMs in unsecure mode will not need any auth, which will regress that path. Your first solution of sending across AMRMToken seems fine to me, we should just mark that API as @Private., Patch that adds to the YarnClient a method to retrieve the AMRM token from an application (giving an appId).

The AMRM token is only returned when:

* the AM is unmanaged
* the AM is owned by the current user
* the AM is RUNNING

testcases verifies the first 2 conditions, the last condition cannot be verified easily.

I've also verified that this patch fixed my unmanaged AM.

The {{TestUnnmanagedAMLauncher}} is still commented out because the {{UnmanagedAMLauncher}} requires additional work (it launches a different JVM, and we need to propagate the tokens to it). I'll open a JIRA to fix this.
, bq. The TestUnnmanagedAMLauncher is still commented out because the UnmanagedAMLauncher requires additional work (it launches a different JVM, and we need to propagate the tokens to it). I'll open a JIRA to fix this.
That's part of the reason why I didn't fix it all in YARN-701. This JIRA is the right place to fix it. We can write the tokens to a file and set the env ApplicationConstants.CONTAINER_TOKEN_FILE_ENV_NAME. Once we do that the actual AM can pick up the credentials just like it does in an managed AM. One big problem is where we store this file, it is the unmanaged AMs responsibility to store it in a secure manner and delete it (on process exit?)., I still don't understand why UnmanagedAMLauncher forks in to a new JVM instead doing everything in process., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12593610/YARN-937.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 4 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager:

                  org.apache.hadoop.mapreduce.security.TestMRCredentials
                  org.apache.hadoop.mapreduce.security.TestBinaryTokenFile
                  org.apache.hadoop.yarn.client.cli.TestYarnCLI
                  org.apache.hadoop.yarn.client.api.impl.TestYarnClient
                  org.apache.hadoop.yarn.api.TestApplicatonReport
                  org.apache.hadoop.yarn.server.resourcemanager.TestClientRMService
                  org.apache.hadoop.yarn.server.resourcemanager.rmapp.TestRMAppTransitions
                  org.apache.hadoop.yarn.server.resourcemanager.TestApplicationACLs
                  org.apache.hadoop.yarn.server.resourcemanager.security.TestClientToAMTokens

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-YARN-Build/1545//testReport/
Console output: https://builds.apache.org/job/PreCommit-YARN-Build/1545//console

This message is automatically generated., The decision to launch it in a new process was to simulate exactly what happens in the cluster. The env is setup and a process is forked just like it is inside the cluster. Trying to keep the AM JVM internals clean from any pre-loading/statics etc that already happened in the launcher code., We could optionally launch it in process but the launching it separately seemed more important., fixing failure in {{TestApplicatonReport}}.

All other YARN testcases failing in jenkins are passing locally with the patch.

The 2 MAPREDUCE testcases failing in jenkins also fail locally without the patch., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12593641/YARN-937.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 4 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager:

                  org.apache.hadoop.mapreduce.security.TestMRCredentials
                  org.apache.hadoop.mapreduce.security.TestBinaryTokenFile

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-YARN-Build/1549//testReport/
Console output: https://builds.apache.org/job/PreCommit-YARN-Build/1549//console

This message is automatically generated., bq. We can write the tokens to a file and set the env ApplicationConstants.CONTAINER_TOKEN_FILE_ENV_NAME. Once we do that the actual AM can pick up the credentials just like it does in an managed AM.
I like this idea because it keeps the AM logic/code identical in managed and unmanaged modes wrt tokens. The unmanagedAMLauncher could write the file out and delete the file when it exits. The unamanagedAMLauncher currently monitors the AM for exit and can delete the token file after the AM has exited. In fact it could delete the file after the AM is reported to be running by the RM since by that time the AM has already loaded the token and contacted the RM using the token.
It would be great if the unmanagedAMLauncher would continue to function like it did earlier., The RM also provides the AM with a secret.  Does the unmanaged AM also receive the secret?  It's almost as if the unmanaged AM launcher needs to construct or obtain the launch context from the RM.  I haven't reviewed the AM launcher code so perhaps it already does this.

I'm not sure why a token file needs to be written out?  Technically it shouldn't be necessary anymore since the tokens are passed in the launch context., [~bikassaha], in the way I've using unmanaged AM I have a running service that hosts the AM without forking a process. IMO, this is the powerful thing about unmanaged AMs. If I would be to fork a new process to run the AM, why would I just use a managed AM.

[~daryn], the AM launcher, after creating an APP, forks a process to register it to the schedulers, the new process does not have the launch context thus we need the token file in this case., new patch passing the token in  a file as Bikas suggested for the UnmanagedAMLauncher. Uncommenting the TestUnmanagedAMLauncher as now works.

The 2 MR testcases failures are unrelated., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12593695/YARN-937.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 5 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-unmanaged-am-launcher hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager:

                  org.apache.hadoop.mapreduce.security.TestMRCredentials
                  org.apache.hadoop.mapreduce.security.TestBinaryTokenFile

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-YARN-Build/1550//testReport/
Console output: https://builds.apache.org/job/PreCommit-YARN-Build/1550//console

This message is automatically generated., Test failures are unrelated, they are also failing in trunk., [~tucu00] Are there jiras open for TestMRCredentials & TestBinaryTokenFile?, [~acmurthy], [~vinodkv] or [~bikassaha], given that there are other JIRAs (YARN-945) that may impact this, it will be eaiser to have this in so if changes are needed we have only one moving target. It would be great if you can review this patch and if ready we can get it in. THX, [~acmurthy], just created YARN-960., Sorry I am little caught up. I will get to this by EOD., Tx for the patch. Quick comments:
 - ApplicationReport.getAmRmToken() -> getAMRMToken and similarly the setter?
 - We should document the above API(s) in ApplicationReport similar to what you did in YarnClient.
 - YarnClientImpl.getAMRMToken(): The  formatting is a little weird, can you fix? Otherwise I can do it at commit time.
 - Clearly the token is only returned in selective cases. So we can have another API in ApplicationReport.newInstance() which doesn't take in a token. It will reduce the patch changes too I think.
 - RMAppImpl.createAndGetApplicationReport()
    -- currentAttempt can be null depending on when the API is called.
    -- token variable can be typed to be Token<AMRMTokenIdentifier> token
    -- You should use BuilderUtils.newToken instead of new newClientToAMToken. Or may be just create the token method itself, the main problem is calling newClientToAMToken for AMRMToken., Not quite sure why we have manually use the RM address to re-create the token. YarnClient uses ClientRMProxy that will automatically switch between RM instances. Hence, the RM address might change after a failover.
{code}
+  public org.apache.hadoop.security.token.Token<AMRMTokenIdentifier> 
+    getAMRMToken(ApplicationId appId) throws YarnException, IOException {
+    org.apache.hadoop.security.token.Token<AMRMTokenIdentifier> amrmToken = null;
+    ApplicationReport report = getApplicationReport(appId);
+    Token token = report.getAmRmToken();
+    if (token != null) {
+    InetSocketAddress address = getConfig().getSocketAddr(
+      YarnConfiguration.RM_SCHEDULER_ADDRESS,
+      YarnConfiguration.DEFAULT_RM_SCHEDULER_ADDRESS,
+      YarnConfiguration.DEFAULT_RM_SCHEDULER_PORT);
+      amrmToken = ConverterUtils.convertFromYarn(token, address);
{code}

typo in name?
{code}
public void testMRAMTokens() throws Exception {
{code}

typo in comment? same exists in the user=foo case.
{code}
+      //managed AMs do return AMRM token
+      Assert.assertNotNull(rmClient.getAMRMToken(appId));
{code}

If the queue ACL's give identical access to a different user then why should that user not be allowed to obtain the AMRM token?

Should we return AMRMToken in getApplicationReport() only if the currentAppAttempt is in a waiting to register state? Once the attempt is registered, is there a need to provide the token to the client?
Similarly the AMLauncher could delete the token file after the app has entered running state based on getApplicationReport()?
, Updated patch fixing typos and making sure the jobtoken file written by the UnmanagedAMLauncher is readonly by the current user (in addition to the original behavior of being deleted on JVM exit).

bq. Not quite sure why we have manually use the RM address to re-create the token....

We need to get the scheduler HOST:PORT to set the service name, from the ClientRMProxy we can not get it, can we? In the case of failover, if we use the same patterns/logic as HDFS failover, instead having concrete HOST:PORT services, we will have logical names that will be resolve appropriately (commented on similar topic in YARN-701 earlier today).

bq. If the queue ACL's give identical access...

We can do that. However, as I see it, being able to schedule resources should be done by the AM process itself and only it. the ACLs are for who/what can manage the AM. (while we can not prevent an AM to to pass the token to another process and then have 2 processes doing scheduling for the same AM, this will definitely break the AMs. But we cannot stop this from happening if somebody is doing something stupid. The best we can do is to check it the same user).

bq. Should we return AMRMToken in getApplicationReport() only if the currentAppAttempt is in a waiting to register state? ...

Unless I'm missing something, these initial AM state transitions happen in the RM without interaction from the AM, we cannot guarantee the AM will query the RM on that particular state. Thus returning it when in RUNNING is safe. We could return it only once, but that would mean we have to keep track of that on the RMAppImpl. And what is there is a failure on the AM before it manages to 'save' it, and the AM needs to re-get it?

bq. Similarly the AMLauncher could delete the token file after the app has entered running state based on getApplicationReport()?

This would mean the AMLauncher would have to have a callback from the forked AM process. And still the window of existence of the file is there, so you are still 'vulnerable' to that file being stolen. The current patch, as mentioned above makes this file user readable only.
, bq. We need to get the scheduler HOST:PORT to set the service name, 
Unless I am missing something, the MR AM code did not have to change to make this translation. The token is transparently read from the env located file by UGI and populated into the currentUser's UGI. Then the proxy is opened to the RM using that token. If this is a correct understanding, then I dont follow why the code in YARNClient needs to make this translation?

bq. Unless I'm missing something, these init
The AMRMToken is used by the AM attempt to register with the RM and on further calls to the RM. So once the unmanaged AM attempt has registered with the RM, there is no need for the RM to supply AMRMToken in getApplicationReport(). Correct? If yes, then doing this will limit the time for which the AMRMToken is externally available and may be better for security.

Isnt there a race condition here? The token may be null right? Refer to Vinods comment above about currentAppAttempt being null.
Lets use FileUtil.chmod instead of setReadable etc because those dont work on Windows.
Is the System.print still necessary?
{code}
+  public void launchAM(ApplicationAttemptId attemptId) 
+    throws IOException, YarnException {
+    Credentials credentials = new Credentials();
+    Token<AMRMTokenIdentifier> token = rmClient.getAMRMToken(attemptId.getApplicationId());
+    credentials.addToken(token.getService(), token);
+    File tokenFile = File.createTempFile("unmanageAMToken","");
+    tokenFile.setReadable(true, true);
+    tokenFile.setWritable(true, true);
+    System.out.println("#####" + tokenFile.getAbsolutePath());
+    tokenFile.deleteOnExit();
{code}

+1 for renaming from AmRm to AMRM. Should the API be marked @Private?, Oops, sorry missed Vinod's comments before, uploading new patch that addresses them (and Bikas' latest comments as well).

A couple things to note:

* On adding a new ApplicationReport.newInstance() signature for this. This method is only used from testcases, I'd rather not proliferate on @Private methods when one is enough.

* Changed the jobtoken file creation to do use FileUtils.chmod() and the file creation to be an append (the temp is created with zero bytes). Then we don't have a race condition.

* Limiting the return window of the AMRM token to when the application is in ACCEPTED state. This is a stable state before the uAM registers with the scheduler, thus the uAM can save the tokens for failover logic if desired.

I think the only outstanding comment is Bikas' "Unless I am missing something, the MR AM code did not have to change to make this translation.... "

Managed AMs do something a bit incorrect, from {{RMAppAttemptImpl}}:

{code}
      // normally the client should set the service after acquiring the
      // token, but this token is directly provided to the AMs
      SecurityUtil.setTokenService(amRmToken, serviceAddr);
{code}
, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12594043/YARN-937.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 5 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-unmanaged-am-launcher hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager:

                  org.apache.hadoop.mapreduce.security.TestMRCredentials
                  org.apache.hadoop.mapreduce.v2.TestNonExistentJob
                  org.apache.hadoop.mapreduce.security.TestBinaryTokenFile
                  org.apache.hadoop.yarn.client.api.impl.TestNMClient

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-YARN-Build/1578//testReport/
Console output: https://builds.apache.org/job/PreCommit-YARN-Build/1578//console

This message is automatically generated., test failures seem unrelated, those failures happen in a clean trunk build as well., Token can be null at this point, right? 
Also, any particular reason the token file is create in temp dir rather than current dir? I am guessing that current dir might be better since usually it will not even be visible to everyone.
{code}
+    Token<AMRMTokenIdentifier> token = rmClient.getAMRMToken(attemptId.getApplicationId());
+    credentials.addToken(token.getService(), token);
+    File tokenFile = File.createTempFile("unmanageAMToken","");
{code}

It might be better to compare currentAttempt.getState() == RMAppAttemptState.LAUNCHED. That is the stable state of the attempt when the RM expects the AM to register. RMAppImpl will not return to ACCEPTED state for a retry (it remains in RUNNING state). The unmanagedAM is currently restricted to not allow retry but that may be relaxed and this code will be future proof if we compare attempt state instead of app state. For the single retry case, this is equivalent to the current check since app will be in ACCEPTED only after attempt is in LAUNCHED state.
{code}
+        if (currentAttempt != null && getState() == RMAppState.ACCEPTED) {
+          try {
{code}

Minor comments

Formatting discrepancies
{code}
+          FinalApplicationStatus.SUCCEEDED, null, "N/A", 0.63789f, "NON-YARN", 
+        null);
{code}

Test timeout? I thought our testpatch warned for new tests with no timeout.
{code}
+  @Test
+  public void testAMMRTokens() throws Exception {
{code}

"of the" current user?
{code}
+   * Applications Masters, the token must be obtained via this method and set
+   * in the {@link org.apache.hadoop.security.UserGroupInformation} current 
+   * user.
{code}

The deletes "-" in this javadoc diff dont make sense??? Only net additions are expected right?
{code}
   /**
-   * <p>
-   * Get a report (ApplicationReport) of all Applications in the cluster.
-   * </p>
+   * Get the AMRM token of the application.
+   * <p/>
+   * The AMRM token is required for AM to RM scheduling operations. For 
.....
+   * </li>
+   * Else this method returns NULL.
    * 
-   * <p>
-   * If the user does not have <code>VIEW_APP</code> access for an application
-   * then the corresponding report will be filtered as described in
-   * {@link #getApplicationReport(ApplicationId)}.
-   * </p>
-   * 
-   * @return a list of reports of all running applications
+   * @param appId {@link ApplicationId} of the application to get the AMRM token
+   * @return the AMRM token if available
{code}

Rest looks good except for the followin about which I am not sure. [~vinodkv] Can you please take a look? Pasting inline for convenience. Does the RM scheduler address thing need to happen here. I am particular about this because we have added an RMProxy layer specifically to avoid having clients look up RM address on their own. This will help with RM HA when the actual current address can change. This change makes YARNClient aware of RM address.
{code}
+  public org.apache.hadoop.security.token.Token<AMRMTokenIdentifier>
+      getAMRMToken(ApplicationId appId) throws YarnException, IOException {
+    org.apache.hadoop.security.token.Token<AMRMTokenIdentifier> amrmToken = null;
+    ApplicationReport report = getApplicationReport(appId);
+    Token token = report.getAMRMToken();
+    if (token != null) {
+      InetSocketAddress address = getConfig().getSocketAddr(
+          YarnConfiguration.RM_SCHEDULER_ADDRESS,
+          YarnConfiguration.DEFAULT_RM_SCHEDULER_ADDRESS,
+          YarnConfiguration.DEFAULT_RM_SCHEDULER_PORT);
+      amrmToken = ConverterUtils.convertFromYarn(token, address);
+    }
+    return amrmToken;
+  }
{code}, Thanks Bikas, addressed your comments:

bq. Token can be null at this point, right? ....

Now adding a precondition check that fails if the AM state is not in ACCEPTED state.

bq. Also, any particular reason the token file is create in temp dir rather than current dir?...

Done.

bq. It might be better to compare currentAttempt.getState() == RMAppAttemptState.LAUNCHED...

Done.

Still I don't think unmanaged AM retries should be a concern of the RM. if the uAM supports that, it should be completely transparent to the RM even from state perspective. In other words, the RM should not be aware the uAM has failed and is retrying if the application is still valid.

bq. Rest looks good except for the followin about which I am not sure.

This could be avoided if the ApplicationReport returns the scheduler port, which it does not today. Because of this, the clien must pick up from its configuration the scheduler port.

Regarding RM HA, as I mentioned before, if we follow the same pattern used by HDFS HA, then all HOSTNAME:PORT entries in the configurations will become logical names that are resolved to the active HOSTNAME:PORT transparently by the RPC client retry policy for HA (if I remember correctly).


, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12594203/YARN-937.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 5 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-unmanaged-am-launcher hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager:

                  org.apache.hadoop.mapreduce.v2.TestNonExistentJob
                  org.apache.hadoop.mapreduce.security.TestMRCredentials
                  org.apache.hadoop.mapreduce.security.TestBinaryTokenFile
                  org.apache.hadoop.yarn.client.api.impl.TestNMClient

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-YARN-Build/1585//testReport/
Console output: https://builds.apache.org/job/PreCommit-YARN-Build/1585//console

This message is automatically generated., test failures, as before, seem to be unrelated., [~bikassaha], [~vinodkv], anything else to be addressed? , Vinod and I looked at the token code and translation logic a fair bit and the URI solution for the name node is actually slightly misleading. The URI is just used as a dummy placeholder. Internally, ConfiguredProxyProvider does some magic to populate the token cache with the real ip address after looking up the token using the dummy URI entry.
Anyways, that is a perhaps orthogonal to the code here. After looking at the code, I think we dont need to look up the addres from config in yarnclientimpl. When the RM creates the token is populates the service field and so applicationReport.getAMRMToken() returns a token that has all fields already populated. So we can simply call 
{code}amrmToken = ConverterUtils.convertFromYarn(token, null);{code}
The helper utility populates the service field of the token from the protoToken and then overrides it with the user supplied addr. Since the AMRMToken already has the service field populated we dont need to override anything. So we dont need to lookup any address from config in the YARNClient code. Later, for HA if we need to do some translation, then it should probably happen via the RMProxy layer. Does that work for you?

Rest of the patch looks good to me. Thanks for taking all the minor comments!
, bq.  org.apache.hadoop.mapreduce.v2.TestNonExistentJob
Filed MAPREDUCE-5424, bq. Since the AMRMToken already has the service field populated we dont need to override anything. So we dont need to lookup any address from config in the YARNClient code. Later, for HA if we need to do some translation, then it should probably happen via the RMProxy layer. Does that work for you?

Well, [~daryn] has been doing lot of work to ensure the service of a token is not set by the server but by the client. Doing what you suggest is going opposite to that.

This has to be done in the client (for example in the case of a multi-homing setup, it would not work otherwise as the RM does not know the hostname/IP visible to the user).

Also, looking at the conf is exactly what the {{ClientRMProxy}} is doing within the {{getRMAddress()}}.

I think the current patch it is the right approach.

, We are on the same page that this translation should happen on the client side. We tried our best to remove static RM address translation code from all clients and NM code and moved the logic into a common RMProxy layer. Hence, I am trying to avoid putting static RM address lookup back into YarnClient code. At some point in the near future, we may be doing the address translation for tokens inside the RMProxy layer like HDFS already does. My suggestion was a compromise that allows things to work correctly as of now while at the same time not regressing on the effort we made to remove RM static address translation code. I hope this clarifies my concerns. Thoughts?, Let's move, folks. Either
 - Keep it on the server side for now (which was always the case) and fix it separately to be in RMProxy later.
 - Or fix it now itself in RMProxy.
 - Or just leave it as is in the patch.

We all agree it needs to be on the client side, and that to in RMProxy. It's okay to compromise in any of the above ways to move this blocker ahead. Tx., Alejandro, 
We can keep my suggestion and remove the translation code from YARNClient now. Things should continue to work if we simply remove that code since the token already has the address and there is no need to re-populate it. 

Or we can continue to keep the config address lookup code in YarnClientImpl. Later, when we improve RMProxy to do the right thing, we will have to remember to come back and remove this code.

Your call.

+1
, Another option is to add a "getRMCurrentAddress()" to RMProxy and use that instead of statically reading from config. We keep the client side address logic while still maintaining the RMProxy as the source of truth., 
{{getRMCurrentAddress()}}, we would have to pass the config and a more appropriate name would be {{getRMSchedulerAddress()}}.

Also, shouldn't be the {{ApplicationClientProtocol}} instance the one returning the address?

And this seems like it will affect other things as well. I think we should take care of this in another JIRA.

Are you OK on committing the current patch and following up with another JIRA (making it a blocker for the release after 2.1.0)?

, Yes, RMProxy methods take conf and protocol class as arguments. 
I have already +1'd. We can make changes later on as appropriate., Committed to trunk, branch-2 and branch-2.1. Also, created YARN-982 to add method to get address from client proxy instead re-reading config.]