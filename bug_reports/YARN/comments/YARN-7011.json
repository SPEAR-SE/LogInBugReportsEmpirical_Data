[What does yarn-daemon.sh --debug say?  You can also run {{yarn-daemon.sh --debug start classpath}}.  The directory passed via --config should be the first entry., For completeness, with a fresh build:

{code}
$ sbin/yarn-daemon.sh --config /tmp/hadoop --debug start classpath 2>&1 | grep /tmp/hadoop
DEBUG: HADOOP_CONF_DIR=/tmp/hadoop
DEBUG: Profiles: importing /tmp/hadoop/shellprofile.d/example.sh
/tmp/hadoop:/Users/aw/H/hadoop-3.0.0-beta1-SNAPSHOT/share/hadoop/common/lib/*:/Users/aw/H/hadoop-3.0.0-beta1-SNAPSHOT/share/hadoop/common/*:/Users/aw/H/hadoop-3.0.0-beta1-SNAPSHOT/share/hadoop/hdfs:/Users/aw/H/hadoop-3.0.0-beta1-SNAPSHOT/share/hadoop/hdfs/lib/*:/Users/aw/H/hadoop-3.0.0-beta1-SNAPSHOT/share/hadoop/hdfs/*:/Users/aw/H/hadoop-3.0.0-beta1-SNAPSHOT/share/hadoop/mapreduce/*:/Users/aw/H/hadoop-3.0.0-beta1-SNAPSHOT/share/hadoop/yarn:/Users/aw/H/hadoop-3.0.0-beta1-SNAPSHOT/share/hadoop/yarn/lib/*:/Users/aw/H/hadoop-3.0.0-beta1-SNAPSHOT/share/hadoop/yarn/*
{code}, Hi [~aw],

I could see "DEBUG: HADOOP_CONF_DIR=/tmp/hadoop" but not "DEBUG: Profiles: importing /tmp/hadoop/". But still i couldnt see the required config change in RM after the start of it
{code}
 sudo su - -c "hadoopInstall/hadoop-yarn-resourcemanager/sbin/yarn-daemon.sh --config /tmp/hadoopConf --debug start resourcemanager" yarn | grep "/tmp/hadoopConf"
DEBUG: hadoop_parse_args: processing start
DEBUG: hadoop_parse: asking caller to skip 3
DEBUG: HADOOP_CONF_DIR=/tmp/hadoopConf
DEBUG: shellprofiles: hadoopInstall/hadoop-client/libexec/shellprofile.d/hadoop-aliyun.sh hadoopInstall/hadoop-client/libexec/shellprofile.d/hadoop-archive-logs.sh hadoopInstall/hadoop-client/libexec/shellprofile.d/hadoop-archives.sh hadoopInstall/hadoop-client/libexec/shellprofile.d/hadoop-aws.sh hadoopInstall/hadoop-client/libexec/shellprofile.d/hadoop-azure-datalake.sh hadoopInstall/hadoop-client/libexec/shellprofile.d/hadoop-azure.sh hadoopInstall/hadoop-client/libexec/shellprofile.d/hadoop-distcp.sh hadoopInstall/hadoop-client/libexec/shellprofile.d/hadoop-extras.sh hadoopInstall/hadoop-client/libexec/shellprofile.d/hadoop-gridmix.sh hadoopInstall/hadoop-client/libexec/shellprofile.d/hadoop-hdfs.sh hadoopInstall/hadoop-client/libexec/shellprofile.d/hadoop-httpfs.sh hadoopInstall/hadoop-client/libexec/shellprofile.d/hadoop-kafka.sh hadoopInstall/hadoop-client/libexec/shellprofile.d/hadoop-kms.sh hadoopInstall/hadoop-client/libexec/shellprofile.d/hadoop-mapreduce.sh hadoopInstall/hadoop-client/libexec/shellprofile.d/hadoop-openstack.sh hadoopInstall/hadoop-client/libexec/shellprofile.d/hadoop-rumen.sh hadoopInstall/hadoop-client/libexec/shellprofile.d/hadoop-streaming.sh hadoopInstall/hadoop-client/libexec/shellprofile.d/hadoop-yarn.sh
DEBUG: Profiles: importing hadoopInstall/hadoop-client/libexec/shellprofile.d/hadoop-aliyun.sh
DEBUG: Profiles: importing hadoopInstall/hadoop-client/libexec/shellprofile.d/hadoop-archive-logs.sh
DEBUG: Profiles: importing hadoopInstall/hadoop-client/libexec/shellprofile.d/hadoop-archives.sh
DEBUG: Profiles: importing hadoopInstall/hadoop-client/libexec/shellprofile.d/hadoop-aws.sh
DEBUG: Profiles: importing hadoopInstall/hadoop-client/libexec/shellprofile.d/hadoop-azure-datalake.sh
DEBUG: Profiles: importing hadoopInstall/hadoop-client/libexec/shellprofile.d/hadoop-azure.sh
DEBUG: Profiles: importing hadoopInstall/hadoop-client/libexec/shellprofile.d/hadoop-distcp.sh
DEBUG: Profiles: importing hadoopInstall/hadoop-client/libexec/shellprofile.d/hadoop-extras.sh
DEBUG: Profiles: importing hadoopInstall/hadoop-client/libexec/shellprofile.d/hadoop-gridmix.sh
DEBUG: Profiles: importing hadoopInstall/hadoop-client/libexec/shellprofile.d/hadoop-hdfs.sh
DEBUG: HADOOP_SHELL_PROFILES accepted hdfs
DEBUG: Profiles: importing hadoopInstall/hadoop-client/libexec/shellprofile.d/hadoop-httpfs.sh
DEBUG: Profiles: importing hadoopInstall/hadoop-client/libexec/shellprofile.d/hadoop-kafka.sh
DEBUG: Profiles: importing hadoopInstall/hadoop-client/libexec/shellprofile.d/hadoop-kms.sh
DEBUG: Profiles: importing hadoopInstall/hadoop-client/libexec/shellprofile.d/hadoop-mapreduce.sh
DEBUG: HADOOP_SHELL_PROFILES accepted mapred
DEBUG: Profiles: importing hadoopInstall/hadoop-client/libexec/shellprofile.d/hadoop-openstack.sh
DEBUG: Profiles: importing hadoopInstall/hadoop-client/libexec/shellprofile.d/hadoop-rumen.sh
DEBUG: Profiles: importing hadoopInstall/hadoop-client/libexec/shellprofile.d/hadoop-streaming.sh
DEBUG: Profiles: importing hadoopInstall/hadoop-client/libexec/shellprofile.d/hadoop-yarn.sh
{code}, What happens if you run {{yarn --config foo --daemon start --debug resourcemanager}}?

Are you setting HADOOP_CONF_DIR in one of the -env.sh files?, Also, please run the classpath command instead of resourcemanager., yarn --config /tmp/hadoopConf --daemon start --debug resourcemanager or yarn --config /tmp/hadoopConf --daemon start --debug classpath gives almost same output as sudo su - -c "hadoopInstall/hadoop-yarn-resourcemanager/sbin/yarn-daemon.sh --config /tmp/hadoopConf --debug start resourcemanager" yarn 
{code:title= yarn --config /tmp/hadoopConf --daemon start --debug resourcemanager/classpath}
yarn --config /tmp/hadoopConf --daemon start --debug resourcemanager
DEBUG: hadoop_parse_args: processing resourcemanager
DEBUG: hadoop_parse: asking caller to skip 5
DEBUG: HADOOP_CONF_DIR=/tmp/hadoopConf
DEBUG: shellprofiles: hadoopInstaller/hadoop-client/libexec/shellprofile.d/hadoop-aliyun.sh hadoopInstaller/hadoop-client/libexec/shellprofile.d/hadoop-archive-logs.sh hadoopInstaller/hadoop-client/libexec/shellprofile.d/hadoop-archives.sh hadoopInstaller/hadoop-client/libexec/shellprofile.d/hadoop-aws.sh hadoopInstaller/hadoop-client/libexec/shellprofile.d/hadoop-azure-datalake.sh hadoopInstaller/hadoop-client/libexec/shellprofile.d/hadoop-azure.sh hadoopInstaller/hadoop-client/libexec/shellprofile.d/hadoop-distcp.sh hadoopInstaller/hadoop-client/libexec/shellprofile.d/hadoop-extras.sh hadoopInstaller/hadoop-client/libexec/shellprofile.d/hadoop-gridmix.sh hadoopInstaller/hadoop-client/libexec/shellprofile.d/hadoop-hdfs.sh hadoopInstaller/hadoop-client/libexec/shellprofile.d/hadoop-httpfs.sh hadoopInstaller/hadoop-client/libexec/shellprofile.d/hadoop-kafka.sh hadoopInstaller/hadoop-client/libexec/shellprofile.d/hadoop-kms.sh hadoopInstaller/hadoop-client/libexec/shellprofile.d/hadoop-mapreduce.sh hadoopInstaller/hadoop-client/libexec/shellprofile.d/hadoop-openstack.sh hadoopInstaller/hadoop-client/libexec/shellprofile.d/hadoop-rumen.sh hadoopInstaller/hadoop-client/libexec/shellprofile.d/hadoop-streaming.sh hadoopInstaller/hadoop-client/libexec/shellprofile.d/hadoop-yarn.sh
{code}

 sudo su - -c "/usr/hdp/current/hadoop-yarn-resourcemanager/sbin/yarn-daemon.sh --config /tmp/hadoopConf start classpath" yarn does not have "DEBUG: HADOOP_CONF_DIR=/tmp/hadoop"  or "DEBUG: Profiles: importing /tmp/hadoop/"


Yes we set HADOOP_CONF_DIR in our env.sh file
, The classpath output is important because one of the first entries should be the HADOOP_CONF_DIR.  We won't see that in the direct output of the resourcemanager subcommand.  (It might be in the daemon's .out file though.  I can't remember.)

bq. "DEBUG: Profiles: importing /tmp/hadoop/"

If this is missing, then that likely means your copy of the config directory is incomplete.  Likely a result of cp -p * instead of cp -pr *.

But anyway...

bq. Yes we set HADOOP_CONF_DIR in our env.sh file

There's the problem then.  Remove it.  Setting HADOOP_CONF_DIR in \*-env.sh effectively resets the config directory back to wherever it is set. It acts as an *override* to the --config option in 3.x.

One other note.  The command you've provided for starting the resourcemanager is probably the hardest way to start the RM in 3.x . :)  You can set YARN_RESOURCEMANAGER_USER=yarn in hadoop-env/yarn-env.sh and then just use {{yarn --daemon start resourcemanager}} as root.  It will switch users for you prior to start., bq. There's the problem then. Remove it. Setting HADOOP_CONF_DIR in *-env.sh effectively resets the config directory back to wherever it is set. It acts as an override to the --config option in 3.x.
In 2.x, --config takes precedence over the environment variables and -env.sh. Why did that have to change in 3.x?, It's effectively a bug in 2.x and lower.

Let's break this down to it's components:

etc/hadoop/x has a working config that includes HADOOP_CONF_DIR definition that points to etc/hadoop

user copies etc/hadoop to tmp/config and changes something else.  HADOOP_CONF_DIR remains etc/hadoop.  That's a problem because HADOOP_CONF_DIR isn't actually etc/hadoop anymore....

This is especially problematic for 3rd parties.  They might read hadoop-env.sh directly and not have the logic in 2.x's hadoop-config.sh to know that the HADOOP_CONF_DIR value is a lie.  In 3.x, users either need to a) make sure that they aren't lying to the system by keeping HADOOP_CONF_DIR truthful or b) not set it at all in the env files., bq. There's the problem then. Remove it. Setting HADOOP_CONF_DIR in *-env.sh effectively resets the config directory back to wherever it is set. It acts as an override to the --config option in 3.x.
Why setting HADOOP_CONF_DIR in env is supposed to override --config specified in yarn or hadoop CLI? This will be a regression since 2.x as existing Hadoop user (and cluster management tools) will get affected.

Set back to blocker for 3.0 beta., It's not a regression since the patch that changed the behavior was specifically marked as an incompatible change. , Closing as not a bug. Working as designed., I have, however, opened HADOOP-14781 to signify that we should clarify the documentation around this.  (Because setting HADOOP_CONF_DIR in hadoop-env.sh isn't productive in any version of Hadoop.), I am not sure if everyone would agree that it is by design at least I am not convinced yet. I tried to understand why we give up this old behavior and what trade-off we get in here as this significantly change the old behavior that work well in production. We shouldn't assume that this is a new major branch/release so we just break everything for free (or just marking as incompatible, and put a line of document). We should also ask why we break this for and also challenge if it deserves to break it. Otherwise, deploying/upgrading Hadoop 3 will be a nightmare for many of Hadoop users.
Let's keep it open for discussion before we make an agreement. I also want to hear what others want to say., bq. I am not sure if everyone would agree that it is by design at least I am not convinced yet.

As the person who designed and wrote the code in trunk, yes, it is working as intended.  

The problem is one of consistency.  There are a ton of different ways that HADOOP_CONF_DIR can get set:  external vs. internal, --config vs. no option on CLI, HADOOP_CONF_DIR manual vs. auto-discovered (2-3 ways), present in hadoop-env.sh vs. not, present but correct vs. present and incorrect, etc ...  branch-2's behavior when going through this is matrix is wildly unpredictable.  (and let's ignore's YARN_CONF_DIR because it just makes things worse and gets us too far into the weeds)

Here's a fun experiment to show my point.  Unpack a new 2.8.1 tar ball.  Set HADOOP_CONF_DIR in hadoop-2.8.1/etc/hadoop/hadoop-env.sh to something incorrect like /bin.  Now run hadoop classpath.

You'll find it starts out as "/bin".

Is that an incorrect behavior? 

On the one hand: yes, HADOOP_CONF_DIR is pointed to a wrong location.  But on the other:  no, the user explicitly told the system that it wanted /bin as the configuration directory.  branch-2 decided that in this instance /bin was correct and went forward.

Is that example different than when --config is used to point to that exact same misconfigured directory? Yes. branch-2's code decided that it was going to ignore what was in the configuration directory as told to us by the user.

Should that behavior be different?

My argument is no:  the system should not suddenly decide the user was incorrect in one instance vs. another. It absolutely must act predictably.  The user is expressly passing us a configuration directory that tells us our configuration is actually in a different directory--very much a misconfiguration.  The system accepts that as truth and moves on.

It's also worthwhile pointing out that 3.x adds a powerful wrinkle here:  .hadoop-env allows the user to specify a different HADOOP_CONF_DIR, overwriting the installed one.  Here, redirection is key.

If you don't like the current behavior, there are only two ways out.  (Let's be clear: I'll reject any patch that continues branch-2's inconsistent behavior.)

* Option 1: always ignore HADOOP_CONF_DIR when set in hadoop-env.sh

If the code is reading hadoop-env.sh, then HADOOP_CONF_DIR is superfluous. It's only used at that point is to give a different set of directories to act as replacements for the files present in this one.

* Option 2: throw a warning

After reading hadoop-env.sh, detect if the value of HADOOP_CONF_DIR changed (after calculating the full path to deal with symbolic links, etc.).  If it did, throw a warning up and then either accept the new value (current behavior) or ignore it (see option 1)., bq. Is that example different than when --config is used to point to that exact same misconfigured directory? Yes. branch-2's code decided that it was going to ignore what was in the configuration directory as told to us by the user.


Actually, I'm wrong.  branch-2 does exactly what trunk does:

{code}
hadoop-2.8.1 aw$ grep HADOOP_CONF_DIR etc/hadoop/hadoop-env.sh
export HADOOP_CONF_DIR=/bin
hadoop-2.8.1 aw$ bin/hadoop --config etc/hadoop classpath
/bin:/private/tmp/hadoop-2.8.1/share/hadoop/common/lib/*: 
...
{code}

So the behavior is exactly the same..., Closing this again given the behavior is actually the same given the same configs., I tried all 4 ways of config in HADOOP 2.7.3, 2.8.1 and 3.0.0-beta:
1. export HADOOP_CONF_DIR=/tmp/hadoop-config-1
2. In hadoop-env.sh: "export HADOOP_CONF_DIR=/tmp/hadoop-config-2"
3. pass --config /tmp/hadoop-config-3 on command line.
4. create a conf directory in HADOOP_HOME where bin/hadoop exists

And here comes the results:

||Scenario||Apache 2.7.3 result||Apache 2.8.1 result||Apache 3 result||
|Only (1)|work|work|work|
|Only (2)|work|work|work|
|Only (3)|work|work|work|
|Only (4)|work|work|work|
|Both (1) and (2)|1 effective|1 effective|1 effective|
|Both (2) and (3)|3 effective|3 effective|3 effective|
|Both (1) and (3)|3 effective|3 effective|3 effective|
|All (1), (2), (3)|3 effective|3 effective| 3 effective|
|Any of (1) / (2) / (3) with (4)|(1)(3) is higher than (4), (2) is lowest|(1)(3) is higher than (4), (2) is lowest|(1)(3) is higher than (4), (2) is lowest|
|All (1), (2), (3), (4)|(3)|(3)|(3)|

Based on results above, I think this shouldn't be an issue for Hadoop 3 beta.]