[Ideally, UPDATE_INTERVAL should be calculated based on current number of entries in queue. Another workaround is making UPDATE_INTERVAL configurable. Attached patch takes the latter approach, because it's easy to implement., Attached stack trace when we faced the problem., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12656305/rm-stack-trace.txt
  against trunk revision .

    {color:red}-1 patch{color}.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-YARN-Build/4347//console

This message is automatically generated., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12656304/YARN-2313.1.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:red}-1 findbugs{color}.  The patch appears to introduce 1 new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager:

                  org.apache.hadoop.yarn.server.resourcemanager.webapp.TestRMWebServices
                  org.apache.hadoop.yarn.server.resourcemanager.webapp.TestRMWebServicesCapacitySched
                  org.apache.hadoop.yarn.server.resourcemanager.webapp.TestRMWebServicesDelegationTokens
                  org.apache.hadoop.yarn.server.resourcemanager.webapp.TestRMWebServicesAppsModification
                  org.apache.hadoop.yarn.server.resourcemanager.webapp.TestRMWebServicesNodes
                  org.apache.hadoop.yarn.server.resourcemanager.webapp.TestRMWebServicesApps
                  org.apache.hadoop.yarn.server.resourcemanager.webapp.TestRMWebServicesFairScheduler

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-YARN-Build/4346//testReport/
Findbugs warnings: https://builds.apache.org/job/PreCommit-YARN-Build/4346//artifact/trunk/patchprocess/newPatchFindbugsWarningshadoop-yarn-server-resourcemanager.html
Console output: https://builds.apache.org/job/PreCommit-YARN-Build/4346//console

This message is automatically generated., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12656316/YARN-2313.1.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:red}-1 findbugs{color}.  The patch appears to introduce 1 new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-YARN-Build/4348//testReport/
Findbugs warnings: https://builds.apache.org/job/PreCommit-YARN-Build/4348//artifact/trunk/patchprocess/newPatchFindbugsWarningshadoop-yarn-server-resourcemanager.html
Console output: https://builds.apache.org/job/PreCommit-YARN-Build/4348//console

This message is automatically generated., Fixed the warning by findbugs., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12656429/YARN-2313.2.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:red}-1 findbugs{color}.  The patch appears to introduce 1 new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-YARN-Build/4355//testReport/
Findbugs warnings: https://builds.apache.org/job/PreCommit-YARN-Build/4355//artifact/trunk/patchprocess/newPatchFindbugsWarningshadoop-yarn-server-resourcemanager.html
Console output: https://builds.apache.org/job/PreCommit-YARN-Build/4355//console

This message is automatically generated., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12656445/YARN-2313.3.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager:

                  org.apache.hadoop.yarn.server.resourcemanager.webapp.TestRMWebServices
                  org.apache.hadoop.yarn.server.resourcemanager.applicationsmanager.TestAMRestart
                  org.apache.hadoop.yarn.server.resourcemanager.webapp.TestRMWebServicesCapacitySched
                  org.apache.hadoop.yarn.server.resourcemanager.webapp.TestRMWebServicesDelegationTokens
                  org.apache.hadoop.yarn.server.resourcemanager.webapp.TestRMWebServicesAppsModification
                  org.apache.hadoop.yarn.server.resourcemanager.webapp.TestRMWebServicesNodes
                  org.apache.hadoop.yarn.server.resourcemanager.webapp.TestRMWebServicesApps
                  org.apache.hadoop.yarn.server.resourcemanager.webapp.TestRMWebServicesFairScheduler

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-YARN-Build/4356//testReport/
Console output: https://builds.apache.org/job/PreCommit-YARN-Build/4356//console

This message is automatically generated., Thanks for reporting this [~ozawa].

A couple nits:
* The new configuration should be defined in FairSchedulerConfiguration like other fair scheduler props
* If I understand correctly, the race described in the findbugs could never actually happen.  For code readability, I think it's better to add a findbugs exclude than an unnecessary synchronization.
* In the warning, replace "use" with "using"
* Extra space after DEFAULT_RM_SCHEDULER_FS_UPDATE_INTERVAL_MS

Eventually, I think we should try to be smarter about the work that goes on in update().  In most cases, the fair shares will stay the same, or will only change for apps in a particular queue, so we can avoid recomputation., Thanks for the review, [~sandyr].

Updated a patch:
* Moved new configuration definition to FairSchedulerConfiguration.
* Excluded warning by updateInterval.
* Replaced warning message "use" with "using"
* Removed trailing spaces.
 , {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12656855/YARN-2313.4.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager:

                  org.apache.hadoop.yarn.server.resourcemanager.webapp.TestRMWebServices
                  org.apache.hadoop.yarn.server.resourcemanager.webapp.TestRMWebServicesCapacitySched
                  org.apache.hadoop.yarn.server.resourcemanager.webapp.TestRMWebServicesDelegationTokens
                  org.apache.hadoop.yarn.server.resourcemanager.webapp.TestRMWebServicesAppsModification
                  org.apache.hadoop.yarn.server.resourcemanager.webapp.TestRMWebServicesNodes
                  org.apache.hadoop.yarn.server.resourcemanager.webapp.TestRMWebServicesApps
                  org.apache.hadoop.yarn.server.resourcemanager.webapp.TestRMWebServicesFairScheduler

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-YARN-Build/4382//testReport/
Console output: https://builds.apache.org/job/PreCommit-YARN-Build/4382//console

This message is automatically generated., The test failure is not related., +1, Pushed to trunk and branch-2 and added a note of documentation on commit., FAILURE: Integrated in Hadoop-trunk-Commit #5948 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/5948/])
YARN-2313. Livelock can occur in FairScheduler when there are lots of running apps (Tsuyoshi Ozawa via Sandy Ryza) (sandy: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1612769)
* /hadoop/common/trunk/hadoop-yarn-project/CHANGES.txt
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/dev-support/findbugs-exclude.xml
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FairScheduler.java
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FairSchedulerConfiguration.java
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/TestFairSchedulerPreemption.java
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-site/src/site/apt/FairScheduler.apt.vm
, Sorry for coming in late here. Didn't see this before.

I think we need a better solution here. Otherwise, clusters will continue to run into this. 

One simple way to address this could be to wait {{updateInterval}} ms after finishing an iteration of update-thread before starting the next iteration. We should do something similar for the continuous thread as well. , Actually, thinking more about it, I don't quite understand how the update-thread can go into a busy loop. Thread.sleep() and update are called serially. So, irrespective of how long update() takes the next Thread.sleep is called for 500 ms, no? 

It is possible that these 500 ms are not enough for other work and the scheduler lags, but should still make progress. , FAILURE: Integrated in Hadoop-Yarn-trunk #621 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/621/])
YARN-2313. Livelock can occur in FairScheduler when there are lots of running apps (Tsuyoshi Ozawa via Sandy Ryza) (sandy: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1612769)
* /hadoop/common/trunk/hadoop-yarn-project/CHANGES.txt
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/dev-support/findbugs-exclude.xml
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FairScheduler.java
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FairSchedulerConfiguration.java
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/TestFairSchedulerPreemption.java
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-site/src/site/apt/FairScheduler.apt.vm
, Hi Karthik, thank you for pointing it out.

{quote}
 So, irrespective of how long update() takes the next Thread.sleep is called for 500 ms, no?
{quote}

You're correct. The description "go busy loop" is wrong. But there still remains starvation problem:

1. {{FairScheduler#update()}} can take more than 10 sec, default value of reloadIntervalMs, with lock.
2. {{AllocationFileLoaderThread#onReload}} can take more than 500 ms, default value of updateInterval, with lock.
3. As a result, {{FairScheduler#update()}} and {{FairScheduler#onReload}} can always wins lock of the instance of {{FairScheduler}}.
4. {{ResourceManager$SchedulerEventDispatcher}} can wait forever.

The problem we faced was that cluster(note that it's very busy cluster!) hung up even after killing exist apps. I got the stack trace when we faced the problem. In our case, we can avoid the problem by setting the configuration value(updateInterval) larger. IIUC, it's because we can have the margin that ResourceManager$SchedulerEventDispatcher acquire lock. 

As you mentioned, this fix is just a workaround. However, it's effective. More essential way is making updateInterval and reloadIntervalMs dynamic. Please correct me if I'm wrong. , FAILURE: Integrated in Hadoop-Hdfs-trunk #1813 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1813/])
YARN-2313. Livelock can occur in FairScheduler when there are lots of running apps (Tsuyoshi Ozawa via Sandy Ryza) (sandy: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1612769)
* /hadoop/common/trunk/hadoop-yarn-project/CHANGES.txt
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/dev-support/findbugs-exclude.xml
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FairScheduler.java
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FairSchedulerConfiguration.java
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/TestFairSchedulerPreemption.java
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-site/src/site/apt/FairScheduler.apt.vm
, SUCCESS: Integrated in Hadoop-Mapreduce-trunk #1840 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1840/])
YARN-2313. Livelock can occur in FairScheduler when there are lots of running apps (Tsuyoshi Ozawa via Sandy Ryza) (sandy: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1612769)
* /hadoop/common/trunk/hadoop-yarn-project/CHANGES.txt
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/dev-support/findbugs-exclude.xml
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FairScheduler.java
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FairSchedulerConfiguration.java
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/TestFairSchedulerPreemption.java
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-site/src/site/apt/FairScheduler.apt.vm
, Thanks for the explanation, [~ozawa]. I see the issue clearly now. 

In that case, a better approach might be to have a single "maintenance" thread that periodically executes a bunch of runnables (reload, update, continuous-scheduling) serially. Otherwise, as we add more threads that hold onto the scheduler lock, it will be hairy to tune all of them so the scheduler can make some meaningful progress. , [~kkambatl], thank you for your suggestion. It sounds reasonable and good to me. I'll open new JIRA to address maintenance thread., [~ozawa] - thanks. I have started looking at it and we can do it on YARN-2328. I hope you haven't also started working on it. , Great. I'll check it.]