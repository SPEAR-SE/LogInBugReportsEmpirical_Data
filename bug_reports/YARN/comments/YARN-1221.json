[Sandy, we're seeing the same. At some point there is an overflow and numbers even show negative.
Looks like we have to first turn on logging for the FS so that we see more messages and figure out what is going on.
Code looked like this may be when reserved containers go into allocated, but the metric is not updated, or there is some synchronization issue with that update or something., According to the fairsheduler log,
2013-09-23 17:32:30,593	ASSIGN	atla-aub-37-sr1.prod.twttr.net	<memory:2048, vCores:1>
2013-09-23 17:32:35,591	ASSIGN	atla-aub-37-sr1.prod.twttr.net	<memory:4096, vCores:1>
2013-09-23 17:32:36,595	ASSIGN	atla-aub-37-sr1.prod.twttr.net	<memory:4096, vCores:1>
2013-09-23 17:32:37,598	ASSIGN	atla-aub-37-sr1.prod.twttr.net	<memory:4096, vCores:1>
2013-09-23 17:32:38,602	ASSIGN	atla-aub-37-sr1.prod.twttr.net	<memory:4096, vCores:1>
2013-09-23 17:32:39,606	ASSIGN	atla-aub-37-sr1.prod.twttr.net	<memory:4096, vCores:1>
2013-09-23 17:32:43,622	ASSIGN	atla-aub-37-sr1.prod.twttr.net	<memory:2048, vCores:1>
2013-09-23 17:32:48,640	ASSIGN	atla-aub-37-sr1.prod.twttr.net	<memory:4096, vCores:1>
2013-09-23 17:32:49,647	ASSIGN	atla-aub-37-sr1.prod.twttr.net	<memory:-1, vCores:0>
2013-09-23 17:33:11,213	ASSIGN	atla-aub-37-sr1.prod.twttr.net	<memory:4096, vCores:1>
2013-09-23 17:33:11,245	ASSIGN	atla-aub-37-sr1.prod.twttr.net	<memory:-1, vCores:0>
2013-09-23 17:33:13,221	ASSIGN	atla-aub-37-sr1.prod.twttr.net	<memory:4096, vCores:1>

the -1 might be the problem, it should be 4096 and the vCores should be 1 instead of 0.
I tried several times, if the log has only one <memory:-1, vCores:0>, the reserved memory will be 4G after all the jobs done, and if the log has two <memory:-1, vCores:0>, the reserved memory will be 8G after all the jobs done., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12605119/YARN1221_v1.patch.txt
  against trunk revision .

    {color:red}-1 patch{color}.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-YARN-Build/2017//console

This message is automatically generated., {code}
-    this.totalMB = availableMB + reservedMB + allocatedMB;
+    this.totalMB = availableMB;
{code}
Total MB should still include allocatedMB.  I agree that reservedMB should be removed from it, but I think this is work for a separate JIRA.  This one is for dealing with why reservedMB is calculated incorrectly.

{code}
-      getMetrics().reserveResource(app.getUser(),
-          container.getResource());
{code}
Can you explain the rationale behind removing this?, inside the reserve method, there are two methods got called
{noformat}
getMetrics().reserveResource(application.getUser(), container.getResource());
getMetrics().reserveResource(app.getUser(), container.getResource());
{noformat}
application.getUser() and app.getUser() return the same user. Therefore, the same metrics get increased twice.

However, inside the unreserve method, there is only one method got called
{noformat}
getMetrics().unreserveResource(application.getUser(), rmContainer.getContainer().getResource()); {noformat}
In conclusion, the reserved memory gets increased twice and decreased only once.

As for the displayed total memory, it should equal to available memory. Since, the available memory is actually the total memory, and it will not decrease when some memory is allocated to mr jobs, {code}
-      getMetrics().reserveResource(app.getUser(),
-          container.getResource());
{code}

The reason I removed the code above is that there is no corresponding
unreserve method got called. In addition, app.getUser() and
application.getUser() return the same user.

Maybe we could add getMetrics().unreserveResource(app.getUser(),
container.getResource());
into corresponding unreserve block.

As far as I saw from the webUI, the available memory never get decremented
when it allocates memory to mr jobs. It actually reflects the totally
memory




, bq. The reason I removed the code above is that there is no corresponding unreserve method got called.
Good catch.  But that shouldn't affect the amount shown in the web UI, because the metrics for which there is double counting are the leaf queue metrics, whereas the value in the web UI is based only off of the root queue metrics.  Is that not right?

bq. As far as I saw from the webUI, the available memory never get decremented when it allocates memory to mr jobs.
Where are you seeing the available memory reported on the web UI?

To be clear, I'm referring to what's shown under the "Cluster Metrics" section when you go to http://<rmhost>:<port>/cluster, It will affect the amount shown in the web UI, since they all have a parent
QueueMetrics, which is the root queue metrics. I am not quite sure about
removing that reserve code. When I did it, the bug in web UI is gone. Maybe
we should add a corresponding unreserve method.



, bq. It will affect the amount shown in the web UI, since they all have a parent QueueMetrics, which is the root queue metrics.
Ah, you are totally right.  Also, applied your patch and the issue went away for me.

For the ClusterMetricsInfo part, I'm still not convinced in the page, I'm still not convinced on the change, but either way we should do it in a separate JIRA.

Also, are you able to add a test?  An easy way to do this might be to just find an existing test in TestFairScheduler that, without the patch, has an incorrect value of reserved MB at the end and add an assert there., I've added a unit test.
The reason I removed the following line is that application is the same object as app.  

getMetrics().reserveResource(app.getUser(),
          container.getResource());

The reason I removed the rootQueueMetrics update is that getMetrics().reserveResource and getMetrics.unreserveResource actually update the rootQueueMetrics.

As for the total memory issue, we can create another JIRA to discuss about it
, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12605362/YARN1221_v2.patch.txt
  against trunk revision .

    {color:red}-1 patch{color}.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-YARN-Build/2026//console

This message is automatically generated., Thanks [~l201514]!  Good point about the rootQueueMetrics update.  I think it's an artifact from when we didn't have hierarchical queues.

Looks like you probably need to rebase on latest trunk - do you mind removing the whitespace change on the line with the if when you do?, {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12605523/YARN1221_v3.patch.txt
  against trunk revision .

    {color:red}-1 patch{color}.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-YARN-Build/2028//console

This message is automatically generated., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12605541/YARN1221_v4.patch
  against trunk revision .

    {color:red}-1 patch{color}.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-YARN-Build/2029//console

This message is automatically generated., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12605568/YARN1221_v5.patch
  against trunk revision .

    {color:red}-1 patch{color}.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-YARN-Build/2030//console

This message is automatically generated., {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12605964/YARN1221_v6.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-YARN-Build/2041//testReport/
Console output: https://builds.apache.org/job/PreCommit-YARN-Build/2041//console

This message is automatically generated., +1, I just committed this to trunk, branch-2, and branch-2.1-beta.  Thanks Siqi!, SUCCESS: Integrated in Hadoop-trunk-Commit #4499 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/4499/])
YARN-1221. With Fair Scheduler, reserved MB reported in RM web UI increases indefinitely (Siqi Li via Sandy Ryza) (sandy: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1527794)
* /hadoop/common/trunk/hadoop-yarn-project/CHANGES.txt
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/AppSchedulable.java
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/TestFairScheduler.java
, you are welcome, FAILURE: Integrated in Hadoop-Yarn-trunk #349 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/349/])
YARN-1221. With Fair Scheduler, reserved MB reported in RM web UI increases indefinitely (Siqi Li via Sandy Ryza) (sandy: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1527794)
* /hadoop/common/trunk/hadoop-yarn-project/CHANGES.txt
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/AppSchedulable.java
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/TestFairScheduler.java
, FAILURE: Integrated in Hadoop-Hdfs-trunk #1539 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1539/])
YARN-1221. With Fair Scheduler, reserved MB reported in RM web UI increases indefinitely (Siqi Li via Sandy Ryza) (sandy: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1527794)
* /hadoop/common/trunk/hadoop-yarn-project/CHANGES.txt
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/AppSchedulable.java
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/TestFairScheduler.java
, FAILURE: Integrated in Hadoop-Mapreduce-trunk #1565 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1565/])
YARN-1221. With Fair Scheduler, reserved MB reported in RM web UI increases indefinitely (Siqi Li via Sandy Ryza) (sandy: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1527794)
* /hadoop/common/trunk/hadoop-yarn-project/CHANGES.txt
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/AppSchedulable.java
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/TestFairScheduler.java
, It seems that there is another place that leaking reserved MB.
Can anyone confirm this issue?  , Closing old tickets that are already part of a release.]