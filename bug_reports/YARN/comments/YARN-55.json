[Seems like a dup of MAPREDUCE-3796, Hi Hitesh,

If you think that MAPREDUCE-3796 will cover the test case of checking that yarn.nodemanager.resource.memory-mb >  yarn.app.mapreduce.am.resource.mb and take appropriate actions accordingly then you can close it as dup of MAPREDUCE-3796.

Thanks,
Anil Gupta, Sorry for the late reply. I dont believe that an error should be thrown when the AM requested memory is greater than the NM memory. I believe this is more of a configuration bug where the scheduler max allocation should be set such that an error is thrown for any AM requesting more than that. The RM should error out if the max scheduler allocation for a single container is less than the resources required to launch a new AM. Please let me know if you have seen something contrary to this. 

However, depending on how the scheduler max allocation is configured, there will be situations in heterogenous clusters where certain nodes may be down creating holes causing requests for large amount of resources/memory to wait for an indefinite amount of time. This is something which needs to be addressed separately and is a bit more tricky in terms of when to decide whether the allocation request cannot be fulfilled ( both from a new AM perspective or container requests by an AM ). I will file a separate jira for that.  

, File MAPREDUCE-4508 for the issue mentioned in the previous comment., Typo in previous comment - that should have bee MAPREDUCE-4578 which is now moved to YARN as YARN-56., Thanks for the update, Hitesh., Closing this as invalid. 

If an AM requests more memory than the configured maximum memory for the RM Scheduler, RM will throw an error. 

If there are no live nodes capable of handling the memory asked for, that should be looked at in YARN-56.]