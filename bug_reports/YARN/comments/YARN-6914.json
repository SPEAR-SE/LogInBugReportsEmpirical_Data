[[~bharaniabhishek123]
Looks like issue with configuration.

{code}
<property>
  <name>yarn.nodemanager.aux-services</name>
<value>mapreduce_shuffle,spark_shuffle</value>
  </property>
<property>
  <name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name>
<value>org.apache.hadoop.mapred.ShuffleHandler</value>
</property>
<property>
  <name>yarn.nodemanager.aux-services.spark_shuffle.class</name>
<value>org.apache.spark.network.yarn.YarnShuffleService</value>
  </property>
{code}

Please contact in user mailing list for questions and discussion. user@hadoop.apache.org, Updated the configuration as above, I am still getting the same error.
 , No info from the NM logs too ?, Below is the information from NM Logs :

2017-08-01 10:19:50,510 ERROR org.apache.spark.network.util.LevelDBProvider: error opening leveldb file /usr/local/hadoop/tmp/nm-local-dir/registeredExecutors.ldb.  Creating new file, will not be able to recover state for existing applications
org.fusesource.leveldbjni.internal.NativeDB$DBException: IO error: /usr/local/hadoop/tmp/nm-local-dir/registeredExecutors.ldb/LOCK: No such file or directory
	at org.fusesource.leveldbjni.internal.NativeDB.checkStatus(NativeDB.java:200)
	at org.fusesource.leveldbjni.internal.NativeDB.open(NativeDB.java:218)
	at org.fusesource.leveldbjni.JniDBFactory.open(JniDBFactory.java:168)
	at org.apache.spark.network.util.LevelDBProvider.initLevelDB(LevelDBProvider.java:48)
	at org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.<init>(ExternalShuffleBlockResolver.java:116)
	at org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.<init>(ExternalShuffleBlockResolver.java:94)
	at org.apache.spark.network.shuffle.ExternalShuffleBlockHandler.<init>(ExternalShuffleBlockHandler.java:65)
	at org.apache.spark.network.yarn.YarnShuffleService.serviceInit(YarnShuffleService.java:166)
	at org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices.serviceInit(AuxServices.java:143)
	at org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)
	at org.apache.hadoop.service.CompositeService.serviceInit(CompositeService.java:107)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.serviceInit(ContainerManagerImpl.java:245)
	at org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)
	at org.apache.hadoop.service.CompositeService.serviceInit(CompositeService.java:107)
	at org.apache.hadoop.yarn.server.nodemanager.NodeManager.serviceInit(NodeManager.java:261)
	at org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)
	at org.apache.hadoop.yarn.server.nodemanager.NodeManager.initAndStartNodeManager(NodeManager.java:495)
	at org.apache.hadoop.yarn.server.nodemanager.NodeManager.main(NodeManager.java:543)
2017-08-01 10:19:50,511 WARN org.apache.spark.network.util.LevelDBProvider: error deleting /usr/local/hadoop/tmp/nm-local-dir/registeredExecutors.ldb
2017-08-01 10:19:50,511 INFO org.apache.hadoop.service.AbstractService: Service spark_shuffle failed in state INITED; cause: java.io.IOException: Unable to create state store
java.io.IOException: Unable to create state store
	at org.apache.spark.network.util.LevelDBProvider.initLevelDB(LevelDBProvider.java:77)
	at org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.<init>(ExternalShuffleBlockResolver.java:116)
	at org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.<init>(ExternalShuffleBlockResolver.java:94)
	at org.apache.spark.network.shuffle.ExternalShuffleBlockHandler.<init>(ExternalShuffleBlockHandler.java:65)
	at org.apache.spark.network.yarn.YarnShuffleService.serviceInit(YarnShuffleService.java:166)
	at org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices.serviceInit(AuxServices.java:143)
	at org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)
	at org.apache.hadoop.service.CompositeService.serviceInit(CompositeService.java:107)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.serviceInit(ContainerManagerImpl.java:245)
	at org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)
	at org.apache.hadoop.service.CompositeService.serviceInit(CompositeService.java:107)
	at org.apache.hadoop.yarn.server.nodemanager.NodeManager.serviceInit(NodeManager.java:261)
	at org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)
	at org.apache.hadoop.yarn.server.nodemanager.NodeManager.initAndStartNodeManager(NodeManager.java:495)
	at org.apache.hadoop.yarn.server.nodemanager.NodeManager.main(NodeManager.java:543)
Caused by: org.fusesource.leveldbjni.internal.NativeDB$DBException: IO error: /usr/local/hadoop/tmp/nm-local-dir/registeredExecutors.ldb/LOCK: No such file or directory
	at org.fusesource.leveldbjni.internal.NativeDB.checkStatus(NativeDB.java:200)
	at org.fusesource.leveldbjni.internal.NativeDB.open(NativeDB.java:218)
	at org.fusesource.leveldbjni.JniDBFactory.open(JniDBFactory.java:168)
	at org.apache.spark.network.util.LevelDBProvider.initLevelDB(LevelDBProvider.java:75)
	... 15 more
2017-08-01 10:19:50,513 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl:  Using ResourceCalculatorPlugin : null
, Hi [~bharaniabhishek123],
Generally the approach which is followed is raise your issue in the forum and if in the forum it gets confirmed to be a defect then raise it in jira. Please ensure next time we follow this procedure else every query will become a jira !
Will close this issue, please raise this in the forum and if required lets reopen this issue.

And coming to the logs, has the NM started ? seems to be a spark issue may be you can check in the spark forum.
One possible reason would be spark aux service leveldb files might have got corrupted, if not production cluster please empty/backup the dir " /usr/local/hadoop/tmp/nm-local-dir/"  and then try.




, Sure [~naganarasimha_gr@apache.org], Thank you for your support !
I didn't knew that we first need to raise issues in forums.  I raised this issue on other forums like stack overflow but din't received any response..
Could you please provide the link to the forum. , Sorry i meant Hadoop mailing list, refer all mailing lists @ https://hadoop.apache.org/mailing_lists.html
you can send mail to user@hadoop.apache.org
but seems like spark issue, so first you could try what i suggested if not a prod setup.]