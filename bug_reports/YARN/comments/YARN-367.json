[Hi, Zhijie.  I was able to reproduce this bug.  When overriding hadoop.tmp.dir, typical usage is to specify it in core-site.xml instead of hdfs-site.xml, so that all of the Hadoop processes receive the new value.  After I moved my configuration of hadoop.tmp.dir to core-site.xml, I stopped seeing this bug.

When I repro'd, I noticed that localization is attempting to use the default local dir for usercache, but then container launch is trying to use the local dir I configured in hdfs-site.xml.  Therefore, container launch doesn't find the container working directory in the place it expects:

2013-01-31 09:02:28,623 INFO  nodemanager.DefaultContainerExecutor (DefaultContainerExecutor.java:startLocalizer(101)) - CWD set to /tmp/hadoop-chris/nm-local-dir/usercache/chris/appcache/application_1359651644148_0002 = file:/tmp/hadoop-chris/nm-local-dir/usercache/chris/appcache/application_1359651644148_0002

2013-01-31 09:02:29,922 WARN  launcher.ContainerLaunch (ContainerLaunch.java:call(247)) - Failed to launch container.
java.io.FileNotFoundException: File /Users/chris/hadoop-deploy-trunk/hadoop-3.0.0-SNAPSHOT/data/nm-local-dir/usercache/chris/appcache/application_1359651644148_0002/container_1359651644148_0002_01_000001 does not exist

My theory is that configuration is getting loaded in 2 different ways for localization and container launch.  The configuration for localization is not loading hdfs-site.xml, but the configuration for container launch is loading hdfs-site.xml, so the 2 pieces are seeing different configurations.  I'm not sure if YARN daemons should be loading hdfs-site.xml.  Whatever the choice, it probably should be consistent throughout the code.

This would be good to track down eventually, but for now, I expect you can quickly fix your environment by moving your hadoop.tmp.dir configuration into core-site.xml.  I hope this helps!
, This is great, I was actually about to do the same thing. there are a number of settings in the confs that I am sure after doing 3 installs in a row according to the instructions online of Hadoop 2.0.x and having wierd conf things that result in errors just like this. The AM Container failure never reports a good exception message, and sometimes even the nodemanager logs of the job attempt are not very specific due to the nature of the missing config, or ...?

Point being, its almost always a config setting, and the framework almost never provides a clue other than job start and immediate failure (outfile not found as in Zhijie's example here, or more cryptic) as to what really made it choke.
, bq. Below is the setting in hdfs-site.xml.
bq. <name>hadoop.tmp.dir</name>

*This.* hadoop.tmp.dir is not supposed to be in there if you want to reuse it for YARN too. It should be in core-site.xml, YARN won't read hdfs-default.xml for any of *its* configs. Closing this as invalid.

Zhijie/Eli, can one of you validate if the AM container launch is correctly reported or not here and file a corresponding ticket?

Eli, can you file more tickets so that we can track any other individual bugs (besides this) you might have run into? Thanks!, Closing this as invalid as per my comment above. Please reopen if you disagree., @Vinod, I've verified it. hadoop.tmp.dir was visible to YARN when it was put into core-site.xml, and the exception was gone., I will look back at my notes and my final GIRAPH-13 patch now that its working and ready for review. I have been saving up some issues to put up until the patch was done and verified and I knew it wasn't just my fault for errors!

Got a few funny things like this to put up. There were a couple things that were documented as optional or not required to get the YARN cluster up but if they weren't set in yarn-site or core-site (etc) the cluster just never worked for me on several 2.0.x Hadoop on OSX. So I'll post some things coming up in the next few days here.
]