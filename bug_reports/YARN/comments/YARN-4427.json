[Marking as critical since {{Nodemanger}} will not be able register to RM. 
 *Trace In NM* 
{noformat}
2015-12-05 16:17:29,384 | ERROR | Thread-6943 | Unexpected error rebooting NodeStatusUpdater | NodeStatusUpdaterImpl.java:276
java.lang.NullPointerException: java.lang.NullPointerException
        at org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService.handleNMContainerStatus(ResourceTrackerService.java:286)
        at org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService.registerNodeManager(ResourceTrackerService.java:395)
        at org.apache.hadoop.yarn.server.api.impl.pb.service.ResourceTrackerPBServiceImpl.registerNodeManager(ResourceTrackerPBServiceImpl.java:54)
        at org.apache.hadoop.yarn.proto.ResourceTracker$ResourceTrackerService$2.callBlockingMethod(ResourceTracker.java:79)
        at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:973)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2088)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2084)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:422)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1673)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2082)
        
        at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
        at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) 
        at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
        at org.apache.hadoop.yarn.ipc.RPCUtil.instantiateException(RPCUtil.java:53)
        at org.apache.hadoop.yarn.ipc.RPCUtil.instantiateRuntimeException(RPCUtil.java:85)
        at org.apache.hadoop.yarn.ipc.RPCUtil.unwrapAndThrowException(RPCUtil.java:122)
        at org.apache.hadoop.yarn.server.api.impl.pb.client.ResourceTrackerPBClientImpl.registerNodeManager(ResourceTrackerPBClientImpl.java:70)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:497)     
        at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
        at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
        at com.sun.proxy.$Proxy78.registerNodeManager(Unknown Source)
        at org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.registerWithRM(NodeStatusUpdaterImpl.java:313)
{noformat}

Adding {{masterContainer != null}} ResourceTrackerService#handleNMContainerStatus, should be fine I think.. anythoughts on this..?, IIUC, {{masterContainer}} never be null since NM is reporting the containers status which means RM has containers status. Can you share the logs? And can you give more details about the issue., NM recovery is enabled, this is the precondition, [~rohithsharma] thanks a for taking a look into this issue..Yes, {{masterContainer}} is null,even I thought {{rmAppAttempt}} can be null,but it is not in this cluster.

{code}  
    RMAppAttempt rmAppAttempt = rmApp.getRMAppAttempt(appAttemptId);
    Container masterContainer = rmAppAttempt.getMasterContainer();
    if ((masterContainer.getId().equals(containerStatus.getContainerId())) && (containerStatus.getContainerState() == ContainerState.COMPLETE))
{code} 

 *Cause :*  As I mentioned in the description,ZK Cluster was up and down which makes frequent leader election..Thinking RM written znode with ZK1 and while recovering reading from ZK2 where data is not synced(Here master container details missed). 

 Please correct me if I am wrong.., Thanks [~brahma] for the details.
During recovery of AppAttempt, {{masterContainer}} can be null only if the AttemptState doesn't have and its very unlikely. if ZK was unstable, do you mean a partial recovery has happened here for AppAttempt where {{masterContainer}} is null?
Could you also pls share the final state of that attempt during recovery.
, [~sunilg] Thanks for taking a look into this issue.. final state was null.. 

 *Resource Manger Log:* 
{noformat}
2015-12-05 15:22:00,780 | INFO  | main-EventThread | Recovering app: application_1449190041506_0175 with 0 attempts and final state = null | RMAppImpl.java:790
2015-12-05 15:26:12,433 | INFO  | main-EventThread | Recovering app: application_1449190041506_0175 with 0 attempts and final state = null | RMAppImpl.java:790
2015-12-05 15:32:46,810 | INFO  | main-EventThread | Recovering app: application_1449190041506_0175 with 0 attempts and final state = null | RMAppImpl.java:790
2015-12-05 15:45:33,199 | INFO  | main-EventThread | Recovering app: application_1449190041506_0175 with 0 attempts and final state = null | RMAppImpl.java:790
2015-12-05 16:11:41,556 | INFO  | main-EventThread | Recovering app: application_1449190041506_0175 with 0 attempts and final state = null | RMAppImpl.java:790
2015-12-05 16:14:28,228 | INFO  | AsyncDispatcher event handler | Storing attempt: AppId: application_1449190041506_0175 AttemptId: appattempt_1449190041506_0175_000001 MasterContainer: Container: [ContainerId: container_1449190041506_0175_01_000001, NodeId: 9-91-8-220:26009, NodeHttpAddress: 9-91-8-220:26010, Resource: <memory:1536, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: **.**.**.220:26009 }, ] | RMAppAttemptImpl.java:1959
2015-12-05 16:17:26,811 | INFO  | main-EventThread | Recovering app: application_1449190041506_0175 with 0 attempts and final state = null | RMAppImpl.java:790
{noformat}

 *ZNode Creation:* 

{noformat}
2015-12-05 16:14:28,241 | INFO  | CommitProcWorkThread-38 | session=0x130006c883cb000d	ip=**.**.**.217	operation=create znode	target=ZooKeeperServer	znode=/rmstore/ZKRMStateRoot/RMAppRoot/application_1449190041506_0175/appattempt_1449190041506_0175_000001	result=success | org.apache.zookeeper.ZKAuditLogger$LogLevel$5.printLog(ZKAuditLogger.java:70)
{noformat}

 *RM Frequent connections to different ZK:* 

{noformat}
2015-12-05 16:15:46,240 | INFO  | main-SendThread(9-91-8-217:24002) | Socket connection established, initiating session, client: /**.**.**.217:53843, server: host-217/**.**.**.217:24002 | ClientCnxn.java:1021
2015-12-05 16:15:46,810 | INFO  | main-SendThread(host-208:24002) | Socket connection established, initiating session, client: /**.**.**.217:46137, server: host-208/**.**.**.208:24002 | ClientCnxn.java:1021
2015-12-05 16:15:47,021 | INFO  | main-SendThread(host-220:24002) | Socket connection established, initiating session, client: /**.**.**.217:39488, server: host-220/**.**.**.220:24002 | ClientCnxn.java:1021
2015-12-05 16:15:47,265 | INFO  | main-SendThread(host-220:24002) | Socket connection established, initiating session, client: /**.**.**.217:39491, server: host-220/**.**.**.220:24002 | ClientCnxn.java:1021
2015-12-05 16:15:55,632 | INFO  | main-SendThread(host-218:24002) | Socket connection established, initiating session, client: /**.**.**.217:56809, server: host-218/**.**.**.218:24002 | ClientCnxn.java:1021
2015-12-05 16:16:33,619 | INFO  | main-SendThread(host-219:24002) | Socket connection established, initiating session, client: /**.**.**.217:48605, server: host-219/**.**.**.219:24002 | ClientCnxn.java:1021
2015-12-05 16:17:18,369 | INFO  | main-SendThread(host-220:24002) | Socket connection established, initiating session, client: /**.**.**.217:40376, server: host-220/**.**.**.220:24002 | ClientCnxn.java:1021
{noformat}

 *NPE In the RM:* 

{noformat}
2015-12-05 16:17:29,385 | WARN  | IPC Server handler 1 on 26003 | IPC Server handler 1 on 26003, call org.apache.hadoop.yarn.server.api.ResourceTrackerPB.registerNodeManager from **.**.**.220:49704 Call#4003 Retry#0 | Server.java:2107
java.lang.NullPointerException
	at org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService.handleNMContainerStatus(ResourceTrackerService.java:286)
	at org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService.registerNodeManager(ResourceTrackerService.java:395)
	at org.apache.hadoop.yarn.server.api.impl.pb.service.ResourceTrackerPBServiceImpl.registerNodeManager(ResourceTrackerPBServiceImpl.java:54)
	at org.apache.hadoop.yarn.proto.ResourceTracker$ResourceTrackerService$2.callBlockingMethod(ResourceTracker.java:79)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:973)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2088)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2084)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1673)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2082)
{noformat}

 *Actual problem is in ZK since data is not persisted in the cluster, for same I will check ZK..what my point is, how to handle when this occurs from RM side..?  adding null check will not solve this since container details will not be deleted from the NM.* 

 *Reproduce Scenario :* 
Just remove the appatempt from ZK and restart the cluster when application is running (ensure work preserving is disabled.)
rmr /rmstore/ZKRMStateRoot/RMAppRoot/application_1449644945944_0001/appattempt_1449644945944_0001_000001]