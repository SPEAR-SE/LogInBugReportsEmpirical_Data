[While running some tests I noticed that NodeManager does not log correct physical/virtual memory values and causes little confusion.

As shown below, even though Xmx is set to 6G log says 1.0gb physical memory configured and 2.1 virtual memory configured.
{noformat}
12/12/21 05:55:07 INFO mapreduce.Job: Task Id : attempt_1356068333956_0002_r_000039_0, Status : FAILED
Container [pid=49507,containerID=container_1356068333956_0002_01_001723] is running beyond virtual memory limits. Current usage: 63.8mb of 1.0gb physical memory used; 6.3gb of 2.1gb virtual memory used. Killing container.
Dump of the process-tree for container_1356068333956_0002_01_001723 :
        |- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
        |- 49507 39941 49507 49507 (java) 197 11 6792540160 16330 /usr/java/default/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx6048m -Djava.io.tmpdir=/data/disk2/yarn/local/usercache/hadoop/appcache/application_1356068333956_0002/container_1356068333956_0002_01_001723/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.mapreduce.container.log.dir=/data/disk6/yarn/logs/application_1356068333956_0002/container_1356068333956_0002_01_001723 -Dyarn.app.mapreduce.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild X.X.X.X 49683 attempt_1356068333956_0002_r_000039_0 1723 
{noformat}, Lohit, NodeManager keeps track of vmem and pmem directly. Xmx is only for java processes, so you will need to specify the memory values also. If this is MapReduce application over YARN that you are talking about, then you should override mapreduce.map.memory.mb and mapreduce.reduce.memory.mb.

Please close this if that works., Thanks for explanation. Closing as invalid ]