[{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12695219/YARN-3111.1.patch
  against trunk revision 03a5e04.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager:

                  org.apache.hadoop.yarn.server.resourcemanager.recovery.TestFSRMStateStore

Test results: https://builds.apache.org/job/PreCommit-YARN-Build/6453//testReport/
Console output: https://builds.apache.org/job/PreCommit-YARN-Build/6453//console

This message is automatically generated., I think test failure of "org.apache.hadoop.yarn.server.resourcemanager.recovery.TestFSRMStateStore.testFSRMStateStoreClientRetry" is not related with this patch, Hey [~kasha],
When you get a chance, can you please review this ?
Due to the spec of our instance type and our default container memory settings, we generally have lot of memory left after all the vcores are taken, and the scheduler page incorrectly shows that there is still room in the cluster even though there is none, which is misleading users., [~kasha@cloudera.com]
, When cluster capacity is 0, do we want to show the ratio as 1? Also, instead of showing the shares as a single percentage, would it make sense to show it as % mem, %cpu? 

[~ashwinshankar77], [~peng.zhang] - thoughts? , Thanks [~kasha] for your advice, I think:
1. When cluster capacity is 0, display is not that important: so 1, 0 are all acceptable for me.
2. Display two percent value for resources is good. And the following question is what about the usage bar? And also what if more resource is supported in YARN?
, [~kasha@cloudera.com],
Yes when cluster capacity is 0, it would be nice to show the ratio as 0.
Yes it makes sense to show both resources as percentages for the shares, but I can't think of a good way of displaying it on the bars.
Did you have anything in mind ?, What do you guys think of overlaying CPU and memory usage, the way steady and instantaneous fairshares are laid out today?

We could just add another value, bar when more resources are supported in YARN. I hope it doesn't get too cluttered, as we have a maximum of four resources? , I think overlay is not a good choice. 
Currently scheduler bar is already overlay of steady share, instantaneous share and max resources. 
Then overlaying  two dimension of resources may generate 2 * 3 elements? If so, it should be too cluttered without new resources added.

When test this patch in our cluster, I found a new issue with some abnormal configuration: 
queue's bar width is decided by (queue steady resource / cluster resource), and queue's usage width is decided by (queue's usage resource / cluster resource). 
For above two percent computation, dominant resource may be different, so two percent value is still in different dimension, and it causes confusion.

To figure out above problem, we practice making queue's steady share proportional to root queue share in different resource dimension, so first percent value(queue steady resource / cluster resource) has the same percent value in different resources, and it will not cause confusion. 

I think deeper problem is that FS can configure cpu and memory seperately(eg: min resource, max resource ), and it makes resource not proportional between queues, but need a view of percentage., bq. What do you guys think of overlaying CPU and memory usage, the way steady and instantaneous fairshares are laid out today?

I agree with Peng, it is going to become pretty cluttered displaying shares/max of each of the resources on the same bar.
Also, if we go by this approach, it would be ambiguous as to which resource is the usage bar representing, since the usage bar shows usage of dominant resource ie max(memoryRatio, vCoresRatio). Usage bar turns orange when its above fairshare, if we represent all the resources in one bar, how do we
know if we are above fair share due to memory or cpu or disk ?

Here is my proposal :
For each queue bar :
1. represent steady/instant/max of only the dominant resource in the bar.
2. usage, like in the patch, will be again usage of dominant resource.
3. In the tooltip, we mention what is the dominant resource we are representing in that queue([memory,cpu]). Note that dominant resource displayed can be memory in one queue and something else in another.
4. We already display steady/instant memory percentage in the tool tip, we could add cpu % of steady/instant/max in there as well, so that we know details
of each of the resource.

Thoughts ?, bq. Then overlaying two dimension of resources may generate 2 * 3 elements? If so, it should be too cluttered without new resources added.
You are right. Let us not over-clutter it. 

Ashwin's proposal sounds reasonable to me. Let us do 1 - 3 in this JIRA, and may be 4 in a follow-up? For 4, what do you guys think of just listing the usage of all resources, and may be labeling the dominant one dominant. Otherwise, users will have to look at both places to get the complete picture. , Hi [~kasha@cloudera.com]
bq. For 4, what do you guys think of just listing the usage of all resources, and may be labeling the dominant one dominant. Otherwise, users will have to look at both places to get the complete picture.
Where did you want to list the usage of all resources ? on the bar or the tooltip or on the text on the right of each bar ?, bq. Where did you want to list the usage of all resources ? on the bar or the tooltip or on the text on the right of each bar ?
Tooltip. Missed mentioning that in my comment. , Sounds good to me., Thanks for your advices

For 4 proposal listed above:
1 & 2 are already done in the patch
3 is good, but one question is that parent queue has no tooltip now, but it has its own bar.
And think over 3 & 4, what about listing all resources's usage percent on the text on the right of each bar? Maybe color red for dominant resource? or just judge it by comparing percent number?

And also what do you think of the issue I mentioned above? I think it still can happen after 1 & 2, cause for one queue: steady, fair, max, usage resource may have different dominant resource type. If I make a mistake here, please let me know.
bq. queue's bar width is decided by (queue steady resource / cluster resource), and queue's usage width is decided by (queue's usage resource / cluster resource). For above two percent computation, dominant resource may be different, so two percent value is still in different dimension, and it causes confusion., I dont think 1 is done in the patch. My bad, I wasn't clear. In 1 what I was suggesting was that - "represent that resource of steady/instant/max on the bar which is dominant in usage or used resources", so that, steady/instant/max/usage on the bar all finally represent ONE dimension in that bar/queue. So lets say usage of the queue is (20% mem, 60 % vcore), then steady/instant/max/usage would all display only vcore.

bq. 3 is good, but one question is that parent queue has no tooltip now, but it has its own bar.
Parent queues(except root) have a tooltip, I just checked in trunk. Can you check again ?

bq. And think over 3 & 4, what about listing all resources's usage percent on the text on the right of each bar? Maybe color red for dominant resource? or just judge it by comparing percent number?
It would be nice to have that with the color, however I'm concerned that it might look ugly from UE perspective.

bq. And also what do you think of the issue I mentioned above? I think it still can happen after 1 & 2, cause for one queue: steady, fair, max, usage resource may have different dominant resource type. If I make a mistake here, please let me know.
I believe this is clarified in the first paragraph of this comment. Let me know if you still have this concern., bq. 1. represent steady/instant/max of only the dominant resource in the bar.
This dominant resource type is decided by queue's usage resource to cluster ?
And then display this type name in tooltip.
I think this is good: all percentage value for one bar is in the same dimension.

bq. Parent queues(except root) have a tooltip, I just checked in trunk. Can you check again ?
Is "tooltip" the block displayed as "xxx Queue Status", and content like "Used Resources" & "Num Active Applications"? 
If so, I checked the code and run local cluster mode with trunk: for non-leafQueue, it doesn't exist.


, I edit FairSchedulerPage.java and add queue status info for non-leafQueue(include root).
If need, I can file a new issue for this., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12705647/parenttooltip.png
  against trunk revision 61a4c7f.

    {color:red}-1 patch{color}.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-YARN-Build/7025//console

This message is automatically generated., bq.This dominant resource type is decided by queue's usage resource to cluster ?
Yes correct.

bq. Is "tooltip" the block displayed as "xxx Queue Status", and content like "Used Resources" & "Num Active Applications"? 
No. I just attached an image parenttooltip.png which shows tooltip when I hover over "root.a" parent queue. This is from local cluster built from trunk.

bq. I edit FairSchedulerPage.java and add queue status info for non-leafQueue(include root).
If need, I can file a new issue for this.
This would be nice, I'll leave it up to [~kasha@cloudera.com] to decide if we want a separate issue for this., [~ashwinshankar77]
Thanks, I got it.

I'll update patch to implement 1 & 3 in your advices., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12706530/YARN-3111.v2.patch
  against trunk revision 0b9f12c.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager.

Test results: https://builds.apache.org/job/PreCommit-YARN-Build/7074//testReport/
Console output: https://builds.apache.org/job/PreCommit-YARN-Build/7074//console

This message is automatically generated., Canceling patch since there is pending work here. ]