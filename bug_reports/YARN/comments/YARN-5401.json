[This is effectively a duplicate of YARN-2261.  MapReduce history requires the MapReduce ApplicationMaster to generate the history when it completes.  hadoop job -kill or mapred job -kill accomplishes the kill by having the client connect to the MapReduce ApplicationMaster for the job and asks it to kill the job.  Since this goes through the ApplicationMaster it allows the history to be generated properly.

When the kill is done via YARN then the ApplicationMaster is not involved.  The ResourceManager kills the AM without the AM's knowledge.  This is similar to kill vs. kill -9 (i.e.: SIGTERM vs SIGKILL) in POSIX.  The former allows the application to perform cleanup tasks on the way down, while the latter mercilessly kills the process without any chance for cleanup.

Since YARN does not allow the application to specify a cleanup task to be performed when the app dies the MapReduce framework doesn't get a chance to finish generating the history for the job., So, should apps always use app specific methods to kill their jobs but never use yarn kill unless really necessary. (like always use kill(TERM) unless kill -9 becomes necessary), Yes, if an application framework provides a kill command then that should be preferred over the yarn kill approach.  The MapReduce framework kill will automatically fallback to the yarn kill if the application master is unresponsive or if the job fails to enter the killed state within a configurable amount of time (controlled via yarn.app.mapreduce.am.hard-kill-timeout-ms).]