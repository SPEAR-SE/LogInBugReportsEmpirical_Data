[The occurrence of these negative usedResources is very strongly correlated with applications being moved from one queue to another. e.g. on one cluster which was started on March 11, usedResources wasn't negative until somebody moved an application from one queue to the afflicted queue on April 7th. Since then, the queue shows negative usedResources.

This might actually be a race condition. It seems like [LeafQueue.detachContainer|https://github.com/apache/hadoop/blob/28eb2aabebd15c15a357d86e23ca407d3c85211c/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/LeafQueue.java#L1890] neglects to lock the LeafQueue object. In comparison, the same thing when a container is completed is done after acquiring a lock on the LeafQueue object in [LeafQueue.completedContainer|https://github.com/apache/hadoop/blob/28eb2aabebd15c15a357d86e23ca407d3c85211c/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/LeafQueue.java#L1538], hadoop 2.6.3  has the same problem ？？, Hi powerinf! It is possible. Do you have the CapacityScheduler? If you have the FairScheduler, YARN-3933 may be relevant, Seems like hadoop 2.6.0 has the same problem, at least I'm facing negative memory and vcores usage with capacity scheduler:

{code:xml}
<queue xsi:type="capacitySchedulerLeafQueueInfo">
        <capacity>19.0</capacity>
        <usedCapacity>-69.52686</usedCapacity>
        <maxCapacity>90.0</maxCapacity>
        <absoluteCapacity>19.0</absoluteCapacity>
        <absoluteMaxCapacity>90.0</absoluteMaxCapacity>
        <absoluteUsedCapacity>0.0</absoluteUsedCapacity>
        <numApplications>10</numApplications>
        <queueName>default</queueName>
        <state>RUNNING</state>
        <resourcesUsed>
           <memory>-152576</memory>
           <vCores>-41</vCores>
        </resourcesUsed>
        <hideReservationQueues>false</hideReservationQueues>
        <nodeLabels>*</nodeLabels>
        <allocatedContainers>24</allocatedContainers>
        <reservedContainers>0</reservedContainers>
        <pendingContainers>0</pendingContainers>
        <numActiveApplications>10</numActiveApplications>
        <numPendingApplications>0</numPendingApplications>
        <numContainers>-41</numContainers>
        <maxApplications>1900</maxApplications>
        <maxApplicationsPerUser>855</maxApplicationsPerUser>
        <maxActiveApplications>102</maxActiveApplications>
        <maxActiveApplicationsPerUser>10</maxActiveApplicationsPerUser>
        <userLimit>10</userLimit>
        ...
  </queue>
{code}
, Hi Filipp! Thanks for your report. Is the occurrence of the first negative usedResources correlated with applications being moved between queues in your case too? You can check this easily from the ResoureManager logs, I'm afraid I don't think I'll find the cycles to work on this in the next few months. ]