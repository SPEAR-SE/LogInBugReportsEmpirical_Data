[This adds a yarn configuration boolean called yarn.nodemanager.linux-container-executor.nonsecure-mode.limit-users that when set to true keeps the current behavior but when set to false goes back to the previous, non-regressed behavior., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12662313/YARN-2424.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager:

                  org.apache.hadoop.yarn.server.nodemanager.TestNodeManagerResync
                  org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager
                  org.apache.hadoop.yarn.server.nodemanager.webapp.TestNMWebServer
                  org.apache.hadoop.yarn.server.nodemanager.TestNodeStatusUpdater
                  org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.TestLogAggregationService
                  org.apache.hadoop.yarn.server.nodemanager.TestNodeManagerShutdown
                  org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.TestContainerLaunch
                  org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.TestContainersMonitor
                  org.apache.hadoop.yarn.server.nodemanager.TestNodeManagerReboot

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-YARN-Build/4646//testReport/
Console output: https://builds.apache.org/job/PreCommit-YARN-Build/4646//console

This message is automatically generated., These tests don't fail for me when I run locally and none of those bits of code are even in the path of the code change.  Suspect something odd on the Jenkins server.  I'll cancel patch and try it again later., please refer to yarn-1253 comments, it was stated there that the old behavior had security issues., This fix is all about EOU and operability.  I can certainly understand the desire to run cgroups without needing local users. But transitioning to security is not a binary process for most users (or, at least, it doesn't have to be...)

The problem with the current code base is that someone moving to a secure mode now has to either enable cgroups (which, as pointed out in YARN-1253 is irrelevant for security) or cut everything over at once.  Enabling LCE prior to enabling security allows for a two step transition and eases problem determination when doing the security upgrade.  Is that user missing from the system or is Kerberos failing?  Clearly the issues stemming from the former can be sorted out without security.  This makes the operations side of the house much easier.

It's also worth pointing out that one of the key benefits of running tasks as the user who submitted them is that it makes troubleshooting much easier.  When one hops on a node, it is evident as to which user's tasks one is looking at it, even if those tasks aren't validated as "that" user.  This is especially important in heavy multi-tenant  scenarios.

But, again, the fix in YARN-1253 caused a regression.  LCE w/out security was supported prior to Hadoop 2.3 and was definitely used by people.    This change still sets the default to be LCE w/either one user or security, but now for folks who want the prior behavior, they can flip a flag and get it., please go over todd's comment over the security issues on sudoing as user without secure auth. definitely you don't want to do that in a multi-tenant cluster. 

btw, fixing a security bug is not a regression.  , I don't think you understood what I wrote., {color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12662313/YARN-2424.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-YARN-Build/4654//testReport/
Console output: https://builds.apache.org/job/PreCommit-YARN-Build/4654//console

This message is automatically generated., I think I did, if I'm reading correctly you are stating that is better for troubleshooting, specially in multi-tenant scenarios: 

bq. It's also worth pointing out that one of the key benefits of running tasks as the user who submitted them is that it makes troubleshooting much easier. When one hops on a node, it is evident as to which user's tasks one is looking at it, even if those tasks aren't validated as "that" user. This is especially important in heavy multi-tenant scenarios.
, Thanks Tucu for pointing out the security implications of allowing un-authenticated users to run tasks as themselves (or impersonate others) on nodes. I agree that is not something we should turn on by default. That is why I think the default value for DEFAULT_NM_NONSECURE_MODE_LIMIT_USERS to be true is necessary. However, there is a use case as pointed out by Allen (as a stepping stone towards turning on Kerberos) that we at Altiscale and presumably others also have (e.g. Jay's last comment on YARN-1253). 
 
Thanks for this patch Allen! I'll take a look at it.

, I really don't like it, it is not my business how you run your clusters, but this is dangerous, specially in a multi-tenancy scenario. From Allen's comment (the one I highlighted) it is not clear to me this is meant only for setup/troubleshooting usage.

I would not -1 this JIRA if...

* the property has 'use-only-for-troubleshooting' in its name.
* the NM logs print a WARN at startup and on every started container stating the flag and its un-secure nature
* the container stdout/stderr also print a WARN to alert the user of the cluster setup., Hi Tucu! Thanks for your comment. There is currently capability to blacklist / whitelist users in the container-executor.cfg file. Given this capability, do you think in a properly configured cluster, yarn tasks launching as different users could create problems? This is with the assumption that most clusters do not have NFS mounts on the slave nodes.

As an aside I think it would be good to add a blacklist + whitelist for groups as well., [~raviprak], allow to sudo to more than one user in unsecure mode, it doesn't give you any extra security. Actually, it may give you a sense of false security.

On using groups in the LCE blacklist/whitelist, i'll comment in YARN-2429., BTW, it should be pointed out that the current code doesn't actually protect non-RPCSEC NFSv3/v2  directories.  It only prevents them from being mounted using system facilities.  (I'll leave it up to the reader to see how to implement an exploit.... not that it's particularly hard.) 

The only "security" thing the current code does is limit containers to run as one uid which in turn means preventing access to any elevated privs that any other user might have.  That's it. So if you have too many users with, say, passwordless sudo or if you don't want to publish user names to your compute nodes, the current code helps.  Otherwise, you're getting zero benefits.  For example, YARN scheduling and HDFS writes are still being done by the originally requested user.

The security aspects, as pointed out in the original JIRA, are a red herring., If security is OFF, I can simply submit a job as ANY user by simply doing -Duser.name=ANY. User ANY will be the one used by YARN and HDFS (I'll leave it up to the reader to see how to do this).

I really don't like what this JIRA is proposing, and I've indicated what it would have to be done for me not to -1.

, You do understand that the current code in branch-2 that this patch modifies doesn't protect HDFS and YARN at all, correct? I can still set HADOOP_USER_NAME and kill any YARN job I want or delete any file in HDFS I want. 

, [~aw], I think you are missing the point.

I know that in an un-secure cluster you can fake the user name to interact with HDFS or YARN from anywhere at anytime. 

YARN-1253 is not about protecting HDFS or YARN, it is about protecting the node at OS level by enforcing the use of a least privileged user., Hi Tucu!
bq. If security is OFF, I can simply submit a job as ANY user by simply doing -Duser.name=ANY. User ANY will be the one used by YARN and HDFS
Is this true? Are you suggesting that the blacklist (banner.users) in container-executor.cfg does not work? Could you not blacklist root, hdfs, mapred and yarn?

We are not doing this for security. We understand that +*with the right configuration*+, the level of security you provide is exactly the same as you would have in an unsecure cluster. If only the users of the cluster are whitelisted and all other users like root / mapred / yarn / hdfs are blacklisted, and the users which are whitelisted don't enjoy any elevated privilidges on the slave nodes. This is a perfectly valid configuration with the same level of security as would be provided if all yarn tasks ran one user.

Could you please point out a technical concern with the security in this configuration? This would not be a configuration for "troubleshooting only". This would be a perfectly valid configuration., Ravi, all the config in the container-executor.cfg is EXCLUSIVELY for enforcing constraints on the process to be launched, it does not restrict a launched JVM process from doing a {{System.setProperty("user.name", "ANY")}} to gain access to HDFS as user ANY (if Kerberos is ON, setting 'user.name' property has no effect).

BTW, I'm not OK with making this a valid configuration, it is not., Thanks Tucu! In YARN-1253, Vinod wrote:
bq. Even if the jobs run as a single 'yarnuser', security isn't still there - like Arun said, any body can bomb HDFS directories of other users, any user can kill any other user's tasks/containers, any one can delete any one else's local dirs, log-dir and so on
Is that not true?
, Repeating myself from a previous comment: "YARN-1253 is not about protecting HDFS or YARN, it is about protecting the node at OS level by enforcing the use of a least privileged user."
, Hi Tucu! I'd brought it up only because in the earlier comment you'd said
bq. Ravi, all the config in the container-executor.cfg is EXCLUSIVELY for enforcing constraints on the process to be launched, it does not restrict a launched JVM process from doing a System.setProperty("user.name", "ANY") to gain access to +*HDFS*+ as user ANY (if Kerberos is ON, setting 'user.name' property has no effect).
I'm glad we agree that YARN-1253 wasn't about protecting HDFS or YARN.

bq. it is about protecting the node at OS level by enforcing the use of a least privileged user.
So if we enforced the use of several least privileged users (instead of only 1), is that not just as secure? Would you argue that with the proper use of blacklists and whitelists this cannot be achieved?, Having more than one 'least privileged' user does not bring you any benefit as they can always step on each other by faking the username at job submission.
, Hi Tucu! The intention was for this to be a useful thing to do as an intermediate step when migrating from an insecure cluster to a Kerberized cluster. This would let people test their provisioning of unix users without having to deal with Kerberos issues.
Could you please answer my question?
bq. So if we enforced the use of several least privileged users (instead of only 1), is that not just as secure?, You are saying this is proactive troubleshooting then, not meant for production? If so, then, as I said before:

* the property has 'use-only-for-troubleshooting' in its name.
* the NM logs print a WARN at startup and on every started container stating the flag and its un-secure nature
* the container stdout/stderr also print a WARN to alert the user of the cluster setup., Hi Tucu! It is a perfectly valid production configuration that is _helpful_ for troubleshooting. It is not for troubleshooting ONLY. In fact, I think it is a good idea for several reasons. IMHO we shouldn't dictate configurations that Hadoop should be run in without good reason. I am sorry I do not understand why you have reservations about this patch. We've already determined that when properly configured the security is the same. To prevent misconfiguration we've set defaults to secure. This used to be a valid hadoop configuration prior to 2.3.
, This is a pretty clear case of trying to fix the breakage from YARN-1253. Yahoo ran clusters for a year with LCE before security was turned on and got significant value from that. The largest being that it prevents "killall -9 java" type mistakes on the part of users. (Yes that did actually happen.), I disagree on YARN-1253 being a breakage. 

Personally, I would never recommend using this in production. Given that, I'm OK with the patch if:

* the NM logs print a WARN at startup stating the setting.
* the container stdout/stderr also prints a WARN to alert the user of the setting.

, Alejandro, after I told you that users have run in production with that setting, it is very rude to say that removing the feature is not breakage. It is *obviously* breakage.

A warning makes sense, but it should only be once when the ResourceManager boots. It is a system level configuration and warning more than once is wrong., I disagree on me being rude (or very rude) just for disagreeing with something. IMO security fixes trump backwards compatibility.

Anyway, I'm -0 with the patch if the WARNs are printed in in the RM at startup as Owen suggests. I insists that the WARN should be in the stderr/stdout of every container. Otherwise this will go completely unnoticed to users running apps. It should be obvious to them that they are exposed.
, bq. It should be obvious to them that they are exposed.

Then we should return a WARN whenever isSecurityEnabled returns false since that's the only way they are secure., if you don't have to kinit it is obvious security is OFF, no?, Apparently not, given:

bq. Otherwise this will go completely unnoticed to users running apps.

, I reviewed the code and the changes make sense to me. I'm a +1 on the patch as is., Added a version with a log statement that warns on startup. [~tucu00], is this sufficient? The config docs are pretty clear about the effect of setting the parameter, and this should be noticed if someone is experimenting with LCE., sure, fine, enough cycles spent on this, thx., {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12663330/Y2424-1.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

        {color:red}-1 release audit{color}.  The applied patch generated 3 release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-YARN-Build/4681//testReport/
Release audit warnings: https://builds.apache.org/job/PreCommit-YARN-Build/4681//artifact/trunk/patchprocess/patchReleaseAuditProblems.txt
Console output: https://builds.apache.org/job/PreCommit-YARN-Build/4681//console

This message is automatically generated., Release audit warnings have nothign to do with this code.

Will commit in a second., Committed to branch-2 and trunk.

Thanks!, FAILURE: Integrated in Hadoop-Yarn-trunk #653 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/653/])
YARN-2424. LCE should support non-cgroups, non-secure mode (Chris Douglas via aw) (aw: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1619421)
* /hadoop/common/trunk/hadoop-yarn-project/CHANGES.txt
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/src/main/java/org/apache/hadoop/yarn/conf/YarnConfiguration.java
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/resources/yarn-default.xml
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/LinuxContainerExecutor.java
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/TestLinuxContainerExecutor.java
, FAILURE: Integrated in Hadoop-trunk-Commit #6092 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/6092/])
YARN-2424. LCE should support non-cgroups, non-secure mode (Chris Douglas via aw) (aw: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1619421)
* /hadoop/common/trunk/hadoop-yarn-project/CHANGES.txt
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/src/main/java/org/apache/hadoop/yarn/conf/YarnConfiguration.java
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/resources/yarn-default.xml
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/LinuxContainerExecutor.java
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/TestLinuxContainerExecutor.java
, FAILURE: Integrated in Hadoop-Hdfs-trunk #1844 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1844/])
YARN-2424. LCE should support non-cgroups, non-secure mode (Chris Douglas via aw) (aw: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1619421)
* /hadoop/common/trunk/hadoop-yarn-project/CHANGES.txt
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/src/main/java/org/apache/hadoop/yarn/conf/YarnConfiguration.java
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/resources/yarn-default.xml
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/LinuxContainerExecutor.java
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/TestLinuxContainerExecutor.java
, SUCCESS: Integrated in Hadoop-Mapreduce-trunk #1870 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1870/])
YARN-2424. LCE should support non-cgroups, non-secure mode (Chris Douglas via aw) (aw: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1619421)
* /hadoop/common/trunk/hadoop-yarn-project/CHANGES.txt
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/src/main/java/org/apache/hadoop/yarn/conf/YarnConfiguration.java
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/resources/yarn-default.xml
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/LinuxContainerExecutor.java
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/TestLinuxContainerExecutor.java
, Adding the fix-version, now that it has been committed., It looks different versions of the patch to fix this were committed to branch-2 and trunk? The corresponding changes to LinuxContainerExecutor.java look different. , [~sidharta-s] - Yes, it appears the warning was skipped in the branch-2 patch, likely by accident. Thanks for spotting this!

Could you file a new YARN JIRA to port the warning back into branch-2?, Here it is : https://issues.apache.org/jira/browse/YARN-3462]