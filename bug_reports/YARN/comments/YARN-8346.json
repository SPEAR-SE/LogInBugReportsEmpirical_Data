[In class ContainerScheduler#enqueueContainer, for recovered container from 2.8.4 execution type is not set which result in else condition with zero queue lenght.  This is sending kill event for container resulting running containers are killed.

{code}
private boolean enqueueContainer(Container container) {
    boolean isGuaranteedContainer = container.getContainerTokenIdentifier().
        getExecutionType() == ExecutionType.GUARANTEED;

    boolean isQueued;
    if (isGuaranteedContainer) {
      queuedGuaranteedContainers.put(container.getContainerId(), container);
      isQueued = true;
    } else {
      if (queuedOpportunisticContainers.size() < maxOppQueueLength) {
        LOG.info("Opportunistic container {} will be queued at the NM.",
            container.getContainerId());
        queuedOpportunisticContainers.put(
            container.getContainerId(), container);
        isQueued = true;
      } else {
        LOG.info("Opportunistic container [{}] will not be queued at the NM" +
                "since max queue length [{}] has been reached",
            container.getContainerId(), maxOppQueueLength);
        container.sendKillEvent(
            ContainerExitStatus.KILLED_BY_CONTAINER_SCHEDULER,
            "Opportunistic container queue is full.");
        isQueued = false;
      }
    }
{code}


Since opportunistic container feature is exist in 2.9, this would also issue upgrading into 2.9 I think.
cc:/ [~jlowe] [~arun.suresh@gmail.com] , bumping up as Blocker., The queue length is based on yarn.nodemanager.opportunistic-containers-max-queue-length setting.  If yarn-site.xml does not specify this, it will have size of 0.  This seems like a bad default value that will cause rolling upgrade to fail.  I think a default value of 4 to 8 is probably sensible.  Number of CPU cores and queue length are some what related, it would be good for external upgrading system like Ambari to set queue length accordingly., IIUC the issue isn't the queue length setting but rather that the containers are recovered with the wrong execution type (opportunistic instead of guaranteed).

I believe the bug is here in ContainerTokenIdentifier#getExecutionType:
{code}
  public ExecutionType getExecutionType(){
    if (!proto.hasExecutionType()) {
      return null;
    }
    return convertFromProtoFormat(proto.getExecutionType());
  }
{code}

Instead of returning NULL for the execution type it should return GUARANTEED.  All containers before an execution type was added were effectively guaranteed since that was the only execution type supported.
, [~jlowe] Yes, you are right.  Existing workload supposed to have execution type GUARANTEED., Hi Guys,

Thanks for reporting and working on the issue. I'm preparing 3.0.3 release, wonder if we can prioritize this one if we deem its a blocker?

Thanks,
, I should have a patch up later today.  I already verified the change I proposed above fixes the case that Rohith reported when I test it manually, just need to add a unit test.
, This defaults the execution type to GUARANTEED and the container type to TASK if the underlying protobuf field in the container token identifier is missing., Thanks for the patch, [~jlowe].

Indeed you are right –  the problem is the lack of execution type. The queue size should remain 0 given that opportunistic containers are disabled in this case.

+1 for the patch., Thanks a lot for the quick turnaround [~jlowe] and [~kkaranasos].
, | (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 33s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 26m 58s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 38s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 29s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 44s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 11m 30s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 18s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 42s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 39s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 35s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 35s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 25s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 38s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 11m 21s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 22s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 39s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  3m  6s{color} | {color:green} hadoop-yarn-common in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 23s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 61m 51s{color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:abb62dd |
| JIRA Issue | YARN-8346 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12924799/YARN-8346.001.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |
| uname | Linux 2a58b0d4306d 3.13.0-139-generic #188-Ubuntu SMP Tue Jan 9 14:43:09 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 51ce02b |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_162 |
| findbugs | v3.1.0-RC1 |
|  Test Results | https://builds.apache.org/job/PreCommit-YARN-Build/20842/testReport/ |
| Max. process+thread count | 303 (vs. ulimit of 10000) |
| modules | C: hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common U: hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common |
| Console output | https://builds.apache.org/job/PreCommit-YARN-Build/20842/console |
| Powered by | Apache Yetus 0.8.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

, Thanks [~jlowe] for quick turnaround. I verified the patch in cluster and working fine as expected.

I am +1 for the patch., committing shortly, committed to trunk/branch-3.1/branch-3.0/branch-2.. thanks to [~jlowe] for quick analysis and patch and thanks to [~kkaranasos] [~eyang] [~yzhangal] for the review., SUCCESS: Integrated in Jenkins build Hadoop-trunk-Commit #14279 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/14279/])
YARN-8346. Upgrading to 3.1 kills running containers with error (rohithsharmaks: rev 4cc0c9b0baa93f5a1c0623eee353874e858a7caa)
* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/test/java/org/apache/hadoop/yarn/security/TestYARNTokenIdentifier.java
* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/security/ContainerTokenIdentifier.java
, Thanks for the reviews!  Does this need to go into branch-2.9 as well?  I think 2.9.1 will have the same issue.
, back ported to 2.9 as well. ]