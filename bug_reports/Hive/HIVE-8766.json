{
    "expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields",
    "fields": {
        "aggregateprogress": {
            "progress": 0,
            "total": 0
        },
        "aggregatetimeestimate": null,
        "aggregatetimeoriginalestimate": null,
        "aggregatetimespent": null,
        "assignee": {
            "active": true,
            "avatarUrls": {
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hsubramaniyan&avatarId=23453",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hsubramaniyan&avatarId=23453",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hsubramaniyan&avatarId=23453",
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=hsubramaniyan&avatarId=23453"
            },
            "displayName": "Hari Sankar Sivarama Subramaniyan",
            "key": "hsubramaniyan",
            "name": "hsubramaniyan",
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=hsubramaniyan",
            "timeZone": "America/Los_Angeles"
        },
        "components": [{
            "description": "Tracks issue dealing with metastore.",
            "id": "12312584",
            "name": "Metastore",
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312584"
        }],
        "created": "2014-11-06T22:08:43.000+0000",
        "creator": {
            "active": true,
            "avatarUrls": {
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hsubramaniyan&avatarId=23453",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hsubramaniyan&avatarId=23453",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hsubramaniyan&avatarId=23453",
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=hsubramaniyan&avatarId=23453"
            },
            "displayName": "Hari Sankar Sivarama Subramaniyan",
            "key": "hsubramaniyan",
            "name": "hsubramaniyan",
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=hsubramaniyan",
            "timeZone": "America/Los_Angeles"
        },
        "customfield_10010": null,
        "customfield_12310191": null,
        "customfield_12310192": null,
        "customfield_12310220": "2014-11-06T22:22:24.350+0000",
        "customfield_12310222": "10002_*:*_2_*:*_35386366_*|*_1_*:*_2_*:*_174018_*|*_5_*:*_1_*:*_0",
        "customfield_12310230": null,
        "customfield_12310250": null,
        "customfield_12310290": null,
        "customfield_12310291": null,
        "customfield_12310300": null,
        "customfield_12310310": "2.0",
        "customfield_12310320": null,
        "customfield_12310420": "9223372036854775807",
        "customfield_12310920": "9223372036854775807",
        "customfield_12310921": null,
        "customfield_12311020": null,
        "customfield_12311024": null,
        "customfield_12311120": null,
        "customfield_12311820": "0|i222vr:",
        "customfield_12312022": null,
        "customfield_12312023": null,
        "customfield_12312024": null,
        "customfield_12312026": null,
        "customfield_12312220": null,
        "customfield_12312320": null,
        "customfield_12312321": null,
        "customfield_12312322": null,
        "customfield_12312323": null,
        "customfield_12312324": null,
        "customfield_12312325": null,
        "customfield_12312326": null,
        "customfield_12312327": null,
        "customfield_12312328": null,
        "customfield_12312329": null,
        "customfield_12312330": null,
        "customfield_12312331": null,
        "customfield_12312332": null,
        "customfield_12312333": null,
        "customfield_12312334": null,
        "customfield_12312335": null,
        "customfield_12312336": null,
        "customfield_12312337": null,
        "customfield_12312338": null,
        "customfield_12312339": null,
        "customfield_12312340": null,
        "customfield_12312341": null,
        "customfield_12312520": null,
        "customfield_12312521": "Thu Nov 13 19:41:10 UTC 2014",
        "customfield_12312720": null,
        "customfield_12312823": null,
        "customfield_12312920": null,
        "customfield_12312921": null,
        "customfield_12312923": null,
        "customfield_12313422": "false",
        "customfield_12313520": null,
        "description": "When we have Metastore operations and the Metastore Database is heavily loaded or takes a long time to respond, we might run into NucleusExceptions as shown in the below stacktrace. In the below scenario, the MetastoreDB is SQL Server and the SQLServer is configured to timeout and terminate with a connection reset after 'x' seconds if it doesnt return a ResultSet. While this needs configuration change at the Metastore DB side, we need to make sure that in such cases the HMS Retrying mechanism should not provide a rigid rule to fail such hive queries. The proposed fix would be allow retries when we hit a Nucleus Exception as shown below: \n\n{noformat}\n2014-11-04 06:40:03,208 ERROR bonecp.ConnectionHandle (ConnectionHandle.java:markPossiblyBroken(388)) - Database access problem. Killing off this connection and all remaining connections in the connection pool. SQL State = 08S01\n2014-11-04 06:40:03,213 ERROR DataNucleus.Transaction (Log4JLogger.java:error(115)) - Operation rollback failed on resource: org.datanucleus.store.rdbms.ConnectionFactoryImpl$EmulatedXAResource@1a35cc16, error code UNKNOWN and transaction: [DataNucleus Transaction, ID=Xid=   ï¿½, enlisted resources=[org.datanucleus.store.rdbms.ConnectionFactoryImpl$EmulatedXAResource@1a35cc16]]\n2014-11-04 06:40:03,217 ERROR metastore.RetryingHMSHandler (RetryingHMSHandler.java:invoke(139)) - MetaException(message:org.datanucleus.exceptions.NucleusDataStoreException: Size request failed : SELECT COUNT(*) FROM SKEWED_VALUES THIS WHERE THIS.SD_ID_OID=? AND THIS.INTEGER_IDX>=0)\n\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newMetaException(HiveMetaStore.java:5183)\n\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table_core(HiveMetaStore.java:1738)\n\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1699)\n\tat sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:101)\n\tat com.sun.proxy.$Proxy11.get_table(Unknown Source)\n\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:1091)\n\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.getTable(SessionHiveMetaStoreClient.java:112)\n\tat sun.reflect.GeneratedMethodAccessor16.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:90)\n\tat com.sun.proxy.$Proxy12.getTable(Unknown Source)\n\tat org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:1060)\n\tat org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:1015)\n\tat org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.getTable(BaseSemanticAnalyzer.java:1316)\n\tat org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.getTable(BaseSemanticAnalyzer.java:1309)\n\tat org.apache.hadoop.hive.ql.parse.DDLSemanticAnalyzer.addInputsOutputsAlterTable(DDLSemanticAnalyzer.java:1387)\n\tat org.apache.hadoop.hive.ql.parse.DDLSemanticAnalyzer.analyzeAlterTableSerde(DDLSemanticAnalyzer.java:1356)\n\tat org.apache.hadoop.hive.ql.parse.DDLSemanticAnalyzer.analyzeInternal(DDLSemanticAnalyzer.java:299)\n\tat org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:221)\n\tat org.apache.hadoop.hive.ql.Driver.compile(Driver.java:415)\n\tat org.apache.hadoop.hive.ql.Driver.compile(Driver.java:303)\n\tat org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:1067)\n\tat org.apache.hadoop.hive.ql.Driver.compileAndRespond(Driver.java:1061)\n\tat org.apache.hive.service.cli.operation.SQLOperation.prepare(SQLOperation.java:100)\n\tat org.apache.hive.service.cli.operation.SQLOperation.runInternal(SQLOperation.java:171)\n\tat org.apache.hive.service.cli.operation.Operation.run(Operation.java:256)\n\tat org.apache.hive.service.cli.session.HiveSessionImpl.executeStatementInternal(HiveSessionImpl.java:376)\n\tat org.apache.hive.service.cli.session.HiveSessionImpl.executeStatementAsync(HiveSessionImpl.java:363)\n\tat org.apache.hive.service.cli.CLIService.executeStatementAsync(CLIService.java:247)\n\tat org.apache.hive.service.cli.thrift.ThriftCLIService.ExecuteStatement(ThriftCLIService.java:396)\n\tat org.apache.hive.service.cli.thrift.TCLIService$Processor$ExecuteStatement.getResult(TCLIService.java:1313)\n\tat org.apache.hive.service.cli.thrift.TCLIService$Processor$ExecuteStatement.getResult(TCLIService.java:1298)\n\tat org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)\n\tat org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)\n\tat org.apache.hive.service.auth.TSetIpAddressProcessor.process(TSetIpAddressProcessor.java:56)\n\tat org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:206)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: org.datanucleus.exceptions.NucleusDataStoreException: Size request failed : SELECT COUNT(*) FROM SKEWED_VALUES THIS WHERE THIS.SD_ID_OID=? AND THIS.INTEGER_IDX>=0\n\tat org.datanucleus.store.rdbms.scostore.ElementContainerStore.getSize(ElementContainerStore.java:666)\n\tat org.datanucleus.store.rdbms.scostore.ElementContainerStore.size(ElementContainerStore.java:429)\n\tat org.datanucleus.store.types.backed.List.size(List.java:581)\n\tat org.apache.hadoop.hive.metastore.ObjectStore.convertToSkewedValues(ObjectStore.java:1190)\n\tat org.apache.hadoop.hive.metastore.ObjectStore.convertToStorageDescriptor(ObjectStore.java:1168)\n\tat org.apache.hadoop.hive.metastore.ObjectStore.convertToStorageDescriptor(ObjectStore.java:1178)\n\tat org.apache.hadoop.hive.metastore.ObjectStore.convertToTable(ObjectStore.java:1035)\n\tat org.apache.hadoop.hive.metastore.ObjectStore.getTable(ObjectStore.java:893)\n\tat sun.reflect.GeneratedMethodAccessor13.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:98)\n\tat com.sun.proxy.$Proxy10.getTable(Unknown Source)\n\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table_core(HiveMetaStore.java:1727)\n\t... 41 more\nCaused by: com.microsoft.sqlserver.jdbc.SQLServerException: SSL peer shut down incorrectly\n\tat com.microsoft.sqlserver.jdbc.SQLServerConnection.terminate(SQLServerConnection.java:1352)\n\tat com.microsoft.sqlserver.jdbc.SQLServerConnection.terminate(SQLServerConnection.java:1339)\n\tat com.microsoft.sqlserver.jdbc.TDSChannel.read(IOBuffer.java:1694)\n\tat com.microsoft.sqlserver.jdbc.TDSReader.readPacket(IOBuffer.java:3734)\n\tat com.microsoft.sqlserver.jdbc.TDSCommand.startResponse(IOBuffer.java:5062)\n\tat com.microsoft.sqlserver.jdbc.SQLServerPreparedStatement.doExecutePreparedStatement(SQLServerPreparedStatement.java:388)\n\tat com.microsoft.sqlserver.jdbc.SQLServerPreparedStatement$PrepStmtExecCmd.doExecute(SQLServerPreparedStatement.java:340)\n\tat com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:4615)\n\tat com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:1400)\n\tat com.microsoft.sqlserver.jdbc.SQLServerStatement.executeCommand(SQLServerStatement.java:179)\n\tat com.microsoft.sqlserver.jdbc.SQLServerStatement.executeStatement(SQLServerStatement.java:154)\n\tat com.microsoft.sqlserver.jdbc.SQLServerPreparedStatement.executeQuery(SQLServerPreparedStatement.java:283)\n\tat com.jolbox.bonecp.PreparedStatementHandle.executeQuery(PreparedStatementHandle.java:174)\n\tat org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeQuery(ParamLoggingPreparedStatement.java:381)\n\tat org.datanucleus.store.rdbms.SQLController.executeStatementQuery(SQLController.java:504)\n\tat org.datanucleus.store.rdbms.scostore.ElementContainerStore.getSize(ElementContainerStore.java:638)\n{noformat}",
        "duedate": null,
        "environment": null,
        "fixVersions": [{
            "archived": false,
            "description": "released",
            "id": "12326450",
            "name": "0.14.0",
            "releaseDate": "2014-11-12",
            "released": true,
            "self": "https://issues.apache.org/jira/rest/api/2/version/12326450"
        }],
        "issuelinks": [{
            "id": "12479503",
            "inwardIssue": {
                "fields": {
                    "issuetype": {
                        "avatarId": 21133,
                        "description": "A problem which impairs or prevents the functions of the product.",
                        "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
                        "id": "1",
                        "name": "Bug",
                        "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
                        "subtask": false
                    },
                    "priority": {
                        "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
                        "id": "3",
                        "name": "Major",
                        "self": "https://issues.apache.org/jira/rest/api/2/priority/3"
                    },
                    "status": {
                        "description": "A patch for this issue has been uploaded to JIRA by a contributor.",
                        "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/document.png",
                        "id": "10002",
                        "name": "Patch Available",
                        "self": "https://issues.apache.org/jira/rest/api/2/status/10002",
                        "statusCategory": {
                            "colorName": "yellow",
                            "id": 4,
                            "key": "indeterminate",
                            "name": "In Progress",
                            "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/4"
                        }
                    },
                    "summary": " Hive Query Fail with MetaException(message:org.datanucleus.exceptions.NucleusDataStoreException: Size request failed"
                },
                "id": "13002335",
                "key": "HIVE-14696",
                "self": "https://issues.apache.org/jira/rest/api/2/issue/13002335"
            },
            "self": "https://issues.apache.org/jira/rest/api/2/issueLink/12479503",
            "type": {
                "id": "10030",
                "inward": "is related to",
                "name": "Reference",
                "outward": "relates to",
                "self": "https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"
            }
        }],
        "issuetype": {
            "avatarId": 21133,
            "description": "A problem which impairs or prevents the functions of the product.",
            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
            "id": "1",
            "name": "Bug",
            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
            "subtask": false
        },
        "labels": [],
        "lastViewed": null,
        "priority": {
            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
            "id": "3",
            "name": "Major",
            "self": "https://issues.apache.org/jira/rest/api/2/priority/3"
        },
        "progress": {
            "progress": 0,
            "total": 0
        },
        "project": {
            "avatarUrls": {
                "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310843&avatarId=11935",
                "24x24": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310843&avatarId=11935",
                "32x32": "https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310843&avatarId=11935",
                "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12310843&avatarId=11935"
            },
            "id": "12310843",
            "key": "HIVE",
            "name": "Hive",
            "projectCategory": {
                "description": "Scalable Distributed Computing",
                "id": "10292",
                "name": "Hadoop",
                "self": "https://issues.apache.org/jira/rest/api/2/projectCategory/10292"
            },
            "self": "https://issues.apache.org/jira/rest/api/2/project/12310843"
        },
        "reporter": {
            "active": true,
            "avatarUrls": {
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hsubramaniyan&avatarId=23453",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hsubramaniyan&avatarId=23453",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hsubramaniyan&avatarId=23453",
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=hsubramaniyan&avatarId=23453"
            },
            "displayName": "Hari Sankar Sivarama Subramaniyan",
            "key": "hsubramaniyan",
            "name": "hsubramaniyan",
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=hsubramaniyan",
            "timeZone": "America/Los_Angeles"
        },
        "resolution": {
            "description": "A fix for this issue is checked into the tree and tested.",
            "id": "1",
            "name": "Fixed",
            "self": "https://issues.apache.org/jira/rest/api/2/resolution/1"
        },
        "resolutiondate": "2014-11-07T08:01:23.000+0000",
        "status": {
            "description": "The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.",
            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/closed.png",
            "id": "6",
            "name": "Closed",
            "self": "https://issues.apache.org/jira/rest/api/2/status/6",
            "statusCategory": {
                "colorName": "green",
                "id": 3,
                "key": "done",
                "name": "Done",
                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3"
            }
        },
        "subtasks": [],
        "summary": "Hive RetryHMSHandler should be retrying the metastore operation in case of NucleusException",
        "timeestimate": null,
        "timeoriginalestimate": null,
        "timespent": null,
        "updated": "2016-09-05T07:58:32.000+0000",
        "versions": [],
        "votes": {
            "hasVoted": false,
            "self": "https://issues.apache.org/jira/rest/api/2/issue/HIVE-8766/votes",
            "votes": 0
        },
        "watches": {
            "isWatching": false,
            "self": "https://issues.apache.org/jira/rest/api/2/issue/HIVE-8766/watchers",
            "watchCount": 3
        },
        "workratio": -1
    },
    "id": "12753535",
    "key": "HIVE-8766",
    "self": "https://issues.apache.org/jira/rest/api/2/issue/12753535"
}