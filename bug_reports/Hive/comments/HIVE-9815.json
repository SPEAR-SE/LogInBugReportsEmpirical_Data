[So the only issue in expanding the max size of SERDE_PARAMS.PARAMS_VALUE is its support Oracle. The database needs to be configured and restarted with the new settings. According to the documentation, https://docs.oracle.com/database/121/REFRN/refrn10321.htm#REFRN10321,

Altering MAX_STRING_SIZE will update database objects and possibly invalidate them, as follows:
* Tables with virtual columns will be updated with new data type metadata for virtual columns of VARCHAR2(4000), 4000-byte NVARCHAR2, or RAW(2000) type.
* Functional indexes will become unusable if a change to their associated virtual columns causes the index key to exceed index key length limits. Attempts to rebuild such indexes will fail with ORA-01450: maximum key length exceeded.
* Views will be invalidated if they contain VARCHAR2(4000), 4000-byte NVARCHAR2, or RAW(2000) typed expression columns.
* Materialized views will be updated with new metadata VARCHAR2(4000), 4000-byte NVARCHAR2, and RAW(2000) typed expression columns

, I am looking for feedback on
What Oracle DB defaults to for MAX_STRING_SIZE? 
What is the impact on existing data in the database, if one were to change the MAX_STRING_SIZE setting from STANDARD to EXTENDED & bounce the instance? Could there be a loss of data that could impact hive metastore?, I am attaching a create table query with a long value for a serde property "hbase.columns.mapping", [~ngangam] This is a problem for table/db params too (both param_key and param_value) and not just for serdes. I hope they are included in this jira's scope. Thanks., This also is a problem when using Hive through Spark Parquet files as Spark attempts to write the Parquet schema in such a property. Many rich schema are over 4K in serialized form., Should this be updated under https://cwiki.apache.org/confluence/display/Hive/AdminManual+MetastoreAdmin#AdminManualMetastoreAdmin-SupportedBackendDatabasesforMetastore? 

1. If the user doing a raw Oracle database installation for meta store, then  MAX_STRING_SIZE setting is to be changed from STANDARD to EXTENDED.

2. If the user is planning to use an existing database, a warning should describe this situation and suggest to use some other database., I would suggest to mark this story as a duplicate since it seems to be a subset of HIVE-12274. Therefore, the focus can be concentrated on HIVE-12274. I added a comment there, summarizing the information collected in this story., Fix for this has been committed to 2.2 and 3.0 releases as part of a larger fix in HIVE-12274. Closing this jira., [~ngangam], the fix version should be 2.3.0 instead of 2.2.0.  (See my comment on HIVE-12274.), Is any wiki documentation needed?

Repeating [~sambit19]'s question from January 21:

{quote}
Should this be updated under https://cwiki.apache.org/confluence/display/Hive/AdminManual+MetastoreAdmin#AdminManualMetastoreAdmin-SupportedBackendDatabasesforMetastore? 

1. If the user doing a raw Oracle database installation for meta store, then  MAX_STRING_SIZE setting is to be changed from STANDARD to EXTENDED.

2. If the user is planning to use an existing database, a warning should describe this situation and suggest to use some other database.
{quote}, [~leftylev] Nope, no new documentation is required. I do not believe we document the schema columns and their datatypes (nor do I see a need to). 

[~sambit19]  To answer your questions
1) I ended up using CLOB datatypes for these columns which expand way beyond what an EXTENDED VARCHAR can offer and no additional database configuration is needed for this change.
2) The upgrade, from an existing version of hive, should work seamlessly if you use the upgrade script provided. There should be no data loss., Okay, thanks Naveen., Hive 3.0.0 has been released so closing this jira.]