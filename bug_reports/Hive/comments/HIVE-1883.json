[I sent this to the dev list earlier:

{quote}
Usually it's the Ops/IT staff that ends up managing things like a production HiveServer instance, and in a UNIX shop I suspect that most of these folks are already going to be familiar with using cron and logrotate (http://linuxcommand.org/man_pages/logrotate8.html) to manage the logs produced by their other server systems. 

Building a log rotation feature into HiveServer defies this convention and will force people to learn how to configure a new log rotation system specific to HiveServer. It also requires us to write, debug, document and maintain code that isn't really necessary. I think the best approach is to take advantage of what already exists by documenting Hive's logging behavior in the Admin manual and providing a sample logrotate configuration file.
{quote}
, Carl is right on this. There is no need to have a 'scheduled' timer task to take care of the log files. There are enough handles already available in log4j library used by Hive to handle the log files.
As far as the current issue is concerned, RolllingFileAppender can be used and a max limit can be set.
if it is wished that no data should be lost then DailyRollingFileAppender can be used and a cron job can be run to handle the a week's[or what ever the time frame chosen] log files.

Further, there is one more disadvantage in running the 'scheduled' timer task to handle log files, creates more problems than it solves. Though ScheduledThreadPoolExecutor could be an answer, but its just not worth the effort.]