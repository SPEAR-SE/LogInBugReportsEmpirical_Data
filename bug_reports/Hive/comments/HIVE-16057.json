[The patch queries the HiveConf for username/password only if they are not provided as a command line argument.

I have done the following manual testing:
- No {{hadoop.security.credential.provider.path}}, no password provided by argument - Got error as expected
- No {{hadoop.security.credential.provider.path}}, password provided by argument - Successful getting the information
- {{hadoop.security.credential.provider.path}} provided, credential password provided through environment, no password provided by argument - Successful getting the information
- {{hadoop.security.credential.provider.path}} provided, credential password not provided, no password provided by argument - Got error as expected
- {{hadoop.security.credential.provider.path}} provided, credential password not provided, password provided by argument - Successful getting information, [~aihuaxu]: Could you please review?

Thanks,
Peter, The patch looks good. +1., Isn't that the expected behavior? If {{hadoop.security.credential.provider.path}} is provided the password has to be provided through either the environment variable or from {{HADOOP_CREDSTORE_PASSWORD}} from the command line. If the user is using credential provider API to secure passwords why will they want to provide the password in clear text on commandline?, SchemaTool provides a way to override the user and password from the command line, in clear text, e.g., with different user rather than the one configured in the conf. 

The jira is to fix this issue that the password is not taken even if it's supplied through command line. 

[~pvary] Is that correct?, Exactly [~aihuaxu].

[~vihangk1]: There is an exisiting possibility to override specific configuration parameters (password, user).
This was working as expected when the password was provided in clear text in the configuration, but was not working if the password was provided by the credential provider (any exception prevented the tool to run, even when the correct password is provided command line). This patch aims to amend this.
I hope my intention is more clear now :)

Thanks,
Peter, Thanks [~pvary] for the explaination. The patch looks good to me in that case +1 (non-binding), Pushed to master. Thanks Peter to work on it and Vihang for reviewing., [~pvary] Seems this breaks the build and causes a lot of test failures. I didn't notice that the pre-commit test was run. Can you take a look?, The patch is reverted., Forgot to press submit patch button.

Let's see what will happen, Build infrastructure failure:
{code}
+ curl -s -S --location --retry 3 https://issues.apache.org/jira/browse/HIVE-16057
curl: (7) Failed to connect to issues.apache.org port 443: No route to host
{code}

Let's see if it is solved, or not, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12856179/HIVE-16057.02.patch

{color:red}ERROR:{color} -1 due to no test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 21 failed/errored test(s), 10327 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestBeeLineDriver.testCliDriver[escape_comments] (batchId=229)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_text_vec_table] (batchId=147)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=224)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query23] (batchId=224)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[vector_between_in] (batchId=119)
org.apache.hive.beeline.TestSchemaTool.testNestedScriptsForDerby (batchId=212)
org.apache.hive.beeline.TestSchemaTool.testNestedScriptsForMySQL (batchId=212)
org.apache.hive.beeline.TestSchemaTool.testNestedScriptsForOracle (batchId=212)
org.apache.hive.beeline.TestSchemaTool.testPostgresFilter (batchId=212)
org.apache.hive.beeline.TestSchemaTool.testSchemaInit (batchId=212)
org.apache.hive.beeline.TestSchemaTool.testSchemaInitDryRun (batchId=212)
org.apache.hive.beeline.TestSchemaTool.testSchemaUpgrade (batchId=212)
org.apache.hive.beeline.TestSchemaTool.testSchemaUpgradeDryRun (batchId=212)
org.apache.hive.beeline.TestSchemaTool.testScriptMultiRowComment (batchId=212)
org.apache.hive.beeline.TestSchemaTool.testScriptWithDelimiter (batchId=212)
org.apache.hive.beeline.TestSchemaTool.testScripts (batchId=212)
org.apache.hive.beeline.TestSchemaTool.testValidateLocations (batchId=212)
org.apache.hive.beeline.TestSchemaTool.testValidateNullValues (batchId=212)
org.apache.hive.beeline.TestSchemaTool.testValidateSchemaTables (batchId=212)
org.apache.hive.beeline.TestSchemaTool.testValidateSchemaVersions (batchId=212)
org.apache.hive.beeline.TestSchemaTool.testValidateSequences (batchId=212)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/3951/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/3951/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-3951/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 21 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12856179 - PreCommit-HIVE-Build, Was not aware, that there are itests for SchemaTool too... Always learning :D
Modified the test to set username and password before running the schematool.

[~aihuaxu]: What do you think about this change? Is it ok, or using the schematool programmatically is an intended use so the doInit method should try to load the username/password too?

Thanks,
Peter, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12856185/HIVE-16057.03.patch

{color:green}SUCCESS:{color} +1 due to 1 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 3 failed/errored test(s), 10327 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestBeeLineDriver.testCliDriver[escape_comments] (batchId=229)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_text_vec_table] (batchId=147)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[vector_between_in] (batchId=119)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/3952/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/3952/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-3952/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 3 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12856185 - PreCommit-HIVE-Build, The failures are not related., +1 on the new patch. , [~aihuaxu] Ready for commit ?, Pushed to master. Thanks Peter for the work., Hive 3.0.0 has been released so closing this jira.]