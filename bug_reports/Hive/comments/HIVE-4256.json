[we have seen 'similar' issues with Hive 0.8, 0.9 and 0.10 re metadata methods such as getTables etc failing to work when null is provided as parameter values for schema etc. , We've seen the behavior where the database specified in the JDBC URL is *sometimes* ignored. 

We worked around it by executing a "use database" query before any others. 

However, It also appears that there is some lingering state because the next program that runs against Hive will use the database specified in the last "use database" statement and not the one specified in the JDBC URL. So all our Hive JDBC programs execute a "use database" query before running any others. 

This is with the Cloudera variant of 0.10.0.


, bq.  It also appears that there is some lingering state because the next program that runs against Hive will use the database specified in the last "use database" statement and not the one specified in the JDBC URL. 
[~jeffbeard] I submitted a fix for that in HIVE-4171, you need that or an equivalent fix.  It is now also part of apache hive 0.12 release., [~analog.sony] Do you want to take a look at this jira ? We just need to call "use database" for database in connection string. See HiveConnection.java
, I can take it up this ticket., [~cdrome]  If you are not working on this, can I take up this ticket., RB Link
https://reviews.apache.org/r/16037/, 

{color:green}Overall{color}: +1 all checks pass

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12617126/HIVE-4256.patch

{color:green}SUCCESS:{color} +1 4457 tests passed

Test results: http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/531/testReport
Console output: http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/531/console

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12617126, Thanks for the patch Anandha! I have added some comments to review board.
, updated the patch as per comments in RB, 

{color:green}Overall{color}: +1 all checks pass

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12617344/HIVE-4256.1.patch

{color:green}SUCCESS:{color} +1 4458 tests passed

Test results: http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/552/testReport
Console output: http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/552/console

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12617344, attached the patch with indentation comments, +1, 

{color:green}Overall{color}: +1 all checks pass

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12617530/HIVE-4256.2.patch

{color:green}SUCCESS:{color} +1 4460 tests passed

Test results: http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/560/testReport
Console output: http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/560/console

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12617530, +1
[~analog.sony] some minor suggestions on the review board. 
BTW, the patch doesn't apply cleanly. Could you please rebase it ?, [~prasadm]

I didn't get your comment "rebase". 
How do I do it. Could you explain in steps ?, The one or more files in your patch has changed on trunk since the patch branched off. Hence the patch doesn't apply cleanly.

If you are using git, you can pull the trunk latest trunk in your repository and use 'git rebase' (checkout http://git-scm.com/book/ch3-6.html).
There are UI tools like [gitk|http://gitk.sourceforge.net/] on Linux or [source tree|http://www.sourcetreeapp.com/] on Mac for git rebase/merge etc.
, I rebased and uploaded the code., 

{color:red}Overall{color}: -1 no tests executed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12618752/HIVE-4256.3.patch

Test results: http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/639/testReport
Console output: http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/639/console

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Tests exited with: NonZeroExitCodeException
Command 'bash /data/hive-ptest/working/scratch/source-prep.sh' failed with exit status 1 and output '+ [[ -n '' ]]
+ export 'ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m '
+ ANT_OPTS='-Xmx1g -XX:MaxPermSize=256m '
+ export 'M2_OPTS=-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128'
+ M2_OPTS='-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128'
+ cd /data/hive-ptest/working/
+ tee /data/hive-ptest/logs/PreCommit-HIVE-Build-639/source-prep.txt
+ [[ false == \t\r\u\e ]]
+ mkdir -p maven ivy
+ [[ svn = \s\v\n ]]
+ [[ -n '' ]]
+ [[ -d apache-svn-trunk-source ]]
+ [[ ! -d apache-svn-trunk-source/.svn ]]
+ [[ ! -d apache-svn-trunk-source ]]
+ cd apache-svn-trunk-source
+ svn revert -R .
++ awk '{print $2}'
++ egrep -v '^X|^Performing status on external'
++ svn status --no-ignore
+ rm -rf target datanucleus.log ant/target shims/target shims/0.20/target shims/assembly/target shims/0.20S/target shims/0.23/target shims/common/target shims/common-secure/target packaging/target hbase-handler/target testutils/target jdbc/target metastore/target itests/target itests/hcatalog-unit/target itests/test-serde/target itests/qtest/target itests/hive-unit/target itests/custom-serde/target itests/util/target hcatalog/target hcatalog/storage-handlers/hbase/target hcatalog/server-extensions/target hcatalog/core/target hcatalog/webhcat/svr/target hcatalog/webhcat/java-client/target hcatalog/hcatalog-pig-adapter/target hwi/target common/target common/src/gen contrib/target service/target serde/target beeline/target odbc/target cli/target ql/dependency-reduced-pom.xml ql/target
+ svn update

Fetching external item into 'hcatalog/src/test/e2e/harness'
External at revision 1550878.

At revision 1550878.
+ patchCommandPath=/data/hive-ptest/working/scratch/smart-apply-patch.sh
+ patchFilePath=/data/hive-ptest/working/scratch/build.patch
+ [[ -f /data/hive-ptest/working/scratch/build.patch ]]
+ chmod +x /data/hive-ptest/working/scratch/smart-apply-patch.sh
+ /data/hive-ptest/working/scratch/smart-apply-patch.sh /data/hive-ptest/working/scratch/build.patch
The patch does not appear to apply with p0, p1, or p2
+ exit 1
'
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12618752, The last patch HIVE-4256.3.patch also didn't apply cleanly. I am attaching the rebased patch that resolves the TestJdbcDriver2 conflict (due to new test).

will commit if the pre-commit test run pass., [~prasadm]
Thanks.
I just noticed this morning. I was looking into that.  , 

{color:red}Overall{color}: -1 at least one tests failed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12618784/HIVE-4256.4.patch

{color:red}ERROR:{color} -1 due to 1 failed/errored test(s), 4786 tests executed
*Failed tests:*
{noformat}
org.apache.hive.jdbc.TestJdbcDriver2.testURIDatabaseName
{noformat}

Test results: http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/641/testReport
Console output: http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/641/console

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 1 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12618784, looking into this, [~analog.sony] I guess starting hiveserver2 at fixed port and waiting for a hardcoded time interval would make the test bit flaky. You might want to consider moving the testcase to TestJdbcWithMiniHS2. That uses the MiniHS2 framework which handles HS2 operations.
, Here's an example of one the test scenarios using MiniHS2
{code}
    Connection con1 =  DriverManager.getConnection(miniHS2.getJdbcURL(),
          System.getProperty("user.name"), "bar");
    String dbName="test_conn_str_default_db";
    Statement stmt = con1.createStatement();
    stmt.execute("create database  if not exists "+dbName);
    stmt.close();
    con1.close();
{code}
, [~prasad mu],[~thejas]

Modified the code and moved the test case to TestJdbcMiniHS2.java., 

{color:red}Overall{color}: -1 no tests executed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12618842/HIVE-4256.5.patch

Test results: http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/644/testReport
Console output: http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/644/console

Messages:
{noformat}
**** This message was trimmed, see log for full details ****
[INFO] Excluding org.apache.httpcomponents:httpclient:jar:4.2.5 from the shaded jar.
[INFO] Excluding org.apache.httpcomponents:httpcore:jar:4.2.4 from the shaded jar.
[INFO] Excluding org.apache.zookeeper:zookeeper:jar:3.4.5 from the shaded jar.
[INFO] Excluding jline:jline:jar:0.9.94 from the shaded jar.
[INFO] Excluding org.codehaus.groovy:groovy-all:jar:2.1.6 from the shaded jar.
[INFO] Including org.codehaus.jackson:jackson-core-asl:jar:1.9.2 in the shaded jar.
[INFO] Including org.codehaus.jackson:jackson-mapper-asl:jar:1.9.2 in the shaded jar.
[INFO] Excluding org.datanucleus:datanucleus-core:jar:3.2.2 from the shaded jar.
[INFO] Including com.google.guava:guava:jar:11.0.2 in the shaded jar.
[INFO] Excluding com.google.code.findbugs:jsr305:jar:1.3.9 from the shaded jar.
[INFO] Including com.google.protobuf:protobuf-java:jar:2.5.0 in the shaded jar.
[INFO] Including com.googlecode.javaewah:JavaEWAH:jar:0.3.2 in the shaded jar.
[INFO] Including org.iq80.snappy:snappy:jar:0.2 in the shaded jar.
[INFO] Including org.json:json:jar:20090211 in the shaded jar.
[INFO] Excluding stax:stax-api:jar:1.0.1 from the shaded jar.
[INFO] Excluding org.apache.hadoop:hadoop-core:jar:1.2.1 from the shaded jar.
[INFO] Excluding xmlenc:xmlenc:jar:0.52 from the shaded jar.
[INFO] Excluding com.sun.jersey:jersey-core:jar:1.14 from the shaded jar.
[INFO] Excluding com.sun.jersey:jersey-json:jar:1.14 from the shaded jar.
[INFO] Excluding org.codehaus.jettison:jettison:jar:1.1 from the shaded jar.
[INFO] Excluding com.sun.xml.bind:jaxb-impl:jar:2.2.3-1 from the shaded jar.
[INFO] Excluding javax.xml.bind:jaxb-api:jar:2.2.2 from the shaded jar.
[INFO] Excluding javax.xml.stream:stax-api:jar:1.0-2 from the shaded jar.
[INFO] Excluding javax.activation:activation:jar:1.1 from the shaded jar.
[INFO] Excluding org.codehaus.jackson:jackson-jaxrs:jar:1.9.2 from the shaded jar.
[INFO] Excluding org.codehaus.jackson:jackson-xc:jar:1.9.2 from the shaded jar.
[INFO] Excluding com.sun.jersey:jersey-server:jar:1.14 from the shaded jar.
[INFO] Excluding asm:asm:jar:3.1 from the shaded jar.
[INFO] Excluding org.apache.commons:commons-math:jar:2.1 from the shaded jar.
[INFO] Excluding commons-configuration:commons-configuration:jar:1.6 from the shaded jar.
[INFO] Excluding commons-digester:commons-digester:jar:1.8 from the shaded jar.
[INFO] Excluding commons-beanutils:commons-beanutils:jar:1.7.0 from the shaded jar.
[INFO] Excluding commons-beanutils:commons-beanutils-core:jar:1.8.0 from the shaded jar.
[INFO] Excluding commons-net:commons-net:jar:1.4.1 from the shaded jar.
[INFO] Excluding org.mortbay.jetty:jetty:jar:6.1.26 from the shaded jar.
[INFO] Excluding org.mortbay.jetty:jetty-util:jar:6.1.26 from the shaded jar.
[INFO] Excluding tomcat:jasper-runtime:jar:5.5.12 from the shaded jar.
[INFO] Excluding tomcat:jasper-compiler:jar:5.5.12 from the shaded jar.
[INFO] Excluding org.mortbay.jetty:jsp-api-2.1:jar:6.1.14 from the shaded jar.
[INFO] Excluding org.mortbay.jetty:servlet-api-2.5:jar:6.1.14 from the shaded jar.
[INFO] Excluding org.mortbay.jetty:jsp-2.1:jar:6.1.14 from the shaded jar.
[INFO] Excluding ant:ant:jar:1.6.5 from the shaded jar.
[INFO] Excluding commons-el:commons-el:jar:1.0 from the shaded jar.
[INFO] Excluding net.java.dev.jets3t:jets3t:jar:0.6.1 from the shaded jar.
[INFO] Excluding hsqldb:hsqldb:jar:1.8.0.10 from the shaded jar.
[INFO] Excluding oro:oro:jar:2.0.8 from the shaded jar.
[INFO] Excluding org.eclipse.jdt:core:jar:3.1.1 from the shaded jar.
[INFO] Excluding org.slf4j:slf4j-api:jar:1.7.5 from the shaded jar.
[INFO] Excluding org.slf4j:slf4j-log4j12:jar:1.7.5 from the shaded jar.
[INFO] Replacing original artifact with shaded artifact.
[INFO] Replacing /data/hive-ptest/working/apache-svn-trunk-source/ql/target/hive-exec-0.13.0-SNAPSHOT.jar with /data/hive-ptest/working/apache-svn-trunk-source/ql/target/hive-exec-0.13.0-SNAPSHOT-shaded.jar
[INFO] Dependency-reduced POM written at: /data/hive-ptest/working/apache-svn-trunk-source/ql/dependency-reduced-pom.xml
[INFO] Dependency-reduced POM written at: /data/hive-ptest/working/apache-svn-trunk-source/ql/dependency-reduced-pom.xml
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-exec ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/ql/target/hive-exec-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-exec/0.13.0-SNAPSHOT/hive-exec-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/ql/dependency-reduced-pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-exec/0.13.0-SNAPSHOT/hive-exec-0.13.0-SNAPSHOT.pom
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/ql/target/hive-exec-0.13.0-SNAPSHOT-tests.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-exec/0.13.0-SNAPSHOT/hive-exec-0.13.0-SNAPSHOT-tests.jar
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Service 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-service ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/service (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- build-helper-maven-plugin:1.8:add-source (add-source) @ hive-service ---
[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/service/src/model added.
[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/service/src/gen/thrift/gen-javabean added.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-service ---
[debug] execute contextualize
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/service/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-service ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-service ---
[INFO] Compiling 153 source files to /data/hive-ptest/working/apache-svn-trunk-source/service/target/classes
[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/service/src/java/org/apache/hive/service/cli/operation/SQLOperation.java uses or overrides a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[WARNING] Note: Some input files use unchecked or unsafe operations.
[WARNING] Note: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-service ---
[debug] execute contextualize
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/service/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-service ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/service/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/service/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/service/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/service/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-service ---
[INFO] Compiling 7 source files to /data/hive-ptest/working/apache-svn-trunk-source/service/target/test-classes
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-service ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-service ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/service/target/hive-service-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-jar-plugin:2.2:test-jar (default) @ hive-service ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/service/target/hive-service-0.13.0-SNAPSHOT-tests.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-service ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/service/target/hive-service-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-service/0.13.0-SNAPSHOT/hive-service-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/service/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-service/0.13.0-SNAPSHOT/hive-service-0.13.0-SNAPSHOT.pom
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/service/target/hive-service-0.13.0-SNAPSHOT-tests.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-service/0.13.0-SNAPSHOT/hive-service-0.13.0-SNAPSHOT-tests.jar
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive JDBC 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-jdbc ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/jdbc (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-jdbc ---
[debug] execute contextualize
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/jdbc/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-jdbc ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-jdbc ---
[INFO] Compiling 30 source files to /data/hive-ptest/working/apache-svn-trunk-source/jdbc/target/classes
[INFO] -------------------------------------------------------------
[ERROR] COMPILATION ERROR : 
[INFO] -------------------------------------------------------------
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/jdbc/src/java/org/apache/hive/jdbc/HiveConnection.java:[279,15] <identifier> expected
[INFO] 1 error
[INFO] -------------------------------------------------------------
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Summary:
[INFO] 
[INFO] Hive .............................................. SUCCESS [4.700s]
[INFO] Hive Ant Utilities ................................ SUCCESS [6.756s]
[INFO] Hive Shims Common ................................. SUCCESS [3.355s]
[INFO] Hive Shims 0.20 ................................... SUCCESS [2.286s]
[INFO] Hive Shims Secure Common .......................... SUCCESS [2.575s]
[INFO] Hive Shims 0.20S .................................. SUCCESS [1.385s]
[INFO] Hive Shims 0.23 ................................... SUCCESS [2.840s]
[INFO] Hive Shims ........................................ SUCCESS [3.711s]
[INFO] Hive Common ....................................... SUCCESS [5.628s]
[INFO] Hive Serde ........................................ SUCCESS [13.555s]
[INFO] Hive Metastore .................................... SUCCESS [25.591s]
[INFO] Hive Query Language ............................... SUCCESS [59.064s]
[INFO] Hive Service ...................................... SUCCESS [4.608s]
[INFO] Hive JDBC ......................................... FAILURE [0.675s]
[INFO] Hive Beeline ...................................... SKIPPED
[INFO] Hive CLI .......................................... SKIPPED
[INFO] Hive Contrib ...................................... SKIPPED
[INFO] Hive HBase Handler ................................ SKIPPED
[INFO] Hive HCatalog ..................................... SKIPPED
[INFO] Hive HCatalog Core ................................ SKIPPED
[INFO] Hive HCatalog Pig Adapter ......................... SKIPPED
[INFO] Hive HCatalog Server Extensions ................... SKIPPED
[INFO] Hive HCatalog Webhcat Java Client ................. SKIPPED
[INFO] Hive HCatalog Webhcat ............................. SKIPPED
[INFO] Hive HCatalog HBase Storage Handler ............... SKIPPED
[INFO] Hive HWI .......................................... SKIPPED
[INFO] Hive ODBC ......................................... SKIPPED
[INFO] Hive Shims Aggregator ............................. SKIPPED
[INFO] Hive TestUtils .................................... SKIPPED
[INFO] Hive Packaging .................................... SKIPPED
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 2:19.623s
[INFO] Finished at: Sun Dec 15 21:42:18 EST 2013
[INFO] Final Memory: 67M/512M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.1:compile (default-compile) on project hive-jdbc: Compilation failure
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/jdbc/src/java/org/apache/hive/jdbc/HiveConnection.java:[279,15] <identifier> expected
[ERROR] -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn <goals> -rf :hive-jdbc
+ exit 1
'
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12618842, updated wrong patch, 

{color:green}Overall{color}: +1 all checks pass

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12618849/HIVE-4256.6.patch

{color:green}SUCCESS:{color} +1 4786 tests passed

Test results: http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/646/testReport
Console output: http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/646/console

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12618849, +1
, Patch committed to trunk.
Thanks for the contribution [~analog.sony] !]