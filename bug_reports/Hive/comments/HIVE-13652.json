[Adding some general background info for anyone who wishes to work on this:

(Note, this is not necessarily to do about Hive Export/Import, but about hive managed table partition creation in general, and the problem is that there isn't a "good" solution to this that won't bug someone the wrong way)

Given that the source can be any arbitrary table, even ones created by a user outside of hive, deciding what "order" to retain is tricky, or even difficult to know what "order" was used. This is so, since the source can have partition year=2012, hour=18, and yet have a directory that looks like any of the following:

{noformat}
/apps/hive/warehouse/weblogs/year=2012/hour=18
/apps/hive/warehouse/weblogs/2012/18
/apps/hive/warehouse/weblogs/201218/
/apps/hive/warehouse/weblogs/frank/
{noformat}

Thus, we do not store the correlation between partition key-values in source and destination, and the only thing we "know" is that a partition with a set of key-value-pairs is associated with some data that we read. Thus, in the destination, irrespective of what the source said about the dir name, we ignore it, and recreate a partition based only on key-value pair info, and let hive default loading mechanism pick the location for us.

==

The underlying problem here is this : currently, the list of key-values is stored as a HashMap which is not ordered, and thus, is not guaranteed to be identical across JDKs or OSes. This doesn't currently affect us, however, since it's only relevant at the time a partition is created, and as long as the metadata for the data is consistent to point to the correct location, hive doesn't care.

Since we don't force an order, that order is whatever native sorting order for that HashMap would be for those values, on that JDK version + OS. This means that as long as you don't change JDK version + OS + the keyvalues, it is repeatably consistent. Change even one of those, however, and you could easily wind up with this differing. This can even happen with Hive wherein we've done "ALTER TABLE ADD PARTITION" for a while on a cluster, upgrade a jdk, and then we do another "ALTER TABLE ADD PARTITION", and it picks dd/mm instead of mm/dd that it has been for a while. Or, if one machine was on ubuntu and the other on centos/etc.

Some possible solutions:
a) We can force order of key-values by order of key occurence in the metastore for all "new" partitions ever created in hive. The problem with this is that it might force additional metastore calls to determine this order(adding load).
b) We can force alphabetical order of key-values for all "new" partitions ever created in hive. The problem with this is that we now get into a notion of what is alphabetical order in what codepage (although that can still deterministic). It's also possible that going alphabetical will cause a pretty "dumb" ordering, where "dumb" in this case can mean  (i) non-intuitive : Say day=23/market_id=45/month=4/year=2016 , or (ii) bad in terms of skew, having a higher frequency partition separation be a parent of a lower freq one, resulting in a much larger number of dirs created.

Neither of these solve the original issue of export/import, because all we wind up doing here is forcing order going forward, and not making sure to "retain" whatever existed. Also, if a JDK/OS combination resulted in a different default for two different users for similar schema, then by "standardizing" it going forward, we break convention for one of them, either way.

Even in the cases where currently, export/import has been flipping a mm/dd/yyyy into a dd/mm/yyyy, for eg., if we standardize to fix it to retain original order, we make it weird for a bunch of users that have had a mm/dd/yyyy in place, and don't care about the order as long as it is consistent across the table(a goal I'd argue they shouldn't have/care about, but nevertheless one that might exist)

Other solutions that are possible:

a) Let a table specify that it cares about its default partition-naming-scheme : Similar to what  hcat.dynamic.partitioning.custom.pattern does for HCat . The problem with this is it can introduce complexity to a warehouse if people use this feature extensively - i.e. it does actually nothing for the data and perf in hive - it's simply for usability with external tools, and we run into a too-many-configs-why-was-this-feature-even-here scenario, but maybe we can ignore that.

b) Change export/import to honour existing order in the case of managed tables (but ignore order or customization for external tables, because we truly cannot determine what patterns might be used for external tables ) - this does not help existing export/import cases, and can decide on a different norm for a bunch of users, but does help a little going ahead.

Sorry for the longer than intended ramble, but this problem has been known about for a while and wasn't fixed because of these, and I wanted to provide context., I just wonder how come there is no definition of order of partitions - when you create table you define order in "partition by" clause, when you do "describe table" than you get the partitioning columns in right order (even after "wrong" import).
If you are worried about external tables than lets use your b) option from other solutions, even though I don't fully comprehend how would it not help existing export/import cases

In any case current behaviour is the worst possible as it leaves partitioning on "higher will", > In any case current behaviour is the worst possible as it leaves partitioning on "higher will"

I laughed at this, and you're definitely right about this.

The rest is merely context behind why this problem has not been tackled earlier (since we break it for some users at the very least), and honestly, if we don't tackle it now, we simply kick the ball further down the road, and it will need tackling one way or another, which we have been doing so far., Added 01.patch:
- Fixed the partition ordering issue with import/repl load.
- Added a test case to verify the bootstrap and incremental replication for table with multi-partition-columns. This test will pass in base code as well as change in order doesn't affect the functionality but impacts performance.
- Added screenshots to show the path for partition data files before and after the fix.

Request [~sushanth], [~thejas] to review the patch. Thanks!, GitHub user sankarh opened a pull request:

    https://github.com/apache/hive/pull/180

    HIVE-13652: Import table change order of dynamic partitions

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/sankarh/hive HIVE-13652

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/hive/pull/180.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #180
    
----
commit 3af1f73aeb854c5b911f48c925365336f15cb0e5
Author: Sankar Hariappan <mailtosankarh@gmail.com>
Date:   2017-05-04T18:51:38Z

    HIVE-13652: Import table change order of dynamic partitions

----
, [~sankarh]
It seems like this test would pass even without this change. Can you also add a check to verify the partition name and location after repl-load ?

ie, check output of "show partitions" and
the location filed (suffix) in output of  "show table extended like" + dbName + "_dupe.namelist partition (year=1990 and month=5 and day=25)" ?

, [~thejas] 
Yes, I knew the test will pass even without this change. I just added the test as this case was never there.
But, I was not aware (or at least didn't click) of above show commands to verify it. Will use these commands to verify the fix and provide a patch soon.
Thanks!, Updated patch for additional verification of partition location.
[~thejas], Please review the patch., I just wonder, if by using LinkedHashMap we don't introduce just another vulnerability there as order of items in the HashMap is not defined and if ever hashing algo change than again we may get  completely different order?


, [~luky]
LinkedHashMap has iteration order that is same as the insertion order, so this would work. So the ordering is defined (it uses a doubly-linked list to remember the order).

However, I agree that the use of Map for partSpec object in the AddPartitionDesc methods makes it vulnerable to such bugs again in future. We should do a cleanup to replace use of Map<String, String> with something like List<Pair<String, String>> which would have prevented this bug in first place. I will create a follow up bug for that.

, Created HIVE-16597 to track larger cleanup around datastructure for partSpec.
, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12866633/HIVE-13652.01.patch

{color:green}SUCCESS:{color} +1 due to 1 test(s) being added or modified.

{color:green}SUCCESS:{color} +1 due to 10653 tests passed

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/5051/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/5051/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-5051/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12866633 - PreCommit-HIVE-Build, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12866633/HIVE-13652.01.patch

{color:green}SUCCESS:{color} +1 due to 1 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 2 failed/errored test(s), 10653 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_if_expr] (batchId=143)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_join30] (batchId=148)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/5078/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/5078/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-5078/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 2 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12866633 - PreCommit-HIVE-Build, [~thejas]
The test failures are irrelevant to this patch. Please help to commit this patch., Thanks for the updates to the test case. +1
, Patch committed to master. Thanks [~sankarh]!
, Does this need to be documented in the wiki?

* [Import/Export | https://cwiki.apache.org/confluence/display/Hive/LanguageManual+ImportExport], Yes, I guess we could document this as a known issue in earlier versions.
, Okay, I added a TODOC3.0 label.  Thanks Thejas., Thanks [~thejas] for the commit!, Github user sankarh closed the pull request at:

    https://github.com/apache/hive/pull/180
, Hive 3.0.0 has been released so closing this jira.]