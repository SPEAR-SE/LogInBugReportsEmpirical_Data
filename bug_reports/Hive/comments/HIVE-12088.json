[is there any help?, @[~xuefuz] is there anything wrong about metastore?
i copy a hive0.14 metastore mysql db when i upgrade to 1.2.1.
and db`s characterencoding is latin1.when i do 'msck repair table abc;'
output:'OK
Partitions not in metastore:	rec_feature_feedback:l_date=2015-09-09/cid=Cyiyaowang/bid=F7734668_CC49_8C4F_24C5_EA8B6728E394	rec_feature_feedback:l_date=2015-09-09/cid=Czgc_pc/bid=949722CF_12F7_523A_EE21_E3D591B7E755
Time taken: 137.984 seconds, Fetched: 1 row(s)'

a segment of hive.log is:
"Caused by: com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: Specified key was too long; max key length is 767 bytes
        at sun.reflect.GeneratedConstructorAccessor40.newInstance(Unknown Source)
        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
        at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
        at com.mysql.jdbc.Util.handleNewInstance(Util.java:406)
        at com.mysql.jdbc.Util.getInstance(Util.java:381)
        at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:1030)"

i upload a hive.log in attachments., @[~xuefuz] is there anything wrong about metastore?
i copy a hive0.14 metastore mysql db when i upgrade to 1.2.1.
and db`s characterencoding is latin1.when i do 'msck repair table abc;'
output:'OK
Partitions not in metastore:	rec_feature_feedback:l_date=2015-09-09/cid=Cyiyaowang/bid=F7734668_CC49_8C4F_24C5_EA8B6728E394	rec_feature_feedback:l_date=2015-09-09/cid=Czgc_pc/bid=949722CF_12F7_523A_EE21_E3D591B7E755
Time taken: 137.984 seconds, Fetched: 1 row(s)'

a segment of hive.log is:
"Caused by: com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: Specified key was too long; max key length is 767 bytes
        at sun.reflect.GeneratedConstructorAccessor40.newInstance(Unknown Source)
        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
        at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
        at com.mysql.jdbc.Util.handleNewInstance(Util.java:406)
        at com.mysql.jdbc.Util.getInstance(Util.java:381)
        at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:1030)"

i upload a hive.log in attachments., @[~xuefuz] is there anything wrong about metastore?
i copy a hive0.14 metastore mysql db when i upgrade to 1.2.1.
and db`s characterencoding is latin1.when i do 'msck repair table abc;'
output:'OK
Partitions not in metastore:	rec_feature_feedback:l_date=2015-09-09/cid=Cyiyaowang/bid=F7734668_CC49_8C4F_24C5_EA8B6728E394	rec_feature_feedback:l_date=2015-09-09/cid=Czgc_pc/bid=949722CF_12F7_523A_EE21_E3D591B7E755
Time taken: 137.984 seconds, Fetched: 1 row(s)'

a segment of hive.log is:
"Caused by: com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: Specified key was too long; max key length is 767 bytes
        at sun.reflect.GeneratedConstructorAccessor40.newInstance(Unknown Source)
        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
        at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
        at com.mysql.jdbc.Util.handleNewInstance(Util.java:406)
        at com.mysql.jdbc.Util.getInstance(Util.java:381)
        at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:1030)"

i upload a hive.log in attachments., when i source apache-hive-1.2.1-bin/scripts/metastore/upgrade/mysql/hive-schema-0.14.0.mysql.sql the error nerver come out again., sorry i may be make a confuse.
the "error never come out again" i said is mean the msck repair table abc get worked,but insert into still cant work.
i guess is may be the incompatibility between 0.14 and 1.2.1 metastore data.
so insteads i copy the metadata from 0.14 and source two files:
upgrade-0.14.0-to-1.1.0.mysql.sql
upgrade-1.1.0-to-1.2.0.mysql.sql
but it is useless.
could you gave me some suggestions?[~xuefuz],thanks!, there are two other error in this job:
2015-10-19 17:27:37,015 ERROR [main]: mr.ExecDriver (ExecDriver.java:execute(400)) - yarn
2015-10-19 17:27:38,424 WARN  [main]: jdbc.JDBCStatsPublisher (JDBCStatsPublisher.java:init(310)) - Failed to update ID (size 255)
com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'VARCHAR(4000)' at line 1
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:406)
	at com.mysql.jdbc.Util.getInstance(Util.java:381)
	at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:1030)
	at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:956)
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3558)
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3490)
	at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:1959)
	at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2109)
	at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2642)
	at com.mysql.jdbc.StatementImpl.executeUpdate(StatementImpl.java:1647)
	at com.mysql.jdbc.StatementImpl.executeUpdate(StatementImpl.java:1566)
	at org.apache.hadoop.hive.ql.stats.jdbc.JDBCStatsPublisher.init(JDBCStatsPublisher.java:304)
	at org.apache.hadoop.hive.ql.exec.mr.ExecDriver.execute(ExecDriver.java:411)
	at org.apache.hadoop.hive.ql.exec.mr.MapRedTask.execute(MapRedTask.java:137)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:160)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:88)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1653)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1412)
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1195)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1059)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1049)
	at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:213)
	at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:165)
	at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:376)
	at org.apache.hadoop.hive.cli.CliDriver.executeDriver(CliDriver.java:736)
	at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:681)
	at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:621)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.util.RunJar.run(RunJar.java:221)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:136)
2015-10-19 17:27:38,558 INFO  [main]: exec.Utilities (Utilities.java:getBaseWork(390)) - PLAN PATH = hdfs://bfdhadoop26/tmp/hive/hadoop/87b4cb59-82e2-4b8d-a66b-0ecd9587e14a/hive_2015-10-19_17-27-31_247_5519557068960011437-1/-mr-10003/d9d465cb-1b84-41d3-a23a-a4d6e511fe9c/map.xml
2015-10-19 17:27:38,559 INFO  [main]: exec.Utilities (Utilities.java:getBaseWork(390)) - PLAN PATH = hdfs://bfdhadoop26/tmp/hive/hadoop/87b4cb59-82e2-4b8d-a66b-0ecd9587e14a/hive_2015-10-19_17-27-31_247_5519557068960011437-1/-mr-10003/d9d465cb-1b84-41d3-a23a-a4d6e511fe9c/reduce.xml
2015-10-19 17:27:38,559 INFO  [main]: exec.Utilities (Utilities.java:getBaseWork(400)) - ***************non-local mode***************
2015-10-19 17:27:38,560 INFO  [main]: exec.Utilities (Utilities.java:getBaseWork(404)) - local path = hdfs://bfdhadoop26/tmp/hive/hadoop/87b4cb59-82e2-4b8d-a66b-0ecd9587e14a/hive_2015-10-19_17-27-31_247_5519557068960011437-1/-mr-10003/d9d465cb-1b84-41d3-a23a-a4d6e511fe9c/reduce.xml
2015-10-19 17:27:38,560 INFO  [main]: exec.Utilities (Utilities.java:getBaseWork(416)) - Open file to read in plan: hdfs://bfdhadoop26/tmp/hive/hadoop/87b4cb59-82e2-4b8d-a66b-0ecd9587e14a/hive_2015-10-19_17-27-31_247_5519557068960011437-1/-mr-10003/d9d465cb-1b84-41d3-a23a-a4d6e511fe9c/reduce.xml
2015-10-19 17:27:38,597 INFO  [main]: exec.Utilities (Utilities.java:getBaseWork(456)) - File not found: File does not exist: /tmp/hive/hadoop/87b4cb59-82e2-4b8d-a66b-0ecd9587e14a/hive_2015-10-19_17-27-31_247_5519557068960011437-1/-mr-10003/d9d465cb-1b84-41d3-a23a-a4d6e511fe9c/reduce.xml
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:66)
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:56)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1891)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1832)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1812)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1784)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:542)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:362)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2039)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2035)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2033)

2015-10-19 17:27:38,598 INFO  [main]: exec.Utilities (Utilities.java:getBaseWork(457)) - No plan file found: hdfs://bfdhadoop26/tmp/hive/hadoop/87b4cb59-82e2-4b8d-a66b-0ecd9587e14a/hive_2015-10-19_17-27-31_247_5519557068960011437-1/-mr-10003/d9d465cb-1b84-41d3-a23a-a4d6e511fe9c/reduce.xml, [~gopalv], [~gopalv] [~xuefuz]please ignore this,it is a mistake. sorry!, Removing fix version 1.2.2]