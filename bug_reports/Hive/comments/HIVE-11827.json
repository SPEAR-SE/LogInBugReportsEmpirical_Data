[schema info can be determined by column info if literal or url does not exist. determineSchemaOrThrowException should try to get the schema by columns info instead of just error out. 
, Need code review., My understanding is that for AVRO, schema must be provided via either a literal or url. In other words, the schema for AVRO tables comes from external. If we are adding functionality, then we have to ensure that the new feature works in more general cases than just an empty table., [~xuefuz], as in the AvroSerDe.initialize, we can getSchemaFromCols
This fix just works the similar way as in the initialize method., Okay. Could you add a test or modify your existing test case to insert some data and query it back?, [~xuefuz], I attach patch 2 to include the insert data and select back. There are should be two rows of data in the final table. , 

{color:red}Overall{color}: -1 at least one tests failed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12761239/HIVE-11827.2.patch

{color:red}ERROR:{color} -1 due to 3 failed/errored test(s), 9410 tests executed
*Failed tests:*
{noformat}
TestMiniSparkOnYarnCliDriver - did not produce a TEST-*.xml file
org.apache.hadoop.hive.thrift.TestHadoop20SAuthBridge.testSaslWithHiveMetaStore
org.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5337/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5337/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-5337/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 3 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12761239 - PreCommit-HIVE-TRUNK-Build, The failures are not related.
org.apache.hadoop.hive.thrift.TestHadoop20SAuthBridge.testSaslWithHiveMetaStore caused by following:
{noformat}
Caused by: org.apache.thrift.transport.TSaslTransportException: No data or no sasl data in the stream
	at org.apache.thrift.transport.TSaslTransport.open(TSaslTransport.java:328) ~[libthrift-0.9.2.jar:0.9.2]
	at org.apache.thrift.transport.TSaslServerTransport.open(TSaslServerTransport.java:41) ~[libthrift-0.9.2.jar:0.9.2]
	at org.apache.thrift.transport.TSaslServerTransport$Factory.getTransport(TSaslServerTransport.java:216) ~[libthrift-0.9.2.jar:0.9.2]
	... 10 more
{noformat}
And it passed with my own build:
{noformat}
-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running org.apache.hadoop.hive.thrift.TestHadoop20SAuthBridge
Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 18.82 sec - in org.apache.hadoop.hive.thrift.TestHadoop20SAuthBridge

Results :

Tests run: 3, Failures: 0, Errors: 0, Skipped: 0
{noformat}

TestMiniSparkOnYarnCliDriver - did not produce a TEST-*.xml file
and org.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation failures age 3 or more. 
, [~xuefuz], could you review patch 2 to see if it has the required tests? Thanks, +1, Thanks [~xuefuz] for reviewing the patch., Committed to master and branch-1. Thanks, Yongzhi.]