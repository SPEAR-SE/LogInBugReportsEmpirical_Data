[

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12812615/HIVE-13989.1.patch

{color:green}SUCCESS:{color} +1 due to 1 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 6 failed/errored test(s), 10256 tests executed
*Failed tests:*
{noformat}
TestNegativeMinimrCliDriver-udf_local_resource.q-mapreduce_stack_trace_turnoff_hadoop20.q-mapreduce_stack_trace.q-and-6-more - did not produce a TEST-*.xml file
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_list_bucket_dml_12
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_stats_list_bucket
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver_vector_complex_all
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver_vector_complex_join
org.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_index_bitmap3
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-MASTER-Build/235/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-MASTER-Build/235/console
Test logs: http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-MASTER-Build-235/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 6 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12812615 - PreCommit-HIVE-MASTER-Build, [~cdrome] can you create a ReviewBoard for this? And also, describe what the issue you are trying to fix here?, [~spena] Might be of interest to you., [~cdrome] Besides the description of the issue, could you add an example on how to reproduce it?

[~ashutoshc] Are we continuing adding fixes to the branch-1?, [~ashutoshc], [~spena], sorry for the delay in updating details about this ticket.

This is a patch that we have had to use internally since 0.13.
I don't have access to a branch-2 cluster, but I can add some notes about how to replicate these failures on branch-1 with the version of Hadoop we use., [~ashutoshc], I created the following reviewboard request: https://reviews.apache.org/r/50018/, [~cdrome] You noted all these issues may not be present on hadoop 2.7 Now that Hive is on 2.7 , is whole of this patch still needed?, [~ashutoshc], I believe that I confirmed the Hive side of this patch is still necessary, but the HCatalog side of the patch may not be.

I likely won't have time to give solid confirmation next week, but will try to get closure on this issue the follow week., 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12812615/HIVE-13989.1.patch

{color:red}ERROR:{color} -1 due to build exiting with an error

Test results: https://builds.apache.org/job/PreCommit-HIVE-MASTER-Build/1104/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-MASTER-Build/1104/console
Test logs: http://ec2-204-236-174-241.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-MASTER-Build-1104/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Tests exited with: NonZeroExitCodeException
Command 'bash /data/hive-ptest/working/scratch/source-prep.sh' failed with exit status 1 and output '+ [[ -n /usr/java/jdk1.8.0_25 ]]
+ export JAVA_HOME=/usr/java/jdk1.8.0_25
+ JAVA_HOME=/usr/java/jdk1.8.0_25
+ export PATH=/usr/java/jdk1.8.0_25/bin/:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
+ PATH=/usr/java/jdk1.8.0_25/bin/:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
+ export 'ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m '
+ ANT_OPTS='-Xmx1g -XX:MaxPermSize=256m '
+ export 'M2_OPTS=-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128'
+ M2_OPTS='-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128'
+ cd /data/hive-ptest/working/
+ tee /data/hive-ptest/logs/PreCommit-HIVE-MASTER-Build-1104/source-prep.txt
+ [[ false == \t\r\u\e ]]
+ mkdir -p maven ivy
+ [[ git = \s\v\n ]]
+ [[ git = \g\i\t ]]
+ [[ -z master ]]
+ [[ -d apache-github-source-source ]]
+ [[ ! -d apache-github-source-source/.git ]]
+ [[ ! -d apache-github-source-source ]]
+ cd apache-github-source-source
+ git fetch origin
+ git reset --hard HEAD
HEAD is now at b74c4d0 HIVE-13383 : RetryingMetaStoreClient retries non retriable embedded metastore client (Thejas Nair via Ashutosh Chauhan)
+ git clean -f -d
Removing ql/src/java/org/apache/hadoop/hive/ql/exec/FunctionRegistry.java.orig
Removing ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFSortArrayByField.java
Removing ql/src/test/org/apache/hadoop/hive/ql/udf/generic/TestGenericUDFSortArrayByField.java
Removing ql/src/test/queries/clientnegative/udf_sort_array_by_wrong1.q
Removing ql/src/test/queries/clientnegative/udf_sort_array_by_wrong2.q
Removing ql/src/test/queries/clientnegative/udf_sort_array_by_wrong3.q
Removing ql/src/test/queries/clientpositive/udf_sort_array_by.q
Removing ql/src/test/results/clientnegative/udf_sort_array_by_wrong1.q.out
Removing ql/src/test/results/clientnegative/udf_sort_array_by_wrong2.q.out
Removing ql/src/test/results/clientnegative/udf_sort_array_by_wrong3.q.out
Removing ql/src/test/results/clientpositive/udf_sort_array_by.q.out
+ git checkout master
Already on 'master'
Your branch is up-to-date with 'origin/master'.
+ git reset --hard origin/master
HEAD is now at b74c4d0 HIVE-13383 : RetryingMetaStoreClient retries non retriable embedded metastore client (Thejas Nair via Ashutosh Chauhan)
+ git merge --ff-only origin/master
Already up-to-date.
+ git gc
+ patchCommandPath=/data/hive-ptest/working/scratch/smart-apply-patch.sh
+ patchFilePath=/data/hive-ptest/working/scratch/build.patch
+ [[ -f /data/hive-ptest/working/scratch/build.patch ]]
+ chmod +x /data/hive-ptest/working/scratch/smart-apply-patch.sh
+ /data/hive-ptest/working/scratch/smart-apply-patch.sh /data/hive-ptest/working/scratch/build.patch
error: patch failed: hcatalog/core/src/main/java/org/apache/hive/hcatalog/mapreduce/FileOutputCommitterContainer.java:32
error: hcatalog/core/src/main/java/org/apache/hive/hcatalog/mapreduce/FileOutputCommitterContainer.java: patch does not apply
error: patch failed: ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java:2916
error: ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java: patch does not apply
The patch does not appear to apply with p0, p1, or p2
+ exit 1
'
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12812615 - PreCommit-HIVE-MASTER-Build, Hi [~cdrome] and [~ashutoshc]

The patch in HIVE-13989 doesn't test ACL inheritance correctly. In FolderPermissionBase.java, some of the tests explicitly set the permissions for the table and the partition directories instead of letting the partitions inherit its permissions from its parent directory. Also, the tests doesn't determine the correct ACLs the child directory should inherit. For example, if the parent directory has a DEFAULT ACL entry set to "default:user:bar:rw-", the test should check that the child directory/file has the corresponding ACCESS ACL entry "access:user:bar:rw-".

Besides the testcases, I noticed some of the DEFAULT|ACCESS ACLs the parent directory has were not inherited as ACCESS ACLs in the child directory.
{noformat}
For example, the warehouse directory has the following ACLs set:
ACCESS        type:USER       name: null      perm: ALL
ACCESS        type:GROUP      name: null      perm: READ_WRITE
ACCESS        type:OTHER      name: null      perm: NONE
ACCESS        type:USER       name: bar       perm: READ_WRITE
ACCESS        type:USER       name: foo       perm: READ_EXECUTE
ACCESS        type:GROUP      name: bar       perm: READ_WRITE
ACCESS        type:GROUP      name: foo       perm: READ_EXECUTE
DEFAULT	      type:USER       name: null      perm: ALL
DEFAULT	      type:USER       name: foo       perm: READ
DEFAULT	      type:GROUP      name: null      perm: READ
DEFAULT	      type:OTHER      name: null      perm: READ

but the table dualstaticpart has the following ACLs:
ACCESS        type:USER       name: bar       perm: READ_WRITE
ACCESS        type:USER       name: foo       perm: READ_EXECUTE
ACCESS        type:GROUP      name: null      perm: READ_WRITE
ACCESS        type:GROUP      name: bar       perm: READ_WRITE
ACCESS        type:GROUP      name: foo       perm: READ_EXECUTE
DEFAULT       type:USER       name: null      perm: ALL
DEFAULT       type:USER       name: foo       perm: READ
DEFAULT       type:GROUP      name: null      perm: READ
DEFAULT       type:MASK       name: null      perm: READ
DEFAULT       type:OTHER      name: null      perm: READ

Instead, it should be:
ACCESS        type:USER       name: bar       perm: READ_WRITE
ACCESS        type:USER       name: foo       perm: READ
ACCESS        type:GROUP      name: null      perm: READ
ACCESS        type:GROUP      name: bar       perm: READ_WRITE
ACCESS        type:GROUP      name: foo       perm: READ_EXECUTE
DEFAULT       type:USER       name: null      perm: ALL
DEFAULT       type:USER       name: foo       perm: READ
DEFAULT       type:GROUP      name: null      perm: READ
DEFAULT       type:MASK       name: null      perm: READ
DEFAULT       type:OTHER      name: null      perm: READ
{noformat}

I closed HIVE-11481 as a duplicate of this one since both Jiras have the same description and merged the changes from both Jiras together with some additional changes on top. I'm not able to upload a new patch, but here is the link to the reviewboard: https://reviews.apache.org/r/51684/

This patch fixes the group permissions and DEFAULT ACL inheritance as described in the description, and additionally, fix the FolderPermissionBase test cases for the partitions to inherit the parent's permissions., Thanks for the comment [~caritaou].

I will look into it., Cancelling patch as it looks like further investigation is required., [~cdrome] Thanks for the work so far. Looks like a bug we should definitely merge into master. Will you have time to address [~caritaou]'s review comments?, [~vgumashta], yes, I will come back to this and verify whether there are still issues in trunk (this patch was originally written against 1.2)., Thanks a lot [~cdrome], Attaching patch for branch 2.3. , [~cdrome] I was able to rebase on 2.3 (the jira is not relevant for master due to HIVE-16392). Would be great if you could take a look whenever you get time. Thanks, [~vgumashta], thanks for the rebase. I'll try to look at it next week., 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12877381/HIVE-13989-branch-2.3.patch

{color:red}ERROR:{color} -1 due to build exiting with an error

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/6040/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/6040/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-6040/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Tests exited with: NonZeroExitCodeException
Command 'bash /data/hiveptest/working/scratch/source-prep.sh' failed with exit status 1 and output '+ date '+%Y-%m-%d %T.%3N'
2017-07-14 21:01:32.392
+ [[ -n /usr/lib/jvm/java-8-openjdk-amd64 ]]
+ export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
+ JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
+ export PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games
+ PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games
+ export 'ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m '
+ ANT_OPTS='-Xmx1g -XX:MaxPermSize=256m '
+ export 'MAVEN_OPTS=-Xmx1g '
+ MAVEN_OPTS='-Xmx1g '
+ cd /data/hiveptest/working/
+ tee /data/hiveptest/logs/PreCommit-HIVE-Build-6040/source-prep.txt
+ [[ false == \t\r\u\e ]]
+ mkdir -p maven ivy
+ [[ git = \s\v\n ]]
+ [[ git = \g\i\t ]]
+ [[ -z branch-2.3 ]]
+ [[ -d apache-github-branch-2.3-source ]]
+ [[ ! -d apache-github-branch-2.3-source/.git ]]
+ [[ ! -d apache-github-branch-2.3-source ]]
+ date '+%Y-%m-%d %T.%3N'
2017-07-14 21:01:32.395
+ cd apache-github-branch-2.3-source
+ git fetch origin
From https://github.com/apache/hive
   31cee7e..6f4c35c  branch-2.3 -> origin/branch-2.3
   4514ec9..d3ba76d  master     -> origin/master
 * [new tag]         release-2.3.0-rc1 -> release-2.3.0-rc1
+ git reset --hard HEAD
HEAD is now at 31cee7e HIVE-15144: JSON.org license is now CatX (Owen O'Malley, reviewed by Alan Gates)
+ git clean -f -d
+ git checkout branch-2.3
Already on 'branch-2.3'
Your branch is behind 'origin/branch-2.3' by 2 commits, and can be fast-forwarded.
  (use "git pull" to update your local branch)
+ git reset --hard origin/branch-2.3
HEAD is now at 6f4c35c Release Notes
+ git merge --ff-only origin/branch-2.3
Already up-to-date.
+ date '+%Y-%m-%d %T.%3N'
2017-07-14 21:01:36.454
+ patchCommandPath=/data/hiveptest/working/scratch/smart-apply-patch.sh
+ patchFilePath=/data/hiveptest/working/scratch/build.patch
+ [[ -f /data/hiveptest/working/scratch/build.patch ]]
+ chmod +x /data/hiveptest/working/scratch/smart-apply-patch.sh
+ /data/hiveptest/working/scratch/smart-apply-patch.sh /data/hiveptest/working/scratch/build.patch
Going to apply patch with: patch -p1
patching file hcatalog/core/src/main/java/org/apache/hive/hcatalog/mapreduce/FileOutputCommitterContainer.java
patching file itests/hive-unit-hadoop2/src/test/java/org/apache/hadoop/hive/ql/security/TestExtendedAcls.java
patching file itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/security/FolderPermissionBase.java
patching file ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java
patching file ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java
patching file shims/common/src/main/java/org/apache/hadoop/hive/io/HdfsUtils.java
patching file shims/common/src/main/test/org/apache/hadoop/hive/io/TestHdfsUtils.java
+ [[ maven == \m\a\v\e\n ]]
+ rm -rf /data/hiveptest/working/maven/org/apache/hive
+ mvn -B clean install -DskipTests -T 4 -q -Dmaven.repo.local=/data/hiveptest/working/maven
[ERROR] Failed to execute goal on project spark-client: Could not resolve dependencies for project org.apache.hive:spark-client:jar:2.3.0: Could not find artifact org.apache.hive:hive-storage-api:jar:2.4.0 in datanucleus (http://www.datanucleus.org/downloads/maven2) -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/DependencyResolutionException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn <goals> -rf :spark-client
+ exit 1
'
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12877381 - PreCommit-HIVE-Build, The branch-2.3 patch is not relevant due to changes in HIVE-15385. Attaching patch for branch-2.2 which merges [~caritaou]'s changes as well., 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12812615/HIVE-13989.1.patch

{color:red}ERROR:{color} -1 due to build exiting with an error

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/6064/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/6064/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-6064/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Tests exited with: NonZeroExitCodeException
Command 'bash /data/hiveptest/working/scratch/source-prep.sh' failed with exit status 1 and output '+ date '+%Y-%m-%d %T.%3N'
2017-07-17 18:22:39.938
+ [[ -n /usr/lib/jvm/java-8-openjdk-amd64 ]]
+ export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
+ JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
+ export PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games
+ PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games
+ export 'ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m '
+ ANT_OPTS='-Xmx1g -XX:MaxPermSize=256m '
+ export 'MAVEN_OPTS=-Xmx1g '
+ MAVEN_OPTS='-Xmx1g '
+ cd /data/hiveptest/working/
+ tee /data/hiveptest/logs/PreCommit-HIVE-Build-6064/source-prep.txt
+ [[ false == \t\r\u\e ]]
+ mkdir -p maven ivy
+ [[ git = \s\v\n ]]
+ [[ git = \g\i\t ]]
+ [[ -z master ]]
+ [[ -d apache-github-source-source ]]
+ [[ ! -d apache-github-source-source/.git ]]
+ [[ ! -d apache-github-source-source ]]
+ date '+%Y-%m-%d %T.%3N'
2017-07-17 18:22:39.940
+ cd apache-github-source-source
+ git fetch origin
+ git reset --hard HEAD
HEAD is now at 1fe8db6 HIVE-14988 : Support INSERT OVERWRITE into a partition on transactional tables (Wei Zheng, reviewed by Eugene Koifman)
+ git clean -f -d
+ git checkout master
Already on 'master'
Your branch is up-to-date with 'origin/master'.
+ git reset --hard origin/master
HEAD is now at 1fe8db6 HIVE-14988 : Support INSERT OVERWRITE into a partition on transactional tables (Wei Zheng, reviewed by Eugene Koifman)
+ git merge --ff-only origin/master
Already up-to-date.
+ date '+%Y-%m-%d %T.%3N'
2017-07-17 18:22:42.710
+ patchCommandPath=/data/hiveptest/working/scratch/smart-apply-patch.sh
+ patchFilePath=/data/hiveptest/working/scratch/build.patch
+ [[ -f /data/hiveptest/working/scratch/build.patch ]]
+ chmod +x /data/hiveptest/working/scratch/smart-apply-patch.sh
+ /data/hiveptest/working/scratch/smart-apply-patch.sh /data/hiveptest/working/scratch/build.patch
error: patch failed: hcatalog/core/src/main/java/org/apache/hive/hcatalog/mapreduce/FileOutputCommitterContainer.java:32
error: hcatalog/core/src/main/java/org/apache/hive/hcatalog/mapreduce/FileOutputCommitterContainer.java: patch does not apply
error: itests/hive-unit-hadoop2/src/test/java/org/apache/hadoop/hive/ql/security/TestExtendedAcls.java: No such file or directory
error: itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/security/FolderPermissionBase.java: No such file or directory
error: patch failed: ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java:2720
error: ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java: patch does not apply
error: patch failed: shims/common/src/main/java/org/apache/hadoop/hive/io/HdfsUtils.java:19
error: shims/common/src/main/java/org/apache/hadoop/hive/io/HdfsUtils.java: patch does not apply
The patch does not appear to apply with p0, p1, or p2
+ exit 1
'
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12812615 - PreCommit-HIVE-Build, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12877638/HIVE-13989-branch-2.2.patch

{color:red}ERROR:{color} -1 due to build exiting with an error

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/6065/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/6065/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-6065/

Messages:
{noformat}
**** This message was trimmed, see log for full details ****
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/Comparable.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-server/1.14/jersey-server-1.14.jar(com/sun/jersey/api/core/PackagesResourceConfig.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-servlet/1.14/jersey-servlet-1.14.jar(com/sun/jersey/spi/container/servlet/ServletContainer.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/io/FileInputStream.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/apache-github-branch-2.2-source/ql/target/hive-exec-2.2.0-SNAPSHOT.jar(org/apache/commons/lang3/StringUtils.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/apache-github-branch-2.2-source/ql/target/hive-exec-2.2.0-SNAPSHOT.jar(org/apache/commons/lang3/ArrayUtils.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/apache-github-branch-2.2-source/common/target/hive-common-2.2.0-SNAPSHOT.jar(org/apache/hadoop/hive/common/classification/InterfaceStability.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-hdfs/2.8.0/hadoop-hdfs-2.8.0.jar(org/apache/hadoop/hdfs/web/AuthFilter.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/apache-github-branch-2.2-source/shims/common/target/hive-shims-common-2.2.0-SNAPSHOT.jar(org/apache/hadoop/hive/shims/Utils.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-common/2.8.0/hadoop-common-2.8.0.jar(org/apache/hadoop/security/UserGroupInformation.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-auth/2.8.0/hadoop-auth-2.8.0.jar(org/apache/hadoop/security/authentication/client/PseudoAuthenticator.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-auth/2.8.0/hadoop-auth-2.8.0.jar(org/apache/hadoop/security/authentication/server/PseudoAuthenticationHandler.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-common/2.8.0/hadoop-common-2.8.0.jar(org/apache/hadoop/util/GenericOptionsParser.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/eclipse/jetty/aggregate/jetty-all-server/7.6.0.v20120127/jetty-all-server-7.6.0.v20120127.jar(org/eclipse/jetty/rewrite/handler/RedirectPatternRule.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/eclipse/jetty/aggregate/jetty-all-server/7.6.0.v20120127/jetty-all-server-7.6.0.v20120127.jar(org/eclipse/jetty/rewrite/handler/RewriteHandler.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/eclipse/jetty/aggregate/jetty-all-server/7.6.0.v20120127/jetty-all-server-7.6.0.v20120127.jar(org/eclipse/jetty/server/Handler.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/eclipse/jetty/aggregate/jetty-all-server/7.6.0.v20120127/jetty-all-server-7.6.0.v20120127.jar(org/eclipse/jetty/server/Server.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/eclipse/jetty/aggregate/jetty-all-server/7.6.0.v20120127/jetty-all-server-7.6.0.v20120127.jar(org/eclipse/jetty/server/handler/HandlerList.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/eclipse/jetty/aggregate/jetty-all-server/7.6.0.v20120127/jetty-all-server-7.6.0.v20120127.jar(org/eclipse/jetty/servlet/FilterHolder.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/eclipse/jetty/aggregate/jetty-all-server/7.6.0.v20120127/jetty-all-server-7.6.0.v20120127.jar(org/eclipse/jetty/servlet/FilterMapping.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/eclipse/jetty/aggregate/jetty-all-server/7.6.0.v20120127/jetty-all-server-7.6.0.v20120127.jar(org/eclipse/jetty/servlet/ServletContextHandler.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/eclipse/jetty/aggregate/jetty-all-server/7.6.0.v20120127/jetty-all-server-7.6.0.v20120127.jar(org/eclipse/jetty/servlet/ServletHolder.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/eclipse/jetty/aggregate/jetty-all-server/7.6.0.v20120127/jetty-all-server-7.6.0.v20120127.jar(org/eclipse/jetty/xml/XmlConfiguration.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/slf4j/jul-to-slf4j/1.7.10/jul-to-slf4j-1.7.10.jar(org/slf4j/bridge/SLF4JBridgeHandler.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/javax/servlet/servlet-api/2.5/servlet-api-2.5.jar(javax/servlet/http/HttpServletRequest.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/apache-github-branch-2.2-source/common/target/hive-common-2.2.0-SNAPSHOT.jar(org/apache/hadoop/hive/common/classification/InterfaceAudience$LimitedPrivate.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/apache-github-branch-2.2-source/common/target/hive-common-2.2.0-SNAPSHOT.jar(org/apache/hadoop/hive/common/classification/InterfaceStability$Unstable.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/io/ByteArrayOutputStream.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/io/OutputStream.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/io/Closeable.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/AutoCloseable.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/io/Flushable.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(javax/xml/bind/annotation/XmlRootElement.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/commons/commons-exec/1.1/commons-exec-1.1.jar(org/apache/commons/exec/ExecuteException.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/security/PrivilegedExceptionAction.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/apache-github-branch-2.2-source/shims/common/target/hive-shims-common-2.2.0-SNAPSHOT.jar(org/apache/hadoop/hive/shims/HadoopShimsSecure.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/apache-github-branch-2.2-source/shims/common/target/hive-shims-common-2.2.0-SNAPSHOT.jar(org/apache/hadoop/hive/shims/ShimLoader.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/apache-github-branch-2.2-source/shims/common/target/hive-shims-common-2.2.0-SNAPSHOT.jar(org/apache/hadoop/hive/shims/HadoopShims.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/apache-github-branch-2.2-source/shims/common/target/hive-shims-common-2.2.0-SNAPSHOT.jar(org/apache/hadoop/hive/shims/HadoopShims$WebHCatJTShim.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-common/2.8.0/hadoop-common-2.8.0.jar(org/apache/hadoop/util/ToolRunner.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/InterruptedException.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/Boolean.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/apache-github-branch-2.2-source/ql/target/hive-exec-2.2.0-SNAPSHOT.jar(org/apache/hadoop/hive/ql/ErrorMsg.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/Integer.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-mapreduce-client-core/2.8.0/hadoop-mapreduce-client-core-2.8.0.jar(org/apache/hadoop/mapred/JobStatus.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/io/FileNotFoundException.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/net/URISyntaxException.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/net/URI.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-common/2.8.0/hadoop-common-2.8.0.jar(org/apache/hadoop/fs/FileSystem.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/apache-github-branch-2.2-source/metastore/target/hive-metastore-2.2.0-SNAPSHOT.jar(org/apache/hadoop/hive/metastore/api/MetaException.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-common/2.8.0/hadoop-common-2.8.0.jar(org/apache/hadoop/io/Text.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-common/2.8.0/hadoop-common-2.8.0.jar(org/apache/hadoop/security/Credentials.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-common/2.8.0/hadoop-common-2.8.0.jar(org/apache/hadoop/security/token/Token.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/thrift/libthrift/0.9.3/libthrift-0.9.3.jar(org/apache/thrift/TException.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/net/InetAddress.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/net/UnknownHostException.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/text/MessageFormat.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/util/regex/Matcher.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/util/regex/Pattern.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar(javax/ws/rs/DELETE.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar(javax/ws/rs/FormParam.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar(javax/ws/rs/GET.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar(javax/ws/rs/POST.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar(javax/ws/rs/PUT.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar(javax/ws/rs/Path.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar(javax/ws/rs/PathParam.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar(javax/ws/rs/Produces.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar(javax/ws/rs/QueryParam.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar(javax/ws/rs/core/Context.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar(javax/ws/rs/core/SecurityContext.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar(javax/ws/rs/core/UriInfo.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-mapreduce-client-core/2.8.0/hadoop-mapreduce-client-core-2.8.0.jar(org/apache/hadoop/mapred/JobProfile.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/Long.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/apache-github-branch-2.2-source/common/target/hive-common-2.2.0-SNAPSHOT.jar(org/apache/hadoop/hive/common/JavaUtils.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/commons-lang/commons-lang/2.6/commons-lang-2.6.jar(org/apache/commons/lang/StringUtils.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-common/2.8.0/hadoop-common-2.8.0.jar(org/apache/hadoop/fs/FileStatus.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-server/1.14/jersey-server-1.14.jar(com/sun/jersey/api/wadl/config/WadlGeneratorConfig.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-server/1.14/jersey-server-1.14.jar(com/sun/jersey/api/wadl/config/WadlGeneratorDescription.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-server/1.14/jersey-server-1.14.jar(com/sun/jersey/server/wadl/generators/resourcedoc/WadlGeneratorResourceDocSupport.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/io/BufferedReader.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/io/InputStream.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/io/InputStreamReader.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/io/PrintWriter.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/util/Map$Entry.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/util/concurrent/Semaphore.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/commons/commons-exec/1.1/commons-exec-1.1.jar(org/apache/commons/exec/CommandLine.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/commons/commons-exec/1.1/commons-exec-1.1.jar(org/apache/commons/exec/DefaultExecutor.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/commons/commons-exec/1.1/commons-exec-1.1.jar(org/apache/commons/exec/ExecuteWatchdog.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/commons/commons-exec/1.1/commons-exec-1.1.jar(org/apache/commons/exec/PumpStreamHandler.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-common/2.8.0/hadoop-common-2.8.0.jar(org/apache/hadoop/util/Shell.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/Thread.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/Runnable.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar(javax/ws/rs/ext/ExceptionMapper.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar(javax/ws/rs/ext/Provider.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-server/1.14/jersey-server-1.14.jar(com/sun/jersey/api/NotFoundException.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-mapreduce-client-core/2.8.0/hadoop-mapreduce-client-core-2.8.0.jar(org/apache/hadoop/mapred/JobID.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-common/2.8.0/hadoop-common-2.8.0.jar(org/apache/hadoop/security/Groups.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/util/HashSet.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/util/Set.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/util/concurrent/ConcurrentHashMap.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/apache-github-branch-2.2-source/common/target/hive-common-2.2.0-SNAPSHOT.jar(org/apache/hive/common/util/HiveVersionInfo.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/apache-github-branch-2.2-source/common/target/hive-common-2.2.0-SNAPSHOT.jar(org/apache/hadoop/hive/common/classification/InterfaceStability$Evolving.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/io/DataInput.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/io/DataOutput.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-mapreduce-client-core/2.8.0/hadoop-mapreduce-client-core-2.8.0.jar(org/apache/hadoop/mapreduce/InputSplit.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/curator/curator-framework/2.7.1/curator-framework-2.7.1.jar(org/apache/curator/framework/CuratorFramework.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar(org/apache/zookeeper/CreateMode.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar(org/apache/zookeeper/KeeperException.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar(org/apache/zookeeper/ZooDefs.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar(org/apache/zookeeper/ZooDefs$Ids.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/io/OutputStreamWriter.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/net/URLConnection.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-mapreduce-client-core/2.8.0/hadoop-mapreduce-client-core-2.8.0.jar(org/apache/hadoop/mapred/JobClient.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-mapreduce-client-core/2.8.0/hadoop-mapreduce-client-core-2.8.0.jar(org/apache/hadoop/mapred/JobConf.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-mapreduce-client-core/2.8.0/hadoop-mapreduce-client-core-2.8.0.jar(org/apache/hadoop/mapred/RunningJob.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/util/StringTokenizer.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/Process.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/StringBuilder.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-common/2.8.0/hadoop-common-2.8.0.jar(org/apache/hadoop/io/NullWritable.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-mapreduce-client-core/2.8.0/hadoop-mapreduce-client-core-2.8.0.jar(org/apache/hadoop/mapreduce/InputFormat.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-mapreduce-client-core/2.8.0/hadoop-mapreduce-client-core-2.8.0.jar(org/apache/hadoop/mapreduce/JobContext.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-mapreduce-client-core/2.8.0/hadoop-mapreduce-client-core-2.8.0.jar(org/apache/hadoop/mapreduce/RecordReader.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-mapreduce-client-core/2.8.0/hadoop-mapreduce-client-core-2.8.0.jar(org/apache/hadoop/mapreduce/TaskAttemptContext.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-common/2.8.0/hadoop-common-2.8.0.jar(org/apache/hadoop/conf/Configured.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-mapreduce-client-core/2.8.0/hadoop-mapreduce-client-core-2.8.0.jar(org/apache/hadoop/mapreduce/Job.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-mapreduce-client-core/2.8.0/hadoop-mapreduce-client-core-2.8.0.jar(org/apache/hadoop/mapreduce/JobID.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-mapreduce-client-core/2.8.0/hadoop-mapreduce-client-core-2.8.0.jar(org/apache/hadoop/mapreduce/lib/output/NullOutputFormat.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-mapreduce-client-core/2.8.0/hadoop-mapreduce-client-core-2.8.0.jar(org/apache/hadoop/mapreduce/security/token/delegation/DelegationTokenIdentifier.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-common/2.8.0/hadoop-common-2.8.0.jar(org/apache/hadoop/util/Tool.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-common/2.8.0/hadoop-common-2.8.0.jar(org/apache/hadoop/conf/Configurable.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/ClassNotFoundException.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/curator/curator-framework/2.7.1/curator-framework-2.7.1.jar(org/apache/curator/framework/CuratorFrameworkFactory.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/curator/curator-client/2.7.1/curator-client-2.7.1.jar(org/apache/curator/retry/ExponentialBackoffRetry.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-mapreduce-client-core/2.8.0/hadoop-mapreduce-client-core-2.8.0.jar(org/apache/hadoop/mapreduce/Mapper.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/util/Iterator.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/util/LinkedList.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/util/concurrent/ExecutorService.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/util/concurrent/Executors.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/util/concurrent/TimeUnit.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-mapreduce-client-core/2.8.0/hadoop-mapreduce-client-core-2.8.0.jar(org/apache/hadoop/mapreduce/Mapper$Context.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/net/URLDecoder.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/util/Enumeration.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/util/Properties.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar(javax/ws/rs/core/UriBuilder.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/apache-github-branch-2.2-source/common/target/hive-common-2.2.0-SNAPSHOT.jar(org/apache/hadoop/hive/common/LogUtils.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/Class.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/annotation/Annotation.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-annotations/2.8.0/hadoop-annotations-2.8.0.jar(org/apache/hadoop/classification/InterfaceAudience.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-annotations/2.8.0/hadoop-annotations-2.8.0.jar(org/apache/hadoop/classification/InterfaceAudience$LimitedPrivate.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/annotation/Retention.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/annotation/RetentionPolicy.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/annotation/Target.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/annotation/ElementType.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar(javax/ws/rs/HttpMethod.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/SuppressWarnings.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/Override.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(sun/misc/Contended.class)]]
[loading RegularFileObject[/data/hiveptest/working/apache-github-branch-2.2-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/HcatException$1.class]]
[loading RegularFileObject[/data/hiveptest/working/apache-github-branch-2.2-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/HcatDelegator$1.class]]
[loading RegularFileObject[/data/hiveptest/working/apache-github-branch-2.2-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/Server$1.class]]
[loading RegularFileObject[/data/hiveptest/working/apache-github-branch-2.2-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/SecureProxySupport$3.class]]
[loading RegularFileObject[/data/hiveptest/working/apache-github-branch-2.2-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/LauncherDelegator$1.class]]
[loading RegularFileObject[/data/hiveptest/working/apache-github-branch-2.2-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/SecureProxySupport$1.class]]
[loading RegularFileObject[/data/hiveptest/working/apache-github-branch-2.2-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/SecureProxySupport$2.class]]
[loading RegularFileObject[/data/hiveptest/working/apache-github-branch-2.2-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/tool/HDFSStorage$1.class]]
[loading RegularFileObject[/data/hiveptest/working/apache-github-branch-2.2-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/tool/TempletonUtils$1.class]]
[loading RegularFileObject[/data/hiveptest/working/apache-github-branch-2.2-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/tool/ZooKeeperStorage$1.class]]
[loading RegularFileObject[/data/hiveptest/working/apache-github-branch-2.2-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob$1.class]]
[loading RegularFileObject[/data/hiveptest/working/apache-github-branch-2.2-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob$1$1.class]]
[loading RegularFileObject[/data/hiveptest/working/apache-github-branch-2.2-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/tool/LogRetriever$1.class]]
[done in 3175 ms]
+ [[ -d itests ]]
+ cd itests
+ mvn -B clean install -DskipTests -T 4 -q -Dmaven.repo.local=/data/hiveptest/working/maven
[ERROR] COMPILATION ERROR : 
[ERROR] /data/hiveptest/working/apache-github-branch-2.2-source/itests/hive-unit-hadoop2/src/test/java/org/apache/hadoop/hive/ql/security/TestInheritPermsExtendedAcls.java:[159,61] cannot find symbol
  symbol:   method getAclStatus()
  location: variable parentFullFileStatus of type org.apache.hadoop.hive.io.HdfsUtils.HadoopFileStatus
[ERROR] /data/hiveptest/working/apache-github-branch-2.2-source/itests/hive-unit-hadoop2/src/test/java/org/apache/hadoop/hive/ql/security/TestInheritPermsExtendedAcls.java:[161,61] cannot find symbol
  symbol:   method getAclStatus()
  location: variable actualFullFileStatus of type org.apache.hadoop.hive.io.HdfsUtils.HadoopFileStatus
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.1:testCompile (default-testCompile) on project hive-it-unit-hadoop2: Compilation failure: Compilation failure:
[ERROR] /data/hiveptest/working/apache-github-branch-2.2-source/itests/hive-unit-hadoop2/src/test/java/org/apache/hadoop/hive/ql/security/TestInheritPermsExtendedAcls.java:[159,61] cannot find symbol
[ERROR] symbol:   method getAclStatus()
[ERROR] location: variable parentFullFileStatus of type org.apache.hadoop.hive.io.HdfsUtils.HadoopFileStatus
[ERROR] /data/hiveptest/working/apache-github-branch-2.2-source/itests/hive-unit-hadoop2/src/test/java/org/apache/hadoop/hive/ql/security/TestInheritPermsExtendedAcls.java:[161,61] cannot find symbol
[ERROR] symbol:   method getAclStatus()
[ERROR] location: variable actualFullFileStatus of type org.apache.hadoop.hive.io.HdfsUtils.HadoopFileStatus
[ERROR] -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn <goals> -rf :hive-it-unit-hadoop2
+ exit 1
'
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12877638 - PreCommit-HIVE-Build, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12877640/HIVE-13989-branch-2.2.patch

{color:green}SUCCESS:{color} +1 due to 2 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 140 failed/errored test(s), 10605 tests executed
*Failed tests:*
{noformat}
TestDerbyConnector - did not produce a TEST-*.xml file (likely timed out) (batchId=245)
TestJdbcDriver2 - did not produce a TEST-*.xml file (likely timed out) (batchId=226)
TestMiniLlapLocalCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=168)
	[acid_globallimit.q,alter_merge_2_orc.q]
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_globallimit] (batchId=27)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[avro_nullable_union] (batchId=51)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[cbo_union_view] (batchId=19)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[druid_basic2] (batchId=10)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[druid_intervals] (batchId=21)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[druid_timeseries] (batchId=54)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[druid_topn] (batchId=3)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[dynpart_sort_optimization_acid] (batchId=41)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[explain_logical] (batchId=59)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[join32] (batchId=17)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[order_null] (batchId=19)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[position_alias_test_1] (batchId=39)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[ppd_union_view] (batchId=27)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[show_create_table_db_table] (batchId=60)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[stats_list_bucket] (batchId=62)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[subquery_notin] (batchId=64)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[subquery_notin_having] (batchId=45)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[subquery_views] (batchId=13)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[table_access_keys_stats] (batchId=65)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[union_fast_stats] (batchId=47)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[union_view] (batchId=14)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[view_cbo] (batchId=62)
org.apache.hadoop.hive.cli.TestEncryptedHDFSCliDriver.testCliDriver[encryption_join_with_different_encryption_keys] (batchId=173)
org.apache.hadoop.hive.cli.TestEncryptedHDFSCliDriver.testCliDriver[encryption_move_tbl] (batchId=170)
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver[hbase_viewjoins] (batchId=88)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[dynamic_partition_pruning] (batchId=161)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[join_acid_non_acid] (batchId=166)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[orc_llap_counters1] (batchId=160)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[orc_llap_counters] (batchId=167)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[schema_evol_orc_acid_mapwork_part] (batchId=162)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[schema_evol_orc_acid_mapwork_table] (batchId=158)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[schema_evol_orc_acidvec_mapwork_part] (batchId=166)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[schema_evol_orc_acidvec_mapwork_table] (batchId=163)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[schema_evol_orc_nonvec_fetchwork_part] (batchId=163)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[schema_evol_orc_nonvec_fetchwork_table] (batchId=162)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[schema_evol_orc_nonvec_mapwork_part] (batchId=159)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[schema_evol_orc_nonvec_mapwork_part_all_primitive] (batchId=165)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[schema_evol_orc_nonvec_mapwork_table] (batchId=165)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[schema_evol_orc_vec_mapwork_part] (batchId=163)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[schema_evol_orc_vec_mapwork_part_all_primitive] (batchId=162)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[schema_evol_orc_vec_mapwork_table] (batchId=158)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[schema_evol_text_nonvec_mapwork_part] (batchId=166)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[schema_evol_text_nonvec_mapwork_part_all_primitive] (batchId=159)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[schema_evol_text_nonvec_mapwork_table] (batchId=161)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[schema_evol_text_vec_mapwork_part] (batchId=165)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[schema_evol_text_vec_mapwork_part_all_primitive] (batchId=158)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[schema_evol_text_vec_mapwork_table] (batchId=160)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[schema_evol_text_vecrow_mapwork_part] (batchId=158)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[schema_evol_text_vecrow_mapwork_part_all_primitive] (batchId=159)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[schema_evol_text_vecrow_mapwork_table] (batchId=166)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[subquery_multi] (batchId=159)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[subquery_scalar] (batchId=162)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[tez_dynpart_hashjoin_3] (batchId=162)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[vector_complex_join] (batchId=163)
org.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver[constprog_partitioner] (batchId=176)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[auto_sortmerge_join_12] (batchId=101)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_5] (batchId=94)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainuser_1] (batchId=102)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[limit_pushdown] (batchId=112)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[metadataonly1] (batchId=111)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[schema_evol_orc_acid_mapwork_part] (batchId=103)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[schema_evol_orc_acid_mapwork_table] (batchId=92)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[schema_evol_orc_acidvec_mapwork_part] (batchId=116)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[schema_evol_orc_acidvec_mapwork_table] (batchId=105)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[schema_evol_orc_nonvec_fetchwork_part] (batchId=106)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[schema_evol_orc_nonvec_fetchwork_table] (batchId=102)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[schema_evol_orc_nonvec_mapwork_part] (batchId=93)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[schema_evol_orc_nonvec_mapwork_part_all_primitive] (batchId=113)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[schema_evol_orc_nonvec_mapwork_table] (batchId=112)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[schema_evol_orc_vec_mapwork_part] (batchId=105)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[schema_evol_orc_vec_mapwork_part_all_primitive] (batchId=104)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[schema_evol_orc_vec_mapwork_table] (batchId=92)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[schema_evol_text_nonvec_mapwork_part] (batchId=115)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[schema_evol_text_nonvec_mapwork_part_all_primitive] (batchId=96)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[schema_evol_text_nonvec_mapwork_table] (batchId=101)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[schema_evol_text_vec_mapwork_part] (batchId=111)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[schema_evol_text_vec_mapwork_part_all_primitive] (batchId=92)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[schema_evol_text_vec_mapwork_table] (batchId=98)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[schema_evol_text_vecrow_mapwork_part] (batchId=92)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[schema_evol_text_vecrow_mapwork_part_all_primitive] (batchId=95)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[schema_evol_text_vecrow_mapwork_table] (batchId=114)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[unionDistinct_1] (batchId=106)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[vector_join30] (batchId=101)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[vector_outer_join0] (batchId=109)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[vector_outer_join1] (batchId=105)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[vector_outer_join2] (batchId=100)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[vector_outer_join3] (batchId=101)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[vector_outer_join4] (batchId=116)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[vector_outer_join5] (batchId=116)
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[avro_non_nullable_union] (batchId=85)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query83] (batchId=236)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[cbo_subq_not_in] (batchId=140)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[count] (batchId=130)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[date_udf] (batchId=133)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[join0] (batchId=144)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[join_view] (batchId=154)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[leftsemijoin] (batchId=138)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[metadata_only_queries] (batchId=133)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[outer_join_ppr] (batchId=128)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[ptf] (batchId=126)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[subquery_exists] (batchId=136)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[subquery_in] (batchId=146)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[subquery_multiinsert] (batchId=155)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[table_access_keys_stats] (batchId=149)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[temp_table_gb1] (batchId=133)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[udf_percentile] (batchId=146)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union25] (batchId=148)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union_null] (batchId=154)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[vector_between_in] (batchId=143)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[vector_cast_constant] (batchId=123)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[vector_mapjoin_reduce] (batchId=153)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[vectorization_0] (batchId=154)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[vectorization_3] (batchId=152)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[vectorization_div0] (batchId=148)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[vectorization_short_regress] (batchId=139)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[vectorized_ptf] (batchId=146)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[windowing] (batchId=141)
org.apache.hadoop.hive.ql.TestMTQueries.testMTQueries1 (batchId=219)
org.apache.hadoop.hive.ql.security.TestInheritPermsExtendedAcls.testCreateDb (batchId=233)
org.apache.hadoop.hive.ql.security.TestInheritPermsExtendedAcls.testCreateTable (batchId=233)
org.apache.hadoop.hive.ql.security.TestInheritPermsExtendedAcls.testCtas (batchId=233)
org.apache.hadoop.hive.ql.security.TestInheritPermsExtendedAcls.testExim (batchId=233)
org.apache.hadoop.hive.ql.security.TestInheritPermsExtendedAcls.testExternalTable (batchId=233)
org.apache.hadoop.hive.ql.security.TestInheritPermsExtendedAcls.testInsertDualDynamicPartitions (batchId=233)
org.apache.hadoop.hive.ql.security.TestInheritPermsExtendedAcls.testInsertNonPartTable (batchId=233)
org.apache.hadoop.hive.ql.security.TestInheritPermsExtendedAcls.testInsertSingleDynamicPartition (batchId=233)
org.apache.hadoop.hive.ql.security.TestInheritPermsExtendedAcls.testInsertStaticDualPartition (batchId=233)
org.apache.hadoop.hive.ql.security.TestInheritPermsExtendedAcls.testInsertStaticSinglePartition (batchId=233)
org.apache.hadoop.hive.ql.security.TestInheritPermsExtendedAcls.testLoad (batchId=233)
org.apache.hadoop.hive.ql.security.TestInheritPermsExtendedAcls.testLoadLocal (batchId=233)
org.apache.hadoop.hive.ql.security.TestInheritPermsExtendedAcls.testPartition (batchId=233)
org.apache.hadoop.hive.ql.security.TestInheritPermsExtendedAcls.testTruncateTable (batchId=233)
org.apache.hive.beeline.TestBeeLineWithArgs.testQueryProgress (batchId=223)
org.apache.hive.beeline.TestBeelineArgParsing.testAddLocalJarWithoutAddDriverClazz[0] (batchId=182)
org.apache.hive.beeline.TestBeelineArgParsing.testAddLocalJar[0] (batchId=182)
org.apache.hive.beeline.TestBeelineArgParsing.testAddLocalJar[1] (batchId=182)
org.apache.hive.jdbc.TestJdbcWithMiniHS2.testAddJarConstructorUnCaching (batchId=229)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/6066/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/6066/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-6066/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 140 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12877640 - PreCommit-HIVE-Build, Attaching a dummy patch to see what tests fail in 2.2 w/o this patch, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12877663/HIVE-13989-branch-2.2.patch

{color:red}ERROR:{color} -1 due to no test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 129 failed/errored test(s), 10591 tests executed
*Failed tests:*
{noformat}
TestDerbyConnector - did not produce a TEST-*.xml file (likely timed out) (batchId=245)
TestJdbcDriver2 - did not produce a TEST-*.xml file (likely timed out) (batchId=226)
TestMiniLlapLocalCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=168)
	[acid_globallimit.q,alter_merge_2_orc.q]
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_globallimit] (batchId=27)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[auto_sortmerge_join_2] (batchId=44)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[avro_nullable_union] (batchId=51)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[cbo_union_view] (batchId=19)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[druid_basic2] (batchId=10)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[druid_intervals] (batchId=21)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[druid_timeseries] (batchId=54)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[druid_topn] (batchId=3)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[dynpart_sort_optimization_acid] (batchId=41)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[explain_logical] (batchId=59)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[join32] (batchId=17)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[list_bucket_dml_12] (batchId=46)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[list_bucket_dml_13] (batchId=23)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[order_null] (batchId=19)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[position_alias_test_1] (batchId=39)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[ppd_union_view] (batchId=27)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[show_create_table_db_table] (batchId=60)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[stats_list_bucket] (batchId=62)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[subquery_notin] (batchId=64)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[subquery_notin_having] (batchId=45)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[subquery_views] (batchId=13)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[table_access_keys_stats] (batchId=65)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[union_fast_stats] (batchId=47)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[union_view] (batchId=14)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[view_cbo] (batchId=62)
org.apache.hadoop.hive.cli.TestEncryptedHDFSCliDriver.testCliDriver[encryption_join_with_different_encryption_keys] (batchId=173)
org.apache.hadoop.hive.cli.TestEncryptedHDFSCliDriver.testCliDriver[encryption_move_tbl] (batchId=170)
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver[hbase_viewjoins] (batchId=88)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[dynamic_partition_pruning] (batchId=161)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[join_acid_non_acid] (batchId=166)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[orc_llap_counters1] (batchId=160)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[orc_llap_counters] (batchId=167)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[schema_evol_orc_acid_mapwork_part] (batchId=162)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[schema_evol_orc_acid_mapwork_table] (batchId=158)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[schema_evol_orc_acidvec_mapwork_part] (batchId=166)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[schema_evol_orc_acidvec_mapwork_table] (batchId=163)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[schema_evol_orc_nonvec_fetchwork_part] (batchId=163)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[schema_evol_orc_nonvec_fetchwork_table] (batchId=162)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[schema_evol_orc_nonvec_mapwork_part] (batchId=159)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[schema_evol_orc_nonvec_mapwork_part_all_primitive] (batchId=165)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[schema_evol_orc_nonvec_mapwork_table] (batchId=165)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[schema_evol_orc_vec_mapwork_part] (batchId=163)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[schema_evol_orc_vec_mapwork_part_all_primitive] (batchId=162)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[schema_evol_orc_vec_mapwork_table] (batchId=158)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[schema_evol_text_nonvec_mapwork_part] (batchId=166)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[schema_evol_text_nonvec_mapwork_part_all_primitive] (batchId=159)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[schema_evol_text_nonvec_mapwork_table] (batchId=161)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[schema_evol_text_vec_mapwork_part] (batchId=165)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[schema_evol_text_vec_mapwork_part_all_primitive] (batchId=158)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[schema_evol_text_vec_mapwork_table] (batchId=160)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[schema_evol_text_vecrow_mapwork_part] (batchId=158)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[schema_evol_text_vecrow_mapwork_part_all_primitive] (batchId=159)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[schema_evol_text_vecrow_mapwork_table] (batchId=166)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[subquery_multi] (batchId=159)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[subquery_scalar] (batchId=162)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[tez_dynpart_hashjoin_3] (batchId=162)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[vector_complex_join] (batchId=163)
org.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver[constprog_partitioner] (batchId=176)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_5] (batchId=94)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainuser_1] (batchId=102)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[limit_pushdown] (batchId=112)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[metadataonly1] (batchId=111)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[schema_evol_orc_acid_mapwork_part] (batchId=103)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[schema_evol_orc_acid_mapwork_table] (batchId=92)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[schema_evol_orc_acidvec_mapwork_part] (batchId=116)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[schema_evol_orc_acidvec_mapwork_table] (batchId=105)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[schema_evol_orc_nonvec_fetchwork_part] (batchId=106)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[schema_evol_orc_nonvec_fetchwork_table] (batchId=102)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[schema_evol_orc_nonvec_mapwork_part] (batchId=93)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[schema_evol_orc_nonvec_mapwork_part_all_primitive] (batchId=113)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[schema_evol_orc_nonvec_mapwork_table] (batchId=112)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[schema_evol_orc_vec_mapwork_part] (batchId=105)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[schema_evol_orc_vec_mapwork_part_all_primitive] (batchId=104)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[schema_evol_orc_vec_mapwork_table] (batchId=92)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[schema_evol_text_nonvec_mapwork_part] (batchId=115)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[schema_evol_text_nonvec_mapwork_part_all_primitive] (batchId=96)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[schema_evol_text_nonvec_mapwork_table] (batchId=101)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[schema_evol_text_vec_mapwork_part] (batchId=111)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[schema_evol_text_vec_mapwork_part_all_primitive] (batchId=92)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[schema_evol_text_vec_mapwork_table] (batchId=98)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[schema_evol_text_vecrow_mapwork_part] (batchId=92)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[schema_evol_text_vecrow_mapwork_part_all_primitive] (batchId=95)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[schema_evol_text_vecrow_mapwork_table] (batchId=114)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[unionDistinct_1] (batchId=106)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[vector_join30] (batchId=101)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[vector_outer_join0] (batchId=109)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[vector_outer_join1] (batchId=105)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[vector_outer_join2] (batchId=100)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[vector_outer_join3] (batchId=101)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[vector_outer_join4] (batchId=116)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[vector_outer_join5] (batchId=116)
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[avro_non_nullable_union] (batchId=85)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query23] (batchId=236)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query83] (batchId=236)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[cbo_subq_not_in] (batchId=140)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[count] (batchId=130)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[date_udf] (batchId=133)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[join0] (batchId=144)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[join_view] (batchId=154)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[leftsemijoin] (batchId=138)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[metadata_only_queries] (batchId=133)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[outer_join_ppr] (batchId=128)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[ptf] (batchId=126)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[subquery_exists] (batchId=136)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[subquery_in] (batchId=146)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[subquery_multiinsert] (batchId=155)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[table_access_keys_stats] (batchId=149)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[temp_table_gb1] (batchId=133)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[udf_percentile] (batchId=146)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union25] (batchId=148)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union_null] (batchId=154)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[vector_between_in] (batchId=143)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[vector_cast_constant] (batchId=123)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[vector_mapjoin_reduce] (batchId=153)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[vectorization_0] (batchId=154)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[vectorization_3] (batchId=152)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[vectorization_div0] (batchId=148)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[vectorization_short_regress] (batchId=139)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[vectorized_ptf] (batchId=146)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[windowing] (batchId=141)
org.apache.hadoop.hive.ql.TestMTQueries.testMTQueries1 (batchId=219)
org.apache.hive.beeline.TestBeeLineWithArgs.testQueryProgressParallel (batchId=223)
org.apache.hive.beeline.TestBeelineArgParsing.testAddLocalJarWithoutAddDriverClazz[0] (batchId=182)
org.apache.hive.beeline.TestBeelineArgParsing.testAddLocalJar[0] (batchId=182)
org.apache.hive.beeline.TestBeelineArgParsing.testAddLocalJar[1] (batchId=182)
org.apache.hive.jdbc.TestJdbcWithMiniHS2.testAddJarConstructorUnCaching (batchId=229)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/6068/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/6068/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-6068/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 129 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12877663 - PreCommit-HIVE-Build, [~cdrome] FYI, with the 2.2 patch, the test case added in the patch itself fails. The diffs b/w previous 2 runs (run1 with patch and run2 w/o):
Failures in Run1 and not in Run2:
{code}
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[auto_sortmerge_join_12] (batchId=101)
org.apache.hadoop.hive.ql.security.TestInheritPermsExtendedAcls.testCreateDb (batchId=233)
org.apache.hadoop.hive.ql.security.TestInheritPermsExtendedAcls.testCreateTable (batchId=233)
org.apache.hadoop.hive.ql.security.TestInheritPermsExtendedAcls.testCtas (batchId=233)
org.apache.hadoop.hive.ql.security.TestInheritPermsExtendedAcls.testExim (batchId=233)
org.apache.hadoop.hive.ql.security.TestInheritPermsExtendedAcls.testExternalTable (batchId=233)
org.apache.hadoop.hive.ql.security.TestInheritPermsExtendedAcls.testInsertDualDynamicPartitions (batchId=233)
org.apache.hadoop.hive.ql.security.TestInheritPermsExtendedAcls.testInsertNonPartTable (batchId=233)
org.apache.hadoop.hive.ql.security.TestInheritPermsExtendedAcls.testInsertSingleDynamicPartition (batchId=233)
org.apache.hadoop.hive.ql.security.TestInheritPermsExtendedAcls.testInsertStaticDualPartition (batchId=233)
org.apache.hadoop.hive.ql.security.TestInheritPermsExtendedAcls.testInsertStaticSinglePartition (batchId=233)
org.apache.hadoop.hive.ql.security.TestInheritPermsExtendedAcls.testLoad (batchId=233)
org.apache.hadoop.hive.ql.security.TestInheritPermsExtendedAcls.testLoadLocal (batchId=233)
org.apache.hadoop.hive.ql.security.TestInheritPermsExtendedAcls.testPartition (batchId=233)
org.apache.hadoop.hive.ql.security.TestInheritPermsExtendedAcls.testTruncateTable (batchId=233)
{code}

Failures in Run2 but not in Run1:
{code}
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[auto_sortmerge_join_2] (batchId=44)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[list_bucket_dml_12] (batchId=46)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[list_bucket_dml_13] (batchId=23)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query23] (batchId=236)
{code}

Run2 was thru a dummy patch which just modified a comment on 2.2 line., [~vgumashta], thanks for checking on the tests. The tests that are failing are from HIVE-11481.

I've got an environment running where I can test branch-2.2, so I'll take a look at those tests., Thanks [~cdrome], Uploaded a new patch for branch-2.2.

I've elected to remove the unittest that was introduced as part of HIVE-11481 because the assumptions are not correct when verifying permissions/ACLs.

Specifically, the comparison always checks for inheritance of ACLs from the parent directory even if the current directory was manually set to something that is inconsistent with the parent directory (which happens in most of the test cases).

Also, I don't feel that sub-classing FolderPermissionBase.java for inheritance types unittests is the right approach. The tests and code in FolderPermissionBase.java is not conducive to fine enough control of different types of inheritance situations., [~cdrome] Thanks for the patch. I have a couple of questions on the overall approach (doc I'm using for reference: https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-access-control#permissions-on-new-files-and-folders).
1. It appears for child directories, HDFS should correctly transfer the default ACLs. However, I understand that in Hive we want to avoid the HDFS permissions umasking (the traditional file permissions and not ACLs). Would it make sense to first let HDFS create the child directory (so that it transfers the default/access ACLs) and then set the desired permissions?
2. This comment will be relevant if we decide to manage ACL transfer from parent to child: referring the above doc, it seems when transferring access ACLs, the rwx on other should be removed if it exist. We might need to consider that in the code.

, [~vgumashta], I'll review your comments and update accordingly., [~vgumashta], I checked the behavior of hadoop-2.7 and hadoop-2.8, which matches what you describe about zeroing out the 'other' permissions.

My intention was to let HDFS create and manage the child directories where possible.
However, the reason for this patch was because early versions of ACL support in hadoop combined with the original treatment of ACLs in hive/hcat were generating incorrect results.

Let me revisit the patch and submit a new version., [~vgumashta], I've done a bunch of testing and rewriting the unittests to ensure they are testing the correct things.

I've incorporated your comments about permissions on OTHER getting converted to none.

However, your first comment will not work. The problem is that data gets written to a temp directory relative to the table root and then moved to the final location. So the data in the temp directory will inherit permissions/acls from the table directory, which might be different from that of the destination.

{{FolderPermissionBase.testInsertSingleDynamicPartition}} tests this use case. Without the additional {{setfacl}} call after the move, the part file acls are in an inconsistent state relative to the parent (partition) directory.

I'm in the middle of cleaning things up, so I should have a new patch to review shortly., Uploaded new version of branch-2.2 patch., 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12882512/HIVE-13989.4-branch-2.2.patch

{color:green}SUCCESS:{color} +1 due to 2 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 58 failed/errored test(s), 9934 tests executed
*Failed tests:*
{noformat}
TestDerbyConnector - did not produce a TEST-*.xml file (likely timed out) (batchId=244)
TestJdbcDriver2 - did not produce a TEST-*.xml file (likely timed out) (batchId=225)
TestMiniLlapLocalCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=167)
	[acid_globallimit.q,alter_merge_2_orc.q]
TestMiniSparkOnYarnCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=173)
	[infer_bucket_sort_reducers_power_two.q,list_bucket_dml_10.q,orc_merge9.q,orc_merge6.q,leftsemijoin_mr.q,bucket6.q,bucketmapjoin7.q,uber_reduce.q,empty_dir_in_table.q,vector_outer_join3.q,index_bitmap_auto.q,vector_outer_join2.q,vector_outer_join1.q,orc_merge1.q,orc_merge_diff_fs.q,load_hdfs_file_with_space_in_the_name.q,scriptfile1_win.q,quotedid_smb.q,truncate_column_buckets.q,orc_merge3.q]
TestMiniSparkOnYarnCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=174)
	[infer_bucket_sort_num_buckets.q,gen_udf_example_add10.q,insert_overwrite_directory2.q,orc_merge5.q,bucketmapjoin6.q,import_exported_table.q,vector_outer_join0.q,orc_merge4.q,temp_table_external.q,orc_merge_incompat1.q,root_dir_external_table.q,constprog_semijoin.q,auto_sortmerge_join_16.q,schemeAuthority.q,index_bitmap3.q,external_table_with_space_in_location_path.q,parallel_orderby.q,infer_bucket_sort_map_operators.q,bucketizedhiveinputformat.q,remote_script.q]
TestMiniSparkOnYarnCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=175)
	[scriptfile1.q,vector_outer_join5.q,file_with_header_footer.q,bucket4.q,input16_cc.q,bucket5.q,infer_bucket_sort_merge.q,constprog_partitioner.q,orc_merge2.q,reduce_deduplicate.q,schemeAuthority2.q,load_fs2.q,orc_merge8.q,orc_merge_incompat2.q,infer_bucket_sort_bucketed_table.q,vector_outer_join4.q,disable_merge_for_bucketing.q,vector_inner_join.q,orc_merge7.q]
TestSparkCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=118)
	[bucketmapjoin4.q,bucket_map_join_spark4.q,union21.q,groupby2_noskew.q,timestamp_2.q,date_join1.q,mergejoins.q,smb_mapjoin_11.q,auto_sortmerge_join_3.q,mapjoin_test_outer.q,vectorization_9.q,merge2.q,groupby6_noskew.q,auto_join_without_localtask.q,multi_join_union.q]
TestSparkCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=119)
	[join_cond_pushdown_unqual4.q,union_remove_7.q,join13.q,join_vc.q,groupby_cube1.q,bucket_map_join_spark2.q,sample3.q,smb_mapjoin_19.q,stats16.q,union23.q,union.q,union31.q,cbo_udf_udaf.q,ptf_decimal.q,bucketmapjoin2.q]
TestSparkCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=120)
	[parallel_join1.q,union27.q,union12.q,groupby7_map_multi_single_reducer.q,varchar_join1.q,join7.q,join_reorder4.q,skewjoinopt2.q,bucketsortoptimize_insert_2.q,smb_mapjoin_17.q,script_env_var1.q,groupby7_map.q,groupby3.q,bucketsortoptimize_insert_8.q,union20.q]
TestSparkCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=121)
	[ptf_general_queries.q,auto_join_reordering_values.q,sample2.q,join1.q,decimal_join.q,mapjoin_subquery2.q,join32_lessSize.q,mapjoin1.q,order2.q,skewjoinopt18.q,union_remove_18.q,join25.q,groupby9.q,bucketsortoptimize_insert_6.q,ctas.q]
TestSparkCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=122)
	[groupby_map_ppr.q,nullgroup4_multi_distinct.q,join_rc.q,union14.q,smb_mapjoin_12.q,vector_cast_constant.q,union_remove_4.q,auto_join11.q,load_dyn_part7.q,udaf_collect_set.q,vectorization_12.q,groupby_sort_skew_1.q,groupby_sort_skew_1_23.q,smb_mapjoin_25.q,skewjoinopt12.q]
TestSparkCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=123)
	[skewjoinopt15.q,auto_join18.q,list_bucket_dml_2.q,input1_limit.q,load_dyn_part3.q,union_remove_14.q,auto_sortmerge_join_14.q,auto_sortmerge_join_15.q,union10.q,bucket_map_join_tez2.q,groupby5_map_skew.q,join_reorder.q,sample1.q,bucketmapjoin8.q,union34.q]
TestSparkCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=124)
	[avro_joins.q,skewjoinopt16.q,auto_join14.q,vectorization_14.q,auto_join26.q,stats1.q,cbo_stats.q,auto_sortmerge_join_6.q,union22.q,union_remove_24.q,union_view.q,smb_mapjoin_22.q,stats15.q,ptf_matchpath.q,transform_ppr1.q]
TestSparkCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=125)
	[limit_pushdown2.q,skewjoin_noskew.q,leftsemijoin_mr.q,bucket3.q,skewjoinopt13.q,bucketmapjoin9.q,auto_join15.q,ptf.q,join22.q,vectorized_nested_mapjoin.q,sample4.q,union18.q,multi_insert_gby.q,join33.q,join_cond_pushdown_unqual2.q]
TestSparkCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=126)
	[vector_decimal_aggregate.q,ppd_join3.q,auto_join23.q,join10.q,union_remove_11.q,union_ppr.q,join32.q,groupby_multi_single_reducer2.q,input18.q,stats3.q,cbo_simple_select.q,parquet_join.q,join26.q,groupby1.q,join_reorder2.q]
TestSparkCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=127)
	[skewjoinopt19.q,order.q,join_merge_multi_expressions.q,skewjoinopt10.q,insert_into1.q,vectorized_math_funcs.q,vectorization_4.q,vectorization_2.q,skewjoinopt6.q,union_remove_19.q,decimal_1_1.q,join14.q,outer_join_ppr.q,rcfile_bigdata.q,load_dyn_part10.q]
TestSparkCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=128)
	[skewjoinopt3.q,smb_mapjoin_4.q,timestamp_comparison.q,union_remove_10.q,mapreduce2.q,bucketmapjoin_negative.q,udf_in_file.q,union5.q,auto_join12.q,skewjoin.q,vector_left_outer_join.q,semijoin.q,skewjoinopt9.q,smb_mapjoin_3.q,stats10.q]
TestSparkCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=129)
	[bucketsortoptimize_insert_4.q,multi_insert_mixed.q,vectorization_10.q,auto_join18_multi_distinct.q,join_cond_pushdown_3.q,custom_input_output_format.q,skewjoinopt5.q,vectorization_part_project.q,vector_count_distinct.q,skewjoinopt4.q,count.q,parallel.q,union33.q,union_lateralview.q,nullgroup4.q]
TestSparkCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=130)
	[skewjoin_union_remove_2.q,avro_decimal_native.q,skewjoinopt8.q,bucketmapjoin_negative3.q,stats6.q,groupby2_map.q,stats_only_null.q,insert_into3.q,join18_multi_distinct.q,vectorization_6.q,cross_join.q,stats9.q,auto_join7.q,timestamp_1.q,join24.q]
TestSparkCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=131)
	[auto_join30.q,timestamp_null.q,union32.q,join16.q,groupby_ppr.q,bucketmapjoin7.q,smb_mapjoin_18.q,join19.q,vector_varchar_4.q,union6.q,cbo_subq_in.q,vectorization_part.q,sample8.q,vectorized_timestamp_funcs.q,join_star.q]
TestSparkCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=132)
	[union_remove_1.q,ppd_outer_join2.q,date_udf.q,groupby1_noskew.q,join20.q,smb_mapjoin_13.q,groupby_rollup1.q,temp_table_gb1.q,vector_string_concat.q,smb_mapjoin_6.q,metadata_only_queries.q,auto_sortmerge_join_12.q,groupby_bigdata.q,groupby3_map_multi_distinct.q,innerjoin.q]
TestSparkCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=133)
	[groupby_grouping_id2.q,input17.q,bucketmapjoin12.q,ppd_gby_join.q,auto_join10.q,ptf_rcfile.q,vector_elt.q,multi_insert.q,ppd_join5.q,ppd_join.q,join_filters_overlap.q,join_cond_pushdown_1.q,timestamp_3.q,load_dyn_part6.q,stats_noscan_2.q]
TestSparkCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=134)
	[tez_joins_explain.q,vectorized_rcfile_columnar.q,transform2.q,cbo_semijoin.q,bucketmapjoin13.q,union_remove_6_subq.q,groupby2_map_multi_distinct.q,load_dyn_part9.q,multi_insert_gby2.q,vectorization_11.q,groupby_position.q,avro_compression_enabled_native.q,smb_mapjoin_8.q,join21.q,auto_join16.q]
TestSparkCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=135)
	[enforce_order.q,smb_mapjoin_21.q,load_dyn_part15.q,udf_min.q,groupby_resolution.q,mapjoin_memcheck.q,subquery_exists.q,groupby5.q,join27.q,alter_merge_stats_orc.q,union_remove_2.q,vector_orderby_5.q,groupby6_map_skew.q,join12.q,union9.q]
TestSparkCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=136)
	[vectorization_16.q,join_casesensitive.q,transform_ppr2.q,join23.q,groupby7_map_skew.q,ppd_join2.q,ppd_outer_join5.q,create_merge_compressed.q,louter_join_ppr.q,sample9.q,smb_mapjoin_16.q,vectorization_not.q,having.q,ppd_outer_join1.q,union_remove_12.q]
TestSparkCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=137)
	[bucketmapjoin3.q,load_dyn_part5.q,union_date.q,cbo_gby.q,auto_join31.q,auto_sortmerge_join_1.q,join_cond_pushdown_unqual1.q,ppd_outer_join3.q,bucket_map_join_spark3.q,union28.q,statsfs.q,escape_sortby1.q,leftsemijoin.q,union_remove_6.q,join29.q]
TestSparkCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=138)
	[escape_distributeby1.q,join9.q,groupby2.q,groupby4_map.q,udf_max.q,vectorization_pushdown.q,cbo_gby_empty.q,join_cond_pushdown_unqual3.q,vectorization_short_regress.q,join8.q,sample10.q,cross_product_check_1.q,auto_join_stats.q,input_part2.q,groupby_multi_single_reducer3.q]
TestSparkCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=139)
	[groupby_map_ppr_multi_distinct.q,vectorization_13.q,mapjoin_mapjoin.q,union2.q,join41.q,groupby8_map.q,cbo_subq_not_in.q,identity_project_remove_skip.q,stats5.q,groupby8_map_skew.q,nullgroup2.q,mapjoin_subquery.q,bucket2.q,smb_mapjoin_1.q,union_remove_8.q]
TestSparkCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=140)
	[join39.q,bucketsortoptimize_insert_7.q,vector_distinct_2.q,bucketmapjoin10.q,join11.q,union13.q,auto_sortmerge_join_16.q,windowing.q,union_remove_3.q,skewjoinopt7.q,stats7.q,annotate_stats_join.q,multi_insert_lateral_view.q,ptf_streaming.q,join_1to1.q]
TestSparkCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=141)
	[timestamp_lazy.q,union29.q,runtime_skewjoin_mapjoin_spark.q,auto_join22.q,union8.q,groupby5_map.q,dynamic_rdd_cache.q,auto_join29.q,groupby6.q,merge1.q,mapjoin_distinct.q,vector_decimal_mapjoin.q,sample5.q,multi_insert_move_tasks_share_dependencies.q,join_array.q]
TestSparkCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=142)
	[load_dyn_part2.q,smb_mapjoin_7.q,vectorization_5.q,smb_mapjoin_2.q,ppd_join_filter.q,column_access_stats.q,stats0.q,vector_between_in.q,vectorized_string_funcs.q,bucket_map_join_2.q,groupby4_map_skew.q,groupby_ppr_multi_distinct.q,temp_table_join1.q,vectorized_case.q,stats_noscan_1.q]
TestSparkCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=143)
	[groupby4_noskew.q,groupby3_map_skew.q,join_cond_pushdown_2.q,union19.q,union24.q,union_remove_5.q,groupby7_noskew_multi_single_reducer.q,vectorization_1.q,index_auto_self_join.q,auto_smb_mapjoin_14.q,script_env_var2.q,pcr.q,auto_join_filters.q,join0.q,join37.q]
TestSparkCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=144)
	[stats12.q,groupby4.q,union_top_level.q,stats2.q,groupby10.q,mapjoin_filter_on_outerjoin.q,auto_sortmerge_join_4.q,limit_partition_metadataonly.q,load_dyn_part4.q,union3.q,groupby_multi_single_reducer.q,smb_mapjoin_14.q,groupby3_noskew_multi_distinct.q,stats18.q,union_remove_21.q]
TestSparkCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=145)
	[auto_sortmerge_join_13.q,join4.q,join35.q,udf_percentile.q,join_reorder3.q,subquery_in.q,auto_join19.q,stats14.q,vectorization_15.q,union7.q,vectorization_nested_udf.q,vector_groupby_3.q,vectorized_ptf.q,auto_join2.q,groupby1_map_skew.q]
TestSparkCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=146)
	[groupby3_map.q,union26.q,mapreduce1.q,mapjoin_addjar.q,bucket_map_join_spark1.q,udf_example_add.q,multi_insert_with_join.q,sample7.q,auto_join_nulls.q,ppd_outer_join4.q,load_dyn_part8.q,alter_merge_orc.q,sample6.q,bucket_map_join_1.q,auto_sortmerge_join_9.q]
TestSparkCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=147)
	[groupby_complex_types.q,multigroupby_singlemr.q,union11.q,groupby7.q,join5.q,bucketmapjoin_negative2.q,vectorization_div0.q,union_script.q,add_part_multiple.q,limit_pushdown.q,union_remove_17.q,uniquejoin.q,metadata_only_queries_with_filters.q,union25.q,load_dyn_part13.q]
TestSparkCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=148)
	[table_access_keys_stats.q,bucketmapjoin11.q,auto_join4.q,mapjoin_decimal.q,join34.q,nullgroup.q,mergejoins_mixed.q,sort.q,stats8.q,auto_join28.q,join17.q,union17.q,skewjoinopt11.q,groupby1_map.q,load_dyn_part11.q]
TestSparkCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=149)
	[ptf_seqfile.q,union_remove_23.q,parallel_join0.q,union_remove_9.q,join_nullsafe.q,skewjoinopt14.q,vectorized_mapjoin.q,union4.q,auto_join5.q,vectorized_shufflejoin.q,smb_mapjoin_20.q,groupby8_noskew.q,auto_sortmerge_join_10.q,groupby11.q,union_remove_16.q]
TestSparkCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=150)
	[smb_mapjoin_15.q,script_pipe.q,auto_join24.q,filter_join_breaktask.q,bucket4.q,ppd_multi_insert.q,skewjoinopt20.q,join_thrift.q,multi_insert_gby3.q,groupby8.q,join_map_ppr.q,auto_sortmerge_join_8.q,escape_clusterby1.q,groupby_multi_insert_common_distinct.q,join6.q]
TestSparkCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=151)
	[ppd_transform.q,auto_join9.q,auto_join1.q,vector_data_types.q,input13.q,input14.q,input12.q,union_remove_22.q,vectorization_3.q,groupby1_map_nomap.q,cbo_union.q,disable_merge_for_bucketing.q,reduce_deduplicate_exclude_join.q,filter_join_breaktask2.q,join30.q]
TestSparkCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=152)
	[router_join_ppr.q,auto_join13.q,union30.q,vector_mapjoin_reduce.q,ptf_register_tblfn.q,join_merging.q,union_date_trim.q,groupby3_noskew.q,optimize_nullscan.q,join3.q,join38.q,skewjoinopt1.q,join_alt_syntax.q,groupby_sort_1_23.q,timestamp_udf.q]
TestSparkCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=153)
	[groupby6_map.q,stats13.q,groupby2_noskew_multi_distinct.q,load_dyn_part12.q,join15.q,auto_join17.q,join_hive_626.q,tez_join_tests.q,auto_join21.q,join_view.q,join_cond_pushdown_4.q,vectorization_0.q,union_null.q,auto_join3.q,vectorization_decimal_date.q]
TestSparkCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=154)
	[union_remove_15.q,bucket_map_join_tez1.q,scriptfile1.q,groupby7_noskew.q,bucketmapjoin1.q,subquery_multiinsert.q,auto_join8.q,auto_join6.q,groupby2_map_skew.q,lateral_view_explode2.q,join28.q,load_dyn_part1.q,skewjoinopt17.q,union_remove_20.q,bucketmapjoin5.q]
TestSparkCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=155)
	[join2.q,join36.q,avro_joins_native.q,join18.q,smb_mapjoin_10.q,temp_table.q,union_remove_13.q,auto_sortmerge_join_5.q,groupby5_noskew.q,auto_join0.q,vectorization_17.q,auto_join_stats2.q,skewjoin_union_remove_1.q,union16.q,join_literals.q]
TestSparkCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=156)
	[auto_sortmerge_join_7.q,auto_join20.q,smb_mapjoin_5.q,vector_char_4.q,cross_product_check_2.q,union15.q,union_remove_25.q,insert_into2.q,join31.q,auto_join27.q,escape_orderby1.q,cbo_limit.q,stats_partscan_1_23.q,groupby_complex_types_multi_single_reducer.q,load_dyn_part14.q]
TestSparkNegativeCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=242)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_globallimit] (batchId=27)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[avrocountemptytbl] (batchId=74)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[columnStatsUpdateForStatsOptimizer_1] (batchId=31)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[index_compact_binary_search] (batchId=55)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[selectindate] (batchId=57)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[union_fast_stats] (batchId=47)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_5] (batchId=94)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainuser_3] (batchId=109)
org.apache.hive.beeline.TestBeeLineWithArgs.testQueryProgressParallel (batchId=222)
org.apache.hive.beeline.TestBeelineArgParsing.testAddLocalJarWithoutAddDriverClazz[0] (batchId=181)
org.apache.hive.beeline.TestBeelineArgParsing.testAddLocalJar[0] (batchId=181)
org.apache.hive.beeline.TestBeelineArgParsing.testAddLocalJar[1] (batchId=181)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/6452/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/6452/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-6452/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 58 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12882512 - PreCommit-HIVE-Build, For the tests that failed (as opposed to those that timed out), I reran on our dev hardware.
I wanted to see if the failure was reproducable and if it also failed at the 2.2.1 fork point.

|| Test || branch-2.2.1 fork (1ed1f28) || branch-2.2 HEAD + HIVE-13989 ||
| org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_globallimit] | FAILED | FAILED |
| org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[avrocountemptytbl] | PASSED | PASSED |
| org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[columnStatsUpdateForStatsOptimizer_1] | FAILED | FAILED |
| org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[index_compact_binary_search] | PASSED | PASSED |
| org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[selectindate] | PASSED | PASSED |
| org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[union_fast_stats] | FAILED | FAILED |
| org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_5] | FAILED | FAILED |
| org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainuser_3] | PASSED | PASSED |
| org.apache.hive.beeline.TestBeeLineWithArgs.testQueryProgressParallel | PASSED | PASSED |
| org.apache.hive.beeline.TestBeelineArgParsing.testAddLocalJarWithoutAddDriverClazz[0] | PASSED | PASSED |
| org.apache.hive.beeline.TestBeelineArgParsing.testAddLocalJar[0] | PASSED | PASSED |
| org.apache.hive.beeline.TestBeelineArgParsing.testAddLocalJar[1] | PASSED | PASSED |

Based on this, HIVE-13989 doesn't appear to be responsible for any of these failures., Uploaded branch-2 patch., Uploaded rebased patch for branch-2., 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12883493/HIVE-13989.4-branch-2.patch

{color:green}SUCCESS:{color} +1 due to 3 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 9 failed/errored test(s), 10606 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[comments] (batchId=35)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[explaindenpendencydiffengs] (batchId=38)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[llap_smb] (batchId=142)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[orc_ppd_basic] (batchId=139)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_if_expr] (batchId=144)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[explaindenpendencydiffengs] (batchId=115)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[vectorized_ptf] (batchId=125)
org.apache.hive.hcatalog.api.TestHCatClient.testTransportFailure (batchId=176)
org.apache.hive.jdbc.TestJdbcDriver2.testYarnATSGuid (batchId=222)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/6520/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/6520/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-6520/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 9 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12883493 - PreCommit-HIVE-Build, +1

[~cdrome] I wasn't able to check the test report in time - did you get a chance to look at them (they don't seem related though). , [~vgumashta], I checked all of the failures on the branch-2.2 build.
See https://issues.apache.org/jira/browse/HIVE-13989?focusedCommentId=16133742&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-16133742 for my comments on that build.

The test results for the branch-2 build are not available anymore.
Shall I submit another patch and rerun?, Ran tests locally before and after the patch on branch-2 and none of the failures appear to be attributable to the patch:

|| Test ||  branch-2 HEAD (b3a6e52) || branch-2 HEAD + HIVE-13989 ||
| org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[comments] | PASSED | PASSED |
| org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[explaindenpendencydiffengs] | FAILED | FAILED |
| org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[llap_smb] | FAILED | FAILED |
| org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[orc_ppd_basic] | FAILED | FAILED |
| org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_if_expr] | PASSED | PASSED |
| org.apache.hive.hcatalog.api.TestHCatClient.testTransportFailure | FAILED | FAILED |
| org.apache.hive.jdbc.TestJdbcDriver2.testYarnATSGuid | PASSED | PASSED |, Thanks for the analysis [~cdrome]. Will commit this shortly, Committed to branch-2.2 and branch-2. Thanks a lot [~cdrome]!, [~vgumashta], this jira is marked as fixed in 2.3.0 and 2.2.1 but you committed it to branch-2 and branch-2.2 so I think it should say fixed in 2.4.0 and 2.2.1.]