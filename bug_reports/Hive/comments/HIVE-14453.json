[The patch; most of it is just moving code.
PhysicalWriter boundary is at data blocks and metadata protobuf objects. It modifies protobuf objects only with regard to physical information like sizes, etc.
Some tests pass locally, let's see what HiveQA thinks... [~prasanth_j] can you take a look, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12822409/HIVE-14453.patch

{color:green}SUCCESS:{color} +1 due to 2 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 3 failed/errored test(s), 10440 tests executed
*Failed tests:*
{noformat}
TestMsgBusConnection - did not produce a TEST-*.xml file
TestQueryLifeTimeHook - did not produce a TEST-*.xml file
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver_orc_llap_counters
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-MASTER-Build/800/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-MASTER-Build/800/console
Test logs: http://ec2-204-236-174-241.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-MASTER-Build-800/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 3 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12822409 - PreCommit-HIVE-MASTER-Build, Forgot the bloom filters, they need to be treated similarly to indexes. Will include in the patch with the first iteration of CR, or maybe earlier if CR is slow ;), Also maybe codec modifier determination should be inside physical writer, Updated., 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12822852/HIVE-14453.01.patch

{color:green}SUCCESS:{color} +1 due to 2 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 9 failed/errored test(s), 10459 tests executed
*Failed tests:*
{noformat}
TestMsgBusConnection - did not produce a TEST-*.xml file
TestQueryLifeTimeHook - did not produce a TEST-*.xml file
org.apache.hive.jdbc.TestJdbcWithMiniHS2.testAddJarConstructorUnCaching
org.apache.hive.minikdc.TestJdbcWithDBTokenStore.testConnection
org.apache.hive.minikdc.TestJdbcWithDBTokenStore.testIsValid
org.apache.hive.minikdc.TestJdbcWithDBTokenStore.testIsValidNeg
org.apache.hive.minikdc.TestJdbcWithDBTokenStore.testNegativeTokenAuth
org.apache.hive.minikdc.TestJdbcWithDBTokenStore.testProxyAuth
org.apache.hive.minikdc.TestJdbcWithDBTokenStore.testTokenAuth
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-MASTER-Build/834/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-MASTER-Build/834/console
Test logs: http://ec2-204-236-174-241.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-MASTER-Build-834/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 9 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12822852 - PreCommit-HIVE-MASTER-Build, Jdbc failures are unrelated., I'd like to revive this patch for HIVE-15147 (where we want to reencode parts of a text file to ORC for caching, and cache columns separately from each other).

[~prasanth_j] can you please review? This is a refactoring, so no real logic changes as far as I see., 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12838280/HIVE-14453.02.patch

{color:green}SUCCESS:{color} +1 due to 2 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 2 failed/errored test(s), 10637 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[join_acid_non_acid] (batchId=150)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[union_fast_stats] (batchId=145)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/2058/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/2058/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-2058/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 2 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12838280 - PreCommit-HIVE-Build, [~prasanth_j] [~gopalv] can you please review or discuss? Needed for HIVE-15147. Anyway I think it's a good idea to separate layers in the writer, PhysicalWriter can renamed to just Writer interface. Implementation could be FileWriter/StreamWriter. Also hflush can be renamed to flush as hflush seems hdfs specific.
Other than that I assume it just moves code around. , [~prasanth_j] Writer/WriterImpl already exists, so I wanted to distinguish it from that. , Renamed the method, rebased, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12840923/HIVE-14453.03.patch

{color:green}SUCCESS:{color} +1 due to 2 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 7 failed/errored test(s), 10746 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[sample2] (batchId=5)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[sample4] (batchId=15)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[sample6] (batchId=60)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[sample7] (batchId=59)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[sample9] (batchId=38)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[transform_ppr2] (batchId=133)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_4] (batchId=91)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/2331/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/2331/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-2331/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 7 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12840923 - PreCommit-HIVE-Build, The PhysicalWriter interface seems brittle in the face of changes. In particular, calling out the different kinds of streams as different methods seems problematic.

What is the goal of this API? Can we implement this at the byte level rather than passing protobufs around?, Different kinds of streams are not distinguished for data streams, only index streams.
Protobufs are necessary for two reasons:
1) Only the physical writer knows certain things that are put in them, e.g. file offsets.
2) Alternative writers do not have to serialize protobufs as bytes (or at all).

An example implementation of using ORC as cache storage format for text tables is in the blocked JIRA that now has a WIP patch.

I think it's actually no more brittle than any other separation of concerns - it just separates the physical file on disk and its organization from the logic of writing the data and metadata, which is good even if it reduces flexibility somewhat, as it avoids monolithic dependencies for these two unrelated things.
, +1, Committed to master, Why are indexes separated out? This is *really* brittle. In particular, I started forward porting this to ORC and this API is *already* broken because the fixed bloom representation in ORC's writer. Let's continue the discussion over on ORC-119., Responded there. ]