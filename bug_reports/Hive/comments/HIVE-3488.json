[Any news?, Reminder., We are getting a similar error after dropping all partitions:

java.io.IOException: cannot find dir = hdfs://HVEname:9000/tmp/hive-admin/hive_2013-07-12_05-31-36_471_398021424951
1966905/-mr-10002/1/emptyFile in pathToPartitionInfo: [hdfs://192.168.156.229:9000/tmp/hive-admin/hive_2013-07-12_0
5-31-36_471_3980214249511966905/-mr-10002/1]
        at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getPartitionDescFromPathRecursively(HiveFileFormatUtils
.java:298)
        at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getPartitionDescFromPathRecursively(HiveFileFormatUtils
.java:260)
        at org.apache.hadoop.hive.ql.io.CombineHiveInputFormat$CombineHiveInputSplit.<init>(CombineHiveInputFormat.
java:104)
        at org.apache.hadoop.hive.ql.io.CombineHiveInputFormat.getSplits(CombineHiveInputFormat.java:407)
        at org.apache.hadoop.mapred.JobClient.writeOldSplits(JobClient.java:929)
        at org.apache.hadoop.mapred.JobClient.writeSplits(JobClient.java:921), Hi, 

I was getting similar exception trace. And quick solution to that is to not use default warehouse location for table i.e; "/user/hive/warehouse". 

Alter table to set location to some other directory like 'hdfs://localhost:8888/user/youruser/hive/test'. 

This might help you. Please let me know if it works.

Thanks]