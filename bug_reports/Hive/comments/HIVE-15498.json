[patch-1: change the default to RangeBoundarySpec for the case sum() over (order by c)  to be consistent., That RangeBoundarySpec should be what the user expects and with that, streaming is supported. With ValueBoundarySpec, streaming is not supported, so the performance is bad. , The only change in the code is:

{noformat}
wFrame = new WindowFrameSpec(		
   new ValueBoundarySpec(Direction.PRECEDING, BoundarySpec.UNBOUNDED_AMOUNT),		
	                  new CurrentRowSpec()		
	            );
{noformat}

to 
{noformat}
wFrame = new WindowFrameSpec(		
   new RangeBoundarySpec(Direction.PRECEDING, BoundarySpec.UNBOUNDED_AMOUNT),		
	                  new CurrentRowSpec()		
	            );
{noformat}

RangeBoundarySpec is for "ROWS BETWEEN" and ValueBoundarySpec is for "RANGE BETWEEN". So it's a little confusing., 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12844434/HIVE-15498.1.patch

{color:red}ERROR:{color} -1 due to no test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 28 failed/errored test(s), 10865 tests executed
*Failed tests:*
{noformat}
TestDerbyConnector - did not produce a TEST-*.xml file (likely timed out) (batchId=234)
TestMiniLlapLocalCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=144)
	[vectorized_rcfile_columnar.q,vector_elt.q,explainuser_1.q,multi_insert.q,tez_dml.q,vector_bround.q,schema_evol_orc_acid_table.q,vector_when_case_null.q,orc_ppd_schema_evol_1b.q,vector_join30.q,vectorization_11.q,cte_3.q,update_tmp_table.q,vector_decimal_cast.q,groupby_grouping_id2.q,vector_decimal_round.q,tez_smb_empty.q,orc_merge6.q,vector_char_mapjoin1.q,vector_decimal_trailing.q,cte_5.q,tez_union.q,vector_decimal_2.q,columnStatsUpdateForStatsOptimizer_1.q,vector_outer_join3.q,schema_evol_text_vec_part_all_complex.q,tez_dynpart_hashjoin_2.q,auto_sortmerge_join_12.q,offset_limit.q,tez_union_multiinsert.q]
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[cbo_rp_windowing] (batchId=35)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[cbo_windowing] (batchId=49)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[dbtxnmgr_showlocks] (batchId=71)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[leadlag] (batchId=51)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[ptf_general_queries] (batchId=6)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[temp_table_windowing_expressions] (batchId=58)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[windowing_decimal] (batchId=62)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[windowing_expressions] (batchId=50)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[windowing_multipartitioning] (batchId=50)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[windowing_udaf] (batchId=60)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[windowing_windowspec] (batchId=16)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[cbo_rp_windowing_2] (batchId=142)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[cbo_windowing] (batchId=148)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[lineage2] (batchId=148)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[lineage3] (batchId=146)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[ptf] (batchId=140)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[ptf_streaming] (batchId=148)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[special_character_in_tabnames_1] (batchId=146)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vectorized_ptf] (batchId=149)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[windowing] (batchId=147)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_2] (batchId=93)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[ptf] (batchId=101)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[ptf_general_queries] (batchId=97)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[ptf_streaming] (batchId=116)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[vectorized_ptf] (batchId=121)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[windowing] (batchId=116)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/2697/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/2697/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-2697/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 28 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12844434 - PreCommit-HIVE-Build, patch-2: Update affected unit tests. , Other databases like Oracle also works in this way., [~ashutoshc], [~ychena]  Can you help review the change? Seems the users are using sum() over (order by c) as a running total, but actually we are incorrectly adding "range between".

Here is what Oracle does (See http://www.oracle.com/technetwork/issue-archive/2013/13-mar/o23sql-1906475.html) which returns a running total., 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12844469/HIVE-15498.2.patch

{color:red}ERROR:{color} -1 due to no test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 2 failed/errored test(s), 10895 tests executed
*Failed tests:*
{noformat}
TestDerbyConnector - did not produce a TEST-*.xml file (likely timed out) (batchId=234)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_4] (batchId=93)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/2704/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/2704/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-2704/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 2 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12844469 - PreCommit-HIVE-Build, Seems I was incorrect. Tried Postgres and Oracle, both default {{sum() over (ORDER BY C)}} to {{RANGE BETWEEN UNBOUNDED PROCEEDING AND CURRENT ROW}} as current Hive behavior. 

So we just need to update the document., Thanks for the doc update, [~aihuaxu].

* [OVER with PARTITION BY and ORDER BY | https://cwiki.apache.org/confluence/display/Hive/LanguageManual+WindowingAndAnalytics#LanguageManualWindowingAndAnalytics-OVERwithPARTITIONBYandORDERBY]]