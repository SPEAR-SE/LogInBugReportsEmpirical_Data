[Exception stack.
{code}
2018-05-24T14:23:08,356 ERROR [bed0135d-46f9-495c-a71a-686aa8c449a2 main] CliDriver: Failed with exception java.io.IOException:java.lang.NumberFormatException: For input string: "2015-03-08 00:00:00"
java.io.IOException: java.lang.NumberFormatException: For input string: "2015-03-08 00:00:00"
        at org.apache.hadoop.hive.ql.exec.FetchOperator.getNextRow(FetchOperator.java:602)
        at org.apache.hadoop.hive.ql.exec.FetchOperator.pushRow(FetchOperator.java:509)
        at org.apache.hadoop.hive.ql.exec.FetchTask.fetch(FetchTask.java:145)
        at org.apache.hadoop.hive.ql.Driver.getResults(Driver.java:2509)
        at org.apache.hadoop.hive.ql.reexec.ReExecDriver.getResults(ReExecDriver.java:229)
        at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:259)
        at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:188)
        at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:402)
        at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:335)
        at org.apache.hadoop.hive.ql.QTestUtil.executeClientInternal(QTestUtil.java:1485)
        at org.apache.hadoop.hive.ql.QTestUtil.executeClient(QTestUtil.java:1459)
        at org.apache.hadoop.hive.cli.control.CoreCliDriver.runTest(CoreCliDriver.java:177)
        at org.apache.hadoop.hive.cli.control.CliAdapter.runTest(CliAdapter.java:104)
        at org.apache.hadoop.hive.cli.TestMiniDruidLocalCliDriver.testCliDriver(TestMiniDruidLocalCliDriver.java:43)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
        at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
        at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
        at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
        at org.apache.hadoop.hive.cli.control.CliAdapter$2$1.evaluate(CliAdapter.java:92)
        at org.junit.rules.RunRules.evaluate(RunRules.java:20)
        at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
        at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
        at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
        at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
        at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
        at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
        at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
        at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
        at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
        at org.junit.runners.Suite.runChild(Suite.java:127)
        at org.junit.runners.Suite.runChild(Suite.java:26)
        at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
        at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
        at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
        at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
        at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
        at org.apache.hadoop.hive.cli.control.CliAdapter$1$1.evaluate(CliAdapter.java:73)
        at org.junit.rules.RunRules.evaluate(RunRules.java:20)
        at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
        at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
        at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
        at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
        at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
        at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:379)
        at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:340)
        at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:125)
        at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:413)
Caused by: java.lang.NumberFormatException: For input string: "2015-03-08 00:00:00"
        at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
        at java.lang.Integer.parseInt(Integer.java:580)
        at java.lang.Integer.valueOf(Integer.java:766)
        at org.apache.hadoop.hive.druid.serde.DruidGroupByQueryRecordReader.lambda$nextKeyValue$2(DruidGroupByQueryRecordReader.java:113)
        at org.apache.hive.druid.com.google.common.collect.Maps$10.getValue(Maps.java:1855)
        at java.util.HashMap.putMapEntries(HashMap.java:513)
        at java.util.HashMap.putAll(HashMap.java:784)
        at org.apache.hadoop.hive.druid.serde.DruidGroupByQueryRecordReader.next(DruidGroupByQueryRecordReader.java:151)
        at org.apache.hadoop.hive.druid.serde.DruidGroupByQueryRecordReader.next(DruidGroupByQueryRecordReader.java:48)
        at org.apache.hadoop.hive.ql.exec.FetchOperator.getNextRow(FetchOperator.java:569)
        ... 50 more
{code}, This is probably not the best way to fix this, but it does the job.
In the future we need to change the way how we ser/deser time column from Druid.
, It seems like it adds logic to parse timestamp with 2nd format after it fails parsing with first format. In what cases we will have timestamps with these 2 diff string representations?, In Case a cast to timestamp is pushed to Druid {code}CAST(`ssb_druid_100`.`__time` AS TIMESTAMP){code}, the results is formatted as a Timestamp {code}yyyy-MM-dd HH:mm:ss{code}.
This is probably not the best way to fix this, but i want us to at least fix this very nasty bug and i will refactor this as soon as possible, especially after all the changes coming from [~jcamachorodriguez] around that part of the code.
 , ok +1, [~ashutoshc] please hold on this, i think i can tackle HIVE-19721 in the same patch., 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12925060/HIVE-19675.2.patch

{color:red}ERROR:{color} -1 due to build exiting with an error

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/11259/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/11259/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-11259/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Tests exited with: NonZeroExitCodeException
Command 'bash /data/hiveptest/working/scratch/source-prep.sh' failed with exit status 1 and output '+ date '+%Y-%m-%d %T.%3N'
2018-05-27 12:22:19.524
+ [[ -n /usr/lib/jvm/java-8-openjdk-amd64 ]]
+ export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
+ JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
+ export PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games
+ PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games
+ export 'ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m '
+ ANT_OPTS='-Xmx1g -XX:MaxPermSize=256m '
+ export 'MAVEN_OPTS=-Xmx1g '
+ MAVEN_OPTS='-Xmx1g '
+ cd /data/hiveptest/working/
+ tee /data/hiveptest/logs/PreCommit-HIVE-Build-11259/source-prep.txt
+ [[ false == \t\r\u\e ]]
+ mkdir -p maven ivy
+ [[ git = \s\v\n ]]
+ [[ git = \g\i\t ]]
+ [[ -z master ]]
+ [[ -d apache-github-source-source ]]
+ [[ ! -d apache-github-source-source/.git ]]
+ [[ ! -d apache-github-source-source ]]
+ date '+%Y-%m-%d %T.%3N'
2018-05-27 12:22:19.527
+ cd apache-github-source-source
+ git fetch origin
+ git reset --hard HEAD
HEAD is now at 702a676 HIVE-19340: Disable timeout of transactions opened by replication task at target cluster (Mahesh Kumar Behera, reviewed by Sankar Hariappan)
+ git clean -f -d
+ git checkout master
Already on 'master'
Your branch is up-to-date with 'origin/master'.
+ git reset --hard origin/master
HEAD is now at 702a676 HIVE-19340: Disable timeout of transactions opened by replication task at target cluster (Mahesh Kumar Behera, reviewed by Sankar Hariappan)
+ git merge --ff-only origin/master
Already up-to-date.
+ date '+%Y-%m-%d %T.%3N'
2018-05-27 12:22:20.877
+ rm -rf ../yetus_PreCommit-HIVE-Build-11259
+ mkdir ../yetus_PreCommit-HIVE-Build-11259
+ git gc
+ cp -R . ../yetus_PreCommit-HIVE-Build-11259
+ mkdir /data/hiveptest/logs/PreCommit-HIVE-Build-11259/yetus
+ patchCommandPath=/data/hiveptest/working/scratch/smart-apply-patch.sh
+ patchFilePath=/data/hiveptest/working/scratch/build.patch
+ [[ -f /data/hiveptest/working/scratch/build.patch ]]
+ chmod +x /data/hiveptest/working/scratch/smart-apply-patch.sh
+ /data/hiveptest/working/scratch/smart-apply-patch.sh /data/hiveptest/working/scratch/build.patch
error: patch failed: ql/src/test/results/clientpositive/druid/druidmini_extractTime.q.out:1015
Falling back to three-way merge...
Applied patch to 'ql/src/test/results/clientpositive/druid/druidmini_extractTime.q.out' with conflicts.
Going to apply patch with: git apply -p0
error: patch failed: ql/src/test/results/clientpositive/druid/druidmini_extractTime.q.out:1015
Falling back to three-way merge...
Applied patch to 'ql/src/test/results/clientpositive/druid/druidmini_extractTime.q.out' with conflicts.
U ql/src/test/results/clientpositive/druid/druidmini_extractTime.q.out
+ exit 1
'
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12925060 - PreCommit-HIVE-Build, | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
|| || || || {color:brown} master Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 37s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  6m 26s{color} | {color:green} master passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m 13s{color} | {color:green} master passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 44s{color} | {color:green} master passed {color} |
| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m 24s{color} | {color:blue} druid-handler in master has 12 extant Findbugs warnings. {color} |
| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  3m 33s{color} | {color:blue} ql in master has 2324 extant Findbugs warnings. {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 59s{color} | {color:green} master passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m  7s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m 47s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m 15s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  1m 15s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} checkstyle {color} | {color:red}  0m 10s{color} | {color:red} druid-handler: The patch generated 2 new + 102 unchanged - 4 fixed = 104 total (was 106) {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  4m 14s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 59s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 11s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 23m 54s{color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Optional Tests |  asflicense  javac  javadoc  findbugs  checkstyle  compile  |
| uname | Linux hiveptest-server-upstream 3.16.0-4-amd64 #1 SMP Debian 3.16.36-1+deb8u1 (2016-09-03) x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /data/hiveptest/working/yetus_PreCommit-HIVE-Build-11321/dev-support/hive-personality.sh |
| git revision | master / 6a24a0c |
| Default Java | 1.8.0_111 |
| findbugs | v3.0.0 |
| checkstyle | http://104.198.109.242/logs//PreCommit-HIVE-Build-11321/yetus/diff-checkstyle-druid-handler.txt |
| modules | C: druid-handler ql U: . |
| Console output | http://104.198.109.242/logs//PreCommit-HIVE-Build-11321/yetus.txt |
| Powered by | Apache Yetus    http://yetus.apache.org |


This message was automatically generated.

, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12925309/HIVE-19675.3.patch

{color:green}SUCCESS:{color} +1 due to 1 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 1 failed/errored test(s), 14409 tests executed
*Failed tests:*
{noformat}
org.apache.hive.hcatalog.pig.TestHCatLoaderComplexSchema.testSyntheticComplexSchema[3] (batchId=197)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/11321/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/11321/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-11321/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.YetusPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 1 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12925309 - PreCommit-HIVE-Build, [~jcamachorodriguez] Do we have jira for TestHCatLoaderComplexSchema.testSyntheticComplexSchema() ? We may need to disable this. [~daijy] Any guess for its flakiness. It fails with following stacktrace:
{code}

org.apache.pig.impl.logicalLayer.FrontendException: ERROR 1066: Unable to open iterator for alias X. Backend error : java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
	at org.apache.pig.PigServer.openIterator(PigServer.java:1009)
	at org.apache.hive.hcatalog.pig.TestHCatLoaderComplexSchema.verifyWriteRead(TestHCatLoaderComplexSchema.java:230)
	at org.apache.hive.hcatalog.pig.TestHCatLoaderComplexSchema.verifyWriteRead(TestHCatLoaderComplexSchema.java:207)
	at org.apache.hive.hcatalog.pig.TestHCatLoaderComplexSchema.testSyntheticComplexSchema(TestHCatLoaderComplexSchema.java:202)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runners.Suite.runChild(Suite.java:127)
	at org.junit.runners.Suite.runChild(Suite.java:26)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:379)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:340)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:125)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:413)
Caused by: org.apache.pig.backend.executionengine.ExecException: ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher.getStats(MapReduceLauncher.java:822)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher.launchPig(MapReduceLauncher.java:452)
	at org.apache.pig.backend.hadoop.executionengine.HExecutionEngine.launchPig(HExecutionEngine.java:308)
	at org.apache.pig.PigServer.launchPlan(PigServer.java:1474)
	at org.apache.pig.PigServer.executeCompiledLogicalPlan(PigServer.java:1459)
	at org.apache.pig.PigServer.storeEx(PigServer.java:1118)
	at org.apache.pig.PigServer.store(PigServer.java:1081)
	at org.apache.pig.PigServer.openIterator(PigServer.java:994)
	... 37 more
Caused by: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
	at org.apache.hadoop.mapreduce.Job.ensureState(Job.java:300)
	at org.apache.hadoop.mapreduce.Job.getTaskReports(Job.java:542)
	at org.apache.pig.backend.hadoop.executionengine.shims.HadoopShims.getTaskReports(HadoopShims.java:235)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher.getStats(MapReduceLauncher.java:801)
	... 44 moreorg.apache
{code}, [~ashutoshc], I have created HIVE-19731 and uploaded a fix. Root cause is the same as with other flaky test: default staging directory.

{noformat}
org.apache.hadoop.util.Shell$ExitCodeException: chmod: cannot access ‘/tmp/hadoop/mapred/staging/hiveptest985275899/.staging/job_local985275899_0088’: No such file or directory

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:1009) ~[hadoop-common-3.1.0.jar:?]
	at org.apache.hadoop.util.Shell.run(Shell.java:902) ~[hadoop-common-3.1.0.jar:?]
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1227) ~[hadoop-common-3.1.0.jar:?]
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1321) ~[hadoop-common-3.1.0.jar:?]
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1303) ~[hadoop-common-3.1.0.jar:?]
	at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:840) ~[hadoop-common-3.1.0.jar:?]
	at org.apache.hadoop.fs.ChecksumFileSystem$1.apply(ChecksumFileSystem.java:508) ~[hadoop-common-3.1.0.jar:?]
	at org.apache.hadoop.fs.ChecksumFileSystem$FsOperation.run(ChecksumFileSystem.java:489) ~[hadoop-common-3.1.0.jar:?]
	at org.apache.hadoop.fs.ChecksumFileSystem.setPermission(ChecksumFileSystem.java:511) ~[hadoop-common-3.1.0.jar:?]
	at org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:727) ~[hadoop-common-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.JobResourceUploader.mkdirs(JobResourceUploader.java:658) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.JobResourceUploader.uploadResourcesInternal(JobResourceUploader.java:172) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.JobResourceUploader.uploadResources(JobResourceUploader.java:133) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(JobSubmitter.java:102) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:197) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1570) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1567) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_102]
	at javax.security.auth.Subject.doAs(Subject.java:422) ~[?:1.8.0_102]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682) ~[hadoop-common-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1567) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:336) [hadoop-mapreduce-client-core-3.1.0.jar:?]
	at sun.reflect.GeneratedMethodAccessor36.invoke(Unknown Source) ~[?:?]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_102]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_102]
	at org.apache.pig.backend.hadoop23.PigJobControl.submit(PigJobControl.java:128) [pig-0.16.0-h2.jar:?]
	at org.apache.pig.backend.hadoop23.PigJobControl.run(PigJobControl.java:194) [pig-0.16.0-h2.jar:?]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_102]
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:276) [pig-0.16.0-h2.jar:?]
{noformat}, | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
|| || || || {color:brown} master Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 22s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  6m  9s{color} | {color:green} master passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m 13s{color} | {color:green} master passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 45s{color} | {color:green} master passed {color} |
| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m 26s{color} | {color:blue} druid-handler in master has 12 extant Findbugs warnings. {color} |
| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  3m 33s{color} | {color:blue} ql in master has 2333 extant Findbugs warnings. {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m  3s{color} | {color:green} master passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m  7s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m 45s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m 12s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  1m 12s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m  9s{color} | {color:green} druid-handler: The patch generated 0 new + 14 unchanged - 92 fixed = 14 total (was 106) {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 36s{color} | {color:green} The patch ql passed checkstyle {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  0m 32s{color} | {color:red} druid-handler generated 1 new + 12 unchanged - 0 fixed = 13 total (was 12) {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m  0s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 12s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 23m 23s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| FindBugs | module:druid-handler |
|  |  Boxing/unboxing to parse a primitive org.apache.hadoop.hive.druid.serde.DruidSerDe.deserialize(Writable)  At DruidSerDe.java:org.apache.hadoop.hive.druid.serde.DruidSerDe.deserialize(Writable)  At DruidSerDe.java:[line 441] |
\\
\\
|| Subsystem || Report/Notes ||
| Optional Tests |  asflicense  javac  javadoc  findbugs  checkstyle  compile  |
| uname | Linux hiveptest-server-upstream 3.16.0-4-amd64 #1 SMP Debian 3.16.36-1+deb8u1 (2016-09-03) x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /data/hiveptest/working/yetus_PreCommit-HIVE-Build-11359/dev-support/hive-personality.sh |
| git revision | master / c2ba457 |
| Default Java | 1.8.0_111 |
| findbugs | v3.0.0 |
| findbugs | http://104.198.109.242/logs//PreCommit-HIVE-Build-11359/yetus/new-findbugs-druid-handler.html |
| modules | C: druid-handler ql U: . |
| Console output | http://104.198.109.242/logs//PreCommit-HIVE-Build-11359/yetus.txt |
| Powered by | Apache Yetus    http://yetus.apache.org |


This message was automatically generated.

, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12925525/HIVE-19675.5.patch

{color:green}SUCCESS:{color} +1 due to 1 test(s) being added or modified.

{color:green}SUCCESS:{color} +1 due to 14414 tests passed

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/11359/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/11359/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-11359/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.YetusPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12925525 - PreCommit-HIVE-Build, Pushed to master. Thanks, Slim
[~vgarg] Can we get this in branch-3 as well. Since change is only in druid-handler/ it has low risk to break any other tests. So, doesn't warrant another run for branch-3., Pushed to branch-3, This is released in Hive 3.1.0.]