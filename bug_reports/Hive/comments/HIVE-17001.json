[

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12875214/HIVE-17001.01.patch

{color:green}SUCCESS:{color} +1 due to 1 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 14 failed/errored test(s), 10825 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestBeeLineDriver.testCliDriver[insert_overwrite_local_directory_1] (batchId=237)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[llap_smb] (batchId=143)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[orc_ppd_basic] (batchId=140)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_if_expr] (batchId=145)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=232)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query23] (batchId=232)
org.apache.hadoop.hive.cli.TestSparkNegativeCliDriver.org.apache.hadoop.hive.cli.TestSparkNegativeCliDriver (batchId=239)
org.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testBootstrapFunctionReplication (batchId=216)
org.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testCreateFunctionIncrementalReplication (batchId=216)
org.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testCreateFunctionWithFunctionBinaryJarsOnHDFS (batchId=216)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema (batchId=177)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema (batchId=177)
org.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation (batchId=177)
org.apache.hive.spark.client.rpc.TestRpc.testClientTimeout (batchId=285)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/5850/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/5850/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-5850/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 14 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12875214 - PreCommit-HIVE-Build, Failures should not be related or are already covered in other Jiras:
HIVE-16931, HIVE-16959, HIVE-15165, HIVE-16908., [~zsombor.klara] I didn't understand the test case.

{noformat}
# One partition dt='p1' with row ("a",1) is added
insert into test_part partition(dt = 'p1') values ("a", 1);

# Partition metadata is removed only (no data because it is an external table)
alter table test_part drop partition (dt='p1');

# Data is moved
dfs -mv ${system:test.tmp.dir}/test/dt=p1/000000_0 ${system:test.tmp.dir}/test/dt=p1/000000_1;

# Partition is re-created with dt='p1" with row ("b",2)
insert overwrite table test_part partition(dt = 'p1') values ("b", 2);

# This is correct, only one row is seen because the row ("a",1) was moved to another location manually.
# Where is the issue here?
select * from test_part;
{noformat}

, [~zsombor.klara] Quick qs on the issue. I am a bit confused between the jira summary and the reproducer. Summary says "insert overwrite" but the reproducer does not use "insert overwrite". So I am wondering if the reproducer is intended to be the same as written.

I am not sure if this is a bug. Say, you execute the following
INSERT INTO test PARTITION(ds='p1') values ('a');
INSERT INTO test PARTITION(ds='p1') values ('a');

The resultant partition directory should contain 2 data files and a select * on the table should return 2 rows. This is by design.
The testcase in this jira is semantically similar to the case above, where you have some existing data in a partition and you are inserting additional data. Would you agree?

Normally, step 4 of the reproducer should have deleted the data for the partition, had it existed. But I think it is legal to manage some or all of the partition data externally, as well. 

Am I making sense? Thanks, [~spena] No, the file is not moved outside in the test just renamed from 000000_0 to 000000_1, it is there in the same partition directory (unless I made a typo I'm not seeing right now).

[~ngangam] Yes I made a mistake in the description, the insert should be an insert overwrite table, let me correct it. But the behaviour is the same, the datafile is not overwritten with insert overwrite either., Cancelling the patch as after some discussions it was decided that this should not be an issue. Data in the directory could be copied there on purpose by the user and should not be deleted without a warning.]