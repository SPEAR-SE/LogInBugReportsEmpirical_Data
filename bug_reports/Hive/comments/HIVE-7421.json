[StringConcatColScalar is not making a recursive call to evaluate its children. I think that is causing the columns to show up with nulls. StringConcatColScalar#evaluate should have following code at the beginning.

{code}
    if (childExpressions != null) {
      super.evaluateChildren(batch);
    }
{code}, Made this change.

Now there are exceptions being thrown and caught below in the same call sequence.

{code}
java.lang.IllegalArgumentException
	at java.sql.Date.valueOf(Date.java:138)
	at org.apache.hadoop.hive.ql.exec.vector.expressions.VectorUDFDateString$1.evaluate(VectorUDFDateString.java:38)
	at org.apache.hadoop.hive.ql.exec.vector.expressions.StringUnaryUDF.evaluate(StringUnaryUDF.java:101)
	at org.apache.hadoop.hive.ql.exec.vector.expressions.VectorExpression.evaluateChildren(VectorExpression.java:112)
	at org.apache.hadoop.hive.ql.exec.vector.expressions.StringConcatColScalar.evaluate(StringConcatColScalar.java:50)
	at org.apache.hadoop.hive.ql.exec.vector.expressions.VectorExpression.evaluateChildren(VectorExpression.java:112)
	at org.apache.hadoop.hive.ql.exec.vector.expressions.gen.FilterStringColEqualStringScalar.evaluate(FilterStringColEqualStringScalar.java:48)
	at org.apache.hadoop.hive.ql.exec.vector.expressions.FilterExprOrExpr.evaluate(FilterExprOrExpr.java:87)
	at org.apache.hadoop.hive.ql.exec.vector.expressions.FilterExprAndExpr.evaluate(FilterExprAndExpr.java:37)
	at org.apache.hadoop.hive.ql.exec.vector.VectorFilterOperator.processOp(VectorFilterOperator.java:91)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:800)
	at org.apache.hadoop.hive.ql.exec.TableScanOperator.processOp(TableScanOperator.java:95)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:800)
	at org.apache.hadoop.hive.ql.exec.vector.VectorMapOperator.process(VectorMapOperator.java:43)
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapper.map(ExecMapper.java:177)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:695)
{code}, 
The dates being passed to VectorUDFDateString which calls Date.valueOf include the time 00:00:00, which isn't allowed...

{code}
14/07/19 21:29:35 INFO vector.VectorGroupByOperator: VectorUDFDateString string passed to Date.valueOf = '2002-12-31 00:00:00'
{code}

Is this an error in the query or in our execution of it?, bq. Is this an error in the query or in our execution of it?
  It is possible that the data contains a string that cannot be parsed as a DATE and those strings are parsed into null value. VectorUDFDateString actually catches the IllegalArgumentException and returns null, therefore the query should not fail. 
  Is the query failing in vectorized path? Or is it returning wrong result?, Yes, I noticed the query catches the exceptions, suppresses it, and doesn't "fail", except it returns no rows.  But the non-vectorized query does return rows., Make VectorUDFDateString use the same date parsing and formatting as GenericUDFDate, which is its non-vectorized counterpart., +1 if tests pass, Thanks Jason !!!, 

{color:red}Overall{color}: -1 at least one tests failed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12660042/HIVE-7421.1.patch

{color:red}ERROR:{color} -1 due to 4 failed/errored test(s), 5882 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_dynpart_sort_opt_vectorization
org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_ql_rewrite_gbtoidx
org.apache.hadoop.hive.ql.TestDDLWithRemoteMetastoreSecondNamenode.testCreateTableWithIndexAndPartitionsNonDefaultNameNode
org.apache.hive.jdbc.miniHS2.TestHiveServer2.testConnection
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/194/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/194/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-194/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 4 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12660042, Committed to trunk. Thanks, Matt!, Thank You!, This has been fixed in 0.14 release. Please open new jira if you see any issues.
]