[There are two problems with this bug:

#1. Missing Dependency:
The compile and test classpath in pdk/scripts/build-plugin.xml is based on build/ivy/lib/default, the following dependencies are missing when building hive-exec*.jar:

hadoop-mapreduce-client-jobclient
hadoop-minicluster

This dependency should be added to ql/ivy.xml, which is the place for hive-exec dependencies.

Note that hadoop-mapreduce-client-jobclient dependency should be updated by just changing the jar placement. putting the jar in build/ivy/lib/test/ would not be included in pdk PluginTest classpath.

#2. After fixing #1, the following log4j warning message appears in the output stream, which fails the testcase(pdk PluginTest diffs expected output with the output stream):

test:
    [junit] Running org.apache.hive.pdk.PluginTest
    [junit] 2012-08-28 19:05:20,679 WARN  [main] conf.Configuration (Configuration.java:loadProperty(1621)) - file:/tmp/cloudera/hive_2012-08-28_19-05-17_531_4347419252405007581/-local-10002/jobconf.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
    [junit] 2012-08-28 19:05:20,680 WARN  [main] conf.Configuration (Configuration.java:loadProperty(1621)) - file:/tmp/cloudera/hive_2012-08-28_19-05-17_531_4347419252405007581/-local-10002/jobconf.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
    [junit] 2]3>)
    [junit] Tests run: 1, Failures: 1, Errors: 0, Time elapsed: 42.318 sec


And the details in: ./build/builtins/TEST-org.apache.hive.pdk.PluginTest.txt

Testsuite: org.apache.hive.pdk.PluginTest
Tests run: 1, Failures: 1, Errors: 0, Time elapsed: 42.318 sec
------------- Standard Error -----------------
GLOBAL SETUP:  Copying file: file:/home/cloudera/Code/hive2/builtins/test/onerow.txt
Deleted /home/cloudera/Code/hive2/build/builtins/warehouse/onerow
Copying file: file:/home/cloudera/Code/hive2/builtins/test/iris.txt
Deleted /home/cloudera/Code/hive2/build/builtins/warehouse/iris
org.apache.hive.builtins.UDAFUnionMap TEARDOWN:
Hive history file=/tmp/cloudera/hive_job_log_cloudera_201208281905_427044653.txt
GLOBAL TEARDOWN:
Hive history file=/tmp/cloudera/hive_job_log_cloudera_201208281905_95794698.txt
OK
Time taken: 6.585 seconds
OK
Time taken: 0.415 seconds
------------- ---------------- ---------------

Testcase: SELECT size(UNION_MAP(MAP(sepal_width, sepal_length))) FROM iris took 9.435 sec
    FAILED
expected:<2[]3> but was:<2[012-08-28 19:05:20,464 WARN  [main] conf.HiveConf (HiveConf.java:<clinit>(75)) - hive-site.xml not found on CLASSPATH
2012-08-28 19:05:20,679 WARN  [main] conf.Configuration (Configuration.java:loadProperty(1621)) - file:/tmp/cloudera/hive_2012-08-28_19-05-17_531_4347419252405007581/-local-10002/jobconf.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
2012-08-28 19:05:20,680 WARN  [main] conf.Configuration (Configuration.java:loadProperty(1621)) - file:/tmp/cloudera/hive_2012-08-28_19-05-17_531_4347419252405007581/-local-10002/jobconf.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
2]3>
junit.framework.ComparisonFailure: expected:<2[]3> but was:<2[012-08-28 19:05:20,464 WARN  [main] conf.HiveConf (HiveConf.java:<clinit>(75)) - hive-site.xml not found on CLASSPATH
2012-08-28 19:05:20,679 WARN  [main] conf.Configuration (Configuration.java:loadProperty(1621)) - file:/tmp/cloudera/hive_2012-08-28_19-05-17_531_4347419252405007581/-local-10002/jobconf.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
2012-08-28 19:05:20,680 WARN  [main] conf.Configuration (Configuration.java:loadProperty(1621)) - file:/tmp/cloudera/hive_2012-08-28_19-05-17_531_4347419252405007581/-local-10002/jobconf.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
2]3>
    at org.apache.hive.pdk.PluginTest.runTest(PluginTest.java:59)
    at junit.extensions.TestDecorator.basicRun(TestDecorator.java:24)
    at junit.extensions.TestSetup$1.protect(TestSetup.java:23)
    at junit.extensions.TestSetup.run(TestSetup.java:27)
    at junit.extensions.TestDecorator.basicRun(TestDecorator.java:24)
    at junit.extensions.TestSetup$1.protect(TestSetup.java:23)
    at junit.extensions.TestSetup.run(TestSetup.java:27)

This warning is printed to console, since it happens before hive configure its log4j(which happens in HiveConf.java static initialization), and hadoop's default log4j configuration is INFA,console. This does not happen on previous branches, since on hadoop0.23, there are code execution path change, and these warnings just appeared when running hive on hadoop0.23.

My proposed solution is to configure hadoop log4j, so that its warning message are printed to the log file, instead of printing on the console, log4j.properties file is added, which configure hadoop log4j to be DEBUG,DRFA.

A new log4j.properties file is added, not using hive-log4j.properties, because:

##1 this is for hadoop log4j configuration, not for hive log4j configuration(which configuration file named hive-log4j.properties), it might be possible for us to have different configuration for each

##2 hadoop defaults to find the configuration named log4j.properties(there is no such named file existed in hive configuration data)

I still take log file named hive.log, not hadoop.log, since these warning info are actually from running hive.

To make the pdk test running OK, without a full hive installation, I put the new log4j.properties file in pdk test directory.
, review request submitted at:
https://reviews.facebook.net/D5001, A quick note, to build hive on hadoop23:
$ant very-clean package.-Dhadoop.version=0.23.1 -Dhadoop-0.23.version=0.23.1 -Dhadoop.mr.rev=23

And run test:
$ant test -Dhadoop.version=0.23.1.-Dhadoop-0.23.version=0.23.1 -Dhadoop.mr.rev=23, @Zhenxiao: Please see my comments on phabricator., There is an error in my Jira ticket comment, actually, not necessary to put these dependencies in compile->default

pdk/scripts/build-plugin.xml has the following line(line 125):
  <fileset dir="${build.ivy.lib.dir}/test" includes="*.jar" excludes="hive*.jar"/>

which makes the build/ivy/lib/test directory also included in its test running classpath.
As Carl pointed, putting the dependency in compile->default will break 0.20 build. It should be put into hadoop0.23.test

@Carl: my updated patch is submitted at:
https://reviews.facebook.net/D5001
, the missing hadoop-minicluster dependency should not go into ql/ivy.xml.
It should be in hadoop23.test, putting into build/ivy/lib/test
pdk plugin test is triggered via builtin/build.xml
add the dependency in builtin/ivy.xml, and also update builtin/build.xml,
so that ivy-retrieve-test dependency is added to target test

Updated patch submitted for review at:
https://reviews.facebook.net/D5001, +1. Will commit if tests pass., Committed to trunk. Thanks Zhenxiao!, Integrated in Hive-trunk-h0.21 #1645 (See [https://builds.apache.org/job/Hive-trunk-h0.21/1645/])
    HIVE-3413. Fix pdk.PluginTest on hadoop23 (Zhenxiao Luo via cws) (Revision 1380478)

     Result = FAILURE
cws : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1380478
Files : 
* /hive/trunk/builtins/build.xml
* /hive/trunk/builtins/ivy.xml
* /hive/trunk/pdk/scripts/build-plugin.xml
* /hive/trunk/pdk/test-plugin/test/conf
* /hive/trunk/pdk/test-plugin/test/conf/log4j.properties
, Integrated in Hive-trunk-hadoop2 #54 (See [https://builds.apache.org/job/Hive-trunk-hadoop2/54/])
    HIVE-3413. Fix pdk.PluginTest on hadoop23 (Zhenxiao Luo via cws) (Revision 1380478)

     Result = ABORTED
cws : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1380478
Files : 
* /hive/trunk/builtins/build.xml
* /hive/trunk/builtins/ivy.xml
* /hive/trunk/pdk/scripts/build-plugin.xml
* /hive/trunk/pdk/test-plugin/test/conf
* /hive/trunk/pdk/test-plugin/test/conf/log4j.properties
, This issue is fixed and released as part of 0.10.0 release. If you find an issue which seems to be related to this one, please create a new jira and link this one with new jira.]