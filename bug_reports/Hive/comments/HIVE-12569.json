[Actually we do like to get this fixed in 2.0., [~lirui], [~chengxiang li], any idea what causes this and how to fix? We didn't seem to have the problem previously. I saw some discussion on the web, but it seems related but not completely applicable. http://stackoverflow.com/questions/30828879/application-report-for-application-state-accepted-never-ends-for-spark-submit. Also, https://github.com/bigdatagenomics/adam/issues/561, I noticed this log, too.
And here is my finds:
The log messages come from a spark class org.apache.spark.deploy.yarn.Client.scala
{code}
 logInfo(s"Application report for $appId (state: $state)")
{code}
And printed out by a Redirector in Hive's SparkClientImpl.java.
{code}
   while ((line = in.readLine()) != null) {
      LOG.info(line);
   }
{code}
The direct way to fix it is only logging message when state changing (Need to change spark code).
And another way is to add a log4j.properties file to spark-submit's class path,changing org.apache.spark.deploy.yarn.Client.scala's log level to WARN.
May be there are other solutions.
, Thanks, [~nemon].

[~vanzin], any insight here? Thanks., As [~nemon] analyzed, the message comes from Spark side, it should be spark get stuck in {{org.apache.spark.deploy.yarn.Client::monitorApplication}} as it never get end state. Looks like a spark issue., Actually, it's not a exactly issue, although the spark job finished, the spark application indeed still alive, so the reported state is right, we just do not want to print it on CLI console. change the log level should be the simplest solution., I also hit the issue before. Changing log4j conf to make the logs go to RFA instead of console fixed my problem., You can set {{spark.yarn.report.interval}} to a really large number (default is 1000)., This is a blocker with no real activity for a while. Is this really a blocker?, I have just downgraded it., Removing 2.0 from target versions as RC0 has been cut. Please -1 the RC, reinstate the version and make this a blocker if that is not acceptable :)]