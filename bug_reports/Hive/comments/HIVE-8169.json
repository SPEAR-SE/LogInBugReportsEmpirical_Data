[Steps to reproduce the issue:
{noformat}
drop table if exists hcat_altertable_16;
create table hcat_altertable_16(a int, b string) stored as textfile;
show table extended like  hcat_altertable_16;
alter table hcat_altertable_16 set location 'hdfs:///tmp/table_has_moved/';
show table extended like  hcat_altertable_16;
{noformat}

Stack trace:
{noformat}
org.apache.hadoop.hive.ql.parse.SemanticException: org.apache.hadoop.hive.ql.parse.SemanticException: java.lang.NullPointerException
	at org.apache.hive.hcatalog.cli.SemanticAnalysis.HCatSemanticAnalyzer.postAnalyze(HCatSemanticAnalyzer.java:264)
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:406)
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:299)
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:993)
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1063)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:930)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:920)
	at org.apache.hive.hcatalog.cli.HCatDriver.run(HCatDriver.java:43)
	at org.apache.hive.hcatalog.cli.HCatCli.processCmd(HCatCli.java:291)
	at org.apache.hive.hcatalog.cli.HCatCli.processLine(HCatCli.java:245)
	at org.apache.hive.hcatalog.cli.HCatCli.processFile(HCatCli.java:264)
	at org.apache.hive.hcatalog.cli.HCatCli.main(HCatCli.java:188)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.util.RunJar.run(RunJar.java:221)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:136)
Caused by: org.apache.hadoop.hive.ql.parse.SemanticException: java.lang.NullPointerException
	at org.apache.hive.hcatalog.cli.SemanticAnalysis.HCatSemanticAnalyzerBase.authorizeDDL(HCatSemanticAnalyzerBase.java:114)
	at org.apache.hive.hcatalog.cli.SemanticAnalysis.HCatSemanticAnalyzer.postAnalyze(HCatSemanticAnalyzer.java:259)
	... 17 more
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hive.ql.security.authorization.StorageBasedAuthorizationProvider.authorize(StorageBasedAuthorizationProvider.java:178)
	at org.apache.hive.hcatalog.cli.SemanticAnalysis.HCatSemanticAnalyzerBase.authorize(HCatSemanticAnalyzerBase.java:161)
	at org.apache.hive.hcatalog.cli.SemanticAnalysis.HCatSemanticAnalyzer.authorizeDDLWork(HCatSemanticAnalyzer.java:381)
	at org.apache.hive.hcatalog.cli.SemanticAnalysis.HCatSemanticAnalyzerBase.authorizeDDL(HCatSemanticAnalyzerBase.java:105)
	... 18 more
{noformat}, Save the above query as HIVE-8169.hql, run it by >python $HIVE_HOME/hcatalog/bin/hcat.py -f HIVE-8169.hql, it pops up exception like:
{noformat}
FAILED: SemanticException org.apache.hadoop.hive.ql.parse.SemanticException: java.lang.NullPointerException
{noformat}, Investigated and found issue comes from line 362 of org.apache.hive.hcatalog.cli.SemanticAnalysis.HCatSemanticAnalyzer. In function authorizeDDLWork, hive.getTable tries to use default and default.hcat_altertable_16 are used as dbname and tablename to query table metadata, eventually, default.default.hcat_altertable_16 is the full table name used for query, causing failure like NoSuchObjectException which is cast to NullPointerException in upstream path.
, Made a patch for review., Change looks fine.  Is there a way to add a unit test for this?, Thanks [~alangates]. There already exist unit test and system test, somehow, just failed in this case., Do you mean it failed to catch this case?  If so, it isn't testing this. , 

{color:red}Overall{color}: -1 at least one tests failed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12669559/HIVE-8169.1.patch

{color:red}ERROR:{color} -1 due to 1 failed/errored test(s), 6290 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.ql.parse.TestParse.testParse_union
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/862/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/862/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-862/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 1 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12669559, Made the 2nd patch by adding unit tests.
[~alangates] can you please review it? Thanks!, 

{color:red}Overall{color}: -1 at least one tests failed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12670859/HIVE-8169.2.patch

{color:red}ERROR:{color} -1 due to 3 failed/errored test(s), 6344 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_tez_union_group_by
org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_schemeAuthority
org.apache.hadoop.hive.ql.parse.TestParse.testParse_union
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/963/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/963/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-963/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 3 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12670859, +1, [~vikram.dixit], I'd like to commit this to 0.14 as it causes an NPE, Patch committed to 0.14 branch and trunk.  Thank's Xiaobing for the patch., This has been fixed in 0.14 release. Please open new jira if you see any issues.
]