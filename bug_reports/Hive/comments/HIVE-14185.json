[[~fmantlik]: because IN doesn't work the way you want.

col2 IN (null, 'A') looks like (col2 == null or col2 == 'A')

nothing is equal to null, even null itself, so it folds into (col2 == 'A'), which implicitly does 'IS NOT NULL' internally. 

If your goal is to look for nulls, equality is the wrong expression - for example, you can filter nulls out by doing col2 == col2, which works like "IS NOT NULL"., Gopal V, Thank you for explanation, but it is not the matter of the issue. The problem is that if you run the first query, you get the following exception if hive.auto.convert.join=false:
{noformat}
Error: java.io.IOException: java.lang.reflect.InvocationTargetException
 at org.apache.hadoop.hive.io.HiveIOExceptionHandlerChain.handleRecordReaderCreationException(HiveIOExceptionHandlerChain.java:97)
 at org.apache.hadoop.hive.io.HiveIOExceptionHandlerUtil.handleRecordReaderCreationException(HiveIOExceptionHandlerUtil.java:57)
 at org.apache.hadoop.hive.shims.HadoopShimsSecure$CombineFileRecordReader.initNextRecordReader(HadoopShimsSecure.java:266)
 at org.apache.hadoop.hive.shims.HadoopShimsSecure$CombineFileRecordReader.<init>(HadoopShimsSecure.java:213)
 at org.apache.hadoop.hive.shims.HadoopShimsSecure$CombineFileInputFormatShim.getRecordReader(HadoopShimsSecure.java:333)
 at org.apache.hadoop.hive.ql.io.CombineHiveInputFormat.getRecordReader(CombineHiveInputFormat.java:719)
 at org.apache.hadoop.mapred.MapTask$TrackedRecordReader.<init>(MapTask.java:169)
 at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:432)
 at org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)
 at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
 at java.security.AccessController.doPrivileged(Native Method)
 at javax.security.auth.Subject.doAs(Subject.java:422)
 at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)
 at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
 Caused by: java.lang.reflect.InvocationTargetException
 at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
 at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
 at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
 at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
 at org.apache.hadoop.hive.shims.HadoopShimsSecure$CombineFileRecordReader.initNextRecordReader(HadoopShimsSecure.java:252)
 ... 11 more
 Caused by: java.lang.NullPointerException
 at org.apache.hadoop.hive.ql.io.sarg.SearchArgumentImpl$ExpressionBuilder.boxLiteral(SearchArgumentImpl.java:446)
 at org.apache.hadoop.hive.ql.io.sarg.SearchArgumentImpl$ExpressionBuilder.getLiteralList(SearchArgumentImpl.java:489)
 at org.apache.hadoop.hive.ql.io.sarg.SearchArgumentImpl$ExpressionBuilder.createLeaf(SearchArgumentImpl.java:518)
 at org.apache.hadoop.hive.ql.io.sarg.SearchArgumentImpl$ExpressionBuilder.parse(SearchArgumentImpl.java:648)
 at org.apache.hadoop.hive.ql.io.sarg.SearchArgumentImpl$ExpressionBuilder.addChildren(SearchArgumentImpl.java:598)
 at org.apache.hadoop.hive.ql.io.sarg.SearchArgumentImpl$ExpressionBuilder.parse(SearchArgumentImpl.java:624)
 at org.apache.hadoop.hive.ql.io.sarg.SearchArgumentImpl$ExpressionBuilder.expression(SearchArgumentImpl.java:916)
 at org.apache.hadoop.hive.ql.io.sarg.SearchArgumentImpl.<init>(SearchArgumentImpl.java:953)
 at org.apache.hadoop.hive.ql.io.sarg.SearchArgumentFactory.create(SearchArgumentFactory.java:36)
 at org.apache.hadoop.hive.ql.io.sarg.SearchArgumentFactory.createFromConf(SearchArgumentFactory.java:50)
 at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat.setSearchArgument(OrcInputFormat.java:312)
 at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat.createReaderFromFile(OrcInputFormat.java:229)
 at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat$OrcRecordReader.<init>(OrcInputFormat.java:163)
 at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat.getRecordReader(OrcInputFormat.java:1104)
 at org.apache.hadoop.hive.ql.io.CombineHiveRecordReader.<init>(CombineHiveRecordReader.java:67)
 ... 16 more
{noformat}
All map attempts fail with the same exception.
If hive.auto.convert.join=true, the message below is returned:
{noformat}
Execution failed with exit status: 2
 Obtaining error information

Task failed!
 Task ID:
 Stage-4

Logs:

/tmp/fmantli/hive.log
 FAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.mr.MapredLocalTask
{noformat}
 The hive.log contains the following:
{noformat}
2016-07-08 09:33:03,526 ERROR 
[main]
: hdfs.KeyProviderCache (KeyProviderCache.java:createKeyProviderURI(87)) - Could not find uri with key 
[dfs.encryption.key.provider.uri]
to create a keyProvider !!
 2016-07-08 09:33:10,589 ERROR 
[main]
: exec.Task (SessionState.java:printError(960)) - Execution failed with exit status: 2
 2016-07-08 09:33:10,590 ERROR 
[main]
: exec.Task (SessionState.java:printError(960)) - Obtaining error information
 2016-07-08 09:33:10,590 ERROR 
[main]
: exec.Task (SessionState.java:printError(960)) -
 Task failed!
 Task ID:
 Stage-4

Logs:

2016-07-08 09:33:10,590 ERROR 
[main]
: exec.Task (SessionState.java:printError(960)) - /tmp/fmantli/hive.log
 2016-07-08 09:33:10,591 ERROR 
[main]
: mr.MapredLocalTask (MapredLocalTask.java:executeInChildVM(306)) - Execution failed with exit status: 2
 2016-07-08 09:33:10,593 ERROR 
[main]
: ql.Driver (SessionState.java:printError(960)) - FAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.mr.MapredLocalTask
{noformat}

This happens only if the left table is empty. In other cases, the query does not fail and returns empty or non-empty results depending on the data. This should be fixed and empty result should be returned instead of the failure.
]