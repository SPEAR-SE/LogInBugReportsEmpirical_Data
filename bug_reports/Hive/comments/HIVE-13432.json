[Can someone confirm that this is related to issue of https://issues.apache.org/jira/browse/HIVE-11981?

Thanks., I ported a number of commits from master to branch-2.0, including:

HIVE-12894 Detect whether ORC is reading from ACID table correctly for Schema Evolution (Matt McCline, reviewed by Prasanth J and Eugene Koifman)

which may fix this issue., I will build hive 2.1/2.0.1 and let you know to see if it works. Many thanks., Hi Matt, 

I build hive from hive git branch 2.0 and see patch of 12984, I try compaction again on the same ACID table but still see the same error,

, kind: TIMESTAMP
, kind: INT
] innerStructSubtype -1
  at org.apache.hadoop.hive.ql.io.orc.TreeReaderFactory$StructTreeReader.<init>(TreeReaderFactory.java:2092)
  at org.apache.hadoop.hive.ql.io.orc.TreeReaderFactory.createTreeReader(TreeReaderFactory.java:2518)
  at org.apache.hadoop.hive.ql.io.orc.TreeReaderFactory$StructTreeReader.<init>(TreeReaderFactory.java:2098)
  at org.apache.hadoop.hive.ql.io.orc.TreeReaderFactory.createTreeReader(TreeReaderFactory.java:2518)
  at org.apache.hadoop.hive.ql.io.orc.RecordReaderImpl.<init>(RecordReaderImpl.java:210)
  at org.apache.hadoop.hive.ql.io.orc.ReaderImpl.rowsOptions(ReaderImpl.java:662)
  at org.apache.hadoop.hive.ql.io.orc.OrcRawRecordMerger$ReaderPair.<init>(OrcRawRecordMerger.java:212)
  at org.apache.hadoop.hive.ql.io.orc.OrcRawRecordMerger.<init>(OrcRawRecordMerger.java:512)
  at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat.getRawReader(OrcInputFormat.java:1870)
  at org.apache.hadoop.hive.ql.txn.compactor.CompactorMR$CompactorMap.map(CompactorMR.java:575)
  at org.apache.hadoop.hive.ql.txn.compactor.CompactorMR$CompactorMap.map(CompactorMR.java:554)
  at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
  at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:450)
  at org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)
  at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:163)
  at java.security.AccessController.doPrivileged(Native Method)
  at javax.security.auth.Subject.doAs(Subject.java:415)
  at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1656)
  at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)

16/04/11 11:54:21 INFO mapreduce.Job:  map 100% reduce 0%
16/04/11 11:54:21 INFO mapreduce.Job: Job job_1458819387386_23797 failed with state FAILED due to: Task failed task_1458819387386_23797_m_000001
Job failed as tasks failed. failedMaps:1 failedReduces:0

16/04/11 11:54:21 INFO mapreduce.Job: Counters: 14
  Job Counters 
    Failed map tasks=9
    Killed map tasks=9
    Launched map tasks=18
    Other local map tasks=8
    Data-local map tasks=4
    Rack-local map tasks=6
    Total time spent by all maps in occupied slots (ms)=405068
    Total time spent by all reduces in occupied slots (ms)=0
    Total time spent by all map tasks (ms)=202534
    Total vcore-seconds taken by all map tasks=202534
    Total megabyte-seconds taken by all map tasks=414789632
  Map-Reduce Framework
    CPU time spent (ms)=0
    Physical memory (bytes) snapshot=0
    Virtual memory (bytes) snapshot=0
16/04/11 11:54:21 ERROR compactor.Worker: Caught exception while trying to compact id:80,dbname:lqz,tableName:my_acid_orc_table,partName:null,state:,type:MAJOR,runAs:null,tooManyAborts:false,highestTxnId:0.  Marking clean to avoid repeated failures, java.io.IOException: Job failed!
  at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:836)
  at org.apache.hadoop.hive.ql.txn.compactor.CompactorMR.launchCompactionJob(CompactorMR.java:247)
  at org.apache.hadoop.hive.ql.txn.compactor.CompactorMR.run(CompactorMR.java:213)
  at org.apache.hadoop.hive.ql.txn.compactor.Worker.run(Worker.java:164)

16/04/11 11:54:34 INFO txn.AcidCompactionHistoryService: History reaper reaper ran for 0seconds.  isAliveCounter=-2147483642

Please let me know if you need more info for this issue. 

Regards,
Qiuzhuang, For more info, I also see the regression to the ACID feature for delete statement,

16/04/11 12:38:43 WARN shims.HadoopShimsSecure: Can't fetch tasklog: TaskLogServlet is not supported in MR2 mode.

Task with the most failures(4): 
-----
Task ID:
  task_1458819387386_23814_r_000003

URL:
  http://nn209003:8088/taskdetails.jsp?jobid=job_1458819387386_23814&tipid=task_1458819387386_23814_r_000003
-----
Diagnostic Messages for this Task:
Error: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row (tag=0) {"key":{"reducesinkkey0":{"transactionid":0,"bucketid":43,"rowid":0}},"value":null}
	at org.apache.hadoop.hive.ql.exec.mr.ExecReducer.reduce(ExecReducer.java:257)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:444)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:163)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1656)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row (tag=0) {"key":{"reducesinkkey0":{"transactionid":0,"bucketid":43,"rowid":0}},"value":null}
	at org.apache.hadoop.hive.ql.exec.mr.ExecReducer.reduce(ExecReducer.java:245)
	... 7 more
Caused by: java.lang.ArrayIndexOutOfBoundsException: 1
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.process(FileSinkOperator.java:759)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:837)
	at org.apache.hadoop.hive.ql.exec.SelectOperator.process(SelectOperator.java:97)
	at org.apache.hadoop.hive.ql.exec.mr.ExecReducer.reduce(ExecReducer.java:236)
	... 7 more


16/04/11 12:38:43 ERROR exec.Task: 
Task with the most failures(4): 
-----
Task ID:
  task_1458819387386_23814_r_000003

URL:
  http://nn209003:8088/taskdetails.jsp?jobid=job_1458819387386_23814&tipid=task_1458819387386_23814_r_000003
-----
Diagnostic Messages for this Task:
Error: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row (tag=0) {"key":{"reducesinkkey0":{"transactionid":0,"bucketid":43,"rowid":0}},"value":null}
	at org.apache.hadoop.hive.ql.exec.mr.ExecReducer.reduce(ExecReducer.java:257)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:444)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:163)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1656)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row (tag=0) {"key":{"reducesinkkey0":{"transactionid":0,"bucketid":43,"rowid":0}},"value":null}
	at org.apache.hadoop.hive.ql.exec.mr.ExecReducer.reduce(ExecReducer.java:245)
	... 7 more
Caused by: java.lang.ArrayIndexOutOfBoundsException: 1
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.process(FileSinkOperator.java:759)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:837)
	at org.apache.hadoop.hive.ql.exec.SelectOperator.process(SelectOperator.java:97)
	at org.apache.hadoop.hive.ql.exec.mr.ExecReducer.reduce(ExecReducer.java:236), Hi Matt,

Since we are blocked by this issue, can you please help take a look at this?

Many thanks., In order to help, I need a repro.

I need a *small self-contained test case*.  DLL for test input files, small amount of data, and the queries to run.  In particular, if any schema changes like adding a column would be critical.  The stack traces provided are insufficient for me to make progress.

The ACID code has undergone a huge amount of change in the last year.  Also, there has been a lot of change for Schema Evolution.

There is a new Hive-2 branch (branch-2.1) being readied.  RC0 as created and a new RC1 is in progress.  It has very recent ACID and Schema Evolution changes.

, We might have a clue of what is causing this problem.

We have one test case where "minor" compaction fails when hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat but succeeds when that environment variable is org.apache.hadoop.hive.ql.io.HiveInputFormat, Sorry for delay response. Yes, our hive-site.xml uses CombineHiveInputFormat. I should have sent you our hive-site.xml. Please check the attached to see if any more clue., At the moment, the repro seems to involve deletions and minor compact.  Investigating., HIVE-13974

(ACID Delete Events have slight different schema than other ACID records), I remove this configuration when running compactorMR job and it looks ok now. BTW, is this CombineHiveInputFormat issue related to the recent fix of HIVE-13968?]