[We probably need to make a shim here.
{quote}
java.lang.NoSuchMethodError: org.apache.hadoop.mapred.lib.TotalOrderPartitioner.setPartitionFile(Lorg/apache/hadoop/mapred/JobConf;Lorg/apache/hadoop/fs/Path;)V
at org.apache.hadoop.hive.ql.exec.mr.ExecDriver.handleSampling(ExecDriver.java:557)
at org.apache.hadoop.hive.ql.exec.mr.ExecDriver.execute(ExecDriver.java:438)
at org.apache.hadoop.hive.ql.exec.mr.MapRedTask.execute(MapRedTask.java:140)
at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:150)
at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:65)
at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1423)
at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1203)
at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1008)
at org.apache.hadoop.hive.ql.Driver.run(Driver.java:880)
at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:259)
at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:216)
at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:413)
at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:348)
at org.apache.hadoop.hive.ql.QTestUtil.executeClient(QTestUtil.java:790)
at org.apache.hadoop.hive.cli.TestMinimrCliDriver.runTest(TestMinimrCliDriver.java:264)
at org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_parallel_orderby(TestMinimrCliDriver.java:224)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
at java.lang.reflect.Method.invoke(Method.java:597)
at junit.framework.TestCase.runTest(TestCase.java:168)
at junit.framework.TestCase.runBare(TestCase.java:134)
at junit.framework.TestResult$1.protect(TestResult.java:110)
at junit.framework.TestResult.runProtected(TestResult.java:128)
at junit.framework.TestResult.run(TestResult.java:113)
at junit.framework.TestCase.run(TestCase.java:124)
at junit.framework.TestSuite.runTest(TestSuite.java:243)
at junit.framework.TestSuite.run(TestSuite.java:238)
at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.run(JUnitTestRunner.java:518)
at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.launch(JUnitTestRunner.java:1052)
at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:906)
junit.framework.AssertionFailedError: Client Execution failed with error code = -101
{quote}, The API is the same between branches:

* [hadoop 1|https://github.com/apache/hadoop-common/blob/branch-1.1/src/mapred/org/apache/hadoop/mapred/lib/TotalOrderPartitioner.java#L106]
* [hadoop 2|https://github.com/apache/hadoop-common/blob/branch-2.0.5-alpha/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/lib/partition/TotalOrderPartitioner.java#L135]

but in hadoop 1 mapred.lib.TotalOrderPartitioner contains the method whereas in hadoop 2 it delegates to mapreduce.lib.partition.TotalOrderPartitioner.  Therefore it makes me wonder if our classpath is wrong when compiling or perhaps if a clean is not being invoked?, Interestingly the hadoop 2 ptests don't have this failure:

* https://builds.apache.org/job/Hive-trunk-hadoop2-ptest/14/#showFailuresLink
* https://builds.apache.org/job/Hive-trunk-hadoop2-ptest/15/#showFailuresLink, Whoops, that is because they are not be executed in the ptest builds. I've enabled this test and will run the ptest on hadoop2 overnight., parallel_orderby passed via the parallely unit tests last night:

https://builds.apache.org/job/Hive-trunk-hadoop2-ptest/16/testReport/org.apache.hadoop.hive.cli/TestMinimrCliDriver/
, Something about it must not be deterministic. The exception above is one of those things that will happen every time unless something is causing a code path to get skipped., The following commands end with the error above:
{noformat}
$ ant clean tar binary
$ ant test -Dhadoop.mr.rev=23 -Dtestcase=TestMinimrCliDriver -Dminimr.query.files=parallel_orderby.q
{noformat}

These do not:
{noformat}
$ ant clean tar binary -Dhadoop.mr.rev=23
$ ant test -Dhadoop.mr.rev=23 -Dtestcase=TestMinimrCliDriver -Dminimr.query.files=parallel_orderby.q
{noformat}

This follows what we are seeing with the builds, this test fails on the normal hadoop2 build while it passes on the ptest hadoop2 build. The normal build does not specify -Dhadoop.mr.rev=23 when building (only when executing tests) while the ptest build specifies -Dhadoop.mr.rev=23 when building and testing.

I believe this makes sense because the change is a JVM level interface change. I've add -Dhadoop.mr.rev=23 to the build section of the hadoop2 build and we'll see what happens after the next build., parallel orderby is passing after the build change: https://builds.apache.org/user/brock/my-views/view/hive/job/Hive-trunk-hadoop2-ptest/lastCompletedBuild/testReport/org.apache.hadoop.hive.cli/TestMinimrCliDriver/testCliDriver_parallel_orderby/, Compiling source with -Dhadoop.mr.rev=23 is not an acceptable solution, since that means we need to generate two different binaries for 20S and 23. Till now single hive binary works for both 20S and 23 and we need to keep it that way. We need to shim this method appropriately., Gotcha. I've removed the -Dhadoop.mr.rev=23 from the hadoop2 build and will create a shim for this., I have attached a patch. I think the issue is the method:

{code}
 TotalOrderPartitioner.setPartitionFile(jobConf, partitionFile);
{code}

The signature changes from JobConf to Conf. Even though JobConf is a child of Conf, the method found at compile time is different then that of the method at runtime. , 

{color:red}Overall{color}: -1 at least one tests failed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12596266/HIVE-4863.1.patch.txt

{color:red}ERROR:{color} -1 due to 1 failed/errored test(s), 2763 tests executed
*Failed tests:*
{noformat}
org.apache.hcatalog.pig.TestHCatLoaderComplexSchema.testSyntheticComplexSchema
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/319/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/319/console

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests failed with: TestsFailedException: 1 tests failed
{noformat}

This message is automatically generated., [~appodictic] I think you can drop the second parameter to the shim method (the Configuration). The shim should do be able to do the exact same call in both cases - the important thing is that we compile it separately against 20S and hadoop 23. Also, in the 23 version you're setting the file on HiveConf not JobConf which I don't think will work, will it?, So the case is this in 0.20

 TotalOrderPartitioner.setPartitionFile(JobConf, partitionFile);

in 0.23
  TotalOrderPartitioner.setPartitionFile(Configuration, partitionFile);

JobConf is a child of Configuration

{quote}
 Also, in the 23 version you're setting the file on HiveConf not JobConf which I don't think will work, will it?
{quote}
^ I think this will not matter since as long as the conf can find hdfs we should be ready do add the file.


{quote}
The shim should do be able to do the exact same call in both cases - the important thing is that we compile it separately against 20S and hadoop 23
{quote}
Good point. This shim stuff hurts my head :) I will rebase as you have suggested.


, 

{color:green}Overall{color}: +1 all checks pass

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12597249/HIVE-4863.2.patch.txt

{color:green}SUCCESS:{color} +1 2774 tests passed

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/380/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/380/console

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
{noformat}

This message is automatically generated., LGTM +1. Will run tests on hadoop 2 before commit., Tried on 20/20S/23 and looks good. Committed to trunk. Thanks Edward!, FAILURE: Integrated in Hive-trunk-hadoop2 #355 (See [https://builds.apache.org/job/Hive-trunk-hadoop2/355/])
HIVE-4863: Fix parallel order by on hadoop2 (Edward Capriolo via Gunther Hagleitner) (gunther: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1513351)
* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/mr/ExecDriver.java
* /hive/trunk/shims/src/0.20/java/org/apache/hadoop/hive/shims/Hadoop20Shims.java
* /hive/trunk/shims/src/0.20S/java/org/apache/hadoop/hive/shims/Hadoop20SShims.java
* /hive/trunk/shims/src/0.23/java/org/apache/hadoop/hive/shims/Hadoop23Shims.java
* /hive/trunk/shims/src/common/java/org/apache/hadoop/hive/shims/HadoopShims.java
, FAILURE: Integrated in Hive-trunk-h0.21 #2265 (See [https://builds.apache.org/job/Hive-trunk-h0.21/2265/])
HIVE-4863: Fix parallel order by on hadoop2 (Edward Capriolo via Gunther Hagleitner) (gunther: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1513351)
* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/mr/ExecDriver.java
* /hive/trunk/shims/src/0.20/java/org/apache/hadoop/hive/shims/Hadoop20Shims.java
* /hive/trunk/shims/src/0.20S/java/org/apache/hadoop/hive/shims/Hadoop20SShims.java
* /hive/trunk/shims/src/0.23/java/org/apache/hadoop/hive/shims/Hadoop23Shims.java
* /hive/trunk/shims/src/common/java/org/apache/hadoop/hive/shims/HadoopShims.java
, FAILURE: Integrated in Hive-trunk-hadoop2-ptest #56 (See [https://builds.apache.org/job/Hive-trunk-hadoop2-ptest/56/])
HIVE-4863: Fix parallel order by on hadoop2 (Edward Capriolo via Gunther Hagleitner) (gunther: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1513351)
* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/mr/ExecDriver.java
* /hive/trunk/shims/src/0.20/java/org/apache/hadoop/hive/shims/Hadoop20Shims.java
* /hive/trunk/shims/src/0.20S/java/org/apache/hadoop/hive/shims/Hadoop20SShims.java
* /hive/trunk/shims/src/0.23/java/org/apache/hadoop/hive/shims/Hadoop23Shims.java
* /hive/trunk/shims/src/common/java/org/apache/hadoop/hive/shims/HadoopShims.java
, FAILURE: Integrated in Hive-trunk-hadoop1-ptest #126 (See [https://builds.apache.org/job/Hive-trunk-hadoop1-ptest/126/])
HIVE-4863: Fix parallel order by on hadoop2 (Edward Capriolo via Gunther Hagleitner) (gunther: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1513351)
* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/mr/ExecDriver.java
* /hive/trunk/shims/src/0.20/java/org/apache/hadoop/hive/shims/Hadoop20Shims.java
* /hive/trunk/shims/src/0.20S/java/org/apache/hadoop/hive/shims/Hadoop20SShims.java
* /hive/trunk/shims/src/0.23/java/org/apache/hadoop/hive/shims/Hadoop23Shims.java
* /hive/trunk/shims/src/common/java/org/apache/hadoop/hive/shims/HadoopShims.java
, This was included in 0.12.0 so I have fixed the fixed version., This issue has been fixed and released as part of 0.12 release. If you find further issues, please create a new jira and link it to this one.]