[My results after some debug. NPE happens because {{inspector.getStructFieldRef(names[0]);}} returns {{null}} 

{code}
  @Override
  public ObjectInspector initialize(ObjectInspector rowInspector) throws HiveException {

    // We need to support field names like KEY.0, VALUE.1 between
    // map-reduce boundary.
    String[] names = expr.getColumn().split("\\.");
    String[] unionfields = names[0].split("\\:");
    if (names.length == 1 && unionfields.length == 1) {
      simpleCase = true;
      inspector = (StructObjectInspector) rowInspector;
      field = inspector.getStructFieldRef(names[0]);
      return outputOI = field.getFieldObjectInspector();
    }
{code}

in {{ExprNodeColumnEvaluator}}. Here {{names[0]}} == {{"ROW__ID"}}. Class {{OrcStruct}} contains method 


{code}
    @Override
    public StructField getStructFieldRef(String s) {
      for(StructField field: fields) {
        if (field.getFieldName().equalsIgnoreCase(s)) {
          return field;
        }
      }
      return null;
    }
{code}

and array {{fields}} is initialized with {{StructField}} for only four columns: {{id}}, {{first_name}}, {{last_name}}, {{age}}. So it returns {{null}} when {{s}} == {{"ROW__ID"}} . Hive wants no insert {{"ROW__ID"}} because it transforms {{MERGE}} into multiple {{INSERT}}:

{code}
FROM
  `default`.`customer_target` `trg`
  RIGHT OUTER JOIN
  `default`.`customer_source` `src`
  ON `src`.`id` = `trg`.`id`
INSERT INTO `default`.`customer_target`    -- update clause
 select `trg`.ROW__ID, `trg`.`id`, `src`.`first_name`, `src`.`last_name`, `trg`.`age`
   WHERE `src`.`id` = `trg`.`id`
 sort by `trg`.ROW__ID 
INSERT INTO `default`.`customer_target`    -- insert clause
  select `src`.`id`, `src`.`first_name`, `src`.`last_name`, `src`.`age`
   WHERE `trg`.`id` IS NULL
INSERT INTO merge_tmp_table
  SELECT cardinality_violation(`trg`.ROW__ID)
 WHERE `src`.`id` = `trg`.`id` GROUP BY `trg`.ROW__ID HAVING count(*) > 1		
{code}

 
, I tried to find out, was the problem in  {{MERGE}} statement or in multiple {{INSERT}}. Skipping cardinality check I have got after 

{code}
FROM
  `default`.`customer_target` `trg`
  RIGHT OUTER JOIN
  `default`.`customer_source` `src`
  ON `src`.`id` = `trg`.`id`
INSERT INTO `default`.`customer_target`    -- update clause
 select `trg`.ROW__ID, `trg`.`id`, `src`.`first_name`, `src`.`last_name`, `trg`.`age`
   WHERE `src`.`id` = `trg`.`id`
 sort by `trg`.ROW__ID 
INSERT INTO `default`.`customer_target`    -- insert clause
  select `src`.`id`, `src`.`first_name`, `src`.`last_name`, `src`.`age`
   WHERE `trg`.`id` IS NULL
{code}

this result

{code}
FAILED: NoMatchingMethodException No matching method for class org.apache.hadoop.hive.ql.udf.UDFToString with (struct<transactionid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(binary)  _FUNC_(boolean)  _FUNC_(date)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(int)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  
{code}

Then I added simple implementation into {{UDFToString}}:

{code}
  public Text evaluate(Object object){
    if (object == null){
      return null;
    }
    return new Text(object.toString());
  }
{code}

And I got this exception:

{code}
FAILED: SemanticException [Error 10087]: The same output cannot be present multiple times:  customer_target
{code}

Right the same exception I have obtained when removed {{ROW__ID}} from  multiple {{INSERT}} query:

{code}
FROM
  `default`.`customer_target` `trg`
  RIGHT OUTER JOIN
  `default`.`customer_source` `src`
  ON `src`.`id` = `trg`.`id`
INSERT INTO `default`.`customer_target`    -- update clause
 select  `trg`.`id`, `src`.`first_name`, `src`.`last_name`, `trg`.`age`
   WHERE `src`.`id` = `trg`.`id`
 sort by `trg`.id 
INSERT INTO `default`.`customer_target`    -- insert clause
  select `src`.`id`, `src`.`first_name`, `src`.`last_name`, `src`.`age`
   WHERE `trg`.`id` IS NULL
{code}

Looks like  multiple {{INSERT}} queries do not work for ORC on MR engine., PS : the above  multiple {{INSERT}} query  does not work even on {{TextInputFormat}} tables with the same error:

{code}
FAILED: SemanticException [Error 10087]: The same output cannot be present multiple times:  customer_target
{code}, This is optimization issue. Setting

{code}
set hive.auto.convert.join=false;
{code}

fixes the issue., it's odd that something is trying to call 
UDFToString on struct<transactionid:bigint,bucketid:int,rowid:bigint> (i.e. the ROW__ID)
The update/delete branches of the multi-insert should be caling UDFToInteger which does have special handling of ROW__ID]