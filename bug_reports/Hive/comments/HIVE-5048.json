[Note on reproduction, you'd hit this issue only if you have hive.security.authorization.enabled set to true, and hive.security.authorization.manager set to "org.apache.hadoop.hive.ql.security.authorization.StorageBasedAuthorizationProvider".

If anyone is experiencing this issue, the work around till this bug is fixed is one of the following :

a) If you would like to turn off the client-side authorization provider, set "hive.security.authorization.enabled" to false.
b) If you desire another client-side authorization instead, set "hive.security.authorization.manager" to something SBAP
c) If you want SBAP behaviour for your authorization, you can use this from the metastore-side, by setting "hive.security.metastore.authorization.manager" to "org.apache.hadoop.hive.ql.security.authorization.StorageBasedAuthorizationProvider" (sets HMAP as SBAP) and "hive.metastore.pre.event.listeners" to "org.apache.hadoop.hive.ql.security.AuthorizationPreEventListener" (turns on metastore-side auth)



, Attached patch to make sure that wh is instantiated whether called from the client side or the metastore side., I think your checks are masking underlying problem. IMO correct fix for this is that Warehouse should always be initialized. If it so happens that metastore is up and warehouse isn't, thats illegal state, doesn't matter if calls are made from client or server. This has been discussed before as well : https://issues.apache.org/jira/browse/HIVE-2079?focusedCommentId=13104063&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13104063, Ashutosh, I'm afraid I don't understand what problem I'm masking, the fix I add is doing exactly that - making sure a wh variable is always instantiated.

In the current form, SBAP is usable only from the metastore-side, and wasn't initially written to be initializable from the client-side. When initialized from the metastore, the setMetaStoreHandler call is called, and the wh variable is initialized from handler.getWh() and all is good.

This patch addresses the case where it is called from the client-side, in which case we do not have a wh object (which we were previously getting from the metastore) and so, with this patch, we initialize it.

I added the else{} block for the sake of completeness/documentation, but realistically, that can never/will never be entered. I can change the MetaException to an IllegalStateException to make that more strict, if that's what you mean., Replaced MetaException with IllegalStateException, which is a more accurate representation for a code block that should never be reached., I see what you mean. My comment on HIVE-2079 needs to be resolved too, but thats a different issue. +1 Can you upload in correct format and mark it Patch Available to get HIVE QA to run on it., Updating patch name from HIVE-5048.patch.2 to HIVE-5048.2.patch :), 

{color:red}Overall{color}: -1 at least one tests failed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12598266/HIVE-5048.2.patch

{color:red}ERROR:{color} -1 due to 1 failed/errored test(s), 2859 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_udtf_not_supported2
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/454/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/454/console

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests failed with: TestsFailedException: 1 tests failed
{noformat}

This message is automatically generated., Committed to trunk. Thanks, Sushanth!, FAILURE: Integrated in Hive-trunk-hadoop2 #364 (See [https://builds.apache.org/job/Hive-trunk-hadoop2/364/])
HIVE-5048 : StorageBasedAuthorization provider causes an NPE when asked to authorize from client side. (Sushanth Sowmyan via Ashutosh Chauhan) (hashutosh: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1514569)
* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/security/authorization/HiveAuthorizationProviderBase.java
* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/security/authorization/StorageBasedAuthorizationProvider.java
, FAILURE: Integrated in Hive-trunk-hadoop2-ptest #60 (See [https://builds.apache.org/job/Hive-trunk-hadoop2-ptest/60/])
HIVE-5048 : StorageBasedAuthorization provider causes an NPE when asked to authorize from client side. (Sushanth Sowmyan via Ashutosh Chauhan) (hashutosh: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1514569)
* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/security/authorization/HiveAuthorizationProviderBase.java
* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/security/authorization/StorageBasedAuthorizationProvider.java
, FAILURE: Integrated in Hive-trunk-hadoop1-ptest #129 (See [https://builds.apache.org/job/Hive-trunk-hadoop1-ptest/129/])
HIVE-5048 : StorageBasedAuthorization provider causes an NPE when asked to authorize from client side. (Sushanth Sowmyan via Ashutosh Chauhan) (hashutosh: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1514569)
* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/security/authorization/HiveAuthorizationProviderBase.java
* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/security/authorization/StorageBasedAuthorizationProvider.java
, FAILURE: Integrated in Hive-trunk-h0.21 #2272 (See [https://builds.apache.org/job/Hive-trunk-h0.21/2272/])
HIVE-5048 : StorageBasedAuthorization provider causes an NPE when asked to authorize from client side. (Sushanth Sowmyan via Ashutosh Chauhan) (hashutosh: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1514569)
* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/security/authorization/HiveAuthorizationProviderBase.java
* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/security/authorization/StorageBasedAuthorizationProvider.java
, This issue has been fixed and released as part of 0.12 release. If you find further issues, please create a new jira and link it to this one.]