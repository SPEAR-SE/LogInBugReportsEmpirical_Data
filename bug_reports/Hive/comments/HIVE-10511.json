[Assign this to Ferdinand as he has expressed his interest of working on this., This is what hive cli supported: https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Cli
Currently qtest framework is using clidriver to process command. I think the first step should be replacing it with beeline. I do believe we can resolve some compatibility issues after resolving all failed issues caused by the refactory. [~xuefuz], do you think we need to create a branch to do the replacing work? Thank you!
, [~Ferd], Please note that the document link is a little outdated in the sense that some of functionality has already removed such as accepting hostname and port, which is meant for HiveServer1. Therefore, we should focus whatever remains. The syntax of the command line might also has difference with Beeline, which needs to be identified.

As to a branch for this development, I think it makes sense. I will discuss in dev list and create it accordingly., I have an investigation for the hive cli. It can help us define the scope of this jira.
*Options*
HiveCli is supporting the following options(Detailed information is available in the class OptionsProcessor):
* database:
* execute quoted query string
* execute query file
* specify initial query file
* set hiveconf
* define variable
* set hivevar
* silent mode
* verbose
* help

By replacing the HIVE Cli, we need to implement all of the options one by one using beeline functionality.

*Iterative commands*
Belows are the commands used by HIVE Cli.
* quite& exit
* source
* +commands begin with !(execute shell command directly)+
* processLocalCommand (executed by CommandProcessor: dirver, addResourceProcessor, etc)

For commands beginning with ‘!’, it is treated as sql command other than shell command in beeline. Addressing this issue, we need add one configuration allowing user to choose command style in beeline or that in hivecli.

Others points including RCFileCat and completes, it should be supported by using beeline funcionality.
Any thoughts about it, [~xuefuz]?, bq. For commands beginning with ‘!’, it is treated as sql command other than shell command in beeline. Addressing this issue, we need add one configuration allowing user to choose command style in beeline or that in hivecli.

Maybe a syntax like that:
{code}
!cmd ls ~/
{code}, Yes, that's one option. I am wondering whether it will break the compatibility. , FYI: Beeline's syntax for executing a shell command is "sh ls /tmp". This is introduced quite some time back., Yeah. I think we need to introduce a mode in Beeline for compatibility with Hive CLI. We don't want to expose this mode to beeline users to avoid confusion. Thus, we may need a light wrapper code for Beeline in which we will turn on this mode.

To implement this mode in Beeline, we can inspect each input line and interpret it according to Hive CLI syntax., I agree, in trunk I found that this command already exists:
bq. !sh ls /tmp work, I must ask the question how has this been looked at from real world usage. Two companies I have worked for now will have major scalability issues with HiveServer2 and beeline. Specifically with large results that a user may return. Whats the mitigation plan so clusters don't end up with 50 HiveServer2's with 12GB heaps...

http://www.cloudera.com/documentation/enterprise/5-4-x/topics/cdh_ig_hiveserver2_configure.html

, [~gss2002]: Part 1 - https://issues.apache.org/jira/browse/HIVE-12427 & Part 2 - https://issues.apache.org/jira/browse/HIVE-14549 

The collaboration with SIMBA for the HDP ODBC driver ensures it gets the same wins as the open source JDBC one, so that Excel, Microstrategy and Tableau can see the gains.

The concerns for beeline are somewhat inherited from sqlline mostly related to formatting performance. The raw JDBC protocol is usually ~10x faster to transport data over 10GigE than beeline can print.

If this is a hard concern, I recommend commenting or interacting with those specific collaboration JIRAs., [~gopalv] out of curiosity the big issue is HS2 has always been a scalability issue. So the next question how do you plan on stopping folks on using sparkSQL cli as it goes directly at metastore and fs which we are using along with native mr / spark going directly at the fs system location of this data?, [~gss2002]: The big issue with HS2 was primarily with MapredLocalTask (if you're going by the Cloudera docs), which effectively burns down the CPU on the HS2 box and both uploads/downloads data to HDFS to run joins.

Currently, I'm doing ~100 concurrent queries per 16Gb  HS2 with LLAP (so, approx ~250-500 sessions per box on Tableau). And some part of it needs to improve, particularly when moving >10k rows per query.

bq. how do you plan on stopping folks on using sparkSQL cli as it goes directly at metastore and fs 

(off-topic)

Look, we're not in the business of stopping users from doing what they want - we're not going to go down that way.

However, some admins and business owners are. When dealing with some groups of users, the fact that a SQL user can't just "copy all this data to my laptop and sell it somewhere" is an advantage.

Current solutions (where filesystem is the only permission level) involve maintaining different copies of data to keep it safe with raw file permissions. Imagine GPS pickup/dropoff, billing address, CC # and real-name in a db - the pricing analysis guys need the first three, the billing folks need the last 3 etc. This is insanity when it comes to ETL scheduling and keeping all parts of the system in sync - so people who go down the "maintain different copies" path will be carrying a pager daily.

Not all of that data processing is SQL, at least not the geo-location or clustering, so in my view, Hive (as a system of record) needs to make sure Spark is not left out of the workflows., [~gopalv] thank you for further insight. I wish all Hadoop Vendors I talked with felt the same way. I know multiple vendors who feel Hive and HiveServer2 should be the ONLY access mechanism on top of Hadoop. I guess the approach we've been taking at my current and past employer is that tools like Voltage or Protegrity or Dataguise would be used to secure column level access using FPE. But I can see how some companies would not want to invest down that road. How is LLAP and doAS working is that going to work as things like Protegrity require jobs to run as the actual endUser. It cannot run as Hive and unfortunately I don't think this requirement will be changing any time soon.]