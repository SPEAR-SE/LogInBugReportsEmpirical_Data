[Stack trace:
{code}
Caused by: java.io.IOException: Trying to extend compressed block into uncompressed block start: 21912896 end: 22018801 cache buffer: 0x21e7053f(2)   at org.apache.hadoop.hive.ql.io.orc.encoded.EncodedReaderImpl.addOneCompressionBuffer(EncodedReaderImpl.java:1452)   at org.apache.hadoop.hive.ql.io.orc.encoded.EncodedReaderImpl.prepareRangesForCompressedRead(EncodedReaderImpl.java:897)   at org.apache.hadoop.hive.ql.io.orc.encoded.EncodedReaderImpl.readEncodedStream(EncodedReaderImpl.java:769)   at org.apache.hadoop.hive.ql.io.orc.encoded.EncodedReaderImpl.readEncodedColumns(EncodedReaderImpl.java:485)   at org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader.performDataRead(OrcEncodedDataReader.java:425)   at org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader$4.run(OrcEncodedDataReader.java:247)   at org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader$4.run(OrcEncodedDataReader.java:244)   at java.security.AccessController.doPrivileged(Native Method)   at javax.security.auth.Subject.doAs(Subject.java:422)   at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1866)   at org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader.callInternal(OrcEncodedDataReader.java:244)   at org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader.callInternal(OrcEncodedDataReader.java:94)
{code}

cc: [~sershe], There's trace dump in the logs which shows a cache buffer that doesn't match the file being read in the cache results. The processing in the trace itself was correct.. trying to figure out how this can happen., Looks like there's some weird race condition just before the first errors due problematic cache buffer appears, in 2 different threads. Looking..., Frankly the only explanation that I can see is if the same ProcCacheChunk is returned twice from the object pool due to a bug (or returned TO the pool twice by a thread and then legitimately returned twice from the pool). It seems like lists from two racing threads are merged at an item while both threads are just straightforwardly uncompressing ORC CBs linearly from a 100% cache miss. At the same time, given that after getting the item it's initialized, I'd expect one of the lists to have a completely invalid item, whereas here looks like only one link is invalid while all lists are contiguous, without the item that would be overwritten. So it's really weird. Looking at it now.
Looks like the ordering checks patch that could have made the error clearer is missing from this build, I'm  backporting it for now. 
Pool has pretty good multi-threaded tests so not sure yet how can this happen.
]