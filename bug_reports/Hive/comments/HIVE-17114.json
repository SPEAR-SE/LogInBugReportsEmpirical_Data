[[~lirui]: Changing the ObjectInspectorUtils.hashCode() implementation breaks all existing bucketed tables, breaks SMB joins and Bucket map-joins.

Specifically this is a problem with Hive-on-Spark, which doesn't have an underlying partitioner implementation for the ReduceSinkDesc$ReducerTraits.UNIFORM trait., Hi [~gopalv], thanks for pointing me to the ReducerTraits. I'll see what I can do with that., I think we can set the UNIFORM trait to the RS and then MurmurHash is used to compute the hash code, which can solve the issue here., [~lirui]: can you provide detail example to explain the problem as I'm interested about the skewed problem? thanks very much, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12877923/HIVE-17114.1.patch

{color:red}ERROR:{color} -1 due to no test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 43 failed/errored test(s), 11073 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[llap_smb] (batchId=143)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[columnstats_part_coltype] (batchId=157)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_if_expr] (batchId=145)
org.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver[constprog_semijoin] (batchId=169)
org.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver[spark_dynamic_partition_pruning] (batchId=167)
org.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver[spark_dynamic_partition_pruning_2] (batchId=169)
org.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver[spark_explainuser_1] (batchId=168)
org.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver[spark_use_op_stats] (batchId=167)
org.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver[spark_use_ts_stats_for_mapjoin] (batchId=168)
org.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver[spark_vectorized_dynamic_partition_pruning] (batchId=167)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_2] (batchId=99)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=233)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query23] (batchId=233)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[groupby3] (batchId=102)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[ppd_join_filter] (batchId=124)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union_remove_10] (batchId=110)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union_remove_13] (batchId=137)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union_remove_15] (batchId=136)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union_remove_16] (batchId=131)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union_remove_7] (batchId=101)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union_remove_8] (batchId=121)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union_remove_9] (batchId=131)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[vector_between_in] (batchId=124)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[vector_cast_constant] (batchId=104)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[vector_count_distinct] (batchId=111)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[vector_decimal_aggregate] (batchId=108)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[vector_distinct_2] (batchId=122)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[vector_groupby_3] (batchId=127)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[vector_mapjoin_reduce] (batchId=134)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[vector_orderby_5] (batchId=118)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[vector_string_concat] (batchId=114)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[vectorization_12] (batchId=104)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[vectorization_13] (batchId=121)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[vectorization_14] (batchId=106)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[vectorization_15] (batchId=127)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[vectorization_16] (batchId=118)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[vectorization_9] (batchId=100)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[vectorization_short_regress] (batchId=121)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[vectorized_ptf] (batchId=127)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[vectorized_shufflejoin] (batchId=131)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema (batchId=178)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema (batchId=178)
org.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation (batchId=178)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/6082/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/6082/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-6082/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 43 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12877923 - PreCommit-HIVE-Build, Hi [~kellyzly], I have an example in the description. Basically, Spark decides the reducer task for each record by computing {{hash(key)%numReducers}}. Currently, for a single int key, hash(key)==key. Therefore in my example, all records go to the same reducer although they have different keys. I think it's a rare case, but I did hit it in a benchmark.
By using MurmurHash, we can distribute the records more evenly, see HIVE-7121., [~lirui]:  several questions:
1.{quote}
Spark decides the reducer task for each record by computing hash(key)%numReducers
{quote}

this is in hive on spark code or in spark code? can you point out detail code place?

2. when i view HIVE-7121, the problem mentioned in the jira description only relates table with bucket ?
{code}
CREATE TABLE bucket1_1(key int, value string) CLUSTERED BY (key) INTO 100 BUCKETS;
{code}, Hi [~kellyzly],
1. It's spark code. You can look at {{HashPartitioner}} which is used for group by and sort by shuffles.
2. I don't think it's only for bucket tables. Actually I think MurmurHash won't be used if table is bucketed. [~gopalv] please let me know if I misunderstand., Yes, the bucketed table fix was taken out of that patch and parked in HIVE-7148, because of backwards compatibility issues.

The description in this jira sounds like HIVE-7074, in particular., [~lirui]: thanks for your explanation, but i also want to ask that the situation happened on query with 1 join or multiple joins?
[~gopalv]: thanks for your link and detail query in HIVE-7074., Patch v2 updates some golden files. Most of the changes are because we'll use different vector RS operators with uniform hash, which is expected., [~gopalv], thanks for your input. Since HIVE-7074 is superseded by HIVE-7121, the murmur hash is sufficient to solve my problem here.
[~kellyzly], I don't think it's related to how many times the join is performed. It happens when the data has the particular keys and we choose the particular number of reducers., [~lirui]: 
{quote}
It happens when the data has the particular keys and we choose the particular number of reducers.
{quote}
yes, the number of reduces(partition numbers of  partition of RDD) usually is decided by spark. So it is rare to happen the partition  number  is 10., 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12878115/HIVE-17114.2.patch

{color:green}SUCCESS:{color} +1 due to 1 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 11 failed/errored test(s), 11075 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestBeeLineDriver.testCliDriver[create_merge_compressed] (batchId=239)
org.apache.hadoop.hive.cli.TestBeeLineDriver.testCliDriver[materialized_view_create_rewrite] (batchId=239)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[llap_smb] (batchId=143)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_if_expr] (batchId=145)
org.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver[constprog_semijoin] (batchId=169)
org.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver[spark_vectorized_dynamic_partition_pruning] (batchId=167)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=234)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query23] (batchId=234)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema (batchId=178)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema (batchId=178)
org.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation (batchId=178)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/6094/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/6094/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-6094/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 11 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12878115 - PreCommit-HIVE-Build, {{constprog_semijoin}} needs sorting query results. Other failures are not related. Update patch v3 to address it.
[~xuefuz], [~csun] would you mind take a look? Thanks.
The idea is to set UNIFORM trait to RS in {{SetSparkReducerParallelism}}, when num reducers is automatically decided. Most of the code change is refactoring in order to be more concise., 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12878159/HIVE-17114.3.patch

{color:green}SUCCESS:{color} +1 due to 2 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 9 failed/errored test(s), 11087 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestBeeLineDriver.testCliDriver[insert_overwrite_local_directory_1] (batchId=240)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[llap_smb] (batchId=144)
org.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver[spark_dynamic_partition_pruning] (batchId=168)
org.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver[spark_vectorized_dynamic_partition_pruning] (batchId=168)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=235)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query23] (batchId=235)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema (batchId=179)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema (batchId=179)
org.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation (batchId=179)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/6096/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/6096/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-6096/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 9 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12878159 - PreCommit-HIVE-Build, Latest failures not related., Looks good. +1., Pushed to master. Thanks Chao for the review., Hive 3.0.0 has been released so closing this jira.]