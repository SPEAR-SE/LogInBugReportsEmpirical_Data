[tried to make all columns unique within a query, but too many things in Hive depend upon _colN names either explicitly by getting number back out of them, or implicitly (such as reducer code when generating OI for distincts). May upload patch somewhere, let me try to maintain lineage in vectorization instead., I will be gone for a week shortly, so if someone decides to take over... I examined two options:
1) Making the assumption true (all column names unique).
2) Adding lineage information to column map.
I was previously unfamiliar with either part of the codebase so I may be missing some important part, feel free to comment or take over.

For (1), I have a partial patch. Unfortunately, many places in hive explicitly or implicitly make assumptions about column names generated by semanticanalyzer or other operators. I've fixed a few places, but those that remain were pretty tough to figure out, patch needs more work. Also, patch will be quite "epic" in its impact relative to the problem, so it's the less-preferred approach.
For (2), adding lineage is easy (output column names are indeed unique within one operator, operator ID can be used and it can be retrieved by tag during the operator, or maps could be scoped to each operator, so an operator would be initialized with "input maps" coming from "output maps" from its parents, and in turn generate the "output map"), but the problem is on retrieve side, because anyone retrieving the column would have to know the lineage of what he's retrieving (from which parent it's coming). 
I've started studying the code of operators to see what kind of assumptions can be made in all the places this map is accessed, esp. e.g. getVectorExpression recursive call thru getCustomUDFExpression, when expressions for UDF parameters are retrieved. It's not quite clear how to get lineage for these parameters and whether it's guaranteed to be from the same parent in any given processOp call. But this seems to be a promising approach.
, Here are 2 patches. Unique cols is abandoned patch with solution 1. 
the main one is for (2), I was able to compile queries properly but running fails. It's probably something related to passing of serialized stuff thru scratch map, but I cannot get MR logging to work in tests so it's hard to tell.

If someone wants to take over either patch, feel free... I will get back to it the monday after next earliest., General pattern - "TODO#" marks where I was going to fix something, double check something, or the debug logging (e,g, TODO# adding blah) that needs to be removed, Uploaded HIVE-5817.00-broken.patch here to make it easier to review the differences:

https://reviews.apache.org/r/15740/, I was able to create a smaller repro as follows.

First, create the table alltypesorc (this is a standard table that is in the Hive source code as test data).

set hive.vectorized.execution.enabled = false;

create table store(s_store_sk int, s_city string)
stored as orc;

insert overwrite table store
select cint, cstring1
from alltypesorc
where cint not in (
-3728, -563, 762, 6981, 253665376, 528534767, 626923679);

create table store_sales(ss_store_sk int, ss_hdemo_sk int, ss_net_profit double)
stored as orc;

insert overwrite table store_sales
select cint, cint, cdouble
from alltypesorc
where cint not in (
-3728, -563, 762, 6981, 253665376, 528534767, 626923679);

create table household_demographics(hd_demo_sk int)
stored as orc;

insert overwrite table household_demographics
select cint 
from alltypesorc
where cint not in (
-3728, -563, 762, 6981, 253665376, 528534767, 626923679);

-- the NOT IN condition makes sure all the cint values are unique

-- finally, run this:
set hive.vectorized.execution.enabled = true;

select store.s_city, ss_net_profit
    from store_sales
     JOIN store ON store_sales.ss_store_sk = store.s_store_sk  
     JOIN household_demographics ON store_sales.ss_hdemo_sk = household_demographics.hd_demo_sk
    limit 100;

Expected result: 100 rows of output are produced
Actual result:
...
2013-11-20 17:57:37,487 Stage-4 map = 0%,  reduce = 0%
2013-11-20 17:58:04,585 Stage-4 map = 100%,  reduce = 100%
Ended Job = job_201311191600_0022 with errors
Error during job, obtaining debugging information...
Job Tracking URL: http://localhost:50030/jobdetails.jsp?jobid=job_201311191600_0022
Examining task ID: task_201311191600_0022_m_000002 (and more) from job job_201311191600_0022

Task with the most failures(4):
-----
Task ID:
  task_201311191600_0022_m_000000

URL:
  http://localhost:50030/taskdetails.jsp?jobid=job_201311191600_0022&tipid=task_201311191600_0022_m_000000
-----
Diagnostic Messages for this Task:
java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row
        at org.apache.hadoop.hive.ql.exec.mr.ExecMapper.map(ExecMapper.java:181)
        at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:50)
        at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
        at org.apache.hadoop.mapred.MapTask.run(MapTask.java:366)
        at org.apache.hadoop.mapred.Child$4.run(Child.java:266)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1136)
        at org.apache.hadoop.mapred.Child.main(Child.java:260)
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row
        at org.apache.hadoop.hive.ql.exec.vector.VectorMapOperator.process(VectorMapOperator.java:45)
        at org.apache.hadoop.hive.ql.exec.mr.ExecMapper.map(ExecMapper.java:163)
        ... 8 more
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: Incompatible Long vector column and primitive category STRING
        at org.apache.hadoop.hive.ql.exec.vector.VectorColumnAssignFactory.buildObjectAssign(VectorColumnAssignFactory.java:278)
        at org.apache.hadoop.hive.ql.exec.vector.VectorColumnAssignFactory.buildAssigners(VectorColumnAssignFactory.java:365)
        at org.apache.hadoop.hive.ql.exec.vector.VectorMapJoinOperator.internalForward(VectorMapJoinOperator.java:235)
        at org.apache.hadoop.hive.ql.exec.CommonJoinOperator.genAllOneUniqueJoinObject(CommonJoinOperator.java:675)
        at org.apache.hadoop.hive.ql.exec.CommonJoinOperator.checkAndGenObject(CommonJoinOperator.java:758)
        at org.apache.hadoop.hive.ql.exec.MapJoinOperator.processOp(MapJoinOperator.java:224)
        at org.apache.hadoop.hive.ql.exec.vector.VectorMapJoinOperator.processOp(VectorMapJoinOperator.java:293)
        at org.apache.hadoop.hive.ql.exec.Operator.process(Operator.java:489)
        at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:827)
        at org.apache.hadoop.hive.ql.exec.vector.VectorMapJoinOperator.flushOutput(VectorMapJoinOperator.java:249)
        at org.apache.hadoop.hive.ql.exec.vector.VectorMapJoinOperator.internalForward(VectorMapJoinOperator.java:244)
        at org.apache.hadoop.hive.ql.exec.CommonJoinOperator.genAllOneUniqueJoinObject(CommonJoinOperator.java:675)
        at org.apache.hadoop.hive.ql.exec.CommonJoinOperator.checkAndGenObject(CommonJoinOperator.java:758)
        at org.apache.hadoop.hive.ql.exec.MapJoinOperator.processOp(MapJoinOperator.java:224)
        at org.apache.hadoop.hive.ql.exec.vector.VectorMapJoinOperator.processOp(VectorMapJoinOperator.java:293)
        at org.apache.hadoop.hive.ql.exec.Operator.process(Operator.java:489)
        at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:827)
        at org.apache.hadoop.hive.ql.exec.TableScanOperator.processOp(TableScanOperator.java:91)
        at org.apache.hadoop.hive.ql.exec.Operator.process(Operator.java:489)
        at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:827)
        at org.apache.hadoop.hive.ql.exec.vector.VectorMapOperator.process(VectorMapOperator.java:43)
        ... 9 more


 , I'm looking at HIVE-5817.00-broken.patch. It looks like a reasonable approach. It does complicate the function interfaces in VectorizationContext a bit because the soureId parameter is added to a lot of functions. The way I understand it, Remus suggested maybe having a different VectorizationContext for each operator (for which there would be a specific VectorizedRowBatch structure). Then the sourceId could perhaps be an instance variable of VectorizationContext and make the function interface simpler. Does anybody have an opinion on this?, I think the only real problem operator is JOIN. Is not necessarily ‘one VC per operator’ but more like ‘one VC per query region’ where query region is defined by boundaries between different VS requirements (basically different result shapes). An operator like JOIN is one that clearly introduces a boundary, and the interesting part is that it needs two vectorization contexts: one for it’s input(s) and one for it’s output. So it would be more along the line that during vectorization each operator takes an VC (for its input, provided by its parent operator) and gives out a VC for its output, for its child operators to consume. Most operators would give out the same VC they get as input (ie. they do not change shape). And there is serialization too, which is handled separately (as properties added to the Map).

I'll try to come up with actual code over this week end., [~ehans] I tried your query. With that I can repro this on a 1-node cluster, but when I use this query in .q file and run mvn test, test actually passes. Any idea why?, Aah.. I missed one config which is required to repro in .q file {{ set hive.auto.convert.join=true; }} Thanks [~ehans] for test-case., [~rusanu] Another approach I am mulling over is to prepend table alias in the column name in that map. That way keys in that map will be unique across different tables, so that they won't collide. Change there is all the callers also need to prepend table alias than, but since all of them have ExprNodeDesc which has table alias, this should work out fine. What do you think ?, I have  the implementation of 'vectorization regions" almost done and I know how to finish it. Will post a patch tomorrow. 

Using the qualified column names (alias + column) will work probably, I don't think a query can have duplicate aliases (not up to par on my ANSI readings one can tell...). Thing is that will ripple everywhere in the vectorization context, we'll have to modify all the expression builders to use the alias.column as a key. If the "region concept" will work, will have a much more contained impact., Great! Thanks for jumping in., Currently other operators also change the column names. In fact there's new method that gets the source operator for lineage, note that the only place where it passes thru to parent is Filter - everyone except filter passes their own column names to child ops (which may or may not be necessary)., https://reviews.apache.org/r/15849/, I came across this exact same issue (column name collision) when I worked on HIVE-5369. As Ashutosh pointed out tabAlias.colName will work. This is what I am using for resolving column names from different parent operators. Reference code can be found in JoinStatsRule under StatsRulesProcFactory.java.
Another option is every operator will have output row schema which has list of ColumnInfo. ColumnInfo internally contains internal column name and table alias, when used as a key for hashmap should avoid column name collision. Hope this helps., [~rusanu] We should add test-case provided by [~ehans] earlier in the comment thread as part of this patch., My patch .4 addresses the issue the following manner:
 
 - vector operators can implement optional interface VectorizationContextRegion. If they do, they must provide a new vectorization context to be used by child operators. In my patch only VectorMapJoinOperator does so.
 - vectorizer walks up the stack of parent nodes to locate the first one (last one?) that created a vectorization context, and this is the vectorization context used to vectorize the current node. At the root of the stack there is a table scan that always creates a vectorization context. 
 - I made the VectorMapJoinOperator build the output VectorizedRowBatch using the VectorizedRowBatchCtx class, same as ORC and RC scanners do. This is more consistent and removes the need for the VectorizedRowBatch.buildBatch method (was used only by VMJ)
 - add a simplified init to VectorizedRowBatchCtx  to be used by VMJ (or any other operator we decide).

I did not enable yet 'submit patch' because more code can be removed  (the mapper scratch for vector type map) , code that was use donly by VMJ to enable it to build the output batch. Using VectorizedRowBatchCtx  makes all that code obsolete.

I tested the repro query and passes fine, produces 100 rows (I assume they're the right ones...). I will do some more testing., [~prasanth_j]: why I wanted to do it via 'vectorization regions' is because I believe this concept is needed not only for name resolution. Currently, w/o 'regions', the same vectorization context is used for the entire query tree. this results in very wide (many columns) contexts, because there has to be a column in the context for every intermediate column. With Joins, this becomes quite wide., [~sershe]: not sure about other operators. Aren't they covered by the existing addOutputColumn mechanism?, About the other operators, what do you mean? In the explain of the original query I was looking at, vectorized select does this
{noformat}
Select Operator
                  expressions:
                        expr: _col22
                        type: string
                        expr: _col53
                        type: float
                  outputColumnNames: _col0, _col1
{noformat}

In that case, _col22 from 2 preceding joins happened to collide, but cannot, for example, _col1 from the last join become _col0 of select? So the collision will happen when _col1 of select is added and there's already _col1 from the last join, Did some testing and found testcase : vectorization_part_project.q is failing after applying this patch with following stack trace:
{code}
java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row
        at org.apache.hadoop.hive.ql.exec.mr.ExecMapper.map(ExecMapper.java:181)
        at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:50)
        at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:436)
        at org.apache.hadoop.mapred.MapTask.run(MapTask.java:372)
        at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:212)
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row
        at org.apache.hadoop.hive.ql.exec.vector.VectorMapOperator.process(VectorMapOperator.java:45)
        at org.apache.hadoop.hive.ql.exec.mr.ExecMapper.map(ExecMapper.java:163)
        ... 4 more
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: Error evaluating (cdouble + 2)
        at org.apache.hadoop.hive.ql.exec.vector.VectorSelectOperator.processOp(VectorSelectOperator.java:117)
        at org.apache.hadoop.hive.ql.exec.Operator.process(Operator.java:489)
        at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:827)
        at org.apache.hadoop.hive.ql.exec.TableScanOperator.processOp(TableScanOperator.java:91)
        at org.apache.hadoop.hive.ql.exec.Operator.process(Operator.java:489)
        at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:827)
        at org.apache.hadoop.hive.ql.exec.vector.VectorMapOperator.process(VectorMapOperator.java:43)
        ... 5 more
Caused by: java.lang.ArrayIndexOutOfBoundsException: 13
        at org.apache.hadoop.hive.ql.exec.vector.expressions.gen.DoubleColAddLongScalar.evaluate(DoubleColAddLongScalar.java:57)
        at org.apache.hadoop.hive.ql.exec.vector.VectorSelectOperator.processOp(VectorSelectOperator.java:115)
{code}, We should add following .q file in patch:
{code}
set hive.auto.convert.join=true;
create table store(s_store_sk int, s_city string)
stored as orc;
insert overwrite table store
select cint, cstring1
from alltypesorc
where cint not in (
-3728, -563, 762, 6981, 253665376, 528534767, 626923679);
create table store_sales(ss_store_sk int, ss_hdemo_sk int, ss_net_profit double)
stored as orc;
insert overwrite table store_sales
select cint, cint, cdouble
from alltypesorc
where cint not in (
-3728, -563, 762, 6981, 253665376, 528534767, 626923679);
create table household_demographics(hd_demo_sk int)
stored as orc;
insert overwrite table household_demographics
select cint
from alltypesorc
where cint not in (
-3728, -563, 762, 6981, 253665376, 528534767, 626923679);

set hive.vectorized.execution.enabled = true;
select store.s_city, ss_net_profit
from store_sales
JOIN store ON store_sales.ss_store_sk = store.s_store_sk
JOIN household_demographics ON store_sales.ss_hdemo_sk = household_demographics.hd_demo_sk
;

set hive.auto.convert.join=false;
set hive.vectorized.execution.enabled = false;
{code}

I tested the patch on above query and output returned are correct., This patch fixes the regression with vectorization_part_project.q 
I added vectorized_context_regression_5817.q but I'm unable to create an expected .out file because mvn test fails on my Windows enlistment:

-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running org.apache.hadoop.hive.cli.TestCliDriver
Tests run: 1, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 32.067 sec <<< FAILURE! - in org.apache.hadoop.hive.cli.TestCliDriver
initializationError(org.apache.hadoop.hive.cli.TestCliDriver)  Time elapsed: 0.006 sec  <<< FAILURE!
java.lang.AssertionError: null
        at org.apache.hadoop.hive.ql.QTestUtil.getHdfsUriString(QTestUtil.java:288)
        at org.apache.hadoop.hive.ql.QTestUtil.convertPathsFromWindowsToHdfs(QTestUtil.java:276)
        at org.apache.hadoop.hive.ql.QTestUtil.initConf(QTestUtil.java:233)
        at org.apache.hadoop.hive.ql.QTestUtil.<init>(QTestUtil.java:317)
        at org.apache.hadoop.hive.cli.TestCliDriver.<clinit>(TestCliDriver.java:39)
, Same patch as .5 but also containing .q.out file for new test., Submitting patch for Hive QA to pick up, +1 I tested Remus's latest patch both with .q files as well with junit tests. All tests passed., [~sershe] Let me think about that (the SELECT and other operators). My patch handles cases where the input batch is different from the output batch (eg. JOIN, GROUP BY) but is not good for SELECT operator because it forces copy from in batch to out batch. What I uploaded is still needed for JOIN, is much better than how JOIN used to handle this issue, but you have a point that the solution may not be complete., Patch looks good to me for what it does, +1
Should it also handle GBY?
Do you want to file a separate JIRA for the select case? I can try to make repro next week, [~sershe] VGBY is outputing rowmode output (since the next operator is always a reduce sink, and also there was no vector sink when we implemented VGBY). Had the VGBY output batch mode, it would need to do the same thing JOIN does (use a vectorization context, generate output batch etc)., 

{color:green}Overall{color}: +1 all checks pass

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12615853/HIVE-5817.6.patch

{color:green}SUCCESS:{color} +1 4660 tests passed

Test results: http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/457/testReport
Console output: http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/457/console

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12615853, Committed to trunk. Thanks, Sergey for initial investigation. Thanks, Remus for patch. Thanks, Eric for reproducible test-case!, It seems like I cannot make a repro for select... even though there are name collisions, the mappings are correct. Perhaps when someone finds a bug we can solve it :), bq. It seems like I cannot make a repro for select... even though there are name collisions, the mappings are correct. Perhaps when someone finds a bug we can solve it .
HIVE-6349 patch includes a test that reproduces the problem for vectorized select. The patch also fixes the issue.]