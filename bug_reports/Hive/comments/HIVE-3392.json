[All DDL statement are calling Hive.getTable() method which internally invoke checkValidity() method.
checkValidity() method internally tries to fetch all the columns using Hive.getFieldsFromDeserializer(getTableName(), getDeserializer()) method.
So while trying to drop the table, it tries to get the Deserializer and causes the exception.

As a resolution we should bypass the checkValidity() method for drop command.

I have tested in local and is working fine.  Let me know your comments so that I can work on the patch.
, Added logic to skip the table schema validation if the command is a drop command. Attached patch file HIVE-3392.1.patch. 
Please do a review., Review request added at https://reviews.apache.org/r/7004/, comments on review board, [~ajeshpg], I have added you as a contributor. You can assign jiras you are working on to yourself, comments


[~ajeshpg], please mark 'submit patch' when you are done with the changes and want others to review, I have an issue with this. Serde's and storage handlers could have custom drop logic. If we allow a drop without the class how do we know the right think was done?, New Review request added at https://reviews.apache.org/r/7004/diff/3/.
As we can not use Junit/.q file for this scenario, I have added testcase in a step by step format.
Please review code and Testcases., Hi Edward Capriolo, when we are dropping a table, why we need to validate the class. We just need to drop the table even if the particular class (which was used while creating the table) is not available.
let me know your comments., Testcases are attached.  
1) HIVE-3392.Test Case - Before Patch.txt
2) HIVE-3392.Test Case - After Patch.txt, Hi Namit,
Do I need to change Assignee to get this patch reviewed., Ajesh. Please address my comments

1 why do we need this?Not having the correct jars is a setup problem.

2 how does this work with storage handlers? When you drop an hbase table you need to have the serde because custom work needs to be done., Hi Edward Capriolo, 
when we are dropping a table, why we need to validate the class. We just need to drop the table even if the particular class (which was used while creating the table) is not available.
let me know your comments., Because some Serde's NEED to do custom things when dropping a table. An example is the hbase handler https://cwiki.apache.org/Hive/storagehandlers.html. So sometimes the check is necessary. 

Also as I was asserting up above. When your missing a JAR file you have a deployment problem. I do not think we want to try to solve/avoid deployment problems with more code.

How about this? Why not make hive check for the existence of the serde, and if the class is not found produce a nice clean exception with a nice error message., Hi Edward Capriolo,
So can we conclude this as not an issue. 
or I can make a change to display a message like below when the class is not found.

hive> drop table temptbl;
FAILED: Hive Internal Error: java.lang.RuntimeException(MetaException(message:org.apache.hadoop.hive.serde2.SerDeException SerDe org.apache.hadoop.hive.serde2.TestDelimitedJSONSerDe does not exist))
hive>, Yes. I think a nice clean exception / error message is the way to go. , Hi Edward Capriolo,

I checked the latest version of Driver.java in trunk.(org/apache/hadoop/hive/ql/Driver.java)
A lot of patches has been already applied  on this file as part of other issue's fixes. 
The change we have discussed to display a clean error message will be taken care by those changes.So we do not need any more code change for this issue.

Attaching a test case for the same."HIVE-3392.Test Case - with_trunk_version.txt"., Hi Edward Capriolo/Namit
As per my previous comment, can you suggest if we need to work more on this or we can consider this issue as resolved?, Sorry I have not had a chance to to a full review. I will try to tackle this before the weekend., Hi Edward Capriolo
As per my previous comment, can you suggest if we need to work more on this or we can consider this issue as resolved?, As Ed noted, custom storage handlers will require jars to be present in classpath, so we cannot ignore missing jars. Also, trunk now throws a nice error message. No more work required on the ticket. Closing., If it's non-native table with custom storage handler, it's right to throw exception. But if it's native table with custom serde, we need not to verify serde of the table. Furthermore, in checkValidity() method,
{code}
if (0 == getCols().size()) throw new HiveException();
{code}
Is not needed except creating a table or partition. [~ashutoshc], can I reopen this issue?, 

{color:red}Overall{color}: -1 at least one tests failed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12650218/HIVE-3392.3.patch.txt

{color:red}ERROR:{color} -1 due to 5 failed/errored test(s), 5536 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_parquet_columnar
org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_root_dir_external_table
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_altern1
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_authorization_ctas
org.apache.hive.hcatalog.pig.TestHCatLoader.testReadDataPrimitiveTypes
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-Build/464/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-Build/464/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-Build-464/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 5 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12650218, I am fine with reopening this. [~appodictic] What do you think ?, Please feel free to take over the review. I will not have any time at the moment. Thanks!, 

{color:red}Overall{color}: -1 at least one tests failed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12654765/HIVE-3392.4.patch.txt

{color:red}ERROR:{color} -1 due to 3 failed/errored test(s), 5701 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_altern1
org.apache.hive.hcatalog.pig.TestHCatLoader.testReadDataPrimitiveTypes
org.apache.hive.jdbc.miniHS2.TestHiveServer2.testConnection
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-Build/720/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-Build/720/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-Build-720/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 3 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12654765, So this moves the validity check from getTable(), over to alterTable/alterPartition.
What kind of error will we get now if we try to do a SELECT on this table when the SerDe cannot be resolved? Do we need to add the validity check somewhere in that code path, or is the current error sufficient?, Basically get the same exception(CNE) but with different stacktrace.

Before the patch (select)
{noformat}
java.lang.ClassNotFoundException: Class org.apache.hadoop.hive.serde2.lazy.TestSerDe not found
	at org.apache.hadoop.conf.Configuration.getClassByName(Configuration.java:1801)
	at org.apache.hadoop.hive.metastore.MetaStoreUtils.getDeserializer(MetaStoreUtils.java:342)
	at org.apache.hadoop.hive.ql.metadata.Table.getDeserializerFromMetaStore(Table.java:288)
	at org.apache.hadoop.hive.ql.metadata.Table.getDeserializer(Table.java:281)
	at org.apache.hadoop.hive.ql.metadata.Table.getCols(Table.java:631)
	at org.apache.hadoop.hive.ql.metadata.Table.checkValidity(Table.java:189)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:1019)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:933)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.getMetaData(SemanticAnalyzer.java:1227)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.getMetaData(SemanticAnalyzer.java:1198)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:9442)
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:328)
{noformat}

After the patch (select)
{noformat}
java.lang.ClassNotFoundException: Class org.apache.hadoop.hive.serde2.lazy.TestSerDe not found
	at org.apache.hadoop.conf.Configuration.getClassByName(Configuration.java:1801)
	at org.apache.hadoop.hive.metastore.MetaStoreUtils.getDeserializer(MetaStoreUtils.java:342)
	at org.apache.hadoop.hive.ql.metadata.Table.getDeserializerFromMetaStore(Table.java:263)
	at org.apache.hadoop.hive.ql.metadata.Table.getDeserializer(Table.java:256)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genTablePlan(SemanticAnalyzer.java:8802)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPlan(SemanticAnalyzer.java:9110)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:9449)
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:328)
{noformat}

I think it would be sufficient to check validity right before updating table or partition metadata. , Left comment on RB, which I think is causing the failure in TestNegativeCliDriver.testNegativeCliDriver_altern1., Rebased to trunk and fixed that. Thanks., +1 if tests pass ok., 

{color:red}Overall{color}: -1 at least one tests failed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12654951/HIVE-3392.5.patch.txt

{color:red}ERROR:{color} -1 due to 3 failed/errored test(s), 5703 tests executed
*Failed tests:*
{noformat}
org.apache.hive.hcatalog.pig.TestHCatLoader.testReadDataPrimitiveTypes
org.apache.hive.hcatalog.pig.TestOrcHCatLoader.testReadDataPrimitiveTypes
org.apache.hive.jdbc.miniHS2.TestHiveServer2.testConnection
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-Build/733/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-Build/733/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-Build-733/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 3 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12654951, Committed to trunk. Thanks Jason, for the review., This has been fixed in 0.14 release. Please open new jira if you see any issues.
]