[Attaching fix, [~gezapeti]: There is a typo in the comment (missing 'n' from locatioN)

[~stakiar], [~xuefuz]: Could you please take a look at this?

Thanks,
Peter, Addressing typo, Overall LGTM. Just a few questions:
* Are these errors thrown by HiveServer2 or by the HoS Remote Driver?
* Is that same thing required for Hive-on-MR?
* Is it possible to add a test for this?, This happens with HiveCLI, not with HS2. 
The exception is coming from the spark driver.

When the HiveCLI is executed from shell, the mapreduce.job.credentials.binary is empty in the configuration as spark-submit is called from the RemoteClient.
When it's executed from Oozie's LauncherMapper, Hive picks up this property from the Oozie launcher's configuration which is correct, but passes it to Spark. Spark runs in yarn-cluster mode so the Spark driver gets it's own container (which may be on an other machine). It look for the credential files in the folder where the Oozie Launcher ran. That's on a different machine, so it can't pick up the conatiner_tokens file which leaves the spark driver with no tokens so it fails.

I don't know how Hive-on-MR works in this regards, but we had no similar issues with the HiveAction before, so I assume it works differently.

I don't think it's possible to reproduce it using MiniClusters as the local folders will be available in the test so the Spark driver will be able to access it. , [~peterceluch], can the tokens in Oozie launcher application still be passed to Spark job when property {{mapreduce.job.credentials.binary}} is unset? For example, in an environment where HDFS transparent encryption is enabled, is Spark job still able to connect to KMS servers?

(The change is in {{RemoteHiveSparkClient}}. Hive on MR shouldn't be affected. Oozie actions have already make sure the tokens are added to action configuration, which then should be passed to MR jobs)., I think the Spark driver will get the tokens afterwards, this property is pointing to an invalid location., bq. I think the Spark driver will get the tokens afterwards
I really doubt that Spark driver can do this. In Oozie environment, it is Oozie server that obtains all the tokens *on behalf of the end user*. When the Hive actions starts a Spark job, the Spark driver has no access to end user ticket or keytab file. I don't think it can obtain necessary tokens. 
I believe we should somehow extract all the tokens from existing toke file, and pass it on to the Spark driver., The Spark driver will get the correct tokens from the parent application - it's in the local folder created for it's container. I'm not sure how it get's them, but they are there. 
The driver will pick it up from the correct container_tokens file using the HADOOP_TOKEN_FILE_LOCATION env variable or something like that. The issue is that Hadoop's TokenCache is looking for the mapreduce.job.credentials.binary property as well, while it's not needed and this invalid reference causes the job to fail., Thanks for the explanation!
This may be done by YARN instead of Spark. 
, [~aihuaxu] may have some input, he knows more about security.

Other than that, LGTM., [~gezapeti] I will take a look. Can you rename your patch to the format of HIVE-15767.1.patch to kick off the build? Looks like that's the reason why the build is not run., Thanks for the comments and reviews!

Renaming patch -002 to .1 to kick off pre-commit job. 
, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12877383/HIVE-15767.1.patch

{color:red}ERROR:{color} -1 due to no test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 14 failed/errored test(s), 10907 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestBeeLineDriver.testCliDriver[create_merge_compressed] (batchId=238)
org.apache.hadoop.hive.cli.TestBeeLineDriver.testCliDriver[insert_overwrite_local_directory_1] (batchId=238)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[llap_smb] (batchId=143)
org.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver[spark_dynamic_partition_pruning] (batchId=167)
org.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver[spark_dynamic_partition_pruning_2] (batchId=169)
org.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver[spark_explainuser_1] (batchId=168)
org.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver[spark_use_op_stats] (batchId=167)
org.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver[spark_use_ts_stats_for_mapjoin] (batchId=168)
org.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver[spark_vectorized_dynamic_partition_pruning] (batchId=167)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query23] (batchId=233)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema (batchId=178)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema (batchId=178)
org.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation (batchId=178)
org.apache.hive.jdbc.TestJdbcWithMiniHS2.testHttpRetryOnServerIdleTimeout (batchId=227)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/6041/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/6041/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-6041/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 14 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12877383 - PreCommit-HIVE-Build, [~gezapeti] Logically seems it's correct to set proper mapreduce.job.credentials.binary and pass to Spark. And MR is also doing the same thing. Can you find out why it makes the difference when oozie calls HiveCLI MR vs. Spark actions? 

, The problem is that we're not setting the _proper_ mapreduce.job.credentials.binary, but [here|https://github.com/apache/hive/blob/master/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/RemoteHiveSparkClient.java#L235], were passing every property from the HiveConf conf to the configuration for Spark.
If HiveCLI is called from the Oozie LauncherMapper, that HiveConf will contain the "mapreduce.job.credentials.binary" property for the LauncherMapper. e.g /yarn/nm/usercache/systest/appcache/application_1501079366372_0045/container_1501079366372_0045_01_000001/container_tokens
This property have to be there so HiveCLI can access the tokens properly.

Passing this folder to the Spark driver is problematic as the driver often will be executed on an other machine in the cluster where it won't be able to read this file as it's not there. There are a couple ways to define the location of the container_tokens file and Yarn takes care of Spark getting the correct location on the node the driver will be executed on.
, From what I see, the patch seems logical, harmless at least. What I don't understand is that why Spark would attempt reading this file. As a side note, I didn't find the source in Spark code base that does this., I don't remember all the details, but here is a longer stack trace:{code}
java.lang.RuntimeException: java.io.IOException: Exception reading file:/yarn/nm/usercache/yshi/appcache/application_1485271416004_0001/container_1485271416004_0001_01_000002/container_tokens
	at org.apache.hadoop.mapreduce.security.TokenCache.mergeBinaryTokens(TokenCache.java:160)
	at org.apache.hadoop.mapreduce.security.TokenCache.obtainTokensForNamenodesInternal(TokenCache.java:138)
	at org.apache.hadoop.mapreduce.security.TokenCache.obtainTokensForNamenodesInternal(TokenCache.java:100)
	at org.apache.hadoop.mapreduce.security.TokenCache.obtainTokensForNamenodes(TokenCache.java:80)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:243)
{code}
Spark does not refer the {{mapreduce.job.credentials.binary}} directly, it is hard-coded in Hadoop's TokenCache [here|https://github.com/apache/hadoop/blob/f67237cbe7bc48a1b9088e990800b37529f1db2a/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/security/TokenCache.java#L148]. I think this TokenCache is used by Hadoop's FileSystem implementation too so when Spark talks to HDFS it does through this class., +1, Pushed to master.
Thanks [~gezapeti] for your contribution!, Hi [~gezapeti] , after apply this patch, i find that the Hive On Spark worked with yarn, all tasks is finished successfully. but there's another error throws at the end of the progress:

 
{code:java}
2018-04-24T14:28:46,409 INFO [116dbf89-2982-407d-9b64-4206b3bbe105 main] lockmgr.DbTxnManager: Stopped heartbeat for query: flowagent_20180424142839_be68e2b9-aca9-4023-89f8-6a18d53dd0c5
2018-04-24T14:28:46,409 INFO [116dbf89-2982-407d-9b64-4206b3bbe105 main] lockmgr.DbLockManager: releaseLocks: [lockid:438 queryId=flowagent_20180424142839_be68e2b9-aca9-4023-89f8-6a18d53dd0c5 txnid:0]
2018-04-24T14:28:46,422 ERROR [116dbf89-2982-407d-9b64-4206b3bbe105 main] CliDriver: Failed with exception java.io.IOException:org.apache.hadoop.ipc.RemoteException(java.io.IOException): Delegation Token can be issued only with kerberos or web authentication
at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getDelegationToken(FSNamesystem.java:6635)
at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getDelegationToken(NameNodeRpcServer.java:563)
at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getDelegationToken(ClientNamenodeProtocolServerSideTranslatorPB.java:988)
at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:969)
at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
at java.security.AccessController.doPrivileged(Native Method)
at javax.security.auth.Subject.doAs(Subject.java:422)
at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1727)
at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2045)

java.io.IOException: org.apache.hadoop.ipc.RemoteException(java.io.IOException): Delegation Token can be issued only with kerberos or web authentication
at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getDelegationToken(FSNamesystem.java:6635)
at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getDelegationToken(NameNodeRpcServer.java:563)
at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getDelegationToken(ClientNamenodeProtocolServerSideTranslatorPB.java:988)
at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:969)
at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
at java.security.AccessController.doPrivileged(Native Method)
at javax.security.auth.Subject.doAs(Subject.java:422)
at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1727)
at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2045)

at org.apache.hadoop.hive.ql.exec.FetchOperator.getNextRow(FetchOperator.java:521)
at org.apache.hadoop.hive.ql.exec.FetchOperator.pushRow(FetchOperator.java:428)
at org.apache.hadoop.hive.ql.exec.FetchTask.fetch(FetchTask.java:147)
at org.apache.hadoop.hive.ql.Driver.getResults(Driver.java:2208)
at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:253)
at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:184)
at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:403)
at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:336)
at org.apache.hadoop.hive.cli.CliDriver.processReader(CliDriver.java:474)
at org.apache.hadoop.hive.cli.CliDriver.processFile(CliDriver.java:490)
at org.apache.hadoop.hive.cli.CliDriver.executeDriver(CliDriver.java:793)
{code}, [~linwukang], we haven't seen this exception after the fix.
This might have to do something in regards the command you're executing or the time frame where the job runs. Without knowing those it's hard to give meaningful suggestions.
Can you check the expiry date for the HDFS token in the job? , Hive 3.0.0 has been released so closing this jira.]