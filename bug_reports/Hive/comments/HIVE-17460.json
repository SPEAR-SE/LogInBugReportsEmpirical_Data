[[~wzheng] Could you please help me to review this patch?, [~debugger87] Your fix looks good. Would it be better to move it inside alterPartitionSpecInMemory()?, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12885518/HIVE-17460.patch

{color:green}SUCCESS:{color} +1 due to 1 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 23 failed/errored test(s), 11028 tests executed
*Failed tests:*
{noformat}
TestAccumuloCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=230)
TestDummy - did not produce a TEST-*.xml file (likely timed out) (batchId=230)
TestNoSaslAuth - did not produce a TEST-*.xml file (likely timed out) (batchId=227)
TestTxnCommandsBase - did not produce a TEST-*.xml file (likely timed out) (batchId=280)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[alter_table_cascade] (batchId=84)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[autoColumnStats_5] (batchId=40)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_values_orig_table_use_metadata] (batchId=61)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[partition_wise_fileformat18] (batchId=69)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_text_nonvec_part] (batchId=149)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_text_nonvec_part_all_complex] (batchId=159)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_text_nonvec_part_all_primitive] (batchId=156)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_text_vec_part] (batchId=157)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_text_vec_part_all_complex] (batchId=153)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_text_vec_part_all_primitive] (batchId=158)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_text_vecrow_part] (batchId=162)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_text_vecrow_part_all_complex] (batchId=162)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_text_vecrow_part_all_primitive] (batchId=158)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=234)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query23] (batchId=234)
org.apache.hadoop.hive.metastore.TestHiveMetaStorePartitionSpecs.org.apache.hadoop.hive.metastore.TestHiveMetaStorePartitionSpecs (batchId=200)
org.apache.hadoop.hive.metastore.TestHiveMetaStorePartitionSpecs.testAddPartitions (batchId=200)
org.apache.hadoop.hive.metastore.TestHiveMetaStorePartitionSpecs.testFetchingPartitionsWithDifferentSchemas (batchId=200)
org.apache.hadoop.hive.metastore.TestHiveMetaStorePartitionSpecs.testGetPartitionSpecs_WithAndWithoutPartitionGrouping (batchId=200)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/6693/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/6693/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-6693/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 23 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12885518 - PreCommit-HIVE-Build, [~wzheng] The reason why so many(23) tests failed is that almost every schema_evol_*.q.out is different with our expected output. e.g. https://builds.apache.org/job/PreCommit-HIVE-Build/6693/testReport/junit/org.apache.hadoop.hive.cli/TestMiniLlapLocalCliDriver/testCliDriver_schema_evol_text_nonvec_part_/

```
125c125
< 2 1 2222 new 3333
---
> 2 1 2222 new NULL
138c138
< 2 1 3333
---
> 2 1 NULL
254c254
< 2 1 2222 new 3333
---
> 2 1 2222 new NULL
267c267
```

Obviously, my output is right. However, we should not ignore those failures. Any suggestions?, Some existing q.out files are wrong, but I noticed some other failures, e.g. autoColumnStats_5.q. I suggest you try moving the fix into alterPartitionSpecInMemory, under the "if (inheritTableSpecs)" block and have another test run., [~wei.zheng] Yes, I have moved those code into alterPartitionSpecInMemory and submit patch again.  , For autoColumnStats_5.q, the difference between my results and original q.out is:

< c                    int                                      
< d                    string 

After  running `alter table partitioned1 add columns(c int, d string)` and `desc formatted partitioned1 partition(part=1)`, the right result should contains `c` and `d`.

Maybe I should re-generate those q.out files which contains wrong results ? [~wzheng]
, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12885647/HIVE-17460.2.patch

{color:green}SUCCESS:{color} +1 due to 1 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 20 failed/errored test(s), 11029 tests executed
*Failed tests:*
{noformat}
TestAccumuloCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=230)
TestDummy - did not produce a TEST-*.xml file (likely timed out) (batchId=230)
TestTxnCommandsBase - did not produce a TEST-*.xml file (likely timed out) (batchId=280)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[alter_table_cascade] (batchId=84)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[autoColumnStats_5] (batchId=40)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_values_orig_table_use_metadata] (batchId=61)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[partition_wise_fileformat18] (batchId=69)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_text_nonvec_part] (batchId=149)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_text_nonvec_part_all_complex] (batchId=159)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_text_nonvec_part_all_primitive] (batchId=156)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_text_vec_part] (batchId=157)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_text_vec_part_all_complex] (batchId=153)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_text_vec_part_all_primitive] (batchId=158)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_text_vecrow_part] (batchId=162)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_text_vecrow_part_all_complex] (batchId=162)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_text_vecrow_part_all_primitive] (batchId=158)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=234)
org.apache.hadoop.hive.llap.security.TestLlapSignerImpl.testSigning (batchId=291)
org.apache.hive.hcatalog.pig.TestTextFileHCatStorer.testWriteDecimalXY (batchId=183)
org.apache.hive.hcatalog.pig.TestTextFileHCatStorer.testWriteTimestamp (batchId=183)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/6698/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/6698/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-6698/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 20 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12885647 - PreCommit-HIVE-Build, I don't think this is right -- you will end up with upset customers because query results will be different.

Unfortunately, the current semantics of adding a column are that the default behavior is RESTRICT not CASCADE.  RESTRICT means the partition schema's do not get updated with the new columns.  Thus, the new columns default to NULL when queried.  In order to get the behavior you are talking about you would need to specify the CASCADE option.

So I'm a -1 on this change.

[~wzheng], [~mmccline] Maybe you are right. However, Spark SQL can do right things to meet our expectation. We added columns to original table and insert overwrite some existed partitions, Spark SQL fetch all column values, whereas, Hive does not. Is there any proper solutions?, [~debugger87] I discussed with Matt regarding this issue as he is the domain expert for schema evolution. He's saying you can achieve what you want by adding CASCADE in your DDL., [~wzheng] [~mmccline] Thanks for your suggestion, I will try CASCADE in DDL. If everything goes right, I will close this issue., `CASCADE` works well for me, I will close this issue. Thanks [~mmccline] [~wzheng], This jira is resolved and released with Hive 3.0 If you find an issue with it, please create a new jira.]