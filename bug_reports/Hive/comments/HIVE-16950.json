[From the description, the requirement is more like an EXTERNAL database which has NOT been supported by Hive yet.

But I think we could add some check when create/drop database to avoid this issue.
There would be two ways to do this:
1. Throw an error when the target location on HDFS already exists.
An existing empty directory is invalid as well. Because currently, Hive allows to create two databases with the same location.
2. ONLY drop the tables belong to the target database.
With this purpose, we should get all the tables under this database when DROP DATABASE is invoked. 
But it would affect the performance of DROP statement.

I prefer the #1. [~ashutoshc], any comments on this?  Thank you.
, *ROOT-CAUSE:*

When we drop database, we remove _all_ contents of destination folder and if DB location the same as default DB, we remove all in _warehouse_ folder. Nevertheless removed DBs still exist in Metastore.

*SOLUTION*

Throw an error when the target location on HDFS already exists., | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
|| || || || {color:brown} Prechecks {color} ||
| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Findbugs executables are not available. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
|| || || || {color:brown} master Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  5m 53s{color} | {color:green} master passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 34s{color} | {color:green} master passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 20s{color} | {color:green} master passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 57s{color} | {color:green} master passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 38s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 37s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 37s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} checkstyle {color} | {color:red}  0m 20s{color} | {color:red} standalone-metastore: The patch generated 1 new + 684 unchanged - 0 fixed = 685 total (was 684) {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 55s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:red}-1{color} | {color:red} asflicense {color} | {color:red}  0m 13s{color} | {color:red} The patch generated 1 ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 10m 43s{color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Optional Tests |  asflicense  javac  javadoc  findbugs  checkstyle  compile  |
| uname | Linux hiveptest-server-upstream 3.16.0-4-amd64 #1 SMP Debian 3.16.36-1+deb8u1 (2016-09-03) x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /data/hiveptest/working/yetus/dev-support/hive-personality.sh |
| git revision | master / b5ba827 |
| Default Java | 1.8.0_111 |
| checkstyle | http://104.198.109.242/logs//PreCommit-HIVE-Build-7971/yetus/diff-checkstyle-standalone-metastore.txt |
| asflicense | http://104.198.109.242/logs//PreCommit-HIVE-Build-7971/yetus/patch-asflicense-problems.txt |
| modules | C: standalone-metastore U: standalone-metastore |
| Console output | http://104.198.109.242/logs//PreCommit-HIVE-Build-7971/yetus.txt |
| Powered by | Apache Yetus    http://yetus.apache.org |


This message was automatically generated.

, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12898872/HIVE-16950.2.patch

{color:red}ERROR:{color} -1 due to no test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 82 failed/errored test(s), 11410 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[alter_change_db_location] (batchId=8)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[auto_sortmerge_join_2] (batchId=47)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[dbtxnmgr_showlocks] (batchId=77)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[hybridgrace_hashjoin_2] (batchId=154)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[insert_values_orig_table_use_metadata] (batchId=162)
org.apache.hadoop.hive.metastore.TestEmbeddedHiveMetaStore.testDatabaseLocation (batchId=212)
org.apache.hadoop.hive.metastore.TestFilterHooks.testDefaultFilter (batchId=211)
org.apache.hadoop.hive.metastore.TestFilterHooks.testDummyFilterForPartition (batchId=211)
org.apache.hadoop.hive.metastore.TestRemoteHiveMetaStore.testDatabaseLocation (batchId=214)
org.apache.hadoop.hive.metastore.TestSetUGIOnBothClientServer.testDatabaseLocation (batchId=210)
org.apache.hadoop.hive.metastore.TestSetUGIOnOnlyClient.testDatabaseLocation (batchId=209)
org.apache.hadoop.hive.metastore.TestSetUGIOnOnlyServer.testDatabaseLocation (batchId=219)
org.apache.hadoop.hive.ql.parse.TestCopyUtils.testPrivilegedDistCpWithSameUserAsCurrentDoesNotTryToImpersonate (batchId=224)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testAlters (batchId=224)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testBasic (batchId=224)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testBasicWithCM (batchId=224)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testBootstrapWithConcurrentDropTable (batchId=224)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testBootstrapWithConcurrentRename (batchId=224)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testCMConflict (batchId=224)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testConcatenatePartitionedTable (batchId=224)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testConcatenateTable (batchId=224)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testConstraints (batchId=224)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testDrops (batchId=224)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testDropsWithCM (batchId=224)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testDumpLimit (batchId=224)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testExchangePartition (batchId=224)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testIdempotentMoveTaskForInsertFiles (batchId=224)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testIncrementalAdds (batchId=224)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testIncrementalInsertDropUnpartitionedTable (batchId=224)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testIncrementalInserts (batchId=224)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testIncrementalLoad (batchId=224)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testIncrementalLoadWithVariableLengthEventId (batchId=224)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testIncrementalRepeatEventOnExistingObject (batchId=224)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testIncrementalRepeatEventOnMissingObject (batchId=224)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testInsertOverwriteOnUnpartitionedTableWithCM (batchId=224)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testInsertToMultiKeyPartition (batchId=224)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testRemoveStats (batchId=224)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testRenamePartitionedTableAcrossDatabases (batchId=224)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testRenameTableAcrossDatabases (batchId=224)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testRenameTableWithCM (batchId=224)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testTruncatePartitionedTable (batchId=224)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testTruncateTable (batchId=224)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testTruncateWithCM (batchId=224)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testViewsReplication (batchId=224)
org.apache.hive.hcatalog.api.TestHCatClient.testDatabaseLocation (batchId=185)
org.apache.hive.hcatalog.hbase.TestPigHBaseStorageHandler.testPigFilterProjection (batchId=238)
org.apache.hive.hcatalog.hbase.TestPigHBaseStorageHandler.testPigPopulation (batchId=238)
org.apache.hive.hcatalog.listener.TestDbNotificationListener.cleanupNotifs (batchId=238)
org.apache.hive.hcatalog.listener.TestDbNotificationListener.createDatabase (batchId=238)
org.apache.hive.hcatalog.listener.TestDbNotificationListener.dropDatabase (batchId=238)
org.apache.hive.hcatalog.listener.TestDbNotificationListener.filter (batchId=238)
org.apache.hive.hcatalog.listener.TestDbNotificationListener.filterWithMax (batchId=238)
org.apache.hive.hcatalog.listener.TestDbNotificationListener.getOnlyMaxEvents (batchId=238)
org.apache.hive.hcatalog.streaming.TestStreaming.testAddPartition (batchId=197)
org.apache.hive.hcatalog.streaming.TestStreaming.testBucketing (batchId=197)
org.apache.hive.hcatalog.streaming.TestStreaming.testBucketingWhereBucketColIsNotFirstCol (batchId=197)
org.apache.hive.hcatalog.streaming.TestStreaming.testConcurrentTransactionBatchCommits (batchId=197)
org.apache.hive.hcatalog.streaming.TestStreaming.testEndpointConnection (batchId=197)
org.apache.hive.hcatalog.streaming.TestStreaming.testErrorHandling (batchId=197)
org.apache.hive.hcatalog.streaming.TestStreaming.testFileDump (batchId=197)
org.apache.hive.hcatalog.streaming.TestStreaming.testFileDumpCorruptDataFiles (batchId=197)
org.apache.hive.hcatalog.streaming.TestStreaming.testFileDumpCorruptSideFiles (batchId=197)
org.apache.hive.hcatalog.streaming.TestStreaming.testHeartbeat (batchId=197)
org.apache.hive.hcatalog.streaming.TestStreaming.testInterleavedTransactionBatchCommits (batchId=197)
org.apache.hive.hcatalog.streaming.TestStreaming.testMultipleTransactionBatchCommits (batchId=197)
org.apache.hive.hcatalog.streaming.TestStreaming.testNoBuckets (batchId=197)
org.apache.hive.hcatalog.streaming.TestStreaming.testRemainingTransactions (batchId=197)
org.apache.hive.hcatalog.streaming.TestStreaming.testStreamBucketingMatchesRegularBucketing (batchId=197)
org.apache.hive.hcatalog.streaming.TestStreaming.testTableValidation (batchId=197)
org.apache.hive.hcatalog.streaming.TestStreaming.testTimeOutReaper (batchId=197)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchAbort (batchId=197)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchAbortAndCommit (batchId=197)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_Delimited (batchId=197)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_DelimitedUGI (batchId=197)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_Json (batchId=197)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_Regex (batchId=197)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_RegexUGI (batchId=197)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchEmptyAbort (batchId=197)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchEmptyCommit (batchId=197)
org.apache.hive.jdbc.TestSSL.testConnectionMismatch (batchId=230)
org.apache.hive.jdbc.TestSSL.testConnectionWrongCertCN (batchId=230)
org.apache.hive.jdbc.TestSSL.testMetastoreConnectionWrongCertCN (batchId=230)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/7971/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/7971/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-7971/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.YetusPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 82 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12898872 - PreCommit-HIVE-Build, | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
|| || || || {color:brown} Prechecks {color} ||
| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Findbugs executables are not available. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
|| || || || {color:brown} master Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  6m  8s{color} | {color:green} master passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 38s{color} | {color:green} master passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 19s{color} | {color:green} master passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m  0s{color} | {color:green} master passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 37s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 35s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 35s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} checkstyle {color} | {color:red}  0m 20s{color} | {color:red} standalone-metastore: The patch generated 1 new + 684 unchanged - 0 fixed = 685 total (was 684) {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 56s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:red}-1{color} | {color:red} asflicense {color} | {color:red}  0m 12s{color} | {color:red} The patch generated 1 ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 11m  4s{color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Optional Tests |  asflicense  javac  javadoc  findbugs  checkstyle  compile  |
| uname | Linux hiveptest-server-upstream 3.16.0-4-amd64 #1 SMP Debian 3.16.36-1+deb8u1 (2016-09-03) x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /data/hiveptest/working/yetus/dev-support/hive-personality.sh |
| git revision | master / b5ba827 |
| Default Java | 1.8.0_111 |
| checkstyle | http://104.198.109.242/logs//PreCommit-HIVE-Build-7972/yetus/diff-checkstyle-standalone-metastore.txt |
| asflicense | http://104.198.109.242/logs//PreCommit-HIVE-Build-7972/yetus/patch-asflicense-problems.txt |
| modules | C: standalone-metastore U: standalone-metastore |
| Console output | http://104.198.109.242/logs//PreCommit-HIVE-Build-7972/yetus.txt |
| Powered by | Apache Yetus    http://yetus.apache.org |


This message was automatically generated.

, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12898872/HIVE-16950.2.patch

{color:red}ERROR:{color} -1 due to no test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 82 failed/errored test(s), 11410 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[alter_change_db_location] (batchId=8)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[dbtxnmgr_showlocks] (batchId=77)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[hybridgrace_hashjoin_2] (batchId=154)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[insert_values_orig_table_use_metadata] (batchId=162)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[llap_acid_fast] (batchId=157)
org.apache.hadoop.hive.metastore.TestEmbeddedHiveMetaStore.testDatabaseLocation (batchId=212)
org.apache.hadoop.hive.metastore.TestFilterHooks.testDefaultFilter (batchId=211)
org.apache.hadoop.hive.metastore.TestFilterHooks.testDummyFilterForPartition (batchId=211)
org.apache.hadoop.hive.metastore.TestRemoteHiveMetaStore.testDatabaseLocation (batchId=214)
org.apache.hadoop.hive.metastore.TestSetUGIOnBothClientServer.testDatabaseLocation (batchId=210)
org.apache.hadoop.hive.metastore.TestSetUGIOnOnlyClient.testDatabaseLocation (batchId=209)
org.apache.hadoop.hive.metastore.TestSetUGIOnOnlyServer.testDatabaseLocation (batchId=219)
org.apache.hadoop.hive.ql.parse.TestCopyUtils.testPrivilegedDistCpWithSameUserAsCurrentDoesNotTryToImpersonate (batchId=224)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testAlters (batchId=224)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testBasic (batchId=224)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testBasicWithCM (batchId=224)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testBootstrapWithConcurrentDropTable (batchId=224)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testBootstrapWithConcurrentRename (batchId=224)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testCMConflict (batchId=224)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testConcatenatePartitionedTable (batchId=224)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testConcatenateTable (batchId=224)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testConstraints (batchId=224)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testDrops (batchId=224)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testDropsWithCM (batchId=224)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testDumpLimit (batchId=224)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testExchangePartition (batchId=224)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testIdempotentMoveTaskForInsertFiles (batchId=224)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testIncrementalAdds (batchId=224)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testIncrementalInsertDropUnpartitionedTable (batchId=224)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testIncrementalInserts (batchId=224)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testIncrementalLoad (batchId=224)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testIncrementalLoadWithVariableLengthEventId (batchId=224)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testIncrementalRepeatEventOnExistingObject (batchId=224)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testIncrementalRepeatEventOnMissingObject (batchId=224)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testInsertOverwriteOnUnpartitionedTableWithCM (batchId=224)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testInsertToMultiKeyPartition (batchId=224)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testRemoveStats (batchId=224)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testRenamePartitionedTableAcrossDatabases (batchId=224)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testRenameTableAcrossDatabases (batchId=224)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testRenameTableWithCM (batchId=224)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testTruncatePartitionedTable (batchId=224)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testTruncateTable (batchId=224)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testTruncateWithCM (batchId=224)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testViewsReplication (batchId=224)
org.apache.hive.hcatalog.api.TestHCatClient.testDatabaseLocation (batchId=185)
org.apache.hive.hcatalog.hbase.TestPigHBaseStorageHandler.testPigFilterProjection (batchId=238)
org.apache.hive.hcatalog.hbase.TestPigHBaseStorageHandler.testPigPopulation (batchId=238)
org.apache.hive.hcatalog.listener.TestDbNotificationListener.cleanupNotifs (batchId=238)
org.apache.hive.hcatalog.listener.TestDbNotificationListener.createDatabase (batchId=238)
org.apache.hive.hcatalog.listener.TestDbNotificationListener.dropDatabase (batchId=238)
org.apache.hive.hcatalog.listener.TestDbNotificationListener.filter (batchId=238)
org.apache.hive.hcatalog.listener.TestDbNotificationListener.filterWithMax (batchId=238)
org.apache.hive.hcatalog.listener.TestDbNotificationListener.getOnlyMaxEvents (batchId=238)
org.apache.hive.hcatalog.streaming.TestStreaming.testAddPartition (batchId=197)
org.apache.hive.hcatalog.streaming.TestStreaming.testBucketing (batchId=197)
org.apache.hive.hcatalog.streaming.TestStreaming.testBucketingWhereBucketColIsNotFirstCol (batchId=197)
org.apache.hive.hcatalog.streaming.TestStreaming.testConcurrentTransactionBatchCommits (batchId=197)
org.apache.hive.hcatalog.streaming.TestStreaming.testEndpointConnection (batchId=197)
org.apache.hive.hcatalog.streaming.TestStreaming.testErrorHandling (batchId=197)
org.apache.hive.hcatalog.streaming.TestStreaming.testFileDump (batchId=197)
org.apache.hive.hcatalog.streaming.TestStreaming.testFileDumpCorruptDataFiles (batchId=197)
org.apache.hive.hcatalog.streaming.TestStreaming.testFileDumpCorruptSideFiles (batchId=197)
org.apache.hive.hcatalog.streaming.TestStreaming.testHeartbeat (batchId=197)
org.apache.hive.hcatalog.streaming.TestStreaming.testInterleavedTransactionBatchCommits (batchId=197)
org.apache.hive.hcatalog.streaming.TestStreaming.testMultipleTransactionBatchCommits (batchId=197)
org.apache.hive.hcatalog.streaming.TestStreaming.testNoBuckets (batchId=197)
org.apache.hive.hcatalog.streaming.TestStreaming.testRemainingTransactions (batchId=197)
org.apache.hive.hcatalog.streaming.TestStreaming.testStreamBucketingMatchesRegularBucketing (batchId=197)
org.apache.hive.hcatalog.streaming.TestStreaming.testTableValidation (batchId=197)
org.apache.hive.hcatalog.streaming.TestStreaming.testTimeOutReaper (batchId=197)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchAbort (batchId=197)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchAbortAndCommit (batchId=197)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_Delimited (batchId=197)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_DelimitedUGI (batchId=197)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_Json (batchId=197)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_Regex (batchId=197)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_RegexUGI (batchId=197)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchEmptyAbort (batchId=197)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchEmptyCommit (batchId=197)
org.apache.hive.jdbc.TestSSL.testConnectionMismatch (batchId=230)
org.apache.hive.jdbc.TestSSL.testConnectionWrongCertCN (batchId=230)
org.apache.hive.jdbc.TestSSL.testMetastoreConnectionWrongCertCN (batchId=230)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/7972/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/7972/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-7972/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.YetusPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 82 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12898872 - PreCommit-HIVE-Build, Hi all.

 

Let's discuss some ideas about this issue. When I have implemented verification for tables (check if table folder exists before creation of a table, and if yes - throw an exception), I have faced some problems here:
 # SemanticAnalyzer uses temp tables placed in one folder, so it starts to fail in INSERT operations.
 # Customers may want to create external tables with existing data/folders to escape from data copying.

 

So I  have added two exceptions: temporary and external tables may use the same folder. Even in that case I have some tests failed (e.g.

org.apache.hive.hcatalog.api.repl.commands.TestCommands.testBasicReplEximCommands). Import command does not work with the fix for tables:

 
{code:java}
hive> export table student to '/user/mysudent';
hive> import table imported_student from '/user/mysudent';
{code}
results with
{code:java}
FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. InvalidObjectException(message:Failed to create table. Table directory already exists
{code}
So my suggestion is to implement fix for databases but not for the tables. Any ideas?

 , Hello [~osayankin]

1. I guess that would be about the virtual tables which are being used during {{values (1)}} clauses
2. I think for external tables the existance of the directory should be required.

And export/import is even more problematic...
I think that for tables we may probably also consider to "check" that what we are dropping "looks" like a table or not...MSCK already does some checks like that during loading new partitions...this would be less robust than the other check; but could prevent other kind of "misues"....

For now and for this ticket; I think fixing this issue for databases is already a step forward.

Regarding the existing patch#2: it looks good to me; but that extra return in {{exists()}} is not neccessary; and I think {{FileUtils}} might be a better home for this new method...and also a testcase would be good., {quote}
but that extra return in {{exists()}} is not necessary;
{quote}
Re-factored.

{quote}
and also a testcase would be good.
{quote}

Added. See patch #3.

 

 , | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
|| || || || {color:brown} Prechecks {color} ||
| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Findbugs executables are not available. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
|| || || || {color:brown} master Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  1m 31s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  5m 29s{color} | {color:green} master passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m 17s{color} | {color:green} master passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 41s{color} | {color:green} master passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m  7s{color} | {color:green} master passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 23s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m 17s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m 12s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  1m 12s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} checkstyle {color} | {color:red}  0m 23s{color} | {color:red} standalone-metastore: The patch generated 2 new + 729 unchanged - 0 fixed = 731 total (was 729) {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m  8s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 12s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 15m 32s{color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Optional Tests |  asflicense  javac  javadoc  findbugs  checkstyle  compile  |
| uname | Linux hiveptest-server-upstream 3.16.0-4-amd64 #1 SMP Debian 3.16.36-1+deb8u1 (2016-09-03) x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /data/hiveptest/working/yetus/dev-support/hive-personality.sh |
| git revision | master / fbb3ed1 |
| Default Java | 1.8.0_111 |
| checkstyle | http://104.198.109.242/logs//PreCommit-HIVE-Build-8657/yetus/diff-checkstyle-standalone-metastore.txt |
| modules | C: standalone-metastore hcatalog/webhcat/java-client hcatalog/streaming U: . |
| Console output | http://104.198.109.242/logs//PreCommit-HIVE-Build-8657/yetus.txt |
| Powered by | Apache Yetus    http://yetus.apache.org |


This message was automatically generated.

, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12906222/HIVE-16950.3.patch

{color:green}SUCCESS:{color} +1 due to 3 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 66 failed/errored test(s), 11625 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[alter_change_db_location] (batchId=8)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[mapjoin_hook] (batchId=12)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[ppd_join5] (batchId=35)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[llap_smb] (batchId=151)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[bucket_map_join_tez1] (batchId=170)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[insert_values_orig_table_use_metadata] (batchId=165)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[llap_acid] (batchId=169)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[llap_acid_fast] (batchId=160)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[mergejoin] (batchId=165)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[sysdb] (batchId=160)
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[authorization_part] (batchId=94)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[ppd_join5] (batchId=121)
org.apache.hadoop.hive.metastore.TestEmbeddedHiveMetaStore.testDatabaseLocation (batchId=205)
org.apache.hadoop.hive.metastore.TestRemoteHiveMetaStore.testDatabaseLocation (batchId=207)
org.apache.hadoop.hive.metastore.TestSetUGIOnBothClientServer.testDatabaseLocation (batchId=204)
org.apache.hadoop.hive.metastore.TestSetUGIOnOnlyClient.testDatabaseLocation (batchId=203)
org.apache.hadoop.hive.metastore.TestSetUGIOnOnlyServer.testDatabaseLocation (batchId=211)
org.apache.hadoop.hive.metastore.client.TestDatabases.testDropDatabaseDeleteData[Embedded] (batchId=206)
org.apache.hadoop.hive.metastore.client.TestDatabases.testDropDatabaseDeleteData[Remote] (batchId=206)
org.apache.hadoop.hive.ql.io.TestDruidRecordWriter.testWrite (batchId=254)
org.apache.hadoop.hive.ql.parse.TestCopyUtils.testPrivilegedDistCpWithSameUserAsCurrentDoesNotTryToImpersonate (batchId=226)
org.apache.hadoop.hive.ql.parse.TestReplicationOnHDFSEncryptedZones.targetAndSourceHaveDifferentEncryptionZoneKeys (batchId=226)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testBasic (batchId=226)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testBasicWithCM (batchId=226)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testBootstrapWithConcurrentDropTable (batchId=226)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testBootstrapWithConcurrentRename (batchId=226)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testCMConflict (batchId=226)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testConcatenatePartitionedTable (batchId=226)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testConcatenateTable (batchId=226)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testConstraints (batchId=226)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testDropPartitionEventWithPartitionOnTimestampColumn (batchId=226)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testDrops (batchId=226)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testDropsWithCM (batchId=226)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testDumpLimit (batchId=226)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testExchangePartition (batchId=226)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testIdempotentMoveTaskForInsertFiles (batchId=226)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testIncrementalAdds (batchId=226)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testIncrementalInsertDropUnpartitionedTable (batchId=226)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testIncrementalInserts (batchId=226)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testIncrementalLoad (batchId=226)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testIncrementalLoadWithVariableLengthEventId (batchId=226)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testIncrementalRepeatEventOnExistingObject (batchId=226)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testIncrementalRepeatEventOnMissingObject (batchId=226)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testInsertOverwriteOnUnpartitionedTableWithCM (batchId=226)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testInsertToMultiKeyPartition (batchId=226)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testRemoveStats (batchId=226)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testRenamePartitionedTableAcrossDatabases (batchId=226)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testRenameTableAcrossDatabases (batchId=226)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testRenameTableWithCM (batchId=226)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testTableAlters (batchId=226)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testTruncatePartitionedTable (batchId=226)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testTruncateTable (batchId=226)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testTruncateWithCM (batchId=226)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testViewsReplication (batchId=226)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testWithStringPartitionSpecialChars (batchId=226)
org.apache.hive.hcatalog.hbase.TestPigHBaseStorageHandler.testPigFilterProjection (batchId=240)
org.apache.hive.hcatalog.hbase.TestPigHBaseStorageHandler.testPigPopulation (batchId=240)
org.apache.hive.hcatalog.listener.TestDbNotificationListener.cleanupNotifs (batchId=240)
org.apache.hive.hcatalog.listener.TestDbNotificationListener.createDatabase (batchId=240)
org.apache.hive.hcatalog.listener.TestDbNotificationListener.dropDatabase (batchId=240)
org.apache.hive.hcatalog.listener.TestDbNotificationListener.filter (batchId=240)
org.apache.hive.hcatalog.listener.TestDbNotificationListener.filterWithMax (batchId=240)
org.apache.hive.hcatalog.listener.TestDbNotificationListener.getOnlyMaxEvents (batchId=240)
org.apache.hive.jdbc.TestSSL.testConnectionMismatch (batchId=232)
org.apache.hive.jdbc.TestSSL.testConnectionWrongCertCN (batchId=232)
org.apache.hive.jdbc.TestSSL.testMetastoreConnectionWrongCertCN (batchId=232)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/8657/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/8657/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-8657/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.YetusPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 66 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12906222 - PreCommit-HIVE-Build, [~kgyrtkirk], please take a look at the last patch., changes look good; and its great that its tested at junit level!
but unfortunately there are still some tests which are failing...
{{alter_change_db_location.q}} is definetly related; since it creates a db at {{/tmp/}} ; and it looks like there are also some broken replication tests in {{TestReplicationScenarios}} - I would guess that probably replication needs an if to be squeezed in somewhere :D
note: try to go thru the failing tests with age=1 ; those are very likely have been broken by the actual patch
https://builds.apache.org/job/PreCommit-HIVE-Build/8657/testReport/, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12907564/HIVE-16950.4.patch

{color:red}ERROR:{color} -1 due to build exiting with an error

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/8838/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/8838/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-8838/

Messages:
{noformat}
**** This message was trimmed, see log for full details ****
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar(javax/servlet/Filter.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar(javax/servlet/FilterChain.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar(javax/servlet/FilterConfig.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar(javax/servlet/ServletException.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar(javax/servlet/ServletRequest.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar(javax/servlet/ServletResponse.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar(javax/servlet/annotation/WebFilter.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar(javax/servlet/http/HttpServletRequest.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar(javax/servlet/http/HttpServletResponse.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/apache-github-source-source/classification/target/hive-classification-3.0.0-SNAPSHOT.jar(org/apache/hadoop/hive/common/classification/InterfaceAudience$LimitedPrivate.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/apache-github-source-source/classification/target/hive-classification-3.0.0-SNAPSHOT.jar(org/apache/hadoop/hive/common/classification/InterfaceStability$Unstable.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/io/ByteArrayOutputStream.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/io/OutputStream.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/io/Closeable.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/AutoCloseable.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/io/Flushable.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(javax/xml/bind/annotation/XmlRootElement.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/commons/commons-exec/1.1/commons-exec-1.1.jar(org/apache/commons/exec/ExecuteException.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/security/PrivilegedExceptionAction.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/util/concurrent/ExecutionException.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/util/concurrent/TimeoutException.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-common/3.0.0-beta1/hadoop-common-3.0.0-beta1.jar(org/apache/hadoop/fs/FileSystem.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/apache-github-source-source/shims/common/target/hive-shims-common-3.0.0-SNAPSHOT.jar(org/apache/hadoop/hive/shims/HadoopShimsSecure.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/apache-github-source-source/shims/common/target/hive-shims-common-3.0.0-SNAPSHOT.jar(org/apache/hadoop/hive/shims/ShimLoader.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/apache-github-source-source/shims/common/target/hive-shims-common-3.0.0-SNAPSHOT.jar(org/apache/hadoop/hive/shims/HadoopShims.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/apache-github-source-source/shims/common/target/hive-shims-common-3.0.0-SNAPSHOT.jar(org/apache/hadoop/hive/shims/HadoopShims$WebHCatJTShim.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-common/3.0.0-beta1/hadoop-common-3.0.0-beta1.jar(org/apache/hadoop/util/ToolRunner.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/util/concurrent/CancellationException.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/util/concurrent/RejectedExecutionException.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/util/concurrent/SynchronousQueue.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/util/concurrent/ThreadPoolExecutor.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/util/concurrent/TimeUnit.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/util/concurrent/Future.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-common/3.0.0-beta1/hadoop-common-3.0.0-beta1.jar(org/apache/hadoop/conf/Configured.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-common/3.0.0-beta1/hadoop-common-3.0.0-beta1.jar(org/apache/hadoop/io/NullWritable.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-common/3.0.0-beta1/hadoop-common-3.0.0-beta1.jar(org/apache/hadoop/io/Text.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-mapreduce-client-core/3.0.0-beta1/hadoop-mapreduce-client-core-3.0.0-beta1.jar(org/apache/hadoop/mapred/JobClient.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-mapreduce-client-core/3.0.0-beta1/hadoop-mapreduce-client-core-3.0.0-beta1.jar(org/apache/hadoop/mapred/JobConf.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-mapreduce-client-core/3.0.0-beta1/hadoop-mapreduce-client-core-3.0.0-beta1.jar(org/apache/hadoop/mapreduce/Job.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-mapreduce-client-core/3.0.0-beta1/hadoop-mapreduce-client-core-3.0.0-beta1.jar(org/apache/hadoop/mapreduce/JobID.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-mapreduce-client-core/3.0.0-beta1/hadoop-mapreduce-client-core-3.0.0-beta1.jar(org/apache/hadoop/mapreduce/lib/output/NullOutputFormat.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-mapreduce-client-core/3.0.0-beta1/hadoop-mapreduce-client-core-3.0.0-beta1.jar(org/apache/hadoop/mapreduce/security/token/delegation/DelegationTokenIdentifier.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-common/3.0.0-beta1/hadoop-common-3.0.0-beta1.jar(org/apache/hadoop/security/token/Token.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-common/3.0.0-beta1/hadoop-common-3.0.0-beta1.jar(org/apache/hadoop/util/Tool.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/thrift/libthrift/0.9.3/libthrift-0.9.3.jar(org/apache/thrift/TException.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-common/3.0.0-beta1/hadoop-common-3.0.0-beta1.jar(org/apache/hadoop/conf/Configurable.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/util/concurrent/Callable.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/InterruptedException.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/Boolean.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/ClassNotFoundException.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/apache-github-source-source/ql/target/hive-exec-3.0.0-SNAPSHOT.jar(org/apache/hadoop/hive/ql/ErrorMsg.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/Integer.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar(org/apache/commons/logging/Log.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar(org/apache/commons/logging/LogFactory.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-mapreduce-client-core/3.0.0-beta1/hadoop-mapreduce-client-core-3.0.0-beta1.jar(org/apache/hadoop/mapred/JobStatus.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-mapreduce-client-core/3.0.0-beta1/hadoop-mapreduce-client-core-3.0.0-beta1.jar(org/apache/hadoop/mapred/JobProfile.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/Long.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/apache-github-source-source/common/target/hive-common-3.0.0-SNAPSHOT.jar(org/apache/hadoop/hive/common/JavaUtils.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/io/FileNotFoundException.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/net/URISyntaxException.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/net/URI.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/apache-github-source-source/standalone-metastore/target/hive-standalone-metastore-3.0.0-SNAPSHOT.jar(org/apache/hadoop/hive/metastore/api/MetaException.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-common/3.0.0-beta1/hadoop-common-3.0.0-beta1.jar(org/apache/hadoop/security/Credentials.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/net/InetAddress.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/net/UnknownHostException.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/text/MessageFormat.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/util/regex/Matcher.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/util/regex/Pattern.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/javax/ws/rs/javax.ws.rs-api/2.0.1/javax.ws.rs-api-2.0.1.jar(javax/ws/rs/DELETE.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/javax/ws/rs/javax.ws.rs-api/2.0.1/javax.ws.rs-api-2.0.1.jar(javax/ws/rs/FormParam.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/javax/ws/rs/javax.ws.rs-api/2.0.1/javax.ws.rs-api-2.0.1.jar(javax/ws/rs/GET.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/javax/ws/rs/javax.ws.rs-api/2.0.1/javax.ws.rs-api-2.0.1.jar(javax/ws/rs/POST.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/javax/ws/rs/javax.ws.rs-api/2.0.1/javax.ws.rs-api-2.0.1.jar(javax/ws/rs/PUT.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/javax/ws/rs/javax.ws.rs-api/2.0.1/javax.ws.rs-api-2.0.1.jar(javax/ws/rs/Path.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/javax/ws/rs/javax.ws.rs-api/2.0.1/javax.ws.rs-api-2.0.1.jar(javax/ws/rs/PathParam.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/javax/ws/rs/javax.ws.rs-api/2.0.1/javax.ws.rs-api-2.0.1.jar(javax/ws/rs/Produces.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/javax/ws/rs/javax.ws.rs-api/2.0.1/javax.ws.rs-api-2.0.1.jar(javax/ws/rs/QueryParam.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/javax/ws/rs/javax.ws.rs-api/2.0.1/javax.ws.rs-api-2.0.1.jar(javax/ws/rs/core/Context.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/javax/ws/rs/javax.ws.rs-api/2.0.1/javax.ws.rs-api-2.0.1.jar(javax/ws/rs/core/SecurityContext.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/javax/ws/rs/javax.ws.rs-api/2.0.1/javax.ws.rs-api-2.0.1.jar(javax/ws/rs/core/UriInfo.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/commons-lang/commons-lang/2.6/commons-lang-2.6.jar(org/apache/commons/lang/StringUtils.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-common/3.0.0-beta1/hadoop-common-3.0.0-beta1.jar(org/apache/hadoop/fs/FileStatus.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar(com/sun/jersey/api/wadl/config/WadlGeneratorConfig.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar(com/sun/jersey/api/wadl/config/WadlGeneratorDescription.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar(com/sun/jersey/server/wadl/generators/resourcedoc/WadlGeneratorResourceDocSupport.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/io/BufferedReader.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/io/InputStream.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/io/InputStreamReader.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/io/PrintWriter.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/util/Map$Entry.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/util/concurrent/Semaphore.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/commons/commons-exec/1.1/commons-exec-1.1.jar(org/apache/commons/exec/CommandLine.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/commons/commons-exec/1.1/commons-exec-1.1.jar(org/apache/commons/exec/DefaultExecutor.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/commons/commons-exec/1.1/commons-exec-1.1.jar(org/apache/commons/exec/ExecuteWatchdog.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/commons/commons-exec/1.1/commons-exec-1.1.jar(org/apache/commons/exec/PumpStreamHandler.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-common/3.0.0-beta1/hadoop-common-3.0.0-beta1.jar(org/apache/hadoop/util/Shell.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/Thread.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/Runnable.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/javax/ws/rs/javax.ws.rs-api/2.0.1/javax.ws.rs-api-2.0.1.jar(javax/ws/rs/ext/ExceptionMapper.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/javax/ws/rs/javax.ws.rs-api/2.0.1/javax.ws.rs-api-2.0.1.jar(javax/ws/rs/ext/Provider.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar(com/sun/jersey/api/NotFoundException.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-mapreduce-client-core/3.0.0-beta1/hadoop-mapreduce-client-core-3.0.0-beta1.jar(org/apache/hadoop/mapred/JobID.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-common/3.0.0-beta1/hadoop-common-3.0.0-beta1.jar(org/apache/hadoop/security/Groups.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/util/HashSet.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/util/Set.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/util/concurrent/ConcurrentHashMap.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/apache-github-source-source/common/target/hive-common-3.0.0-SNAPSHOT.jar(org/apache/hive/common/util/HiveVersionInfo.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/apache-github-source-source/classification/target/hive-classification-3.0.0-SNAPSHOT.jar(org/apache/hadoop/hive/common/classification/InterfaceStability$Evolving.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/io/DataInput.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/io/DataOutput.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-mapreduce-client-core/3.0.0-beta1/hadoop-mapreduce-client-core-3.0.0-beta1.jar(org/apache/hadoop/mapreduce/InputSplit.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/curator/curator-framework/2.12.0/curator-framework-2.12.0.jar(org/apache/curator/framework/CuratorFramework.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar(org/apache/zookeeper/CreateMode.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar(org/apache/zookeeper/KeeperException.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar(org/apache/zookeeper/ZooDefs.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar(org/apache/zookeeper/ZooDefs$Ids.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/io/OutputStreamWriter.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/net/URLConnection.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-mapreduce-client-core/3.0.0-beta1/hadoop-mapreduce-client-core-3.0.0-beta1.jar(org/apache/hadoop/mapred/RunningJob.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/util/StringTokenizer.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/Process.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/StringBuilder.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-mapreduce-client-core/3.0.0-beta1/hadoop-mapreduce-client-core-3.0.0-beta1.jar(org/apache/hadoop/mapreduce/InputFormat.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-mapreduce-client-core/3.0.0-beta1/hadoop-mapreduce-client-core-3.0.0-beta1.jar(org/apache/hadoop/mapreduce/JobContext.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-mapreduce-client-core/3.0.0-beta1/hadoop-mapreduce-client-core-3.0.0-beta1.jar(org/apache/hadoop/mapreduce/RecordReader.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-mapreduce-client-core/3.0.0-beta1/hadoop-mapreduce-client-core-3.0.0-beta1.jar(org/apache/hadoop/mapreduce/TaskAttemptContext.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/curator/curator-framework/2.12.0/curator-framework-2.12.0.jar(org/apache/curator/framework/CuratorFrameworkFactory.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/curator/curator-client/2.12.0/curator-client-2.12.0.jar(org/apache/curator/retry/ExponentialBackoffRetry.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-mapreduce-client-core/3.0.0-beta1/hadoop-mapreduce-client-core-3.0.0-beta1.jar(org/apache/hadoop/mapreduce/Mapper.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/util/Iterator.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/util/LinkedList.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/util/concurrent/ExecutorService.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/util/concurrent/Executors.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-mapreduce-client-core/3.0.0-beta1/hadoop-mapreduce-client-core-3.0.0-beta1.jar(org/apache/hadoop/mapreduce/Mapper$Context.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/net/URLDecoder.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/util/Enumeration.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/util/Properties.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/apache-github-source-source/common/target/hive-common-3.0.0-SNAPSHOT.jar(org/apache/hadoop/hive/common/LogUtils.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/Class.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-annotations/3.0.0-beta1/hadoop-annotations-3.0.0-beta1.jar(org/apache/hadoop/classification/InterfaceAudience.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-annotations/3.0.0-beta1/hadoop-annotations-3.0.0-beta1.jar(org/apache/hadoop/classification/InterfaceAudience$LimitedPrivate.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/annotation/Annotation.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/eclipse/jetty/jetty-util/9.3.19.v20170502/jetty-util-9.3.19.v20170502.jar(org/eclipse/jetty/util/annotation/ManagedObject.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/eclipse/jetty/jetty-util/9.3.19.v20170502/jetty-util-9.3.19.v20170502.jar(org/eclipse/jetty/util/annotation/ManagedAttribute.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/eclipse/jetty/jetty-util/9.3.19.v20170502/jetty-util-9.3.19.v20170502.jar(org/eclipse/jetty/util/annotation/ManagedOperation.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/eclipse/jetty/jetty-util/9.3.19.v20170502/jetty-util-9.3.19.v20170502.jar(org/eclipse/jetty/util/annotation/Name.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/annotation/Target.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/annotation/ElementType.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/annotation/Retention.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/annotation/RetentionPolicy.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/Override.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/SuppressWarnings.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/javax/ws/rs/javax.ws.rs-api/2.0.1/javax.ws.rs-api-2.0.1.jar(javax/ws/rs/HttpMethod.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(sun/misc/Contended.class)]]
[loading RegularFileObject[/data/hiveptest/working/apache-github-source-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/ListDelegator$2.class]]
[loading RegularFileObject[/data/hiveptest/working/apache-github-source-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/HcatException$1.class]]
[loading RegularFileObject[/data/hiveptest/working/apache-github-source-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/ListDelegator$1.class]]
[loading RegularFileObject[/data/hiveptest/working/apache-github-source-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/HcatDelegator$1.class]]
[loading RegularFileObject[/data/hiveptest/working/apache-github-source-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/LauncherDelegator$2.class]]
[loading RegularFileObject[/data/hiveptest/working/apache-github-source-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/SecureProxySupport$3.class]]
[loading RegularFileObject[/data/hiveptest/working/apache-github-source-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/LauncherDelegator$1.class]]
[loading RegularFileObject[/data/hiveptest/working/apache-github-source-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/SecureProxySupport$1.class]]
[loading RegularFileObject[/data/hiveptest/working/apache-github-source-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/SecureProxySupport$2.class]]
[loading RegularFileObject[/data/hiveptest/working/apache-github-source-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/StatusDelegator$1.class]]
[loading RegularFileObject[/data/hiveptest/working/apache-github-source-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/tool/HDFSStorage$1.class]]
[loading RegularFileObject[/data/hiveptest/working/apache-github-source-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/tool/TempletonUtils$1.class]]
[loading RegularFileObject[/data/hiveptest/working/apache-github-source-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/tool/ZooKeeperStorage$1.class]]
[loading RegularFileObject[/data/hiveptest/working/apache-github-source-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob$1.class]]
[loading RegularFileObject[/data/hiveptest/working/apache-github-source-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob$1$1.class]]
[loading RegularFileObject[/data/hiveptest/working/apache-github-source-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/tool/LogRetriever$1.class]]
[done in 3394 ms]
+ [[ -d itests ]]
+ cd itests
+ mvn -B clean install -DskipTests -T 4 -q -Dmaven.repo.local=/data/hiveptest/working/maven
[ERROR] COMPILATION ERROR : 
[ERROR] /data/hiveptest/working/apache-github-source-source/itests/hcatalog-unit/src/test/java/org/apache/hive/hcatalog/listener/TestDbNotificationListener.java:[288,42] cannot find symbol
  symbol:   variable Path
  location: class org.apache.hive.hcatalog.listener.TestDbNotificationListener
[ERROR] /data/hiveptest/working/apache-github-source-source/itests/hcatalog-unit/src/test/java/org/apache/hive/hcatalog/listener/TestDbNotificationListener.java:[330,41] cannot find symbol
  symbol:   variable Path
  location: class org.apache.hive.hcatalog.listener.TestDbNotificationListener
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.6.1:testCompile (default-testCompile) on project hive-hcatalog-it-unit: Compilation failure: Compilation failure:
[ERROR] /data/hiveptest/working/apache-github-source-source/itests/hcatalog-unit/src/test/java/org/apache/hive/hcatalog/listener/TestDbNotificationListener.java:[288,42] cannot find symbol
[ERROR] symbol:   variable Path
[ERROR] location: class org.apache.hive.hcatalog.listener.TestDbNotificationListener
[ERROR] /data/hiveptest/working/apache-github-source-source/itests/hcatalog-unit/src/test/java/org/apache/hive/hcatalog/listener/TestDbNotificationListener.java:[330,41] cannot find symbol
[ERROR] symbol:   variable Path
[ERROR] location: class org.apache.hive.hcatalog.listener.TestDbNotificationListener
[ERROR] -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn <goals> -rf :hive-hcatalog-it-unit
+ exit 1
'
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12907564 - PreCommit-HIVE-Build, Deferring this to 3.1.0 since the branch for 3.0.0 has been cut off. Please update the JIRA if you would like to get your patch in 3.0.0., 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12907564/HIVE-16950.4.patch

{color:red}ERROR:{color} -1 due to build exiting with an error

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/10104/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/10104/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-10104/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Tests exited with: NonZeroExitCodeException
Command 'bash /data/hiveptest/working/scratch/source-prep.sh' failed with exit status 1 and output '+ date '+%Y-%m-%d %T.%3N'
2018-04-10 03:58:00.851
+ [[ -n /usr/lib/jvm/java-8-openjdk-amd64 ]]
+ export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
+ JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
+ export PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games
+ PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games
+ export 'ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m '
+ ANT_OPTS='-Xmx1g -XX:MaxPermSize=256m '
+ export 'MAVEN_OPTS=-Xmx1g '
+ MAVEN_OPTS='-Xmx1g '
+ cd /data/hiveptest/working/
+ tee /data/hiveptest/logs/PreCommit-HIVE-Build-10104/source-prep.txt
+ [[ false == \t\r\u\e ]]
+ mkdir -p maven ivy
+ [[ git = \s\v\n ]]
+ [[ git = \g\i\t ]]
+ [[ -z master ]]
+ [[ -d apache-github-source-source ]]
+ [[ ! -d apache-github-source-source/.git ]]
+ [[ ! -d apache-github-source-source ]]
+ date '+%Y-%m-%d %T.%3N'
2018-04-10 03:58:00.853
+ cd apache-github-source-source
+ git fetch origin
From https://github.com/apache/hive
   55fb0a1..2e92451  master     -> origin/master
   946f619..d1a9358  branch-3   -> origin/branch-3
+ git reset --hard HEAD
HEAD is now at 55fb0a1 HIVE-19143 : Update golden files for negative tests
+ git clean -f -d
+ git checkout master
Already on 'master'
Your branch is behind 'origin/master' by 1 commit, and can be fast-forwarded.
  (use "git pull" to update your local branch)
+ git reset --hard origin/master
HEAD is now at 2e92451 HIVE-18857: Store default value text instead of default value expression in metastore(Vineet Garg, reviewed by Ashutosh Chauhan)
+ git merge --ff-only origin/master
Already up-to-date.
+ date '+%Y-%m-%d %T.%3N'
2018-04-10 03:58:04.664
+ rm -rf ../yetus_PreCommit-HIVE-Build-10104
+ mkdir ../yetus_PreCommit-HIVE-Build-10104
+ git gc
+ cp -R . ../yetus_PreCommit-HIVE-Build-10104
+ mkdir /data/hiveptest/logs/PreCommit-HIVE-Build-10104/yetus
+ patchCommandPath=/data/hiveptest/working/scratch/smart-apply-patch.sh
+ patchFilePath=/data/hiveptest/working/scratch/build.patch
+ [[ -f /data/hiveptest/working/scratch/build.patch ]]
+ chmod +x /data/hiveptest/working/scratch/smart-apply-patch.sh
+ /data/hiveptest/working/scratch/smart-apply-patch.sh /data/hiveptest/working/scratch/build.patch
error: a/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/TestStreaming.java: does not exist in index
error: a/hcatalog/webhcat/java-client/src/test/java/org/apache/hive/hcatalog/api/TestHCatClient.java: does not exist in index
error: a/itests/hcatalog-unit/src/test/java/org/apache/hive/hcatalog/listener/TestDbNotificationListener.java: does not exist in index
error: a/standalone-metastore/src/main/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java: does not exist in index
error: a/standalone-metastore/src/main/java/org/apache/hadoop/hive/metastore/utils/FileUtils.java: does not exist in index
error: patch failed: standalone-metastore/src/main/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java:916
Falling back to three-way merge...
Applied patch to 'standalone-metastore/src/main/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java' with conflicts.
Going to apply patch with: git apply -p1
error: patch failed: standalone-metastore/src/main/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java:916
Falling back to three-way merge...
Applied patch to 'standalone-metastore/src/main/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java' with conflicts.
U standalone-metastore/src/main/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java
+ exit 1
'
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12907564 - PreCommit-HIVE-Build, Deferring this to 3.2.0 since the branch for 3.1.0 has been cut off., | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
|| || || || {color:brown} master Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  7m 38s{color} | {color:green} master passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 40s{color} | {color:green} master passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 20s{color} | {color:green} master passed {color} |
| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  3m  3s{color} | {color:blue} standalone-metastore in master has 228 extant Findbugs warnings. {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 53s{color} | {color:green} master passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 50s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 40s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 40s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} checkstyle {color} | {color:red}  0m 20s{color} | {color:red} standalone-metastore: The patch generated 6 new + 473 unchanged - 0 fixed = 479 total (was 473) {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  3m 12s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 55s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 12s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 19m 12s{color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Optional Tests |  asflicense  javac  javadoc  findbugs  checkstyle  compile  |
| uname | Linux hiveptest-server-upstream 3.16.0-4-amd64 #1 SMP Debian 3.16.36-1+deb8u1 (2016-09-03) x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /data/hiveptest/working/yetus_PreCommit-HIVE-Build-12211/dev-support/hive-personality.sh |
| git revision | master / 09a73bf |
| Default Java | 1.8.0_111 |
| findbugs | v3.0.0 |
| checkstyle | http://104.198.109.242/logs//PreCommit-HIVE-Build-12211/yetus/diff-checkstyle-standalone-metastore.txt |
| modules | C: standalone-metastore U: standalone-metastore |
| Console output | http://104.198.109.242/logs//PreCommit-HIVE-Build-12211/yetus.txt |
| Powered by | Apache Yetus    http://yetus.apache.org |


This message was automatically generated.

, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12929416/HIVE-16950.9.patch

{color:green}SUCCESS:{color} +1 due to 1 test(s) being added or modified.

{color:green}SUCCESS:{color} +1 due to 14614 tests passed

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/12211/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/12211/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-12211/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.YetusPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12929416 - PreCommit-HIVE-Build, +1 ; please format the patch according with the hive formatter; IIRC annotations should be in separate lines..., | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
|| || || || {color:brown} master Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  8m 24s{color} | {color:green} master passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 42s{color} | {color:green} master passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 21s{color} | {color:green} master passed {color} |
| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  3m 11s{color} | {color:blue} standalone-metastore in master has 228 extant Findbugs warnings. {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 56s{color} | {color:green} master passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 49s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 40s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 40s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} checkstyle {color} | {color:red}  0m 21s{color} | {color:red} standalone-metastore: The patch generated 1 new + 474 unchanged - 0 fixed = 475 total (was 474) {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  3m 11s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 57s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 13s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 20m  9s{color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Optional Tests |  asflicense  javac  javadoc  findbugs  checkstyle  compile  |
| uname | Linux hiveptest-server-upstream 3.16.0-4-amd64 #1 SMP Debian 3.16.36-1+deb8u1 (2016-09-03) x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /data/hiveptest/working/yetus_PreCommit-HIVE-Build-12215/dev-support/hive-personality.sh |
| git revision | master / ae008b7 |
| Default Java | 1.8.0_111 |
| findbugs | v3.0.0 |
| checkstyle | http://104.198.109.242/logs//PreCommit-HIVE-Build-12215/yetus/diff-checkstyle-standalone-metastore.txt |
| modules | C: standalone-metastore U: standalone-metastore |
| Console output | http://104.198.109.242/logs//PreCommit-HIVE-Build-12215/yetus.txt |
| Powered by | Apache Yetus    http://yetus.apache.org |


This message was automatically generated.

, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12929576/HIVE-16950.10.patch

{color:green}SUCCESS:{color} +1 due to 1 test(s) being added or modified.

{color:green}SUCCESS:{color} +1 due to 14630 tests passed

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/12215/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/12215/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-12215/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.YetusPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12929576 - PreCommit-HIVE-Build, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12929576/HIVE-16950.10.patch

{color:red}ERROR:{color} -1 due to build exiting with an error

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/12219/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/12219/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-12219/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Tests exited with: Exception: Patch URL https://issues.apache.org/jira/secure/attachment/12929576/HIVE-16950.10.patch was found in seen patch url's cache and a test was probably run already on it. Aborting...
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12929576 - PreCommit-HIVE-Build, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12929576/HIVE-16950.10.patch

{color:red}ERROR:{color} -1 due to build exiting with an error

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/12220/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/12220/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-12220/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Tests exited with: Exception: Patch URL https://issues.apache.org/jira/secure/attachment/12929576/HIVE-16950.10.patch was found in seen patch url's cache and a test was probably run already on it. Aborting...
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12929576 - PreCommit-HIVE-Build, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12929576/HIVE-16950.10.patch

{color:red}ERROR:{color} -1 due to build exiting with an error

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/12274/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/12274/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-12274/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Tests exited with: Exception: Patch URL https://issues.apache.org/jira/secure/attachment/12929576/HIVE-16950.10.patch was found in seen patch url's cache and a test was probably run already on it. Aborting...
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12929576 - PreCommit-HIVE-Build]