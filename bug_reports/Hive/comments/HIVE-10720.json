[Seems the improvement HIVE-5193 causes the issue. I may consider reverting the change and will redo later., The issue is due to ColumnProjectionUtils class is only supported for one table column projection. If the query involves multiple tables, then the later one will overwrite the previous and causes retrieving incorrect results or not retrieving any values. 

I will revert HIVE-5193 so that HCatalog will not use that class for now and do the correct column projection enhancement later., This issue is fixed in our internal code base but has not be applied to open source .
I tried running your test multiple times and with various versions of Pig (mapreduce and tez). It succeeded with returning only 1 result.

There are 2 ways of achieving this:
1) Turning off the optimizer in Pig which does the LoadPushDown or turning the optimizations off -"t -optimizer_off all"
2) Making sure the  ColumnProjectionUtils.setReadColumnIDs sets the "hive.io.file.readcolumn.ids" null when the requiredFieldsInfo is null in the backend. 

Uploading the patch for testing
Regards
Viraj
, Patch for testing, [~viraj] Thanks for your information. Your approach actually is the same as what I did in the subtasks (to revert HIVE-5193) in which we will not optimize the retrieval for column-based table. 

Such optimization, which will only retrieve required columns, is still valid since it will improve the performance.  My plan is to revert HIVE-5193 to unblock the customer and then rework the optimization part. , Sorry. Your patch actually is not a revert. Your patch will those NPE in at org.apache.hadoop.hive.serde2.ColumnProjectionUtils.toReadColumnIDString(ColumnProjectionUtils.java:190) since Ids is null.

Also for the cases that there are any projection prune, there will be still issues., Hi Aihua,
 Can you explain me how the patch I put up in this Jira will lead to loss of functionality. I am setting the 
{code}
ColumnProjectionUtils.setReadColumnIDs(job.getConfiguration(), null);
{code}
only for RequiredFieldList is null. Also let me check internally if we have some changes to ColumnProjectionUtils.

Viraj, Hey, [~aihuaxu]. Could you please post a stack-trace for the NPE?, {noformat}
java.lang.Exception: java.io.IOException: java.lang.NullPointerException
        at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:406)
Caused by: java.io.IOException: java.lang.NullPointerException
        at org.apache.hive.hcatalog.pig.HCatLoader.setLocation(HCatLoader.java:188)
        at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.mergeSplitSpecificConf(PigInputFormat.java:138)
        at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.createRecordReader(PigInputFormat.java:112)
        at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:644)
        at org.apache.hadoop.mapred.MapTask.run(MapTask.java:330)
        at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:268)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
        at java.util.concurrent.FutureTask.run(FutureTask.java:262)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.NullPointerException
        at org.apache.hadoop.hive.serde2.ColumnProjectionUtils.toReadColumnIDString(ColumnProjectionUtils.java:190)
        at org.apache.hadoop.hive.serde2.ColumnProjectionUtils.appendReadColumns(ColumnProjectionUtils.java:92)
        at org.apache.hadoop.hive.serde2.ColumnProjectionUtils.setReadColumnIDs(ColumnProjectionUtils.java:57)
        at org.apache.hive.hcatalog.pig.HCatLoader.setLocation(HCatLoader.java:183)
        ... 10 more
{noformat}, I know revert is frustrating. :) but the patch didn't consider many cases. We need to revert to unblock the customer issue since for the cases involving more than 1 table, the result could be wrong., :] Frustration aside, I'm completely open to reverting the patch if it's the right thing to do. (Incorrect results are a critical bug.) We're trying to make sure that we won't have to revert the revert.

Viraj has confirmed that there was a bug in his patch. He's uploading a new one shortly. If this doesn't sort out the issue you're facing, let's revert and postpone debate to a later time., Hi Mithun and Aihua,
 Sorry for the confusion, I posted the wrong patch. Out internal git has this instead that should not cause the NPE.. Uploading it again. Could you please retry. It should have been 
{code}
ColumnProjectionUtils.setReadAllColumns(job.getConfiguration());
{code} 

Apologize again.
Viraj, Updated patch with the right call to set the read columns,, Unfortunately your patch is not right fix and it still produces incorrect result. You can try the sample pig script I posted above. It will return the result of 
(1,value1,333,1,value1) while the correct result should be (1,value1,333,1,value2). I believe you disabled the pig optimization in-house, so it takes a different code path.

, Ok. Looks like I have held you up long enough. If you've verified that this code path works without HIVE-5193, let's roll it back, and revisit this fix in a separate JIRA. We will try identify how this works correctly on our internal branch. Viral, does that sound ok?

Sorry for the delay. I applaud your diligence and patience, Aihua. Thank you. :], Thanks for your understanding. I have a followup jira to rework on HIVE-5193. Yeah. I have verified that revert will work. Of course, upstream has an additional issue that I also have that jira as the subtask. Will try to fix it after the revert.

Thanks again., Please go ahead and revert HIVE-5193. Internally I ran the script you posted on the Jira, this is on Pig 0.11. Pig 0.14 (both Tez and M/R) and did not get the result you mentioned. I will check with Mithun on Monday and re-check this again.
Regards
Viraj, Thanks [~viraj] I updated the pig script above which you can use to check against your local repository. I ran against Pig 0.12, but seems like the version shouldn't matter.  ]