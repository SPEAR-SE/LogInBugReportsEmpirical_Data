[A simple patch to use another bash script to clean the files., [~ashutoshc] [~xuefuz] can you take a look?, [~sershe], that would be indeed a pain for developers. It takes a while to download. I'm not sure why excluding it from src.xml wouldn't work. Also, when I build with -Pdist, I don't see thirdparty directory in the package., Can it be changed to use maven for dependency management?, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12785840/HIVE-12984.patch

{color:red}ERROR:{color} -1 due to no test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 6 failed/errored test(s), 10037 tests executed
*Failed tests:*
{noformat}
TestCliDriver-create_view_partitioned.q-input0.q-groupby7_noskew_multi_single_reducer.q-and-12-more - did not produce a TEST-*.xml file
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.org.apache.hadoop.hive.cli.TestMiniTezCliDriver
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_dynamic_partition_pruning_2
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_schema_evol_orc_acidvec_mapwork_part
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_authorization_uri_import
org.apache.hive.jdbc.TestSSL.testSSLVersion
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6857/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6857/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-6857/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 6 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12785840 - PreCommit-HIVE-TRUNK-Build, I'm well open to that. However, there isn't such tarball available in the public maven repos. There might be one somewhere from Spark project, but Hive needs a version (for test) that doesn't include Hive artifacts., They actually get pulled into deployed artifacts on mvn deploy, I don't think out packaging filters can affect that. I am cutting the 4th RC now and it's kind of tiresome to delete them every time (after forgetting and noticing the source zip is 300Mb). 
Why do spark tests need to depend on the package instead of just individual jars? MiniTez and MiniMr (and MiniHdfs and MiniHBase and MiniAccumulo) all run fine with just jars. Otherwise, is it possible to file a spark JIRA to have a distribution without Hive if there's no way around it?, bq. Why do spark tests need to depend on the package instead of just individual jars? 

[~szehon] , [~xuefuz] Seems reasonable to me Any specific reason for not doing this? We can put dep on pom file for specific spark jars which are needed at runtime for tests. 
Relying on non-standard locations for jar artifacts is brittle. , The tarball contains not just jars, but also any binaries that an spark install has. Hive on Spark tests depends on this installation env.

While we could clean this up every time when "mvn clean" is triggered, the downside is that developer will bear the cost of downloading it every time if he/she does a clean build.]