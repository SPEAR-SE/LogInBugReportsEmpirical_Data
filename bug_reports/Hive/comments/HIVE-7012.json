[I am thinking about the following fix, but not sure if right:

sameKeys():

        ExprNodeDesc pexpr = pexprs.get(i);
        ExprNodeDesc cexpr = ExprNodeDescUtils.backtrack(cexprs.get(i), child, parent);
        // check if cexpr is from the parent
        if (cexpr == null || (cexpr not contained in the colExprMap of the parent operator) || !pexpr.isSame(cexpr)) {
          return null;
        }, [~sunrui] You're right. It's wrong assumption. I think there was some historical issue for things done like that. Let's see what will happen with the patch., 

{color:red}Overall{color}: -1 at least one tests failed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12643724/HIVE-7012.1.patch.txt

{color:red}ERROR:{color} -1 due to 8 failed/errored test(s), 5433 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_fetch_aggregation
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_ppd2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_reduce_deduplicate_extended
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_stats_partscan_1_23
org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_root_dir_external_table
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input20
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input4
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input5
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-Build/148/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-Build/148/console

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 8 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12643724, reduce_deduplicate_extended.q, ppd.q, fetch_aggregation.q failures might be relevant. [~navis] can you take a look?, Please ignore my previous comment, it seems your new patch takes care of those failures., In ppd2.q.out looks like new MR stage got added, looks like RS-dedup optimization got disabled for it. That looks like performance regression. Was that intentional ?, [~navis] I verified that your patch solved my problem. 

[~navis] and [~yhuai] However, I suspect that the optimizer may still have bug when there are distinct expressions. It seems that the optimizer has not taken support for distinct keys into consideration when it was being implemented. Note that keyCols in ReduceSinkDesc is composed of groupby keys and possibly distinct keys. For example, assume cRS and pRS both have KeyCols as (a, b, c, d) and numDistributionKeys=2. cRS may have distinct expressions like distinct(c, d) while pRS may have distinct expressions like distinct(c), distinct(d). In this case, they have different sort keys while their KeyCols are same. [~yhuai] what do you think?
, 

{color:red}Overall{color}: -1 at least one tests failed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12644076/HIVE-7012.2.patch.txt

{color:red}ERROR:{color} -1 due to 2 failed/errored test(s), 5503 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_stats_partscan_1_23
org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_root_dir_external_table
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-Build/174/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-Build/174/console

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 2 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12644076, [~ashutoshc] Yes, it's intended. In the query ppd2.q
{code}
select a.*
  from (
    select key, count(value) as cc
    from srcpart a
    where a.ds = '2008-04-08' and a.hr = '11'
    group by key
  )a
  distribute by a.key
  sort by a.key,a.cc desc
{code}
cc is generated field by GBY operator, so It's semantically wrong to merge the RS for GBY with any following RS. But the same time, sort on "a.cc" is meaningless so it can be removed in optimizing, but not in here (maybe in SemanticAnalyzer?).

[~sunrui] Yes, RS for distinct should be avoided from any dedup process. Could you take this issue? I think you knows better than me., +1 Issue raised by [~sunrui] if exists will probably require a different fix, which we shall take up in separate jira. , For the issue about distinct, I will investigate it later and if I can find a real test case, I will submit a separate jira., Committed to trunk. Thanks, Navis!, This has been fixed in 0.14 release. Please open new jira if you see any issues.
]