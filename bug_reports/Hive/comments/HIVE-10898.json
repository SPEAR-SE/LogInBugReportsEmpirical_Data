[[~andrew.kurochkin] I am not able to reproduce this with apache hive 0.13 or 1.2.0 .


With hive 1.2.0 -
{code}
hive> SELECT CAST("775983671874188101" as BIGINT);
OK
775983671874188101
Time taken: 0.059 seconds, Fetched: 1 row(s)
{code}

With 0.13.1 -
{code}
hive> SELECT CAST("775983671874188101" as BIGINT);
Total jobs = 1
Launching Job 1 out of 1
Number of reduce tasks is set to 0 since there's no reduce operator
Hadoop job information for null: number of mappers: 0; number of reducers: 0
2015-06-03 07:53:40,131 null map = 100%,  reduce = 0%
Ended Job = job_local238023464_0001
Execution completed successfully
MapredLocal task succeeded
OK
775983671874188101
Time taken: 7.324 seconds, Fetched: 1 row(s)
{code}
, I have constant repro for this: api calls, spark-sql shell. How can I investigate it further?, spark-sql bug is not a hive bug, can you please open a jira for spark project ?


, note that hive-on-spark (hive with spark as execution engine) is different from spark-sql (spark project having parts of hive code copied into it).

]