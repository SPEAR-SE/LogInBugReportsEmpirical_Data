[
This information is from TPC-DS 67, but I think it is probably the same problem:

The exception occurs in (vectorized) Reducer 3 fed from Map 2.

The type shown in the Explain plan for Map 2 shows _col8 as type string.
And, Reducer 3 shows _col8 as type string.  Yet, we seem to create the Vectorized Row Batch in the Tez Reduce code as Decimal?

The COALESCE in the last column of Select Operator expressions shows type decimal(18,2).
Yet, the following Group By operator shows the last column with a funny name "0" and type string.
Something is not right here.

Partial explain output from the end of Map 2:
{noformat}
                              Select Operator
                                expressions: _col3 (type: string), _col2 (type: string), _col1 (type: string), _col4 (type: string), _col12 (type: int), _col14 (type: int), _col13 (type: int), _col16 (type: string), COALESCE((_col8 * CAST( _col7 AS decimal(10,0))),0) (type: decimal(18,2))
                                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8
                                Statistics: Num rows: 915185 Data size: 1236889305 Basic stats: COMPLETE Column stats: NONE
                                Group By Operator
                                  aggregations: sum(_col8)
                                  keys: _col0 (type: string), _col1 (type: string), _col2 (type: string), _col3 (type: string), _col4 (type: int), _col5 (type: int), _col6 (type: int), _col7 (type: string), '0' (type: string)
                                  mode: hash
                                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9
                                  Statistics: Num rows: 8236665 Data size: 11132003745 Basic stats: COMPLETE Column stats: NONE
                                  Reduce Output Operator
                                    key expressions: _col0 (type: string), _col1 (type: string), _col2 (type: string), _col3 (type: string), _col4 (type: int), _col5 (type: int), _col6 (type: int), _col7 (type: string), _col8 (type: string)
                                    sort order: +++++++++
                                    Map-reduce partition columns: _col0 (type: string), _col1 (type: string), _col2 (type: string), _col3 (type: string), _col4 (type: int), _col5 (type: int), _col6 (type: int), _col7 (type: string), _col8 (type: string)
                                    Statistics: Num rows: 8236665 Data size: 11132003745 Basic stats: COMPLETE Column stats: NONE
                                    value expressions: _col9 (type: decimal(28,2))
{noformat}

Full explain output:

{noformat}
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
      Edges:
        Map 2 <- Map 1 (BROADCAST_EDGE), Map 6 (BROADCAST_EDGE), Map 7 (BROADCAST_EDGE)
        Reducer 3 <- Map 2 (SIMPLE_EDGE)
        Reducer 4 <- Reducer 3 (SIMPLE_EDGE)
        Reducer 5 <- Reducer 4 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: item
                  Statistics: Num rows: 18000 Data size: 29671008 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: i_item_sk is not null (type: boolean)
                    Statistics: Num rows: 9000 Data size: 14835504 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: i_item_sk (type: int), i_brand (type: string), i_class (type: string), i_category (type: string), i_product_name (type: string)
                      outputColumnNames: _col0, _col1, _col2, _col3, _col4
                      Statistics: Num rows: 9000 Data size: 14835504 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int)
                        sort order: +
                        Map-reduce partition columns: _col0 (type: int)
                        Statistics: Num rows: 9000 Data size: 14835504 Basic stats: COMPLETE Column stats: NONE
                        value expressions: _col1 (type: string), _col2 (type: string), _col3 (type: string), _col4 (type: string)
        Map 2 
            Map Operator Tree:
                TableScan
                  alias: store_sales
                  Statistics: Num rows: 2750370 Data size: 3717170032 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: (ss_sold_date_sk is not null and ss_item_sk is not null) (type: boolean)
                    Statistics: Num rows: 687593 Data size: 929293183 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: ss_sold_date_sk (type: int), ss_item_sk (type: int), ss_quantity (type: int), ss_sales_price (type: decimal(7,2)), ss_store_sk (type: int)
                      outputColumnNames: _col0, _col1, _col2, _col3, _col4
                      Statistics: Num rows: 687593 Data size: 929293183 Basic stats: COMPLETE Column stats: NONE
                      Map Join Operator
                        condition map:
                             Inner Join 0 to 1
                        keys:
                          0 _col0 (type: int)
                          1 _col0 (type: int)
                        outputColumnNames: _col1, _col2, _col3, _col4, _col7, _col8, _col9
                        input vertices:
                          1 Map 6
                        Statistics: Num rows: 756352 Data size: 1022222523 Basic stats: COMPLETE Column stats: NONE
                        HybridGraceHashJoin: true
                        Map Join Operator
                          condition map:
                               Inner Join 0 to 1
                          keys:
                            0 _col4 (type: int)
                            1 _col0 (type: int)
                          outputColumnNames: _col1, _col2, _col3, _col7, _col8, _col9, _col11
                          input vertices:
                            1 Map 7
                          Statistics: Num rows: 831987 Data size: 1124444799 Basic stats: COMPLETE Column stats: NONE
                          HybridGraceHashJoin: true
                          Select Operator
                            expressions: _col1 (type: int), _col11 (type: string), _col2 (type: int), _col3 (type: decimal(7,2)), _col7 (type: int), _col8 (type: int), _col9 (type: int)
                            outputColumnNames: _col1, _col11, _col2, _col3, _col7, _col8, _col9
                            Statistics: Num rows: 831987 Data size: 1124444799 Basic stats: COMPLETE Column stats: NONE
                            Map Join Operator
                              condition map:
                                   Inner Join 0 to 1
                              keys:
                                0 _col0 (type: int)
                                1 _col1 (type: int)
                              outputColumnNames: _col1, _col2, _col3, _col4, _col7, _col8, _col12, _col13, _col14, _col16
                              input vertices:
                                0 Map 1
                              Statistics: Num rows: 915185 Data size: 1236889305 Basic stats: COMPLETE Column stats: NONE
                              HybridGraceHashJoin: true
                              Select Operator
                                expressions: _col3 (type: string), _col2 (type: string), _col1 (type: string), _col4 (type: string), _col12 (type: int), _col14 (type: int), _col13 (type: int), _col16 (type: string), COALESCE((_col8 * CAST( _col7 AS decimal(10,0))),0) (type: decimal(18,2))
                                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8
                                Statistics: Num rows: 915185 Data size: 1236889305 Basic stats: COMPLETE Column stats: NONE
                                Group By Operator
                                  aggregations: sum(_col8)
                                  keys: _col0 (type: string), _col1 (type: string), _col2 (type: string), _col3 (type: string), _col4 (type: int), _col5 (type: int), _col6 (type: int), _col7 (type: string), '0' (type: string)
                                  mode: hash
                                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9
                                  Statistics: Num rows: 8236665 Data size: 11132003745 Basic stats: COMPLETE Column stats: NONE
                                  Reduce Output Operator
                                    key expressions: _col0 (type: string), _col1 (type: string), _col2 (type: string), _col3 (type: string), _col4 (type: int), _col5 (type: int), _col6 (type: int), _col7 (type: string), _col8 (type: string)
                                    sort order: +++++++++
                                    Map-reduce partition columns: _col0 (type: string), _col1 (type: string), _col2 (type: string), _col3 (type: string), _col4 (type: int), _col5 (type: int), _col6 (type: int), _col7 (type: string), _col8 (type: string)
                                    Statistics: Num rows: 8236665 Data size: 11132003745 Basic stats: COMPLETE Column stats: NONE
                                    value expressions: _col9 (type: decimal(28,2))
        Map 6 
            Map Operator Tree:
                TableScan
                  alias: date_dim
                  Statistics: Num rows: 73049 Data size: 81741831 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: (d_month_seq BETWEEN 1176 AND 1187 and d_date_sk is not null) (type: boolean)
                    Statistics: Num rows: 18262 Data size: 20435178 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: d_date_sk (type: int), d_year (type: int), d_moy (type: int), d_qoy (type: int)
                      outputColumnNames: _col0, _col2, _col3, _col4
                      Statistics: Num rows: 18262 Data size: 20435178 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int)
                        sort order: +
                        Map-reduce partition columns: _col0 (type: int)
                        Statistics: Num rows: 18262 Data size: 20435178 Basic stats: COMPLETE Column stats: NONE
                        value expressions: _col2 (type: int), _col3 (type: int), _col4 (type: int)
        Map 7 
            Map Operator Tree:
                TableScan
                  alias: store
                  Statistics: Num rows: 12 Data size: 25632 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: s_store_sk is not null (type: boolean)
                    Statistics: Num rows: 6 Data size: 12816 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: s_store_sk (type: int), s_store_id (type: string)
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 6 Data size: 12816 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int)
                        sort order: +
                        Map-reduce partition columns: _col0 (type: int)
                        Statistics: Num rows: 6 Data size: 12816 Basic stats: COMPLETE Column stats: NONE
                        value expressions: _col1 (type: string)
                      Select Operator
                        expressions: _col0 (type: int)
                        outputColumnNames: _col0
                        Statistics: Num rows: 6 Data size: 12816 Basic stats: COMPLETE Column stats: NONE
                        Group By Operator
                          keys: _col0 (type: int)
                          mode: hash
                          outputColumnNames: _col0
                          Statistics: Num rows: 6 Data size: 12816 Basic stats: COMPLETE Column stats: NONE
                          Dynamic Partitioning Event Operator
                            Target Input: store_sales
                            Partition key expr: ss_store_sk
                            Statistics: Num rows: 6 Data size: 12816 Basic stats: COMPLETE Column stats: NONE
                            Target column: ss_store_sk
                            Target Vertex: Map 2
        Reducer 3 
            Reduce Operator Tree:
              Group By Operator
                aggregations: sum(VALUE._col0)
                keys: KEY._col0 (type: string), KEY._col1 (type: string), KEY._col2 (type: string), KEY._col3 (type: string), KEY._col4 (type: int), KEY._col5 (type: int), KEY._col6 (type: int), KEY._col7 (type: string), KEY._col8 (type: string)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col9
                Statistics: Num rows: 4118332 Data size: 5566001196 Basic stats: COMPLETE Column stats: NONE
                pruneGroupingSetId: true
                Reduce Output Operator
                  key expressions: _col0 (type: string), _col9 (type: decimal(28,2))
                  sort order: +-
                  Map-reduce partition columns: _col0 (type: string)
                  Statistics: Num rows: 4118332 Data size: 5566001196 Basic stats: COMPLETE Column stats: NONE
                  value expressions: _col1 (type: string), _col2 (type: string), _col3 (type: string), _col4 (type: int), _col5 (type: int), _col6 (type: int), _col7 (type: string), _col9 (type: decimal(28,2))
        Reducer 4 
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: string), VALUE._col0 (type: string), VALUE._col1 (type: string), VALUE._col2 (type: string), VALUE._col3 (type: int), VALUE._col4 (type: int), VALUE._col5 (type: int), VALUE._col6 (type: string), VALUE._col8 (type: decimal(28,2))
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col9
                Statistics: Num rows: 4118332 Data size: 5566001196 Basic stats: COMPLETE Column stats: NONE
                PTF Operator
                  Function definitions:
                      Input definition
                        input alias: ptf_0
                        output shape: _col0: string, _col1: string, _col2: string, _col3: string, _col4: int, _col5: int, _col6: int, _col7: string, _col9: decimal(28,2)
                        type: WINDOWING
                      Windowing table definition
                        input alias: ptf_1
                        name: windowingtablefunction
                        order by: _col9(DESC)
                        partition by: _col0
                        raw input shape:
                        window functions:
                            window function definition
                              alias: rank_window_0
                              arguments: _col9
                              name: rank
                              window function: GenericUDAFRankEvaluator
                              window frame: PRECEDING(MAX)~FOLLOWING(MAX)
                              isPivotResult: true
                  Statistics: Num rows: 4118332 Data size: 5566001196 Basic stats: COMPLETE Column stats: NONE
                  Filter Operator
                    predicate: (rank_window_0 <= 100) (type: boolean)
                    Statistics: Num rows: 1372777 Data size: 1855333281 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: _col0 (type: string), _col1 (type: string), _col2 (type: string), _col3 (type: string), _col4 (type: int), _col5 (type: int), _col6 (type: int), _col7 (type: string), _col9 (type: decimal(28,2)), rank_window_0 (type: int)
                      outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9
                      Statistics: Num rows: 1372777 Data size: 1855333281 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: string), _col1 (type: string), _col2 (type: string), _col3 (type: string), _col4 (type: int), _col5 (type: int), _col6 (type: int), _col7 (type: string), _col8 (type: decimal(28,2)), _col9 (type: int)
                        sort order: ++++++++++
                        Statistics: Num rows: 1372777 Data size: 1855333281 Basic stats: COMPLETE Column stats: NONE
        Reducer 5 
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: string), KEY.reducesinkkey1 (type: string), KEY.reducesinkkey2 (type: string), KEY.reducesinkkey3 (type: string), KEY.reducesinkkey4 (type: int), KEY.reducesinkkey5 (type: int), KEY.reducesinkkey6 (type: int), KEY.reducesinkkey7 (type: string), KEY.reducesinkkey8 (type: decimal(28,2)), KEY.reducesinkkey9 (type: int)
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9
                Statistics: Num rows: 1372777 Data size: 1855333281 Basic stats: COMPLETE Column stats: NONE
                Limit
                  Number of rows: 100
                  Statistics: Num rows: 100 Data size: 135100 Basic stats: COMPLETE Column stats: NONE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 100 Data size: 135100 Basic stats: COMPLETE Column stats: NONE
                    table:
                        input format: org.apache.hadoop.mapred.TextInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: 100
      Processor Tree:
        ListSink
{noformat}, [~jpullokkaran]
Can you please take a look?, [~jcamachorodriguez] Could you take a look?
May be we screwed the types going in/out., I cannot reproduce this one in my environment with {{hive.vectorized.execution.enabled}} and {{hive.vectorized.execution.reduce.enabled}}, is it still an issue?, I struggled with the environment variables necessary for a repro.

The default for is hive.vectorized.execution.mapjoin.native.enabled is true, but for the repro it needs to be set to false.

(Here is the whole list of variables I used in my Q file:)
{noformat}
SET hive.vectorized.execution.enabled=true;
set hive.mapjoin.hybridgrace.hashtable=true;
SET hive.vectorized.execution.mapjoin.native.enabled=false;
set hive.cbo.enable=true;
set hive.fetch.task.conversion=none;
SET hive.auto.convert.join=true;
SET hive.auto.convert.join.noconditionaltask=true;
SET hive.auto.convert.join.noconditionaltask.size=100000000;
set hive.exec.dynamic.partition.mode=nonstrict;
{noformat}, [~mmccline], the problem is not in CBO; in fact, with CBO disabled, the problem appears too. There seems to be a problem in the vectorization code when grouping sets are used (wrong indices? not taking into account grouping__id?). The following simplified query can be used to reproduce the error:

{code}
 select s_store_id
 from store
 group by s_store_id with rollup;
{code}

while this query does not show the error 

{code}
 select s_store_id, GROUPING__ID
 from store
 group by s_store_id with rollup;
{code}

What do you think?, I think this is directly related to HIVE-9347., For 1.2.1, I would prefer to not vectorize if there is GroupByDesc.pruneGroupingSetId is true...., 

{color:red}Overall{color}: -1 at least one tests failed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12734715/HIVE-10244.01.patch

{color:red}ERROR:{color} -1 due to 1 failed/errored test(s), 8969 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestEncryptedHDFSCliDriver.testCliDriver_encryption_insert_partition_static
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/4002/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/4002/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-4002/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 1 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12734715 - PreCommit-HIVE-TRUNK-Build, Test failure is unrelated to changes (has build age 6)., [~mmccline] How can you end up grouping id without grouping sets?
Language prevents referring to grouping id without grouping sets.

If grouping sets are present then previous line should bail out right?

if (desc.isGroupingSetsPresent()) {
      LOG.info("Grouping sets not supported in vector mode");
      return false;
    }, Ya, I know, that is what I thought.  But the new prune flag seems to be on in the Reducer even though isGroupingSetsPresent is false.  We should talk to the author and reviewer of the change.

Jedi Master [~ashutoshc], can you explain to us Padawan Learners [~jpullokkaran] [~mmccline] [~jcamachorodriguez] all about the prune flag?, Ok i looked further.
Logical GB gets translated to different GB-RS-GB pipelines based on config (skew, no of grip sets..).
GrpID Col is always added only for the last operator; rest of the physical GB will not include it.

So on an individual GB its legal to have groupingset set to false & prunegroupingid set to true.
Ex: MapSide GB + SkewInData where grouping__id is not in the projection list., Example Query:
set hive.groupby.skewindata=true;
select key from t1 group by key,value grouping sets((key), (value));, Example Query:
set hive.groupby.skewindata=true;
select key from t1 group by key,value grouping sets((key), (value));, Example Query:
set hive.groupby.skewindata=true;
select key from t1 group by key,value grouping sets((key), (value));, Example Query:
set hive.groupby.skewindata=true;
select key from t1 group by key,value grouping sets((key), (value));, Example Query:
set hive.groupby.skewindata=true;
select key from t1 group by key,value grouping sets((key), (value));, +1, [~jpullokkaran] thank you for digging into the GroupBy logical/physical pipeline and figuring it out!  And, your review +1.  And, and thank you and [~ashutoshc] for discussing it., Committed to master and branch-1.2.]