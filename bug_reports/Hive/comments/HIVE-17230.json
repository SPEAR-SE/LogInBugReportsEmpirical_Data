[The root cause of the issue is, that HiveCLI writes out the value with TimestampWritable.toString() method which specifically changes the output of the timeStamp.toString() for an unknown reason since the "inception" of this code :)
{code:title=TimestampWritable}
  @Override
  public String toString() {
    if (timestampEmpty) {
      populateTimestamp();
    }

    String timestampString = timestamp.toString();
    if (timestampString.length() > 19) {
      if (timestampString.length() == 21) {
        if (timestampString.substring(19).compareTo(".0") == 0) {
          return threadLocalDateFormat.get().format(timestamp);
        }
      }
      return threadLocalDateFormat.get().format(timestamp) + timestampString.substring(19);
    }

    return threadLocalDateFormat.get().format(timestamp);
  }
{code}

The BeeLine receives a Timestamp object and calls it's toString without any changes:
{code:title=org.apache.hive.beeline.Rows}
    Row(int size, ResultSet rs) throws SQLException {
[..]
      for (int i = 0; i < size; i++) {
        if (numberFormat != null) {
          Object o = rs.getObject(i + 1);
          if (o == null) {
            values[i] = null;
          }  else if (o instanceof Number) {
            values[i] = numberFormat.format(o);
          } else {
            values[i] = o.toString();       <--- This row prints out the Timestamp object
          }
        } else {
          values[i] = rs.getString(i + 1);
        }
        values[i] = values[i] == null ? nullStr : values[i];
        sizes[i] = values[i].length();
      }
    }
{code}, I have found this issue when I was trying to run several more tests with the TestBeeLineDriver to see if there is any further differences between the output of BeeLine, and HiveCLI.

[~vihangk1], [~aihuaxu]: What do you think we should do with this difference?
- Change the way BeeLine prints out timestamps?
- Change the way HiveCLI prints out timestamps?
- Document this as a known issue?

I personally do not understand/like the HiveCLI version where the Timestamp nanoseconds are not displayed - in my view this column was specifically defined as a Timestamp because we expect it to be an exact time, so I would go for removing the formatting changes from the HiveCLI, but this is a backward incompatible change, and I might not see every aspect of this change.

I would greatly value your input here [~aihuaxu], [~vihangk1].

Thanks,
Peter, The output from the beeline version is more accurate to me. I feel it makes sense to make that change., Uploading a first version of the patch to see which tests are affected. Most probably there will be some failing tests which will be analyzed.  , 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12881266/HIVE-17230.1.patch

{color:green}SUCCESS:{color} +1 due to 2 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 80 failed/errored test(s), 11002 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestAccumuloCliDriver.testCliDriver[accumulo_index] (batchId=231)
org.apache.hadoop.hive.cli.TestBlobstoreCliDriver.testCliDriver[insert_overwrite_dynamic_partitions_merge_move] (batchId=243)
org.apache.hadoop.hive.cli.TestBlobstoreCliDriver.testCliDriver[insert_overwrite_dynamic_partitions_merge_only] (batchId=243)
org.apache.hadoop.hive.cli.TestBlobstoreCliDriver.testCliDriver[insert_overwrite_dynamic_partitions_move_only] (batchId=243)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[floor_time] (batchId=73)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[interval_alt] (batchId=4)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[interval_arithmetic] (batchId=45)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[json_serde_tsformat] (batchId=5)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[llap_text] (batchId=71)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[orc_merge11] (batchId=38)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[orc_ppd_exception] (batchId=32)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[timestamp] (batchId=28)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[timestamp_ints_casts] (batchId=1)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[timestamp_literal] (batchId=25)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[timestamptz_1] (batchId=56)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[udf_to_utc_timestamp] (batchId=21)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[vector_aggregate_9] (batchId=38)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[vector_interval_1] (batchId=15)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[vector_interval_arithmetic] (batchId=4)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[vectorization_14] (batchId=14)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[vectorization_17] (batchId=83)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[vectorization_7] (batchId=42)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[vectorized_casts] (batchId=79)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[vectorized_date_funcs] (batchId=73)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[vectorized_timestamp] (batchId=74)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[vectorized_timestamp_ints_casts] (batchId=47)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[windowing_windowspec3] (batchId=36)
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver[hbase_timestamp] (batchId=96)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[insert_values_non_partitioned] (batchId=149)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[insert_values_partitioned] (batchId=160)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[orc_merge11] (batchId=153)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[orc_merge5] (batchId=157)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[orc_merge6] (batchId=152)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[orc_merge7] (batchId=162)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[orc_merge_incompat1] (batchId=159)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[orc_merge_incompat2] (batchId=162)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[orc_split_elimination] (batchId=158)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_orc_nonvec_part_all_primitive] (batchId=163)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_orc_vec_part_all_primitive] (batchId=161)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_text_nonvec_part] (batchId=149)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_text_nonvec_part_all_primitive] (batchId=156)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_text_nonvec_table] (batchId=148)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_text_vec_part] (batchId=157)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_text_vec_part_all_primitive] (batchId=158)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_text_vec_table] (batchId=155)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_text_vecrow_part] (batchId=162)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_text_vecrow_part_all_primitive] (batchId=158)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_text_vecrow_table] (batchId=147)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_aggregate_9] (batchId=153)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_interval_1] (batchId=148)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_interval_2] (batchId=159)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_interval_arithmetic] (batchId=146)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_partitioned_date_time] (batchId=161)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vectorization_14] (batchId=148)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vectorization_17] (batchId=163)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vectorization_7] (batchId=154)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vectorized_casts] (batchId=162)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vectorized_date_funcs] (batchId=161)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vectorized_timestamp] (batchId=161)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vectorized_timestamp_ints_casts] (batchId=156)
org.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver[orc_merge5] (batchId=170)
org.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver[orc_merge6] (batchId=170)
org.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver[orc_merge7] (batchId=172)
org.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver[orc_merge_incompat1] (batchId=171)
org.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver[orc_merge_incompat2] (batchId=172)
org.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver[spark_dynamic_partition_pruning_mapjoin_only] (batchId=170)
org.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver[spark_vectorized_dynamic_partition_pruning] (batchId=169)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=235)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query23] (batchId=235)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[date_udf] (batchId=115)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[timestamp_1] (batchId=113)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[timestamp_2] (batchId=101)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[timestamp_lazy] (batchId=124)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[vectorization_14] (batchId=107)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[vectorization_17] (batchId=138)
org.apache.hadoop.hive.ql.io.orc.TestNewInputOutputFormat.testNewInputFormat (batchId=263)
org.apache.hadoop.hive.serde2.io.TestTimestampWritable.testSerializationFormatDirectly (batchId=289)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema (batchId=180)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema (batchId=180)
org.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation (batchId=180)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/6342/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/6342/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-6342/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 80 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12881266 - PreCommit-HIVE-Build, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12886458/HIVE-17230.2.patch

{color:green}SUCCESS:{color} +1 due to 4 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 13 failed/errored test(s), 11033 tests executed
*Failed tests:*
{noformat}
TestAccumuloCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=230)
TestDummy - did not produce a TEST-*.xml file (likely timed out) (batchId=230)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_values_orig_table_use_metadata] (batchId=61)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[interval_arithmetic] (batchId=45)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[orc_merge8] (batchId=81)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[vectorized_timestamp] (batchId=74)
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver[hbase_timestamp] (batchId=96)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_text_nonvec_part] (batchId=149)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_text_nonvec_part_all_primitive] (batchId=156)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_text_vec_part_all_primitive] (batchId=158)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_text_vecrow_part] (batchId=162)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_text_vecrow_part_all_primitive] (batchId=158)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_2] (batchId=100)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/6769/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/6769/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-6769/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 13 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12886458 - PreCommit-HIVE-Build, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12887101/HIVE-17230.3.patch

{color:green}SUCCESS:{color} +1 due to 4 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 12 failed/errored test(s), 11040 tests executed
*Failed tests:*
{noformat}
TestAccumuloCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=230)
TestDummy - did not produce a TEST-*.xml file (likely timed out) (batchId=230)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[create_view] (batchId=39)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_values_orig_table_use_metadata] (batchId=61)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[interval_arithmetic] (batchId=45)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[union_fast_stats] (batchId=156)
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[drop_table_failure2] (batchId=89)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=234)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query23] (batchId=234)
org.apache.hadoop.hive.ql.TestAcidOnTez.testCtasTezUnion (batchId=215)
org.apache.hadoop.hive.ql.TestAcidOnTez.testNonStandardConversion01 (batchId=215)
org.apache.hive.jdbc.TestJdbcDriver2.testSelectExecAsync2 (batchId=225)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/6817/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/6817/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-6817/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 12 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12887101 - PreCommit-HIVE-Build, I've not found any recommendation in the sql standard how this should be formatted on outputting it; however here's what I've found:

* psql - displays timestamp precision only on demand (supresses trailing zeros):
{code}
select cast('2011-11-11 11:11:11.123' as timestamp(2)), cast('2011-11-11 11:11:11' as timestamp(2));
 2011-11-11 11:11:11.12 | 2011-11-11 11:11:11
{code}
* mariadb - seems to be not supporting {{cast}} for me..
  creating a table; and setting timestamp precision explicitly to 2 makes it show .00 all the time
  I must note that {{timestamp}} without specifier should be 6 precise
* oracle has a supercomplicated formatter; which by default outputs all 6 precision digits.
* hive (as of now)
 does not support the timestamp precision setting
 stores all timestamps with precision 9 
 cli: trims trailing zeros

I think from the above that the most user friendly is the behaviour of psql...
I think the only case when we might be ok to show a single trailing zero in case of precision 1. - so I think it would be better to remove those lone trailing 0s.

{code}
create table t(a timestamp);
insert into t values
('2011-11-11 11:11:11')
,('2011-11-11 11:11:11.1234')
,('2011-11-11 11:11:11.1234567')
,('2011-11-11 11:11:11.123456789')
,('2011-11-11 11:11:11.1234567890123')
,('2011-11-11 11:11:11.12345678901234567890')
,('2011-11-11 11:11:11.12345678901234567890123456')
;
select * from t;
{code}, Thanks a lot [~kgyrtkirk] for the investigation you did. You are right that the behavior of psql seems to be the most user friendly. However in this case we have to implement the same custom logic in BeeLine as in Hive CLI instead of just relaying on the string representation of the timestamps. This adds a bit more complexity and extra logic to the BeeLine code.
If we want the same timestamp format in both BeeLine and Hive CLI, we can either change the BeeLine behavior or the CLI behavior and I think both solutions have advantages and disadvantages.
Changing the behavior of the Hive CLI to display the timestamp like in BeeLine (with the trailing .0s) affects many q.out files.
Changing the behavior of BeeLine (remove the trailing 0s) is a smaller change but in return we have to maintain the same formatting logic as in Hive CLI.
[~aihuaxu], what are your thoughts about this? , Thanks [~kgyrtkirk] for looking into it. Seems like the standard is more about how to store the timestamp data  http://troels.arvin.dk/db/rdbms/#data_types-date_and_time-timestamp, not about how to display the timestamp. So either will be fine if the result is correct. Hive follows more with Oracle and Postgres, but Oracle shows the trailing 0 and postgres removes the trailing 0. 

[~jdere] Do you have opinion on this? ]