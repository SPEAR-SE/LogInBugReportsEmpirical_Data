[A query based compactor with tests. Probably needs to be tested in a real cluster, to make sure nothing is messed up w.r.t. state in real metastore. I'll look into that., Probably also needs a config setting to be able to turn it off if smth goes wrong., [~ekoifman] can you take a look? thnx, The flow for Acid compaction is 
1. Initiator - uses some heuristics (like number of delta files, number of aborted txns, etc) to schedule compactions
2. Worker - picks an item from compaction queue (either put there by Initiator or via explicit Alter Table) runs a job to produce new files.
3. Cleaner - removes 'obsolete' files when it's safe to do so.

For MM tables the flow so far was
1. Initiator - look for sufficient number of aborted txns and schedule compaction.
2. Worker - delete the delta_x_x dirs where X is aborted
3. Cleaner - does nothing

compaction_queue/complete_compaction_queue are metastore tables representing the queue (the later keeps historical info) and driver SHOW COMPACTIONS.

With this patch, Alter Table Compact for MM table will do the IOW + delete aborted if any, but the auto initiated compaction will also do IOW.  Do we want that?  Should Initiator have some logic to decide if IOW is needed?  Maybe this can be a follow up ticket.

Longer term I'd like to remove the Cleaner part altogether and move that logic to Worker - maybe 3.1 timeframe.

{{//txnManager.closeTxnManager();}} - I don't think this is needed unless Session is shutdown.  

This is done in the cleaner
{noformat}
   // TODO: Also delete obsolete directories? How do we account for readers?
477	    /*List<FileStatus> obsolete = dir.getObsolete();
478	    for (FileStatus stat : obsolete) {
479	      filesToDelete.add(stat.getPath());
480	    }*/
{noformat}

Can you explain this?
{{// TODO: move to global? should be ok if it's always the same thread.}}

There should be some logic to shutdown the session if there are any errors.  I've seen situations where Session init fails, but it's still attached to ThreadLocal and so every Worker in that thread will always get a bad session.  HIVE-18808 is an example, it has links to others

Another issue: currently compactor will not compact above the smallest open writeID in a table.
But this violates that.  So if 3 is open and 5 is committed, the IOW may produces base_10, for example, which doesn't have and data from 3.  We could add some logic to force the instance of the Driver created here, to create ValidTxnList with HWM set to minOpenTxn (from MIN_HISTORY table) - poor man's flashback query.
, The last point is actually a bug with insert overwrite that I've filed separately..., Fixing initiator to not skip MM tables, addressing most of the other feedback.
Also making sure that compactor doesn't commit a new txn that writes to the table, instead just like a regular compactor it commits by moving the directory into place.

One thing that is not addressed is the parallel writer case, which is the same issue as HIVE-18570.
Let me see if I can address it for compaction specifically...

cc [~gopalv]
Also looking at the Cleaner it seems like it should run just fine for MM tables and delete obsolete directories. It never checks table type... [~ekoifman] are you sure there's a problem with it?, The watermark issue for compactor specifically could probably be addressed by
1) Modifying txn list in recordValidWriteIds in Driver based on the flag. We create the driver so the flag can be set directly, no shennanigans necessary. Compactor write IDs can be created and serialized for the query to only read the data we want.
2) When renaming the directory, generating the final name in commit method, AFTER the query, based on write IDs that the driver actually used.

That way we don't even need any UDFs or INPUT_FILE_NAME stuff and it will work just like that.
I'm not sure I'll have enough time to finish this today and I'm out next week, but I'll attach a WIP patch. 

For insert overwrite outside of compaction this won't work because we do need to overwrite deltas above watermark that have already committed but not the ones in progress, so base would need to be discontinuous. But for compaction we don't need that., WIP patch based on 01 to address the watermark issue. Needs a test. TODO#s mark places where I didn't have enough time to check the existing code so I put whatever came to mind :) needs to be verified., RB doesn't open, so no RB update., | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
|| || || || {color:brown} Prechecks {color} ||
| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Findbugs executables are not available. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
|| || || || {color:brown} master Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 36s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  7m 50s{color} | {color:green} master passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  2m 56s{color} | {color:green} master passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m 36s{color} | {color:green} master passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  3m  3s{color} | {color:green} master passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m  8s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:red}-1{color} | {color:red} mvninstall {color} | {color:red}  0m 58s{color} | {color:red} ql in the patch failed. {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  2m 57s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  2m 57s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} checkstyle {color} | {color:red}  0m 19s{color} | {color:red} itests/hive-unit: The patch generated 4 new + 76 unchanged - 0 fixed = 80 total (was 76) {color} |
| {color:red}-1{color} | {color:red} checkstyle {color} | {color:red}  0m 45s{color} | {color:red} ql: The patch generated 7 new + 209 unchanged - 1 fixed = 216 total (was 210) {color} |
| {color:red}-1{color} | {color:red} checkstyle {color} | {color:red}  0m 20s{color} | {color:red} standalone-metastore: The patch generated 1 new + 19 unchanged - 0 fixed = 20 total (was 19) {color} |
| {color:red}-1{color} | {color:red} whitespace {color} | {color:red}  0m  0s{color} | {color:red} The patch has 2 line(s) that end in whitespace. Use git apply --whitespace=fix <<patch_file>>. Refer https://git-scm.com/docs/git-apply {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m 45s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:red}-1{color} | {color:red} asflicense {color} | {color:red}  0m 15s{color} | {color:red} The patch generated 1 ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 27m  5s{color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Optional Tests |  asflicense  javac  javadoc  findbugs  checkstyle  compile  |
| uname | Linux hiveptest-server-upstream 3.16.0-4-amd64 #1 SMP Debian 3.16.36-1+deb8u1 (2016-09-03) x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /data/hiveptest/working/yetus_PreCommit-HIVE-Build-10055/dev-support/hive-personality.sh |
| git revision | master / a316c82 |
| Default Java | 1.8.0_111 |
| mvninstall | http://104.198.109.242/logs//PreCommit-HIVE-Build-10055/yetus/patch-mvninstall-ql.txt |
| checkstyle | http://104.198.109.242/logs//PreCommit-HIVE-Build-10055/yetus/diff-checkstyle-itests_hive-unit.txt |
| checkstyle | http://104.198.109.242/logs//PreCommit-HIVE-Build-10055/yetus/diff-checkstyle-ql.txt |
| checkstyle | http://104.198.109.242/logs//PreCommit-HIVE-Build-10055/yetus/diff-checkstyle-standalone-metastore.txt |
| whitespace | http://104.198.109.242/logs//PreCommit-HIVE-Build-10055/yetus/whitespace-eol.txt |
| asflicense | http://104.198.109.242/logs//PreCommit-HIVE-Build-10055/yetus/patch-asflicense-problems.txt |
| modules | C: storage-api itests/hive-unit ql standalone-metastore U: . |
| Console output | http://104.198.109.242/logs//PreCommit-HIVE-Build-10055/yetus.txt |
| Powered by | Apache Yetus    http://yetus.apache.org |


This message was automatically generated.

, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12917916/HIVE-19124.02.WIP.patch

{color:green}SUCCESS:{color} +1 due to 1 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 111 failed/errored test(s), 13187 tests executed
*Failed tests:*
{noformat}
TestBeeLineDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=252)
TestCopyUtils - did not produce a TEST-*.xml file (likely timed out) (batchId=230)
TestDbNotificationListener - did not produce a TEST-*.xml file (likely timed out) (batchId=246)
TestDummy - did not produce a TEST-*.xml file (likely timed out) (batchId=252)
TestExportImport - did not produce a TEST-*.xml file (likely timed out) (batchId=230)
TestHCatHiveCompatibility - did not produce a TEST-*.xml file (likely timed out) (batchId=246)
TestMiniDruidCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=252)
TestMiniDruidKafkaCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=252)
TestNegativeCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=95)
	[nopart_insert.q,insert_into_with_schema.q,input41.q,having1.q,create_table_failure3.q,default_constraint_invalid_default_value.q,database_drop_not_empty_restrict.q,windowing_after_orderby.q,orderbysortby.q,subquery_select_distinct2.q,authorization_uri_alterpart_loc.q,udf_last_day_error_1.q,constraint_duplicate_name.q,create_table_failure4.q,alter_tableprops_external_with_notnull_constraint.q,semijoin5.q,udf_format_number_wrong4.q,deletejar.q,exim_11_nonpart_noncompat_sorting.q,show_tables_bad_db2.q,drop_func_nonexistent.q,nopart_load.q,alter_table_non_partitioned_table_cascade.q,check_constraint_subquery.q,load_wrong_fileformat.q,check_constraint_udtf.q,lockneg_try_db_lock_conflict.q,udf_field_wrong_args_len.q,create_table_failure2.q,create_with_fk_constraints_enforced.q,groupby2_map_skew_multi_distinct.q,authorization_update_noupdatepriv.q,show_columns2.q,authorization_insert_noselectpriv.q,orc_replace_columns3_acid.q,compare_double_bigint.q,authorization_set_nonexistent_conf.q,alter_rename_partition_failure3.q,split_sample_wrong_format2.q,create_with_fk_pk_same_tab.q,compare_double_bigint_2.q,authorization_show_roles_no_admin.q,materialized_view_authorization_rebuild_no_grant.q,unionLimit.q,authorization_revoke_table_fail2.q,authorization_insert_noinspriv.q,duplicate_insert3.q,authorization_desc_table_nosel.q,stats_noscan_non_native.q,orc_change_serde_acid.q,create_or_replace_view7.q,exim_07_nonpart_noncompat_ifof.q,create_with_unique_constraints_enforced.q,udf_concat_ws_wrong2.q,fileformat_bad_class.q,merge_negative_2.q,exim_15_part_nonpart.q,authorization_not_owner_drop_view.q,external1.q,authorization_uri_insert.q,create_with_fk_wrong_ref.q,columnstats_tbllvl_incorrect_column.q,authorization_show_parts_nosel.q,authorization_not_owner_drop_tab.q,external2.q,authorization_deletejar.q,temp_table_create_like_partitions.q,udf_greatest_error_1.q,ptf_negative_AggrFuncsWithNoGBYNoPartDef.q,alter_view_as_select_not_exist.q,touch1.q,groupby3_map_skew_multi_distinct.q,insert_into_notnull_constraint.q,exchange_partition_neg_partition_missing.q,groupby_cube_multi_gby.q,columnstats_tbllvl.q,drop_invalid_constraint2.q,alter_table_add_partition.q,update_not_acid.q,archive5.q,alter_table_constraint_invalid_pk_col.q,ivyDownload.q,udf_instr_wrong_type.q,bad_sample_clause.q,authorization_not_owner_drop_tab2.q,authorization_alter_db_owner.q,show_columns1.q,orc_type_promotion3.q,create_view_failure8.q,strict_join.q,udf_add_months_error_1.q,groupby_cube2.q,groupby_cube1.q,groupby_rollup1.q,genericFileFormat.q,invalid_cast_from_binary_4.q,drop_invalid_constraint1.q,serde_regex.q,show_partitions1.q,check_constraint_nonboolean_expr.q,invalid_cast_from_binary_6.q,create_with_multi_pk_constraint.q,udf_field_wrong_type.q,groupby_grouping_sets4.q,groupby_grouping_sets3.q,insertsel_fail.q,udf_locate_wrong_type.q,orc_type_promotion1_acid.q,set_table_property.q,create_or_replace_view2.q,groupby_grouping_sets2.q,alter_view_failure.q,distinct_windowing_failure1.q,invalid_t_alter2.q,alter_table_constraint_invalid_fk_col1.q,invalid_varchar_length_2.q,authorization_show_grant_otheruser_alltabs.q,subquery_windowing_corr.q,compact_non_acid_table.q,authorization_view_4.q,authorization_disallow_transform.q,materialized_view_authorization_rebuild_other.q,authorization_fail_4.q,dbtxnmgr_nodblock.q,set_hiveconf_internal_variable1.q,input_part0_neg.q,udf_printf_wrong3.q,load_orc_negative2.q,druid_buckets.q,archive2.q,authorization_addjar.q,invalid_sum_syntax.q,insert_into_with_schema1.q,udf_add_months_error_2.q,dyn_part_max_per_node.q,authorization_revoke_table_fail1.q,udf_printf_wrong2.q,archive_multi3.q,udf_printf_wrong1.q,subquery_subquery_chain.q,authorization_view_disable_cbo_4.q,no_matching_udf.q,create_view_failure7.q,drop_native_udf.q,truncate_column_list_bucketing.q,authorization_uri_add_partition.q,authorization_view_disable_cbo_3.q,bad_exec_hooks.q,authorization_view_disable_cbo_2.q,fetchtask_ioexception.q,char_pad_convert_fail2.q,authorization_set_role_neg1.q,serde_regex3.q,authorization_delete_nodeletepriv.q,materialized_view_delete.q,create_or_replace_view6.q,bucket_mapjoin_wrong_table_metadata_2.q,udf_sort_array_by_wrong2.q,local_mapred_error_cache.q,alter_external_acid.q,mm_concatenate.q,authorization_fail_3.q,set_hiveconf_internal_variable0.q,udf_last_day_error_2.q,alter_table_constraint_invalid_ref.q,create_table_wrong_regex.q,describe_xpath4.q,join32.q,insert_sorted.q,describe_xpath2.q,authorization_role_grant_otheruser.q,masking_acid_merge.q,authorization_ctas.q,authorization_fail_5.q,alter_view_failure9.q,insert_into_acid_notnull.q,illegal_partition_type3.q,alter_table_constraint_invalid_pk_tbl.q,authorization_uri_import.q,database_drop_does_not_exist.q,date_literal3.q,archive_multi4.q,date_literal2.q,gby_star2.q,authorization_table_grant_nosuchrole.q,insert_into_with_schema2.q,join_cond_unqual_ambiguous_vc.q,archive_multi2.q,analyze1.q,invalid_distinct3.q,fs_default_name1.q,subquery_in_on.q,show_columns3.q,column_rename1.q,authorization_view_1.q,ptf_negative_JoinWithAmbigousAlias.q,groupby_rollup3.q,truncate_table_failure6.q,groupby_cube3.q,invalid_create_tbl1.q,illegal_partition_type.q,cachingprintstream.q,create_function_nonudf_class.q,exchange_partition_neg_table_missing2.q,dbtxnmgr_notablelock.q,create_view_failure1.q,create_view_failure2.q,alter_view_failure8.q,check_constraint_window_fun.q,update_notnull_constraint.q,authorization_drop_db_cascade.q,archive_partspec3.q,truncate_partition_column.q,alter_partition_partial_spec_dyndisabled.q,udf_format_number_wrong2.q,column_rename5.q,authorization_import.q,authorization_fail_2.q,script_error.q,archive_partspec5.q,script_broken_pipe2.q,update_no_such_table.q,exim_09_nonpart_noncompat_serdeparam.q,invalid_cast_from_binary_1.q,archive_partspec1.q,unionDistributeBy.q,drop_function_failure.q,authorization_priv_current_role_neg.q,archive_insert1.q,authorization_addpartition.q,archive_multi6.q,exim_05_nonpart_noncompat_coltype.q,druid_case.q,invalid_cast_to_binary_5.q,orderby_invalid_position.q,materialized_view_authorization_create_no_select_perm.q,exchange_partition_neg_with_fullacid_table.q,druid_address.q,delete_not_acid.q,temp_table_partitions.q,constraint_invalide_name.q,authorization_uri_load_data.q,udf_locate_wrong_args_len.q,duplicate_insert1.q,duplicate_insert2.q,udf_sort_array_by_wrong3.q,stats_publisher_error_2.q,show_tableproperties1.q,invalid_cast_to_binary_2.q,authorization_drop_admin_role.q,lockneg1.q,exim_16_part_noncompat_schema.q,database_switch_does_not_exist.q,ctas.q,exim_10_nonpart_noncompat_bucketing.q,unionOrderBy.q,addpart1.q,ptf_negative_NoWindowDefn.q,authorization_set_invalidconf.q,udtf_explode_not_supported3.q,ptf_negative_AmbiguousWindowDefn.q,create_external_with_check_constraint.q,udtf_invalid_place.q,join_cond_unqual_ambiguous.q,udf_format_number_wrong1.q,authorization_view_disable_cbo_6.q,exim_25_import_nonexist_authfail.q,authorization_role_cycles1.q,invalid_char_length_3.q,groupby_struct.q,join_alt_syntax_comma_on.q,exchange_partition_neg_incomplete_partition.q,udf_test_error_reduce.q,load_wrong_noof_part.q,authorization_export_ptn.q,drop_partition_failure.q,subquery_in_implicit_gby.q,udf_map_values_arg_num.q,udf_elt_wrong_args_len.q,alter_table_wrong_location.q,archive_insert4.q,authorization_grant_table_fail_nogrant.q,authorization_create_func1.q,dyn_part3.q,cte_with_in_subquery.q,column_change_skewedcol_type1.q,materialized_view_drop.q,selectDistinctStarNeg_2.q,exchange_partition_neg_with_mm_table.q,invalid_std_syntax.q,unset_view_property.q,authorization_view_3.q,subquery_exists_implicit_gby.q,authorization_set_role_neg2.q,authorization_grant_group.q,invalid_min_syntax.q,semijoin3.q,truncate_nonexistant_column.q,exchange_partition_neg_table_missing.q,gby_star.q,truncate_partition_column2.q,insertover_dynapart_ifnotexists.q,unionClusterBy.q,udf_qualified_name.q,udaf_invalid_place.q,spark_job_max_tasks.q,authorization_cannot_create_default_role.q,nonkey_groupby.q,spark_stage_max_tasks.q,ptf_negative_HavingLeadWithNoGBYNoWindowing.q,alter_view_as_select_with_partition.q,load_exist_part_authfail.q,archive_multi7.q,authorization_create_func2.q,authorization_grant_uri.q,line_terminator.q,load_view_failure.q,groupby_grouping_sets8.q,invalid_cast_from_binary_3.q,exim_21_part_managed_external.q,insert_into4.q,database_create_invalid_name.q,groupby_grouping_sets7.q,subq_insert.q,dyn_part2.q,alter_external_with_notnull_constraint.q,exchange_partition.q,lateral_view_join.q,allow_change_col_type_par_neg.q,create_function_nonexistent_db.q,create_function_nonexistent_class.q,authorization_not_owner_alter_tab_rename.q,strict_pruning.q,subquery_notexists_implicit_gby.q,orc_reorder_columns1.q,columnstats_partlvl_invalid_values.q,orc_reorder_columns2.q,authorization_dfs.q,udf_format_number_wrong7.q,exim_17_part_spec_underspec.q,druid_partitions.q,authorization_drop_role_no_admin.q,windowing_ll_no_over.q,subquery_corr_from.q,desc_failure2.q,load_non_native.q,windowing_ll_no_neg.q,authorization_role_grant2.q,lockneg4.q,lockneg3.q,drop_table_failure2.q,temp_table_authorize_create_tbl.q,dyn_part_max.q,orc_reorder_columns2_acid.q,change_hive_local_session_path.q,insert_into5.q,insert_into1.q,insert_into3.q,udf_in_2.q,udtf_explode_not_supported2.q,sample.q,udtf_explode_not_supported1.q,authorization_droppartition.q,orc_type_promotion2_acid.q,materialized_view_load.q,right_side_join.q,authorization_fail_1.q,authorization_cannot_create_all_role.q,invalid_max_syntax.q,udf_array_contains_wrong1.q,authorization_cannot_create_none_role.q,subquery_in_lhs.q,orc_replace_columns3.q,udf_size_wrong_args_len.q,create_skewed_table_dup_col_name.q,authorization_fail_7.q,authorization_invalid_priv_v1.q,invalidate_view1.q,union22.q,subquery_scalar_multi_columns.q,disallow_incompatible_type_change_on1.q,semijoin1.q,create_skewed_table_failure_invalid_col_name.q,udf_when_type_wrong.q,timestamp_literal.q,create_external_with_default_constraint.q,truncate_table_failure4.q,masking_acid_delete.q,check_constraint_violation.q,uniquejoin2.q,authorization_grant_table_dup.q,invalid_tbl_name.q,authorization_createview.q,alter_external_with_default_constraint.q,truncate_table_failure1.q,alter_partition_coltype_invalidtype.q,show_tablestatus_not_existing_part.q,authorization_msck.q,truncate_table_failure2.q,joinneg.q]
TestNegativeCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=96)
	[udf_invalid.q,authorization_uri_export.q,default_constraint_complex_default_value.q,druid_datasource2.q,check_constraint_max_length.q,view_update.q,default_partition_name.q,authorization_public_create.q,load_wrong_fileformat_rc_seq.q,default_constraint_invalid_type.q,altern1.q,describe_xpath1.q,drop_view_failure2.q,temp_table_rename.q,invalid_select_column_with_subquery.q,udf_trunc_error1.q,insert_view_failure.q,dbtxnmgr_nodbunlock.q,authorization_show_columns.q,cte_recursion.q,merge_constraint_notnull.q,load_part_nospec.q,clusterbyorderby.q,orc_type_promotion2.q,ctas_noperm_loc.q,udf_min.q,udf_instr_wrong_args_len.q,invalid_create_tbl2.q,part_col_complex_type.q,authorization_drop_db_empty.q,smb_mapjoin_14.q,subquery_scalar_multi_rows.q,alter_partition_coltype_2columns.q,subquery_corr_in_agg.q,insert_overwrite_notnull_constraint.q,authorization_show_grant_otheruser_wtab.q,regex_col_groupby.q,ptf_negative_DuplicateWindowAlias.q,exim_22_export_authfail.q,udf_likeany_wrong1.q,groupby_key.q,ambiguous_col.q,groupby3_multi_distinct.q,authorization_alter_drop_ptn.q,invalid_cast_from_binary_5.q,show_create_table_does_not_exist.q,invalid_select_column.q,exim_20_managed_location_over_existing.q,interval_3.q,authorization_compile.q,join35.q,udf_concat_ws_wrong3.q,create_or_replace_view8.q,create_external_with_notnull_constraint.q,split_sample_out_of_range.q,materialized_view_no_transactional_rewrite.q,authorization_show_grant_otherrole.q,create_with_constraints_duplicate_name.q,invalid_stddev_samp_syntax.q,authorization_view_disable_cbo_7.q,autolocal1.q,avro_non_nullable_union.q,load_orc_negative_part.q,drop_view_failure1.q,columnstats_partlvl_invalid_values_autogather.q,exim_13_nonnative_import.q,alter_table_wrong_regex.q,udf_next_day_error_2.q,authorization_select.q,udf_trunc_error2.q,authorization_view_7.q,udf_format_number_wrong5.q,touch2.q,orc_type_promotion1.q,lateral_view_alias.q,show_tables_bad_db1.q,unset_table_property.q,alter_non_native.q,nvl_mismatch_type.q,load_orc_negative3.q,authorization_create_role_no_admin.q,invalid_distinct1.q,authorization_grant_server.q,orc_type_promotion3_acid.q,hms_using_serde_alter_table_update_columns.q,show_tables_bad1.q,macro_unused_parameter.q,drop_invalid_constraint3.q,drop_partition_filter_failure.q,char_pad_convert_fail3.q,exim_23_import_exist_authfail.q,drop_invalid_constraint4.q,authorization_create_macro1.q,archive1.q,subquery_multiple_cols_in_select.q,change_hive_hdfs_session_path.q,udf_trunc_error3.q,invalid_variance_syntax.q,authorization_truncate_2.q,invalid_avg_syntax.q,invalid_select_column_with_tablename.q,mm_truncate_cols.q,groupby_grouping_sets1.q,druid_location.q,groupby2_multi_distinct.q,authorization_sba_drop_table.q,dynamic_partitions_with_whitelist.q,compare_string_bigint_2.q,udf_greatest_error_2.q,authorization_view_6.q,show_tablestatus.q,duplicate_alias_in_transform_schema.q,create_with_fk_uk_same_tab.q,udtf_not_supported3.q,alter_table_constraint_invalid_fk_col2.q,udtf_not_supported1.q,dbtxnmgr_notableunlock.q,ptf_negative_InvalidValueBoundary.q,alter_table_constraint_duplicate_pk.q,udf_printf_wrong4.q,create_view_failure9.q,udf_elt_wrong_type.q,selectDistinctStarNeg_1.q,invalid_mapjoin1.q,load_stored_as_dirs.q,input1.q,udf_sort_array_wrong1.q,invalid_distinct2.q,invalid_select_fn.q,authorization_role_grant_otherrole.q,archive4.q,load_nonpart_authfail.q,recursive_view.q,authorization_view_disable_cbo_1.q,desc_failure4.q,create_not_acid.q,udf_sort_array_wrong3.q,char_pad_convert_fail0.q,udf_map_values_arg_type.q,alter_view_failure6_2.q,alter_partition_change_col_nonexist.q,update_non_acid_table.q,authorization_view_disable_cbo_5.q,ct_noperm_loc.q,interval_1.q,authorization_show_grant_otheruser_all.q,authorization_view_2.q,show_tables_bad2.q,groupby_rollup2.q,truncate_column_seqfile.q,create_view_failure5.q,authorization_create_view.q,ptf_window_boundaries.q,ctasnullcol.q,input_part0_neg_2.q,create_or_replace_view1.q,udf_max.q,exim_01_nonpart_over_loaded.q,msck_repair_1.q,orc_change_fileformat_acid.q,udf_nonexistent_resource.q,msck_repair_3.q,exim_19_external_over_existing.q,serde_regex2.q,msck_repair_2.q,exim_06_nonpart_noncompat_storage.q,illegal_partition_type4.q,udf_sort_array_by_wrong1.q,windowing_leadlag_in_udaf.q,avro_decimal.q,materialized_view_update.q,illegal_partition_type2.q,invalid_varchar_length_1.q,authorization_view_5.q,nested_complex_neg.q,lockneg_try_drop_locked_db.q,constraint_partition_columns.q,authorization_insertpart_noinspriv.q,avro_add_column_extschema.q,udf_sort_array_wrong2.q,drop_database_cascade.q,archive3.q,alter_view_failure5.q,load_orc_negative1.q,create_external_acid.q,check_constraint_temporary_udf.q,file_with_header_footer_negative.q,alter_view_failure6.q,create_view_failure6.q,char_pad_convert_fail1.q,invalid_var_samp_syntax.q,update_partition_col.q,database_create_already_exists.q,union2.q,windowing_invalid_udaf.q,authorization_public_drop.q,truncate_table_failure5.q,alter_view_failure2.q,udf_reflect_neg.q,interval_2.q,column_rename2.q,set_hiveconf_validation0.q,materialized_view_drop2.q,repl_dump_requires_admin.q,alter_view_failure7.q,alter_view_failure4.q,alter_view_failure3.q,udf_map_keys_arg_type.q,alter_partition_with_whitelist.q,authorization_show_role_principals_no_admin.q,table_nonprintable_negative.q,clusterbydistributeby.q,authorization_rolehierarchy_privs.q,alter_notnull_constraint_violation.q,check_constraint_aggregate.q,script_broken_pipe3.q,column_rename3.q,authorization_fail_create_db.q,compute_stats_long.q,sortmerge_mapjoin_mismatch_1.q,insert_into6.q,select_charliteral.q,fs_default_name2.q,check_constraint_qual_name.q,archive_multi5.q,input4.q,create_udaf_failure.q,create_table_failure1.q,regex_col_1.q,materialized_view_authorization_no_select_perm.q,decimal_precision_1.q,columnstats_partlvl_multiple_part_clause.q,udf_if_not_bool.q,materialized_view_replace_with_view.q,invalid_cast_to_binary_6.q,lockneg5.q,database_drop_not_empty.q,smb_bucketmapjoin.q,alter_rename_partition_failure2.q,invalid_cast_to_binary_4.q,decimal_precision.q,create_view_failure10.q,invalid_cast_to_binary_3.q,groupby_invalid_position.q,load_wrong_fileformat_txt_seq.q,exchange_partition_neg_partition_exists.q,authorization_not_owner_alter_tab_serdeprop.q,alter_rename_partition_failure.q,merge_negative_5.q,authorization_invalid_priv_v2.q,bucket_mapjoin_wrong_table_metadata_1.q,lockneg2.q,join28.q,exchange_partition_neg_test.q,lockneg_try_lock_db_in_use.q,udf_assert_true.q,udf_coalesce.q,join29.q,archive_partspec4.q,exim_24_import_part_authfail.q,exim_08_nonpart_noncompat_serde.q,udtf_explode_not_supported4.q,create_view_failure4.q,default_constraint_invalid_default_value_type.q,invalid_char_length_1.q,udf_in.q,create_view_failure3.q,strict_pruning_2.q,insertexternal1.q,alter_partition_change_col_dup_col.q,authorization_ctas2.q,uniquejoin.q,authorization_role_grant_nosuchrole.q,column_rename4.q,create_with_fk_wrong_ref2.q,authorization_role_case.q,udf_if_wrong_args_len.q,create_skewed_table_col_name_value_no_mismatch.q,compare_string_bigint.q,archive_insert2.q,authorization_grant_table_fail1.q,exim_02_all_part_over_overlap.q,archive_multi1.q,subquery_in_groupby.q,authorization_role_grant.q,insert_into_with_schema3.q,create_with_fk_constraint.q,materialized_view_insert.q,orc_replace_columns1.q,updateBasicStats.q,udf_likeall_wrong1.q,udf_map_keys_arg_num.q,subquery_scalar_corr_multi_rows.q,exchange_partition_neg_partition_exists2.q,udf_test_error.q,distinct_windowing_failure2.q,authorization_caseinsensitivity.q,update_bucket_col.q,create_or_replace_view3.q,lockneg_query_tbl_in_locked_db.q,authorization_select_view.q,create_or_replace_view4.q,disallow_incompatible_type_change_on2.q,ptf_negative_DistributeByOrderBy.q,desc_failure3.q,create_insert_outputformat.q,alter_table_wrong_location2.q,groupby_grouping_sets5.q,authorization_uri_create_table_ext.q,invalid_t_create2.q,archive_corrupt.q,groupby_grouping_sets6.q,subquery_corr_grandparent.q,archive_insert3.q,authorization_alter_table_exchange_partition_fail2.q,invalid_cast_from_binary_2.q,authorize_grant_public.q,authorization_fail_drop_db.q,insert_into_with_schema4.q,parquet_alter_part_table_drop_columns.q,unionSortBy.q,invalid_char_length_2.q,insert_multi_into_notnull.q,groupby_grouping_id1.q,strict_orderby_2.q,udf_next_day_error_1.q,authorize_revoke_public.q,load_part_authfail.q,drop_default_partition_filter.q,orc_replace_columns2.q,alter_file_format.q,authorization_alter_db_owner_default.q,authorization_uri_createdb.q,authorization_import_ptn.q,selectDistinctWithoutAggr.q,split_sample_wrong_format.q,authorization_fail_8.q,regex_col_2.q,ptf_negative_PartitionBySortBy.q,stats_aggregator_error_2.q,drop_table_failure1.q,stats_aggregator_error_1.q,udf_concat_ws_wrong1.q,exim_12_nonnative_export.q,clustern4.q,strict_orderby.q,authorization_insertoverwrite_nodel.q,clustern3.q,exim_18_part_spec_missing.q,invalid_t_transform.q,columnstats_tbllvl_complex_type.q,authorization_grant_table_allpriv.q,msck_repair_4.q,set_hiveconf_validation1.q,authorization_alter_table_exchange_partition_fail.q,ctas_noemptyfolder.q,clustern2.q,set_hiveconf_validation2.q,bucket_mapjoin_mismatch1.q,mm_convert.q,orc_change_fileformat.q,truncate_bucketed_column.q,druid_datasource.q,udf_assert_true2.q,strict_join_2.q,udf_format_number_wrong3.q,default_constraint_invalid_default_value_length.q,masking_acid_update.q,materialized_view_no_transactional_rewrite_2.q,materialized_view_authorization_drop_other.q,dyn_part1.q,default_constraint_invalid_default_value2.q,select_star_suffix.q,subquery_select_distinct.q,authorization_uri_create_table1.q,special_character_in_tabnames_1.q,archive_partspec2.q,analyze_non_existent_tbl.q,create_with_pk_constraints_enforced.q,orderby_position_unsupported.q,subquery_subquery_chain_exists.q,orc_reorder_columns1_acid.q,subquery_notin_implicit_gby.q,notable_alias4.q,semijoin2.q,desc_failure1.q,ptf_negative_HavingLeadWithPTF.q,alter_tableprops_external_with_default_constraint.q,create_unknown_udf_udaf.q,materialized_view_authorization_create_no_grant.q,orc_change_serde.q,uniquejoin3.q,stats_publisher_error_1.q,authorization_part.q,alter_table_constraint_invalid_fk_tbl1.q,fileformat_void_input.q,truncate_table_failure3.q,alter_table_constraint_invalid_fk_tbl2.q,mismatch_columns_insertion.q,repl_load_requires_admin.q]
TestNonCatCallsWithCatalog - did not produce a TEST-*.xml file (likely timed out) (batchId=216)
TestReplicationOnHDFSEncryptedZones - did not produce a TEST-*.xml file (likely timed out) (batchId=230)
TestReplicationScenarios - did not produce a TEST-*.xml file (likely timed out) (batchId=230)
TestReplicationScenariosAcidTables - did not produce a TEST-*.xml file (likely timed out) (batchId=230)
TestReplicationScenariosAcrossInstances - did not produce a TEST-*.xml file (likely timed out) (batchId=230)
TestSequenceFileReadWrite - did not produce a TEST-*.xml file (likely timed out) (batchId=246)
TestTezPerfCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=252)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_table_stats] (batchId=54)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[statsoptimizer] (batchId=62)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[llap_smb] (batchId=153)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[bucket_map_join_tez_empty] (batchId=159)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[groupby_groupingset_bug] (batchId=174)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[insert_values_orig_table_use_metadata] (batchId=169)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[mergejoin] (batchId=168)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[sysdb] (batchId=163)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[tez_smb_main] (batchId=160)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_access_time_non_current_db] (batchId=172)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vectorization_div0] (batchId=170)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vectorized_dynamic_semijoin_reduction] (batchId=155)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_5] (batchId=105)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[subquery_scalar] (batchId=125)
org.apache.hadoop.hive.cli.TestSparkNegativeCliDriver.org.apache.hadoop.hive.cli.TestSparkNegativeCliDriver (batchId=254)
org.apache.hadoop.hive.cli.TestSparkPerfCliDriver.org.apache.hadoop.hive.cli.TestSparkPerfCliDriver (batchId=254)
org.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query11] (batchId=254)
org.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query15] (batchId=254)
org.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query16] (batchId=254)
org.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query18] (batchId=254)
org.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query19] (batchId=254)
org.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query21] (batchId=254)
org.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query24] (batchId=254)
org.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query25] (batchId=254)
org.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query29] (batchId=254)
org.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query30] (batchId=254)
org.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query32] (batchId=254)
org.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query34] (batchId=254)
org.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query35] (batchId=254)
org.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query37] (batchId=254)
org.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query40] (batchId=254)
org.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query44] (batchId=254)
org.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query45] (batchId=254)
org.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query46] (batchId=254)
org.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query47] (batchId=254)
org.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query48] (batchId=254)
org.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query4] (batchId=254)
org.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query50] (batchId=254)
org.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query53] (batchId=254)
org.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query54] (batchId=254)
org.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query57] (batchId=254)
org.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query58] (batchId=254)
org.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query5] (batchId=254)
org.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query61] (batchId=254)
org.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query63] (batchId=254)
org.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query65] (batchId=254)
org.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query66] (batchId=254)
org.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query67] (batchId=254)
org.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query68] (batchId=254)
org.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query6] (batchId=254)
org.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query72] (batchId=254)
org.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query73] (batchId=254)
org.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query75] (batchId=254)
org.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query76] (batchId=254)
org.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query77] (batchId=254)
org.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query78] (batchId=254)
org.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query79] (batchId=254)
org.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query80] (batchId=254)
org.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query81] (batchId=254)
org.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query82] (batchId=254)
org.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query83] (batchId=254)
org.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query85] (batchId=254)
org.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query88] (batchId=254)
org.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query89] (batchId=254)
org.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query8] (batchId=254)
org.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query90] (batchId=254)
org.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query91] (batchId=254)
org.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query92] (batchId=254)
org.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query94] (batchId=254)
org.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query95] (batchId=254)
org.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query97] (batchId=254)
org.apache.hadoop.hive.cli.TestSparkPerfCliDriver.testCliDriver[query99] (batchId=254)
org.apache.hadoop.hive.cli.control.TestDanglingQOuts.checkDanglingQOut (batchId=224)
org.apache.hadoop.hive.metastore.TestMetastoreVersion.testMetastoreVersion (batchId=226)
org.apache.hadoop.hive.metastore.TestMetastoreVersion.testVersionMatching (batchId=226)
org.apache.hadoop.hive.metastore.client.TestAppendPartitions.testAppendPartitionEmptyPartValues[Embedded] (batchId=210)
org.apache.hadoop.hive.metastore.client.TestAppendPartitions.testAppendPartitionEmptyPartValues[Remote] (batchId=210)
org.apache.hadoop.hive.metastore.client.TestAppendPartitions.testAppendPartitionNullPartValues[Embedded] (batchId=210)
org.apache.hadoop.hive.metastore.client.TestAppendPartitions.testAppendPartitionNullPartValues[Remote] (batchId=210)
org.apache.hadoop.hive.ql.TestAcidOnTez.testGetSplitsLocks (batchId=227)
org.apache.hadoop.hive.ql.TestMTQueries.testMTQueries1 (batchId=231)
org.apache.hadoop.hive.ql.TestTxnCommands2.testMmTableCompaction (batchId=286)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testMmTableCompaction (batchId=295)
org.apache.hadoop.hive.ql.TestTxnCommandsForMmTable.testInsertOverwriteForMmTable (batchId=263)
org.apache.hadoop.hive.ql.TestTxnCommandsForMmTable.testMmTableCompaction (batchId=263)
org.apache.hadoop.hive.ql.TestTxnCommandsForMmTable.testOperationsOnCompletedTxnComponentsForMmTable (batchId=263)
org.apache.hadoop.hive.ql.TestTxnCommandsForMmTable.testSnapshotIsolationWithAbortedTxnOnMmTable (batchId=263)
org.apache.hadoop.hive.ql.TestTxnCommandsForOrcMmTable.testInsertOverwriteForMmTable (batchId=283)
org.apache.hadoop.hive.ql.TestTxnCommandsForOrcMmTable.testMmTableCompaction (batchId=283)
org.apache.hadoop.hive.ql.TestTxnCommandsForOrcMmTable.testOperationsOnCompletedTxnComponentsForMmTable (batchId=283)
org.apache.hadoop.hive.ql.TestTxnCommandsForOrcMmTable.testSnapshotIsolationWithAbortedTxnOnMmTable (batchId=283)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.mmTable (batchId=229)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.mmTablePartitioned (batchId=229)
org.apache.hive.jdbc.TestJdbcWithMiniLlap.testLlapInputFormatEndToEnd (batchId=237)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/10055/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/10055/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-10055/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.YetusPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 111 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12917916 - PreCommit-HIVE-Build, Fixed some issues and added a test., [~ekoifman] [~gopalv] can you please review? the latest patch addresses the new transaction creation issue., | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
|| || || || {color:brown} Prechecks {color} ||
| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Findbugs executables are not available. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
|| || || || {color:brown} master Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 49s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  8m 48s{color} | {color:green} master passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  3m 13s{color} | {color:green} master passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m 43s{color} | {color:green} master passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m 55s{color} | {color:green} master passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 10s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:red}-1{color} | {color:red} mvninstall {color} | {color:red}  1m  1s{color} | {color:red} ql in the patch failed. {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  3m  8s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  3m  8s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} checkstyle {color} | {color:red}  0m 20s{color} | {color:red} itests/hive-unit: The patch generated 5 new + 76 unchanged - 0 fixed = 81 total (was 76) {color} |
| {color:red}-1{color} | {color:red} checkstyle {color} | {color:red}  0m 43s{color} | {color:red} ql: The patch generated 7 new + 210 unchanged - 1 fixed = 217 total (was 211) {color} |
| {color:red}-1{color} | {color:red} checkstyle {color} | {color:red}  0m 19s{color} | {color:red} standalone-metastore: The patch generated 1 new + 19 unchanged - 0 fixed = 20 total (was 19) {color} |
| {color:red}-1{color} | {color:red} whitespace {color} | {color:red}  0m  0s{color} | {color:red} The patch has 2 line(s) that end in whitespace. Use git apply --whitespace=fix <<patch_file>>. Refer https://git-scm.com/docs/git-apply {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m 44s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:red}-1{color} | {color:red} asflicense {color} | {color:red}  0m 16s{color} | {color:red} The patch generated 1 ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 28m 59s{color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Optional Tests |  asflicense  javac  javadoc  findbugs  checkstyle  compile  |
| uname | Linux hiveptest-server-upstream 3.16.0-4-amd64 #1 SMP Debian 3.16.36-1+deb8u1 (2016-09-03) x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /data/hiveptest/working/yetus_PreCommit-HIVE-Build-10280/dev-support/hive-personality.sh |
| git revision | master / 4cfec3e |
| Default Java | 1.8.0_111 |
| mvninstall | http://104.198.109.242/logs//PreCommit-HIVE-Build-10280/yetus/patch-mvninstall-ql.txt |
| checkstyle | http://104.198.109.242/logs//PreCommit-HIVE-Build-10280/yetus/diff-checkstyle-itests_hive-unit.txt |
| checkstyle | http://104.198.109.242/logs//PreCommit-HIVE-Build-10280/yetus/diff-checkstyle-ql.txt |
| checkstyle | http://104.198.109.242/logs//PreCommit-HIVE-Build-10280/yetus/diff-checkstyle-standalone-metastore.txt |
| whitespace | http://104.198.109.242/logs//PreCommit-HIVE-Build-10280/yetus/whitespace-eol.txt |
| asflicense | http://104.198.109.242/logs//PreCommit-HIVE-Build-10280/yetus/patch-asflicense-problems.txt |
| modules | C: storage-api itests/hive-unit ql standalone-metastore U: . |
| Console output | http://104.198.109.242/logs//PreCommit-HIVE-Build-10280/yetus.txt |
| Powered by | Apache Yetus    http://yetus.apache.org |


This message was automatically generated.

, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12919293/HIVE-19124.02.patch

{color:green}SUCCESS:{color} +1 due to 1 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 38 failed/errored test(s), 14240 tests executed
*Failed tests:*
{noformat}
TestDbNotificationListener - did not produce a TEST-*.xml file (likely timed out) (batchId=247)
TestHCatHiveCompatibility - did not produce a TEST-*.xml file (likely timed out) (batchId=247)
TestNonCatCallsWithCatalog - did not produce a TEST-*.xml file (likely timed out) (batchId=217)
TestSequenceFileReadWrite - did not produce a TEST-*.xml file (likely timed out) (batchId=247)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[llap_smb] (batchId=92)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[parquet_vectorization_0] (batchId=17)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[results_cache_invalidation2] (batchId=39)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[tez_join_hash] (batchId=54)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[results_cache_invalidation2] (batchId=163)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[sysdb] (batchId=163)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[tez_smb_1] (batchId=171)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_5] (batchId=105)
org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver[infer_bucket_sort_dyn_part] (batchId=93)
org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver[infer_bucket_sort_map_operators] (batchId=93)
org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver[infer_bucket_sort_num_buckets] (batchId=93)
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[alter_notnull_constraint_violation] (batchId=96)
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[default_constraint_invalid_default_value_type] (batchId=96)
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[insert_into_acid_notnull] (batchId=95)
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[insert_into_notnull_constraint] (batchId=95)
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[insert_multi_into_notnull] (batchId=96)
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[insert_overwrite_notnull_constraint] (batchId=96)
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[insertsel_fail] (batchId=95)
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[update_notnull_constraint] (batchId=95)
org.apache.hadoop.hive.cli.control.TestDanglingQOuts.checkDanglingQOut (batchId=225)
org.apache.hadoop.hive.druid.TestDruidStorageHandler.testCommitMultiInsertOverwriteTable (batchId=261)
org.apache.hadoop.hive.llap.daemon.impl.comparator.TestAMReporter.testMultipleAM (batchId=309)
org.apache.hadoop.hive.ql.TestAcidOnTez.testAcidInsertWithRemoveUnion (batchId=228)
org.apache.hadoop.hive.ql.TestAcidOnTez.testCtasTezUnion (batchId=228)
org.apache.hadoop.hive.ql.TestAcidOnTez.testNonStandardConversion01 (batchId=228)
org.apache.hadoop.hive.ql.TestMTQueries.testMTQueries1 (batchId=232)
org.apache.hadoop.hive.ql.TestTxnCommands2.testMmTableCompaction (batchId=287)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testMmTableCompaction (batchId=296)
org.apache.hadoop.hive.ql.TestTxnCommandsForMmTable.testInsertOverwriteForMmTable (batchId=264)
org.apache.hadoop.hive.ql.TestTxnCommandsForMmTable.testMmTableCompaction (batchId=264)
org.apache.hadoop.hive.ql.TestTxnCommandsForMmTable.testSnapshotIsolationWithAbortedTxnOnMmTable (batchId=264)
org.apache.hadoop.hive.ql.TestTxnCommandsForOrcMmTable.testInsertOverwriteForMmTable (batchId=284)
org.apache.hadoop.hive.ql.TestTxnCommandsForOrcMmTable.testMmTableCompaction (batchId=284)
org.apache.hadoop.hive.ql.TestTxnCommandsForOrcMmTable.testSnapshotIsolationWithAbortedTxnOnMmTable (batchId=284)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/10280/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/10280/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-10280/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.YetusPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 38 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12919293 - PreCommit-HIVE-Build, Addressing table type and other characteristics and adding another test.
Also added a config setting.

I think what we eventually need is adding "insert overwrite directory compact" command that will do the right thing for all of this... I left a todo in insert overwrite directory path. Then, it can write the base in place for both ACID and non ACID, via a query, as long as (1) it's done inside a txn (2) the insert overwrite bug is fixed., Again for HiveQA, left some RB comments (btw, it seems to have old patch 3), | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
|| || || || {color:brown} Prechecks {color} ||
| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  1s{color} | {color:blue} Findbugs executables are not available. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
|| || || || {color:brown} master Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 51s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  8m  9s{color} | {color:green} master passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  3m 19s{color} | {color:green} master passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m 59s{color} | {color:green} master passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m 57s{color} | {color:green} master passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m  9s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:red}-1{color} | {color:red} mvninstall {color} | {color:red}  0m 56s{color} | {color:red} ql in the patch failed. {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  3m 13s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  3m 13s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} checkstyle {color} | {color:red}  0m 17s{color} | {color:red} itests/hive-unit: The patch generated 6 new + 76 unchanged - 0 fixed = 82 total (was 76) {color} |
| {color:red}-1{color} | {color:red} checkstyle {color} | {color:red}  0m 47s{color} | {color:red} ql: The patch generated 14 new + 412 unchanged - 1 fixed = 426 total (was 413) {color} |
| {color:red}-1{color} | {color:red} checkstyle {color} | {color:red}  0m 19s{color} | {color:red} standalone-metastore: The patch generated 1 new + 19 unchanged - 0 fixed = 20 total (was 19) {color} |
| {color:red}-1{color} | {color:red} whitespace {color} | {color:red}  0m  0s{color} | {color:red} The patch has 2 line(s) that end in whitespace. Use git apply --whitespace=fix <<patch_file>>. Refer https://git-scm.com/docs/git-apply {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  3m  3s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 16s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 29m 38s{color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Optional Tests |  asflicense  javac  javadoc  findbugs  checkstyle  compile  |
| uname | Linux hiveptest-server-upstream 3.16.0-4-amd64 #1 SMP Debian 3.16.36-1+deb8u1 (2016-09-03) x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /data/hiveptest/working/yetus_PreCommit-HIVE-Build-10376/dev-support/hive-personality.sh |
| git revision | master / 35d1811 |
| Default Java | 1.8.0_111 |
| mvninstall | http://104.198.109.242/logs//PreCommit-HIVE-Build-10376/yetus/patch-mvninstall-ql.txt |
| checkstyle | http://104.198.109.242/logs//PreCommit-HIVE-Build-10376/yetus/diff-checkstyle-itests_hive-unit.txt |
| checkstyle | http://104.198.109.242/logs//PreCommit-HIVE-Build-10376/yetus/diff-checkstyle-ql.txt |
| checkstyle | http://104.198.109.242/logs//PreCommit-HIVE-Build-10376/yetus/diff-checkstyle-standalone-metastore.txt |
| whitespace | http://104.198.109.242/logs//PreCommit-HIVE-Build-10376/yetus/whitespace-eol.txt |
| modules | C: storage-api common itests/hive-unit ql standalone-metastore U: . |
| Console output | http://104.198.109.242/logs//PreCommit-HIVE-Build-10376/yetus.txt |
| Powered by | Apache Yetus    http://yetus.apache.org |


This message was automatically generated.

, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12919935/HIVE-19124.04.patch

{color:green}SUCCESS:{color} +1 due to 1 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 27 failed/errored test(s), 14284 tests executed
*Failed tests:*
{noformat}
TestMinimrCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=93)
	[infer_bucket_sort_num_buckets.q,infer_bucket_sort_reducers_power_two.q,parallel_orderby.q,bucket_num_reducers_acid.q,infer_bucket_sort_map_operators.q,infer_bucket_sort_merge.q,root_dir_external_table.q,infer_bucket_sort_dyn_part.q,udf_using.q,bucket_num_reducers_acid2.q]
TestNonCatCallsWithCatalog - did not produce a TEST-*.xml file (likely timed out) (batchId=217)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[llap_smb] (batchId=92)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[parquet_vectorization_0] (batchId=17)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[results_cache_invalidation2] (batchId=39)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[tez_join_hash] (batchId=54)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[results_cache_invalidation2] (batchId=163)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[sysdb] (batchId=163)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[tez_smb_1] (batchId=171)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_5] (batchId=105)
org.apache.hadoop.hive.cli.TestNegativeMinimrCliDriver.testCliDriver[cluster_tasklog_retrieval] (batchId=98)
org.apache.hadoop.hive.cli.TestNegativeMinimrCliDriver.testCliDriver[mapreduce_stack_trace] (batchId=98)
org.apache.hadoop.hive.cli.TestNegativeMinimrCliDriver.testCliDriver[mapreduce_stack_trace_turnoff] (batchId=98)
org.apache.hadoop.hive.cli.TestNegativeMinimrCliDriver.testCliDriver[minimr_broken_pipe] (batchId=98)
org.apache.hadoop.hive.cli.control.TestDanglingQOuts.checkDanglingQOut (batchId=225)
org.apache.hadoop.hive.metastore.TestStats.partitionedTableInHiveCatalog (batchId=211)
org.apache.hadoop.hive.ql.TestAcidOnTez.testAcidInsertWithRemoveUnion (batchId=228)
org.apache.hadoop.hive.ql.TestAcidOnTez.testCtasTezUnion (batchId=228)
org.apache.hadoop.hive.ql.TestAcidOnTez.testNonStandardConversion01 (batchId=228)
org.apache.hadoop.hive.ql.TestMTQueries.testMTQueries1 (batchId=232)
org.apache.hadoop.hive.ql.TestTxnCommandsForMmTable.testInsertOverwriteForMmTable (batchId=264)
org.apache.hadoop.hive.ql.TestTxnCommandsForOrcMmTable.testInsertOverwriteForMmTable (batchId=284)
org.apache.hive.beeline.TestBeeLineWithArgs.testQueryProgress (batchId=235)
org.apache.hive.beeline.TestBeeLineWithArgs.testQueryProgressParallel (batchId=235)
org.apache.hive.jdbc.TestTriggersMoveWorkloadManager.testTriggerMoveAndKill (batchId=242)
org.apache.hive.jdbc.TestTriggersMoveWorkloadManager.testTriggerMoveConflictKill (batchId=242)
org.apache.hive.minikdc.TestJdbcWithMiniKdcCookie.testCookieNegative (batchId=254)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/10376/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/10376/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-10376/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.YetusPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 27 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12919935 - PreCommit-HIVE-Build, Heh, the only relevant failures are IOW tests for MM table. They run compact for whatever reason, which used to do nothing, but does something now., Removed the parts of the test that test compaction; it's already tested in the compactor test., | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
|| || || || {color:brown} Prechecks {color} ||
| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Findbugs executables are not available. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  1s{color} | {color:green} The patch does not contain any @author tags. {color} |
|| || || || {color:brown} master Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 49s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  7m 40s{color} | {color:green} master passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  3m 10s{color} | {color:green} master passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m 56s{color} | {color:green} master passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m 51s{color} | {color:green} master passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 11s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:red}-1{color} | {color:red} mvninstall {color} | {color:red}  0m 51s{color} | {color:red} ql in the patch failed. {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  3m  9s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  3m  9s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} checkstyle {color} | {color:red}  0m 18s{color} | {color:red} itests/hive-unit: The patch generated 6 new + 76 unchanged - 0 fixed = 82 total (was 76) {color} |
| {color:red}-1{color} | {color:red} checkstyle {color} | {color:red}  0m 47s{color} | {color:red} ql: The patch generated 18 new + 531 unchanged - 8 fixed = 549 total (was 539) {color} |
| {color:red}-1{color} | {color:red} checkstyle {color} | {color:red}  0m 18s{color} | {color:red} standalone-metastore: The patch generated 1 new + 19 unchanged - 0 fixed = 20 total (was 19) {color} |
| {color:red}-1{color} | {color:red} whitespace {color} | {color:red}  0m  0s{color} | {color:red} The patch has 2 line(s) that end in whitespace. Use git apply --whitespace=fix <<patch_file>>. Refer https://git-scm.com/docs/git-apply {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m 48s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 15s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 28m 16s{color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Optional Tests |  asflicense  javac  javadoc  findbugs  checkstyle  compile  |
| uname | Linux hiveptest-server-upstream 3.16.0-4-amd64 #1 SMP Debian 3.16.36-1+deb8u1 (2016-09-03) x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /data/hiveptest/working/yetus_PreCommit-HIVE-Build-10398/dev-support/hive-personality.sh |
| git revision | master / 9fddd6d |
| Default Java | 1.8.0_111 |
| mvninstall | http://104.198.109.242/logs//PreCommit-HIVE-Build-10398/yetus/patch-mvninstall-ql.txt |
| checkstyle | http://104.198.109.242/logs//PreCommit-HIVE-Build-10398/yetus/diff-checkstyle-itests_hive-unit.txt |
| checkstyle | http://104.198.109.242/logs//PreCommit-HIVE-Build-10398/yetus/diff-checkstyle-ql.txt |
| checkstyle | http://104.198.109.242/logs//PreCommit-HIVE-Build-10398/yetus/diff-checkstyle-standalone-metastore.txt |
| whitespace | http://104.198.109.242/logs//PreCommit-HIVE-Build-10398/yetus/whitespace-eol.txt |
| modules | C: storage-api common itests/hive-unit ql standalone-metastore U: . |
| Console output | http://104.198.109.242/logs//PreCommit-HIVE-Build-10398/yetus.txt |
| Powered by | Apache Yetus    http://yetus.apache.org |


This message was automatically generated.

, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12920113/HIVE-19124.05.patch

{color:green}SUCCESS:{color} +1 due to 2 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 24 failed/errored test(s), 14288 tests executed
*Failed tests:*
{noformat}
TestMinimrCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=93)
	[infer_bucket_sort_num_buckets.q,infer_bucket_sort_reducers_power_two.q,parallel_orderby.q,bucket_num_reducers_acid.q,infer_bucket_sort_map_operators.q,infer_bucket_sort_merge.q,root_dir_external_table.q,infer_bucket_sort_dyn_part.q,udf_using.q,bucket_num_reducers_acid2.q]
TestNonCatCallsWithCatalog - did not produce a TEST-*.xml file (likely timed out) (batchId=217)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[parquet_vectorization_0] (batchId=17)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[results_cache_invalidation2] (batchId=39)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[check_constraint] (batchId=158)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[default_constraint] (batchId=163)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[results_cache_invalidation2] (batchId=163)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[sysdb] (batchId=163)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[tez_smb_1] (batchId=171)
org.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver[bucketizedhiveinputformat] (batchId=183)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_5] (batchId=105)
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[update_non_acid_table] (batchId=96)
org.apache.hadoop.hive.cli.TestNegativeMinimrCliDriver.testCliDriver[cluster_tasklog_retrieval] (batchId=98)
org.apache.hadoop.hive.cli.TestNegativeMinimrCliDriver.testCliDriver[mapreduce_stack_trace] (batchId=98)
org.apache.hadoop.hive.cli.TestNegativeMinimrCliDriver.testCliDriver[mapreduce_stack_trace_turnoff] (batchId=98)
org.apache.hadoop.hive.cli.TestNegativeMinimrCliDriver.testCliDriver[minimr_broken_pipe] (batchId=98)
org.apache.hadoop.hive.ql.TestAcidOnTez.testAcidInsertWithRemoveUnion (batchId=228)
org.apache.hadoop.hive.ql.TestAcidOnTez.testCtasTezUnion (batchId=228)
org.apache.hadoop.hive.ql.TestAcidOnTez.testNonStandardConversion01 (batchId=228)
org.apache.hadoop.hive.ql.TestMTQueries.testMTQueries1 (batchId=232)
org.apache.hive.beeline.TestBeeLineWithArgs.testQueryProgress (batchId=235)
org.apache.hive.beeline.TestBeeLineWithArgs.testQueryProgressParallel (batchId=235)
org.apache.hive.jdbc.TestMultiSessionsHS2WithLocalClusterSpark.testNonSparkQuery (batchId=242)
org.apache.hive.minikdc.TestJdbcWithMiniKdcCookie.testCookieNegative (batchId=254)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/10398/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/10398/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-10398/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.YetusPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 24 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12920113 - PreCommit-HIVE-Build, Addressed the recent CR feedback, Cannot repro the only seemingly relevant test failure, seems to be a setup issue., 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12920323/HIVE-19124.06.patch

{color:red}ERROR:{color} -1 due to build exiting with an error

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/10441/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/10441/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-10441/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Tests exited with: NonZeroExitCodeException
Command 'bash /data/hiveptest/working/scratch/source-prep.sh' failed with exit status 1 and output '+ date '+%Y-%m-%d %T.%3N'
2018-04-23 21:30:07.147
+ [[ -n /usr/lib/jvm/java-8-openjdk-amd64 ]]
+ export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
+ JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
+ export PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games
+ PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games
+ export 'ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m '
+ ANT_OPTS='-Xmx1g -XX:MaxPermSize=256m '
+ export 'MAVEN_OPTS=-Xmx1g '
+ MAVEN_OPTS='-Xmx1g '
+ cd /data/hiveptest/working/
+ tee /data/hiveptest/logs/PreCommit-HIVE-Build-10441/source-prep.txt
+ [[ false == \t\r\u\e ]]
+ mkdir -p maven ivy
+ [[ git = \s\v\n ]]
+ [[ git = \g\i\t ]]
+ [[ -z master ]]
+ [[ -d apache-github-source-source ]]
+ [[ ! -d apache-github-source-source/.git ]]
+ [[ ! -d apache-github-source-source ]]
+ date '+%Y-%m-%d %T.%3N'
2018-04-23 21:30:07.149
+ cd apache-github-source-source
+ git fetch origin
From https://github.com/apache/hive
   b3e2d8a..997ad34  master     -> origin/master
   e47ccbc..1c48251  branch-3   -> origin/branch-3
+ git reset --hard HEAD
HEAD is now at b3e2d8a HIVE-19171 : Persist runtime statistics in metastore (Zoltan Haindrich via Ashutosh Chauhan)
+ git clean -f -d
+ git checkout master
Already on 'master'
Your branch is behind 'origin/master' by 1 commit, and can be fast-forwarded.
  (use "git pull" to update your local branch)
+ git reset --hard origin/master
HEAD is now at 997ad34 HIVE-19168: Ranger changes for llap commands (Prasanth Jayachandran reviewed by Sergey Shelukhin)
+ git merge --ff-only origin/master
Already up-to-date.
+ date '+%Y-%m-%d %T.%3N'
2018-04-23 21:30:08.204
+ rm -rf ../yetus_PreCommit-HIVE-Build-10441
+ mkdir ../yetus_PreCommit-HIVE-Build-10441
+ git gc
+ cp -R . ../yetus_PreCommit-HIVE-Build-10441
+ mkdir /data/hiveptest/logs/PreCommit-HIVE-Build-10441/yetus
+ patchCommandPath=/data/hiveptest/working/scratch/smart-apply-patch.sh
+ patchFilePath=/data/hiveptest/working/scratch/build.patch
+ [[ -f /data/hiveptest/working/scratch/build.patch ]]
+ chmod +x /data/hiveptest/working/scratch/smart-apply-patch.sh
+ /data/hiveptest/working/scratch/smart-apply-patch.sh /data/hiveptest/working/scratch/build.patch
Going to apply patch with: git apply -p0
/data/hiveptest/working/scratch/build.patch:196: trailing whitespace.
    verifyHasBase(table.getSd(), fs, "base_0000005"); 
/data/hiveptest/working/scratch/build.patch:250: trailing whitespace.
 
warning: 2 lines add whitespace errors.
+ [[ maven == \m\a\v\e\n ]]
+ rm -rf /data/hiveptest/working/maven/org/apache/hive
+ mvn -B clean install -DskipTests -T 4 -q -Dmaven.repo.local=/data/hiveptest/working/maven
protoc-jar: executing: [/tmp/protoc500762848101639493.exe, --version]
libprotoc 2.5.0
protoc-jar: executing: [/tmp/protoc500762848101639493.exe, -I/data/hiveptest/working/apache-github-source-source/standalone-metastore/src/main/protobuf/org/apache/hadoop/hive/metastore, --java_out=/data/hiveptest/working/apache-github-source-source/standalone-metastore/target/generated-sources, /data/hiveptest/working/apache-github-source-source/standalone-metastore/src/main/protobuf/org/apache/hadoop/hive/metastore/metastore.proto]
ANTLR Parser Generator  Version 3.5.2
Output file /data/hiveptest/working/apache-github-source-source/standalone-metastore/target/generated-sources/org/apache/hadoop/hive/metastore/parser/FilterParser.java does not exist: must build /data/hiveptest/working/apache-github-source-source/standalone-metastore/src/main/java/org/apache/hadoop/hive/metastore/parser/Filter.g
org/apache/hadoop/hive/metastore/parser/Filter.g
log4j:WARN No appenders could be found for logger (DataNucleus.Persistence).
log4j:WARN Please initialize the log4j system properly.
DataNucleus Enhancer (version 4.1.17) for API "JDO"
DataNucleus Enhancer completed with success for 40 classes.
ANTLR Parser Generator  Version 3.5.2
Output file /data/hiveptest/working/apache-github-source-source/ql/target/generated-sources/antlr3/org/apache/hadoop/hive/ql/parse/HiveLexer.java does not exist: must build /data/hiveptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveLexer.g
org/apache/hadoop/hive/ql/parse/HiveLexer.g
Output file /data/hiveptest/working/apache-github-source-source/ql/target/generated-sources/antlr3/org/apache/hadoop/hive/ql/parse/HiveParser.java does not exist: must build /data/hiveptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g
org/apache/hadoop/hive/ql/parse/HiveParser.g
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:2376:5: 
Decision can match input such as "KW_CHECK {KW_EXISTS, KW_TINYINT}" using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:2376:5: 
Decision can match input such as "KW_CHECK KW_STRUCT LESSTHAN" using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:2376:5: 
Decision can match input such as "KW_CHECK KW_DATETIME" using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:2376:5: 
Decision can match input such as "KW_CHECK KW_DATE {LPAREN, StringLiteral}" using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:2376:5: 
Decision can match input such as "KW_CHECK KW_UNIONTYPE LESSTHAN" using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
Output file /data/hiveptest/working/apache-github-source-source/ql/target/generated-sources/antlr3/org/apache/hadoop/hive/ql/parse/HintParser.java does not exist: must build /data/hiveptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HintParser.g
org/apache/hadoop/hive/ql/parse/HintParser.g
Generating vector expression code
Generating vector expression test code
[ERROR] COMPILATION ERROR : 
[ERROR] /data/hiveptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/plan/mapper/SimpleRuntimeStatsSource.java:[29,8] class MapBackedStatsSource is public, should be declared in a file named MapBackedStatsSource.java
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.6.1:compile (default-compile) on project hive-exec: Compilation failure
[ERROR] /data/hiveptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/plan/mapper/SimpleRuntimeStatsSource.java:[29,8] class MapBackedStatsSource is public, should be declared in a file named MapBackedStatsSource.java
[ERROR] -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn <goals> -rf :hive-exec
+ exit 1
'
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12920323 - PreCommit-HIVE-Build, | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
|| || || || {color:brown} Prechecks {color} ||
| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  1s{color} | {color:blue} Findbugs executables are not available. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
|| || || || {color:brown} master Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 51s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  8m  6s{color} | {color:green} master passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  3m 23s{color} | {color:green} master passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m 59s{color} | {color:green} master passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m 53s{color} | {color:green} master passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m  9s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:red}-1{color} | {color:red} mvninstall {color} | {color:red}  0m 55s{color} | {color:red} ql in the patch failed. {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  3m  9s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  3m  9s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} checkstyle {color} | {color:red}  0m 18s{color} | {color:red} itests/hive-unit: The patch generated 6 new + 76 unchanged - 0 fixed = 82 total (was 76) {color} |
| {color:red}-1{color} | {color:red} checkstyle {color} | {color:red}  0m 48s{color} | {color:red} ql: The patch generated 20 new + 532 unchanged - 8 fixed = 552 total (was 540) {color} |
| {color:red}-1{color} | {color:red} checkstyle {color} | {color:red}  0m 19s{color} | {color:red} standalone-metastore: The patch generated 1 new + 19 unchanged - 0 fixed = 20 total (was 19) {color} |
| {color:red}-1{color} | {color:red} whitespace {color} | {color:red}  0m  0s{color} | {color:red} The patch has 2 line(s) that end in whitespace. Use git apply --whitespace=fix <<patch_file>>. Refer https://git-scm.com/docs/git-apply {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m 53s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 15s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 29m 21s{color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Optional Tests |  asflicense  javac  javadoc  findbugs  checkstyle  compile  |
| uname | Linux hiveptest-server-upstream 3.16.0-4-amd64 #1 SMP Debian 3.16.36-1+deb8u1 (2016-09-03) x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /data/hiveptest/working/yetus_PreCommit-HIVE-Build-10449/dev-support/hive-personality.sh |
| git revision | master / f019950 |
| Default Java | 1.8.0_111 |
| mvninstall | http://104.198.109.242/logs//PreCommit-HIVE-Build-10449/yetus/patch-mvninstall-ql.txt |
| checkstyle | http://104.198.109.242/logs//PreCommit-HIVE-Build-10449/yetus/diff-checkstyle-itests_hive-unit.txt |
| checkstyle | http://104.198.109.242/logs//PreCommit-HIVE-Build-10449/yetus/diff-checkstyle-ql.txt |
| checkstyle | http://104.198.109.242/logs//PreCommit-HIVE-Build-10449/yetus/diff-checkstyle-standalone-metastore.txt |
| whitespace | http://104.198.109.242/logs//PreCommit-HIVE-Build-10449/yetus/whitespace-eol.txt |
| modules | C: storage-api common itests/hive-unit ql standalone-metastore U: . |
| Console output | http://104.198.109.242/logs//PreCommit-HIVE-Build-10449/yetus.txt |
| Powered by | Apache Yetus    http://yetus.apache.org |


This message was automatically generated.

, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12920352/HIVE-19124.07.patch

{color:green}SUCCESS:{color} +1 due to 2 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 33 failed/errored test(s), 14290 tests executed
*Failed tests:*
{noformat}
TestMinimrCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=93)
	[infer_bucket_sort_num_buckets.q,infer_bucket_sort_reducers_power_two.q,parallel_orderby.q,bucket_num_reducers_acid.q,infer_bucket_sort_map_operators.q,infer_bucket_sort_merge.q,root_dir_external_table.q,infer_bucket_sort_dyn_part.q,udf_using.q,bucket_num_reducers_acid2.q]
TestNonCatCallsWithCatalog - did not produce a TEST-*.xml file (likely timed out) (batchId=217)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[parquet_vectorization_0] (batchId=17)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[results_cache_invalidation2] (batchId=39)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[bucket_map_join_tez1] (batchId=175)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[check_constraint] (batchId=158)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[default_constraint] (batchId=163)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[mergejoin] (batchId=169)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[results_cache_invalidation2] (batchId=163)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[sysdb] (batchId=163)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[tez_smb_1] (batchId=171)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_5] (batchId=105)
org.apache.hadoop.hive.cli.TestNegativeMinimrCliDriver.testCliDriver[cluster_tasklog_retrieval] (batchId=98)
org.apache.hadoop.hive.cli.TestNegativeMinimrCliDriver.testCliDriver[mapreduce_stack_trace] (batchId=98)
org.apache.hadoop.hive.cli.TestNegativeMinimrCliDriver.testCliDriver[mapreduce_stack_trace_turnoff] (batchId=98)
org.apache.hadoop.hive.cli.TestNegativeMinimrCliDriver.testCliDriver[minimr_broken_pipe] (batchId=98)
org.apache.hadoop.hive.ql.TestAcidOnTez.testAcidInsertWithRemoveUnion (batchId=228)
org.apache.hadoop.hive.ql.TestAcidOnTez.testCtasTezUnion (batchId=228)
org.apache.hadoop.hive.ql.TestAcidOnTez.testNonStandardConversion01 (batchId=228)
org.apache.hadoop.hive.ql.TestMTQueries.testMTQueries1 (batchId=232)
org.apache.hive.beeline.TestBeeLineWithArgs.testQueryProgressParallel (batchId=235)
org.apache.hive.jdbc.TestSSL.testSSLFetchHttp (batchId=239)
org.apache.hive.minikdc.TestJdbcWithDBTokenStore.testTokenAuth (batchId=254)
org.apache.hive.minikdc.TestJdbcWithDBTokenStoreNoDoAs.testCancelRenewTokenFlow (batchId=254)
org.apache.hive.minikdc.TestJdbcWithDBTokenStoreNoDoAs.testConnection (batchId=254)
org.apache.hive.minikdc.TestJdbcWithDBTokenStoreNoDoAs.testIsValid (batchId=254)
org.apache.hive.minikdc.TestJdbcWithDBTokenStoreNoDoAs.testIsValidNeg (batchId=254)
org.apache.hive.minikdc.TestJdbcWithDBTokenStoreNoDoAs.testNegativeProxyAuth (batchId=254)
org.apache.hive.minikdc.TestJdbcWithDBTokenStoreNoDoAs.testNegativeTokenAuth (batchId=254)
org.apache.hive.minikdc.TestJdbcWithDBTokenStoreNoDoAs.testProxyAuth (batchId=254)
org.apache.hive.minikdc.TestJdbcWithDBTokenStoreNoDoAs.testRenewDelegationToken (batchId=254)
org.apache.hive.minikdc.TestJdbcWithDBTokenStoreNoDoAs.testTokenAuth (batchId=254)
org.apache.hive.minikdc.TestJdbcWithMiniKdcCookie.testCookieNegative (batchId=254)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/10449/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/10449/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-10449/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.YetusPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 33 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12920352 - PreCommit-HIVE-Build, LGTM - +1 

This ticket opens up an interesting question about the way metastore fires off compactor jobs (i.e the metastore has to have access to a YARN cluster & it needs to submit it to a specific queue etc)., Well, it already needs to have access to the cluster to use the MR compactor job.
When metastore is separate from Hive, I think compactor should move to HS2 cc [~alangates], Hold on.  We already have a mechanism for compactor to make sure it doesn't compact above an open txn:
TxnUtils.createValidCompactWriteIdList() .
This reinvents the wheel and add a new one to do the same thing in the Reader list.  Why is this good?, Yes, this is true even today, but it will move away with standalone-metastore.

I just realized there's one dropped issue in the code from [~ekoifman] to address.

TxnUtils.updateForCompactionQuery is yet another codepath, which we shouldn't need - the TxnUtils.createValidCompactWriteIdList goes further ahead than that.

Basically if low-water mark is x and x+1, x+2 etc are aborted, your impl only compactors till x., See the comment on RB; we don't have the same input structures needed for this method. There are too many different classes that do not convert into each other... it's better to have an utility method that adjust one property than to convert existing structure back to thrift (or alternatively call metastore again) and then rebuild the new one from scratch from thrift., I saw the comment.  That isn't acceptable.  , There's tons of code in AcidUtils that does similar things based on different inputs (e.g. overloads if isAcidTable)... why is this not acceptable?
Do you want to modify the latest patch? I don't see a way to use this method without either copy-pasting the old method for different input structure, or making it so we do a root canal thru the ear..., You need to modify the TxnUtils to accept a ValidReaderWriteIdList and rewrite the current impl as 

{code}
return createValidCompactWriteIdList(createValidReaderWriteIdList(tableWriteIds));
{code}

And then you don't need a new metastore object.

ValidReaderWriteIdList & ValidCompactorWriteIdList extends ValidReaderWriteIdList

You need a ValidReaderWriteIdList.get to pass into compactionWriteIds., Frankly having to do this points at the need to get rid of all these classes and just have a single one; in a follow up patch. I'll take a look into the root canal thru the ear variant today, for now., bq. I'll take a look into the root canal thru the ear variant today, for now.

Thanks, I'll hold my +1 back for that patch., a simpler approach would have been to address HIVE-18570 first by requiring X lock IOW, then by definition there would be no open txns at the time IOW runs (and similarly no open write txns when X lock is replaced by Write lock which still allows readers).  Unfortunately it's no longer possible since HIVE-18825 moved snapshot acquisition to be before lock acquisition.

I think a larger issue (including Gopal's proposal) is that it gets the wrong HWM.  If you look at Worker,
it creates a Compaction writeIldList and stores the HWM in the metastore.  This is important so that Cleaner later doesn't clean above this mark, i.e. the highest level compaction looked at.

In this patch, the MM compactor IOW query creates it's own Snapshot which may be different.  Perhaps a more consistent approach is to set the snapshot on the Driver in compaction mode from Worker to make this consistent. , The patch currently extracts the write IDs that driver has actually used (and will continue doing so after the change).
The HWM from there can be recorded..., Updated the patch. I ended up splitting the metastore call path to allow the creation of the object without back-conversion., My point was that instead of letting the Driver create the list, the list created by Worker should be passed to the Driver.  That way it doesn't have to extract any ids, does it?  (and the flow between MM and acid remains more similar)
This is the code from Worker that I'm referring to 
{noformat}
        String fullTableName = TxnUtils.getFullTableName(t.getDbName(), t.getTableName());
        GetValidWriteIdsRequest rqst = new GetValidWriteIdsRequest(Collections.singletonList(fullTableName), null);
        final ValidWriteIdList tblValidWriteIds =
                TxnUtils.createValidCompactWriteIdList(txnHandler.getValidWriteIds(rqst).getTblValidWriteIds().get(0));
        LOG.debug("ValidCompactWriteIdList: " + tblValidWriteIds.writeToString());
        txnHandler.setCompactionHighestWriteId(ci, tblValidWriteIds.getHighWatermark());
{noformat}
, Updated, LGTM.  Thank you., | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
|| || || || {color:brown} Prechecks {color} ||
| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Findbugs executables are not available. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
|| || || || {color:brown} master Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 47s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  8m 22s{color} | {color:green} master passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  3m 10s{color} | {color:green} master passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m  4s{color} | {color:green} master passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m 55s{color} | {color:green} master passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m  9s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:red}-1{color} | {color:red} mvninstall {color} | {color:red}  0m 53s{color} | {color:red} ql in the patch failed. {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  3m 14s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  3m 14s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} checkstyle {color} | {color:red}  0m 18s{color} | {color:red} itests/hive-unit: The patch generated 6 new + 76 unchanged - 0 fixed = 82 total (was 76) {color} |
| {color:red}-1{color} | {color:red} checkstyle {color} | {color:red}  0m 50s{color} | {color:red} ql: The patch generated 28 new + 696 unchanged - 8 fixed = 724 total (was 704) {color} |
| {color:red}-1{color} | {color:red} checkstyle {color} | {color:red}  0m 22s{color} | {color:red} standalone-metastore: The patch generated 5 new + 569 unchanged - 0 fixed = 574 total (was 569) {color} |
| {color:red}-1{color} | {color:red} whitespace {color} | {color:red}  0m  0s{color} | {color:red} The patch has 2 line(s) that end in whitespace. Use git apply --whitespace=fix <<patch_file>>. Refer https://git-scm.com/docs/git-apply {color} |
| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  1m  0s{color} | {color:red} standalone-metastore generated 1 new + 54 unchanged - 0 fixed = 55 total (was 54) {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 15s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 29m 37s{color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Optional Tests |  asflicense  javac  javadoc  findbugs  checkstyle  compile  |
| uname | Linux hiveptest-server-upstream 3.16.0-4-amd64 #1 SMP Debian 3.16.36-1+deb8u1 (2016-09-03) x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /data/hiveptest/working/yetus_PreCommit-HIVE-Build-10489/dev-support/hive-personality.sh |
| git revision | master / f30efbe |
| Default Java | 1.8.0_111 |
| mvninstall | http://104.198.109.242/logs//PreCommit-HIVE-Build-10489/yetus/patch-mvninstall-ql.txt |
| checkstyle | http://104.198.109.242/logs//PreCommit-HIVE-Build-10489/yetus/diff-checkstyle-itests_hive-unit.txt |
| checkstyle | http://104.198.109.242/logs//PreCommit-HIVE-Build-10489/yetus/diff-checkstyle-ql.txt |
| checkstyle | http://104.198.109.242/logs//PreCommit-HIVE-Build-10489/yetus/diff-checkstyle-standalone-metastore.txt |
| whitespace | http://104.198.109.242/logs//PreCommit-HIVE-Build-10489/yetus/whitespace-eol.txt |
| javadoc | http://104.198.109.242/logs//PreCommit-HIVE-Build-10489/yetus/diff-javadoc-javadoc-standalone-metastore.txt |
| modules | C: storage-api common itests/hive-unit ql standalone-metastore U: . |
| Console output | http://104.198.109.242/logs//PreCommit-HIVE-Build-10489/yetus.txt |
| Powered by | Apache Yetus    http://yetus.apache.org |


This message was automatically generated.

, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12920557/HIVE-19124.09.patch

{color:green}SUCCESS:{color} +1 due to 2 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 44 failed/errored test(s), 14300 tests executed
*Failed tests:*
{noformat}
TestMinimrCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=93)
	[infer_bucket_sort_num_buckets.q,infer_bucket_sort_reducers_power_two.q,parallel_orderby.q,bucket_num_reducers_acid.q,infer_bucket_sort_map_operators.q,infer_bucket_sort_merge.q,root_dir_external_table.q,infer_bucket_sort_dyn_part.q,udf_using.q,bucket_num_reducers_acid2.q]
TestNonCatCallsWithCatalog - did not produce a TEST-*.xml file (likely timed out) (batchId=217)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_nullscan] (batchId=68)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_table_stats] (batchId=54)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[autoColumnStats_4] (batchId=13)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[list_bucket_dml_6] (batchId=33)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[parquet_vectorization_0] (batchId=17)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[row__id] (batchId=80)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[acid_bucket_pruning] (batchId=150)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[acid_vectorization_original] (batchId=173)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[default_constraint] (batchId=163)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[dynpart_sort_optimization_acid] (batchId=165)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[enforce_constraint_notnull] (batchId=158)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[insert_values_orig_table_use_metadata] (batchId=169)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[llap_smb] (batchId=176)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[materialized_view_create_rewrite_4] (batchId=157)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[materialized_view_create_rewrite_5] (batchId=154)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_stats] (batchId=168)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_text_vec_part] (batchId=168)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[sysdb] (batchId=163)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[acid_vectorization_original_tez] (batchId=106)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_5] (batchId=105)
org.apache.hadoop.hive.cli.TestNegativeMinimrCliDriver.testCliDriver[cluster_tasklog_retrieval] (batchId=98)
org.apache.hadoop.hive.cli.TestNegativeMinimrCliDriver.testCliDriver[mapreduce_stack_trace] (batchId=98)
org.apache.hadoop.hive.cli.TestNegativeMinimrCliDriver.testCliDriver[mapreduce_stack_trace_turnoff] (batchId=98)
org.apache.hadoop.hive.cli.TestNegativeMinimrCliDriver.testCliDriver[minimr_broken_pipe] (batchId=98)
org.apache.hadoop.hive.ql.TestAcidOnTez.testAcidInsertWithRemoveUnion (batchId=228)
org.apache.hadoop.hive.ql.TestAcidOnTez.testCtasTezUnion (batchId=228)
org.apache.hadoop.hive.ql.TestAcidOnTez.testNonStandardConversion01 (batchId=228)
org.apache.hadoop.hive.ql.TestMTQueries.testMTQueries1 (batchId=232)
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testWriteSetTracking3 (batchId=300)
org.apache.hadoop.hive.ql.parse.TestCopyUtils.testPrivilegedDistCpWithSameUserAsCurrentDoesNotTryToImpersonate (batchId=231)
org.apache.hadoop.hive.ql.parse.TestReplicationOnHDFSEncryptedZones.targetAndSourceHaveDifferentEncryptionZoneKeys (batchId=231)
org.apache.hive.jdbc.TestSSL.testSSLFetchHttp (batchId=239)
org.apache.hive.minikdc.TestJdbcWithDBTokenStore.testTokenAuth (batchId=254)
org.apache.hive.minikdc.TestJdbcWithDBTokenStoreNoDoAs.testCancelRenewTokenFlow (batchId=254)
org.apache.hive.minikdc.TestJdbcWithDBTokenStoreNoDoAs.testConnection (batchId=254)
org.apache.hive.minikdc.TestJdbcWithDBTokenStoreNoDoAs.testIsValid (batchId=254)
org.apache.hive.minikdc.TestJdbcWithDBTokenStoreNoDoAs.testIsValidNeg (batchId=254)
org.apache.hive.minikdc.TestJdbcWithDBTokenStoreNoDoAs.testNegativeProxyAuth (batchId=254)
org.apache.hive.minikdc.TestJdbcWithDBTokenStoreNoDoAs.testNegativeTokenAuth (batchId=254)
org.apache.hive.minikdc.TestJdbcWithDBTokenStoreNoDoAs.testProxyAuth (batchId=254)
org.apache.hive.minikdc.TestJdbcWithDBTokenStoreNoDoAs.testRenewDelegationToken (batchId=254)
org.apache.hive.minikdc.TestJdbcWithDBTokenStoreNoDoAs.testTokenAuth (batchId=254)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/10489/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/10489/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-10489/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.YetusPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 44 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12920557 - PreCommit-HIVE-Build, [~gopalv] now that the write ID stuff has been addressed can you review the last iters of the diff?, +1, Committed to master. Thanks for the reviews!, This jira is resolved and released with Hive 3.0 If you find an issue with it, please create a new jira.]