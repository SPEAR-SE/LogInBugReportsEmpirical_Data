[Also needing update is the requirements section. We should include Java 1.7.

, Also add Microsoft SQL Server in databases supported (for 0.14) release.
, Nano-nit:  an extra space before "your own upgrade script."

{noformat}
+- We have provided upgrade scripts for MySQL, PostgreSQL, Oracle,
+  Microsoft SQL Server, and Derby databases. If you are using a
+  different database for your MetaStore you will need to provide
+   your own upgrade script.
{noformat}, Nano-nit #2:  need another space before "frameworks."

{noformat}
+* Query execution via Apache Hadoop MapReduce and using Apache Tez
+ frameworks.
{noformat}

Also a question:  Is "QL" the proper name for the language or "HiveQL"?  The README says HiveQL twice in the Getting Started section.  The wiki is inconsistent with QL, HiveQL, and Hive QL., [~leftylev] Updated patch addressing the comments. Also changed the wording regarding query execution.
, 

{color:red}Overall{color}: -1 at least one tests failed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12641158/HIVE-6932.1.patch

{color:red}ERROR:{color} -1 due to 43 failed/errored test(s), 5416 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join32
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_filter_numeric
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby2_map_skew
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby_sort_1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby_sort_skew_1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_infer_bucket_sort_list_bucket
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_list_bucket_dml_6
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_list_bucket_dml_7
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_list_bucket_dml_8
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_mapjoin_test_outer
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_nullgroup3
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_orc_createas1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_ppd_join4
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_select_dummy_source
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_stats_list_bucket
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_stats_partscan_1_23
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_symlink_text_input_format
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_truncate_column_list_bucket
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_current_database
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_union_remove_1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_union_remove_10
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_union_remove_12
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_union_remove_13
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_union_remove_14
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_union_remove_17
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_union_remove_19
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_union_remove_2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_union_remove_20
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_union_remove_21
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_union_remove_22
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_union_remove_23
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_union_remove_24
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_union_remove_4
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_union_remove_5
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_union_remove_7
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_union_remove_8
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_union_remove_9
org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_auto_sortmerge_join_16
org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_bucketizedhiveinputformat
org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_root_dir_external_table
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_dynamic_partitions_with_whitelist
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_stats_partialscan_autogether
org.apache.hadoop.hive.ql.exec.TestExecDriver.testMapRedPlan3
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-Build/5/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-Build/5/console

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 43 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12641158, Good, I'd wondered about that phrase but moved on to minutiae., bq. Also a question: Is "QL" the proper name for the language or "HiveQL"? The README says HiveQL twice in the Getting Started section. The wiki is inconsistent with QL, HiveQL, and Hive QL.
I am not sure. I actually prefer "SQL" or "Hive SQL" , but not everyone was happy with that. Maybe we should have a discussion on mailing list to see if we have an agreement now.
, +1 LGTM, bq. I actually prefer "SQL" or "Hive SQL"

A general discussion would be good, but let's not hold up this patch for it.

bq. Also, it talks about average latency being in minutes, which is very misleading.

Did you mean to revise the latency part too?, bq. Did you mean to revise the latency part too?
Yes, I did mean to update that, but forgot about it. Let me work on that.
Thanks for pointing that out!
, HIVE-6932.3.patch - Update the section about latency, and also updated the description of the language.
, * Space between  userswith
*  "MapReduce framework will experience long scheduling latencies" better to say  "MapReduce framework *may* experience long scheduling latencies"
* There is also a bit about row level insert / update. You may want to re-word that in light of recent work released in 0.13, HIVE-6932.4.patch - Addressing first two comments from Ashutosh.
Not sure how I should reword the statement about 'row level insert/update' as we still don't allow that through SQL. 
[~owen.omalley] [~alangates] Do you have any opinion on how this paragraph in README should be worded ? Any change to be made at this point in time ?

{code}
Hive is not designed for online transaction processing and does not
support real-time queries or row level insert/updates. It is best used
for batch jobs over large sets of immutable data (like web logs). What
Hive values most are scalability (scale out with more machines added
dynamically to the Hadoop cluster), extensibility (with MapReduce
framework and UDF/UDAF/UDTF), fault-tolerance, and loose-coupling with
its input formats.
{code}, I'd leave the row level insert/update for now, but file a new JIRA and attach it to HIVE-5317 to change this when insert/update/delete are added.  

I'd change the part about not supporting real-time queries to not supporting sub-second queries, as with 0.13 we are now in the few seconds range for many queries, and it's not clear what real-time means to people., HIVE-6932.5.patch - Addressing Alan's comment.
Saying hive does not support sub-second queries is also not accurate. Queries that don't spawn tasks on the cluster can finish in less than a second. For example queries that can be answered using metadata finish in less than second. I think, even 'select * from tab limit 10;' queries also finish in less than a second.
So I have removed the potentially misleading 'real-time' query part from the paragraph. When we say OLTP workloads are not supported, this is sort of implied.
, +1, Patch committed to trunk.
Thanks for the reviews!
, Uh oh, I should have reviewed patch 5 before you committed.  But the typo won't confuse anyone:  "Users are free to swtich back....", HIVE-7003 to fix the typo.
, This has been fixed in 0.14 release. Please open new jira if you see any issues.
]