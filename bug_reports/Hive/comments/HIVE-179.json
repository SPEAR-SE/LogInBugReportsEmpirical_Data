[I note this will break ~27 tests that use {{substr(src.value,4)}} or similar.  Is this going to be a problem for existing user code?, I think we should change it and make it ANSI compliant. It is still early days and I think we can ask the users to change their scripts. Not being SQL compliant will present more problems in the future. , Totally agree. Let's make it ANSI compliant!
, Another thing to test is what does MYSQL returns when the string, or index, or len is NULL., MySQL and Oracle both return NULL if any of the parameters are NULL., The test cases groupby2_map.q and groupby3_map.q break when substr(src.value,4) is changed to substr(src.value,5), even though the output from the UDF is the same (HIVE-215)., This patch is tentative.  All tests pass except these two due to HIVE-215:

ant -Dtestcase=TestCliDriver -Dqfile=groupby2_map.q test
ant -Dtestcase=TestCliDriver -Dqfile=groupby3_map.q test

, The patch looks correct and rather harmless. I tried the change that you suggested to groupby2_map.q on a clean branch and it worked find. If you are getting a cast exception it is likely related to the change of signatures but even that seems harmless. Trying out this patch in my environment now., This seems to be exposing a latent bug in plan generation. Still investigating this, but here is an explanation. If you do 

diff -y ./ql/src/test/results/clientpositive/groupby2_map.q.out ./ql/src/test/results/clientpositive/.svn/text-base/groupby2_map.q.out.svn-base | less 

you will see the plan changes that this patch makes. An excerpt is as follows: 
-------------------------------- 
STAGE PLANS: STAGE PLANS: 
  Stage: Stage-1 Stage: Stage-1 
    Map Reduce Map Reduce 
      Alias -> Map Operator Tree: Alias -> Map Operator Tree: 
        src src 
            Group By Operator Group By Operator 
              aggregations: aggregations: 
                    expr: sum(UDFToDouble(substr(value, 5))) | expr: count(DISTINCT substr(value, 4)) 
                    expr: count(DISTINCT substr(value, 5)) | expr: sum(UDFToDouble(substr(value, 4))) 
              keys: keys: 
                    expr: substr(key, 1, 1) | expr: substr(key, 0, 1) 
                    type: string type: string 
                    expr: substr(value, 5) | expr: substr(value, 4) 
                    type: string type: string 
              mode: hash mode: hash 
              Reduce Output Operator Reduce Output Operator 
                key expressions: key expressions: 
                      expr: 0 expr: 0 
                      type: string type: string 
                      expr: 1 expr: 1 
                      type: string type: string 
                sort order: ++ sort order: ++ 
                Map-reduce partition columns: Map-reduce partition columns: 
                      expr: 0 expr: 0 
                      type: string type: string 
                      expr: 1 expr: 1 
                      type: string type: string 
                tag: -1 tag: -1 
                value expressions: value expressions: 
                      expr: 2 expr: 2 
                      type: double < 
                      expr: 3 < 
                      type: bigint type: bigint 
                                                              > expr: 3 
                                                              > type: double 
      Reduce Operator Tree: Reduce Operator Tree: 
        Group By Operator Group By Operator 
          aggregations: aggregations: 
                expr: count(DISTINCT KEY.1) expr: count(DISTINCT KEY.1) 
                expr: sum(VALUE.0) | expr: sum(VALUE.1) 
          keys: keys: 
                expr: KEY.0 expr: KEY.0 
---------------------------- 
So the point to note here is that the count and the sum expressions are the top most group by operator so 
in the last group by operator in the excerpt I think expr: count(DISTINCT KEY.1) should have been expr: count(DISTINCT KEY0) 

Still debugging this one.., On second thoughts, the plan seems to be ok. Since the keys have not swapped (only the values have swapped), count(DISTINCT KEY.1) seems to be correct.
, The first map/reduce job produces longs where as the second map/reduce job expects a double.
, The actual error is happening between the map and reduce boundary of the second map reduce job. The ddl for the dynamic serde that is used to serialize data at this boundary is double, long where as the output generated is long, double as seen in the plan.
, Filed another JIRA for the issue as it is unrelated to this one. Will post a patch to 222 during the weekend., Running tests on this. Will commit once it is done. Sorry, this one fell off my radar..., committed. Thanks David!! Sorry for not doing this before...]