[Uploading patch, Does this config change affect compaction jobs triggered by ACID?, 

{color:red}Overall{color}: -1 at least one tests failed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12677512/HIVE-8629.patch

{color:red}ERROR:{color} -1 due to 2 failed/errored test(s), 6579 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_optimize_nullscan
org.apache.hive.minikdc.TestJdbcWithMiniKdc.testNegativeTokenAuth
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1498/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1498/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-1498/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 2 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12677512 - PreCommit-HIVE-TRUNK-Build, bq.  Does this config change affect compaction jobs triggered by ACID?
No.  Compactions are done by the metastore service, not the clients.  And they are always done using MR, regardless of what execution engine is configured., Why is it necessary to set METASTORE_EXECUTE_SET_UGI?  As far as I can tell this is only used by the metastore, and so has no affect on the client.

I think you should add a LOG.info() in overrideConfSettings so that users know you are overriding some values in their configuration., [~alangates]  the without setugi, the directories created by the metastore during add partition etc are done as hive user instead of the client user of the metastore process, consequently leading to incorrect permissions and later failure to stream to those directories.

WRT Log.info(): Since this done each time a new connection is created, which occurs multiple times over the duration of a long running streaming process, to reduce noise in the log output .. i am wondering if we should document this instead of log.info()  ? Either I am fine. Let me know what you think., Doing LOG.debug and documenting it should be fine.  Other than that, +1., Revised patch incorporating Alan's comments, +1 for hive .14, Where should this be documented?

Also, can the release note be changed to something more helpful?, I added the doc to  https://cwiki.apache.org/confluence/display/Hive/Streaming+Data+Ingest, Excellent, removing the TODOC14 label.

One question about the doc:  Is something missing after "before" in this sentence? --

bq.  Regardless of what values are set in hive-site.xml or custom HiveConf, the API will internally override some settings in it before to ensure correct streaming behavior., "before" should not be there.. just deleted it. thanks for catching it, This has been fixed in 0.14 release. Please open new jira if you see any issues.
]