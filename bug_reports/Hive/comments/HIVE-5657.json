[[~navis] [~ashutoshc] you guys might be interested, Yes, top-n is not working with distincts. Test included in limit_pushdown.q was not good enough to show the flaw. I'll check this later., Attaching patch, which is not yet completed. I will return to this tomorrow or later., is it ready for review? I skimmed a bit, it makes sense. Would be nice to have RB/FB for final patch. Thanks!, navis requested code review of "HIVE-5657 [jira] TopN produces incorrect results with count(distinct)".

Reviewers: JIRA

HIVE-5657 TopN produces incorrect results with count(distinct)

Attached patch illustrates the problem.
limit_pushdown test has various other cases of aggregations and distincts, incl. count-distinct, that work correctly (that said, src dataset is bad for testing these things because every count, for example, produces one record only), so something must be special about this.
I am not very familiar with distinct- code and these nuances; if someone knows a quick fix feel free to take this, otherwise I will probably start looking next week.

TEST PLAN
  EMPTY

REVISION DETAIL
  https://reviews.facebook.net/D13797

AFFECTED FILES
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java
  ql/src/java/org/apache/hadoop/hive/ql/exec/TopNHash.java
  ql/src/java/org/apache/hadoop/hive/ql/exec/vector/VectorReduceSinkOperator.java
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/LimitPushdownOptimizer.java
  ql/src/java/org/apache/hadoop/hive/ql/plan/ReduceSinkDesc.java
  ql/src/test/queries/clientpositive/limit_pushdown.q
  ql/src/test/queries/clientpositive/limit_pushdown_negative.q
  ql/src/test/results/clientpositive/limit_pushdown.q.out
  ql/src/test/results/clientpositive/limit_pushdown_negative.q.out
  serde/src/java/org/apache/hadoop/hive/serde2/KeySerializer.java
  serde/src/java/org/apache/hadoop/hive/serde2/binarysortable/BinarySortableSerDe.java
  serde/src/java/org/apache/hadoop/hive/serde2/binarysortable/OutputByteBuffer.java

WHY DID I GET THIS EMAIL?
  https://reviews.facebook.net/herald/transcript/41811/

To: JIRA, navis
, Distinct bug fix + Multi-distinct support. But huge conflict with HIVE-5503 is expected. , sershe has commented on the revision "HIVE-5657 [jira] TopN produces incorrect results with count(distinct)".

INLINE COMMENTS
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/LimitPushdownOptimizer.java:125 so this now supports any number of distincts?
  ql/src/java/org/apache/hadoop/hive/ql/exec/TopNHash.java:255 right now this only returns forward... is this by design?
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java:243 should all of this also be done for vectorized path?
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java:268 I fixed it in my patch for vectorized... why is hash needed here?
  If row is excluded we don't need hash, it's only needed when we store the value or collect
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java:297 if index >= 0 this should store value
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java:255 Previously there was just key, which was some columns and optionally one distinct.
  Do I read correctly that distribution key is now the same, just without distinct?

REVISION DETAIL
  https://reviews.facebook.net/D13797

To: JIRA, navis
Cc: sershe
, Left some comments on fb. Can you summarize how the change works? it seems like with any distincts, it will just forward all rows (like if it was disabled), but there is lots of code to do it., What do you want to do about conflict? It seems like your patch contains many of the same changes as my patch also :), navis has commented on the revision "HIVE-5657 [jira] TopN produces incorrect results with count(distinct)".

INLINE COMMENTS
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java:268 Right. it should be -1. I did mistake doing some refactoring.
  ql/src/java/org/apache/hadoop/hive/ql/exec/TopNHash.java:255 For distinct, it does not store values. Check the key and decide to forward all or exclude all. I'm not sure that the previous version was better. In this time, I've focused simplifying the flow of RS-op.
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java:255 Yes right. Previously, the key was like this
  [distributeKey:distinctKey1]
  [distributeKey:distinctKey2]
  and each row is serialized in whole by OI
  structOI[structOI(distributeKey):UnionOI(distinctKey)]

  Now the key is prepared like this and
  [distributeKey]
  [distinctKey1,distinctKey2]

  serialized for each part directly by inner OI : structOI(distributeKey) and UnionOI(distinctKey)

  I'm not feel good introducing new interface KeySerializer. But serializing distributeKey multiple time seemed worse than that.
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/LimitPushdownOptimizer.java:125 yes.
  ql/src/java/org/apache/hadoop/hive/ql/plan/ReduceSinkDesc.java:211 Changed the name because it was confusing that RS is for MapAggr GBY, which is not.
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java:243 I didn't know there was VectorReduceSinkOperator when I've started this, which made me include more refactorings than just amount of fixing the problem. I think current version of patch is way simpler than that of original. But if it makes merging of vectorization hard, I might create minimal patch just for fix.

REVISION DETAIL
  https://reviews.facebook.net/D13797

To: JIRA, navis
Cc: sershe
, (responding to FB comment) yeah, it would be nice to have simpler fix to make merge easier, esp. since many of these changes (e.g. setting writable without duplicated code from BinaryComparable, and some other stuff) is already coming.

What I don't understand still is what it does for distinct. Where can it decide to exclude? It seems the same forward-all behavior can be achieved by removing support for any distinct from optimizer., indexOf() stores keys into hash(yes, confusing name). Exclude or not can be decided base on it., but the hash for distinct in the review always returns FORWARD in current patch on FB:
{code}
class HashForDistinct extends HashForGroup {

 HashForDistinct(int topN, long threshold, BinaryCollector collector) {
 super(topN, threshold, collector);
 }

 @Override
 protected int index(int index) {
 return FORWARD;
 }
}
{code}, Ah, sorry, I read the name of the override function wrong, it's similar. Let me reread, Oh, I see how it works now. Logically, is it the same behavior as groupby, but groupby forwards all MR KVs except one, which is later flushed if it "survives" in the heap, or maybe evicted. Whereas this guy would have to store multiple key-values for each key in the case of multi distinct, so it just forwards everything in case it's in the heap, not storing that one row. 
That part makes sense. Thanks! Function name ("index") could be improved.
Are you going to post updated patch?, navis updated the revision "HIVE-5657 [jira] TopN produces incorrect results with count(distinct)".

  1. Minimized diff
  2. Support multi-distinct cases

Reviewers: JIRA

REVISION DETAIL
  https://reviews.facebook.net/D13797

CHANGE SINCE LAST DIFF
  https://reviews.facebook.net/D13797?vs=42645&id=42747#toc

AFFECTED FILES
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java
  ql/src/java/org/apache/hadoop/hive/ql/exec/TopNHash.java
  ql/src/java/org/apache/hadoop/hive/ql/io/HiveKey.java
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/LimitPushdownOptimizer.java
  ql/src/test/queries/clientpositive/limit_pushdown.q
  ql/src/test/queries/clientpositive/limit_pushdown_negative.q
  ql/src/test/results/clientpositive/limit_pushdown.q.out
  ql/src/test/results/clientpositive/limit_pushdown_negative.q.out

To: JIRA, navis
Cc: sershe
, sershe has commented on the revision "HIVE-5657 [jira] TopN produces incorrect results with count(distinct)".

INLINE COMMENTS
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java:387 this changes the meaning to now refer to the field "this.value". Is it intended? Previously it was not used. Perhaps the first "if" should be removed if not used on purpose

REVISION DETAIL
  https://reviews.facebook.net/D13797

To: JIRA, navis
Cc: sershe
, One small comment about the "value" field usage. I'm +1 if you can remove it, or add comment so that it's clear when it's reused and when it's reset)

Note that I'm not a committed though, so someone else might need to +1 in addition, *committer, HIVE-5503 is committed and I cannot rebase on that. Was it necessary to "refactor" the codes which is not yet confirmed solid and has on-going issues on it? I appreciate progresses made by members of the company. But not like this., I refactored the code there because it was to be called from 2 places (vectorized and not) and some code that is TopN specific was inside ReducerSink, also similarly vectorized and non-vectorized path inside TopNHash would have a lot of code in common like serialization.

Let me try to rebase this patch later today..., Sorry for grief [~navis] However, [~sershe] is offering to rebase this patch, since he is familiar with this piece of code. Hopefully, that is acceptable to you., I think I have the non-vector part, need to add vector part, let me finish this tomorrow, Rebased and added vectorized handling.
I got a little bit carried away and added bunch of comments and renames i, j, index variables to be more specific., 

{color:green}Overall{color}: +1 all checks pass

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12612317/HIVE-5657.02.patch

{color:green}SUCCESS:{color} +1 4551 tests passed

Test results: http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/148/testReport
Console output: http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/148/console

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12612317, [~sershe] Can you create a RB for this ?, https://reviews.apache.org/r/15282/ is the 2nd rb, +1 
Can you create a follow-up jira for removing unnecessary if(firstRow) from processOp(), seems like work in that if block can be done in initializeOp() ?
Also, you need to reupload your patch since seems like Hive QA hasn't picked it up yet., seems like too small an item to create JIRA for... also are you sure it can indeed be moved? see my TODO comment. As a matter of priorities I'd like to not spend time making sure ;), btw please don't commit, let me address my own comments on rb, trivial changes compared to 02, 

{color:green}Overall{color}: +1 all checks pass

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12612869/HIVE-5657.03.patch

{color:green}SUCCESS:{color} +1 4598 tests passed

Test results: http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/218/testReport
Console output: http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/218/console

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12612869, Committed to trunk. Thanks, Sergey!]