[Hi, [~subashprabanantham]
Which Hive version did you use? Could you post the reproduce queries as well? 

I tried it on a Hive package built from branch-2.3, and it worked for me.

My Testing
==============
*hive> describe test;*
OK
col1                	string
col2                	string
Time taken: 0.057 seconds, Fetched: 2 row(s)
*hive> select * from test;*
OK
a1	a2
b1	b2
c1	c2
	D
Time taken: 0.22 seconds, Fetched: 4 row(s)

*hive> select count(1) as cnt from test where col1="" and col2="D";*
Query ID = root_20170630235239_b58b7dbc-14ef-4126-b56b-fdcf187acc09
Total jobs = 1
Launching Job 1 out of 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Spark Job = f25577ce-2ed6-4c5c-a64a-6ff7419ab778
--------------------------------------------------------------------------------------
          STAGES   ATTEMPT        STATUS  TOTAL  COMPLETED  RUNNING  PENDING  FAILED
--------------------------------------------------------------------------------------
Stage-5 ........         0      FINISHED      1          1        0        0       0
Stage-6 ........         0      FINISHED      1          1        0        0       0
--------------------------------------------------------------------------------------
STAGES: 02/02    [==========================>>] 100%  ELAPSED TIME: 1.01 s
--------------------------------------------------------------------------------------
Status: Finished successfully in 1.01 seconds
OK
1
Time taken: 1.436 seconds, Fetched: 1 row(s), Hi Li,
The version we use is 1.1.0

And we use the below query,

select count(1) as cnt from table where col1=" "

The value is not blank "", its space " ".

When we perform this via JDBC we get 0 as the value though we have data.

Thanks,
Subash.]