[+1 pending tests, 

{color:red}Overall{color}: -1 at least one tests failed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12625283/HIVE-6310.patch

{color:red}ERROR:{color} -1 due to 4 failed/errored test(s), 4958 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_import_exported_table
org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_infer_bucket_sort_reducers_power_two
org.apache.hadoop.hive.cli.TestNegativeMinimrCliDriver.testNegativeCliDriver_file_with_header_footer_negative
org.apache.hadoop.hive.cli.TestNegativeMinimrCliDriver.testNegativeCliDriver_mapreduce_stack_trace_hadoop20
{noformat}

Test results: http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/1035/testReport
Console output: http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/1035/console

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 4 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12625283, Test failures above seems strange. All of them passed when being manually started. file_with_header_footer_negative.q seems suffering the same problem as the previous patch was to address. Thus, the new patch, #1, includes fix for that too., 

{color:red}Overall{color}: -1 at least one tests failed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12625381/HIVE-6310.1.patch

{color:red}ERROR:{color} -1 due to 3 failed/errored test(s), 4961 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_import_exported_table
org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_infer_bucket_sort_reducers_power_two
org.apache.hadoop.hive.cli.TestNegativeMinimrCliDriver.testNegativeCliDriver_mapreduce_stack_trace_hadoop20
{noformat}

Test results: http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/1045/testReport
Console output: http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/1045/console

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 3 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12625381, Patch #2 updated with fix for import_exported_table.q. Still having no clue why the other two tests are failing. Will have to exclude them if they keep failing., For test file_with_header_footer_negative.q, it looks like the issue is that the .q file has bad paths in it. Try with these changes and you don't need to update the .q.out file:

{noformat}
-dfs -copyFromLocal ../data/files/header_footer_table_1 hdfs:///tmp/test/header_footer_table_1;
+dfs -copyFromLocal ../../data/files/header_footer_table_1 hdfs:///tmp/test/header_footer_table_1;
 
-dfs -copyFromLocal ../data/files/header_footer_table_2 hdfs:///tmp/test/header_footer_table_2;
+dfs -copyFromLocal ../../data/files/header_footer_table_2 hdfs:///tmp/test/header_footer_table_2;
{noformat}, 

{color:red}Overall{color}: -1 at least one tests failed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12625469/HIVE-6310.2.patch

{color:red}ERROR:{color} -1 due to 2 failed/errored test(s), 4961 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_auto_sortmerge_join_16
org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_infer_bucket_sort_reducers_power_two
{noformat}

Test results: http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/1059/testReport
Console output: http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/1059/console

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 2 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12625469, I checked on the slave nodes and there is plenty of space.

{noformat}
[hiveptest@ip-10-74-94-52 ~]$ df -h
Filesystem            Size  Used Avail Use% Mounted on
/dev/xvde1             40G  4.7G   33G  13% /
{noformat}

Below is the error messages for the two failed tests. Both times there is a runtime exception followed by some hadoop exceptions.

http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-Build-1059/failed/TestMinimrCliDriver-infer_bucket_sort_reducers_power_two.q/source/itests/qtest/target/tmp/history/done/version-1/localhost_1390912810566_/2014/01/28/000000/job_20140128044010447_0005_1390912971033_hiveptest_--+Test+join+on+three+tables+on+d...c.value%2529%2528Stage

{noformat}
Task TASKID="task_20140128044010447_0005_r_000000" TASK_TYPE="REDUCE" START_TIME="1390912978019" SPLITS="" .
Task TASKID="task_20140128044010447_0005_r_000001" TASK_TYPE="REDUCE" START_TIME="1390912978081" SPLITS="" .
Task TASKID="task_20140128044010447_0005_r_000002" TASK_TYPE="REDUCE" START_TIME="1390912978117" SPLITS="" .
ReduceAttempt TASK_TYPE="REDUCE" TASKID="task_20140128044010447_0005_r_000000" TASK_ATTEMPT_ID="attempt_20140128044010447_0005_r_000000_0" START_TIME="1390912978026" TRACKER_NAME="tracker_host0\.foo\.com:localhost/127\.0\.0\.1:60535" HTTP_PORT="53633" LOCALITY="OFF_SWITCH" AVATAAR="VIRGIN" .
ReduceAttempt TASK_TYPE="REDUCE" TASKID="task_20140128044010447_0005_r_000000" TASK_ATTEMPT_ID="attempt_20140128044010447_0005_r_000000_0" TASK_STATUS="FAILED" FINISH_TIME="1390912983112" HOSTNAME="host0\.foo\.com" ERROR="java\.lang\.IllegalArgumentException: Null user
	at org\.apache\.hadoop\.security\.UserGroupInformation\.createRemoteUser(UserGroupInformation\.java:887)
	at org\.apache\.hadoop\.mapred\.Child\.main(Child\.java:241)
" .
MapAttempt TASK_TYPE="MAP" TASKID="task_20140128044010447_0005_m_000000" TASK_ATTEMPT_ID="attempt_20140128044010447_0005_m_000000_0" START_TIME="1390912974953" TRACKER_NAME="tracker_host0\.foo\.com:localhost/127\.0\.0\.1:60535" HTTP_PORT="53633" LOCALITY="RACK_LOCAL" AVATAAR="VIRGIN" .
MapAttempt TASK_TYPE="MAP" TASKID="task_20140128044010447_0005_m_000000" TASK_ATTEMPT_ID="attempt_20140128044010447_0005_m_000000_0" TASK_STATUS="FAILED" FINISH_TIME="1390912977965" HOSTNAME="host0\.foo\.com" ERROR="Map output lost, rescheduling: getMapOutput(attempt_20140128044010447_0005_m_000000_0,2) failed :
org\.apache\.hadoop\.util\.DiskChecker$DiskErrorException: Could not find taskTracker/hiveptest/jobcache/job_20140128044010447_0005/attempt_20140128044010447_0005_m_000000_0/output/file\.out\.index in any of the configured local directories
	at org\.apache\.hadoop\.fs\.LocalDirAllocator$AllocatorPerContext\.getLocalPathToRead(LocalDirAllocator\.java:429)
	at org\.apache\.hadoop\.fs\.LocalDirAllocator\.getLocalPathToRead(LocalDirAllocator\.java:160)
	at org\.apache\.hadoop\.mapred\.TaskTracker$MapOutputServlet\.doGet(TaskTracker\.java:4053)
	at javax\.servlet\.http\.HttpServlet\.service(HttpServlet\.java:707)
	at javax\.servlet\.http\.HttpServlet\.service(HttpServlet\.java:820)
	at org\.mortbay\.jetty\.servlet\.ServletHolder\.handle(ServletHolder\.java:511)
	at org\.mortbay\.jetty\.servlet\.ServletHandler$CachedChain\.doFilter(ServletHandler\.java:1221)
	at org\.apache\.hadoop\.http\.HttpServer$QuotingInputFilter\.doFilter(HttpServer\.java:914)
	at org\.mortbay\.jetty\.servlet\.ServletHandler$CachedChain\.doFilter(ServletHandler\.java:1212)
	at org\.mortbay\.jetty\.servlet\.ServletHandler\.handle(ServletHandler\.java:399)
	at org\.mortbay\.jetty\.security\.SecurityHandler\.handle(SecurityHandler\.java:216)
	at org\.mortbay\.jetty\.servlet\.SessionHandler\.handle(SessionHandler\.java:182)
	at org\.mortbay\.jetty\.handler\.ContextHandler\.handle(ContextHandler\.java:766)
	at org\.mortbay\.jetty\.webapp\.WebAppContext\.handle(WebAppContext\.java:450)
	at org\.mortbay\.jetty\.handler\.ContextHandlerCollection\.handle(ContextHandlerCollection\.java:230)
	at org\.mortbay\.jetty\.handler\.HandlerWrapper\.handle(HandlerWrapper\.java:152)
	at org\.mortbay\.jetty\.Server\.handle(Server\.java:322)
	at org\.mortbay\.jetty\.HttpConnection\.handleRequest(HttpConnection\.java:542)
	at org\.mortbay\.jetty\.HttpConnection$RequestHandler\.headerComplete(HttpConnection\.java:928)
	at org\.mortbay\.jetty\.HttpParser\.parseNext(HttpParser\.java:549)
	at org\.mortbay\.jetty\.HttpParser\.parseAvailable(HttpParser\.java:212)
	at org\.mortbay\.jetty\.HttpConnection\.handle(HttpConnection\.java:404)
	at org\.mortbay\.io\.nio\.SelectChannelEndPoint\.run(SelectChannelEndPoint\.java:410)
	at org\.mortbay\.thread\.QueuedThreadPool$PoolThread\.run(QueuedThreadPool\.java:582)
" .
{noformat}

http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-Build-1059/failed/TestMinimrCliDriver-external_table_with_space_in_location_path.q-infer_bucket_sort_merge.q-auto_sortmerge_join_16.q-and-1-more/source/itests/qtest/target/tmp/history/done/version-1/localhost_1390912806507_/2014/01/28/000000/job_20140128044006356_0003_1390912970454_hiveptest_select+%250Aa.key+%252C+%250Aa.value+%252C+%250Ab.value...b.key%2529%2528Stage

{noformat}
MapAttempt TASK_TYPE="MAP" TASKID="task_20140128044006356_0003_m_000003" TASK_ATTEMPT_ID="attempt_20140128044006356_0003_m_000003_0" START_TIME="1390912978252" TRACKER_NAME="tracker_host2\.foo\.com:localhost/127\.0\.0\.1:58706" HTTP_PORT="37104" LOCALITY="RACK_LOCAL" AVATAAR="VIRGIN" .
MapAttempt TASK_TYPE="MAP" TASKID="task_20140128044006356_0003_m_000003" TASK_ATTEMPT_ID="attempt_20140128044006356_0003_m_000003_0" TASK_STATUS="FAILED" FINISH_TIME="1390912987227" HOSTNAME="host2\.foo\.com" ERROR="java\.lang\.NullPointerException
	at org\.apache\.hadoop\.hive\.ql\.io\.HiveInputFormat\.init(HiveInputFormat\.java:257)
	at org\.apache\.hadoop\.hive\.ql\.io\.HiveInputFormat\.pushProjectionsAndFilters(HiveInputFormat\.java:439)
	at org\.apache\.hadoop\.hive\.ql\.io\.HiveInputFormat\.pushProjectionsAndFilters(HiveInputFormat\.java:432)
	at org\.apache\.hadoop\.hive\.ql\.io\.BucketizedHiveInputFormat\.getRecordReader(BucketizedHiveInputFormat\.java:71)
	at org\.apache\.hadoop\.mapred\.MapTask$TrackedRecordReader\.<init>(MapTask\.java:191)
	at org\.apache\.hadoop\.mapred\.MapTask\.runOldMapper(MapTask\.java:412)
	at org\.apache\.hadoop\.mapred\.MapTask\.run(MapTask\.java:366)
	at org\.apache\.hadoop\.mapred\.Child$4\.run(Child\.java:255)
	at java\.security\.AccessController\.doPrivileged(Native Method)
	at javax\.security\.auth\.Subject\.doAs(Subject\.java:396)
	at org\.apache\.hadoop\.security\.UserGroupInformation\.doAs(UserGroupInformation\.java:1190)
	at org\.apache\.hadoop\.mapred\.Child\.main(Child\.java:249)
" .
MapAttempt TASK_TYPE="MAP" TASKID="task_20140128044006356_0003_m_000006" TASK_ATTEMPT_ID="attempt_20140128044006356_0003_m_000006_0" START_TIME="1390912978652" TRACKER_NAME="tracker_host1\.foo\.com:localhost/127\.0\.0\.1:59914" HTTP_PORT="45568" LOCALITY="RACK_LOCAL" AVATAAR="VIRGIN" .
MapAttempt TASK_TYPE="MAP" TASKID="task_20140128044006356_0003_m_000006" TASK_ATTEMPT_ID="attempt_20140128044006356_0003_m_000006_0" TASK_STATUS="FAILED" FINISH_TIME="1390912987977" HOSTNAME="host1\.foo\.com" ERROR="org\.apache\.hadoop\.util\.DiskChecker$DiskErrorException: Could not find any valid local directory for output/spill0\.out
	at org\.apache\.hadoop\.fs\.LocalDirAllocator$AllocatorPerContext\.getLocalPathForWrite(LocalDirAllocator\.java:381)
	at org\.apache\.hadoop\.fs\.LocalDirAllocator\.getLocalPathForWrite(LocalDirAllocator\.java:146)
	at org\.apache\.hadoop\.fs\.LocalDirAllocator\.getLocalPathForWrite(LocalDirAllocator\.java:127)
	at org\.apache\.hadoop\.mapred\.MapOutputFile\.getSpillFileForWrite(MapOutputFile\.java:121)
	at org\.apache\.hadoop\.mapred\.MapTask$MapOutputBuffer\.sortAndSpill(MapTask\.java:1397)
	at org\.apache\.hadoop\.mapred\.MapTask$MapOutputBuffer\.flush(MapTask\.java:1303)
	at org\.apache\.hadoop\.mapred\.MapTask\.runOldMapper(MapTask\.java:431)
	at org\.apache\.hadoop\.mapred\.MapTask\.run(MapTask\.java:366)
	at org\.apache\.hadoop\.mapred\.Child$4\.run(Child\.java:255)
	at java\.security\.AccessController\.doPrivileged(Native Method)
	at javax\.security\.auth\.Subject\.doAs(Subject\.java:396)
	at org\.apache\.hadoop\.security\.UserGroupInformation\.doAs(UserGroupInformation\.java:1190)
	at org\.apache\.hadoop\.mapred\.Child\.main(Child\.java:249)
{noformat}, Having made some progress after all. Two failure remains. 

infer_bucket_sort_reducers_power_two:
{code}
Begin query: infer_bucket_sort_reducers_power_two.q
Error during job, obtaining debugging information...
Job Tracking URL: http://localhost:37148/jobdetails.jsp?jobid=job_20140128044010447_0005
Examining task ID: task_20140128044010447_0005_m_000002 (and more) from job job_20140128044010447_0005
Examining task ID: task_20140128044010447_0005_m_000001 (and more) from job job_20140128044010447_0005

Task with the most failures(5): 
-----
Task ID:
  task_20140128044010447_0005_m_000000

URL:
  http://localhost:50030/taskdetails.jsp?jobid=job_20140128044010447_0005&tipid=task_20140128044010447_0005_m_000000
-----
Diagnostic Messages for this Task:
java.lang.Throwable: Child Error
	at org.apache.hadoop.mapred.TaskRunner.run(TaskRunner.java:271)
Caused by: java.io.IOException: Task process exit with nonzero status of 1.
	at org.apache.hadoop.mapred.TaskRunner.run(TaskRunner.java:258)

java.lang.Throwable: Child Error
	at org.apache.hadoop.mapred.TaskRunner.run(TaskRunner.java:271)
Caused by: java.io.IOException: Task process exit with nonzero status of 1.
	at org.apache.hadoop.mapred.TaskRunner.run(TaskRunner.java:258)


Exception: Client Execution failed with error code = 2 running 

-- Test join on three tables on different keys, should be bucketed and sorted by latter key
INSERT OVERWRITE TABLE test_table PARTITION (part = '1') 
SELECT a.key, c.value FROM src a JOIN src b ON (a.key = b.key) JOIN src c ON (b.value = c.value)
{code}

auto_sortmerge_join_16.q:

{code}
java.lang.Throwable: Child Error
	at org.apache.hadoop.mapred.TaskRunner.run(TaskRunner.java:271)
Caused by: java.io.IOException: Task process exit with nonzero status of 1.
	at org.apache.hadoop.mapred.TaskRunner.run(TaskRunner.java:258)


Exception: Client Execution failed with error code = 2 running  

select 
a.key , 
a.value , 
b.value , 
'day1' as day, 
1 as pri 
from 
( 
select 
key, 
value 
from bucket_big where day='day1'
) a 
left outer join 
( 
select 
key, 
value
from bucket_small 
where pri between 1 and 2
) b 
on 
(a.key = b.key) 

See ./ql/target/tmp/log/hive.log or ./itests/qtest/target/tmp/log/hive.log, or check ./ql/target/surefire-reports or ./itests/qtest/target/surefire-reports/ for specific test cases logs.
junit.framework.AssertionFailedError: Client Execution failed with error code = 2 running  

select 
a.key , 
a.value , 
b.value , 
'day1' as day, 
1 as pri 
from 
( 
select 
key, 
value 
from bucket_big where day='day1'
) a 
left outer join 
( 
select 
key, 
value
from bucket_small 
where pri between 1 and 2
) b 
on 
(a.key = b.key) 

See ./ql/target/tmp/log/hive.log or ./itests/qtest/target/tmp/log/hive.log, or check ./ql/target/surefire-reports or ./itests/qtest/target/surefire-reports/ for specific test cases logs.
	at junit.framework.Assert.fail(Assert.java:50)
	at org.apache.hadoop.hive.ql.QTestUtil.failed(QTestUtil.java:1716)
	at org.apache.hadoop.hive.cli.TestMinimrCliDriver.runTest(TestMinimrCliDriver.java:156)
	at org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_auto_sortmerge_join_16(TestMinimrCliDriver.java:126)
...
{code}

Since I'm able to find the task log, I have no idea what caused the task failure. [~navis] suggested memory error though. It will be great if any one knows where to pick up the task log. I plan to check in the patch and exclude the two test cases from ptest to avoid further noises.

[~brocknoland] Could you take another look of the patch?, +1 on the latest patch.

bq. suggested memory error though

I don't see any disk space or memory issues on the hosts., BTW, the two failed tests had no problem passing if started manually, which makes the problem more interesting., Thanks, Brock. I'm going to commit the patch right way.

Could the errors [~brocknoland] saw be due to HIVE-6309?

, The tests run as hadoop-1 while I think that is hadoop-2?, Okay. Never mind then., Patch committed to trunk. The remaining two failures were excluded in ptest property file.]