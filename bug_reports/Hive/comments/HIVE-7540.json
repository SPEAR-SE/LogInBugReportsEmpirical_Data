[Hi [~lirui],

It seems this related to serializing a closure as opposed to data. I talked with [~sandyr] and it seems that using Writable serialization is probably difficult/impossible. It looks like the Spark folks have also tried using Kryo to [serialize closures|http://mail-archives.apache.org/mod_mbox/spark-dev/201405.mbox/%3CCAPh_B=Z3mNZp4A=B3M9TnQqe6n+foB6fQSmLEkVwB+mUbb=Akg@mail.gmail.com%3E].

Can you try creating a class HiveBytesWritable which extends from BytesWritable and implements Serializable and then transform the objects into that class before the soryByKey?
, Hi [~brocknoland], we're using BytesWritable because the key of the RDD we create is of that type. Do you mean we should apply some map function to the RDD before (and after?) the sortByKey transformation?, Hi,

I am hoping we don't have to transform back since it will be a subclass of BytesWritable. If it works and we don't have a better solution in the long term we might have to transform to our special type directly after reading from hdfs. We can deal with that later though., OK got it. Let me try it out., It's good to try this out. However, I still think the right solution is in Spark. Any additional processing at per row level will make performance suffer. If there is absolutely impossible in Spark, it's helpful to provide a clear reason for that. , Hi [~xuefuz],

I agree it will cause performance to suffer. However, this will get us past a blocker and doesn't introduce fundamental performance issues in the design so I think we should optimize this later, once we have the functionality working., There are two main cases where serialization occurs in Spark
* Serializing each row for shuffling or caching
* Serializing the functions and data required to execute a task to send from the driver to the executors 

My understanding is that the error here is caused by serialization in the latter, which has minimal performance impact.  For per-row serialization, I agree that using Writable serialization is a worthy goal.  Serializing Writables in task closures is both much more difficult and will have minimal performance benefit., Thx Sandy. The performance discussion here relates to the workaround...a row by roe transform to a serializable type.

Can you speak to the challenges with using writable serialization for closures., In general a Spark closure is a Serializable object.  The proposal would be to allow objects underneath this object to be Writable, but not Serializable.  I'm not aware of a way to tell Java serialization to listen for objects that implement a certain type as it navigates the object graph and use a custom serialization for them.

I'm looking at the RangePartitioner code now and it might be possible to use custom serialization for the range bounds.  I just don't see a way to do it in the general case., Thanks Sandy. For the specific RangePartitioner case, I think we could use writeObject/readObject which are [optional methods|http://docs.oracle.com/javase/7/docs/api/java/io/Serializable.html] Serializable's can implement.

If the number of cases where we need to serialize a writable via java serialization is small, then providing point solutions using writeObject/readObject in RangePartitioner might be a reasonable fix. If anyone has a feeling for the number of times we will end up hitting this, please speak up. In the absence of more information, I would suggest we work around this issue on the Hive side and then once we've gathered more information (how many times we need to serialize a writable in a closure, performance impact, etc) we can decide on how to proceed., Here is what I have in mind:
1. per-row serialization should be using Writable interface. Right now Hive (on Spark) is using Kryo, which is a workaround rather than a solution. [~hshreedharan] has some proposal for this, and in my opinion we should push for it.

2. it's acceptable to use Kryo to serialize non-per-row objects. For this particular case, RangePartitioner should allow kryo if there is a problem with Writable. Especially, Hive already sets serializer=kryo.

3. java serialization should be avoided by all means. Obviously, Spark is tied with this very much, but Hive should not rely on that.

4. the proposed workaround mentioned above seems solving the problem of #2 while putting a per-row penalty. I'm concerned about this.

In general, I like the idea of putting in workaround to allow the project to proceed, but I'd also like the idea of not hiding the underneath real problem just because of the existence of an unacceptable workaround.

, bq. the proposed workaround mentioned above seems solving the problem of #2 while putting a per-row penalty. I'm concerned about this.

I too am concerned about this as it's potentially an expensive workaround. Implementing the "expensive" workaround here simply unblocks us, it doesn't "hide" the problem. We can open another JIRA and discuss the final solution while being unblocked here and giving us more time to gather information. That's valuable IMO., I'd be happy as long as we're not taking the "workaround" as the final solution. Thanks, Brock. Let's try to have the real solution from Spark., BTW, if we are just looking for a workaround that moves the project forward, [~lirui] proposed to set the partition number to one, which seems simpler and quicker., bq. I'd be happy as long as we're not taking the "workaround" as the final solution. 

Agreed 100%. In my original statement I said, we'd only use this solution if we had no better option.

Let's move the medium/long term discussion over to HIVE-7614 and use this JIRA to unblock the project., bq. BTW, if we are just looking for a workaround that moves the project forward, Rui Li proposed to set the partition number to one, which seems simpler and quicker.

It's not clear to me how long HIVE-7614 will take to resolve. I don't see any simple answers. Thus I would suggest we move the functionality of the project forward while giving us time to think through the long term solution to this problem., Just to make sure, was Kryo serialization turned on when you ran into this exception? On closer look, it appears that the Spark code is already trying to handle this situation., Actually, this handling hasn't made it into a release yet - SPARK-2104, but will be in 1.1., Nice, the fix might already be in place. Let's retry with with 1.1?, Hi [~sandyr], I set spark.serializer to KryoSerializer when I met this problem.
I noted that spark.closure.serializer is used when DAGScheduler tries to serialize a task. But spark.closure.serializer currently only supports java serializer., Hi [~lirui], it seems in Spark 1.1 RangePartitioner uses spark.serializer (https://github.com/apache/spark/commit/66135a341d9f8baecc149d13ae5511f14578c395). Can you retry this on the spark 1.1 branch?, Oh sure. It's great if that's already fixed., I've tested with spark 1.1 branch, and verified the NotSerializableException is gone.
[~brocknoland] should we make hive use spark-1.1.0-SNAPSHOT to have this fix?, Yes, since Spark has already implemented the "point" solution let's go with that! I resolved HIVE-7540 as a dup due to this new information., Use spark-1.1.0-SNAPSHOT to solve this issue.
SortByShuffler is changed accordingly since previously we have to set numPartitions to 1 to workaround this issue.

Please note since spark-1.1 is not released yet, we'll have to build it locally and install to the local maven repo., Hi [~brocknoland], I've uploaded a patch. But I'm afraid it will break the build since spark-1.1 is not available yet., Thank you Rui! I think we have some options such as deploying spark 1.1 to a webserver we control. I will look into these.., Hi [~brocknoland] I updated the patch to remove some unused code. Sorry about this., The following patch adds a repository which I control. I can push spark 1.1-SNAPSHOT whenever we require., Thank you very much for your contribution! I have committed the patch to trunk.]