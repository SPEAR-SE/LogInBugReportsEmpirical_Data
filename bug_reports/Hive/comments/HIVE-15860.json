[We cannot simply extend the monitor timeout to cover {{JobSubmitted}}, otherwise we'll hit HIVE-9370 again., Actually Rpc's listener can detect the remote end becomes inactive and mark SparkClient as dead accordingly. However, since we haven't received the JobId on Hive side, RemoteSparkJobStatus won't contact the remote driver for job info and simply return null for the monitor. And thus it never finds out the Rpc channel has already closed.
The patch adds a check every time the monitor runs, to make sure the remote context is still alive. The fix is for remote mode only, because I don't think the issue exists for local mode., Hi [~lirui], thanks for working on this. Just to clarify, does the monitor loop forever in the case? It seems that it does even though the broken connection is already detected at RPC layer. As a result, the user session will hang forever w/o making any progress., [~xuefuz] - yeah the monitor loops forever in that case. For the monitor, the job has started because we have received JobStarted event. So it goes to this switch branch every time it wakes up:
{code}
        case STARTED:
          JobExecutionStatus sparkJobState = sparkJobStatus.getState();
          if (sparkJobState == JobExecutionStatus.RUNNING) {
            Map<String, SparkStageProgress> progressMap = sparkJobStatus.getSparkStageProgress();
            if (!running) {
              perfLogger.PerfLogEnd(CLASS_NAME, PerfLogger.SPARK_SUBMIT_TO_RUNNING);
              printAppInfo();
              // print job stages.
              console.printInfo("\nQuery Hive on Spark job[" + sparkJobStatus.getJobId() +
                  "] stages: " + Arrays.toString(sparkJobStatus.getStageIds()));

              console.printInfo("\nStatus: Running (Hive on Spark job["
                + sparkJobStatus.getJobId() + "])");
              running = true;

              String format = "Job Progress Format\nCurrentTime StageId_StageAttemptId: "
                  + "SucceededTasksCount(+RunningTasksCount-FailedTasksCount)/TotalTasksCount";
              if (!inPlaceUpdate) {
                console.printInfo(format);
              } else {
                console.logInfo(format);
              }
            }

            printStatus(progressMap, lastProgressMap);
            lastProgressMap = progressMap;
          }
          break;
{code}
However, {{sparkJobStatus.getState()}} always returns null because we haven't received the JobSubmitted event which carries the JobId. At this point, we need a way to tell whether the connect has broken, or there's just a big gap between JobStarted and JobSubmitted, see HIVE-9370. So I added the check to see if the client is still alive., A more specific way to fix it is just add the check when job has started and {{sparkJobStatus.getState()}} returns null. The SENT and QUEUED branches are covered by the monitor timeout. The SUCCEEDED and FAILED branch will break the loop themselves. So we only need to worry about the STARTED branch., 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12852020/HIVE-15860.1.patch

{color:red}ERROR:{color} -1 due to no test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 4 failed/errored test(s), 10244 tests executed
*Failed tests:*
{noformat}
TestDerbyConnector - did not produce a TEST-*.xml file (likely timed out) (batchId=235)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[index_auto_partitioned] (batchId=10)
org.apache.hadoop.hive.cli.TestEncryptedHDFSCliDriver.testCliDriver[encryption_join_with_different_encryption_keys] (batchId=159)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=223)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/3485/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/3485/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-3485/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 4 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12852020 - PreCommit-HIVE-Build, Patch v2 adds the check only when job is in STARTED state and we can't get the job info. I think it's better because it avoids checking the remote context every time the monitor runs.
[~xuefuz] what do you think?, +1. Patch #2 looks good to me. Thanks for fixing this, [~lirui]!
, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12852041/HIVE-15860.2.patch

{color:red}ERROR:{color} -1 due to no test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 4 failed/errored test(s), 10227 tests executed
*Failed tests:*
{noformat}
TestDerbyConnector - did not produce a TEST-*.xml file (likely timed out) (batchId=235)
org.apache.hadoop.hive.cli.TestEncryptedHDFSCliDriver.testCliDriver[encryption_join_with_different_encryption_keys] (batchId=159)
org.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.org.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver (batchId=162)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=223)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/3488/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/3488/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-3488/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 4 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12852041 - PreCommit-HIVE-Build, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12852277/HIVE-15860.2.patch

{color:red}ERROR:{color} -1 due to no test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 5 failed/errored test(s), 10236 tests executed
*Failed tests:*
{noformat}
TestDerbyConnector - did not produce a TEST-*.xml file (likely timed out) (batchId=235)
org.apache.hadoop.hive.cli.TestEncryptedHDFSCliDriver.testCliDriver[encryption_join_with_different_encryption_keys] (batchId=159)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_if_expr] (batchId=140)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=223)
org.apache.hive.jdbc.TestMultiSessionsHS2WithLocalClusterSpark.testSparkQuery (batchId=217)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/3510/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/3510/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-3510/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 5 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12852277 - PreCommit-HIVE-Build, Latest failure not related., Committed to master. Thanks Xuefu for the review!, [~lirui], is there a real perf issue with running {{Preconditions.checkState(sparkJobStatus.isRemoteActive()}} during each iteration of the {{while}} loop? There shouldn't be much overhead, the check just checks the value of a {{boolean}} and if a connection is open or closed (which is also done for every RPC call made too).

I think the benefit is that it is safer, in case there are other edge cases we aren't considering, and it allows us to fail faster in the case where the {{RemoteSparkJobMonitor}} is in the {{QUEUED}} / {{SENT}} state. If its stuck in that state, it won't fail until it hits the monitor timeout (by default 1 minute), even though we already know the connection has died. The error message that is thrown is also a little imprecise, it says there could be queue contention, even though we know the real reason is that the connection was lost.

What do you think? If you agree, I can make the change in a follow up JIRA., Hi [~stakiar], I agree it's good to make QUEUED/SENT fail faster. But I still want to avoid the check in "normal" cases because as you said, each RPC call is doing the check already. Anyway, please feel free to open the JIRA.]