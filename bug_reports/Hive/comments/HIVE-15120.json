[Create external table do require write permission for the directory, here is the stack if not:
{code}
	StorageBasedAuthorizationProvider.checkPermissions(FileSystem, FileStatus, EnumSet<FsAction>, String) line: 412	
	StorageBasedAuthorizationProvider.checkPermissions(Configuration, Path, EnumSet<FsAction>) line: 377	
	StorageBasedAuthorizationProvider.authorize(Path, Privilege[], Privilege[]) line: 350	
	StorageBasedAuthorizationProvider.authorize(Table, Privilege[], Privilege[]) line: 195	
	AuthorizationPreEventListener.authorizeCreateTable(PreCreateTableEvent) line: 265	
	AuthorizationPreEventListener.onEvent(PreEventContext) line: 140	
	HiveMetaStore$HMSHandler.firePreEvent(PreEventContext) line: 2148	
	HiveMetaStore$HMSHandler.create_table_core(RawStore, Table, EnvironmentContext, List<SQLPrimaryKey>, List<SQLForeignKey>) line: 1354	
	HiveMetaStore$HMSHandler.create_table_with_environment_context(Table, EnvironmentContext) line: 1442	
	NativeMethodAccessorImpl.invoke0(Method, Object, Object[]) line: not available [native method]	
	NativeMethodAccessorImpl.invoke(Object, Object[]) line: 57	
	DelegatingMethodAccessorImpl.invoke(Object, Object[]) line: 43	
	Method.invoke(Object, Object...) line: 606	
	RetryingHMSHandler.invokeInternal(Object, Method, Object[]) line: 140	
	RetryingHMSHandler.invoke(Object, Method, Object[]) line: 99	
	$Proxy20.create_table_with_environment_context(Table, EnvironmentContext) line: not available	
	ThriftHiveMetastore$Processor$create_table_with_environment_context<I>.getResult(I, create_table_with_environment_context_args) line: 10939	
	ThriftHiveMetastore$Processor$create_table_with_environment_context<I>.getResult(Object, TBase) line: 10923	
	ThriftHiveMetastore$Processor$create_table_with_environment_context<I>(ProcessFunction<I,T>).process(int, TProtocol, TProtocol, I) line: 39	
	TUGIBasedProcessor$1.run() line: 110	
	TUGIBasedProcessor$1.run() line: 106	
	AccessController.doPrivileged(PrivilegedExceptionAction<T>, AccessControlContext) line: not available [native method]	
	Subject.doAs(Subject, PrivilegedExceptionAction<T>) line: 415	
	UserGroupInformation.doAs(PrivilegedExceptionAction<T>) line: 1628	
	TUGIBasedProcessor<I>.process(TProtocol, TProtocol) line: 118	
	TThreadPoolServer$WorkerProcess.run() line: 286	
	ThreadPoolExecutor.runWorker(ThreadPoolExecutor$Worker) line: 1145	
	ThreadPoolExecutor$Worker.run() line: 615	
	Thread.run() line: 745	
{code}

Only at deletion time, we distinguish external table and managed table, which is inconsistent. Not sure why we do that initially, but to maintain backward compatibility, I will still use a flag for this., 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12837304/HIVE-15120.1.patch

{color:green}SUCCESS:{color} +1 due to 2 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 2 failed/errored test(s), 10628 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[join_acid_non_acid] (batchId=150)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[union_fast_stats] (batchId=145)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/1977/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/1977/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-1977/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 2 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12837304 - PreCommit-HIVE-Build,  * I think we can enable this flag to true for new releases, and for backport to 2.1 we can set this to false, so that we don't change behavior in a bug fix release.
 * driver.run("remoke drop on table "+tblName+" from user "+userName);  - It should be revoke. ( looks like the protected methods don't get run anyways!)
 * The test added in TestStorageBasedMetastoreAuthorizationProvider isn't running, I assume that is because it is protected, not public method. See https://builds.apache.org/job/PreCommit-HIVE-Build/1977/testReport/org.apache.hadoop.hive.ql.security/TestStorageBasedMetastoreAuthorizationProvider/
 * +  private Configuration conf; . This isn't necessary. Looks like getConf() already returns the config
 * Use   conf.getBoolean(HiveConf.ConfVars.METASTORE_AUTHORIZATION_EXTERNALTABLE_DROP_CHECK.varname, false) = >   conf.getBoolean(HiveConf.ConfVars.METASTORE_AUTHORIZATION_EXTERNALTABLE_DROP_CHECK.varname, HiveConf.ConfVars.METASTORE_AUTHORIZATION_EXTERNALTABLE_DROP_CHECK.defaultBoolVal)  . 
We should to a cleanup later to just use HiveConf in the class.
, Not related to the patch -
I am not sure if current behavior of requiring write access for external table creation makes sense. Afterall, only read access is required to access the contents. This is something to be revisited in a follow up jira. Maybe allow only 'temporary table' creation with readonly access ?

cc [~sushanth], Address Thejas's comments. Set default value to true and use HiveConf.ConfVars.METASTORE_AUTHORIZATION_EXTERNALTABLE_DROP_CHECK.defaultBoolVal in StorageBasedAuthorizationProvider. The test is running. disallowDropOnTable is not a test, it is invoked by testSimplePrivileges. However, the test is not right in previous patch, corrected in the new one., +1 Pending tests
, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12837842/HIVE-15120.2.patch

{color:green}SUCCESS:{color} +1 due to 2 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 5 failed/errored test(s), 10628 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[join_acid_non_acid] (batchId=150)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[union_fast_stats] (batchId=145)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_4] (batchId=91)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_5] (batchId=90)
org.apache.hadoop.hive.ql.security.TestStorageBasedMetastoreAuthorizationProviderWithACL.testSimplePrivileges (batchId=216)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/2011/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/2011/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-2011/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 5 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12837842 - PreCommit-HIVE-Build, Fix UT failures., 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12837885/HIVE-15120.3.patch

{color:green}SUCCESS:{color} +1 due to 3 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 2 failed/errored test(s), 10628 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[join_acid_non_acid] (batchId=150)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[union_fast_stats] (batchId=145)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/2016/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/2016/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-2016/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 2 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12837885 - PreCommit-HIVE-Build, Review:  The description of *hive.metastore.authorization.storage.check.externaltable.drop* in HiveConf.java is indented by one extra space on lines 2, 3, and 4, but should be the same as line 1.

{code}
+        "Should StorageBasedAuthorization check permission of the storage before dropping external table.\n" +
+         "StorageBasedAuthorization already does this check for managed table. For external table however,\n" +
+         "anyone has read permission of the directory could drop external table, which is surprising.\n" +
+         "The flag set to false by default to maintain backward compatibility."),
{code}

Edits:
*  "anyone has read permission" -> "anyone who has read permission"
*  "The flag set to false" -> "The flag is set to false", Both test failures are tracked in HIVE-15058 .
, Including spelling changes from Lefty., Patch pushed to master and branch-1., Doc note:  This adds *hive.metastore.authorization.storage.check.externaltable.drop* to HiveConf.java, so it needs to be documented in the wiki.

* [Configuration Properties -- MetaStore | https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties#ConfigurationProperties-MetaStore]

Added TODOC1.3 and TODOC2.2 labels., In the code, the flag, hive.metastore.authorization.storage.check.externaltable.drop, is true by default. 
But In comments, it saids "The flag is set to false by default to maintain backward compatibility."
Comments /Doc or the flag default value, should be modified.

Edit 07/Dec/17:  Just a typo fix (flay -> flag) but also a +1 for fixing the parameter description., [~daijy] trying to create external table from S3 with readonly permissions. It throws up 403. Is there a way to disable write access check for external table create ?]