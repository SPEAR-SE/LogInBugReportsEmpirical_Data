[Added a thread to Driver to send heartbeats.  This thread only runs during the main loop in Driver.execute.  I added this in a separate thread because otherwise I would have needed to add threads in every task to see if heartbeats needed to be sent.  This would be very invasive, and also it's not clear it would be possible to cover all cases as there are actions that may simply take a long time (like certain metastore operations).  The downside is that a query will keep running even after it's found out it's locks were aborted and only be terminated at the end., Review board: https://reviews.apache.org/r/19161/, [~rhbutani] This patch should go into the 0.13 branch as well., This will double # of threads for HS2 and worse these threads are not coming from shared threadpool of HS2. How about putting heartbeat while we are waiting for MR job to finish. There is a while loop waiting polling for MR job status. I think we can put heartbeating there. This is in HadoopJobExecHelper::progress(), Have we solved all the places that DDL operations can take an hour plus?  And is this same job helper used by Tez or do we need to do it separately in that case?, I don't remember about any DDL operation taking that long. I don't think this job helper is used by Tez. For, Tez we need to put this somewhere else, need to dig into to find where., New version of the patch reworked according the approach indicated by Ashutosh., +1, 

{color:red}Overall{color}: -1 no tests executed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12634643/HIVE-6635.2.patch

Test results: http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/1799/testReport
Console output: http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/1799/console

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Tests exited with: NonZeroExitCodeException
Command 'bash /data/hive-ptest/working/scratch/source-prep.sh' failed with exit status 1 and output '+ [[ -n '' ]]
+ export 'ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m '
+ ANT_OPTS='-Xmx1g -XX:MaxPermSize=256m '
+ export 'M2_OPTS=-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128'
+ M2_OPTS='-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128'
+ cd /data/hive-ptest/working/
+ tee /data/hive-ptest/logs/PreCommit-HIVE-Build-1799/source-prep.txt
+ [[ false == \t\r\u\e ]]
+ mkdir -p maven ivy
+ [[ svn = \s\v\n ]]
+ [[ -n '' ]]
+ [[ -d apache-svn-trunk-source ]]
+ [[ ! -d apache-svn-trunk-source/.svn ]]
+ [[ ! -d apache-svn-trunk-source ]]
+ cd apache-svn-trunk-source
+ svn revert -R .
Reverted 'conf/hive-default.xml.template'
Reverted 'itests/qtest/pom.xml'
Reverted 'common/src/java/org/apache/hadoop/hive/conf/HiveConf.java'
Reverted 'ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMRTableScan1.java'
Reverted 'ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java'
Reverted 'ql/src/java/org/apache/hadoop/hive/ql/parse/ProcessAnalyzeTable.java'
Reverted 'ql/src/java/org/apache/hadoop/hive/ql/exec/TaskFactory.java'
Reverted 'ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcInputFormat.java'
Reverted 'ql/src/java/org/apache/hadoop/hive/ql/io/orc/ReaderImpl.java'
++ awk '{print $2}'
++ egrep -v '^X|^Performing status on external'
++ svn status --no-ignore
+ rm -rf target datanucleus.log ant/target shims/target shims/0.20/target shims/0.20S/target shims/0.23/target shims/aggregator/target shims/common/target shims/common-secure/target hbase-handler/target testutils/target jdbc/target metastore/target hcatalog/target hcatalog/server-extensions/target hcatalog/core/target hcatalog/webhcat/svr/target hcatalog/webhcat/java-client/target hcatalog/hcatalog-pig-adapter/target hwi/target common/target common/src/gen common/src/java/org/apache/hadoop/hive/conf/HiveConf.java.orig contrib/target service/target serde/target beeline/target odbc/target cli/target ql/dependency-reduced-pom.xml ql/target ql/src/test/results/clientpositive/orc_analyze.q.out ql/src/test/results/clientpositive/tez/orc_analyze.q.out ql/src/test/queries/clientpositive/orc_analyze.q ql/src/java/org/apache/hadoop/hive/ql/plan/StatsNoJobWork.java ql/src/java/org/apache/hadoop/hive/ql/exec/StatsNoJobTask.java ql/src/java/org/apache/hadoop/hive/ql/io/StatsProvidingRecordReader.java
+ svn update

Fetching external item into 'hcatalog/src/test/e2e/harness'
External at revision 1577797.

At revision 1577797.
+ patchCommandPath=/data/hive-ptest/working/scratch/smart-apply-patch.sh
+ patchFilePath=/data/hive-ptest/working/scratch/build.patch
+ [[ -f /data/hive-ptest/working/scratch/build.patch ]]
+ chmod +x /data/hive-ptest/working/scratch/smart-apply-patch.sh
+ /data/hive-ptest/working/scratch/smart-apply-patch.sh /data/hive-ptest/working/scratch/build.patch
The patch does not appear to apply with p0, p1, or p2
+ exit 1
'
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12634643, Resubmitting patch after build break to get tests run., Patch no longer applies.  I'll upload a new version., 

{color:red}Overall{color}: -1 at least one tests failed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12636208/HIVE-6635.3.patch

{color:red}ERROR:{color} -1 due to 1 failed/errored test(s), 5443 tests executed
*Failed tests:*
{noformat}
org.apache.hive.service.cli.thrift.TestThriftHttpCLIService.testExecuteStatementAsync
{noformat}

Test results: http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/1950/testReport
Console output: http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/1950/console

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 1 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12636208, Committed to trunk & 0.13. Thanks, Alan!]