[Here's the patch ported for {{master/}}.

I wonder if it's better to flush at an interval, instead of for *every* partition., Submitting, to run tests., Hi Mithun, thanks for the providing the patch. Can you please update the patch with HIVE specific JIRA number and description of this JIRA as per our convention? You can add a line in the description where this patch was cherry-picked from I you like.. Also, wondering how the patch alleviates the problem? If there are hundreds of partitions being added, aren't they already in memory in the {{List<Partition> parts}} object? If you have any stats to share it would be great. Eg. before --> running out of memory at X number of partitions ; after --> running out of memory at X+Y number of partitions. Thanks!, @[~vihangk1]: Thank you for your attention. :]

bq. Can you please update the patch with HIVE specific JIRA number and description of this JIRA as per our convention?
Sorry, it's been a while, so perhaps you could clarify for me. My memory of the convention is that patches are named {{HIVE-<jira-number>.<version-of-patch>.patch}}. If the patch is a port to another branch, then it's {{HIVE-<jira-number>.<branch>.patch}}. 
From perusing the JIRAs included in [the Hive 2.2 release|https://issues.apache.org/jira/projects/HIVE/versions/12335837], this seems like the format of choice. Could you please clarify what I'm missing?

bq. You can add a line in the description where this patch was cherry-picked from I you like..
This is a port from Yahoo's internal production branch. The commit dates back to April of 2014. :]

bq. If there are hundreds of partitions being added, aren't they already in memory in the {{List<Partition>}} parts object?
A fair question. :] I can try answer this, although [~cdrome] and [~thiruvel] are really the experts on this one. 
The problem being addressed here isn't so much with the size of the hundreds of {{Partition}} objects, but the cruft that builds with the {{PersistenceManager}}, in the JDO layer, as confirmed through memory-profiling.

Our larger commit also plugged leaks from neglecting to call {{Query::close()}}, etc. It looks like those have independently been solved already.
, P.S. I've added clarification in the JIRA description.

We've had a rash of JIRAs with anaemic descriptions recently. I hope this version is more clear., 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12879241/HIVE-17188.1.patch

{color:red}ERROR:{color} -1 due to no test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 11 failed/errored test(s), 11007 tests executed
*Failed tests:*
{noformat}
TestPerfCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=235)
org.apache.hadoop.hive.cli.TestBeeLineDriver.testCliDriver[insert_overwrite_local_directory_1] (batchId=240)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[llap_smb] (batchId=144)
org.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver[spark_dynamic_partition_pruning] (batchId=168)
org.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver[spark_vectorized_dynamic_partition_pruning] (batchId=168)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainuser_3] (batchId=99)
org.apache.hadoop.hive.cli.TestSparkNegativeCliDriver.org.apache.hadoop.hive.cli.TestSparkNegativeCliDriver (batchId=242)
org.apache.hadoop.hive.metastore.TestHiveMetaStoreStatsMerge.testStatsMerge (batchId=206)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema (batchId=179)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema (batchId=179)
org.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation (batchId=179)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/6166/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/6166/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-6166/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 11 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12879241 - PreCommit-HIVE-Build, I'm +1 on this change. This has been running in production for some time now. 

I'd like to commit this to {{master}} and {{branch-2}}, tomorrow, unless there is objection., Looks good to me. 
+1 , Committed to {{master}}, {{branch-2}}, and {{branch-2.2}}, as advised by [~owen.omalley].

Thank you, [~cdrome], for the patch. Thanks, [~vihangk1], for the review., [~mithun], you should add 2.4.0 to the fix versions, since you also committed this to branch-2 (but not to branch-2.3 for 2.3.0)., Yes, would probably make sense to merge this in branch-2.3 as well if this is available in 2.2.0 release. Otherwise, this patch would be available in 2.2.0 and 2.4.0 but not in 2.3.0, [~leftylev]: Thank you for correcting me. I've added 2.4, as per your advice.

bq. would probably make sense to merge this in branch-2.3 as well...
A fair point, [~vihangk1]. [~pxiong], do I have your permission to merge this into {{branch-2.3}}?, Hive 3.0.0 has been released so closing this jira.]