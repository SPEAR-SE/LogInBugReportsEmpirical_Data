[After quite a bit of testing, I found that the most reliable means to detect if beeline is being run via a remote shell is to check if the <stdin> for the process is a pipe.
So I have added an additional check to the condition before using jline's UnsupportedTerminal. The use of UnsupportedTerminal should be limited to beeline processes running locally as a background process.

The output now is as we expected prior to this change.
{code}
ssh -l root <remoteHost.domain.com> "sudo -u hive beeline -u jdbc:hive2://localhost:10000 -n hive -p hive --silent=true --outputformat=csv2 -f /tmp/run.sql"
root@<remoteHost.domain.com>'s password: 
16/08/04 13:46:35 WARN mapreduce.TableMapReduceUtil: The hbase-prefix-tree module jar containing PrefixTreeCodec is not present.  Continuing without it.





key,name,value
1,TRUE,1


$
{code}, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12822163/HIVE-14342.patch

{color:red}ERROR:{color} -1 due to build exiting with an error

Test results: https://builds.apache.org/job/PreCommit-HIVE-MASTER-Build/777/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-MASTER-Build/777/console
Test logs: http://ec2-204-236-174-241.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-MASTER-Build-777/

Messages:
{noformat}
**** This message was trimmed, see log for full details ****
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/spark-client/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/spark-client/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/spark-client/target/tmp/conf
     [copy] Copying 15 files to /data/hive-ptest/working/apache-github-source-source/spark-client/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ spark-client ---
[INFO] Compiling 5 source files to /data/hive-ptest/working/apache-github-source-source/spark-client/target/test-classes
[INFO] 
[INFO] --- maven-dependency-plugin:2.8:copy (copy-guava-14) @ spark-client ---
[INFO] Configured Artifact: com.google.guava:guava:14.0.1:jar
[INFO] Copying guava-14.0.1.jar to /data/hive-ptest/working/apache-github-source-source/spark-client/target/dependency/guava-14.0.1.jar
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ spark-client ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ spark-client ---
[INFO] Building jar: /data/hive-ptest/working/apache-github-source-source/spark-client/target/spark-client-2.2.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-site-plugin:3.3:attach-descriptor (attach-descriptor) @ spark-client ---
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ spark-client ---
[INFO] Installing /data/hive-ptest/working/apache-github-source-source/spark-client/target/spark-client-2.2.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/spark-client/2.2.0-SNAPSHOT/spark-client-2.2.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-github-source-source/spark-client/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/spark-client/2.2.0-SNAPSHOT/spark-client-2.2.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Query Language 2.2.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-exec ---
[INFO] Deleting /data/hive-ptest/working/apache-github-source-source/ql/target
[INFO] Deleting /data/hive-ptest/working/apache-github-source-source/ql (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-enforcer-plugin:1.3.1:enforce (enforce-no-snapshots) @ hive-exec ---
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (generate-sources) @ hive-exec ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/ql/target/generated-sources/java/org/apache/hadoop/hive/ql/exec/vector/expressions/gen
    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/ql/target/generated-sources/java/org/apache/hadoop/hive/ql/exec/vector/expressions/aggregates/gen
    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/ql/target/generated-test-sources/java/org/apache/hadoop/hive/ql/exec/vector/expressions/gen
Generating vector expression code
Generating vector expression test code
[INFO] Executed tasks
[INFO] 
[INFO] --- build-helper-maven-plugin:1.8:add-source (add-source) @ hive-exec ---
[INFO] Source directory: /data/hive-ptest/working/apache-github-source-source/ql/src/gen/thrift/gen-javabean added.
[INFO] Source directory: /data/hive-ptest/working/apache-github-source-source/ql/target/generated-sources/java added.
[INFO] 
[INFO] --- antlr3-maven-plugin:3.4:antlr (default) @ hive-exec ---
[INFO] ANTLR: Processing source directory /data/hive-ptest/working/apache-github-source-source/ql/src/java
ANTLR Parser Generator  Version 3.4
org/apache/hadoop/hive/ql/parse/HiveLexer.g
org/apache/hadoop/hive/ql/parse/HiveParser.g
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hive-exec ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hive-exec ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 4 resources
[INFO] Copying 3 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-exec ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-exec ---
[INFO] Compiling 2653 source files to /data/hive-ptest/working/apache-github-source-source/ql/target/classes
[INFO] -------------------------------------------------------------
[ERROR] COMPILATION ERROR : 
[INFO] -------------------------------------------------------------
[ERROR] /data/hive-ptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java:[130,40] cannot find symbol
  symbol:   class SynchronizedMetaStoreClient
  location: package org.apache.hadoop.hive.metastore
[ERROR] /data/hive-ptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/lockmgr/DbTxnManager.java:[22,40] cannot find symbol
  symbol:   class SynchronizedMetaStoreClient
  location: package org.apache.hadoop.hive.metastore
[ERROR] /data/hive-ptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java:[168,11] cannot find symbol
  symbol:   class SynchronizedMetaStoreClient
  location: class org.apache.hadoop.hive.ql.metadata.Hive
[ERROR] /data/hive-ptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java:[3472,23] cannot find symbol
  symbol:   class SynchronizedMetaStoreClient
  location: class org.apache.hadoop.hive.ql.metadata.Hive
[ERROR] /data/hive-ptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/lockmgr/DbLockManager.java:[21,40] cannot find symbol
  symbol:   class SynchronizedMetaStoreClient
  location: package org.apache.hadoop.hive.metastore
[ERROR] /data/hive-ptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/lockmgr/DbTxnManager.java:[64,11] cannot find symbol
  symbol:   class SynchronizedMetaStoreClient
  location: class org.apache.hadoop.hive.ql.lockmgr.DbTxnManager
[ERROR] /data/hive-ptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/lockmgr/DbTxnManager.java:[89,30] cannot find symbol
  symbol:   class SynchronizedMetaStoreClient
  location: class org.apache.hadoop.hive.ql.lockmgr.DbTxnManager
[ERROR] /data/hive-ptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/lockmgr/DbTxnManager.java:[110,18] cannot find symbol
  symbol:   class SynchronizedMetaStoreClient
  location: class org.apache.hadoop.hive.ql.lockmgr.DbTxnManager
[ERROR] /data/hive-ptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/lockmgr/DbLockManager.java:[56,11] cannot find symbol
  symbol:   class SynchronizedMetaStoreClient
  location: class org.apache.hadoop.hive.ql.lockmgr.DbLockManager
[ERROR] /data/hive-ptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/lockmgr/DbLockManager.java:[60,17] cannot find symbol
  symbol:   class SynchronizedMetaStoreClient
  location: class org.apache.hadoop.hive.ql.lockmgr.DbLockManager
[INFO] 10 errors 
[INFO] -------------------------------------------------------------
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Summary:
[INFO] 
[INFO] Hive .............................................. SUCCESS [1.803s]
[INFO] Hive Shims Common ................................. SUCCESS [3.575s]
[INFO] Hive Shims 0.23 ................................... SUCCESS [1.900s]
[INFO] Hive Shims Scheduler .............................. SUCCESS [0.555s]
[INFO] Hive Shims ........................................ SUCCESS [0.339s]
[INFO] Hive Storage API .................................. SUCCESS [0.892s]
[INFO] Hive ORC .......................................... SUCCESS [4.303s]
[INFO] Hive Common ....................................... SUCCESS [4.289s]
[INFO] Hive Service RPC .................................. SUCCESS [3.322s]
[INFO] Hive Serde ........................................ SUCCESS [4.440s]
[INFO] Hive Metastore .................................... SUCCESS [18.939s]
[INFO] Hive Ant Utilities ................................ SUCCESS [0.295s]
[INFO] Hive Llap Common .................................. SUCCESS [2.427s]
[INFO] Hive Llap Client .................................. SUCCESS [1.042s]
[INFO] Hive Llap Tez ..................................... SUCCESS [1.641s]
[INFO] Spark Remote Client ............................... SUCCESS [2.821s]
[INFO] Hive Query Language ............................... FAILURE [17.695s]
[INFO] Hive Llap Server .................................. SKIPPED
[INFO] Hive Service ...................................... SKIPPED
[INFO] Hive Accumulo Handler ............................. SKIPPED
[INFO] Hive JDBC ......................................... SKIPPED
[INFO] Hive Beeline ...................................... SKIPPED
[INFO] Hive CLI .......................................... SKIPPED
[INFO] Hive Contrib ...................................... SKIPPED
[INFO] Hive HBase Handler ................................ SKIPPED
[INFO] Hive HCatalog ..................................... SKIPPED
[INFO] Hive HCatalog Core ................................ SKIPPED
[INFO] Hive HCatalog Pig Adapter ......................... SKIPPED
[INFO] Hive HCatalog Server Extensions ................... SKIPPED
[INFO] Hive HCatalog Webhcat Java Client ................. SKIPPED
[INFO] Hive HCatalog Webhcat ............................. SKIPPED
[INFO] Hive HCatalog Streaming ........................... SKIPPED
[INFO] Hive HPL/SQL ...................................... SKIPPED
[INFO] Hive HWI .......................................... SKIPPED
[INFO] Hive Llap External Client ......................... SKIPPED
[INFO] Hive Shims Aggregator ............................. SKIPPED
[INFO] Hive TestUtils .................................... SKIPPED
[INFO] Hive Packaging .................................... SKIPPED
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 1:11.114s
[INFO] Finished at: Thu Aug 04 23:08:56 UTC 2016
[INFO] Final Memory: 131M/1021M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.1:compile (default-compile) on project hive-exec: Compilation failure: Compilation failure:
[ERROR] /data/hive-ptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java:[130,40] cannot find symbol
[ERROR] symbol:   class SynchronizedMetaStoreClient
[ERROR] location: package org.apache.hadoop.hive.metastore
[ERROR] /data/hive-ptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/lockmgr/DbTxnManager.java:[22,40] cannot find symbol
[ERROR] symbol:   class SynchronizedMetaStoreClient
[ERROR] location: package org.apache.hadoop.hive.metastore
[ERROR] /data/hive-ptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java:[168,11] cannot find symbol
[ERROR] symbol:   class SynchronizedMetaStoreClient
[ERROR] location: class org.apache.hadoop.hive.ql.metadata.Hive
[ERROR] /data/hive-ptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java:[3472,23] cannot find symbol
[ERROR] symbol:   class SynchronizedMetaStoreClient
[ERROR] location: class org.apache.hadoop.hive.ql.metadata.Hive
[ERROR] /data/hive-ptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/lockmgr/DbLockManager.java:[21,40] cannot find symbol
[ERROR] symbol:   class SynchronizedMetaStoreClient
[ERROR] location: package org.apache.hadoop.hive.metastore
[ERROR] /data/hive-ptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/lockmgr/DbTxnManager.java:[64,11] cannot find symbol
[ERROR] symbol:   class SynchronizedMetaStoreClient
[ERROR] location: class org.apache.hadoop.hive.ql.lockmgr.DbTxnManager
[ERROR] /data/hive-ptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/lockmgr/DbTxnManager.java:[89,30] cannot find symbol
[ERROR] symbol:   class SynchronizedMetaStoreClient
[ERROR] location: class org.apache.hadoop.hive.ql.lockmgr.DbTxnManager
[ERROR] /data/hive-ptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/lockmgr/DbTxnManager.java:[110,18] cannot find symbol
[ERROR] symbol:   class SynchronizedMetaStoreClient
[ERROR] location: class org.apache.hadoop.hive.ql.lockmgr.DbTxnManager
[ERROR] /data/hive-ptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/lockmgr/DbLockManager.java:[56,11] cannot find symbol
[ERROR] symbol:   class SynchronizedMetaStoreClient
[ERROR] location: class org.apache.hadoop.hive.ql.lockmgr.DbLockManager
[ERROR] /data/hive-ptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/lockmgr/DbLockManager.java:[60,17] cannot find symbol
[ERROR] symbol:   class SynchronizedMetaStoreClient
[ERROR] location: class org.apache.hadoop.hive.ql.lockmgr.DbLockManager
[ERROR] -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn <goals> -rf :hive-exec
+ exit 1
'
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12822163 - PreCommit-HIVE-MASTER-Build, Pre-commit build failed because of build failure due to missing file from HIVE-14204. Retrying, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12822205/HIVE-14342.patch

{color:red}ERROR:{color} -1 due to no test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 4 failed/errored test(s), 10440 tests executed
*Failed tests:*
{noformat}
TestMsgBusConnection - did not produce a TEST-*.xml file
TestQueryLifeTimeHook - did not produce a TEST-*.xml file
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver_orc_llap_counters
org.apache.hadoop.hive.metastore.txn.TestCompactionTxnHandler.testRevokeTimedOutWorkers
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-MASTER-Build/781/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-MASTER-Build/781/console
Test logs: http://ec2-204-236-174-241.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-MASTER-Build-781/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 4 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12822205 - PreCommit-HIVE-MASTER-Build, [~mohitsabharwal] [~aihuaxu] Could you please review the fix? 
The proposed fix adds an additional condition to only use the UnsupportedTerminal for beeline running as background process when run locally. The condition detects that beeline is being invoked from a remote shell by checking if stdin for the script is a pipe., Appears that from HIVE-11717 we need to make an additional change to the cli.sh 
Attaching a new patch that includes that fix., Thanks, [~ngangam]

Wondering if you tried simply detecting if the prompt
variable is set ? Seems like that is a more intuitive
solution:
http://tldp.org/LDP/abs/html/intandnonint.html, Thanks Mohit. I ran the following test on bash 4.1.2 (tried both conditions, the second condition for Bash 4.2+ does not seem to work as expected).
The prompt variable does not seem to be set in any scenario. I ran the test both in background and foreground and the result is the same. Running from a remote node results in the same.

{code}
# cat test.sh 
#!/usr/bin/env bash

if [ -z $PS1 ] # no prompt?
#if [ -v PS1 ]   # On Bash 4.2+ ...
then
  echo "non-interactive3"
else
  echo "interactive3"
fi
# ./test.sh 
non-interactive3
# ./test.sh &
[1] 5715
# non-interactive3

[1]+  Done                    ./test.sh
{code}

From a remote node
{code}
ngangam-MBP-2:~ ngangam$ ssh -l root <remoteHost.domain.com> "/root/test.sh"
root@<remoteHost.domain.com>'s password: 
non-interactive3
{code}

In the link above, further down on the page, there is a sample using exactly what the patch is, "-p /dev/stdin". Do you know any other means that might work? Thanks, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12822344/HIVE-14342.2.patch

{color:red}ERROR:{color} -1 due to no test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 5 failed/errored test(s), 10440 tests executed
*Failed tests:*
{noformat}
TestMsgBusConnection - did not produce a TEST-*.xml file
TestQueryLifeTimeHook - did not produce a TEST-*.xml file
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver_orc_llap_counters
org.apache.hadoop.hive.llap.tezplugins.TestLlapTaskSchedulerService.testDelayedLocalityNodeCommErrorImmediateAllocation
org.apache.hive.jdbc.TestJdbcWithMiniHS2.testAddJarConstructorUnCaching
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-MASTER-Build/793/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-MASTER-Build/793/console
Test logs: http://ec2-204-236-174-241.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-MASTER-Build-793/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 5 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12822344 - PreCommit-HIVE-MASTER-Build, Thanks, [~ngangam], LGTM +1, Committed to 2.2.0 and 2.1.1, thanks [~ngangam] for the patch and [~mohitsabharwal] for review., Are you sure this has been fixed? We are using Cloudera distribution with HIVE-14342 bundled and I can confirm that cli.sh file contains check for unsupported terminal:

{code}
updateBeelineOpts() {
  # If process is backgrounded, don't change terminal settings
  if [[ ( ! $(ps -o stat= -p $$) =~ *+ ) && ! ( -p /dev/stdin ) ]]; then
    export HADOOP_CLIENT_OPTS="$HADOOP_CLIENT_OPTS -Djline.terminal=jline.UnsupportedTerminal"
  fi
}
{code}

 

*Test case to reproduce:*

_*test.hql content:*_
{code:sql}
   SELECT 1;
{code}
_*Bash command & output:*_
{code:bash}
$ beeline -u jdbc:hive2://xxxxxxx:10000 --silent=true  --showWarnings=false --showNestedErrs=false --showHeader=false --outputformat=tsv2 -f ~/test.hql & wait
[1] 3076126
null1

{code}
I also tried to add this line before calling beeline:
{code:java}
 export HADOOP_CLIENT_OPTS="$HADOOP_CLIENT_OPTS -Djline.terminal=jline.UnsupportedTerminal"

{code}
Nothing has changed. Please help.

 

 , Anyone can confirm my issue?, [~cabot] Your testcase is slightly different than the issue in this jira. You are running beeline as a background process that has to use the {{-Djline.terminal=jline.UnsupportedTerminal}} property. Otherwise there is contention for STDOUT/STDERR streams between the JLine Terminal and Unix background process. As a result, the backgrounded beeline process is SUSPENDED by the OS (similar to CNTRL Z). 

So without using this property, beeline wouldnt even run as a background process. But unfortunately, it appears to have this side effect. I can look at the jline code again to see if there have been any fixes.

Does that make sense?, [~ngangam] Thank you for your response!
Are you able to reproduce my problem on your cluster configuration as well?]