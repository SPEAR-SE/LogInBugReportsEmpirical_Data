[This is a dependency problem,

in common/src/java/org/apache/hadoop/hive/common/FileUtils.java:

FileUtils.java, tar() is using GzipCompressorOutputStream, and import this class in the header.

When FileSinkOperator.java is calling FileUtils.makePartName(dpColNames, row) in its getDynPartDirectory() function, this NoClassDefFoundError is triggered.

This is because, both tar() and makePartName() are static functions in FileUtils.java.

when one static member of a class is referenced, the JVM has to initialize all static members, including static methods, and part of initializing static methods involves making sure that all of the dependencies are available.

so, when makePartName() is called from FileSinkOperator.getDynPartDirectory(), tar() is initialized, and JVM tries to resolve the GzipCompressorOutputStream dependency.

GzipCompressorOutputStream is from commons-compress*.jar. This dependency is added to common/ivy.xml, but not included in hive-exec.jar.

When running on one machine, it is passed, sine commons-compress*.jar is resolved by ivy, and it is in build/ivy/lib/default.

But when running in a real cluster, commons-compress*.jar is not included in all mapper/reducers classpath. So, this NoClassDefFoundError would be triggered.

My proposed solution is to add commons-compress*.jar into hive-exec.jar., Review Request submitted at:
https://reviews.facebook.net/D5103, This approach is fine. Do you think we can simple redo FileUtils so it is not a final class and we remove the static methods? Or is it that case that we have to include commons-compress in hive-exec regardless? , @Edward: I just found that HIVE-3295 already fixes the bug by a redo of FileUtils. This is definitely better than adding commons-compress into hive-exec. Thanks a lot for your guide. How about I take HIVE-3295's patch, and mark this as duplicate?, This issue is fixed and released as part of 0.10.0 release. If you find an issue which seems to be related to this one, please create a new jira and link this one with new jira.]