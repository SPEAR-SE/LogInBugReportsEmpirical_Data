[I have to look at the stack trace to get more detail. I am guessing the issue could have to do with the result file being created, for later comparison. I say this because this is the only large change to happen to the test case in the last patch.

{noformat}
  File tmpdir = new File("/tmp/" + System.getProperty("user.name") + "/");
                if (tmpdir.exists() && !tmpdir.isDirectory()) {
                        throw new RuntimeException(tmpdir + " exists but is not a directory");
                }

                if (!tmpdir.exists()) {
                        if (!tmpdir.mkdirs()) {
                                throw new RuntimeException("Could not make scratch directory " + tmpdir);
                        }
                }
{noformat}, I have not been able to recreate this error locally. Could this have anything to do with hudson setup?, I can't recreate it locally either and I can't log into the hudson machine to test there either unfortunately. Dhruba, could you have a look?, Looks like it is not able to find /tmp/hadoop-hudson/mapred/system/<id>/job_local_0001

I cannot see any obvious permissions or disk quota issues. Still checking...

[junit] 09/03/30 07:45:20 ERROR exec.ExecDriver: Job Submission failed with exception 'org.apache.hadoop.util.Shell$ExitCodeException(chmod: cannot access `/tmp/hadoop-hudson/mapred/system/206391269/job_local_0001': No such file or directory
    [junit] Job Failed
    [junit] )'
    [junit] org.apache.hadoop.util.Shell$ExitCodeException: chmod: cannot access `/tmp/hadoop-hudson/mapred/system/206391269/job_local_0001': No such file or directory
    [junit] 
    [junit] 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:195)
    [junit] 	at org.apache.hadoop.util.Shell.run(Shell.java:134)
    [junit] 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:286)
    [junit] 	at org.apache.hadoop.util.Shell.execCommand(Shell.java:317)
    [junit] 	at org.apache.hadoop.fs.RawLocalFileSystem.execCommand(RawLocalFileSystem.java:540)
    [junit] 	at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:532)
    [junit] 	at org.apache.hadoop.fs.FilterFileSystem.setPermission(FilterFileSystem.java:284)
    [junit] 	at org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:283)
, I'm trying to run them on different Hudson machines now to see if that helps. Join me on freenode in ##hive if you want to chat about it., It also seems to me that we are using diff -a in our tests and that does not go down well with hudson (I think this is working on a solaris box and it does not have a -a option in the diff command).
, I opened HIVE-388 for the diff issue. 

We normally ran the builds on one of the Ubuntu machines, minerva.apache.org. I just started poking around with the builds an hour ago, trying to run this one: http://hudson.zones.apache.org/hudson/job/Hive-trunk-h0.18/55 on hudson.zones.apache.org (sun) and this one http://hudson.zones.apache.org/hudson/job/Hive-trunk-h0.17/54 on vesta.apache.org (ubuntu), it hasn't started yet thoygh., Seems this build completed now on vesta, so perhaps there's some crap in the tmp dir on minerva? Either way I'm going to put all the builds on vesta for now. http://hudson.zones.apache.org/hudson/job/Hive-trunk-h0.17/54/, Moving to 0.4, doesn't block 0.3 since it's a server issue., Marking this as critical since it is not really blocking the release. Want to get the blocker count to 0 in order to start a vote on the release.
, This doesn't look like a problem any longer. Builds are passing on jenkins.]