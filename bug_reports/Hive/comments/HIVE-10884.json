[WIP patch. Doesn't actually work, shutdown of the first test (?) throws some ClassNotFoundException-s and the whole thing gets stuck, Ok, for me tests get stuck after this:
{noformat}
2015-06-01 14:56:19,500 ERROR [HiveServer2-Handler-Pool: Thread-45]: server.NIOServerCnxnFactory (NIOServerCnxnFactory.java:uncaughtException(44)) - Thread Thread[HiveServer2-Handler-Pool: Thread-45,5,main] died
java.lang.NoClassDefFoundError: org/apache/hive/service/cli/thrift/TCLIService$CloseSession_result$CloseSession_resultStandardScheme
	at org.apache.hive.service.cli.thrift.TCLIService$CloseSession_result$CloseSession_resultStandardSchemeFactory.getScheme(TCLIService.java:2988)
	at org.apache.hive.service.cli.thrift.TCLIService$CloseSession_result$CloseSession_resultStandardSchemeFactory.getScheme(TCLIService.java:2986)
	at org.apache.hive.service.cli.thrift.TCLIService$CloseSession_result.write(TCLIService.java:2943)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:53)
	at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)
	at org.apache.hive.service.auth.TSetIpAddressProcessor.process(TSetIpAddressProcessor.java:56)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:285)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
{noformat}

I have tried cleaning maven repo, regenerating thrift (no significant changes).
In debugger, the factory on the stack is executing from correct jar. If I unjar that, I can also find the offending class:
{noformat}
$ jar -xfv /Users/sergey/.m2/repository/org/apache/hive/hive-service/1.3.0-SNAPSHOT/hive-service-1.3.0-SNAPSHOT.jar | grep CloseSession.*resultStandardScheme
Picked up JAVA_TOOL_OPTIONS: -Djava.awt.headless=true
 inflated: org/apache/hive/service/cli/thrift/TCLIService$CloseSession_result$CloseSession_resultStandardScheme.class
 inflated: org/apache/hive/service/cli/thrift/TCLIService$CloseSession_result$CloseSession_resultStandardSchemeFactory.class
{noformat}

However, when I try to load this class from Factory class classloader in debugger, I also get class not found (factory class classloader can find the factory class itself).

Not really sure how this can happen.

[~cwsteinbach] do you have any background on this?
[~xuefuz] I am assuming you guys will need to enable beeline tests as part of beeline-by-default work... have you run into this issue?, let's see what HiveQA says, just for kicks, 

{color:red}Overall{color}: -1 no tests executed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12736655/HIVE-10884.patch

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/4133/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/4133/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-4133/

Messages:
{noformat}
**** This message was trimmed, see log for full details ****
    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/spark-client/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/spark-client/target/tmp/conf
     [copy] Copying 11 files to /data/hive-ptest/working/apache-github-source-source/spark-client/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ spark-client ---
[INFO] Compiling 5 source files to /data/hive-ptest/working/apache-github-source-source/spark-client/target/test-classes
[INFO] 
[INFO] --- maven-dependency-plugin:2.8:copy (copy-guava-14) @ spark-client ---
[INFO] Configured Artifact: com.google.guava:guava:14.0.1:jar
[INFO] Copying guava-14.0.1.jar to /data/hive-ptest/working/apache-github-source-source/spark-client/target/dependency/guava-14.0.1.jar
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ spark-client ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ spark-client ---
[INFO] Building jar: /data/hive-ptest/working/apache-github-source-source/spark-client/target/spark-client-1.3.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-site-plugin:3.3:attach-descriptor (attach-descriptor) @ spark-client ---
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ spark-client ---
[INFO] Installing /data/hive-ptest/working/apache-github-source-source/spark-client/target/spark-client-1.3.0-SNAPSHOT.jar to /home/hiveptest/.m2/repository/org/apache/hive/spark-client/1.3.0-SNAPSHOT/spark-client-1.3.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-github-source-source/spark-client/pom.xml to /home/hiveptest/.m2/repository/org/apache/hive/spark-client/1.3.0-SNAPSHOT/spark-client-1.3.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Query Language 1.3.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-exec ---
[INFO] Deleting /data/hive-ptest/working/apache-github-source-source/ql/target
[INFO] Deleting /data/hive-ptest/working/apache-github-source-source/ql (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-enforcer-plugin:1.3.1:enforce (enforce-no-snapshots) @ hive-exec ---
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (generate-sources) @ hive-exec ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/ql/target/generated-sources/java/org/apache/hadoop/hive/ql/exec/vector/expressions/gen
    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/ql/target/generated-sources/java/org/apache/hadoop/hive/ql/exec/vector/expressions/aggregates/gen
    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/ql/target/generated-test-sources/java/org/apache/hadoop/hive/ql/exec/vector/expressions/gen
Generating vector expression code
Generating vector expression test code
[INFO] Executed tasks
[INFO] 
[INFO] --- build-helper-maven-plugin:1.8:add-source (add-source) @ hive-exec ---
[INFO] Source directory: /data/hive-ptest/working/apache-github-source-source/ql/src/gen/protobuf/gen-java added.
[INFO] Source directory: /data/hive-ptest/working/apache-github-source-source/ql/src/gen/thrift/gen-javabean added.
[INFO] Source directory: /data/hive-ptest/working/apache-github-source-source/ql/target/generated-sources/java added.
[INFO] 
[INFO] --- antlr3-maven-plugin:3.4:antlr (default) @ hive-exec ---
[INFO] ANTLR: Processing source directory /data/hive-ptest/working/apache-github-source-source/ql/src/java
ANTLR Parser Generator  Version 3.4
org/apache/hadoop/hive/ql/parse/HiveLexer.g
org/apache/hadoop/hive/ql/parse/HiveParser.g
warning(200): IdentifiersParser.g:455:5: 
Decision can match input such as "{KW_REGEXP, KW_RLIKE} KW_ORDER KW_BY" using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:455:5: 
Decision can match input such as "{KW_REGEXP, KW_RLIKE} KW_GROUP KW_BY" using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:455:5: 
Decision can match input such as "{KW_REGEXP, KW_RLIKE} KW_CLUSTER KW_BY" using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:455:5: 
Decision can match input such as "{KW_REGEXP, KW_RLIKE} KW_UNION KW_MAP" using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:455:5: 
Decision can match input such as "{KW_REGEXP, KW_RLIKE} KW_UNION KW_SELECT" using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:455:5: 
Decision can match input such as "{KW_REGEXP, KW_RLIKE} KW_MAP LPAREN" using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:455:5: 
Decision can match input such as "{KW_REGEXP, KW_RLIKE} KW_UNION KW_REDUCE" using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:455:5: 
Decision can match input such as "{KW_REGEXP, KW_RLIKE} KW_LATERAL KW_VIEW" using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:455:5: 
Decision can match input such as "{KW_REGEXP, KW_RLIKE} KW_SORT KW_BY" using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:455:5: 
Decision can match input such as "{KW_REGEXP, KW_RLIKE} KW_INSERT KW_INTO" using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:455:5: 
Decision can match input such as "{KW_REGEXP, KW_RLIKE} KW_UNION KW_ALL" using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:455:5: 
Decision can match input such as "{KW_REGEXP, KW_RLIKE} KW_UNION KW_FROM" using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:455:5: 
Decision can match input such as "{KW_REGEXP, KW_RLIKE} KW_INSERT KW_OVERWRITE" using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:455:5: 
Decision can match input such as "{KW_REGEXP, KW_RLIKE} KW_DISTRIBUTE KW_BY" using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hive-exec ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hive-exec ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 2 resources
[INFO] Copying 3 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-exec ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:2.3.2:compile (default-compile) @ hive-exec ---
[INFO] Compiling 2389 source files to /data/hive-ptest/working/apache-github-source-source/ql/target/classes
[INFO] -------------------------------------------------------------
[ERROR] COMPILATION ERROR : 
[INFO] -------------------------------------------------------------
[ERROR] /data/hive-ptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/HashTableLoader.java:[129,41] error: cannot find symbol
[ERROR]  class HashTableLoader
/data/hive-ptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/HashTableLoader.java:[132,23] error: cannot find symbol
[ERROR]  class HashTableLoader
/data/hive-ptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/HashTableLoader.java:[135,10] error: cannot find symbol
[ERROR]  class HashTableLoader
/data/hive-ptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/HivePairFlatMapFunction.java:[51,6] error: cannot find symbol
[INFO] 4 errors 
[INFO] -------------------------------------------------------------
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Summary:
[INFO] 
[INFO] Hive .............................................. SUCCESS [12.991s]
[INFO] Hive Shims Common ................................. SUCCESS [10.425s]
[INFO] Hive Shims 0.20S .................................. SUCCESS [3.169s]
[INFO] Hive Shims 0.23 ................................... SUCCESS [10.389s]
[INFO] Hive Shims Scheduler .............................. SUCCESS [2.078s]
[INFO] Hive Shims ........................................ SUCCESS [2.726s]
[INFO] Hive Common ....................................... SUCCESS [11.788s]
[INFO] Hive Serde ........................................ SUCCESS [16.435s]
[INFO] Hive Metastore .................................... SUCCESS [35.436s]
[INFO] Hive Ant Utilities ................................ SUCCESS [2.078s]
[INFO] Spark Remote Client ............................... SUCCESS [21.172s]
[INFO] Hive Query Language ............................... FAILURE [1:48.458s]
[INFO] Hive Service ...................................... SKIPPED
[INFO] Hive Accumulo Handler ............................. SKIPPED
[INFO] Hive JDBC ......................................... SKIPPED
[INFO] Hive Beeline ...................................... SKIPPED
[INFO] Hive CLI .......................................... SKIPPED
[INFO] Hive Contrib ...................................... SKIPPED
[INFO] Hive HBase Handler ................................ SKIPPED
[INFO] Hive HCatalog ..................................... SKIPPED
[INFO] Hive HCatalog Core ................................ SKIPPED
[INFO] Hive HCatalog Pig Adapter ......................... SKIPPED
[INFO] Hive HCatalog Server Extensions ................... SKIPPED
[INFO] Hive HCatalog Webhcat Java Client ................. SKIPPED
[INFO] Hive HCatalog Webhcat ............................. SKIPPED
[INFO] Hive HCatalog Streaming ........................... SKIPPED
[INFO] Hive HWI .......................................... SKIPPED
[INFO] Hive ODBC ......................................... SKIPPED
[INFO] Hive Shims Aggregator ............................. SKIPPED
[INFO] Hive TestUtils .................................... SKIPPED
[INFO] Hive Packaging .................................... SKIPPED
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 3:59.745s
[INFO] Finished at: Mon Jun 01 18:15:07 EDT 2015
[INFO] Final Memory: 109M/630M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:2.3.2:compile (default-compile) on project hive-exec: Compilation failure: Compilation failure:
[ERROR] /data/hive-ptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/HashTableLoader.java:[129,41] error: cannot find symbol
[ERROR] class HashTableLoader
[ERROR] /data/hive-ptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/HashTableLoader.java:[132,23] error: cannot find symbol
[ERROR] class HashTableLoader
[ERROR] /data/hive-ptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/HashTableLoader.java:[135,10] error: cannot find symbol
[ERROR] class HashTableLoader
[ERROR] /data/hive-ptest/working/apache-github-source-source/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/HivePairFlatMapFunction.java:[51,6] error: cannot find symbol
[ERROR] -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn <goals> -rf :hive-exec
+ exit 1
'
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12736655 - PreCommit-HIVE-TRUNK-Build, same exact patch, HiveQA failed for unrelated reasons, 

{color:red}Overall{color}: -1 no tests executed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12736678/HIVE-10884.01.patch

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/4134/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/4134/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-4134/

Messages:
{noformat}
**** This message was trimmed, see log for full details ****
[INFO] Installing /data/hive-ptest/working/apache-github-source-source/itests/hcatalog-unit/target/hive-hcatalog-it-unit-1.3.0-SNAPSHOT-tests.jar to /home/hiveptest/.m2/repository/org/apache/hive/hive-hcatalog-it-unit/1.3.0-SNAPSHOT/hive-hcatalog-it-unit-1.3.0-SNAPSHOT-tests.jar
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Integration - Testing Utilities 1.3.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-it-util ---
[INFO] Deleting /data/hive-ptest/working/apache-github-source-source/itests/util/target
[INFO] Deleting /data/hive-ptest/working/apache-github-source-source/itests/util (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-enforcer-plugin:1.3.1:enforce (enforce-no-snapshots) @ hive-it-util ---
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (download-spark) @ hive-it-util ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hive-it-util ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hive-it-util ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-github-source-source/itests/util/src/main/resources
[INFO] Copying 3 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-it-util ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-it-util ---
[INFO] Compiling 50 source files to /data/hive-ptest/working/apache-github-source-source/itests/util/target/classes
[WARNING] /data/hive-ptest/working/apache-github-source-source/itests/util/src/main/java/org/apache/hadoop/hive/ql/QTestUtil.java: Some input files use or override a deprecated API.
[WARNING] /data/hive-ptest/working/apache-github-source-source/itests/util/src/main/java/org/apache/hadoop/hive/ql/QTestUtil.java: Recompile with -Xlint:deprecation for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hive-it-util ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-github-source-source/itests/util/src/test/resources
[INFO] Copying 3 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-it-util ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/itests/util/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/itests/util/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/itests/util/target/tmp/conf
     [copy] Copying 11 files to /data/hive-ptest/working/apache-github-source-source/itests/util/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-it-util ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-it-util ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-it-util ---
[INFO] Building jar: /data/hive-ptest/working/apache-github-source-source/itests/util/target/hive-it-util-1.3.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-site-plugin:3.3:attach-descriptor (attach-descriptor) @ hive-it-util ---
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-it-util ---
[INFO] Installing /data/hive-ptest/working/apache-github-source-source/itests/util/target/hive-it-util-1.3.0-SNAPSHOT.jar to /home/hiveptest/.m2/repository/org/apache/hive/hive-it-util/1.3.0-SNAPSHOT/hive-it-util-1.3.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-github-source-source/itests/util/pom.xml to /home/hiveptest/.m2/repository/org/apache/hive/hive-it-util/1.3.0-SNAPSHOT/hive-it-util-1.3.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Integration - Unit Tests 1.3.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-it-unit ---
[INFO] Deleting /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/target
[INFO] Deleting /data/hive-ptest/working/apache-github-source-source/itests/hive-unit (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-enforcer-plugin:1.3.1:enforce (enforce-no-snapshots) @ hive-it-unit ---
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (download-spark) @ hive-it-unit ---
[INFO] Executing tasks

main:
     [exec] + /bin/pwd
     [exec] /data/hive-ptest/working/apache-github-source-source/itests/hive-unit
     [exec] + BASE_DIR=./target
     [exec] + HIVE_ROOT=./target/../../../
     [exec] + DOWNLOAD_DIR=./../thirdparty
     [exec] + mkdir -p ./../thirdparty
     [exec] + download http://d3jw87u4immizc.cloudfront.net/spark-tarball/spark-1.3.1-bin-hadoop2-without-hive.tgz spark
     [exec] + url=http://d3jw87u4immizc.cloudfront.net/spark-tarball/spark-1.3.1-bin-hadoop2-without-hive.tgz
     [exec] + finalName=spark
     [exec] ++ basename http://d3jw87u4immizc.cloudfront.net/spark-tarball/spark-1.3.1-bin-hadoop2-without-hive.tgz
     [exec] + tarName=spark-1.3.1-bin-hadoop2-without-hive.tgz
     [exec] + rm -rf ./target/spark
     [exec] + [[ ! -f ./../thirdparty/spark-1.3.1-bin-hadoop2-without-hive.tgz ]]
     [exec] + tar -zxf ./../thirdparty/spark-1.3.1-bin-hadoop2-without-hive.tgz -C ./target
     [exec] + mv ./target/spark-1.3.1-bin-hadoop2-without-hive ./target/spark
     [exec] + cp -f ./target/../../..//data/conf/spark/log4j.properties ./target/spark/conf/
     [exec] + sed '/package /d' /data/hive-ptest/working/apache-github-source-source/itests/../contrib/src/java/org/apache/hadoop/hive/contrib/udf/example/UDFExampleAdd.java
     [exec] + javac -cp /home/hiveptest/.m2/repository/org/apache/hive/hive-exec/1.3.0-SNAPSHOT/hive-exec-1.3.0-SNAPSHOT.jar /tmp/UDFExampleAdd.java -d /tmp
     [exec] + jar -cf /tmp/udfexampleadd-1.0.jar -C /tmp UDFExampleAdd.class
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hive-it-unit ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hive-it-unit ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/src/main/resources
[INFO] Copying 3 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-it-unit ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-it-unit ---
[INFO] Compiling 2 source files to /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/target/classes
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hive-it-unit ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/src/test/resources
[INFO] Copying 3 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-it-unit ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/target/tmp/conf
     [copy] Copying 11 files to /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-metastore-scripts) @ hive-it-unit ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/target/tmp/scripts/metastore
     [copy] Copying 219 files to /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/target/tmp/scripts/metastore
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-it-unit ---
[INFO] Compiling 84 source files to /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/target/test-classes
[INFO] -------------------------------------------------------------
[WARNING] COMPILATION WARNING : 
[INFO] -------------------------------------------------------------
[WARNING] /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestRetryingHMSHandler.java: Some input files use or override a deprecated API.
[WARNING] /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestRetryingHMSHandler.java: Recompile with -Xlint:deprecation for details.
[WARNING] /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/security/authorization/plugin/TestHiveAuthorizerShowFilters.java: Some input files use unchecked or unsafe operations.
[WARNING] /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/security/authorization/plugin/TestHiveAuthorizerShowFilters.java: Recompile with -Xlint:unchecked for details.
[INFO] 4 warnings 
[INFO] -------------------------------------------------------------
[INFO] -------------------------------------------------------------
[ERROR] COMPILATION ERROR : 
[INFO] -------------------------------------------------------------
[ERROR] /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/security/authorization/plugin/TestHiveAuthorizerShowFilters.java:[30,30] cannot find symbol
  symbol:   class UtilsForTest
  location: package org.apache.hadoop.hive
[ERROR] /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/security/authorization/plugin/TestHiveAuthorizerShowFilters.java:[123,5] cannot find symbol
  symbol:   variable UtilsForTest
  location: class org.apache.hadoop.hive.ql.security.authorization.plugin.TestHiveAuthorizerShowFilters
[INFO] 2 errors 
[INFO] -------------------------------------------------------------
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Summary:
[INFO] 
[INFO] Hive Integration - Parent ......................... SUCCESS [8.864s]
[INFO] Hive Integration - Custom Serde ................... SUCCESS [16.395s]
[INFO] Hive Integration - HCatalog Unit Tests ............ SUCCESS [12.395s]
[INFO] Hive Integration - Testing Utilities .............. SUCCESS [16.768s]
[INFO] Hive Integration - Unit Tests ..................... FAILURE [19.683s]
[INFO] Hive Integration - Test Serde ..................... SKIPPED
[INFO] Hive Integration - QFile Tests .................... SKIPPED
[INFO] JMH benchmark: Hive ............................... SKIPPED
[INFO] Hive Integration - QFile Spark Tests .............. SKIPPED
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 1:16.533s
[INFO] Finished at: Mon Jun 01 19:44:18 EDT 2015
[INFO] Final Memory: 76M/181M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.1:testCompile (default-testCompile) on project hive-it-unit: Compilation failure: Compilation failure:
[ERROR] /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/security/authorization/plugin/TestHiveAuthorizerShowFilters.java:[30,30] cannot find symbol
[ERROR] symbol:   class UtilsForTest
[ERROR] location: package org.apache.hadoop.hive
[ERROR] /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/security/authorization/plugin/TestHiveAuthorizerShowFilters.java:[123,5] cannot find symbol
[ERROR] symbol:   variable UtilsForTest
[ERROR] location: class org.apache.hadoop.hive.ql.security.authorization.plugin.TestHiveAuthorizerShowFilters
[ERROR] -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn <goals> -rf :hive-it-unit
+ exit 1
'
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12736678 - PreCommit-HIVE-TRUNK-Build, build was broken again... rince, repeat, 

{color:red}Overall{color}: -1 at least one tests failed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12736696/HIVE-10884.02.patch

{color:red}ERROR:{color} -1 due to 2 failed/errored test(s), 8996 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_ql_rewrite_gbtoidx_cbo_2
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_Json
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/4137/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/4137/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-4137/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 2 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12736696 - PreCommit-HIVE-TRUNK-Build, Same patch again. I lost track of this, but it looks like the last time tests didn't fail... let's get the logs to see if they pass (and thus only fail on my machine) or never run on HiveQA , 

{color:red}Overall{color}: -1 no tests executed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12739302/HIVE-10884.03.patch

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/4257/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/4257/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-4257/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Tests exited with: NonZeroExitCodeException
Command 'bash /data/hive-ptest/working/scratch/source-prep.sh' failed with exit status 1 and output '+ [[ -n /usr/java/jdk1.7.0_45-cloudera ]]
+ export JAVA_HOME=/usr/java/jdk1.7.0_45-cloudera
+ JAVA_HOME=/usr/java/jdk1.7.0_45-cloudera
+ export PATH=/usr/java/jdk1.7.0_45-cloudera/bin/:/usr/local/apache-maven-3.0.5/bin:/usr/java/jdk1.7.0_45-cloudera/bin:/usr/local/apache-ant-1.9.1/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/hiveptest/bin
+ PATH=/usr/java/jdk1.7.0_45-cloudera/bin/:/usr/local/apache-maven-3.0.5/bin:/usr/java/jdk1.7.0_45-cloudera/bin:/usr/local/apache-ant-1.9.1/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/hiveptest/bin
+ export 'ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m '
+ ANT_OPTS='-Xmx1g -XX:MaxPermSize=256m '
+ export 'M2_OPTS=-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128'
+ M2_OPTS='-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128'
+ cd /data/hive-ptest/working/
+ tee /data/hive-ptest/logs/PreCommit-HIVE-TRUNK-Build-4257/source-prep.txt
+ [[ false == \t\r\u\e ]]
+ mkdir -p maven ivy
+ [[ git = \s\v\n ]]
+ [[ git = \g\i\t ]]
+ [[ -z master ]]
+ [[ -d apache-github-source-source ]]
+ [[ ! -d apache-github-source-source/.git ]]
+ [[ ! -d apache-github-source-source ]]
+ cd apache-github-source-source
+ git fetch origin
+ git reset --hard HEAD
HEAD is now at e236314 HIVE-10977: No need to instantiate MetaStoreDirectSql when HMS DirectSql is disabled (Chaoyu Tang, reviewed by Xuefu Zhang and Sergey Shelukhin)
+ git clean -f -d
+ git checkout master
Already on 'master'
+ git reset --hard origin/master
HEAD is now at e236314 HIVE-10977: No need to instantiate MetaStoreDirectSql when HMS DirectSql is disabled (Chaoyu Tang, reviewed by Xuefu Zhang and Sergey Shelukhin)
+ git merge --ff-only origin/master
Already up-to-date.
+ git gc
+ patchCommandPath=/data/hive-ptest/working/scratch/smart-apply-patch.sh
+ patchFilePath=/data/hive-ptest/working/scratch/build.patch
+ [[ -f /data/hive-ptest/working/scratch/build.patch ]]
+ chmod +x /data/hive-ptest/working/scratch/smart-apply-patch.sh
+ /data/hive-ptest/working/scratch/smart-apply-patch.sh /data/hive-ptest/working/scratch/build.patch
The patch does not appear to apply with p0, p1, or p2
+ exit 1
'
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12739302 - PreCommit-HIVE-TRUNK-Build, The rebased patch, 

{color:red}Overall{color}: -1 at least one tests failed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12739364/HIVE-10884.04.patch

{color:red}ERROR:{color} -1 due to 3 failed/errored test(s), 9008 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join28
org.apache.hive.beeline.TestSchemaTool.testSchemaInit
org.apache.hive.beeline.TestSchemaTool.testSchemaUpgrade
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/4262/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/4262/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-4262/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 3 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12739364 - PreCommit-HIVE-TRUNK-Build, Beeline tests weren't attempted. Attempting to remove the exclude from hivetest..., After some more changes that I will post shortly just for kicks, it passes one test and then gets stuck on a linux box (cannot make it work on Mac, screw Mac).
The only errors I can see are {noformat}
2015-07-10 13:42:45,170 ERROR [ProcessThread(sid:0 cport:-1):]: server.NIOServerCnxnFactory (NIOServerCnxnFactory.java:uncaughtException(44)) - Thread Thread[ProcessThread(sid:0 cport:-1):,5,main] died
java.lang.NoClassDefFoundError: org/apache/zookeeper/txn/ErrorTxn
        at org.apache.zookeeper.server.PrepRequestProcessor.pRequest(PrepRequestProcessor.java:643)
        at org.apache.zookeeper.server.PrepRequestProcessor.run(PrepRequestProcessor.java:131)
Caused by: java.lang.ClassNotFoundException: org.apache.zookeeper.txn.ErrorTxn
        at java.net.URLClassLoader$1.run(URLClassLoader.java:366)
        at java.net.URLClassLoader$1.run(URLClassLoader.java:355)
        at java.security.AccessController.doPrivileged(Native Method)
        at java.net.URLClassLoader.findClass(URLClassLoader.java:354)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:425)
        at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:358)
        ... 2 more
{noformat}
, I've ran a few tests one by one. Let's see if the stuck-test problem is only on my machine, or also on HiveQA, 

{color:green}Overall{color}: +1 all checks pass

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12744848/HIVE-10884.06.patch

{color:green}SUCCESS:{color} +1 9150 tests passed

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/4590/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/4590/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-4590/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12744848 - PreCommit-HIVE-TRUNK-Build, Found another place where tests can be excluded... sigh, 

{color:green}Overall{color}: +1 all checks pass

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12745096/HIVE-10884.07.patch

{color:green}SUCCESS:{color} +1 9189 tests passed

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/4599/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/4599/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-4599/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12745096 - PreCommit-HIVE-TRUNK-Build, [~spena] do I need to do anything else for test changes to apply? Note that I removed beeline from excludes, and fixed the spelling "Exlcuding" in 07 patch; but HiveQA still excludes the test and still has the broken spelling in console logs

{noformat}
2015-07-13 15:35:50,858 DEBUG TestParser.parseTests:93 In  /data/hive-ptest/working/apache-github-source-source/., found TestBeeLineDriver.class
2015-07-13 15:35:50,858  INFO TestParser.parseTests:97 Exlcuding unit test TestBeeLineDriver
{noformat}, I found that the trunk-mr2.properties file on the ptest environment has this line:

# comes from build-command.xml excludes
unitTests.exclude = TestSerDe TestHiveMetaStore TestBeeLineDriver TestHiveServer2Concurrency TestAccumuloCliDriver

I don't know why it is excluding such test. Do you want me to remove the TestBeeLineDriver from exclusion? 
[~brocknoland] [~szehon] Do you know why this test is excluded from the ptest environment?, Most of those were copied from the old build system. Even I don't know why they were there.

However, I believe {{TestBeeLineDriver}} is there because it ran all tests twice. Once on HiveCLI and once in beeline. If we enable this tests I would suggest we just do it for one q-file test until we resolve all the issues with it., I have changed the config for beeline test (in the attached patch) to run about 10-15 queries.
However, I am not able to run them on HiveQA due to this...
, [~sershe] I removed the TestBeeLineDriver test from the excluded tests.
I re-submitted the patch to run the tests again., 

{color:red}Overall{color}: -1 at least one tests failed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12745618/HIVE-10884.07.patch

{color:red}ERROR:{color} -1 due to 2 failed/errored test(s), 9220 tests executed
*Failed tests:*
{noformat}
TestBeeLineDriver - did not produce a TEST-*.xml file
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_cbo_rp_join0
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/4628/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/4628/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-4628/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 2 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12745618 - PreCommit-HIVE-TRUNK-Build, Looks like it timed out without any output saved...
{noformat}
2015-07-16 10:21:04,139  INFO HostExecutor.executeTests:176 Starting isolated execution on 54.80.208.185
2015-07-16 11:57:56,933  INFO LocalCommand.<init>:35 Starting timeout 1h rsync -vaPe "ssh -i /home/hiveptest/.ssh/hive-ptest-user-key" --timeout 600 hiveptest@107.22.49.60:/home/hiveptest/107.22.49.60-hiveptest-2/logs/ /data/hive-ptest/logs/PreCommit-HIVE-TRUNK-Build-4628/failed/TestBeeLineDriver
20
{noformat}
Would the above directory be preserved somewhere?, Does this issue happen only with the attached patch? Or it happened because I enabled the TestBeeLineDriver tests?
The directory is preserved in the jenkins slaves, but those slaves expired after a while, and then destroyed; so we don't have access to those logs anymore., Looks like the state is that the tests get stuck on HiveQA. On a Linux box here, I can run any tests as long as I run them one at a time, otherwise after the first test it gets stuck. The same thing might be happening on HiveQA.
On an unrelated note, in light of HIVE-11778 I wonder if we should move all tests to beeline driver now?
Feel free to assign to yourself if you want to take this over. I won't be able to resume working on this anytime soon. ]