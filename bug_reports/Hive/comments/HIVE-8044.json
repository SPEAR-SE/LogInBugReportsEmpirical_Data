[[~prasanth_j], [~mmokhtar]/[~rhbutani] is this same as HIVE-7156 but for CBO?, [~prasanth_j]
Yup, looks similar.
Would be great to extend the patch to cover Map joins as well, Looks like the sizing of inputs is correct but we don't correctly account of the Hash Table size.

More info from the logs.
{code}
2014-09-25 15:28:13,651 INFO [TezChild] org.apache.tez.runtime.task.TezTaskRunner: Encounted an error while executing task: attempt_1406566393272_6236_1_26_000000_0
java.lang.RuntimeException: java.lang.OutOfMemoryError: Java heap space
        at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:163)
        at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:142)
        at org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:324)
        at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:180)
        at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:172)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:415)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)
        at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.call(TezTaskRunner.java:172)
        at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.call(TezTaskRunner.java:167)
        at java.util.concurrent.FutureTask.run(FutureTask.java:262)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        at java.lang.Thread.run(Thread.java:744)
Caused by: java.lang.OutOfMemoryError: Java heap space
        at org.apache.hadoop.hive.serde2.WriteBuffers.nextBufferToWrite(WriteBuffers.java:206)
        at org.apache.hadoop.hive.serde2.WriteBuffers.write(WriteBuffers.java:182)
        at org.apache.hadoop.hive.ql.exec.persistence.MapJoinBytesTableContainer$LazyBinaryKvWriter.writeValue(MapJoinBytesTableContainer.java:227)
        at org.apache.hadoop.hive.ql.exec.persistence.BytesBytesMultiHashMap.writeValueAndLength(BytesBytesMultiHashMap.java:584)
        at org.apache.hadoop.hive.ql.exec.persistence.BytesBytesMultiHashMap.put(BytesBytesMultiHashMap.java:218)
        at org.apache.hadoop.hive.ql.exec.persistence.MapJoinBytesTableContainer.putRow(MapJoinBytesTableContainer.java:267)
        at org.apache.hadoop.hive.ql.exec.tez.HashTableLoader.load(HashTableLoader.java:114)
        at org.apache.hadoop.hive.ql.exec.MapJoinOperator.loadHashTable(MapJoinOperator.java:185)
        at org.apache.hadoop.hive.ql.exec.MapJoinOperator.cleanUpInputFileChangedOp(MapJoinOperator.java:211)
        at org.apache.hadoop.hive.ql.exec.Operator.cleanUpInputFileChanged(Operator.java:1038)
        at org.apache.hadoop.hive.ql.exec.Operator.cleanUpInputFileChanged(Operator.java:1042)
        at org.apache.hadoop.hive.ql.exec.Operator.cleanUpInputFileChanged(Operator.java:1042)
        at org.apache.hadoop.hive.ql.exec.Operator.cleanUpInputFileChanged(Operator.java:1042)
        at org.apache.hadoop.hive.ql.exec.Operator.cleanUpInputFileChanged(Operator.java:1042)
        at org.apache.hadoop.hive.ql.exec.vector.VectorMapOperator.process(VectorMapOperator.java:37)
        at org.apache.hadoop.hive.ql.exec.tez.MapRecordSource.processRow(MapRecordSource.java:85)
        at org.apache.hadoop.hive.ql.exec.tez.MapRecordSource.pushRecord(MapRecordSource.java:70)
        at org.apache.hadoop.hive.ql.exec.tez.MapRecordProcessor.run(MapRecordProcessor.java:272)
        at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:154)
        ... 13 more
2014-09-25 15:28:14,087 INFO [TezChild] org.apache.tez.runtime.LogicalIOProcessorRuntimeTask: Final Counters : Counters: 44 [[File System Counters FILE: BYTES_READ=3215828284, FILE: BYTES_WRITTEN=4305364425, FILE: READ_OPS=0, FILE: LARGE_READ_OPS=0, FILE: WRITE_OPS=0, HDFS: BYTES_READ=72662, HDFS: BYTES_WRITTEN=0, HDFS: READ_OPS=6, HDFS: LARGE_READ_OPS=0, HDFS: WRITE_OPS=0][org.apache.tez.common.counters.TaskCounter GC_TIME_MILLIS=8032, CPU_MILLISECONDS=233170, PHYSICAL_MEMORY_BYTES=2215120896, VIRTUAL_MEMORY_BYTES=4919201792, COMMITTED_HEAP_BYTES=3837263872][TaskCounter_Map_16_INPUT_Map_2 INPUT_RECORDS_PROCESSED=0, NUM_FAILED_SHUFFLE_INPUTS=0, NUM_SHUFFLED_INPUTS=1, SHUFFLE_BYTES=4208, SHUFFLE_BYTES_DECOMPRESSED=4204, SHUFFLE_BYTES_DISK_DIRECT=0, SHUFFLE_BYTES_TO_DISK=0, SHUFFLE_BYTES_TO_MEM=4208][TaskCounter_Map_16_INPUT_Map_23 INPUT_RECORDS_PROCESSED=0, NUM_FAILED_SHUFFLE_INPUTS=0, NUM_SHUFFLED_INPUTS=1, SHUFFLE_BYTES=2938, SHUFFLE_BYTES_DECOMPRESSED=2934, SHUFFLE_BYTES_DISK_DIRECT=0, SHUFFLE_BYTES_TO_DISK=0, SHUFFLE_BYTES_TO_MEM=2938][TaskCounter_Map_16_INPUT_Map_6 INPUT_RECORDS_PROCESSED=82959225, NUM_FAILED_SHUFFLE_INPUTS=0, NUM_SHUFFLED_INPUTS=101, SHUFFLE_BYTES=5064327526, SHUFFLE_BYTES_DECOMPRESSED=5064327122, SHUFFLE_BYTES_DISK_DIRECT=0, SHUFFLE_BYTES_TO_DISK=4271988665, SHUFFLE_BYTES_TO_MEM=792338861][TaskCounter_Map_16_INPUT_cd1 INPUT_RECORDS_PROCESSED=1][TaskCounter_Map_16_OUTPUT_Map_35 OUTPUT_BYTES=0, OUTPUT_BYTES_PHYSICAL=0, OUTPUT_BYTES_WITH_OVERHEAD=0, OUTPUT_RECORDS=0]]
{code}, Trimmed log file, I looked at getMapJoinConversionPos and it doesn't seem to take into account the overhead from the hash table., This work's as expected. The size of hashtable will not be taken into account during data size computation. We can either account that in datasize or increase the size in the config (noconditional task size). It better to do the later than to add more complication to the data size estimation. , This has been fixed in 0.14 release. Please open new jira if you see any issues.
]