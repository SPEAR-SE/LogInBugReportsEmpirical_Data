[I am using CDH 5.4.3-Hive 1.1.0 version and not sure if this issue is relative to "set hive.exec.parallel=True;", I am using cdh5.3.2-hive-0.13.1version set hive.exec.parallel=True; But still error, I am using 
cat /opt/cloudera/parcels/CDH/lib/hive/cloudera/cdh_version.properties
# Autogenerated build properties
version=1.1.0-cdh5.11.1
git.hash=3a539bca442da39111270cab403f4a3b46a94e86
cloudera.hash=3a539bca442da39111270cab403f4a3b46a94e86
cloudera.cdh.hash=fe410de082ff998791b4db61fc6605a6c391ce8d
cloudera.cdh-packaging.hash=84bf4c840e5668e16598875236c2067206b58535
cloudera.base-branch=cdh5-base-1.1.0
cloudera.build-branch=cdh5-1.1.0_5.11.1
cloudera.pkg.version=1.1.0+cdh5.11.1+1041
cloudera.pkg.release=1.cdh5.11.1.p0.6
cloudera.pkg.name=hive
cloudera.cdh.release=cdh5.11.1
cloudera.build.time=2017.06.01-16:56:18GMT

Issue is sporadic, restarting the HS does not seem to help, so it does not appear to be a resource issue., Not sure if this helps, but my issue was not related to Kryo or any other serialization method.
I tried
set hive.plan.serialization.format=javaXML;
which ended up throwing a different MR error.

What ended resolving the issue for me was setting hive.exec.input.listing.max.threads to 1.
Which essentially prevents a thread pool from being used preventing the thread leak.
See HIVE-16949 for more information.

If you notice a huge amount of JVM threads being used by your HiveServer, the above workaround may work for you or you can apply the patch.

Hope this helps
]