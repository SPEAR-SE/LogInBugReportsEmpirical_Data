[The schema tool also fails to update PART_NAME in table PARTITIONS. Without this Hive will enter an infinite loop when a user attempts to drop the table.

I would include the following Update statement in addition to handling none date type entries such as __HIVE_DEFAULT_PARTITION__

UPDATE PARTITIONS JOIN PARTITION_KEYS ON PARTITIONS.TBL_ID= PARTITION_KEYS.TBL_ID  
SET PART_NAME=ifnull(REPLACE(PART_NAME,RIGHT(PART_NAME,8),cast(RIGHT(PART_NAME,8) as date)),PART_NAME)
WHERE PKEY_TYPE= 'date' and 
PART_NAME not like '%-%-%';


Ref:http://github.mtv.cloudera.com/CDH/hive/blob/cdh5-0.13.1_5.2.0/metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java#1504

LINE 1480:
 private List<Path> dropPartitionsAndGetLocations(RawStore ms, String dbName,
      String tableName, Path tablePath, List<FieldSchema> partitionKeys, boolean checkLocation)
      throws MetaException, IOException, NoSuchObjectException, InvalidObjectException,
      InvalidInputException {
      int partitionBatchSize = HiveConf.getIntVar(hiveConf,
          ConfVars.METASTORE_BATCH_RETRIEVE_MAX);
      Path tableDnsPath = null;
      if (tablePath != null) {
        tableDnsPath = wh.getDnsPath(tablePath);
      }
      List<Path> partPaths = new ArrayList<Path>();
      Table tbl = ms.getTable(dbName, tableName);

      // call dropPartition on each of the table's partitions to follow the
      // procedure for cleanly dropping partitions.
      while (true) {
        List<Partition> partsToDelete = ms.getPartitions(dbName, tableName, partitionBatchSize);
        if (partsToDelete == null || partsToDelete.isEmpty()) {
          break;
        }
        List<String> partNames = new ArrayList<String>();
        for (Partition part : partsToDelete) {
          if (checkLocation && part.getSd() != null &&
              part.getSd().getLocation() != null) {

            Path partPath = wh.getDnsPath(new Path(part.getSd().getLocation()));
            if (tableDnsPath == null ||
                (partPath != null && !isSubdirectory(tableDnsPath, partPath))) {
              if (!wh.isWritable(partPath.getParent())) {
                throw new MetaException("Table metadata not deleted since the partition " +
                    Warehouse.makePartName(partitionKeys, part.getValues()) +
                    " has parent location " + partPath.getParent() + " which is not writable " +
                    "by " + hiveConf.getUser());
              }
              partPaths.add(partPath);
            }
          }
          partNames.add(Warehouse.makePartName(tbl.getPartitionKeys(), part.getValues()));
        }
        ms.dropPartitions(dbName, tableName, partNames);
      }
      return partPaths;
    }, We are going to reverting HIVE-5700 in HIVE-9445.]