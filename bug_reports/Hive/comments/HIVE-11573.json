[

{color:red}Overall{color}: -1 at least one tests failed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12751242/HIVE-11573.2.patch

{color:red}ERROR:{color} -1 due to 11 failed/errored test(s), 9370 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_alter_partition_coltype
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_annotate_stats_filter
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_flatten_and_or
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_pcr
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_ppd_transform
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_vectorized_case
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_explainuser_1
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_vectorized_case
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_pcr
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_ppd_transform
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vectorized_case
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5010/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5010/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-5010/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 11 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12751242 - PreCommit-HIVE-TRUNK-Build, Add test case testing the sub-expr extract & min restriction.

Fixed golden files., +1 pending QA run., 

{color:red}Overall{color}: -1 at least one tests failed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12751653/HIVE-11573.3.patch

{color:red}ERROR:{color} -1 due to 1 failed/errored test(s), 9372 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_pointlookup
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5032/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5032/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-5032/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 1 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12751653 - PreCommit-HIVE-TRUNK-Build, Fix the hashset traversal order and update qfiles., 

{color:green}Overall{color}: +1 all checks pass

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12751821/HIVE-11573.4.patch

{color:green}SUCCESS:{color} +1 9377 tests passed

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5041/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5041/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-5041/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12751821 - PreCommit-HIVE-TRUNK-Build, [~gopalv], I added a new test in HIVE-11573.5.patch to verify that partition pruning is working fine.

I have a comment about the patch. I think we should not store the original predicate in the Filter operator if {{hive.optimize.point.lookup.extract}} is set to true (line 155 in PointLookupOptimizer). We added that line in HIVE-11461 so we do not get regressions with partition pruner, but with your patch, we shouldn't see that issue if extract is true. What do you think?

cc'd [~ashutoshc], 

{color:green}Overall{color}: +1 all checks pass

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12751994/HIVE-11573.5.patch

{color:green}SUCCESS:{color} +1 9379 tests passed

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5052/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5052/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-5052/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12751994 - PreCommit-HIVE-TRUNK-Build, I agree there is no good reason for storing original predicate in FilterDesc any more., Changed the original predicate insertion into an if(!extract), 

{color:red}Overall{color}: -1 at least one tests failed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12752557/HIVE-11573.6.patch

{color:red}ERROR:{color} -1 due to 1 failed/errored test(s), 9379 tests executed
*Failed tests:*
{noformat}
org.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5081/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5081/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-5081/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 1 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12752557 - PreCommit-HIVE-TRUNK-Build, Pushed to master, thanks [~gopalv]!, Doc note:  This adds two configuration parameters (*hive.optimize.point.lookup.min* and *hive.optimize.point.lookup.extract*) to HiveConf.java, so they need to be documented in Configuration Properties.

* [Configuration Properties -- Query and DDL Execution | https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties#ConfigurationProperties-QueryandDDLExecution], [~asears] documented *hive.optimize.point.lookup* in the wiki so I'm removing the TODOC2.0 label.  (*hive.optimize.point.lookup.extract* does not need to be documented because HIVE-11634 removed it.)  Thanks, Andrew.

* [Configuration Properties -- hive.optimize.point.lookup.min | https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties#ConfigurationProperties-hive.optimize.point.lookup.min], [~gopalv] I see that the goal here was to prevent the conversion of smaller (a=1 || a=2) to a IN (1,2) expressions
but right now I'm tempted to to set the min value to 2 or 3; because handling of INs have been improved ever since - I think the original reason behind this ticket might have been gone...and to make really use of CALCITE-2247 I've to enable decomposition of all INs to ORs as a preprocessing step - but I think it makes sens to convert them back to INs in PointLookupOptimizer - because it will make the stats estimation probably more sane...
Do you have any concers...or any recommendations to keep an eye for?, [~kgyrtkirk]: this was written to prevent algorithmic complexity of the expression walkers because (a = 1 || a = 2) is actually UDFOr(UDFOpEq(a, 1), UDFOpEq(a, 2)) while the other one is GenericUDFIn(a, [1,2]) which is faster to walk through.

The original bad case had 680 x (a = 1 and b = 2) or (a=1 and b=3) ... etc, which got generated as (a=1) and (b=(2,3,...)) and ((a,b) IN ((1,2),(2,3)...) so that the disjunction could be pushed down to the ORC PPD.]