[The root cause of the problem is that HCatalog fails to figure out that the jobContext of the PoS job indeed has backend context. (This then causes to program to proceed in unwanted code paths)

This feature was working previously by {{mapred.task.id}} property being set for Pig on MR/Tez jobs. In Spark mode this property is not used so I had to extend to condition used in {{checkJobContextIfRunningFromBackend()}} so it recognises PoS jobs as backend too.

[~xuefuz], [~kellyzly] can you take a look on this patch please?, Patch looks fine. However, I'm wondering if it would be better to set mapred.task.id in Pig on Spark, as Hive on Spark sets it already., 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12896846/HIVE-18030.0.patch

{color:red}ERROR:{color} -1 due to no test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 11 failed/errored test(s), 11359 tests executed
*Failed tests:*
{noformat}
TestMiniLlapCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=146)
	[intersect_all.q,unionDistinct_1.q,orc_ppd_schema_evol_3a.q,table_nonprintable.q,tez_union_dynamic_partition.q,tez_union_dynamic_partition_2.q,temp_table_external.q,global_limit.q,llap_udf.q,schemeAuthority.q,cte_2.q,rcfile_createas1.q,dynamic_partition_pruning_2.q,intersect_merge.q,parallel_colstats.q]
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[dbtxnmgr_showlocks] (batchId=77)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_values_orig_table_use_metadata] (batchId=62)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[llap_acid_fast] (batchId=157)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[sysdb] (batchId=156)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_2] (batchId=102)
org.apache.hadoop.hive.cli.TestNegativeMinimrCliDriver.testCliDriver[ct_noperm_loc] (batchId=94)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[subquery_multi] (batchId=111)
org.apache.hadoop.hive.cli.control.TestDanglingQOuts.checkDanglingQOut (batchId=206)
org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testConstraints (batchId=223)
org.apache.hive.hcatalog.pig.TestHCatLoaderComplexSchema.testTupleInBagInTupleInBag[3] (batchId=187)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/7740/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/7740/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-7740/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 11 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12896846 - PreCommit-HIVE-Build, [~szita]: my question is same as Xuefu, can we set {{mapred.task.id}} in pig to bypass the problem? If not ,can you tell me the reason, tks!, I would rather have this fixed in Hive, because:
* I think setting {{mapred.task.id}} in Pig just so that we let Hive's HCatalog know it's a backend job is a hacky workaround.
* We don't have any other usage of this property when using Pig on Spark
* Telling HCatalog explicitly to consider Pig on Spark jobs as backend seems like a much clearer approach to me, I see it as being less prone to unwanted surprises in the future., [~xuefuz] does this sound reasonable?, [~szita], as you noted,
{quote}
This feature was working previously by mapred.task.id property being set for Pig on MR/Tez jobs. In Spark mode this property is not used...
{quote}
I think setting {{mapred.task.id}} in Pig on Spark is a consistency as it's done for MR and Tez. Setting this property is not necessarily just for either Hive or Pig itself, but for downstream application as a bafkcompatibile measure., [~xuefuz] I see. I created PIG-5316 to track this on Pig side.]