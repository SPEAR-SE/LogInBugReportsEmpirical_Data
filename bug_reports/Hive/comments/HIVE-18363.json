[Wouldn't this depend on what {{fs.default.name}} is set to? With an unqualified path literal, HS2 might just be looking on HDFS, not local FS., fs.default.name/fs.defaultFS is set to hdfs://<ip>:8020, which means default fs is hdfs.

But continuation to above issue, even if I try command with file prefix it is not working.
Command: add jar file:///home/anuradha/shareinsights/udfs/hivexmlserde-1.0.5.3.jar;

Log trace on hiveserver2:

2018-01-04 11:06:00,881 INFO  [HiveServer2-Handler-Pool: Thread-36]: session.HiveSessionImpl (HiveSessionImpl.java:acquire(304)) - We are setting the hadoop caller context to 5b895579-78f7-4057-b289-b4e4e7dbd16b for thread HiveServer2-Handler-Pool: Thread-36
2018-01-04 11:06:00,881 INFO  [HiveServer2-Handler-Pool: Thread-36]: operation.Operation (HiveCommandOperation.java:setupSessionIO(69)) - Putting temp output to file /tmp/hive/5b895579-78f7-4057-b289-b4e4e7dbd16b5283435069997218995.pipeout
2018-01-04 11:06:00,882 DEBUG [HiveServer2-Handler-Pool: Thread-36]: parse.VariableSubstitution (VariableSubstitution.java:substitute(53)) - Substitution is on: jar file:///home/anuradha/shareinsights/udfs/hivexmlserde-1.0.5.3.jar
2018-01-04 11:06:00,882 INFO  [HiveServer2-Handler-Pool: Thread-36]: sqlstd.SQLStdHiveAccessController (SQLStdHiveAccessController.java:<init>(95)) - Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=5b895579-78f7-4057-b289-b4e4e7dbd16b, clientType=HIVESERVER2]
2018-01-04 11:06:00,882 DEBUG [HiveServer2-Handler-Pool: Thread-36]: session.SessionState (SessionState.java:setupAuth(721)) - Session is using authorization class class org.apache.hadoop.hive.ql.security.authorization.plugin.HiveAuthorizerImpl
2018-01-04 11:06:00,883 ERROR [HiveServer2-Handler-Pool: Thread-36]: SessionState (SessionState.java:printError(932)) - file:///home/anuradha/shareinsights/udfs/hivexmlserde-1.0.5.3.jar does not exist
java.lang.IllegalArgumentException: file:///home/anuradha/shareinsights/udfs/hivexmlserde-1.0.5.3.jar does not exist
	at org.apache.hadoop.hive.ql.session.SessionState.validateFiles(SessionState.java:970)
	at org.apache.hadoop.hive.ql.session.SessionState$ResourceType.preHook(SessionState.java:1074)
	at org.apache.hadoop.hive.ql.session.SessionState$ResourceType$1.preHook(SessionState.java:1063)
	at org.apache.hadoop.hive.ql.session.SessionState.add_resources(SessionState.java:1163)
	at org.apache.hadoop.hive.ql.session.SessionState.add_resources(SessionState.java:1121)
	at org.apache.hadoop.hive.ql.processors.AddResourceProcessor.run(AddResourceProcessor.java:67)
	at org.apache.hive.service.cli.operation.HiveCommandOperation.runInternal(HiveCommandOperation.java:105)
	at org.apache.hive.service.cli.operation.Operation.run(Operation.java:257)
	at org.apache.hive.service.cli.session.HiveSessionImpl.executeStatementInternal(HiveSessionImpl.java:419)
	at org.apache.hive.service.cli.session.HiveSessionImpl.executeStatementAsync(HiveSessionImpl.java:406)
	at org.apache.hive.service.cli.CLIService.executeStatementAsync(CLIService.java:274)
	at org.apache.hive.service.cli.thrift.ThriftCLIService.ExecuteStatement(ThriftCLIService.java:486)
	at org.apache.hive.service.cli.thrift.TCLIService$Processor$ExecuteStatement.getResult(TCLIService.java:1317)
	at org.apache.hive.service.cli.thrift.TCLIService$Processor$ExecuteStatement.getResult(TCLIService.java:1302)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
	at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)
	at org.apache.hive.service.auth.TSetIpAddressProcessor.process(TSetIpAddressProcessor.java:56)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:285)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

2018-01-04 11:06:00,884 INFO  [HiveServer2-Handler-Pool: Thread-36]: session.HiveSessionImpl (HiveSessionImpl.java:release(318)) - We are resetting the hadoop caller context for thread HiveServer2-Handler-Pool: Thread-36
2018-01-04 11:06:00,884 WARN  [HiveServer2-Handler-Pool: Thread-36]: thrift.ThriftCLIService (ThriftCLIService.java:ExecuteStatement(492)) - Error executing statement: 
org.apache.hive.service.cli.HiveSQLException: Error while processing statement: file:///home/anuradha/shareinsights/udfs/hivexmlserde-1.0.5.3.jar does not exist
	at org.apache.hive.service.cli.operation.Operation.toSQLException(Operation.java:315)
	at org.apache.hive.service.cli.operation.HiveCommandOperation.runInternal(HiveCommandOperation.java:108)
	at org.apache.hive.service.cli.operation.Operation.run(Operation.java:257)
	at org.apache.hive.service.cli.session.HiveSessionImpl.executeStatementInternal(HiveSessionImpl.java:419)
	at org.apache.hive.service.cli.session.HiveSessionImpl.executeStatementAsync(HiveSessionImpl.java:406)
	at org.apache.hive.service.cli.CLIService.executeStatementAsync(CLIService.java:274)
	at org.apache.hive.service.cli.thrift.ThriftCLIService.ExecuteStatement(ThriftCLIService.java:486)
	at org.apache.hive.service.cli.thrift.TCLIService$Processor$ExecuteStatement.getResult(TCLIService.java:1317)
	at org.apache.hive.service.cli.thrift.TCLIService$Processor$ExecuteStatement.getResult(TCLIService.java:1302)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
	at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)
	at org.apache.hive.service.auth.TSetIpAddressProcessor.process(TSetIpAddressProcessor.java:56)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:285)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
2018-01-04 11:06:00,885 DEBUG [HiveServer2-Handler-Pool: Thread-36]: transport.TSaslTransport (TSaslTransport.java:flush(498)) - writing data length: 1745, [~anuradha_gadge], I'm guessing that {{file:///home/anuradha/shareinsights/udfs/hivexmlserde-1.0.5.3.jar}} exists on the client machine (where you're running beeline), and not on the HS2 server. Is that right? 

Please realize that beeline won't transmit your jar from the client machine's local FS to the HS2 server (where your query is actually running). You're better off using an HDFS path for your jar.

, HS2 and beeline both are running on the same machine. Hence the path file:///home/anuradha/shareinsights/udfs/hivexmlserde-1.0.5.3.jar is available to both HS2 and beeline client.

It works fine when I put the jar on HDFS path.
]