[A proposal for the solution:
Instead of the Metastore code creating the directories why not have HiveMetastoreClient create it in createTable() after the table is created - i.e. it can do a getTable().getSd().getLocation() and perform wh.mkdirs() on that path. We could do the same thing with addPartition() and other places where needed. The issue with this is it still breaks direct thrift clients. So a compromise is to use a conf variable - "strict.owner.mode" - if this is set to true on the server, dirs will not be created and they will be created on the client (both client and server should have the same value (true or false).  In installations where there are thrift clients, this can be set to false till the point the clients are ready to create the dirs themselves.

HiveMetaStoreClient needs to change to read this conf variable and create dirs if it is set to true. This directory creation/deletion is relevant to create table/drop table/add partition/alter table/alter partition I think.


 
, The above file attached for review is a patch generated by svn diff against revision 985768 off hive svn trunk.

It uses a new parameter "hadoop.fs.operations.owner" to determine whether or not a component is allowed to perform operations(write) on the filesystem. It defaults to true for HiveMetaStore, and defaults to false for HiveMetaStoreClient.

To run in thrift mode and get the behaviour described in this jira, we would need to override this parameter to false on the thrift server start, and true on the client side.

Thanks for reviewing and looking over this!

Other comments : During testing, I wanted to disable filesystem access on the thrift server end, by providing an invalid fs.default.name - the idea being that if this patch covered all writing usecases, we would not need to write from the thrift end, and would not encounter any runtime failures. However, as you may guess, that didn't turn out to be the case, because we still read off it. We still perform path translations, we perform setLocation() on StorageDescriptors after getting appropriate paths, etc. Now this raised another further issue, wherein we'd potentially like this patch to be a bit more - to be able to move all fs ops to the client side if configured to be so, as that would be useful for integrating with secure hadoop, where the thrift server might not have access to the filesystem, and if it were to need access, it would need to keep requesting auth tokens. The idea there might be to have it be a pure metadata service. Anyhow, the intent now is to submit that as a separate feature-request jira, while leaving this one to address this.
, Hi,
  I am out of the office on vacation from Friday Aug 20th to Friday, Sept 17th. Please contact my manager, Olga Natkovich for any urgent issues.

Thanks,
Pradeep

, @Paul, can you take a look at this ?, Updated patch to go against version 991714(current trunk), In the absence of making the metastore truly a metadata-only service, it seems like what we really want is for the metastore to act on behalf of users.

Could we have the hive client fetch an HDFS delegation token and pass it securely to the metastore, so the metastore can act as the user to perform the operations?
Alternatively, could the metastore be set up with an HDFS proxy user principal that allows it to impersonate anyone in a "hive" group?

Although we don't have true authorization, etc, at the moment, in Hive, we should think about how to solve this in a way that at least moves us closer to that goal., BTW, we are working on a SASL-secured Thrift transport over at THRIFT-876, @Todd, Thrift over HTTP transport (THRIFT-814) can use kerberos over SPNEGO., @Venkatesh: THRIFT-814 covers adding SPNEGO support to Thrift., Edit: I mean THRIFT-889.]