[I create partitioned table and load .gz file into the partition:
CREATE EXTERNAL TABLE IF NOT EXISTS if_pmt_note_staging (
apsdactno string, date_tr string, apsdjrnno string, apsdseqno string, province_code string
) partitioned by (batch_id string);

alter table if_pmt_note_staging add partition (batch_id='201510') location '/hive/if_pmt_note_staging';

The location '/hive/if_pmt_note_staging' has some .gz files. such as 1.gz,2.gz and so on

then I create index:

CREATE INDEX index_if_pmt_note_staging_date_tr 
ON TABLE if_pmt_note_staging (date_tr) 
AS 'org.apache.hadoop.hive.ql.index.compact.CompactIndexHandler' 
WITH DEFERRED REBUILD 
IN TABLE t_index_if_pmt_note_staging_date_tr; 

alter index index_if_pmt_note_staging_date_tr on if_pmt_note_staging rebuild; 

CREATE INDEX index_apsh_province_code_apsdprocod_apsdactno_tr
ON TABLE apsh (apsdprocod) 
AS 'org.apache.hadoop.hive.ql.index.compact.CompactIndexHandler' 
WITH DEFERRED REBUILD
IN TABLE t_index_province_code_apsdprocod_apsdactno_tr;

when I excute query use the the index date_tr:
select * from if_pmt_note_staging where date_tr='20121205';

I found that some of the data should be queried without query. such as the matched data in the 3.gz file

The hive logs print as follows:
split start : 10336
split end : 59916
...................

It is true that hiveIndexResult.contains function Filter out some files in the HiveIndexedInputFormat,  the function list as below:

  public boolean contains(FileSplit split) throws HiveException {
  
    ....................
    for (Long offset : bucket.getOffsets()) {
      if ((offset >= split.getStart())
          && (offset <= split.getStart() + split.getLength())) {
        return true;
      }
    }
   }
the offset length  is the length of the file after decompression ,but the split.getLength() is the length of the file before decompression. so some files may filter out by this function.
It seemed this section of code isn't necessary, we can delete it. ,    Hive use index for queries will lose some data if the Query file is compressed.
   Hive created the index using the extracted file length when use the file is  the compressed, but when to divide the data into pieces in MapReduce,Hive use the file length to compare with the extracted file length,If it found that these two lengths are not matched, It filters out the file.So the query will lose some data., 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12782464/HIVE-12877.patch

{color:red}ERROR:{color} -1 due to no test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 6 failed/errored test(s), 10019 tests executed
*Failed tests:*
{noformat}
TestHWISessionManager - did not produce a TEST-*.xml file
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_tez_union
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_authorization_uri_import
org.apache.hadoop.hive.ql.exec.spark.session.TestSparkSessionManagerImpl.testMultiSessionMultipleUse
org.apache.hadoop.hive.ql.exec.spark.session.TestSparkSessionManagerImpl.testSingleSessionMultipleUse
org.apache.hive.jdbc.TestSSL.testSSLVersion
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6642/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6642/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-6642/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 6 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12782464 - PreCommit-HIVE-TRUNK-Build, None of the test failures here are related or regressions, could you please take a quick look at this patch, [~yangfang] Can you add test in the patch ?, I have add .q test in index_query_compressed_file_failure.q, 19-index_compressed_file.gz is my compressed file which used for test.]