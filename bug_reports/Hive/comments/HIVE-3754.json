[[~ashutoshc] [~cwsteinbach], are you aware of any build command change? Is this still the right way to build hadoop 23? It has been working well except recent trunk. Just ensure it's right way. thanks

{code}
ant clean package -Dhadoop.version=0.23.1 -Dhadoop-0.23.version=0.23.1 -Dhadoop.mr.rev=23
{code}, CCing: [~amalakar] This seems to be related to HIVE-3645, [~ashutoshc] thank you very much Tim

[~amalakar] [~viraj] would you please check if it is introduced by HIVE-3645? If yes, would you please fix it in trunk? It's blocking me. thanks a lot Tim, Arup Malakar recently checked this in to enable Federation capability.
Viraj, Viraj can you check if it breaks Hadoop 23 build? You can use the following to check

Sent from my iPhone

On Nov 28, 2012, at 6:25 PM, "Viraj Bhat (JIRA)" <jira@apache.org> wrote:

, Hi Gang the API getDefaultBlockSize(Path) and getDefaultReplication(Path) in FileSystem is not available on 0.23.1 they are in 0.23.3 though or 2.0.0-alpha. That is why they are building fine with default configuration , but won't compile when you use Hadoop 0.23.1. Is this a concern?, Hi Arup

Thank you for explanation.

What ant command should we use for Hadoop 23 build after jira 3645?

Thanks



, You can use either of 
{code}
ant clean package -Dhadoop.version=0.23.3 -Dhadoop-0.23.version=0.23.3 -Dhadoop.mr.rev=23
ant clean package -Dhadoop.version=2.0.0-alpha -Dhadoop-0.23.version=2.0.0-alpha -Dhadoop.mr.rev=23
{code}, [~ashutoshc] thanks. 

I will use this jira to track documentation change. I just update https://cwiki.apache.org/confluence/display/Hive/GettingStarted with new build command.

thanks

Tim, update documentation https://cwiki.apache.org/confluence/display/Hive/GettingStarted, Gang I am assuming it is now compiling for you with the commands Ashutosh provided., Yes. thank Arup for follow up.

Actually, I tried 23.3 before Ashutosh's comment and it worked well :)

Ashutosh's comment confirmed my experiment and also told me another choice of "alpha". thank Ashutosh again for prompt comment. thanks a lot.

Again, Arup, thank you very much for prompt explanation and follow up.]