[Hive on spark can submit spark job in a separate JVM while "hive.exec.submitviachild" configured as true, so that Hive only need to load dependencies identified by HIVE-7371. But we still get this issue while Hive submit spark job in same JVM with Hive CLI., Seems that hive (spark branch) also depends on guava-14. Can we bump the version to 14 in hadoop too?, [~lirui] Guava 11 are used in many hadoop components. Upgrading it across board poses a big challenge. However, Spark isn't using anythinging from Guava 12+, so I proposed in SPARK-2420 that guava be downgraded to 11 in Spark. Unfortunately, it hasn't been taken seriously in Spark community., Hi Xuefu, I was wrong about Spark not using Guava 12+. It does now. I posted an update on the Spark JIRA. That makes it somewhat harder to downgrade, although not much. I would not characterize it as not being taken seriously. There are legitimate questions here, like why Hadoop can't get off of Guava 11, which is about 2.5 years old now. It was very helpful to link the Spark JIRA to this one, which has the details., Thanks, Sean. Linked., This patch provided by [~srowen] may solve the conflict with guava. I tested it with Spark v1.0.1.
, {quote}
This patch provided by Sean Owen may solve the conflict with guava. I tested it with Spark v1.0.1.
{quote}

To clarify, the patch isn't for Hive, but for Spark on top of 1.0.1, as a workaround for this problem: simply apply the patch to your own Spark build.

[~szehon] Could you included this as your wiki "get started" instructions?, Sure, will add this once I add the page., With SPARK-2848, shading guava in Spark, this is no longer a problem in Hive., does it merge into spark 1.1.1?, bq: does it merge into spark 1.1.1?

Yes., This affects anyone trying to use a custom UDF from the Hive CLI when the UDF depends on later Guava methods too.  
Suggest reopening this as a valid issue.]