[What is happening here is:
1) HiveMetaStoreClient.dropDatabase() gets the list of table names in the given db. This list includes both the normal tables and index tables
2) dropTable is called for each table. When deleting a table all its indexes are also deleted. If a index consist of a table, then it will also be deleted, but the list got in step 1 is not updated and assumes that remaining tables in the list are still in database. So when the next request comes to delete the index table we get the "table not found exception"

Proposed fix: Instead of getting table names get the Table objects. Call dropTable for each table only if the table is not an index table and it still exists., ReviewBoard link: https://reviews.apache.org/r/14996/, 

{color:green}Overall{color}: +1 all checks pass

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12610898/HIVE-5664.1.patch.txt

{color:green}SUCCESS:{color} +1 4516 tests passed

Test results: http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/32/testReport
Console output: http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/32/console

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
{noformat}

This message is automatically generated., This fix suffers from [TOCTOU bug | http://en.wikipedia.org/wiki/Time_of_check_to_time_of_use] by first retrieving objects in client and than updating (deleting) those. All of this should be handled on server side. Metastore client should just request that it wants to delete tables. Metastore server should figure out if table is index table or not and take appropriate actions (perhaps all within one transaction)., Hi Ashutosh,
The fix retrieves the table names only (not the objects) in the client, but before deleting the table it makes sure it still exists in the db. The reason the cascade drop moved to client side is in [HIVE-3563 | https://issues.apache.org/jira/browse/HIVE-3563] (https://reviews.apache.org/r/7517/) due to storage handler callbacks., [~ashutoshc] HIVE-3563 already attempted to move the cascade drop to server side, but has to revert that change because storage handler callbacks are executed on client side. One of the [review|https://reviews.apache.org/r/7517/] descriptions talks about logging a separate JIRA to move the storage handler callbacks to servers side, but I don't find any JIRA for the same. I will look at the code again to see if it actually moved to server side. The fix attached to this bug checks if the table with a given name exists. If it exists then only it attempts to delete it., 

{color:red}Overall{color}: -1 at least one tests failed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12610898/HIVE-5664.1.patch.txt

{color:red}ERROR:{color} -1 due to 3 failed/errored test(s), 5436 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_database_drop
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_stats_partscan_1_23
org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_root_dir_external_table
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-Build/157/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-Build/157/console

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 3 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12610898, We had the same issue. In case we cannot move the drop db cascade to server side for now, the simple fix can be client request table name/index name list again after each drop request. It is not perfect solution, but is simple and more general. , Rebased on latest trunk and fixed the .out changes., Proposed in current form, a db containing 1000 tables, we will make 1000 trips to metastore from client while doing cascade drop. That will be expensive, it will be good to avoid if we can.

I wonder if instead of getAllTables() , if we can use getTables() or listTableNamesByFilter() to only retrieve base tables and no index tables. Since index tables follow specific naming pattern, we can construct and pass that pattern to one of the above methods to get only base tables. This will avoid multiple round trips to metastore from client. , bq. Proposed in current form, a db containing 1000 tables, we will make 1000 trips to metastore from client while doing cascade drop. That will be expensive, it will be good to avoid if we can.
In current Hive (without the fix attached to this jira), HiveMetastoreClient is getting all table names first and for each table name it is getting the {{Table}} object as part of dropTable() method. So with this fix, we are not making it any more expensive, but I agree that it is very expensive to make n+1 metastore calls.

bq. I wonder if instead of getAllTables() , if we can use getTables() or listTableNamesByFilter() to only retrieve base tables and no index tables. Since index tables follow specific naming pattern, we can construct and pass that pattern to one of the above methods to get only base tables. This will avoid multiple round trips to metastore from client.
Index tables can have custom names like in {{CREATE INDEX temp_tbl3_idx ON TABLE temp_tbl3(id) AS 'COMPACT' with DEFERRED REBUILD IN TABLE temp_tbl3_idx_tbl;}}

Couple of other alternatives:
1. Failure is because there is no {{Table}} object is found in {{dropTable}} method for index tables. Simple fix is to ignore {{NoSuchObjectExceptions}}.
2. Add a method {{getTables(TableType)}} to MetaStore interface to retrieve {{Table}} objects based on table type. We may need to fetch the tables in batches to avoid memory issues., Seems like simply changing {{dropTable(name, table, deleteData, false);}} to {{dropTable(name, table, deleteData, true);}} will do the trick of ignoring unknown table.
 If that doesnt work for whatever reason lets go with your option 1 of catch and ignoring NSOException, since its hard to delete an object which doesnt exist : ) in catch block its sufficient to just log error message in that case and move on., bq. Seems like simply changing dropTable(name, table, deleteData, false); to dropTable(name, table, deleteData, true); will do the trick of ignoring unknown table.
Yep, thats what I meant to use in option 1. Attached the patch., +1, 

{color:red}Overall{color}: -1 at least one tests failed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12681669/HIVE-5664.3.patch.txt

{color:red}ERROR:{color} -1 due to 1 failed/errored test(s), 6688 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_optimize_nullscan
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1804/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1804/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-1804/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 1 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12681669 - PreCommit-HIVE-TRUNK-Build, Committed to trunk. Thanks, Venki!, [~ashutoshc] back port to .14?, Committed to 0.14, Updating release version for jiras resolved in 1.0.0 .
, This issue has been fixed in Apache Hive 1.0.0. If there is any issue with the fix, please open a new jira to address it.
]