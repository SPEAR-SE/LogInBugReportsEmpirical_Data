[Hi,

My idea is to replicate the same checks from the org.apache.hadoop.hive.ql.txn.compactor.Initiator.java to the org.apache.hadoop.hive.ql.txn.compactor.Worker.java logic.

{code:title=org.apache.hadoop.hive.ql.txn.compactor.Initiator.java|borderStyle=solid}
// Figure out if there are any currently running compactions on the same table or partition.
  private boolean lookForCurrentCompactions(ShowCompactResponse compactions,
                                            CompactionInfo ci) {
    if (compactions.getCompacts() != null) {
      for (ShowCompactResponseElement e : compactions.getCompacts()) {
         if ((e.getState().equals(TxnStore.WORKING_RESPONSE) || e.getState().equals(TxnStore.INITIATED_RESPONSE)) &&
            e.getDbname().equals(ci.dbname) &&
            e.getTablename().equals(ci.tableName) &&
            (e.getPartitionname() == null && ci.partName == null ||
                  e.getPartitionname().equals(ci.partName))) {
          return true;
        }
      }
    }
    return false;
  }

public void run(){
    //...
    if (lookForCurrentCompactions(currentCompactions, ci)) {
        LOG.debug("Found currently initiated or working compaction for " + ci.getFullPartitionName() + " so we will not initiate another compaction");
        continue;
    }
    //...
}
{code}

{code:title=org.apache.hadoop.hive.ql.txn.compactor.Worker.java|borderStyle=solid}
public void run() {
      //...
          // This chicanery is to get around the fact that the table needs to be final in order to
        // go into the doAs below.
        final Table t = t1;

        ShowCompactResponse currentCompactions = txnHandler.showCompact(new ShowCompactRequest());
        if (lookForCurrentCompactions(currentCompactions, ci)) {
          LOG.debug("Found currently initiated or working compaction for " +
              ci.getFullPartitionName() + " so we will not initiate another compaction");
          continue;
        }
        
        // Find the partition we will be working with, if there is one.
        Partition p = null;
      //...
      //Figure out if there are any currently running compactions on the same table or partition.
 private boolean lookForCurrentCompactions(ShowCompactResponse compactions,
                                           CompactionInfo ci) {
   if (compactions.getCompacts() != null) {
     for (ShowCompactResponseElement e : compactions.getCompacts()) {
        if ((e.getState().equals(TxnStore.WORKING_RESPONSE) || e.getState().equals(TxnStore.INITIATED_RESPONSE)) &&
           e.getDbname().equals(ci.dbname) &&
           e.getTablename().equals(ci.tableName) &&
           (e.getPartitionname() == null && ci.partName == null ||
                 e.getPartitionname().equals(ci.partName))) {
         return true;
       }
     }
   }
   return false;
 }
}
  //...
{code}

Please let me know if this is the correct approach., cc [~ekoifman] 

Should the compactor just use locks?, Relying on "show compactions" is not atomic so it's not a complete fix.
It should use locks of some kind, but not in the current lock manager.  MutexAPI.acquireLock(String) was meant to support the kind of locking that this needs but it's not quite complete.  If you use </db/table/partition> for the key, and use this from Worker, it will achieve the proper synchronization atomically and the "lock" will be released if the process dies.
, This should now be fixed via HIVE-15202, fixed in HIVE-15202]