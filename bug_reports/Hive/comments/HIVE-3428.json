[Problems in the current log4j configuration:

1. When hive is running MapReduce job using hadoop(which locates in testutils/hadoop), hadoop is configured using HADOOP_CONF_DIR. While, currently, HADOOP_CONF_DIR is not set properly(not set at all except for pdk scripts).

2. hadoop is by default doing log4j initialization by reading log4j.properties in its HADOOP_CONF_DIR. We do have a hive-log4j.properties, which is used to initialize hive log4j, but no such log4j.properties exited for hadoop.

3. In the current hive-log4j.properties file, there is no log4j.appender.NullAppender defined, which could produce the following log4j error message:

[junit] < log4j:ERROR Could not find value for key log4j.appender.NullAppender
[junit] < log4j:ERROR Could not instantiate appender named "NullAppender".

4. The current log4j Event Counter Appender is initialized with an deprecated value, which would produce the following warning message:

[junit] < WARNING: org.apache.hadoop.metrics.jvm.EventCounter is deprecated. Please use org.apache.hadoop.log.metrics.EventCounter in all the log4j.properties files.
, Review Request submitted at:
https://reviews.facebook.net/D5133, +1. Will commit if tests pass., This patch seems to break lots of stuff on 0.21.

@Zhenxiao: Did you try running any tests on trunk with the standard configuration (i.e. using Hadoop 0.21)?, Updated patch submitted for review at:
https://reviews.facebook.net/D5133, More comments on phabricator., Updated patch, review request submitted at:
https://reviews.facebook.net/D5133, Updated patch. comments addressed. review request submitted at:
https://reviews.facebook.net/D5133, @Zhenxiao: please see my comments on phabricator., @Carl:
Thanks for the comments. I updated my patch at:
https://reviews.facebook.net/D5133, Patch doesn't apply cleanly. Zhenxiao, can you please refresh the patch?, Patch doesn't seem to provide configuration for hadoop.mr.rev=20S (hadoop 1-line). More importantly, if the only difference between the files is the Hadoop's deprecated EventCounter, it seems better to create a shim class for that. This way there's only one conf file and hive will pick the right file from the classpath at runtime., Proposed shim for EventCounter class. Does not contain NullAppender or HADOOP_CONF variable., Hi Gunther, would you please add a review request at:
https://reviews.facebook.net/
It is easy to review there., [~zhenxiao]: Sorry for the delay: https://reviews.facebook.net/D8805, +1 Running tests., Committed to trunk. Thanks, Gunther!, Integrated in Hive-trunk-h0.21 #1989 (See [https://builds.apache.org/job/Hive-trunk-h0.21/1989/])
    HIVE-3428 : Fix log4j configuration errors when running hive on hadoop23 (Gunther Hagleitner via Ashutosh Chauhan) (Revision 1450645)

     Result = SUCCESS
hashutosh : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1450645
Files : 
* /hive/trunk/common/src/java/conf/hive-log4j.properties
* /hive/trunk/data/conf/hive-log4j.properties
* /hive/trunk/pdk/scripts/conf/log4j.properties
* /hive/trunk/ql/src/java/conf/hive-exec-log4j.properties
* /hive/trunk/shims/ivy.xml
* /hive/trunk/shims/src/common/java/org/apache/hadoop/hive/shims/HiveEventCounter.java
* /hive/trunk/shims/src/common/java/org/apache/hadoop/hive/shims/ShimLoader.java
, Integrated in Hive-trunk-hadoop2 #138 (See [https://builds.apache.org/job/Hive-trunk-hadoop2/138/])
    HIVE-3428 : Fix log4j configuration errors when running hive on hadoop23 (Gunther Hagleitner via Ashutosh Chauhan) (Revision 1450645)

     Result = FAILURE
hashutosh : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1450645
Files : 
* /hive/trunk/common/src/java/conf/hive-log4j.properties
* /hive/trunk/data/conf/hive-log4j.properties
* /hive/trunk/pdk/scripts/conf/log4j.properties
* /hive/trunk/ql/src/java/conf/hive-exec-log4j.properties
* /hive/trunk/shims/ivy.xml
* /hive/trunk/shims/src/common/java/org/apache/hadoop/hive/shims/HiveEventCounter.java
* /hive/trunk/shims/src/common/java/org/apache/hadoop/hive/shims/ShimLoader.java
]