[Ours is not an empty file issue. However, the code section emanating the exception is same., Root cause of this issue is Not picking the YarnRunner as the job runner when hive.exec.mode.local.auto=true
mapreduce.framework.name gets set to 'local' instead of 'yarn'. This results in the LocalJobRunner being used as the JobRunner, and messes up the path creation. , Root cause of this issue is:
The classpath for jars in local mode points to a real file on disk. However, the JobSubmitter was cutting off the protocol part of the path. By default DistributedCache assumes that a protocol-less file is from HDFS, and that was causing the FileNotFound exception.
The solution is to the entire path to the DistributedCache, which allowed DistributedCache to find it in the file system., The patch changes 1 line in JobSubmitter, submitting the full classpath to the DistributedCache instead of the truncated path. , Changes the classpaths submitted by the JobSubmitter to full path., This changes the classpath submitted by the jobsubmitter to the distributed cache. The old path did not include the protocol. The new path includes the protocol. This allows the classpath to be resolved for local mode., [~ashahab] Your patch is on hadoop codebase. AFAICS there is nothing to fix in Hive. I will suggest you to open a bug on hadoop project and submit your patch there., Unintentional change is added to patch., Ashutosh Chauhan, just saw your comment. I will move this to hadoop., Resolving this as 'Not a problem', since claimed bug is on the hadoop project., Hi Abin, seems this issue still exits in the latest hadoop 2.6.0 code. Could you please create a Jira to hadoop? Thanks.
, The root cause has been fixed in hadoop 2.7.1, see https://issues.apache.org/jira/browse/MAPREDUCE-6238

Working around solutions for earlier hadoop version: 
Since this issue will occured when "-libjars 1.jar -files 2.jar -archives 3.jar " options are specified, for supporting local mode on earlier hadoop version, you can work around by make those 3 options empty, which are  generated from Hive options.

see ExecDriver.java:
"-libjars" are generated from "hive.aux.jars.path" and "hive.added.jars.path"
"-files" are generated from "hive.added.files.path"
"-archives" are generated from "hive.added.archives.path"

Then,  e.g.  "set hive.aux.jars.path=;"  can empty the "-libjars" options.
However, some aux jars may be required that you can add those jars by setting "HIVE_AUX_JARS_PATH" in env.
When setting "HIVE_AUX_JARS_PATH" in env, hcat command  will append those jars to the HADOOP_CLASSPATH and make it work in local mode.




]