[Supports schema on read when file schema has more columns.

Currently missing a way to determine if split is for an ACID table.  Code currently invokes ORC ACID reading code for non-ACID tables..., 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12783001/HIVE-12887.01.patch

{color:red}ERROR:{color} -1 due to no test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 6 failed/errored test(s), 10010 tests executed
*Failed tests:*
{noformat}
TestHWISessionManager - did not produce a TEST-*.xml file
TestSparkCliDriver-timestamp_lazy.q-bucketsortoptimize_insert_4.q-date_udf.q-and-12-more - did not produce a TEST-*.xml file
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_authorization_uri_import
org.apache.hadoop.hive.ql.exec.spark.session.TestSparkSessionManagerImpl.testMultiSessionMultipleUse
org.apache.hadoop.hive.ql.exec.spark.session.TestSparkSessionManagerImpl.testSingleSessionMultipleUse
org.apache.hive.jdbc.TestSSL.testSSLVersion
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6671/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6671/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-6671/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 6 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12783001 - PreCommit-HIVE-TRUNK-Build, What will happen after column removal with this patch? Is test needed?
Also, nit: please surround LOG.info with types with if LOG.isInfoEnabled.
, Added Q file test., [~sershe] In this patch the extra columns are now ignored by the ORC readers.  [Note that if you add columns again the readers will try and interpret the old columns... more problems in this area... need different metadata support]

Please +1.  Thanks., +1, Committed to master and branch-1

Thanks [~sershe] for the review!, Does this need to be backported to 2.0.1? (branch-2.0), Tried to port to branch-2.0 but got error org.apache.hadoop.hive.ql.metadata.HiveException: Changing SerDe (from OrcSerde) is not supported for table default.orc_partitioned. File format may be incompatible

Some other commit is needed, too., Hmm. If it's a bug in some other commit, is the fix even needed in 2.0.1?, [~mmccline] ping?, [~mmccline] ping??, Committed to branch-2.0]