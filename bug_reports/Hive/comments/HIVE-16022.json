[Noticed a couple of problems when I run the semijoin optimization on a MERGE statement:
- DynamicPartitionPruningOptimization.generateSemiJoinOperator(): parentOfRS does not necessarily have to be a SelectOperator - in this case it is a TS. As a result we are missing some important checking on whether this table is appropriate for semijoin opt.
- grandParent.getChildren().add(bloomFilterNode) - This wrongly assumes grandParent is AND: In this case, there was no previous filterExpr so grandParent is BETWEEN. Adding the child here incorrectly adds a new parameter to BETWEEN , which is probably getting ignored. This is why in_bloom_filter() is not in the EXPLAIN., Looking at the partition column checking logic in generateSemiJoinOperatorPlan(), I still don't think it is right. The loop to try to get the TableScanOperator will blindly follow the 1st parent link, even if this means passing through a RS boundary. I think a better check here is to check that the key is a column expr node, and then checking getIsPartitionColOrVirtualCol() on the column to see if it is a partition column., [~hagleitn] [~ashutoshc] [~ekoifman] can you review, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12854159/HIVE-16022.2.patch

{color:green}SUCCESS:{color} +1 due to 1 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 7 failed/errored test(s), 10258 tests executed
*Failed tests:*
{noformat}
TestDerbyConnector - did not produce a TEST-*.xml file (likely timed out) (batchId=235)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[orc_ppd_schema_evol_3a] (batchId=136)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[dynamic_partition_pruning] (batchId=144)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vectorized_dynamic_partition_pruning] (batchId=144)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=223)
org.apache.hive.beeline.TestBeeLineWithArgs.testQueryProgressParallel (batchId=211)
org.apache.hive.service.server.TestHS2HttpServer.testContextRootUrlRewrite (batchId=186)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/3736/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/3736/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-3736/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 7 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12854159 - PreCommit-HIVE-Build, Looks like the partition column checking still needs to follow the parent operators until it hits a TableScan., 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12854609/HIVE-16022.3.patch

{color:green}SUCCESS:{color} +1 due to 1 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 5 failed/errored test(s), 10246 tests executed
*Failed tests:*
{noformat}
TestDerbyConnector - did not produce a TEST-*.xml file (likely timed out) (batchId=235)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=223)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query23] (batchId=223)
org.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=117)
org.apache.hadoop.hive.metastore.TestMetaStoreInitListener.testMetaStoreInitListener (batchId=203)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/3775/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/3775/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-3775/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 5 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12854609 - PreCommit-HIVE-Build, Precommit tests looked good. [~hagleitn] [~ekoifman] can you review?, the new plans look good but I don't know enough about the optimizer part to review this, Looks good overall. Can you explain why you need to recursively find another column desc? I think you're looking for whether any partition column contributed to the expr you're looking at. That doesn't seem to be the right check either. Does it? A better check would be to make sure there are no parallel dyn part and semi join branches, wouldn't it?, I believe the partition column check here may be a workaround to the fact that min/max/bloomfilter generation was not working properly on partition columns.
I'm going to remove this part of the changes and just focus on the part of the fix related to in_bloom_filter() not being added properly to the MERGE statement.
We can follow up on the partition column check later on., +1, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12855035/HIVE-16022.4.patch

{color:green}SUCCESS:{color} +1 due to 1 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 4 failed/errored test(s), 10270 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_text_vec_table] (batchId=147)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=223)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query23] (batchId=223)
org.apache.hadoop.hive.cli.TestSparkNegativeCliDriver.org.apache.hadoop.hive.cli.TestSparkNegativeCliDriver (batchId=230)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/3830/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/3830/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-3830/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 4 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12855035 - PreCommit-HIVE-Build, Committed to master, As Jason mentioned, the check was added because semijoin reduction does not work properly with partition column, the reason being, it is not a real column but a logical one.
The logic expects a real column to compute min and max.
Aslo, there can never be parallel DPP and semijoin branches by design as they are created in if ...else if... block.]