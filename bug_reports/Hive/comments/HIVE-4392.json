[navis requested code review of "HIVE-4392 [jira] Illogical InvalidObjectException throwed when use mulit aggregate functions with star columns".

Reviewers: JIRA

HIVE-4392 Illogical InvalidObjectException throwed when use multi aggregate functions with star columns

For Example:

hive (default)> create table liza_1 as
              > select *, sum(key), sum(value)
              > from new_src;
Total MapReduce jobs = 1
Launching Job 1 out of 1
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201304191025_0003, Tracking URL = http://hd17-vm5:51030/jobdetails.jsp?jobid=job_201304191025_0003
Kill Command = /home/zongren/hadoop-current/bin/../bin/hadoop job  -kill job_201304191025_0003
Hadoop job information for Stage-1: number of mappers: 0; number of reducers: 1
2013-04-22 11:09:28,017 Stage-1 map = 0%,  reduce = 0%
2013-04-22 11:09:34,054 Stage-1 map = 0%,  reduce = 100%
2013-04-22 11:09:37,074 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_201304191025_0003
Moving data to: hdfs://hd17-vm5:9101/user/zongren/hive/liza_1
FAILED: Error in metadata: InvalidObjectException(message:liza_1 is not a valid object name)
FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
MapReduce Jobs Launched:
Job 0: Reduce: 1   HDFS Read: 0 HDFS Write: 12 SUCCESS
Total MapReduce CPU Time Spent: 0 msec

hive (default)> create table liza_1 as
              > select *, sum(key), sum(value)
              > from new_src
              > group by key, value;
Total MapReduce jobs = 1
Launching Job 1 out of 1
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201304191025_0004, Tracking URL = http://hd17-vm5:51030/jobdetails.jsp?jobid=job_201304191025_0004
Kill Command = /home/zongren/hadoop-current/bin/../bin/hadoop job  -kill job_201304191025_0004
Hadoop job information for Stage-1: number of mappers: 0; number of reducers: 1
2013-04-22 11:11:58,945 Stage-1 map = 0%,  reduce = 0%
2013-04-22 11:12:01,964 Stage-1 map = 0%,  reduce = 100%
2013-04-22 11:12:04,982 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_201304191025_0004
Moving data to: hdfs://hd17-vm5:9101/user/zongren/hive/liza_1
FAILED: Error in metadata: InvalidObjectException(message:liza_1 is not a valid object name)
FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
MapReduce Jobs Launched:
Job 0: Reduce: 1   HDFS Read: 0 HDFS Write: 0 SUCCESS
Total MapReduce CPU Time Spent: 0 msec

But the following tow Queries  work:
hive (default)> create table liza_1 as select * from new_src;
Total MapReduce jobs = 3
Launching Job 1 out of 3
Number of reduce tasks is set to 0 since there's no reduce operator
Starting Job = job_201304191025_0006, Tracking URL = http://hd17-vm5:51030/jobdetails.jsp?jobid=job_201304191025_0006
Kill Command = /home/zongren/hadoop-current/bin/../bin/hadoop job  -kill job_201304191025_0006
Hadoop job information for Stage-1: number of mappers: 0; number of reducers: 0
2013-04-22 11:15:00,681 Stage-1 map = 0%,  reduce = 0%
2013-04-22 11:15:03,697 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_201304191025_0006
Stage-4 is selected by condition resolver.
Stage-3 is filtered out by condition resolver.
Stage-5 is filtered out by condition resolver.
Moving data to: hdfs://hd17-vm5:9101/user/zongren/hive-scratchdir/hive_2013-04-22_11-14-54_632_6709035018023861094/-ext-10001
Moving data to: hdfs://hd17-vm5:9101/user/zongren/hive/liza_1
Table default.liza_1 stats: [num_partitions: 0, num_files: 0, num_rows: 0, total_size: 0, raw_data_size: 0]
MapReduce Jobs Launched:
Job 0:  HDFS Read: 0 HDFS Write: 0 SUCCESS
Total MapReduce CPU Time Spent: 0 msec
OK
Time taken: 9.576 seconds

hive (default)> create table liza_1 as
              > select sum (key), sum(value)
              > from new_test;
Total MapReduce jobs = 1
Launching Job 1 out of 1
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201304191025_0008, Tracking URL = http://hd17-vm5:51030/jobdetails.jsp?jobid=job_201304191025_0008
Kill Command = /home/zongren/hadoop-current/bin/../bin/hadoop job  -kill job_201304191025_0008
Hadoop job information for Stage-1: number of mappers: 0; number of reducers: 1
2013-04-22 11:22:52,200 Stage-1 map = 0%,  reduce = 0%
2013-04-22 11:22:55,216 Stage-1 map = 0%,  reduce = 100%
2013-04-22 11:22:58,234 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_201304191025_0008
Moving data to: hdfs://hd17-vm5:9101/user/zongren/hive/liza_1
Table default.liza_1 stats: [num_partitions: 0, num_files: 1, num_rows: 0, total_size: 6, raw_data_size: 0]
MapReduce Jobs Launched:
Job 0: Reduce: 1   HDFS Read: 0 HDFS Write: 6 SUCCESS
Total MapReduce CPU Time Spent: 0 msec
OK
Time taken: 11.115 seconds

TEST PLAN
  EMPTY

REVISION DETAIL
  https://reviews.facebook.net/D10431

AFFECTED FILES
  metastore/src/java/org/apache/hadoop/hive/metastore/HiveAlterHandler.java
  metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java
  metastore/src/java/org/apache/hadoop/hive/metastore/MetaStoreUtils.java
  ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
  ql/src/test/queries/clientpositive/ctas_colname.q
  ql/src/test/results/clientpositive/ctas_colname.q.out

MANAGE HERALD RULES
  https://reviews.facebook.net/herald/view/differential/

WHY DID I GET THIS EMAIL?
  https://reviews.facebook.net/herald/transcript/24963/

To: JIRA, navis
, Looks like same bug is causing HIVE-4391 as well., Since, HIVE-4391 is very similar to this. I tried with this patch and the queries posted there (e.g.,  from t2 insert overwrite  table t7  select c1, rank() over() ; ) . This query used to fail exactly as in the stacktrace here earlier (ie, after executing MR job, failing saying InvalidObjectException). But now fails at compile time itself with exception
{noformat}
FAILED: SemanticException [Error 10001]: Line 1:32 Table not found 't7'
{noformat}, I'll check that. Thanks., [~ashutoshc] It's not CTAS and it seemed t7 is not exist. I've tried "create table x2 as select *, rank() over() as rr from src" and it worked., [~navis] You are correct (as always : ) ). It does indeed work. Can you add some variant of following tests in the patch. I verified these tests work. I meanwhile will review the patch.
{code}
 create table x4 as select *, rank() over(partition by c1 order by c2)  as rr from t1; 
 select * from x4;  
create table x5 as select *, lead(c3,1) over(partition by c1 order by c2)   from t1 limit 5;
select * from x5;
{code}, navis updated the revision "HIVE-4392 [jira] Illogical InvalidObjectException throwed when use mulit aggregate functions with star columns".

  Added test cases

Reviewers: JIRA

REVISION DETAIL
  https://reviews.facebook.net/D10431

CHANGE SINCE LAST DIFF
  https://reviews.facebook.net/D10431?vs=32607&id=32715#toc

AFFECTED FILES
  metastore/src/java/org/apache/hadoop/hive/metastore/HiveAlterHandler.java
  metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java
  metastore/src/java/org/apache/hadoop/hive/metastore/MetaStoreUtils.java
  ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
  ql/src/test/queries/clientpositive/ctas_colname.q
  ql/src/test/results/clientpositive/ctas_colname.q.out

To: JIRA, navis
, comments., ashutoshc has requested changes to the revision "HIVE-4392 [jira] Illogical InvalidObjectException throwed when use mulit aggregate functions with star columns".

  .q.out file changes doesn't look right for windowing functions.

INLINE COMMENTS
  ql/src/test/results/clientpositive/ctas_colname.q.out:245 This doesn't look right. There should be three columns here, not 4.
  Column _col2 looks suspicious.
  ql/src/test/results/clientpositive/ctas_colname.q.out:291 Some rows here have 3 columns and others have 4 columns. How is that possible?
  ql/src/test/results/clientpositive/ctas_colname.q.out:430 Again, there should only be 3 columns here, not 4.

REVISION DETAIL
  https://reviews.facebook.net/D10431

BRANCH
  HIVE-4392

ARCANIST PROJECT
  hive

To: JIRA, ashutoshc, navis
, navis has commented on the revision "HIVE-4392 [jira] Illogical InvalidObjectException throwed when use mulit aggregate functions with star columns".

INLINE COMMENTS
  ql/src/test/results/clientpositive/ctas_colname.q.out:245 PTF operator, which is parent of SEL hands over 3 columns(except vcs). One window column and two other columns(key, value). So * is resolved into theses three columns and adding one window column(rank()..) makes 4 columns.

  it's similar to "select *, key from src" returning 3 columns.
  ql/src/test/results/clientpositive/ctas_colname.q.out:291 The table 'src1' has null columns which makes query result very confusing.

REVISION DETAIL
  https://reviews.facebook.net/D10431

BRANCH
  HIVE-4392

ARCANIST PROJECT
  hive

To: JIRA, ashutoshc, navis
, ashutoshc has added CCs to the revision "HIVE-4392 [jira] Illogical InvalidObjectException throwed when use mulit aggregate functions with star columns".
Added CCs: hbutani

  I think we need to fix why in case of windowing we have an extra column.
  CCing Harish, who may have an insight into this.

INLINE COMMENTS
  ql/src/test/results/clientpositive/ctas_colname.q.out:245 I see why is this happening. But that still against the semantics. When I do create table t1 as select * , rank() from src; where src has 2 columns. I expect t1 to have 3 columns, not 4. Isn't it ?
  ql/src/test/results/clientpositive/ctas_colname.q.out:291 I thought when column is null, we print NULL for column, how come its empty string in this case?

REVISION DETAIL
  https://reviews.facebook.net/D10431

BRANCH
  HIVE-4392

ARCANIST PROJECT
  hive

To: JIRA, ashutoshc, navis
Cc: hbutani
, navis has commented on the revision "HIVE-4392 [jira] Illogical InvalidObjectException throwed when use mulit aggregate functions with star columns".

INLINE COMMENTS
  ql/src/test/results/clientpositive/ctas_colname.q.out:245 Yes, I think windows columns should be marked as hidden-virtual column. But I can't decide it cause I don't know anything on windowing functions.
  ql/src/test/results/clientpositive/ctas_colname.q.out:291 You are right, what's that then? I should investigate on it.

REVISION DETAIL
  https://reviews.facebook.net/D10431

BRANCH
  HIVE-4392

ARCANIST PROJECT
  hive

To: JIRA, ashutoshc, navis
Cc: hbutani
, [~rhbutani] Do you think marking windowing column as hidden virtual column is a wise thing to do?, navis has commented on the revision "HIVE-4392 [jira] Illogical InvalidObjectException throwed when use mulit aggregate functions with star columns".

INLINE COMMENTS
  ql/src/test/results/clientpositive/ctas_colname.q.out:245 I've changed window columns to hidden virtual columns and it seemed working good (passed ptf* and window* in client positive tests in ql). But still need a confirmation from Harish.
  ql/src/test/results/clientpositive/ctas_colname.q.out:291 My bad. It's empty string, not null.

REVISION DETAIL
  https://reviews.facebook.net/D10431

BRANCH
  HIVE-4392

ARCANIST PROJECT
  hive

To: JIRA, ashutoshc, navis
Cc: hbutani
, [~navis] Can you update the phabricator entry with your fix. I will take a look., But the check in genFileSinkPlan doesn't work for this query:
{noformat}
create table x4 as select * from (select *, rank() over(partition by key order by value) as rr from src1) a
{noformat}

It would be nice to fix this in genSelectPlan. 
- both PTFOp and GByOp set the agg function expression's ColInfo.alias as the ast.toStringTree
- because of the star, genColListRegex adds the ColInfo's for these to the out_schema
- then in the expr loop in genSelectPlan, the expression is added again, using the alias specified this time.

Still trying to see how to prevent the expression from being added twice:
- the straightforward answer would be to check in genColListRegex if the ColInfo.alias matches some expression.toStringTree on the SelectList. But to me it appears that this would require reproducing a lot of logic that is in genSelectPlan here.
- a potential simple check is, to check in genColListRegex if the alias is a validName; if not then the Column represents an expression that will get added explicitly in the genSelectPlan expr loop. But I am not sure if this is a bullet proof check.
By adding the following, around line 1816 in SemAnalyzer, I get the above e.g. to work:
{noformat}
       if ( !MetaStoreUtils.validateName(entry.getKey()) ) {
         continue;
       }
{noformat}
But haven't run any other tests, so this is very preliminary., navis updated the revision "HIVE-4392 [jira] Illogical InvalidObjectException throwed when use mulit aggregate functions with star columns".

  Changed window/ptf columns to hidden virtual column

Reviewers: ashutoshc, JIRA

REVISION DETAIL
  https://reviews.facebook.net/D10431

CHANGE SINCE LAST DIFF
  https://reviews.facebook.net/D10431?vs=32715&id=32847#toc

AFFECTED FILES
  metastore/src/java/org/apache/hadoop/hive/metastore/HiveAlterHandler.java
  metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java
  metastore/src/java/org/apache/hadoop/hive/metastore/MetaStoreUtils.java
  ql/src/java/org/apache/hadoop/hive/ql/parse/PTFTranslator.java
  ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
  ql/src/test/queries/clientpositive/ctas_colname.q
  ql/src/test/results/clientpositive/ctas_colname.q.out

To: JIRA, ashutoshc, navis
Cc: hbutani
, [~rhbutani] I didn't completely follow your suggestion. But, Navis's trick of treating the window column as hidden virtual column seems to have fixed the issue. I tested the test-case you have posted. That seems to have worked. I also ran all windowing and ptf tests those worked too. Can you take a look at Navis's latest patch to see if that looks right., In PTFTranslator, only the change on line 1053(pertaining to Window Functions) should be made. 

But to me it looks like the issue is the same for both PTFOp and GByOp. And the issue is in how the RowResolver is constructed in SelectOp when a '*' is present in the Select List.

The combination of:
1. using the internalName in genFileSinkPlan when the input column has no table Alias.
2. making the Windowing expressions hidden Virtual

Works for PTFs. But same thing has to be done for GBy.

1. For this e.g.  
{noformat}
create table x4 as select *, min(value) from src1
{noformat}
 the output schema still has 2 columns instead of 1; the GByOp's RowResolver has 1 column; but the SelectOp's RR has 2 columns.

2. This one still fails:
{noformat}
create table x4 as select * from (select *, min(value) from src1) a
{noformat}

I wonder if you can make the aggregations expressions in GByOp virtual hidden? They maybe referenced in a Having clause.
A more direct fix maybe to avoid adding these SelectExprs twice in the SelectOp RR. 
, I see. Thanks for explanation. I agree right fix is to correctly handle * and not add select list twice in such cases. I would make following proposal. 
For 0.11 we go ahead with current fix and track the correct fix in a new jira.  
[~navis] / [~rhbutani] What do you guys think ?, Harish is right. Query 2 is failing and it's apparent that the patch is still missing something even for a stopgap. I'll look into this more., navis updated the revision "HIVE-4392 [jira] Illogical InvalidObjectException throwed when use mulit aggregate functions with star columns".

  Addressed comments

Reviewers: ashutoshc, JIRA

REVISION DETAIL
  https://reviews.facebook.net/D10431

CHANGE SINCE LAST DIFF
  https://reviews.facebook.net/D10431?vs=32847&id=33177#toc

AFFECTED FILES
  metastore/src/java/org/apache/hadoop/hive/metastore/HiveAlterHandler.java
  metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java
  metastore/src/java/org/apache/hadoop/hive/metastore/MetaStoreUtils.java
  ql/src/java/org/apache/hadoop/hive/ql/parse/PTFTranslator.java
  ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
  ql/src/test/queries/clientpositive/ctas_colname.q
  ql/src/test/results/clientpositive/ctas_colname.q.out

To: JIRA, ashutoshc, navis
Cc: hbutani
, [~rhbutani] / [~ashutoshc] Updated patch. Could you take a look at it?, [~navis] You opted to make aggregate column virtual hidden. But as [~rhbutani] this may still be problematic when these aggregate columns are referenced in having clause. e.g, consider query 2 from Harish's example with groupby and having clause in subquery. Did you test that.

Also as Harish suggested root problem here is
bq. And the issue is in how the RowResolver is constructed in SelectOp when a '*' is present in the Select List.

So, proper fix is to correctly handle * and only add requisite columns in RowResolver of select Op and thereby avoiding duplication of columns in first place. Wondering if you explored that route ?, I played bit more with the patch and tried out following queries:
{quote}
 create table x6 as select * from (select * from t1 group by key) a;
 create table x6 as select * from (select * from t1 group by key having key < 9) a;
 create table x7 as select * from (select max(value),key from t1 group by key having key < 9) a;
{quote}

All of the above worked, so seems like patch is effective. [~rhbutani] Do you think there could be other queries which you think might still be broken. I am fine with moving forward with the current patch, unless [~rhbutani] or [~navis] you guys want to do further investigation on the proper fix., I've understood this issue is for temporal stopgap. Wasn't it?

Making a column as VHC does not affect resolving it in "having" or others and just affects "select" clause. And changing aggregation columns to VHC might make backward compatibility issue (different schema)., I was suggesting this as a stopgap for 0.11. But since now that 0.11 has already shipped there is no rush. So, now we can take time to fix it the proper way. There are few alternatives now:
* We check this fix in and forget about the issue.
* We check this fix in to fix the issue on trunk and create another jira to track proper fix.
* We don't check in this fix and explore the proper fix (of correctly handling * in RR of select op) in this jira and try to get that in trunk.

[~navis] Since you are the one actively working on the issue, I will let you make the call for it. I am fine with any of three options.
, I agree [~navis] your call.

But couple of related observations, what are your thoughts on this.
If you do this query:
{noformat}
select *, max(p_size), min(p_size) from part
{noformat}
- The output has 4 columns. It will always be twice the number of aggregation expressions. 
- If you do this
{noformat}
select *, max(p_size), min(p_size) from part group by p_name
{noformat}
- you get 5 columns.
- This is because the * applies to the schema of the GBy Op.
- In the case of the PTFs you don't get duplicates because the agg. expressions are marked as VHC.
- But if you try either of these in Postgres
{noformat}
select *, max(p_size) from part
select *, max(p_size) from part group by p_name
{noformat}
- they fail; giving an error to the effect the part columns are not in Group By.
- So the '*' is resolved against the schema before the GBy 
- I think the behavior in Hive makes more sense; at some point should we change it so that we don't get duplicate output columns for aggregations?, [~charish] I was writing on the same issue, and now I see your comment. Thanks.
For the patch, I think this would be enough for now. But it's based on assumptions which can be broken if things changed, so let's include tests mentioned above and wait for next fail (and fix then).

And.. it seemed better to decide whether aggregation columns should be included or not for select-star in here. I prefer to change it not-included, but I'm not sure of it., Ok. Lets go ahead with this patch than. [~navis] Do you want to update the patch with these tests or shall I go ahead with testing it for commit?, navis updated the revision "HIVE-4392 [jira] Illogical InvalidObjectException throwed when use mulit aggregate functions with star columns".

  Added tests

Reviewers: ashutoshc, JIRA

REVISION DETAIL
  https://reviews.facebook.net/D10431

CHANGE SINCE LAST DIFF
  https://reviews.facebook.net/D10431?vs=33177&id=33285#toc

AFFECTED FILES
  metastore/src/java/org/apache/hadoop/hive/metastore/HiveAlterHandler.java
  metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java
  metastore/src/java/org/apache/hadoop/hive/metastore/MetaStoreUtils.java
  ql/src/java/org/apache/hadoop/hive/ql/parse/PTFTranslator.java
  ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
  ql/src/test/queries/clientpositive/ctas_colname.q
  ql/src/test/results/clientpositive/ctas_colname.q.out

To: JIRA, ashutoshc, navis
Cc: hbutani
, Added tests. Not changed aggregation columns., hive>create table summary as select *, sum(key), count(value) from src;
hive>select * from summary;
130091.0	500	130091.0	500

Such kind of query will generate only one row of result ? 
And the the first two column values are not correct ?
, hive (default)> select * from src_for_test;
	35
48	
100	100
hive (default)> select *, sum(key), count(value)  from src_for_test group by key, value ;
	35	0.0	1	0.0	1
100	100	100.0	1	100.0	1
48		48.0	1	48.0	1

two more columns generated!, [~caofangkun] As discussed earlier on this thread, I went ahead with the commit of the patch. Can you test  on top of trunk and please feel free to open new jiras if you think behavior is incorrect.

Committed to trunk. Thanks, Navis!, Integrated in Hive-trunk-h0.21 #2091 (See [https://builds.apache.org/job/Hive-trunk-h0.21/2091/])
    HIVE-4392 : Illogical InvalidObjectException throwed when use mulit aggregate functions with star columns  (Navis via Ashutosh Chauhan) (Revision 1480161)

     Result = FAILURE
hashutosh : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1480161
Files : 
* /hive/trunk/metastore/src/java/org/apache/hadoop/hive/metastore/HiveAlterHandler.java
* /hive/trunk/metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java
* /hive/trunk/metastore/src/java/org/apache/hadoop/hive/metastore/MetaStoreUtils.java
* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/PTFTranslator.java
* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
* /hive/trunk/ql/src/test/queries/clientpositive/ctas_colname.q
* /hive/trunk/ql/src/test/results/clientpositive/ctas_colname.q.out
, Integrated in Hive-trunk-hadoop2 #188 (See [https://builds.apache.org/job/Hive-trunk-hadoop2/188/])
    HIVE-4392 : Illogical InvalidObjectException throwed when use mulit aggregate functions with star columns  (Navis via Ashutosh Chauhan) (Revision 1480161)

     Result = ABORTED
hashutosh : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1480161
Files : 
* /hive/trunk/metastore/src/java/org/apache/hadoop/hive/metastore/HiveAlterHandler.java
* /hive/trunk/metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java
* /hive/trunk/metastore/src/java/org/apache/hadoop/hive/metastore/MetaStoreUtils.java
* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/PTFTranslator.java
* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
* /hive/trunk/ql/src/test/queries/clientpositive/ctas_colname.q
* /hive/trunk/ql/src/test/results/clientpositive/ctas_colname.q.out
, This issue has been fixed and released as part of 0.12 release. If you find further issues, please create a new jira and link it to this one.]