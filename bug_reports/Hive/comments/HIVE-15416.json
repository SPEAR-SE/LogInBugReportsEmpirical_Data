[That's probably because some code goes thru float or double. I remember seeing code like that in some conversion cases., You should use the following statement instead:
select CAST(decimal_col AS VARCHAR(38)) from test_hive_bug30;
The reason is UDFToString inherits UDF rather than GenericUDF. According to https://cwiki.apache.org/confluence/download/attachments/27362075/Hive_Decimal_Precision_Scale_Support.pdf, UDF does not support decimal with precision/scale and always assume maximum precision and scale. GenericUDFToVarchar address precision and scale gracefully., Thanks for your reply, I can confirm the approach you describe works. I have however two comments to it:
 - It does not look like a proper solution, but rather workaround. The user may not be aware of those UDF/GenericUDF subtleties and even in case he is, he still needs to treat the DECIMAL columns differently than other types, that can be cast to string without problems.
 - Is the VARCHAR size 38 enough to contain even the largest decimal values, possibly also including minus sign and decimal separator?
, Yes, it is fair to still consider it is a bug, as UDFToString is a builtin UDF and is implicitly invoked by Hive. We shall convert all builtin UDFs to GenericUDF. As for length of varchar, I should say it is varchar(41) to avoid the situation you described, the size is just a maximum.]