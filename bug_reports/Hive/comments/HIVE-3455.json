[284,285c282,283
<         double xavgOld = myagg.xavg;
<         double yavgOld = myagg.yavg;
---
>         double deltaX = vx - myagg.xavg;
>         double deltaY = vy - myagg.yavg;
287,288c285,286
<         myagg.xavg += (vx - xavgOld) / myagg.count;
<         myagg.yavg += (vy - yavgOld) / myagg.count;
---
>         myagg.xavg += deltaX / ((double) myagg.count);
>         myagg.yavg += deltaY / ((double) myagg.count);
290,292c288,290
<             myagg.covar += (vx - xavgOld) * (vy - myagg.yavg);
<             myagg.xvar += (vx - xavgOld) * (vx - myagg.xavg);
<             myagg.yvar += (vy - yavgOld) * (vy - myagg.yavg);
---
>             myagg.covar += deltaX * (vy - myagg.yavg);
>             myagg.xvar += deltaX * (vx - myagg.xavg);
>             myagg.yvar += deltaY * (vy - myagg.yavg);
345,350c343,351
<           myagg.xavg = (xavgA * nA + xavgB * nB) / myagg.count;
<           myagg.yavg = (yavgA * nA + yavgB * nB) / myagg.count;
<           myagg.xvar += xvarB + (xavgA - xavgB) * (xavgA - xavgB) * myagg.count;
<           myagg.yvar += yvarB + (yavgA - yavgB) * (yavgA - yavgB) * myagg.count;
<           myagg.covar +=
<               covarB + (xavgA - xavgB) * (yavgA - yavgB) * ((double) (nA * nB) / myagg.count);
---
>           double n=myagg.count;
>           double nn=nA*nB/n;
>           double dX = xavgA-xavgB;
>           double dY = yavgA-yavgB;
>           myagg.xavg = xavgA * nA / n + xavgB * nB / n;
>           myagg.yavg = yavgA * nA / n + yavgB * nB / n;
>           myagg.xvar  += xvarB  + dX * dX * nn ;
>           myagg.yvar  += yvarB  + dY * dY * nn ;
>           myagg.covar += covarB + dX * dY * nn;
, the test, the correct answer is 1.
hive> select * from max_corr ;
OK
1	2
2	4
3	6
Time taken: 2.304 seconds
hive> select corr(a,b) from max_corr ;
Total MapReduce jobs = 1
Launching Job 1 out of 1
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201207232322_2781, Tracking URL = http://*****/jobdetails.jsp?jobid=job_201207232322_2781
Kill Command = /usr/lib/hadoop/bin/hadoop job  -Dmapred.job.tracker=hdfs://***** -kill job_201207232322_2781
2012-09-12 10:04:17,663 Stage-1 map = 0%,  reduce = 0%
2012-09-12 10:04:20,681 Stage-1 map = 100%,  reduce = 0%
2012-09-12 10:04:27,720 Stage-1 map = 100%,  reduce = 33%
2012-09-12 10:04:28,728 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_201207232322_2781
OK
0.27586206896551724
Time taken: 15.088 seconds
hive> 
, I think your data file must be in error.

{noformat}
FROM (

select inline ( array( struct(1,2), struct(2,4), struct(3,6) ) ) as (x,y) from dummy limit 3

) b select corr(b.x,b.y) 

OK
0.9999999999999999
Time taken: 9.436 seconds

{noformat}

and 

{noformat}
hive> FROM (
    > 
    > select inline ( array( struct(1,3), struct(2,2), struct(3,1) ) ) as (x,y) from dummy limit 3
    > 
    > ) b select corr(b.x,b.y) ;

Mapred Local Task Succeeded . Convert the Join into MapJoin
OK
-0.9999999999999999
Time taken: 10.842 seconds

{noformat}

Looks good compared to. http://my.safaribooksonline.com/book/databases/sql/9780596155322/ansi-sql-aggregate-functions/id3490390

Please re-open if I am wrong., the whole point of the bug is that the MERGE part is wrong, not the MAP, you can't test it with just inline array, you have to have at least to pieces to merge in a reducer. please check again the formula in the merge part.
, the whole point of the bug is that the MERGE part is wrong, not the MAP, you can't test it with just inline array, you have to have at least to pieces to merge in a reducer. please check again the formula in the merge part., I will look into this more. You example uses a select * which does not have a reduce phase. So I do not see how your example produces that result., I do have a cluster with 26 nodes, select * just an example of a simple table.
The table was created by "create external table ... location ... ;"
For this table "select corr(a,b) from t;" hive starts 2 mappers and 1 reducer.
The unit test for this function doesn't cover all cases.
, Good catch I set the input format to NLineInput 

create table data6 (name string, x int, y int) stored as inputformat 'org.apache.hadoop.mapred.lib.NLineInputFormat' outputformat 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat';

This did indeed mess produce the wrongresults. Nice catch. Will patch shortly., Can you please attach your diff as something that will apply with patch -p0. I do not know how to apply your patch., the patch for the
src/ql/src/java/org/apache/hadoop/hive/ql/udf/generic, Patch needs a testcase. Maxim / Ed, if you guys are working on this, can you please add a testcase and update the patch?, Attached are a data file, a ".q" file and a ".q.out" file that exercise the corr merge problem.  The patch in this ticket passes this test.  (test correlates a variable with itself using a CLUSTER BY column), Clearing fix version. in hive the fix version is set after a patch is committed.
, Hi all,
I have dumped into the same issue. Maxim's patch is correct, I applied it and everything works correct
I'm pretty sure it must be included into trunk ASAP, because of current Hive's implementation is incorrect, Does Anybody work on including this path into release branches?, This is apparently a bug. Rebased patch with a test case and +1 for me., 

{color:green}Overall{color}: +1 all checks pass

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12617110/HIVE-3455.1.patch.txt

{color:green}SUCCESS:{color} +1 4458 tests passed

Test results: http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/525/testReport
Console output: http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/525/console

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12617110, Committed to trunk. Thanks Maxim!]