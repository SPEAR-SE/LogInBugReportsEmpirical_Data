[[~ekoifman] Can you take a look at WIP patch 1?, I think this needs some tests.  For example, 
_int index = Arrays.binarySearch(exceptions, txn);_should return -1 if txn is not found.
which means _if (abortedBits.get(index)) {_ will fail with some ArrayIndexOutOfBounds or something


ValidReadTxnList.isTxnRangeAborted() is doing (maxTxnId-minTxnId) binary searches.  Why not just do 1 for minTxnId and then use nextSetBit(int fromIndex) to find next aborted txn and see if it equals minTxnId + 1, etc.


Also, you don't need to override isTxnRangeAborted() ValidCompactorTxnList.

some javadoc on new methods would be useful
, For ValidReadTxnList.isTxnRangeAborted, I think I shouldn't have performed check for every txn in exceptions. Instead I should just scan every txn from min to max in the specified range, and for each of them, check if it's aborted by searching exceptions and the bitset. I corrected that. 

I think the override of isTxnRangeAborted in ValidCompactorTxnList is necessary. The reason is for ValidCompactorTxnList, "exceptions" includes aborted txns only (see TxnUtils.createValidCompactTxnList). So we don't maintain a bitset for it as it's not necessary. So in the implementation of that method we have a slight difference which is we omit the check against the bitset.

I will add JavaDoc and tests., using nextSetBig() is also linear but faster for cases where not all txn are aborted; you'd still want to do Binary Search to find the minTxn in the exceptions list
if there are no aborted txns, the BitSet is empty and "abortedBits.get(index)" is always false - that is why it's the same for both.

, OK, I agree the override for isTxnRangeAborted is not necessary. I also adopted the approach you suggested which is to use nextSetBit to check if an aborted transaction falls into the range between min and max., [~ekoifman] Can you take a look at patch 2?, you refactored ValidReadTxnList() c'tor and removed the sorting of exceptions - why?
writeToString() always creates 3 ':' - why does the deserializer need cases like _if (values.length < 3) {_

wouldn't be simpler to just serialize the BitSet as "0010110...." - it's very compact and the deserializer wouldn't have to sort and do multiple binary searches.... 

why does _isTxnAborted()_ need a binary search?  why not just look up the in the bitset?

_bitSet.set(0, bitSet.length()); // for ValidCompactorTxnList, everything in exceptio_ - shouldn't this turn all the bits ON?
Nit: seems like ValidCompactorTxnList() c'tor could do this  since it's always the case for compactor

, The sorting of exceptions in ValidReadTxnList is troublesome for the accompanying BitSet, as we have to sort the BitSet in the same manner. So I removed the sorting logic in the ctor and added "oder by txn_id" to TxnHandler.getOpenTxns so we don't need to worry about sorting later on.

It's true that we always have 3 ':'. But if some fields are missing, e.g. "1:2::", then String.split() will only return an array of size 2.

I do serialize the BitSet into a byte array before sending it over Thrift interface. After receiving it I convert it back to BitSet since the bit manipulation is convenient.

I need to binary search in isTxnAborted() to get the index for the txnid, then look up in the bitset using that index.

bitSet.set(0, bitSet.length()) does turn all the bits on, right?, 
bq. I do serialize the BitSet into a byte array before sending it over Thrift interface. After receiving it I convert it back to BitSet since the bit manipulation is convenient.

I meant in writeToString() - seems like that would make reading from string much simper/efficient

You are right about the other points, another thought: I think implementation of isTxnRangeAborted() is problematic
suppose we do an insert in Table1/part1 with txnid=5.  Then there is no activity on this table for a month.
Then there is another insert into Table1/part1 with txnid=1000000.
After compaction we get a delta_5_1000000.

so now this method is going to do 1M binary searches....

If (isAborted(minTxnId) && isAborted(maxTxnId) && (the number of on bits in BitSet between index of minTxnId and maxTxnId is max - min + 1) - then all txns in range in question are aborted - this gives ALL

I'm not sure how to do NONE/SOME efficiently, We can drop this:
{code}
    while (txnId <= maxTxnId) {
      firstAbortedTxnIndex = Arrays.binarySearch(exceptions, txnId);
      if (firstAbortedTxnIndex >= 0) {
        break;
      }
      txnId++;
    }
{code}
The main usage of above code is to locate the index for first aborted txn in the range so that we can save some unnecessary iterations when scanning the BitSet. But in your example which is very likely to be a common situation, this is not acceptable.

Considering the BitSet is not big (comparing to the gap between 5 and 1000000), we can just start from index 0 and scan thru the BitSet. I think this should be ok., patch 3 removes the binary search logic in isTxnRangeAborted as commented above., +1 patch 3 pending tests
Could you add a comment that the exception list is excepted the sorted when passed in ValidReadTxnList

, Added the comment for ValidTxnList.readFromString, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12865830/HIVE-16534.4.patch

{color:red}ERROR:{color} -1 due to build exiting with an error

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/4970/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/4970/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-4970/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Tests exited with: NonZeroExitCodeException
Command 'bash /data/hiveptest/working/scratch/source-prep.sh' failed with exit status 1 and output '+ date '+%Y-%m-%d %T.%3N'
2017-05-01 23:20:05.963
+ [[ -n /usr/lib/jvm/java-8-openjdk-amd64 ]]
+ export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
+ JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
+ export PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games
+ PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games
+ export 'ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m '
+ ANT_OPTS='-Xmx1g -XX:MaxPermSize=256m '
+ export 'MAVEN_OPTS=-Xmx1g '
+ MAVEN_OPTS='-Xmx1g '
+ cd /data/hiveptest/working/
+ tee /data/hiveptest/logs/PreCommit-HIVE-Build-4970/source-prep.txt
+ [[ false == \t\r\u\e ]]
+ mkdir -p maven ivy
+ [[ git = \s\v\n ]]
+ [[ git = \g\i\t ]]
+ [[ -z master ]]
+ [[ -d apache-github-source-source ]]
+ [[ ! -d apache-github-source-source/.git ]]
+ [[ ! -d apache-github-source-source ]]
+ date '+%Y-%m-%d %T.%3N'
2017-05-01 23:20:05.966
+ cd apache-github-source-source
+ git fetch origin
+ git reset --hard HEAD
HEAD is now at 2f79bd6 HIVE-16520: Cache hive metadata in metastore (Daniel Dai, Vaibhav Gumashta, reviewed by Thejas Nair)
+ git clean -f -d
+ git checkout master
Already on 'master'
Your branch is up-to-date with 'origin/master'.
+ git reset --hard origin/master
HEAD is now at 2f79bd6 HIVE-16520: Cache hive metadata in metastore (Daniel Dai, Vaibhav Gumashta, reviewed by Thejas Nair)
+ git merge --ff-only origin/master
Already up-to-date.
+ date '+%Y-%m-%d %T.%3N'
2017-05-01 23:20:11.973
+ patchCommandPath=/data/hiveptest/working/scratch/smart-apply-patch.sh
+ patchFilePath=/data/hiveptest/working/scratch/build.patch
+ [[ -f /data/hiveptest/working/scratch/build.patch ]]
+ chmod +x /data/hiveptest/working/scratch/smart-apply-patch.sh
+ /data/hiveptest/working/scratch/smart-apply-patch.sh /data/hiveptest/working/scratch/build.patch
error: patch failed: metastore/src/gen/thrift/gen-cpp/ThriftHiveMetastore.cpp:6055
error: metastore/src/gen/thrift/gen-cpp/ThriftHiveMetastore.cpp: patch does not apply
error: patch failed: metastore/src/gen/thrift/gen-php/metastore/ThriftHiveMetastore.php:15489
error: metastore/src/gen/thrift/gen-php/metastore/ThriftHiveMetastore.php: patch does not apply
error: patch failed: metastore/src/java/org/apache/hadoop/hive/metastore/txn/TxnUtils.java:51
error: metastore/src/java/org/apache/hadoop/hive/metastore/txn/TxnUtils.java: patch does not apply
The patch does not appear to apply with p0, p1, or p2
+ exit 1
'
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12865830 - PreCommit-HIVE-Build, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12865844/HIVE-16534.5.patch

{color:red}ERROR:{color} -1 due to build exiting with an error

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/4974/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/4974/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-4974/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Tests exited with: NonZeroExitCodeException
Command 'bash /data/hiveptest/working/scratch/source-prep.sh' failed with exit status 1 and output '+ date '+%Y-%m-%d %T.%3N'
2017-05-02 02:03:35.278
+ [[ -n /usr/lib/jvm/java-8-openjdk-amd64 ]]
+ export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
+ JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
+ export PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games
+ PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games
+ export 'ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m '
+ ANT_OPTS='-Xmx1g -XX:MaxPermSize=256m '
+ export 'MAVEN_OPTS=-Xmx1g '
+ MAVEN_OPTS='-Xmx1g '
+ cd /data/hiveptest/working/
+ tee /data/hiveptest/logs/PreCommit-HIVE-Build-4974/source-prep.txt
+ [[ false == \t\r\u\e ]]
+ mkdir -p maven ivy
+ [[ git = \s\v\n ]]
+ [[ git = \g\i\t ]]
+ [[ -z master ]]
+ [[ -d apache-github-source-source ]]
+ [[ ! -d apache-github-source-source/.git ]]
+ [[ ! -d apache-github-source-source ]]
+ date '+%Y-%m-%d %T.%3N'
2017-05-02 02:03:35.280
+ cd apache-github-source-source
+ git fetch origin
From https://github.com/apache/hive
   62fbdd8..5ab03cb  master     -> origin/master
+ git reset --hard HEAD
HEAD is now at 62fbdd8 Add license and notice file for storage-api
+ git clean -f -d
Removing metastore/scripts/upgrade/derby/040-HIVE-16399.derby.sql
Removing metastore/scripts/upgrade/mssql/025-HIVE-16399.mssql.sql
Removing metastore/scripts/upgrade/mysql/040-HIVE-16399.mysql.sql
Removing metastore/scripts/upgrade/oracle/040-HIVE-16399.oracle.sql
Removing metastore/scripts/upgrade/postgres/039-HIVE-16399.postgres.sql
+ git checkout master
Already on 'master'
Your branch is behind 'origin/master' by 2 commits, and can be fast-forwarded.
  (use "git pull" to update your local branch)
+ git reset --hard origin/master
HEAD is now at 5ab03cb HIVE-16524: Remove the redundant item type in hiveserver2.jsp and QueryProfileTmpl.jamon (ZhangBing via Xuefu)
+ git merge --ff-only origin/master
Already up-to-date.
+ date '+%Y-%m-%d %T.%3N'
2017-05-02 02:03:40.406
+ patchCommandPath=/data/hiveptest/working/scratch/smart-apply-patch.sh
+ patchFilePath=/data/hiveptest/working/scratch/build.patch
+ [[ -f /data/hiveptest/working/scratch/build.patch ]]
+ chmod +x /data/hiveptest/working/scratch/smart-apply-patch.sh
+ /data/hiveptest/working/scratch/smart-apply-patch.sh /data/hiveptest/working/scratch/build.patch
Going to apply patch with: patch -p0
patching file common/src/java/org/apache/hadoop/hive/common/ValidCompactorTxnList.java
patching file common/src/java/org/apache/hadoop/hive/common/ValidReadTxnList.java
patching file common/src/java/org/apache/hadoop/hive/common/ValidTxnList.java
patching file common/src/test/org/apache/hadoop/hive/common/TestValidReadTxnList.java
patching file itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/txn/compactor/TestCompactor.java
patching file metastore/if/hive_metastore.thrift
patching file metastore/src/gen/thrift/gen-cpp/ThriftHiveMetastore.cpp
patching file metastore/src/gen/thrift/gen-cpp/hive_metastore_types.cpp
patching file metastore/src/gen/thrift/gen-cpp/hive_metastore_types.h
patching file metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/GetOpenTxnsResponse.java
patching file metastore/src/gen/thrift/gen-php/metastore/ThriftHiveMetastore.php
patching file metastore/src/gen/thrift/gen-php/metastore/Types.php
patching file metastore/src/gen/thrift/gen-py/hive_metastore/ttypes.py
patching file metastore/src/gen/thrift/gen-rb/hive_metastore_types.rb
patching file metastore/src/java/org/apache/hadoop/hive/metastore/txn/TxnHandler.java
patching file metastore/src/java/org/apache/hadoop/hive/metastore/txn/TxnUtils.java
patching file metastore/src/test/org/apache/hadoop/hive/metastore/txn/TestValidCompactorTxnList.java
patching file ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java
+ [[ maven == \m\a\v\e\n ]]
+ rm -rf /data/hiveptest/working/maven/org/apache/hive
+ mvn -B clean install -DskipTests -T 4 -q -Dmaven.repo.local=/data/hiveptest/working/maven
[ERROR] COMPILATION ERROR : 
[ERROR] /data/hiveptest/working/apache-github-source-source/common/src/java/org/apache/hadoop/hive/common/jsonexplain/tez/TezJsonParserUtils.java:[27,8] class DagJsonParserUtils is public, should be declared in a file named DagJsonParserUtils.java
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.6.1:compile (default-compile) on project hive-common: Compilation failure
[ERROR] /data/hiveptest/working/apache-github-source-source/common/src/java/org/apache/hadoop/hive/common/jsonexplain/tez/TezJsonParserUtils.java:[27,8] class DagJsonParserUtils is public, should be declared in a file named DagJsonParserUtils.java
[ERROR] -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn <goals> -rf :hive-common
+ exit 1
'
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12865844 - PreCommit-HIVE-Build, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12865844/HIVE-16534.5.patch

{color:red}ERROR:{color} -1 due to build exiting with an error

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/4977/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/4977/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-4977/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Tests exited with: NonZeroExitCodeException
Command 'bash /data/hiveptest/working/scratch/source-prep.sh' failed with exit status 1 and output '+ date '+%Y-%m-%d %T.%3N'
2017-05-02 02:07:19.555
+ [[ -n /usr/lib/jvm/java-8-openjdk-amd64 ]]
+ export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
+ JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
+ export PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games
+ PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games
+ export 'ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m '
+ ANT_OPTS='-Xmx1g -XX:MaxPermSize=256m '
+ export 'MAVEN_OPTS=-Xmx1g '
+ MAVEN_OPTS='-Xmx1g '
+ cd /data/hiveptest/working/
+ tee /data/hiveptest/logs/PreCommit-HIVE-Build-4977/source-prep.txt
+ [[ false == \t\r\u\e ]]
+ mkdir -p maven ivy
+ [[ git = \s\v\n ]]
+ [[ git = \g\i\t ]]
+ [[ -z master ]]
+ [[ -d apache-github-source-source ]]
+ [[ ! -d apache-github-source-source/.git ]]
+ [[ ! -d apache-github-source-source ]]
+ date '+%Y-%m-%d %T.%3N'
2017-05-02 02:07:19.557
+ cd apache-github-source-source
+ git fetch origin
+ git reset --hard HEAD
HEAD is now at 5ab03cb HIVE-16524: Remove the redundant item type in hiveserver2.jsp and QueryProfileTmpl.jamon (ZhangBing via Xuefu)
+ git clean -f -d
Removing metastore/scripts/upgrade/hive/
Removing ql/src/test/queries/clientpositive/sysdb.q
Removing ql/src/test/results/clientpositive/llap/sysdb.q.out
+ git checkout master
Already on 'master'
Your branch is up-to-date with 'origin/master'.
+ git reset --hard origin/master
HEAD is now at 5ab03cb HIVE-16524: Remove the redundant item type in hiveserver2.jsp and QueryProfileTmpl.jamon (ZhangBing via Xuefu)
+ git merge --ff-only origin/master
Already up-to-date.
+ date '+%Y-%m-%d %T.%3N'
2017-05-02 02:07:20.082
+ patchCommandPath=/data/hiveptest/working/scratch/smart-apply-patch.sh
+ patchFilePath=/data/hiveptest/working/scratch/build.patch
+ [[ -f /data/hiveptest/working/scratch/build.patch ]]
+ chmod +x /data/hiveptest/working/scratch/smart-apply-patch.sh
+ /data/hiveptest/working/scratch/smart-apply-patch.sh /data/hiveptest/working/scratch/build.patch
Going to apply patch with: patch -p0
patching file common/src/java/org/apache/hadoop/hive/common/ValidCompactorTxnList.java
patching file common/src/java/org/apache/hadoop/hive/common/ValidReadTxnList.java
patching file common/src/java/org/apache/hadoop/hive/common/ValidTxnList.java
patching file common/src/test/org/apache/hadoop/hive/common/TestValidReadTxnList.java
patching file itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/txn/compactor/TestCompactor.java
patching file metastore/if/hive_metastore.thrift
patching file metastore/src/gen/thrift/gen-cpp/ThriftHiveMetastore.cpp
patching file metastore/src/gen/thrift/gen-cpp/hive_metastore_types.cpp
patching file metastore/src/gen/thrift/gen-cpp/hive_metastore_types.h
patching file metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/GetOpenTxnsResponse.java
patching file metastore/src/gen/thrift/gen-php/metastore/ThriftHiveMetastore.php
patching file metastore/src/gen/thrift/gen-php/metastore/Types.php
patching file metastore/src/gen/thrift/gen-py/hive_metastore/ttypes.py
patching file metastore/src/gen/thrift/gen-rb/hive_metastore_types.rb
patching file metastore/src/java/org/apache/hadoop/hive/metastore/txn/TxnHandler.java
patching file metastore/src/java/org/apache/hadoop/hive/metastore/txn/TxnUtils.java
patching file metastore/src/test/org/apache/hadoop/hive/metastore/txn/TestValidCompactorTxnList.java
patching file ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java
+ [[ maven == \m\a\v\e\n ]]
+ rm -rf /data/hiveptest/working/maven/org/apache/hive
+ mvn -B clean install -DskipTests -T 4 -q -Dmaven.repo.local=/data/hiveptest/working/maven
[ERROR] COMPILATION ERROR : 
[ERROR] /data/hiveptest/working/apache-github-source-source/common/src/java/org/apache/hadoop/hive/common/jsonexplain/tez/TezJsonParserUtils.java:[27,8] class DagJsonParserUtils is public, should be declared in a file named DagJsonParserUtils.java
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.6.1:compile (default-compile) on project hive-common: Compilation failure
[ERROR] /data/hiveptest/working/apache-github-source-source/common/src/java/org/apache/hadoop/hive/common/jsonexplain/tez/TezJsonParserUtils.java:[27,8] class DagJsonParserUtils is public, should be declared in a file named DagJsonParserUtils.java
[ERROR] -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn <goals> -rf :hive-common
+ exit 1
'
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12865844 - PreCommit-HIVE-Build, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12865844/HIVE-16534.5.patch

{color:green}SUCCESS:{color} +1 due to 3 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 257 failed/errored test(s), 10634 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestAccumuloCliDriver.testCliDriver[accumulo_index] (batchId=225)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_join] (batchId=15)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_mapjoin] (batchId=10)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_subquery] (batchId=37)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_table_stats] (batchId=50)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_vectorization] (batchId=61)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_vectorization_partition] (batchId=68)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[acid_vectorization_project] (batchId=18)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[authorization_delete] (batchId=77)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[authorization_delete_own_table] (batchId=62)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[authorization_update] (batchId=8)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[authorization_update_own_table] (batchId=73)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[autoColumnStats_4] (batchId=12)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[dbtxnmgr_showlocks] (batchId=74)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[delete_all_non_partitioned] (batchId=27)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[delete_all_partitioned] (batchId=27)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[delete_orig_table] (batchId=38)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[delete_tmp_table] (batchId=48)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[delete_where_no_match] (batchId=27)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[delete_where_non_partitioned] (batchId=37)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[delete_where_partitioned] (batchId=38)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[delete_whole_partition] (batchId=9)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_acid_dynamic_partition] (batchId=19)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_nonacid_from_acid] (batchId=69)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_orig_table] (batchId=58)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_update_delete] (batchId=80)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_values_dynamic_partitioned] (batchId=71)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_values_non_partitioned] (batchId=19)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_values_orig_table] (batchId=54)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_values_orig_table_use_metadata] (batchId=59)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_values_partitioned] (batchId=71)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_values_tmp_table] (batchId=4)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[llap_acid] (batchId=75)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[llap_reader] (batchId=7)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[masking_acid_no_masking] (batchId=22)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[orc_ppd_exception] (batchId=32)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[row__id] (batchId=73)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[transform_acid] (batchId=19)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_after_multiple_inserts] (batchId=64)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_after_multiple_inserts_special_characters] (batchId=68)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_all_non_partitioned] (batchId=7)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_all_partitioned] (batchId=49)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_all_types] (batchId=17)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_orig_table] (batchId=58)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_tmp_table] (batchId=34)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_two_cols] (batchId=20)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_where_no_match] (batchId=19)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_where_non_partitioned] (batchId=15)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[update_where_partitioned] (batchId=58)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[vector_acid3] (batchId=26)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[vector_join_part_col_char] (batchId=22)
org.apache.hadoop.hive.cli.TestEncryptedHDFSCliDriver.testCliDriver[encryption_insert_partition_dynamic] (batchId=163)
org.apache.hadoop.hive.cli.TestEncryptedHDFSCliDriver.testCliDriver[encryption_insert_partition_static] (batchId=160)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[acid_bucket_pruning] (batchId=137)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[acid_globallimit] (batchId=147)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[acid_vectorization_missing_cols] (batchId=146)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[delete_all_non_partitioned] (batchId=147)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[delete_all_partitioned] (batchId=147)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[delete_tmp_table] (batchId=152)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[delete_where_no_match] (batchId=147)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[delete_where_non_partitioned] (batchId=149)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[delete_where_partitioned] (batchId=149)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[delete_whole_partition] (batchId=143)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[dynamic_semijoin_reduction_3] (batchId=156)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[dynpart_sort_optimization_acid] (batchId=150)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[insert_orig_table] (batchId=154)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[insert_update_delete] (batchId=158)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[insert_values_dynamic_partitioned] (batchId=156)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[insert_values_non_partitioned] (batchId=145)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[insert_values_partitioned] (batchId=156)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[insert_values_tmp_table] (batchId=142)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[join_acid_non_acid] (batchId=157)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_orc_acid_part] (batchId=147)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_orc_acid_part_update] (batchId=155)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_orc_acid_table] (batchId=149)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_orc_acid_table_update] (batchId=154)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_orc_acidvec_part] (batchId=154)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_orc_acidvec_part_update] (batchId=144)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_orc_acidvec_table] (batchId=158)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_orc_acidvec_table_update] (batchId=142)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_after_multiple_inserts] (batchId=155)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_all_non_partitioned] (batchId=143)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_all_partitioned] (batchId=152)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_all_types] (batchId=144)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_tmp_table] (batchId=149)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_two_cols] (batchId=145)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_where_no_match] (batchId=145)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_where_non_partitioned] (batchId=144)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_where_partitioned] (batchId=154)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_acid3] (batchId=146)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_if_expr] (batchId=143)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[delete_orig_table] (batchId=96)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_5] (batchId=96)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainuser_3] (batchId=96)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[update_orig_table] (batchId=96)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[vector_join_part_col_char] (batchId=96)
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[acid_overwrite] (batchId=88)
org.apache.hadoop.hive.metastore.TestHiveMetaStoreTxns.stringifyValidTxns (batchId=209)
org.apache.hadoop.hive.metastore.TestHiveMetaStoreTxns.testOpenTxnNotExcluded (batchId=209)
org.apache.hadoop.hive.metastore.TestHiveMetaStoreTxns.testTxnRange (batchId=209)
org.apache.hadoop.hive.metastore.TestHiveMetaStoreTxns.testTxns (batchId=209)
org.apache.hadoop.hive.metastore.txn.TestCompactionTxnHandler.testMarkCleanedCleansTxnsAndTxnComponents (batchId=244)
org.apache.hadoop.hive.metastore.txn.TestTxnHandler.testAbortTxn (batchId=244)
org.apache.hadoop.hive.metastore.txn.TestTxnHandler.testOpenTxn (batchId=244)
org.apache.hadoop.hive.metastore.txn.TestTxnHandler.testValidTxnsEmpty (batchId=244)
org.apache.hadoop.hive.metastore.txn.TestTxnHandler.testValidTxnsNoneOpen (batchId=244)
org.apache.hadoop.hive.metastore.txn.TestTxnHandler.testValidTxnsSomeOpen (batchId=244)
org.apache.hadoop.hive.metastore.txn.TestTxnHandlerNoConnectionPool.testOpenTxn (batchId=244)
org.apache.hadoop.hive.metastore.txn.TestValidCompactorTxnList.writeToString (batchId=193)
org.apache.hadoop.hive.ql.TestAcidOnTez.testMapJoinOnMR (batchId=210)
org.apache.hadoop.hive.ql.TestAcidOnTez.testMapJoinOnTez (batchId=210)
org.apache.hadoop.hive.ql.TestAcidOnTez.testMergeJoinOnMR (batchId=210)
org.apache.hadoop.hive.ql.TestAcidOnTez.testMergeJoinOnTez (batchId=210)
org.apache.hadoop.hive.ql.TestAcidOnTezWithSplitUpdate.testMapJoinOnMR (batchId=213)
org.apache.hadoop.hive.ql.TestAcidOnTezWithSplitUpdate.testMapJoinOnTez (batchId=213)
org.apache.hadoop.hive.ql.TestAcidOnTezWithSplitUpdate.testMergeJoinOnMR (batchId=213)
org.apache.hadoop.hive.ql.TestAcidOnTezWithSplitUpdate.testMergeJoinOnTez (batchId=213)
org.apache.hadoop.hive.ql.TestTxnCommands.testDelete (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands.testDeleteIn (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands.testErrors (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands.testExplicitRollback (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands.testImplicitRollback (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands.testMergeCardinalityViolation (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands.testMergeCase (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands.testMergeDeleteUpdate (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands.testMergeType2SCD01 (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands.testMergeType2SCD02 (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands.testMergeUpdateDelete (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands.testMergeUpdateDeleteNoCardCheck (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands.testMultipleDelete (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands.testMultipleInserts (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands.testQuotedIdentifier (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands.testQuotedIdentifier2 (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands.testReadMyOwnInsert (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands.testSimpleAcidInsert (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands.testTimeOutReaper (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands.testUpdateDeleteOfInserts (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands.testUpdateOfInserts (batchId=277)
org.apache.hadoop.hive.ql.TestTxnCommands2.testACIDwithSchemaEvolutionAndCompaction (batchId=265)
org.apache.hadoop.hive.ql.TestTxnCommands2.testAcidWithSchemaEvolution (batchId=265)
org.apache.hadoop.hive.ql.TestTxnCommands2.testAlterTable (batchId=265)
org.apache.hadoop.hive.ql.TestTxnCommands2.testBucketizedInputFormat (batchId=265)
org.apache.hadoop.hive.ql.TestTxnCommands2.testCompactWithDelete (batchId=265)
org.apache.hadoop.hive.ql.TestTxnCommands2.testDeleteIn (batchId=265)
org.apache.hadoop.hive.ql.TestTxnCommands2.testDynamicPartitionsMerge (batchId=265)
org.apache.hadoop.hive.ql.TestTxnCommands2.testDynamicPartitionsMerge2 (batchId=265)
org.apache.hadoop.hive.ql.TestTxnCommands2.testETLSplitStrategyForACID (batchId=265)
org.apache.hadoop.hive.ql.TestTxnCommands2.testFailHeartbeater (batchId=265)
org.apache.hadoop.hive.ql.TestTxnCommands2.testFileSystemUnCaching (batchId=265)
org.apache.hadoop.hive.ql.TestTxnCommands2.testInitiatorWithMultipleFailedCompactions (batchId=265)
org.apache.hadoop.hive.ql.TestTxnCommands2.testMerge (batchId=265)
org.apache.hadoop.hive.ql.TestTxnCommands2.testMerge2 (batchId=265)
org.apache.hadoop.hive.ql.TestTxnCommands2.testMerge3 (batchId=265)
org.apache.hadoop.hive.ql.TestTxnCommands2.testMergeWithPredicate (batchId=265)
org.apache.hadoop.hive.ql.TestTxnCommands2.testMultiInsertStatement (batchId=265)
org.apache.hadoop.hive.ql.TestTxnCommands2.testNoHistory (batchId=265)
org.apache.hadoop.hive.ql.TestTxnCommands2.testNonAcidToAcidConversion1 (batchId=265)
org.apache.hadoop.hive.ql.TestTxnCommands2.testNonAcidToAcidConversion2 (batchId=265)
org.apache.hadoop.hive.ql.TestTxnCommands2.testNonAcidToAcidConversion3 (batchId=265)
org.apache.hadoop.hive.ql.TestTxnCommands2.testOrcNoPPD (batchId=265)
org.apache.hadoop.hive.ql.TestTxnCommands2.testOrcPPD (batchId=265)
org.apache.hadoop.hive.ql.TestTxnCommands2.testOriginalFileReaderWhenNonAcidConvertedToAcid (batchId=265)
org.apache.hadoop.hive.ql.TestTxnCommands2.testSimpleRead (batchId=265)
org.apache.hadoop.hive.ql.TestTxnCommands2.testUpdateMixedCase (batchId=265)
org.apache.hadoop.hive.ql.TestTxnCommands2.updateDeletePartitioned (batchId=265)
org.apache.hadoop.hive.ql.TestTxnCommands2.writeBetweenWorkerAndCleaner (batchId=265)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testACIDwithSchemaEvolutionAndCompaction (batchId=275)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testAcidWithSchemaEvolution (batchId=275)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testAlterTable (batchId=275)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testBucketizedInputFormat (batchId=275)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testCompactWithDelete (batchId=275)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testDeleteIn (batchId=275)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testETLSplitStrategyForACID (batchId=275)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testFailHeartbeater (batchId=275)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testFileSystemUnCaching (batchId=275)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testInitiatorWithMultipleFailedCompactions (batchId=275)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testMerge2 (batchId=275)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testMerge3 (batchId=275)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testMultiInsertStatement (batchId=275)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testNoHistory (batchId=275)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testNonAcidToAcidConversion1 (batchId=275)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testNonAcidToAcidConversion2 (batchId=275)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testNonAcidToAcidConversion3 (batchId=275)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testOrcNoPPD (batchId=275)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testOrcPPD (batchId=275)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testOriginalFileReaderWhenNonAcidConvertedToAcid (batchId=275)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testSimpleRead (batchId=275)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testUpdateMixedCase (batchId=275)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.updateDeletePartitioned (batchId=275)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.writeBetweenWorkerAndCleaner (batchId=275)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testACIDwithSchemaEvolutionAndCompaction (batchId=272)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testAcidWithSchemaEvolution (batchId=272)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testAlterTable (batchId=272)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testBucketizedInputFormat (batchId=272)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testCompactWithDelete (batchId=272)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testDeleteIn (batchId=272)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testETLSplitStrategyForACID (batchId=272)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testFailHeartbeater (batchId=272)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testFileSystemUnCaching (batchId=272)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testInitiatorWithMultipleFailedCompactions (batchId=272)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testMerge2 (batchId=272)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testMerge3 (batchId=272)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testMultiInsertStatement (batchId=272)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testNoHistory (batchId=272)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testNonAcidToAcidConversion1 (batchId=272)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testNonAcidToAcidConversion2 (batchId=272)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testNonAcidToAcidConversion3 (batchId=272)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testOrcNoPPD (batchId=272)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testOrcPPD (batchId=272)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testOriginalFileReaderWhenNonAcidConvertedToAcid (batchId=272)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testSimpleRead (batchId=272)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testUpdateMixedCase (batchId=272)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.updateDeletePartitioned (batchId=272)
org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.writeBetweenWorkerAndCleaner (batchId=272)
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.checkExpectedLocks2 (batchId=276)
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testCompletedTxnComponents (batchId=276)
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testDynamicPartitionInsert (batchId=276)
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testMerge3Way01 (batchId=276)
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testMerge3Way02 (batchId=276)
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testMergePartitioned01 (batchId=276)
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testMergePartitioned02 (batchId=276)
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testMergeUnpartitioned01 (batchId=276)
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testMergeUnpartitioned02 (batchId=276)
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testMetastoreTablesCleanup (batchId=276)
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testMultiInsert (batchId=276)
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testWriteSetTracking10 (batchId=276)
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testWriteSetTracking11 (batchId=276)
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testWriteSetTracking3 (batchId=276)
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testWriteSetTracking5 (batchId=276)
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testWriteSetTracking7 (batchId=276)
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testWriteSetTracking8 (batchId=276)
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testWriteSetTracking9 (batchId=276)
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.updateSelectUpdate (batchId=276)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.dynamicPartitioningDelete (batchId=211)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.dynamicPartitioningInsert (batchId=211)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.dynamicPartitioningUpdate (batchId=211)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.schemaEvolutionAddColDynamicPartitioningInsert (batchId=211)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.schemaEvolutionAddColDynamicPartitioningUpdate (batchId=211)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.testMinorCompactionForSplitUpdateWithInsertsAndDeletes (batchId=211)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.testMinorCompactionForSplitUpdateWithOnlyInserts (batchId=211)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.testStatsAfterCompactionPartTbl (batchId=211)
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.testTableProperties (batchId=211)
org.apache.hadoop.hive.ql.txn.compactor.TestInitiator.cleanEmptyAbortedTxns (batchId=253)
org.apache.hive.hcatalog.streaming.TestStreaming.testInterleavedTransactionBatchCommits (batchId=187)
org.apache.hive.hcatalog.streaming.TestStreaming.testMultipleTransactionBatchCommits (batchId=187)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchAbort (batchId=187)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchAbortAndCommit (batchId=187)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_Delimited (batchId=187)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_DelimitedUGI (batchId=187)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_Json (batchId=187)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_Regex (batchId=187)
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_RegexUGI (batchId=187)
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testMulti (batchId=187)
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testTransactionBatchAbort (batchId=187)
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testTransactionBatchCommitPartitioned (batchId=187)
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testTransactionBatchCommitUnpartitioned (batchId=187)
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testUpdatesAndDeletes (batchId=187)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/4982/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/4982/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-4982/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 257 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12865844 - PreCommit-HIVE-Build, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12865883/HIVE-16534.6.patch

{color:green}SUCCESS:{color} +1 due to 3 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 5 failed/errored test(s), 10635 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestAccumuloCliDriver.testCliDriver[accumulo_index] (batchId=225)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_if_expr] (batchId=143)
org.apache.hadoop.hive.metastore.TestHiveMetaStoreTxns.stringifyValidTxns (batchId=209)
org.apache.hadoop.hive.metastore.TestHiveMetaStoreTxns.testTxnRange (batchId=209)
org.apache.hadoop.hive.metastore.txn.TestValidCompactorTxnList.writeToString (batchId=193)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/4987/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/4987/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-4987/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 5 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12865883 - PreCommit-HIVE-Build, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12865883/HIVE-16534.6.patch

{color:green}SUCCESS:{color} +1 due to 3 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 5 failed/errored test(s), 10637 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestAccumuloCliDriver.testCliDriver[accumulo_index] (batchId=225)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_if_expr] (batchId=143)
org.apache.hadoop.hive.metastore.TestHiveMetaStoreTxns.stringifyValidTxns (batchId=209)
org.apache.hadoop.hive.metastore.TestHiveMetaStoreTxns.testTxnRange (batchId=209)
org.apache.hadoop.hive.metastore.txn.TestValidCompactorTxnList.writeToString (batchId=193)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/4998/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/4998/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-4998/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 5 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12865883 - PreCommit-HIVE-Build, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12866005/HIVE-16534.7.patch

{color:green}SUCCESS:{color} +1 due to 4 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 3 failed/errored test(s), 10637 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestAccumuloCliDriver.testCliDriver[accumulo_index] (batchId=225)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[ppd_windowing2] (batchId=10)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_if_expr] (batchId=143)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/5000/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/5000/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-5000/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 3 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12866005 - PreCommit-HIVE-Build, Committed patch 7 to master. Thanks Eugene for the review., Hive 3.0.0 has been released so closing this jira.]