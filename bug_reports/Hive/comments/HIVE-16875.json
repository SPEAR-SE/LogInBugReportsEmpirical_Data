[The explain dependency for hive MR and HOS is different in HIVE 1.1:
Spark:
{"input_partitions":[{"partitionName":"default@j1part@b=1"}],"input_tables":[{"tablename":"default@jview","tabletype":"VIRTUAL_VIEW"},{"tablename":"default@j1part","tabletype":"MANAGED_TABLE","tableParents":"[default@jview]"}]}

MR:
{"input_partitions":[{"partitionParents":"[default@jview]","partitionName":"default@j1part@b=1"}],"input_tables":[{"tablename":"default@jview","tabletype":"VIRTUAL_VIEW"},{"tablename":"default@j1part","tabletype":"MANAGED_TABLE","tableParents":"[default@jview]"}]} 

For spark, there is missing partitionParents which caused the issue. , Fix the issue by including parent information in alias. , 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12872772/HIVE-16875.1.patch

{color:green}SUCCESS:{color} +1 due to 1 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 51 failed/errored test(s), 10831 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[partition_wise_fileformat6] (batchId=7)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[orc_ppd_basic] (batchId=140)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_if_expr] (batchId=145)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=232)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query16] (batchId=232)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query94] (batchId=232)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[auto_join_reordering_values] (batchId=103)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[auto_sortmerge_join_12] (batchId=114)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[auto_sortmerge_join_1] (batchId=119)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[auto_sortmerge_join_3] (batchId=100)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[auto_sortmerge_join_4] (batchId=126)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[auto_sortmerge_join_5] (batchId=137)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[auto_sortmerge_join_7] (batchId=138)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[auto_sortmerge_join_8] (batchId=132)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[bucket_map_join_spark1] (batchId=128)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[bucket_map_join_spark2] (batchId=101)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[bucket_map_join_spark3] (batchId=119)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[bucket_map_join_spark4] (batchId=100)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[bucketmapjoin1] (batchId=136)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[bucketmapjoin2] (batchId=101)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[bucketmapjoin3] (batchId=119)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[bucketmapjoin4] (batchId=100)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[filter_join_breaktask] (batchId=132)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[groupby_map_ppr] (batchId=104)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[groupby_map_ppr_multi_distinct] (batchId=121)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[groupby_ppr] (batchId=113)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[groupby_ppr_multi_distinct] (batchId=124)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[groupby_sort_1_23] (batchId=134)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[groupby_sort_skew_1_23] (batchId=104)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[join17] (batchId=130)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[join26] (batchId=108)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[join32] (batchId=108)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[join32_lessSize] (batchId=103)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[join33] (batchId=107)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[join34] (batchId=130)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[join35] (batchId=127)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[join9] (batchId=120)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[join_filters_overlap] (batchId=115)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[louter_join_ppr] (batchId=118)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[mapjoin_mapjoin] (batchId=121)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[optimize_nullscan] (batchId=134)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[outer_join_ppr] (batchId=109)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[pcr] (batchId=125)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[ppd_join_filter] (batchId=124)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[router_join_ppr] (batchId=134)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[smb_mapjoin_15] (batchId=132)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[transform_ppr1] (batchId=106)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[transform_ppr2] (batchId=118)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union22] (batchId=106)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union24] (batchId=125)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union_ppr] (batchId=108)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/5629/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/5629/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-5629/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 51 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12872772 - PreCommit-HIVE-Build, Second patch to fix the test results for spark, and add new test to spark unit test, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12873552/HIVE-16875.2.patch

{color:green}SUCCESS:{color} +1 due to 1 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 15 failed/errored test(s), 10835 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestBeeLineDriver.testCliDriver[materialized_view_create_rewrite] (batchId=238)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[orc_ppd_basic] (batchId=141)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[tez_smb_main] (batchId=150)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[delete_orig_table] (batchId=98)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[hybridgrace_hashjoin_1] (batchId=98)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=233)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query16] (batchId=233)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query23] (batchId=233)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query94] (batchId=233)
org.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testBootstrapFunctionReplication (batchId=217)
org.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testCreateFunctionIncrementalReplication (batchId=217)
org.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testCreateFunctionWithFunctionBinaryJarsOnHDFS (batchId=217)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema (batchId=178)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema (batchId=178)
org.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation (batchId=178)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/5681/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/5681/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-5681/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 15 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12873552 - PreCommit-HIVE-Build, The failures are not related. [~xuefuz], [~csun] , [~aihuaxu] could you review the change ? Thanks, [~ychena] You are saying the alias in context.parseContext.getTopOps() and getConf().getAlias() are different which causes we are retrieving incorrect partition info later?

, Yes, they are different. The TS operator getConf.getAlias only has table name in it. context.parseContext.getTopOps()'s keys are the aliases with view information. , I'm wondering if the alias from Conf and parseContext should be the same? Do you know why they are not the same? , AFAIK: they are sometimes are different:
Following is from hive comment in GenSparkProcContext.java: 
 // Alias to operator map, from the semantic analyzer.
  // This is necessary as sometimes semantic analyzer's mapping is different than operator's own alias.
  public final Map<String, Operator<? extends OperatorDesc>> topOps;

And it is what I saw when debugging. 

In SemanticAnalyzer.java:
private Operator genTablePlan(String alias, QB qb) throws SemanticException {

String alias_id = getAliasId(alias, qb);

.....
 // Create the root of the operator tree
      TableScanDesc tsDesc = new TableScanDesc(alias, vcList, tab);
      setupStats(tsDesc, qb.getParseInfo(), tab, alias, rwsch);


....
      top = putOpInsertMap(OperatorFactory.get(tsDesc,
          new RowSchema(rwsch.getColumnInfos())), rwsch);

...
     // Add this to the list of top operators - we always start from a table
      // scan
      topOps.put(alias_id, top);


If alias != alias_id, then the conf (TableScanDesc) is different from topOps's key
, I see. We are expecting an alias_id here rather than an alias. 

nit: maybe we can change alias to alias_id and the same in the function {{setupMapWork(MapWork mapWork, GenSparkProcContext context, PrunedPartitionList partitions, TableScanOperator root, String alias)}} to be clear.

Otherwise, the change looks good to me. +1. , Attach patch 3 with changing alias to alias_id., 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12873738/HIVE-16875.3.patch

{color:green}SUCCESS:{color} +1 due to 1 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 14 failed/errored test(s), 10838 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestBeeLineDriver.testCliDriver[create_merge_compressed] (batchId=238)
org.apache.hadoop.hive.cli.TestBeeLineDriver.testCliDriver[insert_overwrite_local_directory_1] (batchId=238)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[tez_smb_main] (batchId=150)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=233)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query16] (batchId=233)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query94] (batchId=233)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union24] (batchId=125)
org.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testBootstrapFunctionReplication (batchId=217)
org.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testCreateFunctionIncrementalReplication (batchId=217)
org.apache.hadoop.hive.ql.parse.TestReplicationScenariosAcrossInstances.testCreateFunctionWithFunctionBinaryJarsOnHDFS (batchId=217)
org.apache.hadoop.hive.ql.security.TestStorageBasedMetastoreAuthorizationProvider.testSimplePrivileges (batchId=220)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema (batchId=178)
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema (batchId=178)
org.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation (batchId=178)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/5696/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/5696/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-5696/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 14 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12873738 - PreCommit-HIVE-Build, Committed the fix to master and branch-2. Thanks [~aihuaxu] for reviewing the code., Hive 3.0.0 has been released so closing this jira.]