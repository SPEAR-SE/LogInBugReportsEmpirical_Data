[It seems ReusableRowContainer iterator should convert LazyObjects to StandardObjects, as other join operators did. 

Please let me know which qfile I can use to add more unit tests., 

{color:red}Overall{color}: -1 at least one tests failed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12733263/HIVE-10729.1.patch

{color:red}ERROR:{color} -1 due to 2 failed/errored test(s), 8943 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestEncryptedHDFSCliDriver.testCliDriver_encryption_insert_partition_static
org.apache.hive.hcatalog.hbase.TestPigHBaseStorageHandler.org.apache.hive.hcatalog.hbase.TestPigHBaseStorageHandler
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/3919/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/3919/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-3919/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 2 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12733263 - PreCommit-HIVE-TRUNK-Build, The unit test failures seem irrelevant to this patch. , [~sershe] Can you take a look please?, +1. Nit - can you pre-size the array list to fields size?, Yes. Will do. , added pre-size the array list to fields size, 

{color:red}Overall{color}: -1 at least one tests failed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12734209/HIVE-10729.2.patch

{color:red}ERROR:{color} -1 due to 1 failed/errored test(s), 8965 tests executed
*Failed tests:*
{noformat}
org.apache.hive.hcatalog.hbase.TestPigHBaseStorageHandler.org.apache.hive.hcatalog.hbase.TestPigHBaseStorageHandler
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/3969/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/3969/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-3969/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 1 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12734209 - PreCommit-HIVE-TRUNK-Build, The above unit test failure seems not relevant to this patch. , I tried this patch with Hive 1.2.0 and I am still getting this error.... 

Caused by: java.lang.ClassCastException: org.apache.hadoop.hive.serde2.lazybinary.LazyBinaryArray cannot be cast to [Ljava.lang.Object;
        at org.apache.hadoop.hive.serde2.objectinspector.StandardListObjectInspector.getListElement(StandardListObjectInspector.java:66)
        at org.apache.hadoop.hive.ql.udf.generic.GenericUDFIndex.evaluate(GenericUDFIndex.java:102)
        at org.apache.hadoop.hive.ql.exec.ExprNodeGenericFuncEvaluator._evaluate(ExprNodeGenericFuncEvaluator.java:186)
        at org.apache.hadoop.hive.ql.exec.ExprNodeEvaluator.evaluate(ExprNodeEvaluator.java:77)
        at org.apache.hadoop.hive.ql.exec.ExprNodeEvaluator.evaluate(ExprNodeEvaluator.java:65)
        at org.apache.hadoop.hive.ql.exec.SelectOperator.process(SelectOperator.java:81)
        ... 31 more, [~selinazh] Any updates here? Can you take a look at [~gss2002]'s comment? [~gss2002] Can you provide a simple test where you saw the above exception.

Thanks
Vikram., Here is the query and source table describe that shows the array<string> which seems to be the cause...

drop table debug.ct_gsd_events1_test;
create table debug.ct_gsd_events1_test
as select  a.*,
b.svcrqst_id,
b.svcrqct_cds,
b.svcrtyp_cd,
b.cmpltyp_cd,
b.sum_reason_cd as src,
b.cnctmd_cd,
b.notes
from ctm.ct_gsd_events a
inner join
mbr.gsd_service_request b
on a.contact_event_id = b.cnctevn_id;


hive> describe formatted ctm.ct_gsd_events;
OK
# col_name              data_type               comment             
                 
hmoid                   string                                      
cumb_id_no              int                                         
mbrind_id               string                                      
contact_event_id        string                                      
ce_create_dt            string                                      
ce_end_dt               string                                      
contact_type            string                                      
cnctevs_cd              string                                      
contact_mode            string                                      
cntvnst_stts_cd         string                                      
total_transfers         int                                         
ce_notes                array<string>                               
                 
# Detailed Table Information             
Database:               ctm                      
Owner:                  LOAD_USER                  
CreateTime:             Fri May 29 09:41:58 EDT 2015     
LastAccessTime:         UNKNOWN                  
Protect Mode:           None                     
Retention:              0                        
Location:               hdfs://xhadnnm1p.example.com:8020/apps/hive/warehouse/ctm.db/ct_gsd_events         
Table Type:             MANAGED_TABLE            
Table Parameters:                
        COLUMN_STATS_ACCURATE   true                
        numFiles                154                 
        numRows                 0                   
        rawDataSize             0                   
        totalSize               5464108             
        transient_lastDdlTime   1432906919          
                 
# Storage Information            
SerDe Library:          org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe       
InputFormat:            org.apache.hadoop.mapred.TextInputFormat         
OutputFormat:           org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat       
Compressed:             No                       
Num Buckets:            -1                       
Bucket Columns:         []                       
Sort Columns:           []                       
Storage Desc Params:             
        serialization.format    1                   
Time taken: 2.968 seconds, Fetched: 42 row(s), Here is a sample of the data I think the cause is their is a null in the array<string> field of notes... this was not a problem with Hive 0.13 it definitely started with Hive 0.14/1.x line..


Vertex failed, vertexName=Map 2, vertexId=vertex_1426958683478_216665_2_01, diagnostics=[Task failed, taskId=task_1426958683478_216665_2_01_000104, diagnostics=[TaskAttempt 0 failed, info=[Error: Failure while running task:java.lang.RuntimeException: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row {"cumb_id_no":31XXXX585,"cumb_id_no_sub":31XXXX585,"cnctevn_id":"0021XXX86715","svcrqst_id":"0000003XXX346030","svcrqst_crt_dts":"2015-03-09 11:25:10.927722","subject_seq_no":1,"cntmbrp_id":"692XX60     ","plan_component":"HXXXX     ","psuniq_id":"0000000014XXX279","cust_segment":"RM ","idcard":"MEXXXXXX         ","cnctyp_cd":"001","cnctmd_cd":"D01","cnctevs_cd":"007","svcrtyp_cd":"722","svrstyp_cd":"832","cmpltyp_cd":" ","catsrsn_cd":"        ","apealvl_cd":" ","cnstnty_cd":"001","svcrqst_asrqst_ind":"Y","svcrqst_rtnorig_in":"N","svcrqst_vwasof_dt":"null","svcrqst_lupdusr_id":"XXXXXXX ","sum_reason_cd":"98","sum_reason":"Exclude","crsr_master_claim_index":null,"svcrqct_cds":["   "],"svcrqst_lupdt":"2015-03-09 11:25:10.927722","crsr_lupdt":null,"cntmbrp_lupdt":"2015-03-09 11:24:51.315134","cntevsds_lupdt":"2015-03-09 11:25:13.429458","ignore_me":1,"notes":null}
        at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:171)
        at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:137)
        at org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:324)
        at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:176)
        at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:168)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:415)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1556)
        at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.call(TezTaskRunner.java:168)
        at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.call(TezTaskRunner.java:163)
        at java.util.concurrent.FutureTask.run(FutureTask.java:262)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        at java.lang.Thread.run(Thread.java:744)
Caused by: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row {"cumb_id_no":31XXX585,"cumb_id_no_sub":31XXX585,"cnctevn_id":"0021XXX86715","svcrqst_id":"0000003XXX346030","svcrqst_crt_dts":"2015-03-09 11:25:10.927722","subject_seq_no":1,"cntmbrp_id":"692XX60     ","plan_component":"HXXXX     ","psuniq_id":"0000000014XXX279","cust_segment":"RM ","idcard":"MEXXXXXX         ","cnctyp_cd":"001","cnctmd_cd":"D01","cnctevs_cd":"007","svcrtyp_cd":"722","svrstyp_cd":"832","cmpltyp_cd":" ","catsrsn_cd":"        ","apealvl_cd":" ","cnstnty_cd":"001","svcrqst_asrqst_ind":"Y","svcrqst_rtnorig_in":"N","svcrqst_vwasof_dt":"null","svcrqst_lupdusr_id":"XXXXXXX ","sum_reason_cd":"98","sum_reason":"Exclude","crsr_master_claim_index":null,"svcrqct_cds":["   "],"svcrqst_lupdt":"2015-03-09 11:25:10.927722","crsr_lupdt":null,"cntmbrp_lupdt":"2015-03-09 11:24:51.315134","cntevsds_lupdt":"2015-03-09 11:25:13.429458","ignore_me":1,"notes":null}
        at org.apache.hadoop.hive.ql.exec.tez.MapRecordSource.processRow(MapRecordSource.java:91)
        at org.apache.hadoop.hive.ql.exec.tez.MapRecordSource.pushRecord(MapRecordSource.java:68)
        at org.apache.hadoop.hive.ql.exec.tez.MapRecordProcessor.run(MapRecordProcessor.java:290)
        at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:148)
        ... 13 more
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row {"cumb_id_no":31XXXX585,"cumb_id_no_sub":31XXXX585,"cnctevn_id":"0021XXX86715","svcrqst_id":"0000003XXX346030","svcrqst_crt_dts":"2015-03-09 11:25:10.927722","subject_seq_no":1,"cntmbrp_id":"692XX60     ","plan_component":"HXXXX     ","psuniq_id":"0000000014XXX279","cust_segment":"RM ","idcard":"MEXXXXXX         ","cnctyp_cd":"001","cnctmd_cd":"D01","cnctevs_cd":"007","svcrtyp_cd":"722","svrstyp_cd":"832","cmpltyp_cd":" ","catsrsn_cd":"        ","apealvl_cd":" ","cnstnty_cd":"001","svcrqst_asrqst_ind":"Y","svcrqst_rtnorig_in":"N","svcrqst_vwasof_dt":"null","svcrqst_lupdusr_id":"XXXXXXX ","sum_reason_cd":"98","sum_reason":"Exclude","crsr_master_claim_index":null,"svcrqct_cds":["   "],"svcrqst_lupdt":"2015-03-09 11:25:10.927722","crsr_lupdt":null,"cntmbrp_lupdt":"2015-03-09 11:24:51.315134","cntevsds_lupdt":"2015-03-09 11:25:13.429458","ignore_me":1,"notes":null}
        at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:518)
        at org.apache.hadoop.hive.ql.exec.tez.MapRecordSource.processRow(MapRecordSource.java:83)
        ... 16 more
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: Unexpected exception: org.apache.hadoop.hive.serde2.lazybinary.LazyBinaryArray cannot be cast to [Ljava.lang.Object;
        at org.apache.hadoop.hive.ql.exec.MapJoinOperator.process(MapJoinOperator.java:426)
        at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:837)
        at org.apache.hadoop.hive.ql.exec.FilterOperator.process(FilterOperator.java:122)
        at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:837)
        at org.apache.hadoop.hive.ql.exec.TableScanOperator.process(TableScanOperator.java:97)
        at org.apache.hadoop.hive.ql.exec.MapOperator$MapOpCtx.forward(MapOperator.java:162)
        at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:508)
        ... 17 more
Caused by: java.lang.ClassCastException: org.apache.hadoop.hive.serde2.lazybinary.LazyBinaryArray cannot be cast to [Ljava.lang.Object;
        at org.apache.hadoop.hive.serde2.objectinspector.StandardListObjectInspector.getList(StandardListObjectInspector.java:111)
        at org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe.serialize(LazySimpleSerDe.java:314)
        at org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe.serializeField(LazySimpleSerDe.java:262)
        at org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe.doSerialize(LazySimpleSerDe.java:246)
        at org.apache.hadoop.hive.serde2.AbstractEncodingAwareSerDe.serialize(AbstractEncodingAwareSerDe.java:50)
        at org.apache.hadoop.hive.ql.exec.FileSinkOperator.process(FileSinkOperator.java:720)
        at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:837)
        at org.apache.hadoop.hive.ql.exec.SelectOperator.process(SelectOperator.java:88)
        at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:837)
        at org.apache.hadoop.hive.ql.exec.CommonJoinOperator.internalForward(CommonJoinOperator.java:644)
        at org.apache.hadoop.hive.ql.exec.CommonJoinOperator.genAllOneUniqueJoinObject(CommonJoinOperator.java:676)
        at org.apache.hadoop.hive.ql.exec.CommonJoinOperator.checkAndGenObject(CommonJoinOperator.java:754)
        at org.apache.hadoop.hive.ql.exec.MapJoinOperator.process(MapJoinOperator.java:414)
        ... 23 more, Any status on this jira is this stalled? Can i help any further??? This is a real issue plaguing folks since around hive 0.14, NOTE: We have a possible solution here but *NO TEST*.

There is an attached Q file with a array of integers and array of strings tests, but I haven't been able to get the tests to fail on trunk.  I'm not sure what I'm missing.  So, unclear if new code is being tested yet., 

{color:green}Overall{color}: +1 all checks pass

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12741285/HIVE-10729.03.patch

{color:green}SUCCESS:{color} +1 9014 tests passed

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/4351/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/4351/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-4351/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12741285 - PreCommit-HIVE-TRUNK-Build, [~mmccline] the test on this bug doesn't happen anymore but there is: https://issues.apache.org/jira/browse/HIVE-11051. The attached test on that bug used to be fixed with this patch here. It might makes sense to resolve this one and move the code over to HIVE-11051 if that's the case., Gunther Hagleitner and Matt Mcline Using this Patch against my JIRA HIVE-11051 and the test case on Hadoop 2.4.1 with Hive 1.2.0 and Tez 0.5.4 it still fails:

Caused by: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row {"cnctevn_id":"002246948195","svcrqst_id":"0000003629537980","svcrqst_crt_dts":"2015-04-24 12:48:37.859683","subject_seq_no":1,"plan_component":"HMOM1     ","cust_segment":"RM ","cnctyp_cd":"001","cnctmd_cd":"D02","cnctevs_cd":"007","svcrtyp_cd":"335","svrstyp_cd":"088","cmpltyp_cd":" ","catsrsn_cd":"        ","apealvl_cd":" ","cnstnty_cd":"001","svcrqst_asrqst_ind":"Y","svcrqst_rtnorig_in":"N","svcrqst_vwasof_dt":"null","sum_reason_cd":"98","sum_reason":"Exclude","crsr_master_claim_index":null,"svcrqct_cds":["   "],"svcrqst_lupdt":"2015-04-24 12:48:37.859683","crsr_lupdt":null,"cntevsds_lupdt":"2015-04-24 12:48:40.499238","ignore_me":1,"notes":null}
        at org.apache.hadoop.hive.ql.exec.tez.MapRecordSource.processRow(MapRecordSource.java:91)
        at org.apache.hadoop.hive.ql.exec.tez.MapRecordSource.pushRecord(MapRecordSource.java:68)
        at org.apache.hadoop.hive.ql.exec.tez.MapRecordProcessor.run(MapRecordProcessor.java:290)
        at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:148)
        ... 13 more
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row {"cnctevn_id":"002246948195","svcrqst_id":"0000003629537980","svcrqst_crt_dts":"2015-04-24 12:48:37.859683","subject_seq_no":1,"plan_component":"HMOM1     ","cust_segment":"RM ","cnctyp_cd":"001","cnctmd_cd":"D02","cnctevs_cd":"007","svcrtyp_cd":"335","svrstyp_cd":"088","cmpltyp_cd":" ","catsrsn_cd":"        ","apealvl_cd":" ","cnstnty_cd":"001","svcrqst_asrqst_ind":"Y","svcrqst_rtnorig_in":"N","svcrqst_vwasof_dt":"null","sum_reason_cd":"98","sum_reason":"Exclude","crsr_master_claim_index":null,"svcrqct_cds":["   "],"svcrqst_lupdt":"2015-04-24 12:48:37.859683","crsr_lupdt":null,"cntevsds_lupdt":"2015-04-24 12:48:40.499238","ignore_me":1,"notes":null}
        at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:518)
        at org.apache.hadoop.hive.ql.exec.tez.MapRecordSource.processRow(MapRecordSource.java:83)
        ... 16 more
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: Unexpected exception: Index: 0, Size: 0
        at org.apache.hadoop.hive.ql.exec.MapJoinOperator.process(MapJoinOperator.java:426)
        at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:837)
        at org.apache.hadoop.hive.ql.exec.FilterOperator.process(FilterOperator.java:122)
        at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:837)
        at org.apache.hadoop.hive.ql.exec.TableScanOperator.process(TableScanOperator.java:97)
        at org.apache.hadoop.hive.ql.exec.MapOperator$MapOpCtx.forward(MapOperator.java:162)
        at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:508)
        ... 17 more
Caused by: java.lang.IndexOutOfBoundsException: Index: 0, Size: 0
        at java.util.ArrayList.rangeCheck(ArrayList.java:635)
        at java.util.ArrayList.set(ArrayList.java:426)
        at org.apache.hadoop.hive.ql.exec.persistence.MapJoinBytesTableContainer.fixupComplexObjects(MapJoinBytesTableContainer.java:424)
        at org.apache.hadoop.hive.ql.exec.persistence.HybridHashTableContainer$ReusableRowContainer.uppack(HybridHashTableContainer.java:875)
        at org.apache.hadoop.hive.ql.exec.persistence.HybridHashTableContainer$ReusableRowContainer.first(HybridHashTableContainer.java:845)
        at org.apache.hadoop.hive.ql.exec.persistence.HybridHashTableContainer$ReusableRowContainer.first(HybridHashTableContainer.java:722)
        at org.apache.hadoop.hive.ql.exec.persistence.UnwrapRowContainer.first(UnwrapRowContainer.java:62)
        at org.apache.hadoop.hive.ql.exec.persistence.UnwrapRowContainer.first(UnwrapRowContainer.java:33)
        at org.apache.hadoop.hive.ql.exec.CommonJoinOperator.genUniqueJoinObject(CommonJoinOperator.java:650)
        at org.apache.hadoop.hive.ql.exec.CommonJoinOperator.checkAndGenObject(CommonJoinOperator.java:756)
        at org.apache.hadoop.hive.ql.exec.MapJoinOperator.process(MapJoinOperator.java:414)
        ... 23 more
]], Vertex failed as one or more tasks failed. failedTasks:1, Vertex vertex_1434641270368_13820_2_01 [Map 2] killed/failed due to:null]DAG failed due to vertex failure. failedVertices:1 killedVertices:0, Yes, the trace from fixupComplexObjects in patch #3 is a bug in that patch.

Since I was able to repro the problem with data and script from HIVE-11051, I just submitted a patch on that JIRA that is basically this JIRA's patch #3 plus a bug fix.  The new Q file tests with hive.mapjoin.hybridgrace.hashtable false and true to make sure MapJoinBytesTableContainer and HybridHashTableContainer are tested.

So, this JIRA's patch #3 is defunct., The problem is the Vectorization class was not checking data types in the small table expression., Didn't look at the test file, I assume it's the same as w/o vector :)
posSingleVectorMapJoinSmallTable - assumes there are two elements in the array, right? Should there be an assert? 
Looks good pending tests otherwise. +1, Thank you for the review., 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12795540/HIVE-10729.04.patch

{color:green}SUCCESS:{color} +1 due to 1 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 7 failed/errored test(s), 9873 tests executed
*Failed tests:*
{noformat}
TestMiniTezCliDriver-cte_4.q-orc_merge5.q-vectorization_limit.q-and-12-more - did not produce a TEST-*.xml file
TestSparkCliDriver-groupby3_map.q-sample2.q-auto_join14.q-and-12-more - did not produce a TEST-*.xml file
TestSparkCliDriver-groupby_map_ppr_multi_distinct.q-table_access_keys_stats.q-groupby4_noskew.q-and-12-more - did not produce a TEST-*.xml file
TestSparkCliDriver-join_rc.q-insert1.q-vectorized_rcfile_columnar.q-and-12-more - did not produce a TEST-*.xml file
TestSparkCliDriver-ppd_join4.q-join9.q-ppd_join3.q-and-12-more - did not produce a TEST-*.xml file
org.apache.hadoop.hive.ql.optimizer.physical.TestVectorizer.testValidateMapJoinOperator
org.apache.hadoop.hive.ql.optimizer.physical.TestVectorizer.testValidateSMBJoinOperator
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/7400/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/7400/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-7400/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 7 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12795540 - PreCommit-HIVE-TRUNK-Build, Fix TestVectorizer unit test., Committed to master and branch-1., Committed to branch-2.0 also., is there patch for 0.14.0?]