[Patch attached., [~hsubramaniyan], could you please review? Thanks!, +1 , +1, 

{color:red}Overall{color}: -1 no tests executed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12724087/HIVE-10272.patch

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/3379/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/3379/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-3379/

Messages:
{noformat}
**** This message was trimmed, see log for full details ****
[INFO] 
[INFO] --- build-helper-maven-plugin:1.7:add-test-source (add-test-sources) @ hive-hbase-handler ---
[INFO] Test Source directory: /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/src/gen/avro/gen-java added.
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hive-hbase-handler ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/src/test/resources
[INFO] Copying 3 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-hbase-handler ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/target/tmp/conf
     [copy] Copying 11 files to /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-hbase-handler ---
[INFO] Compiling 16 source files to /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/target/test-classes
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/src/test/org/apache/hadoop/hive/hbase/SampleHBaseKeyFactory3.java: Some input files use or override a deprecated API.
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/src/test/org/apache/hadoop/hive/hbase/SampleHBaseKeyFactory3.java: Recompile with -Xlint:deprecation for details.
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/src/test/org/apache/hadoop/hive/hbase/avro/ContactInfo.java: Some input files use unchecked or unsafe operations.
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/src/test/org/apache/hadoop/hive/hbase/avro/ContactInfo.java: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-hbase-handler ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-hbase-handler ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/target/hive-hbase-handler-1.2.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-site-plugin:3.3:attach-descriptor (attach-descriptor) @ hive-hbase-handler ---
[INFO] 
[INFO] --- maven-jar-plugin:2.2:test-jar (default) @ hive-hbase-handler ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/target/hive-hbase-handler-1.2.0-SNAPSHOT-tests.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-hbase-handler ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/target/hive-hbase-handler-1.2.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-hbase-handler/1.2.0-SNAPSHOT/hive-hbase-handler-1.2.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-hbase-handler/1.2.0-SNAPSHOT/hive-hbase-handler-1.2.0-SNAPSHOT.pom
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/target/hive-hbase-handler-1.2.0-SNAPSHOT-tests.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-hbase-handler/1.2.0-SNAPSHOT/hive-hbase-handler-1.2.0-SNAPSHOT-tests.jar
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive HCatalog 1.2.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-hcatalog ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/hcatalog (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-enforcer-plugin:1.3.1:enforce (enforce-no-snapshots) @ hive-hcatalog ---
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hive-hcatalog ---
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-hcatalog ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-hcatalog ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/target/tmp/conf
     [copy] Copying 11 files to /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-site-plugin:3.3:attach-descriptor (attach-descriptor) @ hive-hcatalog ---
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-hcatalog ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hcatalog/hive-hcatalog/1.2.0-SNAPSHOT/hive-hcatalog-1.2.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive HCatalog Core 1.2.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-hcatalog-core ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-enforcer-plugin:1.3.1:enforce (enforce-no-snapshots) @ hive-hcatalog-core ---
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hive-hcatalog-core ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hive-hcatalog-core ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/src/main/resources
[INFO] Copying 3 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-hcatalog-core ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-hcatalog-core ---
[INFO] Compiling 79 source files to /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/target/classes
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/src/main/java/org/apache/hive/hcatalog/data/JsonSerDe.java: Some input files use or override a deprecated API.
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/src/main/java/org/apache/hive/hcatalog/data/JsonSerDe.java: Recompile with -Xlint:deprecation for details.
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/src/main/java/org/apache/hive/hcatalog/mapreduce/HCatBaseOutputFormat.java: Some input files use unchecked or unsafe operations.
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/src/main/java/org/apache/hive/hcatalog/mapreduce/HCatBaseOutputFormat.java: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hive-hcatalog-core ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/src/test/resources
[INFO] Copying 3 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-hcatalog-core ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/target/tmp/conf
     [copy] Copying 11 files to /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-hcatalog-core ---
[INFO] Compiling 38 source files to /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/target/test-classes
[INFO] -------------------------------------------------------------
[WARNING] COMPILATION WARNING : 
[INFO] -------------------------------------------------------------
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/src/test/java/org/apache/hive/hcatalog/mapreduce/TestHCatDynamicPartitioned.java: Some input files use or override a deprecated API.
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/src/test/java/org/apache/hive/hcatalog/mapreduce/TestHCatDynamicPartitioned.java: Recompile with -Xlint:deprecation for details.
[INFO] 2 warnings 
[INFO] -------------------------------------------------------------
[INFO] -------------------------------------------------------------
[ERROR] COMPILATION ERROR : 
[INFO] -------------------------------------------------------------
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/src/test/java/org/apache/hive/hcatalog/mapreduce/HCatBaseTest.java:[85,9] cannot find symbol
  symbol:   variable Shell
  location: class org.apache.hive.hcatalog.mapreduce.HCatBaseTest
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/src/test/java/org/apache/hive/hcatalog/mapreduce/HCatBaseTest.java:[85,8] illegal start of type
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/src/test/java/org/apache/hive/hcatalog/mapreduce/HCatBaseTest.java:[86,7] cannot find symbol
  symbol:   variable WindowsPathUtil
  location: class org.apache.hive.hcatalog.mapreduce.HCatBaseTest
[INFO] 3 errors 
[INFO] -------------------------------------------------------------
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Summary:
[INFO] 
[INFO] Hive .............................................. SUCCESS [10.932s]
[INFO] Hive Shims Common ................................. SUCCESS [11.022s]
[INFO] Hive Shims 0.20S .................................. SUCCESS [2.836s]
[INFO] Hive Shims 0.23 ................................... SUCCESS [11.512s]
[INFO] Hive Shims Scheduler .............................. SUCCESS [1.956s]
[INFO] Hive Shims ........................................ SUCCESS [2.548s]
[INFO] Hive Common ....................................... SUCCESS [29.273s]
[INFO] Hive Serde ........................................ SUCCESS [22.940s]
[INFO] Hive Metastore .................................... SUCCESS [36.821s]
[INFO] Hive Ant Utilities ................................ SUCCESS [1.885s]
[INFO] Spark Remote Client ............................... SUCCESS [28.115s]
[INFO] Hive Query Language ............................... SUCCESS [2:10.453s]
[INFO] Hive Service ...................................... SUCCESS [7.030s]
[INFO] Hive Accumulo Handler ............................. SUCCESS [5.739s]
[INFO] Hive JDBC ......................................... SUCCESS [12.501s]
[INFO] Hive Beeline ...................................... SUCCESS [2.061s]
[INFO] Hive CLI .......................................... SUCCESS [3.388s]
[INFO] Hive Contrib ...................................... SUCCESS [3.824s]
[INFO] Hive HBase Handler ................................ SUCCESS [6.362s]
[INFO] Hive HCatalog ..................................... SUCCESS [1.252s]
[INFO] Hive HCatalog Core ................................ FAILURE [4.900s]
[INFO] Hive HCatalog Pig Adapter ......................... SKIPPED
[INFO] Hive HCatalog Server Extensions ................... SKIPPED
[INFO] Hive HCatalog Webhcat Java Client ................. SKIPPED
[INFO] Hive HCatalog Webhcat ............................. SKIPPED
[INFO] Hive HCatalog Streaming ........................... SKIPPED
[INFO] Hive HWI .......................................... SKIPPED
[INFO] Hive ODBC ......................................... SKIPPED
[INFO] Hive Shims Aggregator ............................. SKIPPED
[INFO] Hive TestUtils .................................... SKIPPED
[INFO] Hive Packaging .................................... SKIPPED
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 5:40.380s
[INFO] Finished at: Sat Apr 11 10:40:19 EDT 2015
[INFO] Final Memory: 169M/687M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.1:testCompile (default-testCompile) on project hive-hcatalog-core: Compilation failure: Compilation failure:
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/src/test/java/org/apache/hive/hcatalog/mapreduce/HCatBaseTest.java:[85,9] cannot find symbol
[ERROR] symbol:   variable Shell
[ERROR] location: class org.apache.hive.hcatalog.mapreduce.HCatBaseTest
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/src/test/java/org/apache/hive/hcatalog/mapreduce/HCatBaseTest.java:[85,8] illegal start of type
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/src/test/java/org/apache/hive/hcatalog/mapreduce/HCatBaseTest.java:[86,7] cannot find symbol
[ERROR] symbol:   variable WindowsPathUtil
[ERROR] location: class org.apache.hive.hcatalog.mapreduce.HCatBaseTest
[ERROR] -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn <goals> -rf :hive-hcatalog-core
+ exit 1
'
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12724087 - PreCommit-HIVE-TRUNK-Build, Updated patch, imports were needed., 

{color:red}Overall{color}: -1 at least one tests failed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12725039/HIVE-10272.2.patch

{color:red}ERROR:{color} -1 due to 13 failed/errored test(s), 8674 tests executed
*Failed tests:*
{noformat}
TestMinimrCliDriver-bucketmapjoin6.q-constprog_partitioner.q-infer_bucket_sort_dyn_part.q-and-1-more - did not produce a TEST-*.xml file
TestMinimrCliDriver-external_table_with_space_in_location_path.q-infer_bucket_sort_merge.q-auto_sortmerge_join_16.q-and-1-more - did not produce a TEST-*.xml file
TestMinimrCliDriver-groupby2.q-import_exported_table.q-bucketizedhiveinputformat.q-and-1-more - did not produce a TEST-*.xml file
TestMinimrCliDriver-index_bitmap3.q-stats_counter_partitioned.q-temp_table_external.q-and-1-more - did not produce a TEST-*.xml file
TestMinimrCliDriver-infer_bucket_sort_map_operators.q-join1.q-bucketmapjoin7.q-and-1-more - did not produce a TEST-*.xml file
TestMinimrCliDriver-infer_bucket_sort_num_buckets.q-disable_merge_for_bucketing.q-uber_reduce.q-and-1-more - did not produce a TEST-*.xml file
TestMinimrCliDriver-infer_bucket_sort_reducers_power_two.q-scriptfile1.q-scriptfile1_win.q-and-1-more - did not produce a TEST-*.xml file
TestMinimrCliDriver-leftsemijoin_mr.q-load_hdfs_file_with_space_in_the_name.q-root_dir_external_table.q-and-1-more - did not produce a TEST-*.xml file
TestMinimrCliDriver-list_bucket_dml_10.q-bucket_num_reducers.q-bucket6.q-and-1-more - did not produce a TEST-*.xml file
TestMinimrCliDriver-load_fs2.q-file_with_header_footer.q-ql_rewrite_gbtoidx_cbo_1.q-and-1-more - did not produce a TEST-*.xml file
TestMinimrCliDriver-parallel_orderby.q-reduce_deduplicate.q-ql_rewrite_gbtoidx_cbo_2.q-and-1-more - did not produce a TEST-*.xml file
TestMinimrCliDriver-ql_rewrite_gbtoidx.q-smb_mapjoin_8.q - did not produce a TEST-*.xml file
TestMinimrCliDriver-schemeAuthority2.q-bucket4.q-input16_cc.q-and-1-more - did not produce a TEST-*.xml file
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/3412/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/3412/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-3412/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 13 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12725039 - PreCommit-HIVE-TRUNK-Build, Per http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/3412/testReport, all tests passed, the issue above is that TestMiniMRCliDriver does not seem to be working generally, and is not connected to this patch.
, Since I have Thejas' and Hari's +1 on this issue, and have had only a minimal change from the previous patch, and this patch is minor and affects only windows tests for HCat, I'm going to go ahead and commit it., This issue has been fixed and released as part of the 1.2.0 release. If you find an issue which seems to be related to this one, please create a new jira and link this one with new jira.]