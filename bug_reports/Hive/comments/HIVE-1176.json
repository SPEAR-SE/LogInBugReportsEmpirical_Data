[Can you provide a reproducible test case for this bug?, my bad. There is already a test case :), This problem is due to [a bug in Datanucleus JDOQL|http://www.jpox.org/servlet/jira/browse/NUCCORE-427] implementation and has been fixed in version 2.0.x.

The fix is therefore to upgrade datanucleus plugins to the latest stable release.

*Details:*
- Replaced the old datanucleus plugins version 1.1.2 with the latest stable release.
- Updated jdo2-api library with the version required by datanucleus - 2.3-0ec, available from datanucleus maven repository at http://www.datanucleus.org/downloads/maven2/javax/jdo/jdo2-api/2.3-ec/, Apache licensed
- Modified the build files to suppress auto-enhancement of all complied classes, a new feature introduced in the latest version.
- Modified the HiveMetaStoreClient implementation to create deep-copies of non-primitive objects being returned from the thrift server. Without this change, some collections were being fetched as semi-populated proxies with missing session context leading to NPEs.

*Testing Done:*
Built and ran all tests. Only two failures were reported - clientpositive test for input20.q and input33.q. These tests appear to be failing on the trunk as well., This patch replaces the patch submitted before (HIVE-1176.lib-files.tar.gz and HIVE-1176.patch).

{code}
HIVE-1176-1.patch:

#	modified:   build.properties
#	modified:   build.xml
#	modified:   eclipse-templates/.classpath
#	modified:   ivy/ivysettings.xml
#	deleted:    lib/datanucleus-core-1.1.2.LICENSE
#	deleted:    lib/datanucleus-core-1.1.2.jar
#	deleted:    lib/datanucleus-enhancer-1.1.2.LICENSE
#	deleted:    lib/datanucleus-enhancer-1.1.2.jar
#	deleted:    lib/datanucleus-rdbms-1.1.2.LICENSE
#	deleted:    lib/datanucleus-rdbms-1.1.2.jar
#	deleted:    lib/jdo2-api-2.3-SNAPSHOT.LICENSE
#	deleted:    lib/jdo2-api-2.3-SNAPSHOT.jar
#	modified:   metastore/ivy.xml
#	modified:   metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStoreClient.java
{code}, Updated the patch so that it cleanly applies to the trunk. 

*Changes from Previous Patch:*

* This patch uses ivy to download the updated datanucleus plugins and other dependent libraries. There is no need to use the previously supplied tar.gz anymore.
* At the time the previous patch was written, the enhancer plugin version was 2.0.1 which by default would enable annotation processing. Since then version 2.0.3 has been released which [disables this behavior|http://www.datanucleus.org/servlet/jira/browse/NUCENHANCER-56]. Hence the previously submitted changes to {{javac.args}} in build.properties file are no longer necessary. This patch uses the updated version of the datanucleus enhancer plugin.
* The JDO2 API library used by datanucleus plugin is distributed by the datanucleus's public maven repository. This repository has been added to ivy configuration to automate the download.
* The connection pool libraries have been updated to work with the newer datanucleus plugins. Library {{commons-dbcp}} has been updated from 1.2.2 to 1.4, {{commons-pool}} from 1.2 to 1.5.4, and {{datanucleus-connectionpool}} from 1.0.2 to 2.0.1.
* As with the previously submitted patch, {{HiveMetaStoreClient}} implementation has been modified to create deep-copies of non-primitive objects being returned from the thrift server in order to avoid semi-populated proxies causing NPEs downstream.

*Testing Done:*

Built and ran all tests. Only two failures were reported as before - clientpositive test for input20.q and input33.q. These tests appear to be failing on the trunk as well.
, What failures are you seeing on trunk for input20.q and input33.q?  I do see recent Hudson sporadic failures for the flaky negative tests script_broken_pipe1 and loadpart_err, but not input20.q and input33.q.

http://hudson.zones.apache.org/hudson/job/Hive-trunk-h0.20/
, John - I debugged the failures that I was seeing for input20 and input33 and it turns out to be a subtle difference in the way the stream editor {{sed}} works on Mac vs the regular linux distribution. I installed the GNU port for {{sed}} and the failures no longer occur.

I don't think this is related to the sporadic failures that are reported on hudson., @Arvind: Can you explain what the difference is between OSX sed and GNU sed? Can we rewrite the sed script so that it works on both platforms? Seems like we are probably relying on a non-POSIX feature that is present in the GNU version., I think the difference is more likely a bug in Mac OSX version of {{sed}}. Specifically, it fails to process directives with escaped tab sequence characters and instead treats it as unescaped. For example, the command to replace first occurrence of *b* in the string *abc* with a tab character *\t* fails as shown below:

{code}
$ echo "abc" | /usr/bin/sed "s@b@\t@"
atc
{code}

Whereas this works fine with the GNU distribution of sed

{code}
$ echo "abc" | /opt/local/bin/sed "s@b@\t@"
a	c
{code}, Can you elaborate on what you mean by 'some collections were being fetched as semi-populated proxies with missing session context leading to NPEs'? Is there something I can do to reproduce this?, Updating the patch with latest trunk image. This is necessary since HIVE-1373 updated the eclipse classpath with connection pool libraries which will be outdated with the application of this patch. The updated version of the patch takes care of this problem by updating eclipse classpath to use the updated libraries instead. Tested out launch configuration via eclipse to make sure it is working., The updated patch HIVE-1176-2.patch contains the following changes:

#	modified:   build.properties
#	modified:   build.xml
#	modified:   eclipse-templates/.classpath
#	modified:   ivy/ivysettings.xml
#	deleted:    lib/datanucleus-core-1.1.2.LICENSE
#	deleted:    lib/datanucleus-core-1.1.2.jar
#	deleted:    lib/datanucleus-enhancer-1.1.2.LICENSE
#	deleted:    lib/datanucleus-enhancer-1.1.2.jar
#	deleted:    lib/datanucleus-rdbms-1.1.2.LICENSE
#	deleted:    lib/datanucleus-rdbms-1.1.2.jar
#	deleted:    lib/jdo2-api-2.3-SNAPSHOT.LICENSE
#	deleted:    lib/jdo2-api-2.3-SNAPSHOT.jar
#	modified:   metastore/ivy.xml
#	modified:   metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStoreClient.java, bq. Can you elaborate on what you mean by 'some collections were being fetched as semi-populated proxies with missing session context leading to NPEs'? Is there something I can do to reproduce this?

@Paul: Here are the steps to reproduce this problem:

# Startout with a clean workspace checkout and apply the updated patch HIVE-1176-2.patch. 
# Manually revert the file {{metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStoreClient.java}} to its previous state
# run {{ant package}} from the root of the workspace
# run {{ant test}} from within metastore

You should see failures like the following:
{code}
    [junit] testPartition() failed.
    [junit] java.lang.NullPointerException
    [junit] 	at org.datanucleus.store.mapped.scostore.AbstractMapStore.validateKeyForWriting(AbstractMapStore.java:333)
    [junit] 	at org.datanucleus.store.mapped.scostore.JoinMapStore.put(JoinMapStore.java:252)
    [junit] 	at org.datanucleus.sco.backed.Map.put(Map.java:640)
    [junit] 	at org.apache.hadoop.hive.metastore.api.Table.putToParameters(Table.java:359)
    [junit] 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.alter_table(HiveMetaStore.java:1281)
    [junit] 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.alter_table(HiveMetaStoreClient.java:140)
    [junit] 	at org.apache.hadoop.hive.metastore.TestHiveMetaStore.testAlterTable(TestHiveMetaStore.java:728)
    [junit] 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    ...
{code}

If you look at {{src/gen-javabean/org/apache/hadoop/hive/metastore/api/Table.java}} you would notice that the line causing this exception should ideally be a {{HashMap}} and not an {{org.datanucleus.store.mapped.scostore.AbstractMapStore}} as indicated by the stack trace. This happens because the datanucleus JDO framework replaces collections with its own implementation in order to allow lazy-dereferencing and optimize for database connections/queries/memory consumption etc.

Lazy loading of collections (and second class objects in general) can be disabled at a global level or at entity level. Disabling this globally is generally not recommended unless there is evidence backed by extensive testing that supports that change. Disabling at an entity level is still OK provided the entity object graph is fully dereferenced at all times. This could lead to extensive memory consumption in the system in case the entity graph is huge. 

My approach towards fixing the problem was to *not* change the default behavior in the general case. Instead I felt that it was better to circumvent this problem in the case of a remote metastore by creating a copy explicitly. If you have other suggestions on how to address this, please let me know.

Also - more information on the lazy dereferencing mechanism used by datanucleus framework can be found [here|http://www.datanucleus.org/plugins/core/sco.html].
, @Paul: Any updates on this from your end? Thanks., I was going to look at it again today, but looks like I'll get to it around mid-day tomorrow? Will keep this posted., For some reason, I don't see the JDO files being deleted after applying the patch:

{code}
?      build.xml.orig
?      HIVE-1176-2.patch
?      test.log
M      eclipse-templates/.classpath
M      build.properties
M      build.xml
?      metastore/test.log
M      metastore/ivy.xml
M      metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStoreClient.java
!      lib/jdo2-api-2.3-SNAPSHOT.LICENSE
!      lib/datanucleus-rdbms-1.1.2.LICENSE
!      lib/datanucleus-enhancer-1.1.2.LICENSE
!      lib/datanucleus-core-1.1.2.LICENSE
M      ivy/ivysettings.xml
{code}

Also, the patch works for branch 0.6 but not for trunk. Can you regenerate it?, To clarify, I am referring to the jars under /lib that should be deleted along with the *.LICENSE files., Nevermind - JVS pointed out that jars are skipped as they are binary files., @Paul: I just tested the patch (HIVE-1176-2.patch) on latest trunk and it seems to apply cleanly. Can you please try again and see if it works? Also, can you post the errors that you are seeing? If necessary, I can break down the patch into single-file units to help with applying it. Just let me know either way.
, Tried it again, and yep, it works. Not sure what happened before. Anyway though, yeah I do see the NPE's that you mentioned. Why did this not occur before? Just changes in behavior between major versions?, Yes - it appears that the change in behavior can be attributed to the difference in major versions., One last thing, can you include a unit test to verify the fix?, Sorry - it is not clear to me what unit test should I be writing. Can you give an example perhaps?

From my perspective, any test that uses the metastore exercises this change. And together, all the tests form an exhaustive layer that ensures that there is no regression seeping into the system. Note that this is not a functionality change, only a change of underlying libraries. , Also, for the specific change to {{HiveMetaStoreClient.java}} - the tests under {{metastore}} validate that the new libraries are working correctly. , Oh, but I thought the original problem (as per title) was an exception with 'create table if not exists tmp_select(s string, c string, n int)'?

So maybe something like:

CREATE TABLE IF NOT EXISTS tmp_select(s STRING, c STRING, n INT);
DROP TABLE tmp_select;
, Makes sense. Will add a test case and update the patch soon. Sorry for the misunderstanding., Updated patch with a test case attached. Please use HIVE-1176-3.patch. The changed files in this patch are as follows:


#	modified:   build.properties
#	modified:   build.xml
#	new file:   data/files/simple.txt
#	modified:   eclipse-templates/.classpath
#	modified:   ivy/ivysettings.xml
#	deleted:    lib/datanucleus-core-1.1.2.LICENSE
#	deleted:    lib/datanucleus-core-1.1.2.jar
#	deleted:    lib/datanucleus-enhancer-1.1.2.LICENSE
#	deleted:    lib/datanucleus-enhancer-1.1.2.jar
#	deleted:    lib/datanucleus-rdbms-1.1.2.LICENSE
#	deleted:    lib/datanucleus-rdbms-1.1.2.jar
#	deleted:    lib/jdo2-api-2.3-SNAPSHOT.LICENSE
#	deleted:    lib/jdo2-api-2.3-SNAPSHOT.jar
#	modified:   metastore/ivy.xml
#	modified:   metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStoreClient.java
#	new file:   ql/src/test/queries/clientpositive/hive_1176.q
#	new file:   ql/src/test/results/clientpositive/hive_1176.q.out
, @Arvind - While the test that you added is thorough, I think for this case, we might be able to get by with something simpler / faster? 

e.g.
* Use one of the existing source files or insert from an existing table like 'src'. 
* Limit to one select statement / table as we test select more extensively in other unit tests. 
* Remove the drop table statements in the beginning, as other tests aren't supposed to leave tables around at the end of their run. 
* Rename the query file to something more descriptive. This would help developers browsing the list of tests.

We don't want to sacrifice coverage, but at the same time, the whole suite of tests take quite a while to execute., Paul, we currently do pre-drops in the test to avoid collisions in case other tests fail, or if a negative test happens to use the same table name since there's currently no way for a negative test to clean up after itself.  It would be better if our test framework automatically cleaned out the catalog at the beginning of each test, but until we have that, pre-drop is required.
, @Paul: You suggestions are fair enough. I have incorporated all changes you suggested except for the pre-drop based on @John's response. Let me know if you guys need any further tweaking of this patch., @John - good point! In which case, we'll probably need to fix up some of the other unit tests with a create table., Looks good to me

+1, Just one more change needed...please add an ORDER BY to the select in the testcase.  This is required to avoid spurious diffs later since without ORDER BY, the query result order is non-deterministic.

After that I'll run through tests and commit.
, @John: done. Please see the new patch attachment -  HIVE-1176-5.patch

Since a lot of good points came out of the discussion on this jira, I took the liberty of adding them to the Hive wiki for posterity. You can find it [here|http://wiki.apache.org/hadoop/Hive/TipsForAddingNewTests]. Please add to it any other points that you feel contributors should take into consideration while adding new tests., Thanks for the doc Arvind.  

But for the patch:  we need the ORDER BY on the SELECT that produces results in the output log (not the INSERT)., yes - thats what my intention was. Thanks for catching it.
, +1.  Will commit when tests pass.
, Committed.  Thanks Arvind!
]