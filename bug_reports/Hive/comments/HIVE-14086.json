[SQL to create table (avro.sql):
{noformat}
CREATE TABLE avro_table
  PARTITIONED BY (str_part STRING)
  ROW FORMAT SERDE
  'org.apache.hadoop.hive.serde2.avro.AvroSerDe'
  STORED AS INPUTFORMAT
  'org.apache.hadoop.hive.ql.io.avro.AvroContainerInputFormat'
  OUTPUTFORMAT
  'org.apache.hadoop.hive.ql.io.avro.AvroContainerOutputFormat'
  TBLPROPERTIES (
    'avro.schema.url'='hdfs://localhost:20500/tmp/avro.json'
  );
{noformat}

avro.json:
{noformat}
{
    "namespace": "com.cloudera.test",
    "name": "avro_table",
    "type": "record",
    "fields": [
    { "name":"string1", "type":"string" },
    { "name":"CamelCol", "type":"string" }
    ]
    }
{noformat}

avroremoved.json (one column removed from schema):
{noformat}
{
    "namespace": "com.cloudera.test",
    "name": "avro_table",
    "type": "record",
    "fields": [
    { "name":"string1", "type":"string" }
    ]
    }
{noformat}, [~lv] I think you can get the actual schema from the following method: {{get_schema(String db, String tableName)}}

The {{get_schema}} method will return the partition columns (read from COLUMNS_V2) and the regular columns (read from the table serialization library). The serialization library will build the columns from what Hive uses as schema on the table. This schema should be based on the {{avro.schema.url}}, [~spena] - Thanks for the update. Has this been added to Hive recently? Can you point me to a commit that adds the feature?, Note that since 2.0 (HIVE-11985) the column names for serdes with external schemas are generally not stored in metastore anymore.]