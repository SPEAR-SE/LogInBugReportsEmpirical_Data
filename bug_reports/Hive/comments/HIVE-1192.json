[I'll get 0.20.1 added to the FB mirror.  Any others?, bq. I'll get 0.20.1 added to the FB mirror. Any others? 

Yes: 0.17.0, 0.17.1, 0.17.2, 0.18.1, 0.18.2, 0.19.1, and 0.19.2. I think that anything listed [here|http://archive.apache.org/dist/hadoop/core/] with a minor version >= 17 is fair game.

What do you think of my suggestion that we repackage these tarballs using names that drop the patch number?, I don't think we should drop the patch number, since someone may want a specific version.  But we can improve the wiki docs about which versions can be obtained where and what to do if you don't care about patch number.
, For this particular application I don't think the patch numbers matter. We download
the Hadoop tarballs in order to obtain the jars which are referenced when the
shims are built in order to satisfy the compiler. Since the API does not change between
patch versions there is no difference between using 0.20.1 and 0.20.0, etc for this
step. Subsequently, the contents of these tarballs are not referenced at all --
we expect users to supply their own installation of Hadoop. I think it's a bug
that our build currently thinks there is a difference between 0.20.0 and 0.20.1.
Am I missing something?

, hadoop.version is used for running tests too (not just for building shims).

From "test" target in build-common.xml:

      <env key="HADOOP_HOME" value="${hadoop.root}"/>

From build.properties:

hadoop.version.ant-internal=${hadoop.version}
hadoop.root.default=${build.dir.hadoop}/hadoop-${hadoop.version.ant-internal}
hadoop.root=${hadoop.root.default}

, Wiki docs updated here:

http://wiki.apache.org/hadoop/Hive/HowToContribute#Hadoop_Dependencies
, I am trying to build 0.5.0 for Hadoop 0.20.1.  It looks like 0.20.1 is only available on http://archive.apache.org/dist.  So I set hadoop.mirror to that but I am getting the same error as in HIVE-984:

https://issues.apache.org/jira/browse/HIVE-984

I can connect and download the file but there is a problem with the checksum.

What do I need to do to proceed?, Hmmm, looks like the mirrors have been updated to 0.20.2.  Facebook hasn't yet gotten around to provisioning more archival versions under mirror.facebook.net/facebook/hive-deps.

If you can't use 0.20.2, you could 
* retry with archive.apache.org (sometimes it is under too much load)
* or see if you can google for a mirror which didn't get refreshed
* or else try downloading it through some other means such as wget (ivy seems to be very sensitive to network problems)
, Meanwhile, I'm pinging Facebook ops to see if we can get 0.20.1 added to mirror.facebook.net/facebook/hive-deps., 0.20.1 is there now...Bill, can you try it?
, John/Bill: Ivy can't download the 0.20.1 tarball off of archive.apache.org because
the associated md5 checksum file does not adhere to convention, i.e. it was not created
by running 'md5sum' on the tarball.

For example, compare the following two files:
http://mirror.facebook.net/facebook/hive-deps/hadoop/core/hadoop-0.20.0/hadoop-0.20.0.tar.gz.md5
http://mirror.facebook.net/facebook/hive-deps/hadoop/core/hadoop-0.20.1/hadoop-0.20.1.tar.gz.md5

The checksum file for 0.20.0 contains the output of md5sum. The checksum file for 0.20.1
contains a bunch of checksums generated using some other tool. Ivy barfs when it tries to located
the md5 checksum in this mess.
, If someone regenerates the correctly formatted .md5 file and tests it, I can get the bad one replaced on mirror.facebook.net.
, @John: I attached a correctly formatted version of the md5 checksum file for the 0.20.1 tarball., As Carl has pointed out, I have no problem downloading the file.  But ivy fails because of the bad checksum., A temporary workaround for this problem is to set the property ivy.checksums="" in ivy/ivysettings.xml:

{code}
<property name="ivy.checksums" value=""/>
{code}

This has the affect of disabling checksum checks., Thanks Carl.  I'm working on getting the corrected checksum uploaded.

Note that in the past, the checksums have actually been needed for detecting bad downloads from archive.apache.org when it was overloaded.

Is there a JIRA open for Apache to keep the release directories ivy-friendly?  Or maybe it has already been corrected for later releases?
, @John: As far as I know 0.20.1 is the only release on archive.apache.org with a bogus md5 file.
I raised this issue on common-user a couple months ago and got no response.  I just filed
HADOOP-6737 to track this problem., Checksum file has been corrected; please retry.
, I think we can close this one now?
, I just ran into this issue building the latest hive checkout.  Ivy somehow fails to retrieve the sources for 0.20.1 (notice how it's not in the list below): 
{code}
[ivy:retrieve]  confs: [default]
[ivy:retrieve]  found hadoop#core;0.17.2.1 in hadoop-source
[ivy:retrieve]  found hadoop#core;0.18.3 in hadoop-source
[ivy:retrieve]  found hadoop#core;0.19.0 in hadoop-source
[ivy:retrieve]  found hadoop#core;0.20.0 in hadoop-source
[ivy:retrieve] :: resolution report :: resolve 5143ms :: artifacts dl 5ms
{code}

I could get the build to work by doing wget http://mirror.facebook.net/facebook/hive-deps/hadoop/core/hadoop-0.20.1/hadoop-0.20.1.tar.gz and uncompressing into $HIVE_SRC/build/hadoopcore, but this is an unsatisfactory solution since we are trying to automate all builds.  Any ideas on a better fix?, I am still encountering problems with this on a Hudson continuous build server. It works find on the command line, but on Hudson it fails. Here is a small change to build-common.xml that detects if the relevant files are in the build/hadoopcore directory, and if so skips the ivy:retrieve phase, so if necessary you can retrieve them by hand. At the moment that is not possible., Changes to build-common.xml to skip the ivy:retrieve phase if the files are already present. ]