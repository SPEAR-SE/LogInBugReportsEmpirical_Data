[Looking at the code, it appears to be safe to create a new buffer that does not contain all of the previous rows' values, if the existing buffer size gets too big., So, the expression newLength *= 2 can get too large and wrap back causing an infinite loop?

Yes, and yes we do not necessarily need to copy the old values since they are referenced in the byte[][] vector, Attaching patch v1:
- Don't grow current buffer the new size will exceed 1MB
- Check for overflow while doing newLength *= 2, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12849014/HIVE-15700.1.patch

{color:red}ERROR:{color} -1 due to no test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 16 failed/errored test(s), 10990 tests executed
*Failed tests:*
{noformat}
TestDerbyConnector - did not produce a TEST-*.xml file (likely timed out) (batchId=235)
org.apache.hadoop.hive.cli.TestBlobstoreCliDriver.testCliDriver[ctas] (batchId=231)
org.apache.hadoop.hive.cli.TestBlobstoreCliDriver.testCliDriver[insert_into_dynamic_partitions] (batchId=231)
org.apache.hadoop.hive.cli.TestBlobstoreCliDriver.testCliDriver[insert_into_table] (batchId=231)
org.apache.hadoop.hive.cli.TestBlobstoreCliDriver.testCliDriver[insert_overwrite_directory] (batchId=231)
org.apache.hadoop.hive.cli.TestBlobstoreCliDriver.testCliDriver[insert_overwrite_dynamic_partitions] (batchId=231)
org.apache.hadoop.hive.cli.TestBlobstoreCliDriver.testCliDriver[insert_overwrite_table] (batchId=231)
org.apache.hadoop.hive.cli.TestBlobstoreCliDriver.testCliDriver[write_final_output_blobstore] (batchId=231)
org.apache.hadoop.hive.cli.TestEncryptedHDFSCliDriver.testCliDriver[encryption_join_with_different_encryption_keys] (batchId=159)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[offset_limit_ppd_optimizer] (batchId=151)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[optimize_nullscan] (batchId=153)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_text_vec_part] (batchId=149)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_if_expr] (batchId=140)
org.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver[bucket5] (batchId=162)
org.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver[list_bucket_dml_10] (batchId=160)
org.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver[reduce_deduplicate] (batchId=162)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/3135/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/3135/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-3135/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 16 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12849014 - PreCommit-HIVE-Build, Test failures are all previously existing failures., Ok, I’ve been thinking about this.

First, I think the old code’s idea of doubling the buffer and copying old data isn’t great.  We are copying old data that doesn’t need to be copied – the old byte[][] vector is still referencing that old buffer.

The memory usage of BytesColumnVector is cyclical.  Rather than doubling the buffer I think we should just allocate another buffer with the old size and start at the beginning of it.  So for this cycle we’d have more than one buffer.  If the new request is so large the old size is inadequate, then of course take the max of the old buffer size and the new request size.  In effect, very large requests would just get their own buffer.

Add more bookkeeping the notice the largest amount of data used in a long member for the cycle.

When we reset the BytesColumnVector, we can then decide what do with the current buffer.  Perhaps the old buffer needs to be let go and a new larger buffer allocated.   But if we have been allocating a bunch of large buffers for large requests, perhaps we let the old buffer be.
, [~gopalv] FYI, Patch v2:
- Keeps re-using the same buffer for small writes (<= 1MB) when possible. This was an offline suggestion from [~mmccline]. If the small buffer fills up a new one is allocated (double the old size) for subsequent small writes, and the old values continue to reference the old buffer.
- Large writes (> 1MB) get their own buffer., 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12849487/HIVE-15700.2.patch

{color:green}SUCCESS:{color} +1 due to 1 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 5 failed/errored test(s), 11001 tests executed
*Failed tests:*
{noformat}
TestDerbyConnector - did not produce a TEST-*.xml file (likely timed out) (batchId=235)
org.apache.hadoop.hive.cli.TestEncryptedHDFSCliDriver.testCliDriver[encryption_join_with_different_encryption_keys] (batchId=159)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_text_vec_part] (batchId=149)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainuser_3] (batchId=93)
org.apache.hadoop.hive.ql.exec.vector.expressions.TestVectorStringExpressions.testLoadBytesColumnVectorByValueLargeData (batchId=266)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/3197/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/3197/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-3197/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 5 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12849487 - PreCommit-HIVE-Build, Failure in schema_evol_text_vec_part looks like it may be due to HIVE-15734
TestVectorStringExpressions.testLoadBytesColumnVectorByValueLargeData needs an adjustment in the test - the new reallocation logic does allocate a new buffer but not as large as expected in the test., 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12849572/HIVE-15700.3.patch

{color:green}SUCCESS:{color} +1 due to 2 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 6 failed/errored test(s), 11003 tests executed
*Failed tests:*
{noformat}
TestDerbyConnector - did not produce a TEST-*.xml file (likely timed out) (batchId=235)
org.apache.hadoop.hive.cli.TestEncryptedHDFSCliDriver.testCliDriver[encryption_join_with_different_encryption_keys] (batchId=159)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_varchar_simple] (batchId=153)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainuser_3] (batchId=93)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query23] (batchId=223)
org.apache.hive.hcatalog.pig.TestHCatLoaderComplexSchema.testTupleInBagInTupleInBag[2] (batchId=173)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/3206/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/3206/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-3206/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 6 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12849572 - PreCommit-HIVE-Build, [~mmccline] can you review?, Moving reset of bufferAllocationCount to initBuffer() per [~mmccline]'s suggestion, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12850309/HIVE-15700.4.patch

{color:green}SUCCESS:{color} +1 due to 2 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 4 failed/errored test(s), 11016 tests executed
*Failed tests:*
{noformat}
TestDerbyConnector - did not produce a TEST-*.xml file (likely timed out) (batchId=235)
org.apache.hadoop.hive.cli.TestEncryptedHDFSCliDriver.testCliDriver[encryption_join_with_different_encryption_keys] (batchId=159)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_char_simple] (batchId=147)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=223)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/3288/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/3288/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-3288/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 4 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12850309 - PreCommit-HIVE-Build, failures not related, +1 LGTM, Committed to master]