[issue is related to https://issues.apache.org/jira/browse/HIVE-12274 but need to fix at two places though, How frustrating, after all this time we seem to be getting further away from a solution rather than closer., We're running Hive on EMR 5 which uses Hive 2.x. We are now completely blocked on migrating some of our tables over to this since they have metadata (a json serde schema) which when stored in the DB exceeds this value. In the past on EMR 4 using Hive 1.x we did the (not ideal) workaround of increasing the size in the underlying database but now that this check is also in Java code that doesn't work any more. Ideally we'd like the types in the underlying DB to be unbounded (i.e. TEXT) and then for any checks in the Java code to match what's in the DB rather than having this implemented (and maintained) in two separate places. Perhaps the Java code checks should be completely removed and the checks just implemented in the DB?, I have attached a patch to HIVE-12274. Please try the patch and let me know if it resolves the issue. It will also provide me additional validation that it resolves the issue. Thanks, [~ngangam] 
Thanks for addressing this.
I've look through the patch (haven't applied it) but it doesn't touch any java code. In order to fix this this check needs to be addressed. 
https://github.com/apache/hive/blob/master/metastore/src/java/org/apache/hadoop/hive/metastore/MetaStoreUtils.java#L696
Used here:
https://github.com/apache/hive/blob/master/metastore/src/java/org/apache/hadoop/hive/metastore/MetaStoreUtils.java#L708

I can confirm that changing the COLUMNS_V2.COLUMN TYPE_NAME as done in the patch fixes the DB issue but a create/alter table will still fail due to the error described in this ticket., Can we just remove the 
{code}
if (type.length() > MAX_MS_TYPENAME_LENGTH) {
      return "type name is too long: " + type;
}
{code}
entirely so we don't have to keep these lengths synchronised in two places? Or somehow derive the max length from the length of the type in the db rather than having it a hard coded constant in that class?, [~patduin] Thank you for the pointer. I thought my testcase that created a column of a large struct type succeeded. I will have to re-run the scenario. I have had to run schema tests, upgrade scenarios against 4 different databases installations that I may have missed this failure. 
[~massdosage@gmail.com] To me, it makes sense to remove this check and just have the JDO layer (or database layer in case of DirectSQL) enforce it. I will look into the history as to why this was put in place in the first place. Thanks for the suggestion., [~ngangam] - agreed on the approach of removing the check if possible, good luck in digging into the history to find why this was added, we're very curious too!, Fix for this issue has been included as part of a larger fix in HIVE-12274. Closing this jira., [~ngangam], the fix version should be 2.3.0 instead of 2.2.0.  (See my comment on HIVE-12274.), Hive 3.0.0 has been released so closing this jira.]