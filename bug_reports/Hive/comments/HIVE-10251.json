[Hi [~nntnag17], can you please prepare a patch for this problem and submit it for review? Thanks., rb: https://reviews.apache.org/r/32966/, Left feedback on the patch. Also should we have JUnits proving that the patch is actually fixing the issue?, Thanks for the quick patch, Anant!

Looking through the changes, I'm +1 on this patch fixing this breakage, and not introducing any new breakage that I can see. Manual testing shows that this patch fixes the primary issue.

There are review comments though, and normally, we'd wait till all comments are resolved before applying the patch.

As to unit testing this, we could have a mock test, potentially, that shows that using a method from this class still works if ClassLoader.getSystemResource is not used statically as it currently is.

That said, as of right now, hive-trunk is broken for environments that do not have an ivysettings.xml file, and we need to fix it soon. We have a couple of options at hand that I see:

a) Revert HIVE-9664 till we have a fix for this that we're comfortable is the right fix and works properly, and then we can re-apply both.
b) Go ahead and apply HIVE-10251, possibly ignoring the 24hr moratorium, and take on an addendum jira to handle review comments and hardening of this issue's unit tests, etc.

Any thoughts? I'm personally leaning towards (b), but we do need to move quickly to fix trunk., Attaching trivial patch for HIVE-10251, One more possibility, is:

c) we can commit a trivial fix as with the above attached HIVE-10251.simple.patch that addresses only this breakage and nothing else, and handle redoing DependencyResolver per Anant's patch as a separate patch. That way, we fix trunk, we don't have to revert HIVE-9664, and we can spend as much time as it takes to address review comments for DependencyResolver's instantiation as needed., Okay, on thinking about this a bit more, I don't know that it quite meets the bar for breaking the 24hr moratorium for the new trivial patch, or fast-forwarding this current patch especially since we'd at least have to wait for hive_qe to finish running tests on it. This is still a breakage for other components like flume that use hive, since their environments include hive as jars, rather than necessarily working against a deployed hive environment which might contain an ivysettings.xml file. But, then, that's the cost of those other components being developed against hive trunk rather than a hive released branch.

So, here's what I think I'm going to do:

a) Open a new jira cloning this for the trivial patch, to fix the breakage. That one's scope will be limited to fixing the issue as determined by manual testing. This patch can get committed in 24 hours.
b) This current jira can continue to be developed upon, by Anant, till all the reviewers are happy with the changes and unit tests/etc.
, Created HIVE-10267 for tracking that., Can we fix this problem by bundling a default copy of ivysettings.xml in one of the JAR files while giving preference to the first non-bundled copy of ivysettings.xml found on the classpath?, Latest patch after addressing comments in the rb., hi [~sushanth],

I've addressed the comments in the rb and updated the patch. I'm not sure about how to do unit testing on this since ivysettings.xml file is added to the classpath while running unit tests. Also there is a default  defaultGrapeConfig.xml file shipped in the groovy jar which will be used if ivysettings.xml is not found in the classpath. Any suggestions or comments on how to do this?, [~cwsteinbach]:

I had a discussion with [~arpitgupta] yesterday, who seemed to advocate the same idea of shipping ivysettings.xml inside the jar, since we already do things like shipping hadoop-default.xml inside hadoop jars, for example.

On one hand, I like that idea, since it simplifies build & release, and makes it so that this feature is controlled by our build, rather than whatever build/packaging scheme is used on top of hive, and whether or not the conf dir is appropriately set up. As in, if the conf dir were to be set up, we'd prefer that, but otherwise, we'd use ours. This has a very solid benefit for us.

On the flip side, this feels similar to namespace pollution for me - users of our jars will now have an ivysettings.xml in their classpath because of us, and if they don't have similar dependency resolution semantics where they prefer an external provided ivysettings.xml over the one in classpath, they have an issue. Also, if they use a ivysettings.xml in their classpath mode of operation, then order of jar import becomes important.

Ultimately, my distaste for this approach is not strong enough to offset the benefits, I think, and a case could still be made that a jar user could go ahead and shade our jar, or override as need be. We could also take a midling approach where the included xml file can be called something like hive-ivysettings-default.xml, and that's the name we depend on, then there's no confusion or pollution.

[~nntnag17]:

One way to unit test this would be as follows :

a) Have a protected method in DependencyResolver that returns ClassLoader.getSystemResource(String), and use that method across DependencyResolver across the board, instead of directly calling ClassLoader.getSystemResource(...).
b) In a unit test, then, you can extend DependencyResolver to DummyDependencyResolver, overriding that method so that it always returns null for resolving ivysettings.xml or whatever, and then you can show that you can still instantiate it, and resolve using it, although it would then return nothing, but without throwing exceptions. You could also use a DependencyResolver as-is, to show that it appropriately can resolve and fetch ivy urls when required., (Forgive me if this idea idea is stupid, because of my limited knowledge of ivy). Is it possible do do something like hadoop's *defualt.xml vs *site.xml ? Ie, package something like ivysettings-hivedefault.xml as the default file in jar and then use that only if there is no ivysettings.xml in path ? (or iveysettings-hivesite.xml).
Would that address the concerns [~sushanth] ?
, [~thejas] : Yup, that's exactly what I was suggesting - since we're the ones doing the dependency resolution, we can look for ivysettings.xml in conf dir and then classpath, and if not found, fall back to hive-ivysettings-default.xml, which we can package in our jars., bq. Yup, that's exactly what I was suggesting
Sorry, missed that last line your earlier comment!
, +1 for the hive-ivysettings-default.xml approach., Anant, I've committed HIVE-10267 so trunk is in a stable state, but this means you'll have to refactor your patch slightly. Also, could you please implement the hive-ivysettings-default.xml approach discussed here, and add it to the jar(probably to hive-exec, I think) packaging?, *Added hive-ivysettings-default.xml to hive-exec jar.
*Moved ivysettings.xml check to separate function.
* Added unit test., [~sushanth],


bq. a) Have a protected method in DependencyResolver that returns ClassLoader.getSystemResource(String), and use that method across DependencyResolver across the board, instead of directly calling ClassLoader.getSystemResource(...).
bq. b) In a unit test, then, you can extend DependencyResolver to DummyDependencyResolver, overriding that method so that it always returns null for resolving ivysettings.xml or whatever
The problem here is that DependencyResolver is a singleton class which checks for ivysettings in the constructor. So even if I'm able to mock it or create a subclass, the constructor would be called before I could define the behavior of any of its methods. 
                                      One solution I can think of is to create a method getIvySettings() and call it before downloading dependencies in the downloadDependencies method and have a protected method for getting system resource as you suggested. I can then mock that method to return different values  and then check for graceful exit. I've implemented this solution in the updated patch. Please give your comments. 

bq.  Also, could you please implement the hive-ivysettings-default.xml approach discussed here,

I've implemented the hive-ivysettings-default.xml approach in the updated patch. 
, 

{color:red}Overall{color}: -1 at least one tests failed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12724559/HIVE-10251.3.patch

{color:red}ERROR:{color} -1 due to 25 failed/errored test(s), 8674 tests executed
*Failed tests:*
{noformat}
TestMinimrCliDriver-bucketmapjoin6.q-constprog_partitioner.q-infer_bucket_sort_dyn_part.q-and-1-more - did not produce a TEST-*.xml file
TestMinimrCliDriver-external_table_with_space_in_location_path.q-infer_bucket_sort_merge.q-auto_sortmerge_join_16.q-and-1-more - did not produce a TEST-*.xml file
TestMinimrCliDriver-groupby2.q-import_exported_table.q-bucketizedhiveinputformat.q-and-1-more - did not produce a TEST-*.xml file
TestMinimrCliDriver-index_bitmap3.q-stats_counter_partitioned.q-temp_table_external.q-and-1-more - did not produce a TEST-*.xml file
TestMinimrCliDriver-infer_bucket_sort_map_operators.q-join1.q-bucketmapjoin7.q-and-1-more - did not produce a TEST-*.xml file
TestMinimrCliDriver-infer_bucket_sort_num_buckets.q-disable_merge_for_bucketing.q-uber_reduce.q-and-1-more - did not produce a TEST-*.xml file
TestMinimrCliDriver-infer_bucket_sort_reducers_power_two.q-scriptfile1.q-scriptfile1_win.q-and-1-more - did not produce a TEST-*.xml file
TestMinimrCliDriver-leftsemijoin_mr.q-load_hdfs_file_with_space_in_the_name.q-root_dir_external_table.q-and-1-more - did not produce a TEST-*.xml file
TestMinimrCliDriver-list_bucket_dml_10.q-bucket_num_reducers.q-bucket6.q-and-1-more - did not produce a TEST-*.xml file
TestMinimrCliDriver-load_fs2.q-file_with_header_footer.q-ql_rewrite_gbtoidx_cbo_1.q-and-1-more - did not produce a TEST-*.xml file
TestMinimrCliDriver-parallel_orderby.q-reduce_deduplicate.q-ql_rewrite_gbtoidx_cbo_2.q-and-1-more - did not produce a TEST-*.xml file
TestMinimrCliDriver-ql_rewrite_gbtoidx.q-smb_mapjoin_8.q - did not produce a TEST-*.xml file
TestMinimrCliDriver-schemeAuthority2.q-bucket4.q-input16_cc.q-and-1-more - did not produce a TEST-*.xml file
org.apache.hadoop.hive.ql.session.TestDependencyResolver.testForSuccessfulDownload
org.apache.hadoop.hive.thrift.TestHadoop20SAuthBridge.testMetastoreProxyUser
org.apache.hadoop.hive.thrift.TestHadoop20SAuthBridge.testSaslWithHiveMetaStore
org.apache.hive.jdbc.TestJdbcWithMiniHS2.testNewConnectionConfiguration
org.apache.hive.jdbc.TestSSL.testSSLFetchHttp
org.apache.hive.spark.client.TestSparkClient.testAddJarsAndFiles
org.apache.hive.spark.client.TestSparkClient.testCounters
org.apache.hive.spark.client.TestSparkClient.testErrorJob
org.apache.hive.spark.client.TestSparkClient.testJobSubmission
org.apache.hive.spark.client.TestSparkClient.testMetricsCollection
org.apache.hive.spark.client.TestSparkClient.testSimpleSparkJob
org.apache.hive.spark.client.TestSparkClient.testSyncRpc
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/3363/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/3363/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-3363/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 25 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12724559 - PreCommit-HIVE-TRUNK-Build, Hi Anant,

One more note - HIVE09664 also makes changes in itests/pom.xml that are not portable:

{code}
diff --git a/itests/pom.xml b/itests/pom.xml
index fd4bb41fd8f74cdf261b791d1944dbca4b04f927..6f6cf742c41a11647589692ac4f266f467be2812 100644
--- a/itests/pom.xml
+++ b/itests/pom.xml
@@ -93,6 +93,9 @@
                   mkdir -p $DOWNLOAD_DIR
                   download "http://d3jw87u4immizc.cloudfront.net/spark-tarball/spark-${spark.version}-bin-hadoop2-without-hive.tgz" "spark"
                   cp -f $HIVE_ROOT/data/conf/spark/log4j.properties $BASE_DIR/spark/conf/
+                  sed '/package /d' ${basedir}/${hive.path.to.root}/contrib/src/java/org/apache/hadoop/hive/contrib/udf/example/UDFExampleAdd.java > /tmp/UDFExampleAdd.java
+                  javac -cp  ${settings.localRepository}/org/apache/hive/hive-exec/${project.version}/hive-exec-${project.version}.jar /tmp/UDFExampleAdd.java -d /tmp
+                  jar -cf /tmp/udfexampleadd-1.0.jar -C /tmp UDFExampleAdd.class
                 </echo>
               </target>
             </configuration>
{code}

sed is not something that's available in windows, and instead of compiling UDFExampleAdd.java in here, it might be better to create another quick jar build in the contrib package, and depend on it from the qtests to show that we're able to appropriately add jars., Hi Sushanth,

Creating a jar build in the contrib package will put the jar in the classpath while running the qtest tests which will make ivyDownload.q test invalid. We need to have a jar which is not in the classpath while running the ivyDownload.q test. I think we should compile it either here in itests/pom.xml or itests/qtest/pom.xml and use it from the qtest.
             Also, I already have  HIVE-10376 open which moves this code to qtest/pom.xml. I can modify that Jira to also include the code to make it portable. Your thoughts?, Resolving as this was superseded by HIVE-10267.]