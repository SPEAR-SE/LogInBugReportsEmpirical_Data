[Updates the Assigned messages to include status of the node to which the fragment was assigned. Fixes some other messages. Moves metrics for addNode to the correct place, and fixes the re-enablement of nodes.

cc [~prasanth_j], [~sershe] for review., Minor update to the patch., +1. Are jiras needed for all the TODOs?, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12855729/HIVE-16097.01.patch

{color:red}ERROR:{color} -1 due to build exiting with an error

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/3910/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/3910/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-3910/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Tests exited with: ExecutionException: java.util.concurrent.ExecutionException: org.apache.hive.ptest.execution.ssh.SSHExecutionException: RSyncResult [localFile=/data/hiveptest/logs/PreCommit-HIVE-Build-3910/failed/272_UTBatch_ql_10_tests, remoteFile=/home/hiveptest/104.154.214.200-hiveptest-0/logs/, getExitCode()=11, getException()=null, getUser()=hiveptest, getHost()=104.154.214.200, getInstance()=0]: 'Warning: Permanently added '104.154.214.200' (ECDSA) to the list of known hosts.
receiving incremental file list
./
TEST-272_UTBatch_ql_10_tests-TEST-org.apache.hadoop.hive.ql.TestTxnCommands.xml

              0   0%    0.00kB/s    0:00:00  
          8,245 100%    7.86MB/s    0:00:00 (xfr#1, to-chk=9/11)
TEST-272_UTBatch_ql_10_tests-TEST-org.apache.hadoop.hive.ql.lockmgr.TestEmbeddedLockManager.xml

              0   0%    0.00kB/s    0:00:00  
          5,269 100%    5.02MB/s    0:00:00 (xfr#2, to-chk=8/11)
TEST-272_UTBatch_ql_10_tests-TEST-org.apache.hadoop.hive.ql.lockmgr.TestHiveLockObject.xml

              0   0%    0.00kB/s    0:00:00  
          5,269 100%    5.02MB/s    0:00:00 (xfr#3, to-chk=7/11)
TEST-272_UTBatch_ql_10_tests-TEST-org.apache.hadoop.hive.ql.lockmgr.zookeeper.TestZookeeperLockManager.xml

              0   0%    0.00kB/s    0:00:00  
          5,562 100%    5.30MB/s    0:00:00 (xfr#4, to-chk=6/11)
maven-test.txt

              0   0%    0.00kB/s    0:00:00  
          6,526 100%    6.22MB/s    0:00:00 (xfr#5, to-chk=5/11)
logs/
logs/derby.log

              0   0%    0.00kB/s    0:00:00  
            978 100%  955.08kB/s    0:00:00 (xfr#6, to-chk=2/11)
logs/hive.log

              0   0%    0.00kB/s    0:00:00  
     44,990,464   0%   42.91MB/s    0:11:50  
     90,505,216   0%   43.09MB/s    0:11:46  
rsync: write failed on "/data/hiveptest/logs/PreCommit-HIVE-Build-3910/failed/272_UTBatch_ql_10_tests/logs/hive.log": No space left on device (28)
rsync error: error in file IO (code 11) at receiver.c(393) [receiver=3.1.1]
Warning: Permanently added '104.154.214.200' (ECDSA) to the list of known hosts.
receiving incremental file list
logs/
logs/hive.log

              0   0%    0.00kB/s    0:00:00  
rsync: write failed on "/data/hiveptest/logs/PreCommit-HIVE-Build-3910/failed/272_UTBatch_ql_10_tests/logs/hive.log": No space left on device (28)
rsync error: error in file IO (code 11) at receiver.c(393) [receiver=3.1.1]
Warning: Permanently added '104.154.214.200' (ECDSA) to the list of known hosts.
receiving incremental file list
logs/
logs/hive.log

              0   0%    0.00kB/s    0:00:00  
rsync: write failed on "/data/hiveptest/logs/PreCommit-HIVE-Build-3910/failed/272_UTBatch_ql_10_tests/logs/hive.log": No space left on device (28)
rsync error: error in file IO (code 11) at receiver.c(393) [receiver=3.1.1]
Warning: Permanently added '104.154.214.200' (ECDSA) to the list of known hosts.
receiving incremental file list
logs/
logs/hive.log

              0   0%    0.00kB/s    0:00:00  
rsync: write failed on "/data/hiveptest/logs/PreCommit-HIVE-Build-3910/failed/272_UTBatch_ql_10_tests/logs/hive.log": No space left on device (28)
rsync error: error in file IO (code 11) at receiver.c(393) [receiver=3.1.1]
Warning: Permanently added '104.154.214.200' (ECDSA) to the list of known hosts.
receiving incremental file list
logs/
logs/hive.log

              0   0%    0.00kB/s    0:00:00  
rsync: write failed on "/data/hiveptest/logs/PreCommit-HIVE-Build-3910/failed/272_UTBatch_ql_10_tests/logs/hive.log": No space left on device (28)
rsync error: error in file IO (code 11) at receiver.c(393) [receiver=3.1.1]
'
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12855729 - PreCommit-HIVE-Build, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12855729/HIVE-16097.01.patch

{color:red}ERROR:{color} -1 due to build exiting with an error

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/3914/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/3914/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-3914/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Tests exited with: ExecutionException: java.util.concurrent.ExecutionException: org.apache.hive.ptest.execution.ssh.SSHExecutionException: RSyncResult [localFile=/data/hiveptest/logs/PreCommit-HIVE-Build-3914/succeeded/218_UTBatch_itests__hive-unit_9_tests, remoteFile=/home/hiveptest/130.211.153.161-hiveptest-0/logs/, getExitCode()=11, getException()=null, getUser()=hiveptest, getHost()=130.211.153.161, getInstance()=0]: 'Warning: Permanently added '130.211.153.161' (ECDSA) to the list of known hosts.
receiving incremental file list
./
TEST-218_UTBatch_itests__hive-unit_9_tests-TEST-org.apache.hive.jdbc.TestJdbcWithLocalClusterSpark.xml

              0   0%    0.00kB/s    0:00:00  
          5,753 100%    5.49MB/s    0:00:00 (xfr#1, to-chk=54/56)
TEST-218_UTBatch_itests__hive-unit_9_tests-TEST-org.apache.hive.jdbc.TestJdbcWithMiniHS2.xml

              0   0%    0.00kB/s    0:00:00  
          7,896 100%    7.53MB/s    0:00:00 (xfr#2, to-chk=53/56)
TEST-218_UTBatch_itests__hive-unit_9_tests-TEST-org.apache.hive.jdbc.TestJdbcWithMiniLlap.xml

              0   0%    0.00kB/s    0:00:00  
          5,511 100%    5.26MB/s    0:00:00 (xfr#3, to-chk=52/56)
TEST-218_UTBatch_itests__hive-unit_9_tests-TEST-org.apache.hive.jdbc.TestMultiSessionsHS2WithLocalClusterSpark.xml

              0   0%    0.00kB/s    0:00:00  
          5,454 100%    5.20MB/s    0:00:00 (xfr#4, to-chk=51/56)
TEST-218_UTBatch_itests__hive-unit_9_tests-TEST-org.apache.hive.jdbc.TestNoSaslAuth.xml

              0   0%    0.00kB/s    0:00:00  
          5,272 100%    5.03MB/s    0:00:00 (xfr#5, to-chk=50/56)
TEST-218_UTBatch_itests__hive-unit_9_tests-TEST-org.apache.hive.jdbc.TestServiceDiscovery.xml

              0   0%    0.00kB/s    0:00:00  
          5,281 100%  151.68kB/s    0:00:00 (xfr#6, to-chk=49/56)
TEST-218_UTBatch_itests__hive-unit_9_tests-TEST-org.apache.hive.jdbc.TestXSRFFilter.xml

              0   0%    0.00kB/s    0:00:00  
          5,627 100%  161.62kB/s    0:00:00 (xfr#7, to-chk=48/56)
TEST-218_UTBatch_itests__hive-unit_9_tests-TEST-org.apache.hive.jdbc.authorization.TestCLIAuthzSessionContext.xml

              0   0%    0.00kB/s    0:00:00  
          5,341 100%  153.41kB/s    0:00:00 (xfr#8, to-chk=47/56)
TEST-218_UTBatch_itests__hive-unit_9_tests-TEST-org.apache.hive.jdbc.authorization.TestJdbcWithSQLAuthUDFBlacklist.xml

              0   0%    0.00kB/s    0:00:00  
          5,345 100%  153.52kB/s    0:00:00 (xfr#9, to-chk=46/56)
maven-test.txt

              0   0%    0.00kB/s    0:00:00  
          9,088 100%  261.03kB/s    0:00:00 (xfr#10, to-chk=45/56)
logs/
logs/derby.log

              0   0%    0.00kB/s    0:00:00  
          1,020 100%   29.30kB/s    0:00:00 (xfr#11, to-chk=42/56)
logs/hive.log

              0   0%    0.00kB/s    0:00:00  
     16,723,213 100%   31.83MB/s    0:00:00 (xfr#12, to-chk=41/56)
logs/spark-log/
logs/spark-log/app-20170303064938-0000/
logs/spark-log/app-20170303064938-0000/0/
logs/spark-log/app-20170303064938-0000/0/stderr

              0   0%    0.00kB/s    0:00:00  
          3,595 100%    7.01kB/s    0:00:00 (xfr#13, to-chk=32/56)
logs/spark-log/app-20170303064938-0000/0/stdout

              0 100%    0.00kB/s    0:00:00 (xfr#14, to-chk=31/56)
logs/spark-log/app-20170303064938-0000/1/
logs/spark-log/app-20170303064938-0000/1/hive-exec-2.2.0-SNAPSHOT.jar

              0   0%    0.00kB/s    0:00:00  
     23,789,568  69%   22.55MB/s    0:00:00  
     34,103,628 100%   27.19MB/s    0:00:01 (xfr#15, to-chk=30/56)
logs/spark-log/app-20170303064938-0000/1/stderr

              0   0%    0.00kB/s    0:00:00  
         11,698 100%   60.13kB/s    0:00:00 (xfr#16, to-chk=29/56)
logs/spark-log/app-20170303064938-0000/1/stdout

              0 100%    0.00kB/s    0:00:00 (xfr#17, to-chk=28/56)
logs/spark-log/app-20170303064942-0000/
logs/spark-log/app-20170303064942-0000/0/
logs/spark-log/app-20170303064942-0000/0/hive-exec-2.2.0-SNAPSHOT.jar

              0   0%    0.00kB/s    0:00:00  
     34,103,628 100%   36.92MB/s    0:00:00 (xfr#18, to-chk=25/56)
logs/spark-log/app-20170303064942-0000/0/stderr

              0   0%    0.00kB/s    0:00:00  
         11,791 100%   13.07kB/s    0:00:00 (xfr#19, to-chk=24/56)
logs/spark-log/app-20170303064942-0000/0/stdout

              0 100%    0.00kB/s    0:00:00 (xfr#20, to-chk=23/56)
logs/spark-log/app-20170303064942-0000/1/
logs/spark-log/app-20170303064942-0000/1/stderr

              0   0%    0.00kB/s    0:00:00  
          3,722 100%    4.13kB/s    0:00:00 (xfr#21, to-chk=22/56)
logs/spark-log/app-20170303064942-0000/1/stdout

              0 100%    0.00kB/s    0:00:00 (xfr#22, to-chk=21/56)
logs/spark-log/app-20170303064945-0000/
logs/spark-log/app-20170303064945-0000/0/
logs/spark-log/app-20170303064945-0000/0/hive-exec-2.2.0-SNAPSHOT.jar

              0   0%    0.00kB/s    0:00:00  
      5,570,560  16%    5.31MB/s    0:00:05  
     34,103,628 100%   20.76MB/s    0:00:01 (xfr#23, to-chk=18/56)
logs/spark-log/app-20170303064945-0000/0/stderr

              0   0%    0.00kB/s    0:00:00  
         11,698 100%   20.22kB/s    0:00:00 (xfr#24, to-chk=17/56)
logs/spark-log/app-20170303064945-0000/0/stdout

              0 100%    0.00kB/s    0:00:00 (xfr#25, to-chk=16/56)
logs/spark-log/app-20170303064945-0000/1/
logs/spark-log/app-20170303064945-0000/1/stderr

              0   0%    0.00kB/s    0:00:00  
          3,545 100%    6.13kB/s    0:00:00 (xfr#26, to-chk=15/56)
logs/spark-log/app-20170303064945-0000/1/stdout

              0 100%    0.00kB/s    0:00:00 (xfr#27, to-chk=14/56)
logs/spark-log/app-20170303065034-0000/
logs/spark-log/app-20170303065034-0000/0/
logs/spark-log/app-20170303065034-0000/0/stderr

              0   0%    0.00kB/s    0:00:00  
          3,390 100%    5.85kB/s    0:00:00 (xfr#28, to-chk=11/56)
logs/spark-log/app-20170303065034-0000/0/stdout

              0 100%    0.00kB/s    0:00:00 (xfr#29, to-chk=10/56)
logs/spark-log/app-20170303065034-0000/1/
logs/spark-log/app-20170303065034-0000/1/hive-exec-2.2.0-SNAPSHOT.jar

              0   0%    0.00kB/s    0:00:00  
     21,364,736  62%   20.38MB/s    0:00:00  
     34,103,628 100%   26.02MB/s    0:00:01 (xfr#30, to-chk=9/56)
logs/spark-log/app-20170303065034-0000/1/stderr

              0   0%    0.00kB/s    0:00:00  
         11,759 100%   45.75kB/s    0:00:00 (xfr#31, to-chk=8/56)
logs/spark-log/app-20170303065034-0000/1/stdout

              0 100%    0.00kB/s    0:00:00 (xfr#32, to-chk=7/56)
logs/spark-log/app-20170303065050-0000/
logs/spark-log/app-20170303065050-0000/0/
logs/spark-log/app-20170303065050-0000/0/hive-exec-2.2.0-SNAPSHOT.jar

              0   0%    0.00kB/s    0:00:00  
rsync: write failed on "/data/hiveptest/logs/PreCommit-HIVE-Build-3914/succeeded/218_UTBatch_itests__hive-unit_9_tests/logs/spark-log/app-20170303065050-0000/0/hive-exec-2.2.0-SNAPSHOT.jar": No space left on device (28)
rsync error: error in file IO (code 11) at receiver.c(393) [receiver=3.1.1]
Warning: Permanently added '130.211.153.161' (ECDSA) to the list of known hosts.
receiving incremental file list
logs/spark-log/app-20170303065050-0000/0/
logs/spark-log/app-20170303065050-0000/0/hive-exec-2.2.0-SNAPSHOT.jar

              0   0%    0.00kB/s    0:00:00  
rsync: write failed on "/data/hiveptest/logs/PreCommit-HIVE-Build-3914/succeeded/218_UTBatch_itests__hive-unit_9_tests/logs/spark-log/app-20170303065050-0000/0/hive-exec-2.2.0-SNAPSHOT.jar": No space left on device (28)
rsync error: error in file IO (code 11) at receiver.c(393) [receiver=3.1.1]
Warning: Permanently added '130.211.153.161' (ECDSA) to the list of known hosts.
receiving incremental file list
logs/spark-log/app-20170303065050-0000/0/
logs/spark-log/app-20170303065050-0000/0/hive-exec-2.2.0-SNAPSHOT.jar

              0   0%    0.00kB/s    0:00:00  
rsync: write failed on "/data/hiveptest/logs/PreCommit-HIVE-Build-3914/succeeded/218_UTBatch_itests__hive-unit_9_tests/logs/spark-log/app-20170303065050-0000/0/hive-exec-2.2.0-SNAPSHOT.jar": No space left on device (28)
rsync error: error in file IO (code 11) at receiver.c(393) [receiver=3.1.1]
Warning: Permanently added '130.211.153.161' (ECDSA) to the list of known hosts.
receiving incremental file list
logs/spark-log/app-20170303065050-0000/0/
logs/spark-log/app-20170303065050-0000/0/hive-exec-2.2.0-SNAPSHOT.jar

              0   0%    0.00kB/s    0:00:00  
rsync: write failed on "/data/hiveptest/logs/PreCommit-HIVE-Build-3914/succeeded/218_UTBatch_itests__hive-unit_9_tests/logs/spark-log/app-20170303065050-0000/0/hive-exec-2.2.0-SNAPSHOT.jar": No space left on device (28)
rsync error: error in file IO (code 11) at receiver.c(393) [receiver=3.1.1]
Warning: Permanently added '130.211.153.161' (ECDSA) to the list of known hosts.
receiving incremental file list
logs/spark-log/app-20170303065050-0000/0/
logs/spark-log/app-20170303065050-0000/0/hive-exec-2.2.0-SNAPSHOT.jar

              0   0%    0.00kB/s    0:00:00  
rsync: write failed on "/data/hiveptest/logs/PreCommit-HIVE-Build-3914/succeeded/218_UTBatch_itests__hive-unit_9_tests/logs/spark-log/app-20170303065050-0000/0/hive-exec-2.2.0-SNAPSHOT.jar": No space left on device (28)
rsync error: error in file IO (code 11) at receiver.c(393) [receiver=3.1.1]
'
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12855729 - PreCommit-HIVE-Build, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12855729/HIVE-16097.01.patch

{color:red}ERROR:{color} -1 due to build exiting with an error

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/3930/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/3930/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-3930/

Messages:
{noformat}
**** This message was trimmed, see log for full details ****
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-common/2.7.2/hadoop-common-2.7.2.jar(org/apache/hadoop/conf/Configuration.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-common/2.7.2/hadoop-common-2.7.2.jar(org/apache/hadoop/fs/Path.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/apache-github-source-source/common/target/hive-common-2.2.0-SNAPSHOT.jar(org/apache/hadoop/hive/conf/HiveConfUtil.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-common/2.7.2/hadoop-common-2.7.2.jar(org/apache/hadoop/util/StringUtils.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-common/2.7.2/hadoop-common-2.7.2.jar(org/apache/hadoop/util/VersionInfo.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/Iterable.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-common/2.7.2/hadoop-common-2.7.2.jar(org/apache/hadoop/io/Writable.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/String.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/eclipse/jetty/aggregate/jetty-all-server/7.6.0.v20120127/jetty-all-server-7.6.0.v20120127.jar(org/eclipse/jetty/http/HttpStatus.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/util/HashMap.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar(javax/ws/rs/core/MediaType.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar(javax/ws/rs/core/Response.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar(org/codehaus/jackson/map/ObjectMapper.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/Exception.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/Throwable.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/io/Serializable.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/Enum.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/Comparable.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-server/1.14/jersey-server-1.14.jar(com/sun/jersey/api/core/PackagesResourceConfig.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-servlet/1.14/jersey-servlet-1.14.jar(com/sun/jersey/spi/container/servlet/ServletContainer.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/io/FileInputStream.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/apache-github-source-source/ql/target/hive-exec-2.2.0-SNAPSHOT.jar(org/apache/commons/lang3/StringUtils.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/apache-github-source-source/ql/target/hive-exec-2.2.0-SNAPSHOT.jar(org/apache/commons/lang3/ArrayUtils.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/apache-github-source-source/common/target/hive-common-2.2.0-SNAPSHOT.jar(org/apache/hadoop/hive/common/classification/InterfaceStability.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-hdfs/2.7.2/hadoop-hdfs-2.7.2.jar(org/apache/hadoop/hdfs/web/AuthFilter.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/apache-github-source-source/shims/common/target/hive-shims-common-2.2.0-SNAPSHOT.jar(org/apache/hadoop/hive/shims/Utils.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-common/2.7.2/hadoop-common-2.7.2.jar(org/apache/hadoop/security/UserGroupInformation.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-auth/2.7.2/hadoop-auth-2.7.2.jar(org/apache/hadoop/security/authentication/client/PseudoAuthenticator.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-auth/2.7.2/hadoop-auth-2.7.2.jar(org/apache/hadoop/security/authentication/server/PseudoAuthenticationHandler.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-common/2.7.2/hadoop-common-2.7.2.jar(org/apache/hadoop/util/GenericOptionsParser.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/eclipse/jetty/aggregate/jetty-all-server/7.6.0.v20120127/jetty-all-server-7.6.0.v20120127.jar(org/eclipse/jetty/rewrite/handler/RedirectPatternRule.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/eclipse/jetty/aggregate/jetty-all-server/7.6.0.v20120127/jetty-all-server-7.6.0.v20120127.jar(org/eclipse/jetty/rewrite/handler/RewriteHandler.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/eclipse/jetty/aggregate/jetty-all-server/7.6.0.v20120127/jetty-all-server-7.6.0.v20120127.jar(org/eclipse/jetty/server/Handler.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/eclipse/jetty/aggregate/jetty-all-server/7.6.0.v20120127/jetty-all-server-7.6.0.v20120127.jar(org/eclipse/jetty/server/Server.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/eclipse/jetty/aggregate/jetty-all-server/7.6.0.v20120127/jetty-all-server-7.6.0.v20120127.jar(org/eclipse/jetty/server/handler/HandlerList.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/eclipse/jetty/aggregate/jetty-all-server/7.6.0.v20120127/jetty-all-server-7.6.0.v20120127.jar(org/eclipse/jetty/servlet/FilterHolder.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/eclipse/jetty/aggregate/jetty-all-server/7.6.0.v20120127/jetty-all-server-7.6.0.v20120127.jar(org/eclipse/jetty/servlet/FilterMapping.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/eclipse/jetty/aggregate/jetty-all-server/7.6.0.v20120127/jetty-all-server-7.6.0.v20120127.jar(org/eclipse/jetty/servlet/ServletContextHandler.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/eclipse/jetty/aggregate/jetty-all-server/7.6.0.v20120127/jetty-all-server-7.6.0.v20120127.jar(org/eclipse/jetty/servlet/ServletHolder.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/eclipse/jetty/aggregate/jetty-all-server/7.6.0.v20120127/jetty-all-server-7.6.0.v20120127.jar(org/eclipse/jetty/xml/XmlConfiguration.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/slf4j/jul-to-slf4j/1.7.10/jul-to-slf4j-1.7.10.jar(org/slf4j/bridge/SLF4JBridgeHandler.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/javax/servlet/servlet-api/2.5/servlet-api-2.5.jar(javax/servlet/http/HttpServletRequest.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/apache-github-source-source/common/target/hive-common-2.2.0-SNAPSHOT.jar(org/apache/hadoop/hive/common/classification/InterfaceAudience$LimitedPrivate.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/apache-github-source-source/common/target/hive-common-2.2.0-SNAPSHOT.jar(org/apache/hadoop/hive/common/classification/InterfaceStability$Unstable.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/io/ByteArrayOutputStream.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/io/OutputStream.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/io/Closeable.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/AutoCloseable.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/io/Flushable.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(javax/xml/bind/annotation/XmlRootElement.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/commons/commons-exec/1.1/commons-exec-1.1.jar(org/apache/commons/exec/ExecuteException.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/security/PrivilegedExceptionAction.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/apache-github-source-source/shims/common/target/hive-shims-common-2.2.0-SNAPSHOT.jar(org/apache/hadoop/hive/shims/HadoopShimsSecure.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/apache-github-source-source/shims/common/target/hive-shims-common-2.2.0-SNAPSHOT.jar(org/apache/hadoop/hive/shims/ShimLoader.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/apache-github-source-source/shims/common/target/hive-shims-common-2.2.0-SNAPSHOT.jar(org/apache/hadoop/hive/shims/HadoopShims.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/apache-github-source-source/shims/common/target/hive-shims-common-2.2.0-SNAPSHOT.jar(org/apache/hadoop/hive/shims/HadoopShims$WebHCatJTShim.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-common/2.7.2/hadoop-common-2.7.2.jar(org/apache/hadoop/util/ToolRunner.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/InterruptedException.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/Boolean.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/apache-github-source-source/ql/target/hive-exec-2.2.0-SNAPSHOT.jar(org/apache/hadoop/hive/ql/ErrorMsg.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/Integer.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-mapreduce-client-core/2.7.2/hadoop-mapreduce-client-core-2.7.2.jar(org/apache/hadoop/mapred/JobStatus.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/io/FileNotFoundException.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/net/URISyntaxException.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/net/URI.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-common/2.7.2/hadoop-common-2.7.2.jar(org/apache/hadoop/fs/FileSystem.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/apache-github-source-source/metastore/target/hive-metastore-2.2.0-SNAPSHOT.jar(org/apache/hadoop/hive/metastore/api/MetaException.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-common/2.7.2/hadoop-common-2.7.2.jar(org/apache/hadoop/io/Text.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-common/2.7.2/hadoop-common-2.7.2.jar(org/apache/hadoop/security/Credentials.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-common/2.7.2/hadoop-common-2.7.2.jar(org/apache/hadoop/security/token/Token.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/thrift/libthrift/0.9.3/libthrift-0.9.3.jar(org/apache/thrift/TException.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/net/InetAddress.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/net/UnknownHostException.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/text/MessageFormat.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/util/regex/Matcher.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/util/regex/Pattern.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar(javax/ws/rs/DELETE.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar(javax/ws/rs/FormParam.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar(javax/ws/rs/GET.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar(javax/ws/rs/POST.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar(javax/ws/rs/PUT.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar(javax/ws/rs/Path.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar(javax/ws/rs/PathParam.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar(javax/ws/rs/Produces.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar(javax/ws/rs/QueryParam.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar(javax/ws/rs/core/Context.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar(javax/ws/rs/core/SecurityContext.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar(javax/ws/rs/core/UriInfo.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-mapreduce-client-core/2.7.2/hadoop-mapreduce-client-core-2.7.2.jar(org/apache/hadoop/mapred/JobProfile.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/Long.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/apache-github-source-source/common/target/hive-common-2.2.0-SNAPSHOT.jar(org/apache/hadoop/hive/common/JavaUtils.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/commons-lang/commons-lang/2.6/commons-lang-2.6.jar(org/apache/commons/lang/StringUtils.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-common/2.7.2/hadoop-common-2.7.2.jar(org/apache/hadoop/fs/FileStatus.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-server/1.14/jersey-server-1.14.jar(com/sun/jersey/api/wadl/config/WadlGeneratorConfig.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-server/1.14/jersey-server-1.14.jar(com/sun/jersey/api/wadl/config/WadlGeneratorDescription.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-server/1.14/jersey-server-1.14.jar(com/sun/jersey/server/wadl/generators/resourcedoc/WadlGeneratorResourceDocSupport.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/io/BufferedReader.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/io/InputStream.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/io/InputStreamReader.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/io/PrintWriter.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/util/Map$Entry.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/util/concurrent/Semaphore.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/commons/commons-exec/1.1/commons-exec-1.1.jar(org/apache/commons/exec/CommandLine.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/commons/commons-exec/1.1/commons-exec-1.1.jar(org/apache/commons/exec/DefaultExecutor.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/commons/commons-exec/1.1/commons-exec-1.1.jar(org/apache/commons/exec/ExecuteWatchdog.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/commons/commons-exec/1.1/commons-exec-1.1.jar(org/apache/commons/exec/PumpStreamHandler.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-common/2.7.2/hadoop-common-2.7.2.jar(org/apache/hadoop/util/Shell.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/Thread.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/Runnable.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar(javax/ws/rs/ext/ExceptionMapper.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar(javax/ws/rs/ext/Provider.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-server/1.14/jersey-server-1.14.jar(com/sun/jersey/api/NotFoundException.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-mapreduce-client-core/2.7.2/hadoop-mapreduce-client-core-2.7.2.jar(org/apache/hadoop/mapred/JobID.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-common/2.7.2/hadoop-common-2.7.2.jar(org/apache/hadoop/security/Groups.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/util/HashSet.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/util/Set.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/util/concurrent/ConcurrentHashMap.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/apache-github-source-source/common/target/hive-common-2.2.0-SNAPSHOT.jar(org/apache/hive/common/util/HiveVersionInfo.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/apache-github-source-source/common/target/hive-common-2.2.0-SNAPSHOT.jar(org/apache/hadoop/hive/common/classification/InterfaceStability$Evolving.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/io/DataInput.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/io/DataOutput.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-mapreduce-client-core/2.7.2/hadoop-mapreduce-client-core-2.7.2.jar(org/apache/hadoop/mapreduce/InputSplit.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/curator/curator-framework/2.7.1/curator-framework-2.7.1.jar(org/apache/curator/framework/CuratorFramework.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar(org/apache/zookeeper/CreateMode.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar(org/apache/zookeeper/KeeperException.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar(org/apache/zookeeper/ZooDefs.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar(org/apache/zookeeper/ZooDefs$Ids.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/io/OutputStreamWriter.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/net/URLConnection.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-mapreduce-client-core/2.7.2/hadoop-mapreduce-client-core-2.7.2.jar(org/apache/hadoop/mapred/JobClient.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-mapreduce-client-core/2.7.2/hadoop-mapreduce-client-core-2.7.2.jar(org/apache/hadoop/mapred/JobConf.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-mapreduce-client-core/2.7.2/hadoop-mapreduce-client-core-2.7.2.jar(org/apache/hadoop/mapred/RunningJob.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/util/StringTokenizer.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/Process.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/StringBuilder.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-common/2.7.2/hadoop-common-2.7.2.jar(org/apache/hadoop/io/NullWritable.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-mapreduce-client-core/2.7.2/hadoop-mapreduce-client-core-2.7.2.jar(org/apache/hadoop/mapreduce/InputFormat.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-mapreduce-client-core/2.7.2/hadoop-mapreduce-client-core-2.7.2.jar(org/apache/hadoop/mapreduce/JobContext.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-mapreduce-client-core/2.7.2/hadoop-mapreduce-client-core-2.7.2.jar(org/apache/hadoop/mapreduce/RecordReader.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-mapreduce-client-core/2.7.2/hadoop-mapreduce-client-core-2.7.2.jar(org/apache/hadoop/mapreduce/TaskAttemptContext.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-common/2.7.2/hadoop-common-2.7.2.jar(org/apache/hadoop/conf/Configured.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-mapreduce-client-core/2.7.2/hadoop-mapreduce-client-core-2.7.2.jar(org/apache/hadoop/mapreduce/Job.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-mapreduce-client-core/2.7.2/hadoop-mapreduce-client-core-2.7.2.jar(org/apache/hadoop/mapreduce/JobID.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-mapreduce-client-core/2.7.2/hadoop-mapreduce-client-core-2.7.2.jar(org/apache/hadoop/mapreduce/lib/output/NullOutputFormat.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-mapreduce-client-core/2.7.2/hadoop-mapreduce-client-core-2.7.2.jar(org/apache/hadoop/mapreduce/security/token/delegation/DelegationTokenIdentifier.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-common/2.7.2/hadoop-common-2.7.2.jar(org/apache/hadoop/util/Tool.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-common/2.7.2/hadoop-common-2.7.2.jar(org/apache/hadoop/conf/Configurable.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/ClassNotFoundException.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/curator/curator-framework/2.7.1/curator-framework-2.7.1.jar(org/apache/curator/framework/CuratorFrameworkFactory.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/curator/curator-client/2.7.1/curator-client-2.7.1.jar(org/apache/curator/retry/ExponentialBackoffRetry.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-mapreduce-client-core/2.7.2/hadoop-mapreduce-client-core-2.7.2.jar(org/apache/hadoop/mapreduce/Mapper.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/util/Iterator.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/util/LinkedList.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/util/concurrent/ExecutorService.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/util/concurrent/Executors.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/util/concurrent/TimeUnit.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-mapreduce-client-core/2.7.2/hadoop-mapreduce-client-core-2.7.2.jar(org/apache/hadoop/mapreduce/Mapper$Context.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/net/URLDecoder.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/util/Enumeration.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/util/Properties.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar(javax/ws/rs/core/UriBuilder.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/apache-github-source-source/common/target/hive-common-2.2.0-SNAPSHOT.jar(org/apache/hadoop/hive/common/LogUtils.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/Class.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/annotation/Annotation.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-annotations/2.7.2/hadoop-annotations-2.7.2.jar(org/apache/hadoop/classification/InterfaceAudience.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/org/apache/hadoop/hadoop-annotations/2.7.2/hadoop-annotations-2.7.2.jar(org/apache/hadoop/classification/InterfaceAudience$LimitedPrivate.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/annotation/Retention.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/annotation/RetentionPolicy.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/annotation/Target.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/annotation/ElementType.class)]]
[loading ZipFileIndexFileObject[/data/hiveptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar(javax/ws/rs/HttpMethod.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/SuppressWarnings.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(java/lang/Override.class)]]
[loading ZipFileIndexFileObject[/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar(sun/misc/Contended.class)]]
[loading RegularFileObject[/data/hiveptest/working/apache-github-source-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/HcatException$1.class]]
[loading RegularFileObject[/data/hiveptest/working/apache-github-source-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/HcatDelegator$1.class]]
[loading RegularFileObject[/data/hiveptest/working/apache-github-source-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/Server$1.class]]
[loading RegularFileObject[/data/hiveptest/working/apache-github-source-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/SecureProxySupport$3.class]]
[loading RegularFileObject[/data/hiveptest/working/apache-github-source-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/LauncherDelegator$1.class]]
[loading RegularFileObject[/data/hiveptest/working/apache-github-source-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/SecureProxySupport$1.class]]
[loading RegularFileObject[/data/hiveptest/working/apache-github-source-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/SecureProxySupport$2.class]]
[loading RegularFileObject[/data/hiveptest/working/apache-github-source-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/tool/HDFSStorage$1.class]]
[loading RegularFileObject[/data/hiveptest/working/apache-github-source-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/tool/TempletonUtils$1.class]]
[loading RegularFileObject[/data/hiveptest/working/apache-github-source-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/tool/ZooKeeperStorage$1.class]]
[loading RegularFileObject[/data/hiveptest/working/apache-github-source-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob$1.class]]
[loading RegularFileObject[/data/hiveptest/working/apache-github-source-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob$1$1.class]]
[loading RegularFileObject[/data/hiveptest/working/apache-github-source-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/tool/LogRetriever$1.class]]
[done in 3687 ms]
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-install-plugin:2.4:install (default-install) on project hive-jdbc: Failed to install artifact org.apache.hive:hive-jdbc:jar:standalone:2.2.0-SNAPSHOT: No space left on device -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn <goals> -rf :hive-jdbc
+ exit 1
'
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12855729 - PreCommit-HIVE-Build, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12855729/HIVE-16097.01.patch

{color:red}ERROR:{color} -1 due to no test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 5 failed/errored test(s), 10328 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestBeeLineDriver.testCliDriver[escape_comments] (batchId=229)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[schema_evol_text_vec_table] (batchId=147)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=224)
org.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query23] (batchId=224)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[vector_between_in] (batchId=119)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/3974/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/3974/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-3974/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 5 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12855729 - PreCommit-HIVE-Build, Test failures are not related. Committing. Will convert TODOs to jiras.]