[Further note, the error you get for the case items is:

select width_bucket(5, c2, case c1 when 1 then c1 * 2 else c1 * 3 end, 10) from e011_01;
OK
Failed with exception java.io.IOException:org.apache.hadoop.hive.ql.metadata.HiveException: Error evaluating width_bucket(5, c2, CASE WHEN ((c1 = 1)) THEN ((c1 * 2)) ELSE ((c1 * 3)) END, 10)
Time taken: 0.087 seconds, Another update, the case expression thing turns out to be another divide by zero thing that got swallowed up.

{code}
h exception java.io.IOException:org.apache.hadoop.hive.ql.metadata.HiveException: Error evaluating width_bucket(5, c2, CASE WHEN ((c1 = 1)) THEN ((c1 * 2)) ELSE ((c1 * 3)) END, 10)
java.io.IOException: org.apache.hadoop.hive.ql.metadata.HiveException: Error evaluating width_bucket(5, c2, CASE WHEN ((c1 = 1)) THEN ((c1 * 2)) ELSE ((c1 * 3)) END, 10)
	at org.apache.hadoop.hive.ql.exec.FetchTask.fetch(FetchTask.java:165)
	at org.apache.hadoop.hive.ql.Driver.getResults(Driver.java:2154)
	at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:253)
	at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:184)
	at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:403)
	at org.apache.hadoop.hive.cli.CliDriver.executeDriver(CliDriver.java:821)
	at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:759)
	at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:686)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.util.RunJar.run(RunJar.java:233)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:148)
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: Error evaluating width_bucket(5, c2, CASE WHEN ((c1 = 1)) THEN ((c1 * 2)) ELSE ((c1 * 3)) END, 10)
	at org.apache.hadoop.hive.ql.exec.SelectOperator.process(SelectOperator.java:93)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:897)
	at org.apache.hadoop.hive.ql.exec.TableScanOperator.process(TableScanOperator.java:130)
	at org.apache.hadoop.hive.ql.exec.FetchOperator.pushRow(FetchOperator.java:442)
	at org.apache.hadoop.hive.ql.exec.FetchOperator.pushRow(FetchOperator.java:434)
	at org.apache.hadoop.hive.ql.exec.FetchTask.fetch(FetchTask.java:147)
	... 13 more
Caused by: java.lang.ArithmeticException: / by zero
	at org.apache.hadoop.hive.ql.udf.generic.GenericUDFWidthBucket.evaluate(GenericUDFWidthBucket.java:75)
	at org.apache.hadoop.hive.ql.exec.ExprNodeGenericFuncEvaluator._evaluate(ExprNodeGenericFuncEvaluator.java:187)
	at org.apache.hadoop.hive.ql.exec.ExprNodeEvaluator.evaluate(ExprNodeEvaluator.java:80)
	at org.apache.hadoop.hive.ql.exec.ExprNodeEvaluatorHead._evaluate(ExprNodeEvaluatorHead.java:44)
	at org.apache.hadoop.hive.ql.exec.ExprNodeEvaluator.evaluate(ExprNodeEvaluator.java:80)
	at org.apache.hadoop.hive.ql.exec.ExprNodeEvaluator.evaluate(ExprNodeEvaluator.java:68)
	at org.apache.hadoop.hive.ql.exec.SelectOperator.process(SelectOperator.java:88)
	... 18 more
{code}, [~stakiar] Would you like to take a look?, Yup, I'll try to take a look later today, if not tomorrow., Initial patch, addresses the issues raised in the description. Added more qtests for decimal values, confirmed they lineup with Postgres.

Had to change the approach to use {{BigDecimal}} for the values of expr, min_value, and max_value instead of long. Decided to go with {{BigDecimal}} to support long values and doubles., Confirmed the same here. As for the grouping thing I think either Ashutosh or [~jcamachorodriguez] would need to comment on why that wouldn't work transparently.

Thanks for taking a look [~stakiar], Updated patch, addressed comments on the RB, some significant changes to the approach:

* Using {{FunctionRegistry.getCommonClassForComparison}} to find a common {{TypeInfo}} for {{minValue}}, {{maxValue}}, {{expr}} so that they can all be compared properly
** Once the proper {{TypeInfo}} is determined, {{ObjectInspectorConverters.getConverter}} is used to convert each argument to the correct type
** A {{switch...case}} statement is then used based on the common {{TypeInfo}}
* I changed the approach of the core algorithm for calculating the correct bucket. The old algorithm relied on the modulus operator, which had issues when run against doubles; the new algorithm is based on the approach taken by Postgres
* Added a lot more tests to the qfile, 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12865462/HIVE-16513.2.patch

{color:green}SUCCESS:{color} +1 due to 1 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 2 failed/errored test(s), 10635 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestAccumuloCliDriver.testCliDriver[accumulo_index] (batchId=225)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_if_expr] (batchId=143)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/4924/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/4924/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-4924/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 2 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12865462 - PreCommit-HIVE-Build, [~ashutoshc] test failures are unrelated. Comments on the RB have been addressed., Determination of Types  should be done in initialize() not in evaluate(). This will hurt performance and is wasteful. UDFs are allowed to assume that types determined in initialize don't change on per row basis. , 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12865814/HIVE-16513.3.patch

{color:green}SUCCESS:{color} +1 due to 1 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 1 failed/errored test(s), 10631 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestAccumuloCliDriver.testCliDriver[accumulo_index] (batchId=225)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/4969/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/4969/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-4969/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 1 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12865814 - PreCommit-HIVE-Build, [~ashutoshc], addressed comments. Test failures are flaky., 

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12866311/HIVE-16513.4.patch

{color:green}SUCCESS:{color} +1 due to 1 test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 1 failed/errored test(s), 10649 tests executed
*Failed tests:*
{noformat}
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_if_expr] (batchId=143)
{noformat}

Test results: https://builds.apache.org/job/PreCommit-HIVE-Build/5036/testReport
Console output: https://builds.apache.org/job/PreCommit-HIVE-Build/5036/console
Test logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-5036/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 1 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12866311 - PreCommit-HIVE-Build, +1, Pushed to master. Thanks, Sahil !, Does this need any documentation in the wiki (along with HIVE-15982)?, [~leftylev] the original ticket should suffice, Okay, thanks Carter., Hive 3.0.0 has been released so closing this jira.]