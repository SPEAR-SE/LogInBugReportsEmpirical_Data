[Do not redirect the error, let the error shown in console or record in stderr.log, Need code review or better idea to fix the issue. , 

{color:red}Overall{color}: -1 at least one tests failed

Here are the results of testing the latest attachment:
https://issues.apache.org/jira/secure/attachment/12765695/HIVE-12058.1.patch

{color:red}ERROR:{color} -1 due to no test(s) being added or modified.

{color:red}ERROR:{color} -1 due to 2 failed/errored test(s), 9659 tests executed
*Failed tests:*
{noformat}
org.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation
org.apache.hive.jdbc.TestSSL.testSSLVersion
{noformat}

Test results: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5595/testReport
Console output: http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5595/console
Test logs: http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-5595/

Messages:
{noformat}
Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 2 tests failed
{noformat}

This message is automatically generated.

ATTACHMENT ID: 12765695 - PreCommit-HIVE-TRUNK-Build, The two failures are not related. [~jxiang], could you review the change? Thanks, I think we should not remove "2>/dev/null". Otherwise, the script will break sometimes when mapredcp outputs more than we need.

In the failure scenario you have, does mparedcp outputs more or less than the normal output?, [~jxiang], when the hbase mapredcp fails, without 2>/dev/null, the error will go to stderr.log or console in our system, it will not become input for the for loop, so remving "2>/dev/null" does no harm. Hive still can startup. I think the only thing 2>/dev/null does is hiding the failure. 
With/Without the 2>/dev/null, when hbase mapredcp fails, there is no hbase related library added to the HADOOP_CLASSPATH. So there is
no functional change in Hive server by removing the redirection, and we get the error log to analyze the hbase failure for extra. 
, With the change, when hbase mapredcp works, this script may not work any more. For exmaple, on my cluster hbase mapredcp returns the following
{noformat}
2015-10-12 11:51:45,630 WARN  [main] util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
/data/tarball/hbase-0.98.11-hadoop2/lib/hbase-protocol-0.98.11-hadoop2.jar:/data/tarball/hbase-0.98.11-hadoop2/lib/hbase-client-0.98.11-hadoop2.jar:/data/tarball/hbase-0.98.11-hadoop2/lib/hbase-common-0.98.11-hadoop2.jar:/data/tarball/hbase-0.98.11-hadoop2/lib/hbase-server-0.98.11-hadoop2.jar:/data/tarball/hbase-0.98.11-hadoop2/lib/hbase-hadoop-compat-0.98.11-hadoop2.jar:/data/tarball/hbase-0.98.11-hadoop2/lib/netty-3.6.6.Final.jar:/data/tarball/hbase-0.98.11-hadoop2/lib/protobuf-java-2.5.0.jar:/data/tarball/hbase-0.98.11-hadoop2/lib/zookeeper-3.4.6.jar:/data/tarball/hbase-0.98.11-hadoop2/lib/high-scale-lib-1.1.1.jar:/data/tarball/hbase-0.98.11-hadoop2/lib/guava-12.0.1.jar:/data/tarball/hbase-0.98.11-hadoop2/lib/htrace-core-2.04.jar
{noformat}, [~jxiang], have you try the changed script in your system? You can just type hive to start cli, I think the warning will not end up in your classpath. , You are right. The warning doesn't mess up the classpath for me. +1, Integrated into trunk and branch 1. Thanks Yongzhi for the patch., Thanks [~jxiang] for reviewing the patch., Hi folks! What about clusters where an HBase instance doesn't exist? It seems the problem here is that the hive script itself is making assumptions about the configuration. Usually, there are feature flags to turn off and on features that may not be available.]